---------------------------------------------------------------------
----------------------------- MEETING 1 -----------------------------
---------------------------------------------------------------------

Tabea mail:

I trained two different dictionaries for the two differnt types of noise that I mostly considered, Baseline Wander (BW) and Muscle Artefacts (MA).

The BW is the easier one. I just use the Basis Pusuit Denoising Algorithm (BPDN) to sparsly approximate the BW that is included in the noisy signal. Then I substract the BW approximation from the noisy signal and obtain the denoised one. The code is in the BW_denoising function of the complete_denoising_BW_MA file. 

The Denoising of the MA is a little more complicated. The dictionary has a shape (13, 132, 100), basically representing 13 different dictionaries. Every input ECG is split up into frames of 132 samples and with a threshhold on the maximal deviation from the mean it is determined whether there is a QRS complex in the frame and what position it is on. The 132 samples are now again split up into 12 windows and we train one dictionary only on training data that has the R peak in the specific window. The 13th dictionary is for the ECG frames, that do not contain a QRS complex at all. The corresponding function is called MA_denoising.

I attached the paper that describes these two approaches.

For training and testing I used data from the BUT QDB (https://physionet.org/content/butqdb/1.0.0/#files-panel). I attached a numpy array with the chosen test signals (the ones with perfect quality rating).

The noise that I added ontop of the clean signals came from the MIT-BIH Noise Stress Test Database (https://physionet.org/content/nstdb/1.0.0/).


---------------------------------------------------------------------
----------------------------- MEETING 2 -----------------------------
---------------------------------------------------------------------

QUESTIONS
---------

Data generation
1. Is the noise file correct - bw.dat file from MIT-BIH with wfdb python module?
2. Is the data generation process correct - augmenting the test signals with the BW noise?
3. Is adding the noise correct - resampling to 250Hz + cutting both test and noise signals at independent random locations + summing them?
4. What does an alpha sparse representation look like - array of sum 1 / with (0, 1) elements?

Previous implementation
1. How were the dictionaries learned - an alpha wasn't there learned as well?

FISTA-Net implementation
1. Is the gaussian noise assumption for epsilon correct - can we get rid of the W gradient operator? - not

Additional things needed
1. code for BPDN - received
2. one (y, alpha) pair that works well with the dictionary - I can generate this with BPDN


NOTES
-----

Később sparse representation lehet jobb lesz a bemenet sparse reprezentációját nézni
szimmetria loss-t ki kell venni
ha egy plusz ReLU-t betettünk valahol az Abel trf miatt
nagy a learning rate
egy batch-re túltanítani, mert úgy nagyon gyorsan overfittelnie kell


---------------------------------------------------------------------
----------------------------- MEETING 3 -----------------------------
---------------------------------------------------------------------

- The last 2/3 (138) of the test signals are all zero arrays
- The total magnitudes of the non-zero test signals are very different from each other
- Is BPDN (cvxopt) always going to yield the optimal result for a given dictionary?

- presented materials/MEETING03_presentation.pdf

-> ther might be BW noise in the target signal as well - real-world signal data
-> orthogonal matching pursuit for the initial approximation

TODO:
    1. Perform more BPDN iterations for the inputs
    2. F and F_theta as identity matrices to avoid enforcing  sparsity in a latent space 
    3. Compare FISTA-Net sparse representation with BPDN
        - generate BPDN estimations for validation data
        - implement plotting comparison with generated BPDN signals
    4. Save all run parameters as a main log file, outside of model checkpoints


---------------------------------------------------------------------
----------------------------- MEETING 4 -----------------------------
---------------------------------------------------------------------

Fixes:
- b in Ax=b is not the measurement vector in our case, but rather the noise on the measurement vector, i.e. y_target - x_in
- memmory leak bug caused by not closing plt figures correctly

Observations:
- letting BPDN run for 1 iteration doesn't seem sufficient enough by looking at the alpha estimates (see workspace/BPDN_iteration_analysis.ipynb) - running for more (3, 5) iterations should be a better initial estimate, but FISTA-Net still finds other non-sparse solutions, that seemingly have no relation to the BPDN input
    - the model didn't really work on the max iteration BPDN input either (at least not for specifically enforcing sparcity), because it only learned to keep the input untouched
- getting rid of the F and F_theta convolutional blocks makes sense, now we measure sparcity of the actual alpha estimates, but the sparcity measurement itself might still not be adequate:
    - sparcity = mean(abs(alpha))
        - encourages low values accross the whole estimate,
        - rather than a large number of zeros, and a few high-value non-zero elements like BPDN estimates (again, see workspace/BPDN_iteration_analysis.ipynb)
    - adding the percentage of close-to-zero elements in alpha doesn't enforce sparcity, even slows down convergence
    - getting rid of the conv blocks doesn't help with sparcity either, only slows down convergence
    - there is a sparcity term (l1_loss(pred, y_target, 0.1)) in the main discrepancy loss - we could try increasing the weight of this
- when running training for longer (10k epochs), the model seems to reset (find new direction with very high loss) every 3-4k epochs
- was the sent test data correct? | BPM-s are very different between samples, is this correct? - maybe sparcity could easier be enforced on a more homogenous dataset

TODOS:
1. Try to set the sparcity weight higher at the start for more iteration runs
2. Calculate and show BPDN-FISTANet MSE comparison in plots - pattern analysis
3. Reduce dataset to similar BPM samples
4. Show initial BPDN estimate inputs on plots:
    - include on alpha plots
    - include denoising result on comp plots
5. Save all run parameters as a main log file, outside of model checkpoints
6. Initialize training input with SPARSE random vector (or threshold the limited iteration BPDN inputs)


---------------------------------------------------------------------
----------------------------- MEETING 5 -----------------------------
---------------------------------------------------------------------

TODOS:
1. Plot all elements of the loss function, not only the final sum
2. Implement repeatable experiments (fixed random seeds for everything) - https://alexandruburlacu.github.io/posts/2023-01-12-mlops-for-independent-research
3. Take the sparcity loss value (L1) from alpha after normalization - we don't want to punish very high values
4. Compare L1 and MSE values of BPDN and FISTA-Net accross the entire validation set
5. Perform the good reconstruction with random initialization
6. We can also think of other datasets to use for a paper e.g. PhysioNet - for example the test signals already contain one kind of noise 
7. Muscle Artifact noise with the same model
8. Plot alpha without BPDN to see the spikes

- run 2024-05-24-16-07-49_1000-lam-pred-spars_5iter-init resulted in a very good reconstruction, however, alpha is still not sparse as we expect it
    - 1000 lambda_pred_spars refers to the L1 loss of the target - denoised prediction, not at the L1 loss of alpha
    -> this was only emphasizing discrepancy loss, but through L1 (L1(target-pred)) -> maybe using only the L1 loss would be sufficient for the discrepancy loss
- we could min-max normalize alpha before calculating the L1 norm to avoid penalyzing very high values (as BDPN also produces some high values)

