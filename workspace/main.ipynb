{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7baaefd-888e-4894-9776-d7291899f1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.fistanet.M5FISTANet import FISTANet\n",
    "from src.fistanet.M5FISTANetNoST import FISTANetNoST\n",
    "from src.fistanet.loader import DataSplit\n",
    "from src.fistanet.solver import Solver\n",
    "from os.path import join as pjoin\n",
    "from torchsummary import summary\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9846d1b1-46fe-471c-b4a9-93e7a8ce0ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data'\n",
    "DATA_FILE_GEN = 'generated/BW_master_10000_2024-04-07-12-43-32.pkl'\n",
    "DATA_FILE_SIGS = 'steinbrinker/testing_data_mvg_avg.npy'\n",
    "DATA_FILE_BW = 'mit-bih/bw'\n",
    "DATA_FILE_GAUSS = 'generated/gaussian_noise.npy'\n",
    "# DATA_FILE_BPDN = 'generated/BW_alphas-BPDN_10000_2024-04-07-12-43-32.npy'\n",
    "# DATA_FILE_BPDN = 'generated/BW_alphas-BPDN-1iters_10000_2024-04-07-12-43-32.npy'\n",
    "# DATA_FILE_BPDN = 'generated/BW_alphas-BPDN-3iters_10000_2024-04-07-12-43-32.npy'\n",
    "DATA_FILE_BPDN = 'generated/BW_alphas-BPDN-5iters_10000_2024-04-07-12-43-32.npy'\n",
    "DICT_FILE_BW = 'steinbrinker/dictionary_BW_real_data.npy'\n",
    "NOISE_TYPE = 'bw'\n",
    "if NOISE_TYPE == 'bw':\n",
    "    DATA_FILE_NOISE = DATA_FILE_BW\n",
    "elif NOISE_TYPE == 'gauss':\n",
    "    DATA_FILE_NOISE = DATA_FILE_GAUSS\n",
    "DATA_SIZE = 10000\n",
    "BATCH_SIZE = 1000\n",
    "TVT_SPLIT = {\n",
    "    'train': 80,\n",
    "    'valid': 10,\n",
    "    'test': 10\n",
    "}\n",
    "\n",
    "FNET_LAYER_NO = 4\n",
    "FNET_FEATURE_NO = 32\n",
    "LAMBDA_SP_LOSS = 1\n",
    "LAMBDA_PRED_SP_LOSS = 0\n",
    "LAMBDA_SYM_LOSS = 1e-1\n",
    "\n",
    "EPOCH_NO = 10000\n",
    "TEST_EPOCH = 10001\n",
    "LR_DEC_AFTER = 10000\n",
    "LR_DEC_EVERY = 10\n",
    "START_EPOCH = 0\n",
    "START_RUN = '2024-05-05-13-10-59'\n",
    "LOG_INTERVAL = 4\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "\n",
    "\n",
    "# DATA_FILE_GEN = 'generated/BW_master_7999-8000_2024-04-07-12-43-32.pkl'\n",
    "# DATA_SIZE = 2\n",
    "# BATCH_SIZE = 1\n",
    "# TVT_SPLIT = {\n",
    "#     'train': 50,\n",
    "#     'valid': 50,\n",
    "#     'test': 0\n",
    "# }\n",
    "# FNET_LAYER_NO = 4\n",
    "# FNET_FEATURE_NO = 16\n",
    "# LEARNING_RATE = 1e-3\n",
    "# LAMBDA_SP_LOSS = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74e188c4-1bdd-43bd-8fad-aa3c615aefbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ldr, val_ldr, tst_ldr = DataSplit(DATA_DIR, NOISE_TYPE, DATA_FILE_GEN, DATA_FILE_SIGS, DATA_FILE_NOISE, DATA_FILE_BPDN, TVT_SPLIT, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45bcd124-d0c4-4140-8607-2ed4ff8a8003",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36276fd7-c4b4-49e2-859c-6d09d87aae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Psi = np.load(pjoin(DATA_DIR, DICT_FILE_BW))\n",
    "Psi = torch.from_numpy(Psi)\n",
    "Psi = Psi.clone().detach().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03f7f9ea-e218-4790-84e8-caf0a10489d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fista_net = FISTANet(FNET_LAYER_NO, FNET_FEATURE_NO)\n",
    "fista_net = fista_net.to(device)# define arguments of fista_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42d7c70b-85c2-4256-b761-683d59095c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fista_net = FISTANetNoST(FNET_LAYER_NO, FNET_FEATURE_NO)\n",
    "# fista_net = fista_net.to(device)# define arguments of fista_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f12c4823-35ea-41b9-97a1-bf6746dc204d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters fista net: 74599\n"
     ]
    }
   ],
   "source": [
    "# summary(fista_net, input_size=(1, 64, 298), device=str(device))\n",
    "print('Total number of parameters fista net:',\n",
    "          sum(p.numel() for p in fista_net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3579c675-faba-4918-bffe-7a3ee0c8afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "if START_EPOCH:\n",
    "    dt = START_RUN\n",
    "args = {\n",
    "    'model_name': 'FISTANet',\n",
    "    'num_epochs': EPOCH_NO,\n",
    "    'lr': LEARNING_RATE,\n",
    "    'data_dir': DATA_DIR,\n",
    "    'save_path': f'./runs/{dt}',\n",
    "    'start_epoch': START_EPOCH,\n",
    "    'start_run': START_RUN,\n",
    "    'multi_gpu': False,\n",
    "    'device': device,\n",
    "    'log_interval': LOG_INTERVAL,\n",
    "    'test_epoch': TEST_EPOCH,\n",
    "    'lr_dec_after': LR_DEC_AFTER,\n",
    "    'lr_dec_every': LR_DEC_EVERY,\n",
    "    'lambda_sp_loss': LAMBDA_SP_LOSS,\n",
    "    'lambda_pred_sp_loss': LAMBDA_PRED_SP_LOSS,\n",
    "    'lambda_sym_loss': LAMBDA_SYM_LOSS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37c787d6-372b-4189-b428-133486557995",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Solver(fista_net, Psi, trn_ldr, val_ldr, BATCH_SIZE, args, tst_ldr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dba58ed-bcde-4a91-994f-1b69c8decd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 1...\n",
      "\n",
      "Train Epoch: 1 [0/8000 (0%)]\tBatch Loss: 135937762.797572\tLearning Rate (w_theta): 0.001000\t TIME:6.7s\n",
      "\t\t\t\tDisc: 135761888.851090\t\tSym: 175843.375000\t\tSpars: 30.571482\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.501000 | TVb: -1.999000 | GSw: -0.201000 | GSb: 0.099000 | TSUw: 0.499000 | TSUb: 0.001000\n",
      "\n",
      "Train Epoch: 1 [4000/8000 (50%)]\tBatch Loss: 141908036.054484\tLearning Rate (w_theta): 0.001000\t TIME:8.4s\n",
      "\t\t\t\tDisc: 141733877.067385\t\tSym: 174107.875000\t\tSpars: 51.112099\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.504344 | TVb: -2.002264 | GSw: -0.204998 | GSb: 0.095002 | TSUw: 0.495002 | TSUb: 0.004998\n",
      "Validating epoch 1...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 149515207.36051577\n",
      "Average validation loss: 133115207.49378775\n",
      "Training epoch 2...\n",
      "\n",
      "Train Epoch: 2 [0/8000 (0%)]\tBatch Loss: 145685645.471958\tLearning Rate (w_theta): 0.001000\t TIME:10.6s\n",
      "\t\t\t\tDisc: 145503403.010898\t\tSym: 182134.765625\t\tSpars: 107.695435\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.508085 | TVb: -2.005761 | GSw: -0.208973 | GSb: 0.091028 | TSUw: 0.491026 | TSUb: 0.008970\n",
      "\n",
      "Train Epoch: 2 [4000/8000 (50%)]\tBatch Loss: 104829797.096162\tLearning Rate (w_theta): 0.001000\t TIME:12.2s\n",
      "\t\t\t\tDisc: 104688054.230943\t\tSym: 141539.609375\t\tSpars: 203.255844\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.512116 | TVb: -2.009375 | GSw: -0.212861 | GSb: 0.087140 | TSUw: 0.487133 | TSUb: 0.012852\n",
      "Validating epoch 2...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 131158884.62311944\n",
      "Average validation loss: 99764290.41365059\n",
      "Training epoch 3...\n",
      "\n",
      "Train Epoch: 3 [0/8000 (0%)]\tBatch Loss: 60623578.093495\tLearning Rate (w_theta): 0.001000\t TIME:14.3s\n",
      "\t\t\t\tDisc: 60521935.794728\t\tSym: 101313.046875\t\tSpars: 329.251892\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.516420 | TVb: -2.013305 | GSw: -0.216503 | GSb: 0.083501 | TSUw: 0.483483 | TSUb: 0.016483\n",
      "\n",
      "Train Epoch: 3 [4000/8000 (50%)]\tBatch Loss: 11084115.113177\tLearning Rate (w_theta): 0.001000\t TIME:16.0s\n",
      "\t\t\t\tDisc: 11040534.561419\t\tSym: 43235.761719\t\tSpars: 344.790039\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.520810 | TVb: -2.017548 | GSw: -0.219562 | GSb: 0.080447 | TSUw: 0.480415 | TSUb: 0.019528\n",
      "Validating epoch 3...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 95139900.03134982\n",
      "Average validation loss: 66510060.51545028\n",
      "Training epoch 4...\n",
      "\n",
      "Train Epoch: 4 [0/8000 (0%)]\tBatch Loss: 1607.557538\tLearning Rate (w_theta): 0.001000\t TIME:18.1s\n",
      "\t\t\t\tDisc: 1305.517362\t\tSym: 262.400208\t\tSpars: 39.639969\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.524365 | TVb: -2.020991 | GSw: -0.221750 | GSb: 0.078264 | TSUw: 0.478220 | TSUb: 0.021705\n",
      "\n",
      "Train Epoch: 4 [4000/8000 (50%)]\tBatch Loss: 4712275.365163\tLearning Rate (w_theta): 0.001000\t TIME:19.8s\n",
      "\t\t\t\tDisc: 4514236.773977\t\tSym: 197287.343750\t\tSpars: 751.247437\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.526700 | TVb: -2.023299 | GSw: -0.223264 | GSb: 0.076754 | TSUw: 0.476701 | TSUb: 0.023211\n",
      "Validating epoch 4...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 71613845.27770679\n",
      "Average validation loss: 49992880.10392659\n",
      "Training epoch 5...\n",
      "\n",
      "Train Epoch: 5 [0/8000 (0%)]\tBatch Loss: 435376.453378\tLearning Rate (w_theta): 0.001000\t TIME:21.8s\n",
      "\t\t\t\tDisc: 396511.753396\t\tSym: 38492.203125\t\tSpars: 372.496857\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.527855 | TVb: -2.024621 | GSw: -0.224331 | GSb: 0.075695 | TSUw: 0.475631 | TSUb: 0.024271\n",
      "\n",
      "Train Epoch: 5 [4000/8000 (50%)]\tBatch Loss: 200193.170010\tLearning Rate (w_theta): 0.001000\t TIME:23.5s\n",
      "\t\t\t\tDisc: 178949.722378\t\tSym: 20980.294922\t\tSpars: 263.152710\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.528588 | TVb: -2.025503 | GSw: -0.225069 | GSb: 0.074962 | TSUw: 0.474890 | TSUb: 0.025005\n",
      "Validating epoch 5...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 57365599.97291588\n",
      "Average validation loss: 40120116.84395143\n",
      "Training epoch 6...\n",
      "\n",
      "Train Epoch: 6 [0/8000 (0%)]\tBatch Loss: 567410.106193\tLearning Rate (w_theta): 0.001000\t TIME:25.7s\n",
      "\t\t\t\tDisc: 522473.530967\t\tSym: 44545.601562\t\tSpars: 390.973663\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.529126 | TVb: -2.026110 | GSw: -0.225583 | GSb: 0.074454 | TSUw: 0.474374 | TSUb: 0.025517\n",
      "\n",
      "Train Epoch: 6 [4000/8000 (50%)]\tBatch Loss: 109185.556817\tLearning Rate (w_theta): 0.001000\t TIME:27.4s\n",
      "\t\t\t\tDisc: 96907.969095\t\tSym: 12054.416016\t\tSpars: 223.171707\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.529550 | TVb: -2.026538 | GSw: -0.225943 | GSb: 0.074100 | TSUw: 0.474013 | TSUb: 0.025875\n",
      "Validating epoch 6...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 47841220.7221774\n",
      "Average validation loss: 33435466.92233935\n",
      "Training epoch 7...\n",
      "\n",
      "Train Epoch: 7 [0/8000 (0%)]\tBatch Loss: 11960.602138\tLearning Rate (w_theta): 0.001000\t TIME:29.4s\n",
      "\t\t\t\tDisc: 9408.168582\t\tSym: 2449.269775\t\tSpars: 103.163780\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.529862 | TVb: -2.026832 | GSw: -0.226190 | GSb: 0.073856 | TSUw: 0.473764 | TSUb: 0.026121\n",
      "\n",
      "Train Epoch: 7 [4000/8000 (50%)]\tBatch Loss: 2448.576201\tLearning Rate (w_theta): 0.001000\t TIME:31.1s\n",
      "\t\t\t\tDisc: 1661.716155\t\tSym: 730.043030\t\tSpars: 56.817017\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530080 | TVb: -2.027034 | GSw: -0.226360 | GSb: 0.073690 | TSUw: 0.473594 | TSUb: 0.026289\n",
      "Validating epoch 7...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 41007378.73113728\n",
      "Average validation loss: 28659108.9083529\n",
      "Training epoch 8...\n",
      "\n",
      "Train Epoch: 8 [0/8000 (0%)]\tBatch Loss: 1051.858508\tLearning Rate (w_theta): 0.001000\t TIME:33.3s\n",
      "\t\t\t\tDisc: 652.389114\t\tSym: 359.743896\t\tSpars: 39.725498\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530231 | TVb: -2.027171 | GSw: -0.226475 | GSb: 0.073576 | TSUw: 0.473478 | TSUb: 0.026403\n",
      "\n",
      "Train Epoch: 8 [4000/8000 (50%)]\tBatch Loss: 541.192092\tLearning Rate (w_theta): 0.001000\t TIME:34.9s\n",
      "\t\t\t\tDisc: 328.994663\t\tSym: 182.416245\t\tSpars: 29.781185\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530334 | TVb: -2.027264 | GSw: -0.226553 | GSb: 0.073499 | TSUw: 0.473400 | TSUb: 0.026481\n",
      "Validating epoch 8...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 35881534.413450636\n",
      "Average validation loss: 25076769.02470906\n",
      "Training epoch 9...\n",
      "\n",
      "Train Epoch: 9 [0/8000 (0%)]\tBatch Loss: 395.657827\tLearning Rate (w_theta): 0.001000\t TIME:37.0s\n",
      "\t\t\t\tDisc: 234.379240\t\tSym: 135.210480\t\tSpars: 26.068108\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530405 | TVb: -2.027327 | GSw: -0.226606 | GSb: 0.073447 | TSUw: 0.473347 | TSUb: 0.026534\n",
      "\n",
      "Train Epoch: 9 [4000/8000 (50%)]\tBatch Loss: 303.340949\tLearning Rate (w_theta): 0.001000\t TIME:38.7s\n",
      "\t\t\t\tDisc: 174.992869\t\tSym: 104.493019\t\tSpars: 23.855061\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530453 | TVb: -2.027369 | GSw: -0.226642 | GSb: 0.073412 | TSUw: 0.473311 | TSUb: 0.026569\n",
      "Validating epoch 9...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 31894732.861102365\n",
      "Average validation loss: 22290491.12060516\n",
      "Training epoch 10...\n",
      "\n",
      "Train Epoch: 10 [0/8000 (0%)]\tBatch Loss: 286.896777\tLearning Rate (w_theta): 0.001000\t TIME:40.9s\n",
      "\t\t\t\tDisc: 160.113830\t\tSym: 102.875076\t\tSpars: 23.907871\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530486 | TVb: -2.027399 | GSw: -0.226666 | GSb: 0.073388 | TSUw: 0.473286 | TSUb: 0.026593\n",
      "\n",
      "Train Epoch: 10 [4000/8000 (50%)]\tBatch Loss: 235.663954\tLearning Rate (w_theta): 0.001000\t TIME:42.6s\n",
      "\t\t\t\tDisc: 130.287916\t\tSym: 83.324417\t\tSpars: 22.051620\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530508 | TVb: -2.027418 | GSw: -0.226683 | GSb: 0.073372 | TSUw: 0.473270 | TSUb: 0.026610\n",
      "Validating epoch 10...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 28705283.77980274\n",
      "Average validation loss: 20061464.372597564\n",
      "Training epoch 11...\n",
      "\n",
      "Train Epoch: 11 [0/8000 (0%)]\tBatch Loss: 219.007729\tLearning Rate (w_theta): 0.001000\t TIME:45.6s\n",
      "\t\t\t\tDisc: 117.189191\t\tSym: 80.092735\t\tSpars: 21.725803\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530524 | TVb: -2.027431 | GSw: -0.226694 | GSb: 0.073361 | TSUw: 0.473259 | TSUb: 0.026621\n",
      "\n",
      "Train Epoch: 11 [4000/8000 (50%)]\tBatch Loss: 225.613334\tLearning Rate (w_theta): 0.001000\t TIME:47.2s\n",
      "\t\t\t\tDisc: 120.154602\t\tSym: 83.429375\t\tSpars: 22.029358\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530535 | TVb: -2.027440 | GSw: -0.226701 | GSb: 0.073353 | TSUw: 0.473251 | TSUb: 0.026628\n",
      "Validating epoch 11...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 26095731.58258595\n",
      "Average validation loss: 18237712.98847928\n",
      "Training epoch 12...\n",
      "\n",
      "Train Epoch: 12 [0/8000 (0%)]\tBatch Loss: 204.386822\tLearning Rate (w_theta): 0.001000\t TIME:49.4s\n",
      "\t\t\t\tDisc: 106.700486\t\tSym: 76.350685\t\tSpars: 21.335651\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530542 | TVb: -2.027446 | GSw: -0.226706 | GSb: 0.073349 | TSUw: 0.473246 | TSUb: 0.026633\n",
      "\n",
      "Train Epoch: 12 [4000/8000 (50%)]\tBatch Loss: 188.322227\tLearning Rate (w_theta): 0.001000\t TIME:51.1s\n",
      "\t\t\t\tDisc: 95.499988\t\tSym: 72.229057\t\tSpars: 20.593182\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530547 | TVb: -2.027450 | GSw: -0.226710 | GSb: 0.073345 | TSUw: 0.473243 | TSUb: 0.026636\n",
      "Validating epoch 12...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 23921102.836912144\n",
      "Average validation loss: 16717918.229986351\n",
      "Training epoch 13...\n",
      "\n",
      "Train Epoch: 13 [0/8000 (0%)]\tBatch Loss: 181.636106\tLearning Rate (w_theta): 0.001000\t TIME:53.2s\n",
      "\t\t\t\tDisc: 91.135831\t\tSym: 69.819901\t\tSpars: 20.680374\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530551 | TVb: -2.027452 | GSw: -0.226712 | GSb: 0.073343 | TSUw: 0.473240 | TSUb: 0.026639\n",
      "\n",
      "Train Epoch: 13 [4000/8000 (50%)]\tBatch Loss: 156.805092\tLearning Rate (w_theta): 0.001000\t TIME:54.8s\n",
      "\t\t\t\tDisc: 76.755876\t\tSym: 60.524147\t\tSpars: 19.525068\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530554 | TVb: -2.027454 | GSw: -0.226713 | GSb: 0.073342 | TSUw: 0.473239 | TSUb: 0.026640\n",
      "Validating epoch 13...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 22081030.76259481\n",
      "Average validation loss: 15431936.663456792\n",
      "Training epoch 14...\n",
      "\n",
      "Train Epoch: 14 [0/8000 (0%)]\tBatch Loss: 166.405881\tLearning Rate (w_theta): 0.001000\t TIME:57.0s\n",
      "\t\t\t\tDisc: 81.494531\t\tSym: 64.737175\t\tSpars: 20.174175\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530556 | TVb: -2.027455 | GSw: -0.226714 | GSb: 0.073341 | TSUw: 0.473238 | TSUb: 0.026641\n",
      "\n",
      "Train Epoch: 14 [4000/8000 (50%)]\tBatch Loss: 151.838585\tLearning Rate (w_theta): 0.001000\t TIME:58.7s\n",
      "\t\t\t\tDisc: 72.585545\t\tSym: 59.520020\t\tSpars: 19.733021\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530557 | TVb: -2.027456 | GSw: -0.226715 | GSb: 0.073340 | TSUw: 0.473237 | TSUb: 0.026642\n",
      "Validating epoch 14...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 20503825.106109295\n",
      "Average validation loss: 14329665.861519108\n",
      "Training epoch 15...\n",
      "\n",
      "Train Epoch: 15 [0/8000 (0%)]\tBatch Loss: 142.333453\tLearning Rate (w_theta): 0.001000\t TIME:60.8s\n",
      "\t\t\t\tDisc: 67.508799\t\tSym: 55.533077\t\tSpars: 19.291576\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530559 | TVb: -2.027457 | GSw: -0.226716 | GSb: 0.073339 | TSUw: 0.473237 | TSUb: 0.026642\n",
      "\n",
      "Train Epoch: 15 [4000/8000 (50%)]\tBatch Loss: 135.923532\tLearning Rate (w_theta): 0.001000\t TIME:62.4s\n",
      "\t\t\t\tDisc: 64.744584\t\tSym: 52.403698\t\tSpars: 18.775249\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530559 | TVb: -2.027457 | GSw: -0.226716 | GSb: 0.073339 | TSUw: 0.473236 | TSUb: 0.026643\n",
      "Validating epoch 15...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 19136912.7895092\n",
      "Average validation loss: 13374363.762339767\n",
      "Training epoch 16...\n",
      "\n",
      "Train Epoch: 16 [0/8000 (0%)]\tBatch Loss: 135.643728\tLearning Rate (w_theta): 0.001000\t TIME:64.6s\n",
      "\t\t\t\tDisc: 63.762615\t\tSym: 52.817738\t\tSpars: 19.063375\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530560 | TVb: -2.027457 | GSw: -0.226716 | GSb: 0.073339 | TSUw: 0.473236 | TSUb: 0.026643\n",
      "\n",
      "Train Epoch: 16 [4000/8000 (50%)]\tBatch Loss: 129.624189\tLearning Rate (w_theta): 0.001000\t TIME:66.2s\n",
      "\t\t\t\tDisc: 61.007013\t\tSym: 50.011086\t\tSpars: 18.606091\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530561 | TVb: -2.027457 | GSw: -0.226716 | GSb: 0.073339 | TSUw: 0.473236 | TSUb: 0.026643\n",
      "Validating epoch 16...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 17940863.8695168\n",
      "Average validation loss: 12538473.824825065\n",
      "Training epoch 17...\n",
      "\n",
      "Train Epoch: 17 [0/8000 (0%)]\tBatch Loss: 120.894218\tLearning Rate (w_theta): 0.001000\t TIME:68.4s\n",
      "\t\t\t\tDisc: 56.249058\t\tSym: 46.436176\t\tSpars: 18.208984\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530561 | TVb: -2.027457 | GSw: -0.226716 | GSb: 0.073339 | TSUw: 0.473236 | TSUb: 0.026643\n",
      "\n",
      "Train Epoch: 17 [4000/8000 (50%)]\tBatch Loss: 122.976491\tLearning Rate (w_theta): 0.001000\t TIME:70.1s\n",
      "\t\t\t\tDisc: 57.026934\t\tSym: 47.447681\t\tSpars: 18.501875\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530562 | TVb: -2.027457 | GSw: -0.226716 | GSb: 0.073339 | TSUw: 0.473236 | TSUb: 0.026643\n",
      "Validating epoch 17...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 16885526.067359615\n",
      "Average validation loss: 11800923.43389955\n",
      "Training epoch 18...\n",
      "\n",
      "Train Epoch: 18 [0/8000 (0%)]\tBatch Loss: 115.205853\tLearning Rate (w_theta): 0.001000\t TIME:72.2s\n",
      "\t\t\t\tDisc: 53.624299\t\tSym: 43.713799\t\tSpars: 17.867756\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530562 | TVb: -2.027457 | GSw: -0.226716 | GSb: 0.073339 | TSUw: 0.473236 | TSUb: 0.026643\n",
      "\n",
      "Train Epoch: 18 [4000/8000 (50%)]\tBatch Loss: 111.445642\tLearning Rate (w_theta): 0.001000\t TIME:73.9s\n",
      "\t\t\t\tDisc: 51.866815\t\tSym: 41.955090\t\tSpars: 17.623737\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530562 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026643\n",
      "Validating epoch 18...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 15947447.646172393\n",
      "Average validation loss: 11145322.768000279\n",
      "Training epoch 19...\n",
      "\n",
      "Train Epoch: 19 [0/8000 (0%)]\tBatch Loss: 111.642246\tLearning Rate (w_theta): 0.001000\t TIME:76.1s\n",
      "\t\t\t\tDisc: 52.153037\t\tSym: 41.781338\t\tSpars: 17.707870\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026643\n",
      "\n",
      "Train Epoch: 19 [4000/8000 (50%)]\tBatch Loss: 110.385283\tLearning Rate (w_theta): 0.001000\t TIME:77.7s\n",
      "\t\t\t\tDisc: 51.432406\t\tSym: 41.260479\t\tSpars: 17.692398\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026643\n",
      "Validating epoch 19...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 15108114.0634548\n",
      "Average validation loss: 10558732.486154592\n",
      "Training epoch 20...\n",
      "\n",
      "Train Epoch: 20 [0/8000 (0%)]\tBatch Loss: 109.265518\tLearning Rate (w_theta): 0.001000\t TIME:79.9s\n",
      "\t\t\t\tDisc: 51.622311\t\tSym: 40.181465\t\tSpars: 17.461742\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026643\n",
      "\n",
      "Train Epoch: 20 [4000/8000 (50%)]\tBatch Loss: 105.340851\tLearning Rate (w_theta): 0.001000\t TIME:81.5s\n",
      "\t\t\t\tDisc: 48.537517\t\tSym: 39.413067\t\tSpars: 17.390266\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026643\n",
      "Validating epoch 20...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 14352713.6602342\n",
      "Average validation loss: 10030801.080089008\n",
      "Training epoch 21...\n",
      "\n",
      "Train Epoch: 21 [0/8000 (0%)]\tBatch Loss: 103.832356\tLearning Rate (w_theta): 0.001000\t TIME:84.4s\n",
      "\t\t\t\tDisc: 48.926335\t\tSym: 37.766037\t\tSpars: 17.139984\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026643\n",
      "\n",
      "Train Epoch: 21 [4000/8000 (50%)]\tBatch Loss: 102.533269\tLearning Rate (w_theta): 0.001000\t TIME:86.1s\n",
      "\t\t\t\tDisc: 47.875455\t\tSym: 37.598560\t\tSpars: 17.059254\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026643\n",
      "Validating epoch 21...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 13669256.018222276\n",
      "Average validation loss: 9553148.73223355\n",
      "Training epoch 22...\n",
      "\n",
      "Train Epoch: 22 [0/8000 (0%)]\tBatch Loss: 93.823896\tLearning Rate (w_theta): 0.001000\t TIME:88.3s\n",
      "\t\t\t\tDisc: 43.647104\t\tSym: 33.804379\t\tSpars: 16.372414\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026643\n",
      "\n",
      "Train Epoch: 22 [4000/8000 (50%)]\tBatch Loss: 102.765840\tLearning Rate (w_theta): 0.001000\t TIME:90.0s\n",
      "\t\t\t\tDisc: 48.588395\t\tSym: 37.023491\t\tSpars: 17.153954\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026643\n",
      "Validating epoch 22...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 13047930.77805999\n",
      "Average validation loss: 9118919.220819185\n",
      "Training epoch 23...\n",
      "\n",
      "Train Epoch: 23 [0/8000 (0%)]\tBatch Loss: 103.298082\tLearning Rate (w_theta): 0.001000\t TIME:92.1s\n",
      "\t\t\t\tDisc: 48.606806\t\tSym: 37.521137\t\tSpars: 17.170139\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026643\n",
      "\n",
      "Train Epoch: 23 [4000/8000 (50%)]\tBatch Loss: 87.632171\tLearning Rate (w_theta): 0.001000\t TIME:93.8s\n",
      "\t\t\t\tDisc: 39.574458\t\tSym: 32.028366\t\tSpars: 16.029346\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026643\n",
      "Validating epoch 23...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 12480633.725834163\n",
      "Average validation loss: 8722448.708000839\n",
      "Training epoch 24...\n",
      "\n",
      "Train Epoch: 24 [0/8000 (0%)]\tBatch Loss: 103.961374\tLearning Rate (w_theta): 0.001000\t TIME:96.0s\n",
      "\t\t\t\tDisc: 48.560995\t\tSym: 38.191586\t\tSpars: 17.208794\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026643\n",
      "\n",
      "Train Epoch: 24 [4000/8000 (50%)]\tBatch Loss: 95.306527\tLearning Rate (w_theta): 0.001000\t TIME:97.7s\n",
      "\t\t\t\tDisc: 44.203152\t\tSym: 34.473736\t\tSpars: 16.629639\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026643\n",
      "Validating epoch 24...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 11960611.348506195\n",
      "Average validation loss: 8359017.329363852\n",
      "Training epoch 25...\n",
      "\n",
      "Train Epoch: 25 [0/8000 (0%)]\tBatch Loss: 91.441861\tLearning Rate (w_theta): 0.001000\t TIME:99.8s\n",
      "\t\t\t\tDisc: 41.674005\t\tSym: 33.313793\t\tSpars: 16.454063\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026643\n",
      "\n",
      "Train Epoch: 25 [4000/8000 (50%)]\tBatch Loss: 96.294797\tLearning Rate (w_theta): 0.001000\t TIME:101.5s\n",
      "\t\t\t\tDisc: 43.362348\t\tSym: 36.027946\t\tSpars: 16.904503\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026643\n",
      "Validating epoch 25...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 11482190.693686275\n",
      "Average validation loss: 8024660.3983442085\n",
      "Training epoch 26...\n",
      "\n",
      "Train Epoch: 26 [0/8000 (0%)]\tBatch Loss: 90.275668\tLearning Rate (w_theta): 0.001000\t TIME:103.6s\n",
      "\t\t\t\tDisc: 41.375914\t\tSym: 32.604214\t\tSpars: 16.295540\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026643\n",
      "\n",
      "Train Epoch: 26 [4000/8000 (50%)]\tBatch Loss: 95.915337\tLearning Rate (w_theta): 0.001000\t TIME:105.3s\n",
      "\t\t\t\tDisc: 43.759720\t\tSym: 35.227551\t\tSpars: 16.928066\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 26...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 11040571.570256783\n",
      "Average validation loss: 7716023.176825835\n",
      "Training epoch 27...\n",
      "\n",
      "Train Epoch: 27 [0/8000 (0%)]\tBatch Loss: 91.778609\tLearning Rate (w_theta): 0.001000\t TIME:107.5s\n",
      "\t\t\t\tDisc: 40.911399\t\tSym: 33.987904\t\tSpars: 16.879307\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 27 [4000/8000 (50%)]\tBatch Loss: 89.574150\tLearning Rate (w_theta): 0.001000\t TIME:109.2s\n",
      "\t\t\t\tDisc: 41.044464\t\tSym: 32.436855\t\tSpars: 16.092831\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 27...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 10631664.9237938\n",
      "Average validation loss: 7430247.923579113\n",
      "Training epoch 28...\n",
      "\n",
      "Train Epoch: 28 [0/8000 (0%)]\tBatch Loss: 87.988202\tLearning Rate (w_theta): 0.001000\t TIME:111.3s\n",
      "\t\t\t\tDisc: 39.377082\t\tSym: 32.163433\t\tSpars: 16.447687\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 28 [4000/8000 (50%)]\tBatch Loss: 96.387146\tLearning Rate (w_theta): 0.001000\t TIME:113.0s\n",
      "\t\t\t\tDisc: 43.660333\t\tSym: 35.717491\t\tSpars: 17.009321\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 28...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 10251965.850170149\n",
      "Average validation loss: 7164885.14486876\n",
      "Training epoch 29...\n",
      "\n",
      "Train Epoch: 29 [0/8000 (0%)]\tBatch Loss: 87.859555\tLearning Rate (w_theta): 0.001000\t TIME:115.2s\n",
      "\t\t\t\tDisc: 39.962069\t\tSym: 31.720520\t\tSpars: 16.176966\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 29 [4000/8000 (50%)]\tBatch Loss: 84.425514\tLearning Rate (w_theta): 0.001000\t TIME:116.8s\n",
      "\t\t\t\tDisc: 38.273354\t\tSym: 30.308268\t\tSpars: 15.843893\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 29...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 9898452.877718689\n",
      "Average validation loss: 6917823.207648156\n",
      "Training epoch 30...\n",
      "\n",
      "Train Epoch: 30 [0/8000 (0%)]\tBatch Loss: 92.783645\tLearning Rate (w_theta): 0.001000\t TIME:119.0s\n",
      "\t\t\t\tDisc: 42.913741\t\tSym: 33.356060\t\tSpars: 16.513844\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 30 [4000/8000 (50%)]\tBatch Loss: 92.017586\tLearning Rate (w_theta): 0.001000\t TIME:120.7s\n",
      "\t\t\t\tDisc: 42.132439\t\tSym: 33.292793\t\tSpars: 16.592354\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 30...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 9568507.399418274\n",
      "Average validation loss: 6687232.02857025\n",
      "Training epoch 31...\n",
      "\n",
      "Train Epoch: 31 [0/8000 (0%)]\tBatch Loss: 86.573114\tLearning Rate (w_theta): 0.001000\t TIME:123.7s\n",
      "\t\t\t\tDisc: 39.214906\t\tSym: 31.327682\t\tSpars: 16.030525\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 31 [4000/8000 (50%)]\tBatch Loss: 87.051612\tLearning Rate (w_theta): 0.001000\t TIME:125.3s\n",
      "\t\t\t\tDisc: 39.294143\t\tSym: 31.526672\t\tSpars: 16.230797\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 31...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 9259848.690226316\n",
      "Average validation loss: 6471517.664565024\n",
      "Training epoch 32...\n",
      "\n",
      "Train Epoch: 32 [0/8000 (0%)]\tBatch Loss: 89.767150\tLearning Rate (w_theta): 0.001000\t TIME:127.5s\n",
      "\t\t\t\tDisc: 41.349593\t\tSym: 32.159332\t\tSpars: 16.258224\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 32 [4000/8000 (50%)]\tBatch Loss: 89.263689\tLearning Rate (w_theta): 0.001000\t TIME:129.2s\n",
      "\t\t\t\tDisc: 40.503466\t\tSym: 32.468620\t\tSpars: 16.291603\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 32...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 8970481.117240872\n",
      "Average validation loss: 6269285.41518641\n",
      "Training epoch 33...\n",
      "\n",
      "Train Epoch: 33 [0/8000 (0%)]\tBatch Loss: 86.095530\tLearning Rate (w_theta): 0.001000\t TIME:131.4s\n",
      "\t\t\t\tDisc: 38.522445\t\tSym: 31.347065\t\tSpars: 16.226021\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 33 [4000/8000 (50%)]\tBatch Loss: 84.187881\tLearning Rate (w_theta): 0.001000\t TIME:133.1s\n",
      "\t\t\t\tDisc: 37.483033\t\tSym: 30.820026\t\tSpars: 15.884821\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 33...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 8698650.941438781\n",
      "Average validation loss: 6079309.6347704725\n",
      "Training epoch 34...\n",
      "\n",
      "Train Epoch: 34 [0/8000 (0%)]\tBatch Loss: 84.609158\tLearning Rate (w_theta): 0.001000\t TIME:135.2s\n",
      "\t\t\t\tDisc: 37.800545\t\tSym: 30.824610\t\tSpars: 15.984004\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 34 [4000/8000 (50%)]\tBatch Loss: 87.682008\tLearning Rate (w_theta): 0.001000\t TIME:136.9s\n",
      "\t\t\t\tDisc: 38.571853\t\tSym: 32.540344\t\tSpars: 16.569811\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 34...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 8442810.747277372\n",
      "Average validation loss: 5900508.8711082125\n",
      "Training epoch 35...\n",
      "\n",
      "Train Epoch: 35 [0/8000 (0%)]\tBatch Loss: 80.771448\tLearning Rate (w_theta): 0.001000\t TIME:139.0s\n",
      "\t\t\t\tDisc: 36.065425\t\tSym: 29.070154\t\tSpars: 15.635868\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 35 [4000/8000 (50%)]\tBatch Loss: 85.826019\tLearning Rate (w_theta): 0.001000\t TIME:140.7s\n",
      "\t\t\t\tDisc: 38.504737\t\tSym: 31.131571\t\tSpars: 16.189711\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 35...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 8201589.965494459\n",
      "Average validation loss: 5731925.267125916\n",
      "Training epoch 36...\n",
      "\n",
      "Train Epoch: 36 [0/8000 (0%)]\tBatch Loss: 83.677403\tLearning Rate (w_theta): 0.001000\t TIME:142.9s\n",
      "\t\t\t\tDisc: 37.424756\t\tSym: 30.327589\t\tSpars: 15.925058\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 36 [4000/8000 (50%)]\tBatch Loss: 80.288035\tLearning Rate (w_theta): 0.001000\t TIME:144.6s\n",
      "\t\t\t\tDisc: 35.235865\t\tSym: 29.356985\t\tSpars: 15.695185\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 36...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 7973770.31299762\n",
      "Average validation loss: 5572707.393216577\n",
      "Training epoch 37...\n",
      "\n",
      "Train Epoch: 37 [0/8000 (0%)]\tBatch Loss: 81.551972\tLearning Rate (w_theta): 0.001000\t TIME:146.7s\n",
      "\t\t\t\tDisc: 35.802647\t\tSym: 29.778601\t\tSpars: 15.970724\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 37 [4000/8000 (50%)]\tBatch Loss: 85.661909\tLearning Rate (w_theta): 0.001000\t TIME:148.4s\n",
      "\t\t\t\tDisc: 38.263639\t\tSym: 31.074152\t\tSpars: 16.324118\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 37...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 7758265.212572486\n",
      "Average validation loss: 5422095.866649639\n",
      "Training epoch 38...\n",
      "\n",
      "Train Epoch: 38 [0/8000 (0%)]\tBatch Loss: 79.805402\tLearning Rate (w_theta): 0.001000\t TIME:150.6s\n",
      "\t\t\t\tDisc: 34.415550\t\tSym: 29.452024\t\tSpars: 15.937827\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 38 [4000/8000 (50%)]\tBatch Loss: 79.118278\tLearning Rate (w_theta): 0.001000\t TIME:152.3s\n",
      "\t\t\t\tDisc: 34.480020\t\tSym: 28.921759\t\tSpars: 15.716499\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 38...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 7554102.463195189\n",
      "Average validation loss: 5279411.239902689\n",
      "Training epoch 39...\n",
      "\n",
      "Train Epoch: 39 [0/8000 (0%)]\tBatch Loss: 76.152586\tLearning Rate (w_theta): 0.001000\t TIME:154.4s\n",
      "\t\t\t\tDisc: 33.869611\t\tSym: 27.132483\t\tSpars: 15.150493\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 39 [4000/8000 (50%)]\tBatch Loss: 78.785238\tLearning Rate (w_theta): 0.001000\t TIME:156.1s\n",
      "\t\t\t\tDisc: 33.848517\t\tSym: 29.042511\t\tSpars: 15.894211\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 39...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 7360409.577019853\n",
      "Average validation loss: 5144043.751972956\n",
      "Training epoch 40...\n",
      "\n",
      "Train Epoch: 40 [0/8000 (0%)]\tBatch Loss: 77.907895\tLearning Rate (w_theta): 0.001000\t TIME:158.2s\n",
      "\t\t\t\tDisc: 34.681536\t\tSym: 27.858627\t\tSpars: 15.367731\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 40 [4000/8000 (50%)]\tBatch Loss: 79.685392\tLearning Rate (w_theta): 0.001000\t TIME:159.9s\n",
      "\t\t\t\tDisc: 34.619428\t\tSym: 29.129988\t\tSpars: 15.935976\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 40...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 7176401.315014555\n",
      "Average validation loss: 5015444.6177223\n",
      "Training epoch 41...\n",
      "\n",
      "Train Epoch: 41 [0/8000 (0%)]\tBatch Loss: 76.973382\tLearning Rate (w_theta): 0.001000\t TIME:163.0s\n",
      "\t\t\t\tDisc: 34.177856\t\tSym: 27.449635\t\tSpars: 15.345892\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 41 [4000/8000 (50%)]\tBatch Loss: 77.912157\tLearning Rate (w_theta): 0.001000\t TIME:164.7s\n",
      "\t\t\t\tDisc: 34.113735\t\tSym: 28.131693\t\tSpars: 15.666729\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 41...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 7001369.046301637\n",
      "Average validation loss: 4893118.592122305\n",
      "Training epoch 42...\n",
      "\n",
      "Train Epoch: 42 [0/8000 (0%)]\tBatch Loss: 77.459641\tLearning Rate (w_theta): 0.001000\t TIME:166.8s\n",
      "\t\t\t\tDisc: 33.900481\t\tSym: 28.006281\t\tSpars: 15.552879\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 42 [4000/8000 (50%)]\tBatch Loss: 78.363438\tLearning Rate (w_theta): 0.001000\t TIME:168.5s\n",
      "\t\t\t\tDisc: 34.396607\t\tSym: 28.307173\t\tSpars: 15.659658\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 42...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 6834671.628805508\n",
      "Average validation loss: 4776617.596344865\n",
      "Training epoch 43...\n",
      "\n",
      "Train Epoch: 43 [0/8000 (0%)]\tBatch Loss: 75.117412\tLearning Rate (w_theta): 0.001000\t TIME:170.7s\n",
      "\t\t\t\tDisc: 32.838237\t\tSym: 26.971527\t\tSpars: 15.307648\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 43 [4000/8000 (50%)]\tBatch Loss: 74.455869\tLearning Rate (w_theta): 0.001000\t TIME:172.4s\n",
      "\t\t\t\tDisc: 32.967850\t\tSym: 26.459488\t\tSpars: 15.028531\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 43...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 6675727.561575172\n",
      "Average validation loss: 4665535.232989317\n",
      "Training epoch 44...\n",
      "\n",
      "Train Epoch: 44 [0/8000 (0%)]\tBatch Loss: 81.627625\tLearning Rate (w_theta): 0.001000\t TIME:174.6s\n",
      "\t\t\t\tDisc: 35.677832\t\tSym: 29.850958\t\tSpars: 16.098835\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 44 [4000/8000 (50%)]\tBatch Loss: 73.092916\tLearning Rate (w_theta): 0.001000\t TIME:176.3s\n",
      "\t\t\t\tDisc: 31.389676\t\tSym: 26.473831\t\tSpars: 15.229409\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 44...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 6524008.207252012\n",
      "Average validation loss: 4559502.049727974\n",
      "Training epoch 45...\n",
      "\n",
      "Train Epoch: 45 [0/8000 (0%)]\tBatch Loss: 75.014893\tLearning Rate (w_theta): 0.001000\t TIME:178.4s\n",
      "\t\t\t\tDisc: 33.109303\t\tSym: 26.671354\t\tSpars: 15.234236\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 45 [4000/8000 (50%)]\tBatch Loss: 75.204650\tLearning Rate (w_theta): 0.001000\t TIME:180.1s\n",
      "\t\t\t\tDisc: 32.874307\t\tSym: 26.919882\t\tSpars: 15.410461\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 45...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 6379031.918259797\n",
      "Average validation loss: 4458181.434628008\n",
      "Training epoch 46...\n",
      "\n",
      "Train Epoch: 46 [0/8000 (0%)]\tBatch Loss: 73.125901\tLearning Rate (w_theta): 0.001000\t TIME:182.2s\n",
      "\t\t\t\tDisc: 31.912416\t\tSym: 26.074467\t\tSpars: 15.139019\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 46 [4000/8000 (50%)]\tBatch Loss: 73.951257\tLearning Rate (w_theta): 0.001000\t TIME:184.0s\n",
      "\t\t\t\tDisc: 31.903188\t\tSym: 26.704435\t\tSpars: 15.343634\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 46...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 6240358.929644084\n",
      "Average validation loss: 4361266.046129652\n",
      "Training epoch 47...\n",
      "\n",
      "Train Epoch: 47 [0/8000 (0%)]\tBatch Loss: 74.133371\tLearning Rate (w_theta): 0.001000\t TIME:186.1s\n",
      "\t\t\t\tDisc: 32.964994\t\tSym: 26.004566\t\tSpars: 15.163811\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 47 [4000/8000 (50%)]\tBatch Loss: 72.753070\tLearning Rate (w_theta): 0.001000\t TIME:187.8s\n",
      "\t\t\t\tDisc: 31.340306\t\tSym: 26.188147\t\tSpars: 15.224617\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 47...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 6107586.902927369\n",
      "Average validation loss: 4268474.699679416\n",
      "Training epoch 48...\n",
      "\n",
      "Train Epoch: 48 [0/8000 (0%)]\tBatch Loss: 77.284493\tLearning Rate (w_theta): 0.001000\t TIME:190.0s\n",
      "\t\t\t\tDisc: 34.089209\t\tSym: 27.622614\t\tSpars: 15.572670\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 48 [4000/8000 (50%)]\tBatch Loss: 71.749389\tLearning Rate (w_theta): 0.001000\t TIME:191.7s\n",
      "\t\t\t\tDisc: 31.293348\t\tSym: 25.418205\t\tSpars: 15.037835\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 48...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 5980347.028147374\n",
      "Average validation loss: 4179549.64287151\n",
      "Training epoch 49...\n",
      "\n",
      "Train Epoch: 49 [0/8000 (0%)]\tBatch Loss: 73.587911\tLearning Rate (w_theta): 0.001000\t TIME:193.8s\n",
      "\t\t\t\tDisc: 32.297857\t\tSym: 26.101130\t\tSpars: 15.188925\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 49 [4000/8000 (50%)]\tBatch Loss: 72.690408\tLearning Rate (w_theta): 0.001000\t TIME:195.5s\n",
      "\t\t\t\tDisc: 31.521388\t\tSym: 25.871449\t\tSpars: 15.297571\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 49...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 5858300.602083822\n",
      "Average validation loss: 4094254.163804904\n",
      "Training epoch 50...\n",
      "\n",
      "Train Epoch: 50 [0/8000 (0%)]\tBatch Loss: 70.896017\tLearning Rate (w_theta): 0.001000\t TIME:197.7s\n",
      "\t\t\t\tDisc: 31.179309\t\tSym: 24.850828\t\tSpars: 14.865880\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 50 [4000/8000 (50%)]\tBatch Loss: 66.255747\tLearning Rate (w_theta): 0.001000\t TIME:199.4s\n",
      "\t\t\t\tDisc: 27.490698\t\tSym: 23.996120\t\tSpars: 14.768929\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530563 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 50...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 5741136.017810325\n",
      "Average validation loss: 4012370.487703715\n",
      "Training epoch 51...\n",
      "\n",
      "Train Epoch: 51 [0/8000 (0%)]\tBatch Loss: 69.288021\tLearning Rate (w_theta): 0.001000\t TIME:202.4s\n",
      "\t\t\t\tDisc: 29.889297\t\tSym: 24.755518\t\tSpars: 14.643206\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530562 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 51 [4000/8000 (50%)]\tBatch Loss: 72.479754\tLearning Rate (w_theta): 0.001000\t TIME:204.1s\n",
      "\t\t\t\tDisc: 31.648226\t\tSym: 25.640522\t\tSpars: 15.191006\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530562 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 51...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 5628566.108045905\n",
      "Average validation loss: 3933697.9201523755\n",
      "Training epoch 52...\n",
      "\n",
      "Train Epoch: 52 [0/8000 (0%)]\tBatch Loss: 67.143469\tLearning Rate (w_theta): 0.001000\t TIME:206.2s\n",
      "\t\t\t\tDisc: 28.872260\t\tSym: 23.717405\t\tSpars: 14.553803\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530562 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 52 [4000/8000 (50%)]\tBatch Loss: 69.851733\tLearning Rate (w_theta): 0.001000\t TIME:207.9s\n",
      "\t\t\t\tDisc: 29.974858\t\tSym: 24.855705\t\tSpars: 15.021170\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530562 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 52...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 5520325.795587284\n",
      "Average validation loss: 3858051.2044678126\n",
      "Training epoch 53...\n",
      "\n",
      "Train Epoch: 53 [0/8000 (0%)]\tBatch Loss: 70.626946\tLearning Rate (w_theta): 0.001000\t TIME:210.1s\n",
      "\t\t\t\tDisc: 30.526116\t\tSym: 24.991785\t\tSpars: 15.109045\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530561 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 53 [4000/8000 (50%)]\tBatch Loss: 65.960417\tLearning Rate (w_theta): 0.001000\t TIME:211.8s\n",
      "\t\t\t\tDisc: 28.219679\t\tSym: 23.222082\t\tSpars: 14.518656\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530561 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 53...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 5416170.008843983\n",
      "Average validation loss: 3785259.0659491145\n",
      "Training epoch 54...\n",
      "\n",
      "Train Epoch: 54 [0/8000 (0%)]\tBatch Loss: 69.439304\tLearning Rate (w_theta): 0.001000\t TIME:213.9s\n",
      "\t\t\t\tDisc: 29.606289\t\tSym: 24.834705\t\tSpars: 14.998310\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530561 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 54 [4000/8000 (50%)]\tBatch Loss: 69.828896\tLearning Rate (w_theta): 0.001000\t TIME:215.7s\n",
      "\t\t\t\tDisc: 30.840357\t\tSym: 24.243393\t\tSpars: 14.745147\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530561 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 54...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 5315871.829614538\n",
      "Average validation loss: 3715162.9169352558\n",
      "Training epoch 55...\n",
      "\n",
      "Train Epoch: 55 [0/8000 (0%)]\tBatch Loss: 63.691508\tLearning Rate (w_theta): 0.001000\t TIME:217.8s\n",
      "\t\t\t\tDisc: 26.847250\t\tSym: 22.536606\t\tSpars: 14.307652\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530560 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 55 [4000/8000 (50%)]\tBatch Loss: 69.741249\tLearning Rate (w_theta): 0.001000\t TIME:219.5s\n",
      "\t\t\t\tDisc: 29.964851\t\tSym: 24.716780\t\tSpars: 15.059618\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530560 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 55...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 5219220.842919854\n",
      "Average validation loss: 3647615.703547311\n",
      "Training epoch 56...\n",
      "\n",
      "Train Epoch: 56 [0/8000 (0%)]\tBatch Loss: 68.315328\tLearning Rate (w_theta): 0.001000\t TIME:221.7s\n",
      "\t\t\t\tDisc: 29.771435\t\tSym: 23.959469\t\tSpars: 14.584425\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530560 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 56 [4000/8000 (50%)]\tBatch Loss: 65.237275\tLearning Rate (w_theta): 0.001000\t TIME:223.4s\n",
      "\t\t\t\tDisc: 27.344869\t\tSym: 23.254080\t\tSpars: 14.638327\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530560 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 56...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 5126021.663471653\n",
      "Average validation loss: 3582480.8755078157\n",
      "Training epoch 57...\n",
      "\n",
      "Train Epoch: 57 [0/8000 (0%)]\tBatch Loss: 64.951377\tLearning Rate (w_theta): 0.001000\t TIME:225.5s\n",
      "\t\t\t\tDisc: 27.444522\t\tSym: 23.081715\t\tSpars: 14.425140\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530560 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 57 [4000/8000 (50%)]\tBatch Loss: 64.905829\tLearning Rate (w_theta): 0.001000\t TIME:227.2s\n",
      "\t\t\t\tDisc: 27.527463\t\tSym: 22.863214\t\tSpars: 14.515152\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530559 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 57...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 5036092.61698637\n",
      "Average validation loss: 3519631.4651254616\n",
      "Training epoch 58...\n",
      "\n",
      "Train Epoch: 58 [0/8000 (0%)]\tBatch Loss: 65.430702\tLearning Rate (w_theta): 0.001000\t TIME:229.4s\n",
      "\t\t\t\tDisc: 27.899365\t\tSym: 23.022236\t\tSpars: 14.509102\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530559 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 58 [4000/8000 (50%)]\tBatch Loss: 63.200778\tLearning Rate (w_theta): 0.001000\t TIME:231.1s\n",
      "\t\t\t\tDisc: 26.245305\t\tSym: 22.589483\t\tSpars: 14.365990\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530559 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 58...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 4949264.558433796\n",
      "Average validation loss: 3458949.2604234014\n",
      "Training epoch 59...\n",
      "\n",
      "Train Epoch: 59 [0/8000 (0%)]\tBatch Loss: 64.073316\tLearning Rate (w_theta): 0.001000\t TIME:233.3s\n",
      "\t\t\t\tDisc: 26.613056\t\tSym: 22.985125\t\tSpars: 14.475136\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530559 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 59 [4000/8000 (50%)]\tBatch Loss: 65.262835\tLearning Rate (w_theta): 0.001000\t TIME:235.0s\n",
      "\t\t\t\tDisc: 27.980634\t\tSym: 22.715345\t\tSpars: 14.566856\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530558 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 59...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 4865379.810261633\n",
      "Average validation loss: 3400324.064379327\n",
      "Training epoch 60...\n",
      "\n",
      "Train Epoch: 60 [0/8000 (0%)]\tBatch Loss: 63.170334\tLearning Rate (w_theta): 0.001000\t TIME:237.1s\n",
      "\t\t\t\tDisc: 26.421172\t\tSym: 22.382933\t\tSpars: 14.366230\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530558 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 60 [4000/8000 (50%)]\tBatch Loss: 64.543834\tLearning Rate (w_theta): 0.001000\t TIME:238.8s\n",
      "\t\t\t\tDisc: 26.788538\t\tSym: 23.060963\t\tSpars: 14.694334\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530558 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 60...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 4784291.206601169\n",
      "Average validation loss: 3343653.026121477\n",
      "Training epoch 61...\n",
      "\n",
      "Train Epoch: 61 [0/8000 (0%)]\tBatch Loss: 62.713510\tLearning Rate (w_theta): 0.001000\t TIME:241.7s\n",
      "\t\t\t\tDisc: 26.135406\t\tSym: 22.160353\t\tSpars: 14.417751\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530558 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 61 [4000/8000 (50%)]\tBatch Loss: 60.909103\tLearning Rate (w_theta): 0.001000\t TIME:243.4s\n",
      "\t\t\t\tDisc: 25.257276\t\tSym: 21.620123\t\tSpars: 14.031705\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530557 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 61...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 4705861.231737245\n",
      "Average validation loss: 3288840.0392018086\n",
      "Training epoch 62...\n",
      "\n",
      "Train Epoch: 62 [0/8000 (0%)]\tBatch Loss: 62.942190\tLearning Rate (w_theta): 0.001000\t TIME:245.6s\n",
      "\t\t\t\tDisc: 25.488717\t\tSym: 22.875038\t\tSpars: 14.578434\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530557 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 62 [4000/8000 (50%)]\tBatch Loss: 65.101845\tLearning Rate (w_theta): 0.001000\t TIME:247.3s\n",
      "\t\t\t\tDisc: 27.914778\t\tSym: 22.784544\t\tSpars: 14.402523\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530557 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 62...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 4629961.242071312\n",
      "Average validation loss: 3235795.197736211\n",
      "Training epoch 63...\n",
      "\n",
      "Train Epoch: 63 [0/8000 (0%)]\tBatch Loss: 63.457720\tLearning Rate (w_theta): 0.001000\t TIME:249.4s\n",
      "\t\t\t\tDisc: 26.064068\t\tSym: 22.783199\t\tSpars: 14.610453\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530557 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 63 [4000/8000 (50%)]\tBatch Loss: 59.801719\tLearning Rate (w_theta): 0.001000\t TIME:251.2s\n",
      "\t\t\t\tDisc: 23.704430\t\tSym: 21.835670\t\tSpars: 14.261619\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530556 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 63...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 4556470.761965841\n",
      "Average validation loss: 3184434.303800767\n",
      "Training epoch 64...\n",
      "\n",
      "Train Epoch: 64 [0/8000 (0%)]\tBatch Loss: 61.272493\tLearning Rate (w_theta): 0.001000\t TIME:253.3s\n",
      "\t\t\t\tDisc: 25.083657\t\tSym: 21.887110\t\tSpars: 14.301725\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530556 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 64 [4000/8000 (50%)]\tBatch Loss: 61.666683\tLearning Rate (w_theta): 0.001000\t TIME:255.0s\n",
      "\t\t\t\tDisc: 25.567124\t\tSym: 21.846844\t\tSpars: 14.252715\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530556 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 64...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 4485276.844617534\n",
      "Average validation loss: 3134678.4225115273\n",
      "Training epoch 65...\n",
      "\n",
      "Train Epoch: 65 [0/8000 (0%)]\tBatch Loss: 61.423563\tLearning Rate (w_theta): 0.001000\t TIME:257.2s\n",
      "\t\t\t\tDisc: 25.198168\t\tSym: 21.882771\t\tSpars: 14.342625\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530556 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 65 [4000/8000 (50%)]\tBatch Loss: 59.405725\tLearning Rate (w_theta): 0.001000\t TIME:258.9s\n",
      "\t\t\t\tDisc: 23.652261\t\tSym: 21.501875\t\tSpars: 14.251589\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530555 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 65...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 4416273.4950458715\n",
      "Average validation loss: 3086453.4760793485\n",
      "Training epoch 66...\n",
      "\n",
      "Train Epoch: 66 [0/8000 (0%)]\tBatch Loss: 58.824810\tLearning Rate (w_theta): 0.001000\t TIME:261.0s\n",
      "\t\t\t\tDisc: 23.605433\t\tSym: 21.088078\t\tSpars: 14.131299\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530555 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 66 [4000/8000 (50%)]\tBatch Loss: 60.312969\tLearning Rate (w_theta): 0.001000\t TIME:262.7s\n",
      "\t\t\t\tDisc: 23.744047\t\tSym: 22.159977\t\tSpars: 14.408945\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530555 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 66...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 4349361.141376276\n",
      "Average validation loss: 3039689.8773596054\n",
      "Training epoch 67...\n",
      "\n",
      "Train Epoch: 67 [0/8000 (0%)]\tBatch Loss: 59.346456\tLearning Rate (w_theta): 0.001000\t TIME:264.9s\n",
      "\t\t\t\tDisc: 23.485216\t\tSym: 21.710342\t\tSpars: 14.150898\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530555 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 67 [4000/8000 (50%)]\tBatch Loss: 56.255706\tLearning Rate (w_theta): 0.001000\t TIME:266.6s\n",
      "\t\t\t\tDisc: 21.855680\t\tSym: 20.461363\t\tSpars: 13.938663\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530555 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 67...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 4284446.157369622\n",
      "Average validation loss: 2994322.1932398905\n",
      "Training epoch 68...\n",
      "\n",
      "Train Epoch: 68 [0/8000 (0%)]\tBatch Loss: 56.343943\tLearning Rate (w_theta): 0.001000\t TIME:268.8s\n",
      "\t\t\t\tDisc: 21.693960\t\tSym: 20.657944\t\tSpars: 13.992039\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530554 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 68 [4000/8000 (50%)]\tBatch Loss: 53.660366\tLearning Rate (w_theta): 0.001000\t TIME:270.5s\n",
      "\t\t\t\tDisc: 20.093620\t\tSym: 19.795420\t\tSpars: 13.771326\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530554 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 68...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 4221440.424019298\n",
      "Average validation loss: 2950288.839786896\n",
      "Training epoch 69...\n",
      "\n",
      "Train Epoch: 69 [0/8000 (0%)]\tBatch Loss: 56.604405\tLearning Rate (w_theta): 0.001000\t TIME:272.6s\n",
      "\t\t\t\tDisc: 22.222985\t\tSym: 20.603025\t\tSpars: 13.778394\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530554 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 69 [4000/8000 (50%)]\tBatch Loss: 55.611745\tLearning Rate (w_theta): 0.001000\t TIME:274.4s\n",
      "\t\t\t\tDisc: 21.483226\t\tSym: 20.188639\t\tSpars: 13.939880\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530554 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 69...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 4160260.9310165867\n",
      "Average validation loss: 2907531.8031213945\n",
      "Training epoch 70...\n",
      "\n",
      "Train Epoch: 70 [0/8000 (0%)]\tBatch Loss: 54.438393\tLearning Rate (w_theta): 0.001000\t TIME:276.5s\n",
      "\t\t\t\tDisc: 20.401777\t\tSym: 20.207691\t\tSpars: 13.828924\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530553 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 70 [4000/8000 (50%)]\tBatch Loss: 54.212821\tLearning Rate (w_theta): 0.001000\t TIME:278.2s\n",
      "\t\t\t\tDisc: 20.797666\t\tSym: 19.728308\t\tSpars: 13.686848\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530553 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 70...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 4100829.41100105\n",
      "Average validation loss: 2865996.384262195\n",
      "Training epoch 71...\n",
      "\n",
      "Train Epoch: 71 [0/8000 (0%)]\tBatch Loss: 52.503650\tLearning Rate (w_theta): 0.001000\t TIME:281.2s\n",
      "\t\t\t\tDisc: 19.466516\t\tSym: 19.399485\t\tSpars: 13.637650\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530553 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 71 [4000/8000 (50%)]\tBatch Loss: 52.546634\tLearning Rate (w_theta): 0.001000\t TIME:282.9s\n",
      "\t\t\t\tDisc: 19.381260\t\tSym: 19.474394\t\tSpars: 13.690980\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530553 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 71...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 4043072.0063840323\n",
      "Average validation loss: 2825630.9659674107\n",
      "Training epoch 72...\n",
      "\n",
      "Train Epoch: 72 [0/8000 (0%)]\tBatch Loss: 54.571286\tLearning Rate (w_theta): 0.001000\t TIME:285.1s\n",
      "\t\t\t\tDisc: 20.487896\t\tSym: 20.310644\t\tSpars: 13.772746\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530552 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 72 [4000/8000 (50%)]\tBatch Loss: 54.170531\tLearning Rate (w_theta): 0.001000\t TIME:286.8s\n",
      "\t\t\t\tDisc: 20.089023\t\tSym: 20.122501\t\tSpars: 13.959007\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530552 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 72...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3986918.9624685002\n",
      "Average validation loss: 2786386.7979537006\n",
      "Training epoch 73...\n",
      "\n",
      "Train Epoch: 73 [0/8000 (0%)]\tBatch Loss: 53.757606\tLearning Rate (w_theta): 0.001000\t TIME:289.0s\n",
      "\t\t\t\tDisc: 20.225088\t\tSym: 19.679693\t\tSpars: 13.852825\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530552 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 73 [4000/8000 (50%)]\tBatch Loss: 51.201301\tLearning Rate (w_theta): 0.001000\t TIME:290.7s\n",
      "\t\t\t\tDisc: 18.973602\t\tSym: 18.791107\t\tSpars: 13.436592\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530552 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 73...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3932304.3467535037\n",
      "Average validation loss: 2748217.801924521\n",
      "Training epoch 74...\n",
      "\n",
      "Train Epoch: 74 [0/8000 (0%)]\tBatch Loss: 56.125162\tLearning Rate (w_theta): 0.001000\t TIME:292.8s\n",
      "\t\t\t\tDisc: 21.243294\t\tSym: 20.881916\t\tSpars: 13.999952\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530551 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 74 [4000/8000 (50%)]\tBatch Loss: 48.457537\tLearning Rate (w_theta): 0.001000\t TIME:294.5s\n",
      "\t\t\t\tDisc: 17.451954\t\tSym: 17.888514\t\tSpars: 13.117069\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530551 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 74...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3879165.7907620072\n",
      "Average validation loss: 2711080.3900727266\n",
      "Training epoch 75...\n",
      "\n",
      "Train Epoch: 75 [0/8000 (0%)]\tBatch Loss: 51.823748\tLearning Rate (w_theta): 0.001000\t TIME:296.7s\n",
      "\t\t\t\tDisc: 18.676096\t\tSym: 19.404579\t\tSpars: 13.743073\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530551 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 75 [4000/8000 (50%)]\tBatch Loss: 48.734957\tLearning Rate (w_theta): 0.001000\t TIME:298.4s\n",
      "\t\t\t\tDisc: 17.595927\t\tSym: 17.887039\t\tSpars: 13.251990\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530551 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 75...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3827444.2524658917\n",
      "Average validation loss: 2674933.299425668\n",
      "Training epoch 76...\n",
      "\n",
      "Train Epoch: 76 [0/8000 (0%)]\tBatch Loss: 50.261454\tLearning Rate (w_theta): 0.001000\t TIME:300.6s\n",
      "\t\t\t\tDisc: 17.821934\t\tSym: 18.863800\t\tSpars: 13.575720\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530550 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 76 [4000/8000 (50%)]\tBatch Loss: 47.900344\tLearning Rate (w_theta): 0.001000\t TIME:302.3s\n",
      "\t\t\t\tDisc: 17.449452\t\tSym: 17.397621\t\tSpars: 13.053270\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530550 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 76...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3777083.7969837403\n",
      "Average validation loss: 2639737.4382863264\n",
      "Training epoch 77...\n",
      "\n",
      "Train Epoch: 77 [0/8000 (0%)]\tBatch Loss: 50.788568\tLearning Rate (w_theta): 0.001000\t TIME:304.4s\n",
      "\t\t\t\tDisc: 18.331771\t\tSym: 18.871046\t\tSpars: 13.585751\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530550 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 77 [4000/8000 (50%)]\tBatch Loss: 49.352402\tLearning Rate (w_theta): 0.001000\t TIME:306.1s\n",
      "\t\t\t\tDisc: 17.283505\t\tSym: 18.630920\t\tSpars: 13.437977\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530550 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 77...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3728031.3956300095\n",
      "Average validation loss: 2605455.746203193\n",
      "Training epoch 78...\n",
      "\n",
      "Train Epoch: 78 [0/8000 (0%)]\tBatch Loss: 48.249055\tLearning Rate (w_theta): 0.001000\t TIME:308.3s\n",
      "\t\t\t\tDisc: 16.574939\t\tSym: 18.336777\t\tSpars: 13.337339\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530550 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 78 [4000/8000 (50%)]\tBatch Loss: 47.401587\tLearning Rate (w_theta): 0.001000\t TIME:310.0s\n",
      "\t\t\t\tDisc: 16.488181\t\tSym: 17.726397\t\tSpars: 13.187010\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530549 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 78...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3680236.7387736063\n",
      "Average validation loss: 2572053.063107747\n",
      "Training epoch 79...\n",
      "\n",
      "Train Epoch: 79 [0/8000 (0%)]\tBatch Loss: 47.226717\tLearning Rate (w_theta): 0.001000\t TIME:312.2s\n",
      "\t\t\t\tDisc: 16.557392\t\tSym: 17.533676\t\tSpars: 13.135649\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530549 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 79 [4000/8000 (50%)]\tBatch Loss: 46.866179\tLearning Rate (w_theta): 0.001000\t TIME:313.9s\n",
      "\t\t\t\tDisc: 16.260769\t\tSym: 17.457977\t\tSpars: 13.147432\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530549 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 79...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3633652.0644824933\n",
      "Average validation loss: 2539496.00911372\n",
      "Training epoch 80...\n",
      "\n",
      "Train Epoch: 80 [0/8000 (0%)]\tBatch Loss: 47.733321\tLearning Rate (w_theta): 0.001000\t TIME:316.0s\n",
      "\t\t\t\tDisc: 16.428542\t\tSym: 18.006433\t\tSpars: 13.298346\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530549 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 80 [4000/8000 (50%)]\tBatch Loss: 47.251407\tLearning Rate (w_theta): 0.001000\t TIME:317.7s\n",
      "\t\t\t\tDisc: 15.922714\t\tSym: 17.962713\t\tSpars: 13.365980\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530548 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 80...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3588231.9983155853\n",
      "Average validation loss: 2507752.8734021354\n",
      "Training epoch 81...\n",
      "\n",
      "Train Epoch: 81 [0/8000 (0%)]\tBatch Loss: 47.278506\tLearning Rate (w_theta): 0.001000\t TIME:320.7s\n",
      "\t\t\t\tDisc: 16.255691\t\tSym: 17.876802\t\tSpars: 13.146013\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530548 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 81 [4000/8000 (50%)]\tBatch Loss: 44.713738\tLearning Rate (w_theta): 0.001000\t TIME:322.4s\n",
      "\t\t\t\tDisc: 15.031756\t\tSym: 16.720396\t\tSpars: 12.961586\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530548 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 81...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3543933.4072430334\n",
      "Average validation loss: 2476793.511145316\n",
      "Training epoch 82...\n",
      "\n",
      "Train Epoch: 82 [0/8000 (0%)]\tBatch Loss: 46.727812\tLearning Rate (w_theta): 0.001000\t TIME:324.6s\n",
      "\t\t\t\tDisc: 15.352531\t\tSym: 18.087585\t\tSpars: 13.287696\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530548 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 82 [4000/8000 (50%)]\tBatch Loss: 44.442643\tLearning Rate (w_theta): 0.001000\t TIME:326.3s\n",
      "\t\t\t\tDisc: 14.697661\t\tSym: 16.754553\t\tSpars: 12.990429\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530547 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 82...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3500715.2619801937\n",
      "Average validation loss: 2446589.2479343684\n",
      "Training epoch 83...\n",
      "\n",
      "Train Epoch: 83 [0/8000 (0%)]\tBatch Loss: 46.756624\tLearning Rate (w_theta): 0.001000\t TIME:328.5s\n",
      "\t\t\t\tDisc: 15.436377\t\tSym: 18.022608\t\tSpars: 13.297640\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530547 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 83 [4000/8000 (50%)]\tBatch Loss: 45.901981\tLearning Rate (w_theta): 0.001000\t TIME:330.2s\n",
      "\t\t\t\tDisc: 15.083935\t\tSym: 17.648787\t\tSpars: 13.169260\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530547 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 83...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3458538.5105185113\n",
      "Average validation loss: 2417112.791313574\n",
      "Training epoch 84...\n",
      "\n",
      "Train Epoch: 84 [0/8000 (0%)]\tBatch Loss: 45.640478\tLearning Rate (w_theta): 0.001000\t TIME:332.4s\n",
      "\t\t\t\tDisc: 15.017181\t\tSym: 17.523670\t\tSpars: 13.099627\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530547 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 84 [4000/8000 (50%)]\tBatch Loss: 44.925187\tLearning Rate (w_theta): 0.001000\t TIME:334.1s\n",
      "\t\t\t\tDisc: 14.495559\t\tSym: 17.342188\t\tSpars: 13.087440\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530546 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 84...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3417365.9605640764\n",
      "Average validation loss: 2388338.1484692777\n",
      "Training epoch 85...\n",
      "\n",
      "Train Epoch: 85 [0/8000 (0%)]\tBatch Loss: 43.055329\tLearning Rate (w_theta): 0.001000\t TIME:336.2s\n",
      "\t\t\t\tDisc: 13.954087\t\tSym: 16.397167\t\tSpars: 12.704075\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530546 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 85 [4000/8000 (50%)]\tBatch Loss: 44.469446\tLearning Rate (w_theta): 0.001000\t TIME:337.9s\n",
      "\t\t\t\tDisc: 14.239511\t\tSym: 17.116337\t\tSpars: 13.113598\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530546 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 85...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3377162.16995372\n",
      "Average validation loss: 2360240.5498958267\n",
      "Training epoch 86...\n",
      "\n",
      "Train Epoch: 86 [0/8000 (0%)]\tBatch Loss: 40.199940\tLearning Rate (w_theta): 0.001000\t TIME:340.1s\n",
      "\t\t\t\tDisc: 12.560771\t\tSym: 15.295761\t\tSpars: 12.343408\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530546 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 86 [4000/8000 (50%)]\tBatch Loss: 41.107801\tLearning Rate (w_theta): 0.001000\t TIME:341.8s\n",
      "\t\t\t\tDisc: 12.647667\t\tSym: 15.903546\t\tSpars: 12.556587\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530545 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 86...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3337893.3449921613\n",
      "Average validation loss: 2332796.3779666987\n",
      "Training epoch 87...\n",
      "\n",
      "Train Epoch: 87 [0/8000 (0%)]\tBatch Loss: 41.815057\tLearning Rate (w_theta): 0.001000\t TIME:343.9s\n",
      "\t\t\t\tDisc: 13.032350\t\tSym: 16.141445\t\tSpars: 12.641262\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530545 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 87 [4000/8000 (50%)]\tBatch Loss: 44.227412\tLearning Rate (w_theta): 0.001000\t TIME:345.6s\n",
      "\t\t\t\tDisc: 14.067535\t\tSym: 17.087000\t\tSpars: 13.072877\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530545 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 87...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3299527.245871258\n",
      "Average validation loss: 2305983.1010374716\n",
      "Training epoch 88...\n",
      "\n",
      "Train Epoch: 88 [0/8000 (0%)]\tBatch Loss: 41.978550\tLearning Rate (w_theta): 0.001000\t TIME:347.8s\n",
      "\t\t\t\tDisc: 12.872488\t\tSym: 16.285069\t\tSpars: 12.820993\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530545 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 88 [4000/8000 (50%)]\tBatch Loss: 42.926214\tLearning Rate (w_theta): 0.001000\t TIME:349.6s\n",
      "\t\t\t\tDisc: 12.991598\t\tSym: 16.965595\t\tSpars: 12.969021\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530545 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 88...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3262033.098097444\n",
      "Average validation loss: 2279779.2116144123\n",
      "Training epoch 89...\n",
      "\n",
      "Train Epoch: 89 [0/8000 (0%)]\tBatch Loss: 42.317554\tLearning Rate (w_theta): 0.001000\t TIME:351.7s\n",
      "\t\t\t\tDisc: 13.182206\t\tSym: 16.300812\t\tSpars: 12.834537\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530544 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 89 [4000/8000 (50%)]\tBatch Loss: 41.268480\tLearning Rate (w_theta): 0.001000\t TIME:353.4s\n",
      "\t\t\t\tDisc: 12.480123\t\tSym: 16.072660\t\tSpars: 12.715697\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530544 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 89...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3225381.510276568\n",
      "Average validation loss: 2254164.1687774183\n",
      "Training epoch 90...\n",
      "\n",
      "Train Epoch: 90 [0/8000 (0%)]\tBatch Loss: 44.038356\tLearning Rate (w_theta): 0.001000\t TIME:355.5s\n",
      "\t\t\t\tDisc: 13.318154\t\tSym: 17.557837\t\tSpars: 13.162366\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530544 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 90 [4000/8000 (50%)]\tBatch Loss: 40.744655\tLearning Rate (w_theta): 0.001000\t TIME:357.2s\n",
      "\t\t\t\tDisc: 12.229467\t\tSym: 15.784270\t\tSpars: 12.730918\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530544 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 90...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3189544.3974190233\n",
      "Average validation loss: 2229118.344556791\n",
      "Training epoch 91...\n",
      "\n",
      "Train Epoch: 91 [0/8000 (0%)]\tBatch Loss: 42.696697\tLearning Rate (w_theta): 0.001000\t TIME:360.3s\n",
      "\t\t\t\tDisc: 13.147122\t\tSym: 16.612488\t\tSpars: 12.937087\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530543 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 91 [4000/8000 (50%)]\tBatch Loss: 39.794652\tLearning Rate (w_theta): 0.001000\t TIME:362.0s\n",
      "\t\t\t\tDisc: 11.781472\t\tSym: 15.531348\t\tSpars: 12.481833\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530543 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 91...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3154494.908853311\n",
      "Average validation loss: 2204622.9737089295\n",
      "Training epoch 92...\n",
      "\n",
      "Train Epoch: 92 [0/8000 (0%)]\tBatch Loss: 40.451157\tLearning Rate (w_theta): 0.001000\t TIME:364.1s\n",
      "\t\t\t\tDisc: 11.872445\t\tSym: 15.831688\t\tSpars: 12.747025\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530543 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 92 [4000/8000 (50%)]\tBatch Loss: 39.927239\tLearning Rate (w_theta): 0.001000\t TIME:365.9s\n",
      "\t\t\t\tDisc: 11.968015\t\tSym: 15.462857\t\tSpars: 12.496367\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530543 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "Validating epoch 92...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3120207.3613905623\n",
      "Average validation loss: 2180660.1068981946\n",
      "Training epoch 93...\n",
      "\n",
      "Train Epoch: 93 [0/8000 (0%)]\tBatch Loss: 40.943623\tLearning Rate (w_theta): 0.001000\t TIME:368.0s\n",
      "\t\t\t\tDisc: 12.247097\t\tSym: 15.930475\t\tSpars: 12.766050\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530542 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026644\n",
      "\n",
      "Train Epoch: 93 [4000/8000 (50%)]\tBatch Loss: 39.162032\tLearning Rate (w_theta): 0.001000\t TIME:369.7s\n",
      "\t\t\t\tDisc: 11.574144\t\tSym: 15.167584\t\tSpars: 12.420304\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530542 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 93...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3086657.17654508\n",
      "Average validation loss: 2157212.5667504016\n",
      "Training epoch 94...\n",
      "\n",
      "Train Epoch: 94 [0/8000 (0%)]\tBatch Loss: 39.697617\tLearning Rate (w_theta): 0.001000\t TIME:371.9s\n",
      "\t\t\t\tDisc: 11.888371\t\tSym: 15.337562\t\tSpars: 12.471684\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530542 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 94 [4000/8000 (50%)]\tBatch Loss: 41.339522\tLearning Rate (w_theta): 0.001000\t TIME:373.6s\n",
      "\t\t\t\tDisc: 12.204510\t\tSym: 16.297392\t\tSpars: 12.837620\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530542 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 94...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3053820.821651003\n",
      "Average validation loss: 2134263.9068970624\n",
      "Training epoch 95...\n",
      "\n",
      "Train Epoch: 95 [0/8000 (0%)]\tBatch Loss: 40.279964\tLearning Rate (w_theta): 0.001000\t TIME:375.8s\n",
      "\t\t\t\tDisc: 11.874838\t\tSym: 15.661964\t\tSpars: 12.743162\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530541 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 95 [4000/8000 (50%)]\tBatch Loss: 38.405743\tLearning Rate (w_theta): 0.001000\t TIME:377.5s\n",
      "\t\t\t\tDisc: 11.192413\t\tSym: 14.927791\t\tSpars: 12.285540\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530541 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 95...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3021675.7548778905\n",
      "Average validation loss: 2111798.373334519\n",
      "Training epoch 96...\n",
      "\n",
      "Train Epoch: 96 [0/8000 (0%)]\tBatch Loss: 41.011071\tLearning Rate (w_theta): 0.001000\t TIME:379.6s\n",
      "\t\t\t\tDisc: 12.012952\t\tSym: 16.186071\t\tSpars: 12.812048\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530541 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 96 [4000/8000 (50%)]\tBatch Loss: 39.660127\tLearning Rate (w_theta): 0.001000\t TIME:381.3s\n",
      "\t\t\t\tDisc: 11.347206\t\tSym: 15.571759\t\tSpars: 12.741161\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530541 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 96...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2990200.373713662\n",
      "Average validation loss: 2089800.8685475462\n",
      "Training epoch 97...\n",
      "\n",
      "Train Epoch: 97 [0/8000 (0%)]\tBatch Loss: 39.201965\tLearning Rate (w_theta): 0.001000\t TIME:383.5s\n",
      "\t\t\t\tDisc: 11.284228\t\tSym: 15.332364\t\tSpars: 12.585373\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530540 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 97 [4000/8000 (50%)]\tBatch Loss: 37.678528\tLearning Rate (w_theta): 0.001000\t TIME:385.2s\n",
      "\t\t\t\tDisc: 10.665116\t\tSym: 14.635857\t\tSpars: 12.377556\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530540 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 97...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2959373.9663259424\n",
      "Average validation loss: 2068256.917554727\n",
      "Training epoch 98...\n",
      "\n",
      "Train Epoch: 98 [0/8000 (0%)]\tBatch Loss: 40.343393\tLearning Rate (w_theta): 0.001000\t TIME:387.4s\n",
      "\t\t\t\tDisc: 11.358367\t\tSym: 16.143621\t\tSpars: 12.841405\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530540 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 98 [4000/8000 (50%)]\tBatch Loss: 38.362071\tLearning Rate (w_theta): 0.001000\t TIME:389.1s\n",
      "\t\t\t\tDisc: 10.965066\t\tSym: 14.921320\t\tSpars: 12.475685\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530540 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 98...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2929176.6663267994\n",
      "Average validation loss: 2047152.6362286378\n",
      "Training epoch 99...\n",
      "\n",
      "Train Epoch: 99 [0/8000 (0%)]\tBatch Loss: 39.548828\tLearning Rate (w_theta): 0.001000\t TIME:391.5s\n",
      "\t\t\t\tDisc: 11.168715\t\tSym: 15.735007\t\tSpars: 12.645105\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530540 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 99 [4000/8000 (50%)]\tBatch Loss: 36.056275\tLearning Rate (w_theta): 0.001000\t TIME:393.2s\n",
      "\t\t\t\tDisc: 10.263442\t\tSym: 13.809525\t\tSpars: 11.983309\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530539 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 99...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2899589.4100224017\n",
      "Average validation loss: 2026474.7013691093\n",
      "Training epoch 100...\n",
      "\n",
      "Train Epoch: 100 [0/8000 (0%)]\tBatch Loss: 39.604234\tLearning Rate (w_theta): 0.001000\t TIME:395.4s\n",
      "\t\t\t\tDisc: 11.097569\t\tSym: 15.765398\t\tSpars: 12.741267\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530539 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 100 [4000/8000 (50%)]\tBatch Loss: 39.699036\tLearning Rate (w_theta): 0.001000\t TIME:397.1s\n",
      "\t\t\t\tDisc: 11.265703\t\tSym: 15.669492\t\tSpars: 12.763842\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530539 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 100...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2870593.896152551\n",
      "Average validation loss: 2006210.3227623093\n",
      "Training epoch 101...\n",
      "\n",
      "Train Epoch: 101 [0/8000 (0%)]\tBatch Loss: 38.139500\tLearning Rate (w_theta): 0.001000\t TIME:400.1s\n",
      "\t\t\t\tDisc: 10.700615\t\tSym: 14.994242\t\tSpars: 12.444643\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530539 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 101 [4000/8000 (50%)]\tBatch Loss: 36.605198\tLearning Rate (w_theta): 0.001000\t TIME:401.8s\n",
      "\t\t\t\tDisc: 9.956127\t\tSym: 14.331827\t\tSpars: 12.317245\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530538 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 101...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2842172.548373685\n",
      "Average validation loss: 1986347.2165997084\n",
      "Training epoch 102...\n",
      "\n",
      "Train Epoch: 102 [0/8000 (0%)]\tBatch Loss: 36.397242\tLearning Rate (w_theta): 0.001000\t TIME:404.0s\n",
      "\t\t\t\tDisc: 9.974356\t\tSym: 14.258957\t\tSpars: 12.163929\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530538 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 102 [4000/8000 (50%)]\tBatch Loss: 35.321040\tLearning Rate (w_theta): 0.001000\t TIME:405.7s\n",
      "\t\t\t\tDisc: 9.495031\t\tSym: 13.726169\t\tSpars: 12.099840\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530538 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 102...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2814308.479560408\n",
      "Average validation loss: 1966873.580850841\n",
      "Training epoch 103...\n",
      "\n",
      "Train Epoch: 103 [0/8000 (0%)]\tBatch Loss: 38.235125\tLearning Rate (w_theta): 0.001000\t TIME:408.1s\n",
      "\t\t\t\tDisc: 10.712928\t\tSym: 15.030210\t\tSpars: 12.491988\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530538 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 103 [4000/8000 (50%)]\tBatch Loss: 36.354837\tLearning Rate (w_theta): 0.001000\t TIME:409.8s\n",
      "\t\t\t\tDisc: 9.904833\t\tSym: 14.246816\t\tSpars: 12.203188\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530537 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 103...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2786985.4583994457\n",
      "Average validation loss: 1947778.0718085393\n",
      "Training epoch 104...\n",
      "\n",
      "Train Epoch: 104 [0/8000 (0%)]\tBatch Loss: 36.144700\tLearning Rate (w_theta): 0.001000\t TIME:412.0s\n",
      "\t\t\t\tDisc: 9.805373\t\tSym: 14.197551\t\tSpars: 12.141777\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530537 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 104 [4000/8000 (50%)]\tBatch Loss: 36.789334\tLearning Rate (w_theta): 0.001000\t TIME:413.7s\n",
      "\t\t\t\tDisc: 10.083874\t\tSym: 14.374178\t\tSpars: 12.331283\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530537 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 104...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2760187.8778427914\n",
      "Average validation loss: 1929049.7820787774\n",
      "Training epoch 105...\n",
      "\n",
      "Train Epoch: 105 [0/8000 (0%)]\tBatch Loss: 38.485638\tLearning Rate (w_theta): 0.001000\t TIME:416.0s\n",
      "\t\t\t\tDisc: 10.459198\t\tSym: 15.317130\t\tSpars: 12.709311\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530537 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 105 [4000/8000 (50%)]\tBatch Loss: 36.866753\tLearning Rate (w_theta): 0.001000\t TIME:417.7s\n",
      "\t\t\t\tDisc: 10.096480\t\tSym: 14.528279\t\tSpars: 12.241994\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530536 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 105...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2733900.725300301\n",
      "Average validation loss: 1910678.2197039064\n",
      "Training epoch 106...\n",
      "\n",
      "Train Epoch: 106 [0/8000 (0%)]\tBatch Loss: 34.903286\tLearning Rate (w_theta): 0.001000\t TIME:420.0s\n",
      "\t\t\t\tDisc: 9.534944\t\tSym: 13.394092\t\tSpars: 11.974251\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530536 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 106 [4000/8000 (50%)]\tBatch Loss: 39.505148\tLearning Rate (w_theta): 0.001000\t TIME:421.7s\n",
      "\t\t\t\tDisc: 10.694695\t\tSym: 16.032444\t\tSpars: 12.778009\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530536 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 106...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2708109.5548668727\n",
      "Average validation loss: 1892653.2887073355\n",
      "Training epoch 107...\n",
      "\n",
      "Train Epoch: 107 [0/8000 (0%)]\tBatch Loss: 37.044036\tLearning Rate (w_theta): 0.001000\t TIME:423.9s\n",
      "\t\t\t\tDisc: 9.914855\t\tSym: 14.787872\t\tSpars: 12.341309\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530536 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 107 [4000/8000 (50%)]\tBatch Loss: 34.431533\tLearning Rate (w_theta): 0.001000\t TIME:425.6s\n",
      "\t\t\t\tDisc: 9.126764\t\tSym: 13.451587\t\tSpars: 11.853182\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530535 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 107...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2682800.4605545555\n",
      "Average validation loss: 1874965.2706051082\n",
      "Training epoch 108...\n",
      "\n",
      "Train Epoch: 108 [0/8000 (0%)]\tBatch Loss: 36.897939\tLearning Rate (w_theta): 0.001000\t TIME:427.9s\n",
      "\t\t\t\tDisc: 9.876344\t\tSym: 14.564783\t\tSpars: 12.456812\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530535 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 108 [4000/8000 (50%)]\tBatch Loss: 35.988922\tLearning Rate (w_theta): 0.001000\t TIME:429.6s\n",
      "\t\t\t\tDisc: 9.591305\t\tSym: 14.263267\t\tSpars: 12.134351\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530535 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 108...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2657960.0512484787\n",
      "Average validation loss: 1857604.8066028964\n",
      "Training epoch 109...\n",
      "\n",
      "Train Epoch: 109 [0/8000 (0%)]\tBatch Loss: 34.894105\tLearning Rate (w_theta): 0.001000\t TIME:431.8s\n",
      "\t\t\t\tDisc: 9.322502\t\tSym: 13.574506\t\tSpars: 11.997097\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530535 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 109 [4000/8000 (50%)]\tBatch Loss: 36.756379\tLearning Rate (w_theta): 0.001000\t TIME:433.5s\n",
      "\t\t\t\tDisc: 9.485853\t\tSym: 14.893727\t\tSpars: 12.376799\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530535 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 109...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2633575.4276048774\n",
      "Average validation loss: 1840562.8815736205\n",
      "Training epoch 110...\n",
      "\n",
      "Train Epoch: 110 [0/8000 (0%)]\tBatch Loss: 36.323066\tLearning Rate (w_theta): 0.001000\t TIME:435.8s\n",
      "\t\t\t\tDisc: 9.639891\t\tSym: 14.428530\t\tSpars: 12.254645\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530534 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 110 [4000/8000 (50%)]\tBatch Loss: 35.902958\tLearning Rate (w_theta): 0.001000\t TIME:437.5s\n",
      "\t\t\t\tDisc: 9.460533\t\tSym: 14.160385\t\tSpars: 12.282040\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530534 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 110...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2609634.159097714\n",
      "Average validation loss: 1823830.808165772\n",
      "Training epoch 111...\n",
      "\n",
      "Train Epoch: 111 [0/8000 (0%)]\tBatch Loss: 36.300117\tLearning Rate (w_theta): 0.001000\t TIME:440.6s\n",
      "\t\t\t\tDisc: 9.725832\t\tSym: 14.343752\t\tSpars: 12.230534\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530534 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 111 [4000/8000 (50%)]\tBatch Loss: 36.000314\tLearning Rate (w_theta): 0.001000\t TIME:442.3s\n",
      "\t\t\t\tDisc: 9.507028\t\tSym: 14.173922\t\tSpars: 12.319365\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530534 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 111...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2586124.2632218087\n",
      "Average validation loss: 1807400.2120551497\n",
      "Training epoch 112...\n",
      "\n",
      "Train Epoch: 112 [0/8000 (0%)]\tBatch Loss: 35.110139\tLearning Rate (w_theta): 0.001000\t TIME:444.6s\n",
      "\t\t\t\tDisc: 9.104806\t\tSym: 13.871480\t\tSpars: 12.133854\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530533 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 112 [4000/8000 (50%)]\tBatch Loss: 37.312336\tLearning Rate (w_theta): 0.001000\t TIME:446.3s\n",
      "\t\t\t\tDisc: 9.820758\t\tSym: 14.918948\t\tSpars: 12.572630\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530533 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 112...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2563034.1853694627\n",
      "Average validation loss: 1791263.018018606\n",
      "Training epoch 113...\n",
      "\n",
      "Train Epoch: 113 [0/8000 (0%)]\tBatch Loss: 36.241548\tLearning Rate (w_theta): 0.001000\t TIME:448.5s\n",
      "\t\t\t\tDisc: 9.863453\t\tSym: 14.164283\t\tSpars: 12.213812\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530533 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 113 [4000/8000 (50%)]\tBatch Loss: 34.840236\tLearning Rate (w_theta): 0.001000\t TIME:450.3s\n",
      "\t\t\t\tDisc: 9.233396\t\tSym: 13.555408\t\tSpars: 12.051432\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530533 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 113...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2540352.7799744625\n",
      "Average validation loss: 1775411.436575954\n",
      "Training epoch 114...\n",
      "\n",
      "Train Epoch: 114 [0/8000 (0%)]\tBatch Loss: 35.983010\tLearning Rate (w_theta): 0.001000\t TIME:452.5s\n",
      "\t\t\t\tDisc: 9.631921\t\tSym: 14.145493\t\tSpars: 12.205597\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530532 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 114 [4000/8000 (50%)]\tBatch Loss: 33.734867\tLearning Rate (w_theta): 0.001000\t TIME:454.3s\n",
      "\t\t\t\tDisc: 8.685827\t\tSym: 13.169148\t\tSpars: 11.879892\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530532 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 114...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2518069.292560558\n",
      "Average validation loss: 1759837.9516728122\n",
      "Training epoch 115...\n",
      "\n",
      "Train Epoch: 115 [0/8000 (0%)]\tBatch Loss: 35.291954\tLearning Rate (w_theta): 0.001000\t TIME:456.5s\n",
      "\t\t\t\tDisc: 9.398963\t\tSym: 13.780637\t\tSpars: 12.112354\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530532 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 115 [4000/8000 (50%)]\tBatch Loss: 36.111642\tLearning Rate (w_theta): 0.001000\t TIME:458.3s\n",
      "\t\t\t\tDisc: 9.347169\t\tSym: 14.294797\t\tSpars: 12.469676\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530532 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 115...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2496173.3426517164\n",
      "Average validation loss: 1744535.3086986186\n",
      "Training epoch 116...\n",
      "\n",
      "Train Epoch: 116 [0/8000 (0%)]\tBatch Loss: 36.466013\tLearning Rate (w_theta): 0.001000\t TIME:460.5s\n",
      "\t\t\t\tDisc: 9.529764\t\tSym: 14.509244\t\tSpars: 12.427005\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530531 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 116 [4000/8000 (50%)]\tBatch Loss: 34.858061\tLearning Rate (w_theta): 0.001000\t TIME:462.2s\n",
      "\t\t\t\tDisc: 8.930757\t\tSym: 13.698657\t\tSpars: 12.228647\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530531 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 116...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2474654.9077946558\n",
      "Average validation loss: 1729496.5031066702\n",
      "Training epoch 117...\n",
      "\n",
      "Train Epoch: 117 [0/8000 (0%)]\tBatch Loss: 33.501953\tLearning Rate (w_theta): 0.001000\t TIME:464.5s\n",
      "\t\t\t\tDisc: 8.580126\t\tSym: 12.914543\t\tSpars: 12.007284\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530531 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 117 [4000/8000 (50%)]\tBatch Loss: 35.154975\tLearning Rate (w_theta): 0.001000\t TIME:466.2s\n",
      "\t\t\t\tDisc: 8.830468\t\tSym: 14.057495\t\tSpars: 12.267012\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530531 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 117...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2453504.3081942312\n",
      "Average validation loss: 1714714.7698809116\n",
      "Training epoch 118...\n",
      "\n",
      "Train Epoch: 118 [0/8000 (0%)]\tBatch Loss: 35.029191\tLearning Rate (w_theta): 0.001000\t TIME:468.5s\n",
      "\t\t\t\tDisc: 9.358907\t\tSym: 13.555442\t\tSpars: 12.114841\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530530 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 118 [4000/8000 (50%)]\tBatch Loss: 35.584767\tLearning Rate (w_theta): 0.001000\t TIME:470.3s\n",
      "\t\t\t\tDisc: 9.271376\t\tSym: 13.959586\t\tSpars: 12.353806\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530530 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 118...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2432712.1920305016\n",
      "Average validation loss: 1700183.5732866551\n",
      "Training epoch 119...\n",
      "\n",
      "Train Epoch: 119 [0/8000 (0%)]\tBatch Loss: 33.948152\tLearning Rate (w_theta): 0.001000\t TIME:472.6s\n",
      "\t\t\t\tDisc: 8.875780\t\tSym: 13.131171\t\tSpars: 11.941200\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530530 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 119 [4000/8000 (50%)]\tBatch Loss: 34.586312\tLearning Rate (w_theta): 0.001000\t TIME:474.3s\n",
      "\t\t\t\tDisc: 8.899060\t\tSym: 13.602785\t\tSpars: 12.084467\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530530 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 119...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2412269.5219875025\n",
      "Average validation loss: 1685896.5973260517\n",
      "Training epoch 120...\n",
      "\n",
      "Train Epoch: 120 [0/8000 (0%)]\tBatch Loss: 34.844418\tLearning Rate (w_theta): 0.001000\t TIME:476.6s\n",
      "\t\t\t\tDisc: 9.080549\t\tSym: 13.765471\t\tSpars: 11.998398\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530529 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 120 [4000/8000 (50%)]\tBatch Loss: 33.450061\tLearning Rate (w_theta): 0.001000\t TIME:478.3s\n",
      "\t\t\t\tDisc: 8.376116\t\tSym: 13.135436\t\tSpars: 11.938509\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530529 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 120...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2392167.5620599003\n",
      "Average validation loss: 1671847.7365279999\n",
      "Training epoch 121...\n",
      "\n",
      "Train Epoch: 121 [0/8000 (0%)]\tBatch Loss: 33.634633\tLearning Rate (w_theta): 0.001000\t TIME:481.4s\n",
      "\t\t\t\tDisc: 8.638921\t\tSym: 13.023002\t\tSpars: 11.972711\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530529 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 121 [4000/8000 (50%)]\tBatch Loss: 33.867131\tLearning Rate (w_theta): 0.001000\t TIME:483.1s\n",
      "\t\t\t\tDisc: 8.441091\t\tSym: 13.409760\t\tSpars: 12.016281\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530529 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 121...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2372397.864784713\n",
      "Average validation loss: 1658031.087194413\n",
      "Training epoch 122...\n",
      "\n",
      "Train Epoch: 122 [0/8000 (0%)]\tBatch Loss: 34.397382\tLearning Rate (w_theta): 0.001000\t TIME:485.3s\n",
      "\t\t\t\tDisc: 8.470265\t\tSym: 13.651996\t\tSpars: 12.275122\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530529 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 122 [4000/8000 (50%)]\tBatch Loss: 35.019279\tLearning Rate (w_theta): 0.001000\t TIME:487.0s\n",
      "\t\t\t\tDisc: 9.064808\t\tSym: 13.716413\t\tSpars: 12.238058\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530528 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 122...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2352952.259636091\n",
      "Average validation loss: 1644440.9392682305\n",
      "Training epoch 123...\n",
      "\n",
      "Train Epoch: 123 [0/8000 (0%)]\tBatch Loss: 33.677808\tLearning Rate (w_theta): 0.001000\t TIME:489.3s\n",
      "\t\t\t\tDisc: 8.568748\t\tSym: 13.215627\t\tSpars: 11.893433\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530528 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 123 [4000/8000 (50%)]\tBatch Loss: 33.540699\tLearning Rate (w_theta): 0.001000\t TIME:491.0s\n",
      "\t\t\t\tDisc: 8.463078\t\tSym: 13.078816\t\tSpars: 11.998805\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530528 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 123...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2333822.842231143\n",
      "Average validation loss: 1631071.7682579628\n",
      "Training epoch 124...\n",
      "\n",
      "Train Epoch: 124 [0/8000 (0%)]\tBatch Loss: 32.323802\tLearning Rate (w_theta): 0.001000\t TIME:493.3s\n",
      "\t\t\t\tDisc: 8.195570\t\tSym: 12.448863\t\tSpars: 11.679369\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530528 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 124 [4000/8000 (50%)]\tBatch Loss: 33.758958\tLearning Rate (w_theta): 0.001000\t TIME:495.0s\n",
      "\t\t\t\tDisc: 8.691856\t\tSym: 13.189336\t\tSpars: 11.877766\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530527 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 124...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2315001.962689062\n",
      "Average validation loss: 1617918.2280436556\n",
      "Training epoch 125...\n",
      "\n",
      "Train Epoch: 125 [0/8000 (0%)]\tBatch Loss: 35.918072\tLearning Rate (w_theta): 0.001000\t TIME:497.2s\n",
      "\t\t\t\tDisc: 9.067218\t\tSym: 14.377967\t\tSpars: 12.472887\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530527 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 125 [4000/8000 (50%)]\tBatch Loss: 34.954830\tLearning Rate (w_theta): 0.001000\t TIME:498.9s\n",
      "\t\t\t\tDisc: 8.786855\t\tSym: 14.075513\t\tSpars: 12.092463\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530527 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 125...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2296482.2161665214\n",
      "Average validation loss: 1604975.143452988\n",
      "Training epoch 126...\n",
      "\n",
      "Train Epoch: 126 [0/8000 (0%)]\tBatch Loss: 34.211443\tLearning Rate (w_theta): 0.001000\t TIME:501.1s\n",
      "\t\t\t\tDisc: 8.537940\t\tSym: 13.519019\t\tSpars: 12.154484\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530527 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 126 [4000/8000 (50%)]\tBatch Loss: 33.204994\tLearning Rate (w_theta): 0.001000\t TIME:502.9s\n",
      "\t\t\t\tDisc: 8.352159\t\tSym: 13.046657\t\tSpars: 11.806179\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530526 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 126...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2278256.4328053496\n",
      "Average validation loss: 1592237.5036738797\n",
      "Training epoch 127...\n",
      "\n",
      "Train Epoch: 127 [0/8000 (0%)]\tBatch Loss: 33.626317\tLearning Rate (w_theta): 0.001000\t TIME:505.1s\n",
      "\t\t\t\tDisc: 8.361028\t\tSym: 13.209305\t\tSpars: 12.055984\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530526 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 127 [4000/8000 (50%)]\tBatch Loss: 32.921599\tLearning Rate (w_theta): 0.001000\t TIME:506.9s\n",
      "\t\t\t\tDisc: 8.287689\t\tSym: 12.639728\t\tSpars: 11.994183\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530526 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 127...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2260317.6687209043\n",
      "Average validation loss: 1579700.4556176425\n",
      "Training epoch 128...\n",
      "\n",
      "Train Epoch: 128 [0/8000 (0%)]\tBatch Loss: 31.410758\tLearning Rate (w_theta): 0.001000\t TIME:509.2s\n",
      "\t\t\t\tDisc: 7.646820\t\tSym: 12.069296\t\tSpars: 11.694642\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530526 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 128 [4000/8000 (50%)]\tBatch Loss: 34.314369\tLearning Rate (w_theta): 0.001000\t TIME:510.9s\n",
      "\t\t\t\tDisc: 8.610989\t\tSym: 13.651979\t\tSpars: 12.051401\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530525 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 128...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2242659.1968644517\n",
      "Average validation loss: 1567359.2980082973\n",
      "Training epoch 129...\n",
      "\n",
      "Train Epoch: 129 [0/8000 (0%)]\tBatch Loss: 33.576239\tLearning Rate (w_theta): 0.001000\t TIME:513.1s\n",
      "\t\t\t\tDisc: 8.449797\t\tSym: 13.130260\t\tSpars: 11.996183\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530525 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 129 [4000/8000 (50%)]\tBatch Loss: 35.021750\tLearning Rate (w_theta): 0.001000\t TIME:515.0s\n",
      "\t\t\t\tDisc: 8.965623\t\tSym: 13.809905\t\tSpars: 12.246222\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530525 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 129...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2225274.498701149\n",
      "Average validation loss: 1555209.4752739477\n",
      "Training epoch 130...\n",
      "\n",
      "Train Epoch: 130 [0/8000 (0%)]\tBatch Loss: 32.656933\tLearning Rate (w_theta): 0.001000\t TIME:517.2s\n",
      "\t\t\t\tDisc: 8.236371\t\tSym: 12.597806\t\tSpars: 11.822756\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530525 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 130 [4000/8000 (50%)]\tBatch Loss: 32.085483\tLearning Rate (w_theta): 0.001000\t TIME:518.9s\n",
      "\t\t\t\tDisc: 7.973121\t\tSym: 12.383457\t\tSpars: 11.728905\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530524 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 130...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2208157.2564563435\n",
      "Average validation loss: 1543246.5719457401\n",
      "Training epoch 131...\n",
      "\n",
      "Train Epoch: 131 [0/8000 (0%)]\tBatch Loss: 31.716565\tLearning Rate (w_theta): 0.001000\t TIME:522.0s\n",
      "\t\t\t\tDisc: 7.850244\t\tSym: 12.255757\t\tSpars: 11.610563\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530524 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 131 [4000/8000 (50%)]\tBatch Loss: 32.126896\tLearning Rate (w_theta): 0.001000\t TIME:523.7s\n",
      "\t\t\t\tDisc: 7.843467\t\tSym: 12.494823\t\tSpars: 11.788607\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530524 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 131...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2191301.345259138\n",
      "Average validation loss: 1531466.3074759252\n",
      "Training epoch 132...\n",
      "\n",
      "Train Epoch: 132 [0/8000 (0%)]\tBatch Loss: 34.649127\tLearning Rate (w_theta): 0.001000\t TIME:526.0s\n",
      "\t\t\t\tDisc: 8.684330\t\tSym: 13.719871\t\tSpars: 12.244926\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530524 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 132 [4000/8000 (50%)]\tBatch Loss: 33.288487\tLearning Rate (w_theta): 0.001000\t TIME:527.7s\n",
      "\t\t\t\tDisc: 8.249900\t\tSym: 12.990878\t\tSpars: 12.047709\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530524 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 132...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2174700.8257594216\n",
      "Average validation loss: 1519864.5309919426\n",
      "Training epoch 133...\n",
      "\n",
      "Train Epoch: 133 [0/8000 (0%)]\tBatch Loss: 31.719947\tLearning Rate (w_theta): 0.001000\t TIME:530.0s\n",
      "\t\t\t\tDisc: 7.827725\t\tSym: 12.102736\t\tSpars: 11.789486\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530523 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 133 [4000/8000 (50%)]\tBatch Loss: 33.311829\tLearning Rate (w_theta): 0.001000\t TIME:531.7s\n",
      "\t\t\t\tDisc: 8.218234\t\tSym: 13.115768\t\tSpars: 11.977826\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530523 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 133...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2158349.93727196\n",
      "Average validation loss: 1508437.2164234188\n",
      "Training epoch 134...\n",
      "\n",
      "Train Epoch: 134 [0/8000 (0%)]\tBatch Loss: 32.458419\tLearning Rate (w_theta): 0.001000\t TIME:534.0s\n",
      "\t\t\t\tDisc: 7.788980\t\tSym: 12.710516\t\tSpars: 11.958923\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530523 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 134 [4000/8000 (50%)]\tBatch Loss: 32.442909\tLearning Rate (w_theta): 0.001000\t TIME:535.7s\n",
      "\t\t\t\tDisc: 8.109738\t\tSym: 12.522899\t\tSpars: 11.810272\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530523 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 134...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2142243.090968335\n",
      "Average validation loss: 1497180.457941849\n",
      "Training epoch 135...\n",
      "\n",
      "Train Epoch: 135 [0/8000 (0%)]\tBatch Loss: 33.263952\tLearning Rate (w_theta): 0.001000\t TIME:537.9s\n",
      "\t\t\t\tDisc: 8.125443\t\tSym: 13.040939\t\tSpars: 12.097569\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530522 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 135 [4000/8000 (50%)]\tBatch Loss: 32.796385\tLearning Rate (w_theta): 0.001000\t TIME:539.6s\n",
      "\t\t\t\tDisc: 8.148408\t\tSym: 12.785932\t\tSpars: 11.862045\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530522 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 135...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2126374.8637158694\n",
      "Average validation loss: 1486090.465413946\n",
      "Training epoch 136...\n",
      "\n",
      "Train Epoch: 136 [0/8000 (0%)]\tBatch Loss: 34.564459\tLearning Rate (w_theta): 0.001000\t TIME:541.9s\n",
      "\t\t\t\tDisc: 8.753809\t\tSym: 13.595949\t\tSpars: 12.214701\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530522 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 136 [4000/8000 (50%)]\tBatch Loss: 30.981512\tLearning Rate (w_theta): 0.001000\t TIME:543.6s\n",
      "\t\t\t\tDisc: 7.629836\t\tSym: 11.737565\t\tSpars: 11.614111\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530522 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 136...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2110739.991935354\n",
      "Average validation loss: 1475163.5601801195\n",
      "Training epoch 137...\n",
      "\n",
      "Train Epoch: 137 [0/8000 (0%)]\tBatch Loss: 32.429138\tLearning Rate (w_theta): 0.001000\t TIME:545.9s\n",
      "\t\t\t\tDisc: 7.970724\t\tSym: 12.615432\t\tSpars: 11.842982\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530521 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 137 [4000/8000 (50%)]\tBatch Loss: 32.213906\tLearning Rate (w_theta): 0.001000\t TIME:547.6s\n",
      "\t\t\t\tDisc: 7.803082\t\tSym: 12.594202\t\tSpars: 11.816623\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530521 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 137...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2095333.36559753\n",
      "Average validation loss: 1464396.1710055016\n",
      "Training epoch 138...\n",
      "\n",
      "Train Epoch: 138 [0/8000 (0%)]\tBatch Loss: 32.447159\tLearning Rate (w_theta): 0.001000\t TIME:549.9s\n",
      "\t\t\t\tDisc: 8.000085\t\tSym: 12.668179\t\tSpars: 11.778896\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530521 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 138 [4000/8000 (50%)]\tBatch Loss: 30.669300\tLearning Rate (w_theta): 0.001000\t TIME:551.6s\n",
      "\t\t\t\tDisc: 7.564399\t\tSym: 11.623901\t\tSpars: 11.480999\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530521 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 138...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2080150.0228688635\n",
      "Average validation loss: 1453784.8301585214\n",
      "Training epoch 139...\n",
      "\n",
      "Train Epoch: 139 [0/8000 (0%)]\tBatch Loss: 32.314785\tLearning Rate (w_theta): 0.001000\t TIME:553.9s\n",
      "\t\t\t\tDisc: 7.890085\t\tSym: 12.622755\t\tSpars: 11.801945\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530520 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 139 [4000/8000 (50%)]\tBatch Loss: 32.337478\tLearning Rate (w_theta): 0.001000\t TIME:555.6s\n",
      "\t\t\t\tDisc: 8.073948\t\tSym: 12.522904\t\tSpars: 11.740625\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530520 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 139...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2065185.1447240517\n",
      "Average validation loss: 1443326.169700506\n",
      "Training epoch 140...\n",
      "\n",
      "Train Epoch: 140 [0/8000 (0%)]\tBatch Loss: 31.406834\tLearning Rate (w_theta): 0.001000\t TIME:557.9s\n",
      "\t\t\t\tDisc: 7.685644\t\tSym: 11.969405\t\tSpars: 11.751785\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530520 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 140 [4000/8000 (50%)]\tBatch Loss: 32.299675\tLearning Rate (w_theta): 0.001000\t TIME:559.6s\n",
      "\t\t\t\tDisc: 7.771220\t\tSym: 12.670331\t\tSpars: 11.858124\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530520 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 140...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2050434.0497464775\n",
      "Average validation loss: 1433016.9179009367\n",
      "Training epoch 141...\n",
      "\n",
      "Train Epoch: 141 [0/8000 (0%)]\tBatch Loss: 32.014067\tLearning Rate (w_theta): 0.001000\t TIME:562.7s\n",
      "\t\t\t\tDisc: 7.950869\t\tSym: 12.425568\t\tSpars: 11.637630\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530519 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 141 [4000/8000 (50%)]\tBatch Loss: 31.733375\tLearning Rate (w_theta): 0.001000\t TIME:564.5s\n",
      "\t\t\t\tDisc: 7.620993\t\tSym: 12.348824\t\tSpars: 11.763559\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530519 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 141...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2035892.1894031228\n",
      "Average validation loss: 1422853.8958877476\n",
      "Training epoch 142...\n",
      "\n",
      "Train Epoch: 142 [0/8000 (0%)]\tBatch Loss: 30.899725\tLearning Rate (w_theta): 0.001000\t TIME:566.7s\n",
      "\t\t\t\tDisc: 7.470084\t\tSym: 11.794592\t\tSpars: 11.635049\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530519 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 142 [4000/8000 (50%)]\tBatch Loss: 31.982104\tLearning Rate (w_theta): 0.001000\t TIME:568.4s\n",
      "\t\t\t\tDisc: 7.856746\t\tSym: 12.464554\t\tSpars: 11.660805\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530519 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 142...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2021555.143180285\n",
      "Average validation loss: 1412834.0142730055\n",
      "Training epoch 143...\n",
      "\n",
      "Train Epoch: 143 [0/8000 (0%)]\tBatch Loss: 32.022449\tLearning Rate (w_theta): 0.001000\t TIME:570.7s\n",
      "\t\t\t\tDisc: 7.840320\t\tSym: 12.463629\t\tSpars: 11.718500\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530519 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 143 [4000/8000 (50%)]\tBatch Loss: 31.315956\tLearning Rate (w_theta): 0.001000\t TIME:572.4s\n",
      "\t\t\t\tDisc: 7.725003\t\tSym: 11.929873\t\tSpars: 11.661080\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530518 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 143...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2007418.6143197552\n",
      "Average validation loss: 1402954.2701394064\n",
      "Training epoch 144...\n",
      "\n",
      "Train Epoch: 144 [0/8000 (0%)]\tBatch Loss: 29.994276\tLearning Rate (w_theta): 0.001000\t TIME:574.7s\n",
      "\t\t\t\tDisc: 7.100771\t\tSym: 11.474227\t\tSpars: 11.419278\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530518 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 144 [4000/8000 (50%)]\tBatch Loss: 30.776261\tLearning Rate (w_theta): 0.001000\t TIME:576.4s\n",
      "\t\t\t\tDisc: 7.523284\t\tSym: 11.666934\t\tSpars: 11.586042\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530518 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 144...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1993478.425406147\n",
      "Average validation loss: 1393211.743952816\n",
      "Training epoch 145...\n",
      "\n",
      "Train Epoch: 145 [0/8000 (0%)]\tBatch Loss: 30.541833\tLearning Rate (w_theta): 0.001000\t TIME:578.6s\n",
      "\t\t\t\tDisc: 7.309625\t\tSym: 11.672338\t\tSpars: 11.559870\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530518 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 145 [4000/8000 (50%)]\tBatch Loss: 30.986447\tLearning Rate (w_theta): 0.001000\t TIME:580.4s\n",
      "\t\t\t\tDisc: 7.488784\t\tSym: 11.900270\t\tSpars: 11.597393\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530517 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 145...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1979730.5142050383\n",
      "Average validation loss: 1383603.5967297973\n",
      "Training epoch 146...\n",
      "\n",
      "Train Epoch: 146 [0/8000 (0%)]\tBatch Loss: 31.880012\tLearning Rate (w_theta): 0.001000\t TIME:582.6s\n",
      "\t\t\t\tDisc: 7.551088\t\tSym: 12.448336\t\tSpars: 11.880588\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530517 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 146 [4000/8000 (50%)]\tBatch Loss: 31.457730\tLearning Rate (w_theta): 0.001000\t TIME:584.4s\n",
      "\t\t\t\tDisc: 7.484552\t\tSym: 12.258323\t\tSpars: 11.714856\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530517 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 146...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1966170.9298384578\n",
      "Average validation loss: 1374127.0672598574\n",
      "Training epoch 147...\n",
      "\n",
      "Train Epoch: 147 [0/8000 (0%)]\tBatch Loss: 33.880758\tLearning Rate (w_theta): 0.001000\t TIME:586.7s\n",
      "\t\t\t\tDisc: 8.223081\t\tSym: 13.458102\t\tSpars: 12.199575\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530517 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 147 [4000/8000 (50%)]\tBatch Loss: 30.734106\tLearning Rate (w_theta): 0.001000\t TIME:588.4s\n",
      "\t\t\t\tDisc: 7.370353\t\tSym: 11.792177\t\tSpars: 11.571576\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530516 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 147...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1952795.8289266056\n",
      "Average validation loss: 1364779.4694691626\n",
      "Training epoch 148...\n",
      "\n",
      "Train Epoch: 148 [0/8000 (0%)]\tBatch Loss: 29.625235\tLearning Rate (w_theta): 0.001000\t TIME:590.8s\n",
      "\t\t\t\tDisc: 7.105627\t\tSym: 11.291858\t\tSpars: 11.227751\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530516 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 148 [4000/8000 (50%)]\tBatch Loss: 30.891767\tLearning Rate (w_theta): 0.001000\t TIME:592.6s\n",
      "\t\t\t\tDisc: 7.445357\t\tSym: 11.873497\t\tSpars: 11.572913\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530516 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 148...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1939601.4719025935\n",
      "Average validation loss: 1355558.189915057\n",
      "Training epoch 149...\n",
      "\n",
      "Train Epoch: 149 [0/8000 (0%)]\tBatch Loss: 31.549726\tLearning Rate (w_theta): 0.001000\t TIME:594.9s\n",
      "\t\t\t\tDisc: 7.591257\t\tSym: 12.204589\t\tSpars: 11.753880\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530516 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 149 [4000/8000 (50%)]\tBatch Loss: 30.415339\tLearning Rate (w_theta): 0.001000\t TIME:596.6s\n",
      "\t\t\t\tDisc: 7.227836\t\tSym: 11.616534\t\tSpars: 11.570969\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530515 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 149...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1926584.2196169433\n",
      "Average validation loss: 1346460.685254931\n",
      "Training epoch 150...\n",
      "\n",
      "Train Epoch: 150 [0/8000 (0%)]\tBatch Loss: 31.982756\tLearning Rate (w_theta): 0.001000\t TIME:598.8s\n",
      "\t\t\t\tDisc: 7.645830\t\tSym: 12.497695\t\tSpars: 11.839231\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530515 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 150 [4000/8000 (50%)]\tBatch Loss: 30.678616\tLearning Rate (w_theta): 0.001000\t TIME:600.6s\n",
      "\t\t\t\tDisc: 7.276861\t\tSym: 11.828021\t\tSpars: 11.573734\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530515 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 150...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1913740.5300710266\n",
      "Average validation loss: 1337484.479986997\n",
      "Training epoch 151...\n",
      "\n",
      "Train Epoch: 151 [0/8000 (0%)]\tBatch Loss: 30.565493\tLearning Rate (w_theta): 0.001000\t TIME:603.6s\n",
      "\t\t\t\tDisc: 7.279615\t\tSym: 11.794669\t\tSpars: 11.491209\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530515 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 151 [4000/8000 (50%)]\tBatch Loss: 30.062336\tLearning Rate (w_theta): 0.001000\t TIME:605.3s\n",
      "\t\t\t\tDisc: 7.117559\t\tSym: 11.409746\t\tSpars: 11.535030\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530514 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 151...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1901066.9549067607\n",
      "Average validation loss: 1328627.1641818322\n",
      "Training epoch 152...\n",
      "\n",
      "Train Epoch: 152 [0/8000 (0%)]\tBatch Loss: 29.655037\tLearning Rate (w_theta): 0.001000\t TIME:607.6s\n",
      "\t\t\t\tDisc: 6.857843\t\tSym: 11.379974\t\tSpars: 11.417219\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530514 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 152 [4000/8000 (50%)]\tBatch Loss: 30.385564\tLearning Rate (w_theta): 0.001000\t TIME:609.3s\n",
      "\t\t\t\tDisc: 7.214445\t\tSym: 11.620124\t\tSpars: 11.550995\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530514 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 152...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1888560.136631576\n",
      "Average validation loss: 1319886.3913629071\n",
      "Training epoch 153...\n",
      "\n",
      "Train Epoch: 153 [0/8000 (0%)]\tBatch Loss: 31.300018\tLearning Rate (w_theta): 0.001000\t TIME:611.5s\n",
      "\t\t\t\tDisc: 7.390302\t\tSym: 12.188471\t\tSpars: 11.721245\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530514 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 153 [4000/8000 (50%)]\tBatch Loss: 30.868275\tLearning Rate (w_theta): 0.001000\t TIME:613.2s\n",
      "\t\t\t\tDisc: 7.467798\t\tSym: 11.868634\t\tSpars: 11.531843\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530514 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 153...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1876216.8055194106\n",
      "Average validation loss: 1311259.8763731078\n",
      "Training epoch 154...\n",
      "\n",
      "Train Epoch: 154 [0/8000 (0%)]\tBatch Loss: 28.459119\tLearning Rate (w_theta): 0.001000\t TIME:615.5s\n",
      "\t\t\t\tDisc: 6.761513\t\tSym: 10.644926\t\tSpars: 11.052680\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530513 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 154 [4000/8000 (50%)]\tBatch Loss: 31.024684\tLearning Rate (w_theta): 0.001000\t TIME:617.3s\n",
      "\t\t\t\tDisc: 7.157015\t\tSym: 12.058915\t\tSpars: 11.808754\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530513 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 154...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1864033.7767602361\n",
      "Average validation loss: 1302745.3934124978\n",
      "Training epoch 155...\n",
      "\n",
      "Train Epoch: 155 [0/8000 (0%)]\tBatch Loss: 29.599218\tLearning Rate (w_theta): 0.001000\t TIME:619.6s\n",
      "\t\t\t\tDisc: 6.946149\t\tSym: 11.332242\t\tSpars: 11.320827\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530513 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 155 [4000/8000 (50%)]\tBatch Loss: 30.405023\tLearning Rate (w_theta): 0.001000\t TIME:621.3s\n",
      "\t\t\t\tDisc: 7.300670\t\tSym: 11.637123\t\tSpars: 11.467230\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530513 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 155...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1852007.9477290025\n",
      "Average validation loss: 1294340.7741289947\n",
      "Training epoch 156...\n",
      "\n",
      "Train Epoch: 156 [0/8000 (0%)]\tBatch Loss: 30.307085\tLearning Rate (w_theta): 0.001000\t TIME:623.6s\n",
      "\t\t\t\tDisc: 7.109013\t\tSym: 11.596847\t\tSpars: 11.601226\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530512 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 156 [4000/8000 (50%)]\tBatch Loss: 28.816550\tLearning Rate (w_theta): 0.001000\t TIME:625.3s\n",
      "\t\t\t\tDisc: 6.679734\t\tSym: 10.771934\t\tSpars: 11.364882\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530512 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 156...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1840136.295371665\n",
      "Average validation loss: 1286043.905762569\n",
      "Training epoch 157...\n",
      "\n",
      "Train Epoch: 157 [0/8000 (0%)]\tBatch Loss: 29.908876\tLearning Rate (w_theta): 0.001000\t TIME:627.5s\n",
      "\t\t\t\tDisc: 6.984178\t\tSym: 11.356264\t\tSpars: 11.568434\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530512 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 157 [4000/8000 (50%)]\tBatch Loss: 31.467949\tLearning Rate (w_theta): 0.001000\t TIME:629.2s\n",
      "\t\t\t\tDisc: 7.362198\t\tSym: 12.292381\t\tSpars: 11.813370\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530512 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 157...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1828415.873624397\n",
      "Average validation loss: 1277852.7293935881\n",
      "Training epoch 158...\n",
      "\n",
      "Train Epoch: 158 [0/8000 (0%)]\tBatch Loss: 30.294361\tLearning Rate (w_theta): 0.001000\t TIME:631.5s\n",
      "\t\t\t\tDisc: 7.369843\t\tSym: 11.486139\t\tSpars: 11.438378\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530511 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 158 [4000/8000 (50%)]\tBatch Loss: 29.104793\tLearning Rate (w_theta): 0.001000\t TIME:633.3s\n",
      "\t\t\t\tDisc: 6.574339\t\tSym: 11.151120\t\tSpars: 11.379333\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530511 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 158...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1816843.8110173156\n",
      "Average validation loss: 1269765.238178925\n",
      "Training epoch 159...\n",
      "\n",
      "Train Epoch: 159 [0/8000 (0%)]\tBatch Loss: 30.280197\tLearning Rate (w_theta): 0.001000\t TIME:635.6s\n",
      "\t\t\t\tDisc: 7.065193\t\tSym: 11.653450\t\tSpars: 11.561554\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530511 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 159 [4000/8000 (50%)]\tBatch Loss: 30.951682\tLearning Rate (w_theta): 0.001000\t TIME:637.4s\n",
      "\t\t\t\tDisc: 7.383111\t\tSym: 11.805468\t\tSpars: 11.763103\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530511 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "Validating epoch 159...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1805417.3083306458\n",
      "Average validation loss: 1261779.4758190603\n",
      "Training epoch 160...\n",
      "\n",
      "Train Epoch: 160 [0/8000 (0%)]\tBatch Loss: 31.763974\tLearning Rate (w_theta): 0.001000\t TIME:639.7s\n",
      "\t\t\t\tDisc: 7.525444\t\tSym: 12.452846\t\tSpars: 11.785685\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530510 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026645\n",
      "\n",
      "Train Epoch: 160 [4000/8000 (50%)]\tBatch Loss: 30.600134\tLearning Rate (w_theta): 0.001000\t TIME:641.4s\n",
      "\t\t\t\tDisc: 7.259193\t\tSym: 11.687263\t\tSpars: 11.653679\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530510 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 160...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1794133.6363326397\n",
      "Average validation loss: 1253893.5349043775\n",
      "Training epoch 161...\n",
      "\n",
      "Train Epoch: 161 [0/8000 (0%)]\tBatch Loss: 29.778826\tLearning Rate (w_theta): 0.001000\t TIME:644.5s\n",
      "\t\t\t\tDisc: 6.885309\t\tSym: 11.394925\t\tSpars: 11.498592\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530510 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 161 [4000/8000 (50%)]\tBatch Loss: 29.869486\tLearning Rate (w_theta): 0.001000\t TIME:646.2s\n",
      "\t\t\t\tDisc: 6.992347\t\tSym: 11.371709\t\tSpars: 11.505430\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530510 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 161...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1782990.1335906691\n",
      "Average validation loss: 1246105.555412814\n",
      "Training epoch 162...\n",
      "\n",
      "Train Epoch: 162 [0/8000 (0%)]\tBatch Loss: 29.922316\tLearning Rate (w_theta): 0.001000\t TIME:648.5s\n",
      "\t\t\t\tDisc: 6.950115\t\tSym: 11.494115\t\tSpars: 11.478086\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530509 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 162 [4000/8000 (50%)]\tBatch Loss: 27.972262\tLearning Rate (w_theta): 0.001000\t TIME:650.2s\n",
      "\t\t\t\tDisc: 6.432748\t\tSym: 10.489967\t\tSpars: 11.049546\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530509 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 162...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1771984.2044026675\n",
      "Average validation loss: 1238413.7232667594\n",
      "Training epoch 163...\n",
      "\n",
      "Train Epoch: 163 [0/8000 (0%)]\tBatch Loss: 30.707289\tLearning Rate (w_theta): 0.001000\t TIME:652.6s\n",
      "\t\t\t\tDisc: 7.140132\t\tSym: 11.813265\t\tSpars: 11.753893\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530509 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 163 [4000/8000 (50%)]\tBatch Loss: 28.987171\tLearning Rate (w_theta): 0.001000\t TIME:654.3s\n",
      "\t\t\t\tDisc: 6.696795\t\tSym: 11.056048\t\tSpars: 11.234327\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530509 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 163...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1761113.3166545464\n",
      "Average validation loss: 1230816.2688864337\n",
      "Training epoch 164...\n",
      "\n",
      "Train Epoch: 164 [0/8000 (0%)]\tBatch Loss: 29.557168\tLearning Rate (w_theta): 0.001000\t TIME:656.5s\n",
      "\t\t\t\tDisc: 6.791212\t\tSym: 11.336905\t\tSpars: 11.429050\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530509 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 164 [4000/8000 (50%)]\tBatch Loss: 29.279600\tLearning Rate (w_theta): 0.001000\t TIME:658.2s\n",
      "\t\t\t\tDisc: 6.780693\t\tSym: 11.170959\t\tSpars: 11.327948\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530508 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 164...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1750375.0001885998\n",
      "Average validation loss: 1223311.4658182622\n",
      "Training epoch 165...\n",
      "\n",
      "Train Epoch: 165 [0/8000 (0%)]\tBatch Loss: 30.411529\tLearning Rate (w_theta): 0.001000\t TIME:660.5s\n",
      "\t\t\t\tDisc: 7.169909\t\tSym: 11.696327\t\tSpars: 11.545293\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530508 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 165 [4000/8000 (50%)]\tBatch Loss: 27.848408\tLearning Rate (w_theta): 0.001000\t TIME:662.2s\n",
      "\t\t\t\tDisc: 6.441561\t\tSym: 10.484305\t\tSpars: 10.922542\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530508 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 165...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1739766.8445069857\n",
      "Average validation loss: 1215897.629508993\n",
      "Training epoch 166...\n",
      "\n",
      "Train Epoch: 166 [0/8000 (0%)]\tBatch Loss: 29.143760\tLearning Rate (w_theta): 0.001000\t TIME:664.6s\n",
      "\t\t\t\tDisc: 6.615416\t\tSym: 11.085276\t\tSpars: 11.443069\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530508 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 166 [4000/8000 (50%)]\tBatch Loss: 28.055784\tLearning Rate (w_theta): 0.001000\t TIME:666.3s\n",
      "\t\t\t\tDisc: 6.526725\t\tSym: 10.390192\t\tSpars: 11.138867\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530507 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 166...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1729286.497380149\n",
      "Average validation loss: 1208573.1159864562\n",
      "Training epoch 167...\n",
      "\n",
      "Train Epoch: 167 [0/8000 (0%)]\tBatch Loss: 28.706012\tLearning Rate (w_theta): 0.001000\t TIME:668.7s\n",
      "\t\t\t\tDisc: 6.556805\t\tSym: 10.847630\t\tSpars: 11.301578\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530507 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 167 [4000/8000 (50%)]\tBatch Loss: 29.191196\tLearning Rate (w_theta): 0.001000\t TIME:670.4s\n",
      "\t\t\t\tDisc: 6.727637\t\tSym: 11.126353\t\tSpars: 11.337206\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530507 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 167...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1718931.6628304238\n",
      "Average validation loss: 1201336.3206676994\n",
      "Training epoch 168...\n",
      "\n",
      "Train Epoch: 168 [0/8000 (0%)]\tBatch Loss: 29.493395\tLearning Rate (w_theta): 0.001000\t TIME:672.7s\n",
      "\t\t\t\tDisc: 6.732110\t\tSym: 11.343122\t\tSpars: 11.418163\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530507 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 168 [4000/8000 (50%)]\tBatch Loss: 28.752348\tLearning Rate (w_theta): 0.001000\t TIME:674.4s\n",
      "\t\t\t\tDisc: 6.573674\t\tSym: 10.908188\t\tSpars: 11.270486\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530506 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 168...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1708700.0996177783\n",
      "Average validation loss: 1194185.6771557727\n",
      "Training epoch 169...\n",
      "\n",
      "Train Epoch: 169 [0/8000 (0%)]\tBatch Loss: 28.069436\tLearning Rate (w_theta): 0.001000\t TIME:676.6s\n",
      "\t\t\t\tDisc: 6.375192\t\tSym: 10.555381\t\tSpars: 11.138863\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530506 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 169 [4000/8000 (50%)]\tBatch Loss: 28.603086\tLearning Rate (w_theta): 0.001000\t TIME:678.3s\n",
      "\t\t\t\tDisc: 6.629214\t\tSym: 10.879668\t\tSpars: 11.094204\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530506 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 169...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1698589.619447954\n",
      "Average validation loss: 1187119.656127156\n",
      "Training epoch 170...\n",
      "\n",
      "Train Epoch: 170 [0/8000 (0%)]\tBatch Loss: 27.922287\tLearning Rate (w_theta): 0.001000\t TIME:680.7s\n",
      "\t\t\t\tDisc: 6.265696\t\tSym: 10.490977\t\tSpars: 11.165613\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530506 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 170 [4000/8000 (50%)]\tBatch Loss: 28.617658\tLearning Rate (w_theta): 0.001000\t TIME:682.5s\n",
      "\t\t\t\tDisc: 6.498162\t\tSym: 10.850802\t\tSpars: 11.268693\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530505 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 170...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1688598.0855610762\n",
      "Average validation loss: 1180136.764264892\n",
      "Training epoch 171...\n",
      "\n",
      "Train Epoch: 171 [0/8000 (0%)]\tBatch Loss: 28.457862\tLearning Rate (w_theta): 0.001000\t TIME:685.6s\n",
      "\t\t\t\tDisc: 6.469061\t\tSym: 10.697423\t\tSpars: 11.291378\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530505 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 171 [4000/8000 (50%)]\tBatch Loss: 28.930176\tLearning Rate (w_theta): 0.001000\t TIME:687.3s\n",
      "\t\t\t\tDisc: 6.692510\t\tSym: 10.912530\t\tSpars: 11.325136\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530505 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 171...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1678723.41118775\n",
      "Average validation loss: 1173235.5431428899\n",
      "Training epoch 172...\n",
      "\n",
      "Train Epoch: 172 [0/8000 (0%)]\tBatch Loss: 28.407924\tLearning Rate (w_theta): 0.001000\t TIME:689.5s\n",
      "\t\t\t\tDisc: 6.527106\t\tSym: 10.657549\t\tSpars: 11.223269\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530505 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 172 [4000/8000 (50%)]\tBatch Loss: 27.838099\tLearning Rate (w_theta): 0.001000\t TIME:691.3s\n",
      "\t\t\t\tDisc: 6.233929\t\tSym: 10.472465\t\tSpars: 11.131705\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530504 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 172...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1668963.5580960256\n",
      "Average validation loss: 1166414.5682782456\n",
      "Training epoch 173...\n",
      "\n",
      "Train Epoch: 173 [0/8000 (0%)]\tBatch Loss: 29.904105\tLearning Rate (w_theta): 0.001000\t TIME:693.7s\n",
      "\t\t\t\tDisc: 6.936075\t\tSym: 11.462371\t\tSpars: 11.505659\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530504 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 173 [4000/8000 (50%)]\tBatch Loss: 28.462405\tLearning Rate (w_theta): 0.001000\t TIME:695.4s\n",
      "\t\t\t\tDisc: 6.497591\t\tSym: 10.702071\t\tSpars: 11.262743\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530504 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 173...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1659316.5351920477\n",
      "Average validation loss: 1159672.4481210532\n",
      "Training epoch 174...\n",
      "\n",
      "Train Epoch: 174 [0/8000 (0%)]\tBatch Loss: 28.001754\tLearning Rate (w_theta): 0.001000\t TIME:697.7s\n",
      "\t\t\t\tDisc: 6.554402\t\tSym: 10.280574\t\tSpars: 11.166779\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530504 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 174 [4000/8000 (50%)]\tBatch Loss: 28.667056\tLearning Rate (w_theta): 0.001000\t TIME:699.4s\n",
      "\t\t\t\tDisc: 6.492248\t\tSym: 10.934188\t\tSpars: 11.240621\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530504 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 174...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1649780.397101563\n",
      "Average validation loss: 1153007.8231149665\n",
      "Training epoch 175...\n",
      "\n",
      "Train Epoch: 175 [0/8000 (0%)]\tBatch Loss: 28.921287\tLearning Rate (w_theta): 0.001000\t TIME:701.7s\n",
      "\t\t\t\tDisc: 6.546272\t\tSym: 11.147181\t\tSpars: 11.227835\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530503 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 175 [4000/8000 (50%)]\tBatch Loss: 28.978316\tLearning Rate (w_theta): 0.001000\t TIME:703.4s\n",
      "\t\t\t\tDisc: 6.667806\t\tSym: 10.894771\t\tSpars: 11.415739\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530503 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 175...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1640353.2429373553\n",
      "Average validation loss: 1146419.3647723226\n",
      "Training epoch 176...\n",
      "\n",
      "Train Epoch: 176 [0/8000 (0%)]\tBatch Loss: 27.717090\tLearning Rate (w_theta): 0.001000\t TIME:705.8s\n",
      "\t\t\t\tDisc: 6.273372\t\tSym: 10.424689\t\tSpars: 11.019029\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530503 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 176 [4000/8000 (50%)]\tBatch Loss: 28.007220\tLearning Rate (w_theta): 0.001000\t TIME:707.5s\n",
      "\t\t\t\tDisc: 6.235416\t\tSym: 10.633102\t\tSpars: 11.138701\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530503 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 176...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1631033.2150190517\n",
      "Average validation loss: 1139905.774798636\n",
      "Training epoch 177...\n",
      "\n",
      "Train Epoch: 177 [0/8000 (0%)]\tBatch Loss: 27.450269\tLearning Rate (w_theta): 0.001000\t TIME:709.8s\n",
      "\t\t\t\tDisc: 6.127773\t\tSym: 10.230788\t\tSpars: 11.091707\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530502 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 177 [4000/8000 (50%)]\tBatch Loss: 27.395389\tLearning Rate (w_theta): 0.001000\t TIME:711.5s\n",
      "\t\t\t\tDisc: 6.129085\t\tSym: 10.188605\t\tSpars: 11.077699\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530502 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 177...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1621818.4976579088\n",
      "Average validation loss: 1133465.7842444968\n",
      "Training epoch 178...\n",
      "\n",
      "Train Epoch: 178 [0/8000 (0%)]\tBatch Loss: 29.625640\tLearning Rate (w_theta): 0.001000\t TIME:713.8s\n",
      "\t\t\t\tDisc: 6.768898\t\tSym: 11.392932\t\tSpars: 11.463810\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530502 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 178 [4000/8000 (50%)]\tBatch Loss: 28.911328\tLearning Rate (w_theta): 0.001000\t TIME:715.5s\n",
      "\t\t\t\tDisc: 6.627390\t\tSym: 10.914054\t\tSpars: 11.369884\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530502 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 178...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1612707.315981182\n",
      "Average validation loss: 1127098.1526796378\n",
      "Training epoch 179...\n",
      "\n",
      "Train Epoch: 179 [0/8000 (0%)]\tBatch Loss: 27.599476\tLearning Rate (w_theta): 0.001000\t TIME:717.9s\n",
      "\t\t\t\tDisc: 6.223685\t\tSym: 10.392589\t\tSpars: 10.983202\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530501 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 179 [4000/8000 (50%)]\tBatch Loss: 29.128029\tLearning Rate (w_theta): 0.001000\t TIME:719.6s\n",
      "\t\t\t\tDisc: 6.620129\t\tSym: 11.157104\t\tSpars: 11.350796\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530501 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 179...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1603697.9347072584\n",
      "Average validation loss: 1120801.6673703392\n",
      "Training epoch 180...\n",
      "\n",
      "Train Epoch: 180 [0/8000 (0%)]\tBatch Loss: 28.333525\tLearning Rate (w_theta): 0.001000\t TIME:721.9s\n",
      "\t\t\t\tDisc: 6.335298\t\tSym: 10.751441\t\tSpars: 11.246786\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530501 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 180 [4000/8000 (50%)]\tBatch Loss: 27.943538\tLearning Rate (w_theta): 0.001000\t TIME:723.6s\n",
      "\t\t\t\tDisc: 6.353927\t\tSym: 10.470412\t\tSpars: 11.119199\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530501 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 180...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1594788.6572155752\n",
      "Average validation loss: 1114575.142542139\n",
      "Training epoch 181...\n",
      "\n",
      "Train Epoch: 181 [0/8000 (0%)]\tBatch Loss: 27.420023\tLearning Rate (w_theta): 0.001000\t TIME:726.8s\n",
      "\t\t\t\tDisc: 6.006722\t\tSym: 10.283075\t\tSpars: 11.130226\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530500 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 181 [4000/8000 (50%)]\tBatch Loss: 26.361970\tLearning Rate (w_theta): 0.001000\t TIME:728.5s\n",
      "\t\t\t\tDisc: 5.920605\t\tSym: 9.557762\t\tSpars: 10.883602\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530500 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 181...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1585977.8243016165\n",
      "Average validation loss: 1108417.4186385788\n",
      "Training epoch 182...\n",
      "\n",
      "Train Epoch: 182 [0/8000 (0%)]\tBatch Loss: 27.926087\tLearning Rate (w_theta): 0.001000\t TIME:730.8s\n",
      "\t\t\t\tDisc: 6.098633\t\tSym: 10.521260\t\tSpars: 11.306194\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530500 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 182 [4000/8000 (50%)]\tBatch Loss: 27.834847\tLearning Rate (w_theta): 0.001000\t TIME:732.5s\n",
      "\t\t\t\tDisc: 6.148596\t\tSym: 10.505420\t\tSpars: 11.180832\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530500 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 182...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1577263.8132567352\n",
      "Average validation loss: 1102327.3615749644\n",
      "Training epoch 183...\n",
      "\n",
      "Train Epoch: 183 [0/8000 (0%)]\tBatch Loss: 27.626896\tLearning Rate (w_theta): 0.001000\t TIME:734.8s\n",
      "\t\t\t\tDisc: 6.155984\t\tSym: 10.357491\t\tSpars: 11.113421\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530499 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 183 [4000/8000 (50%)]\tBatch Loss: 27.253728\tLearning Rate (w_theta): 0.001000\t TIME:736.5s\n",
      "\t\t\t\tDisc: 6.084018\t\tSym: 10.110588\t\tSpars: 11.059122\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530499 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 183...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1568645.0368401168\n",
      "Average validation loss: 1096303.8620663548\n",
      "Training epoch 184...\n",
      "\n",
      "Train Epoch: 184 [0/8000 (0%)]\tBatch Loss: 27.740907\tLearning Rate (w_theta): 0.001000\t TIME:738.7s\n",
      "\t\t\t\tDisc: 6.163235\t\tSym: 10.465785\t\tSpars: 11.111887\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530499 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 184 [4000/8000 (50%)]\tBatch Loss: 27.541396\tLearning Rate (w_theta): 0.001000\t TIME:740.4s\n",
      "\t\t\t\tDisc: 6.067518\t\tSym: 10.323013\t\tSpars: 11.150865\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530499 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 184...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1560119.942318567\n",
      "Average validation loss: 1090345.834932869\n",
      "Training epoch 185...\n",
      "\n",
      "Train Epoch: 185 [0/8000 (0%)]\tBatch Loss: 26.076228\tLearning Rate (w_theta): 0.001000\t TIME:742.7s\n",
      "\t\t\t\tDisc: 5.589128\t\tSym: 9.673569\t\tSpars: 10.813532\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530499 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 185 [4000/8000 (50%)]\tBatch Loss: 28.856728\tLearning Rate (w_theta): 0.001000\t TIME:744.5s\n",
      "\t\t\t\tDisc: 6.467526\t\tSym: 11.002223\t\tSpars: 11.386979\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530498 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 185...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1551687.0105249824\n",
      "Average validation loss: 1084452.2184666349\n",
      "Training epoch 186...\n",
      "\n",
      "Train Epoch: 186 [0/8000 (0%)]\tBatch Loss: 28.628246\tLearning Rate (w_theta): 0.001000\t TIME:746.8s\n",
      "\t\t\t\tDisc: 6.330190\t\tSym: 10.894218\t\tSpars: 11.403838\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530498 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 186 [4000/8000 (50%)]\tBatch Loss: 27.737765\tLearning Rate (w_theta): 0.001000\t TIME:748.6s\n",
      "\t\t\t\tDisc: 6.318605\t\tSym: 10.419291\t\tSpars: 10.999868\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530498 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 186...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1543344.7549709182\n",
      "Average validation loss: 1078621.9737807184\n",
      "Training epoch 187...\n",
      "\n",
      "Train Epoch: 187 [0/8000 (0%)]\tBatch Loss: 28.678598\tLearning Rate (w_theta): 0.001000\t TIME:750.9s\n",
      "\t\t\t\tDisc: 6.430977\t\tSym: 10.969264\t\tSpars: 11.278357\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530498 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 187 [4000/8000 (50%)]\tBatch Loss: 27.704311\tLearning Rate (w_theta): 0.001000\t TIME:752.6s\n",
      "\t\t\t\tDisc: 6.087704\t\tSym: 10.410051\t\tSpars: 11.206556\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530497 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 187...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1535091.7209645887\n",
      "Average validation loss: 1072854.0842199347\n",
      "Training epoch 188...\n",
      "\n",
      "Train Epoch: 188 [0/8000 (0%)]\tBatch Loss: 27.755834\tLearning Rate (w_theta): 0.001000\t TIME:754.9s\n",
      "\t\t\t\tDisc: 6.007274\t\tSym: 10.610761\t\tSpars: 11.137800\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530497 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 188 [4000/8000 (50%)]\tBatch Loss: 28.920682\tLearning Rate (w_theta): 0.001000\t TIME:756.6s\n",
      "\t\t\t\tDisc: 6.575288\t\tSym: 10.992778\t\tSpars: 11.352616\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530497 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 188...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1526926.4847484636\n",
      "Average validation loss: 1067147.5547613525\n",
      "Training epoch 189...\n",
      "\n",
      "Train Epoch: 189 [0/8000 (0%)]\tBatch Loss: 28.318551\tLearning Rate (w_theta): 0.001000\t TIME:758.9s\n",
      "\t\t\t\tDisc: 6.188162\t\tSym: 10.915016\t\tSpars: 11.215373\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530497 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 189 [4000/8000 (50%)]\tBatch Loss: 26.296504\tLearning Rate (w_theta): 0.001000\t TIME:760.7s\n",
      "\t\t\t\tDisc: 5.748830\t\tSym: 9.725351\t\tSpars: 10.822322\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530496 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 189...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1518847.6527548758\n",
      "Average validation loss: 1061501.4114308918\n",
      "Training epoch 190...\n",
      "\n",
      "Train Epoch: 190 [0/8000 (0%)]\tBatch Loss: 26.900679\tLearning Rate (w_theta): 0.001000\t TIME:762.9s\n",
      "\t\t\t\tDisc: 5.915635\t\tSym: 10.034793\t\tSpars: 10.950251\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530496 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 190 [4000/8000 (50%)]\tBatch Loss: 26.875292\tLearning Rate (w_theta): 0.001000\t TIME:764.6s\n",
      "\t\t\t\tDisc: 5.828251\t\tSym: 10.081339\t\tSpars: 10.965702\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530496 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 190...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1510853.8606311798\n",
      "Average validation loss: 1055914.700779234\n",
      "Training epoch 191...\n",
      "\n",
      "Train Epoch: 191 [0/8000 (0%)]\tBatch Loss: 26.449803\tLearning Rate (w_theta): 0.001000\t TIME:767.8s\n",
      "\t\t\t\tDisc: 5.641037\t\tSym: 9.962314\t\tSpars: 10.846453\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530496 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 191 [4000/8000 (50%)]\tBatch Loss: 27.313706\tLearning Rate (w_theta): 0.001000\t TIME:769.6s\n",
      "\t\t\t\tDisc: 5.956132\t\tSym: 10.227388\t\tSpars: 11.130186\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530495 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 191...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1502943.772709209\n",
      "Average validation loss: 1050386.4892944784\n",
      "Training epoch 192...\n",
      "\n",
      "Train Epoch: 192 [0/8000 (0%)]\tBatch Loss: 26.289564\tLearning Rate (w_theta): 0.001000\t TIME:771.8s\n",
      "\t\t\t\tDisc: 5.683179\t\tSym: 9.810044\t\tSpars: 10.796340\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530495 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 192 [4000/8000 (50%)]\tBatch Loss: 25.823252\tLearning Rate (w_theta): 0.001000\t TIME:773.5s\n",
      "\t\t\t\tDisc: 5.606344\t\tSym: 9.532428\t\tSpars: 10.684481\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530495 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 192...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1495116.0810961516\n",
      "Average validation loss: 1044915.8629220342\n",
      "Training epoch 193...\n",
      "\n",
      "Train Epoch: 193 [0/8000 (0%)]\tBatch Loss: 26.531182\tLearning Rate (w_theta): 0.001000\t TIME:775.8s\n",
      "\t\t\t\tDisc: 5.756530\t\tSym: 9.999856\t\tSpars: 10.774796\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530495 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 193 [4000/8000 (50%)]\tBatch Loss: 27.991745\tLearning Rate (w_theta): 0.001000\t TIME:777.5s\n",
      "\t\t\t\tDisc: 5.992863\t\tSym: 10.763814\t\tSpars: 11.235068\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530494 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 193...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1487369.5050349731\n",
      "Average validation loss: 1039501.9265676643\n",
      "Training epoch 194...\n",
      "\n",
      "Train Epoch: 194 [0/8000 (0%)]\tBatch Loss: 27.309191\tLearning Rate (w_theta): 0.001000\t TIME:780.0s\n",
      "\t\t\t\tDisc: 5.870747\t\tSym: 10.321926\t\tSpars: 11.116518\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530494 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 194 [4000/8000 (50%)]\tBatch Loss: 26.837377\tLearning Rate (w_theta): 0.001000\t TIME:781.7s\n",
      "\t\t\t\tDisc: 5.924332\t\tSym: 9.952975\t\tSpars: 10.960070\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530494 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 194...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1479702.7901586494\n",
      "Average validation loss: 1034143.803584044\n",
      "Training epoch 195...\n",
      "\n",
      "Train Epoch: 195 [0/8000 (0%)]\tBatch Loss: 26.018496\tLearning Rate (w_theta): 0.001000\t TIME:783.9s\n",
      "\t\t\t\tDisc: 5.637367\t\tSym: 9.635243\t\tSpars: 10.745886\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530494 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 195 [4000/8000 (50%)]\tBatch Loss: 26.658474\tLearning Rate (w_theta): 0.001000\t TIME:785.6s\n",
      "\t\t\t\tDisc: 5.793369\t\tSym: 10.067757\t\tSpars: 10.797348\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530493 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 195...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1472114.7078362885\n",
      "Average validation loss: 1028840.6352982589\n",
      "Training epoch 196...\n",
      "\n",
      "Train Epoch: 196 [0/8000 (0%)]\tBatch Loss: 25.196808\tLearning Rate (w_theta): 0.001000\t TIME:787.9s\n",
      "\t\t\t\tDisc: 5.399835\t\tSym: 9.183545\t\tSpars: 10.613428\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530493 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 196 [4000/8000 (50%)]\tBatch Loss: 27.637353\tLearning Rate (w_theta): 0.001000\t TIME:789.6s\n",
      "\t\t\t\tDisc: 5.976847\t\tSym: 10.497870\t\tSpars: 11.162636\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530493 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 196...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1464604.054505805\n",
      "Average validation loss: 1023591.580569346\n",
      "Training epoch 197...\n",
      "\n",
      "Train Epoch: 197 [0/8000 (0%)]\tBatch Loss: 26.673750\tLearning Rate (w_theta): 0.001000\t TIME:791.9s\n",
      "\t\t\t\tDisc: 5.809542\t\tSym: 9.907477\t\tSpars: 10.956730\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530493 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 197 [4000/8000 (50%)]\tBatch Loss: 26.853544\tLearning Rate (w_theta): 0.001000\t TIME:793.7s\n",
      "\t\t\t\tDisc: 5.835141\t\tSym: 10.043109\t\tSpars: 10.975294\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530493 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 197...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1457169.6510678022\n",
      "Average validation loss: 1018395.8153324065\n",
      "Training epoch 198...\n",
      "\n",
      "Train Epoch: 198 [0/8000 (0%)]\tBatch Loss: 26.841076\tLearning Rate (w_theta): 0.001000\t TIME:796.1s\n",
      "\t\t\t\tDisc: 5.723648\t\tSym: 10.106772\t\tSpars: 11.010655\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530492 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 198 [4000/8000 (50%)]\tBatch Loss: 25.291334\tLearning Rate (w_theta): 0.001000\t TIME:797.8s\n",
      "\t\t\t\tDisc: 5.271719\t\tSym: 9.398618\t\tSpars: 10.620996\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530492 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 198...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1449810.3421881625\n",
      "Average validation loss: 1013252.5321843629\n",
      "Training epoch 199...\n",
      "\n",
      "Train Epoch: 199 [0/8000 (0%)]\tBatch Loss: 24.886095\tLearning Rate (w_theta): 0.001000\t TIME:800.1s\n",
      "\t\t\t\tDisc: 5.128356\t\tSym: 9.163828\t\tSpars: 10.593911\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530492 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 199 [4000/8000 (50%)]\tBatch Loss: 26.480789\tLearning Rate (w_theta): 0.001000\t TIME:801.8s\n",
      "\t\t\t\tDisc: 5.592534\t\tSym: 9.899688\t\tSpars: 10.988567\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530492 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 199...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1442524.9958008407\n",
      "Average validation loss: 1008160.9399124043\n",
      "Training epoch 200...\n",
      "\n",
      "Train Epoch: 200 [0/8000 (0%)]\tBatch Loss: 25.995320\tLearning Rate (w_theta): 0.001000\t TIME:804.0s\n",
      "\t\t\t\tDisc: 5.516128\t\tSym: 9.691874\t\tSpars: 10.787318\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530491 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 200 [4000/8000 (50%)]\tBatch Loss: 27.218967\tLearning Rate (w_theta): 0.001000\t TIME:805.7s\n",
      "\t\t\t\tDisc: 5.902838\t\tSym: 10.214986\t\tSpars: 11.101143\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530491 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 200...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1435312.5024749583\n",
      "Average validation loss: 1003120.2631648487\n",
      "Training epoch 201...\n",
      "\n",
      "Train Epoch: 201 [0/8000 (0%)]\tBatch Loss: 24.748534\tLearning Rate (w_theta): 0.001000\t TIME:809.0s\n",
      "\t\t\t\tDisc: 5.168450\t\tSym: 8.980858\t\tSpars: 10.599226\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530491 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 201 [4000/8000 (50%)]\tBatch Loss: 26.166129\tLearning Rate (w_theta): 0.001000\t TIME:810.7s\n",
      "\t\t\t\tDisc: 5.584293\t\tSym: 9.771166\t\tSpars: 10.810670\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530491 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 201...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1428171.7748879415\n",
      "Average validation loss: 998129.7420111111\n",
      "Training epoch 202...\n",
      "\n",
      "Train Epoch: 202 [0/8000 (0%)]\tBatch Loss: 26.106753\tLearning Rate (w_theta): 0.001000\t TIME:813.0s\n",
      "\t\t\t\tDisc: 5.494735\t\tSym: 9.693831\t\tSpars: 10.918186\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530490 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 202 [4000/8000 (50%)]\tBatch Loss: 27.219213\tLearning Rate (w_theta): 0.001000\t TIME:814.7s\n",
      "\t\t\t\tDisc: 5.792776\t\tSym: 10.359433\t\tSpars: 11.067004\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530490 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 202...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1421101.7471443953\n",
      "Average validation loss: 993188.6315624057\n",
      "Training epoch 203...\n",
      "\n",
      "Train Epoch: 203 [0/8000 (0%)]\tBatch Loss: 25.549935\tLearning Rate (w_theta): 0.001000\t TIME:816.9s\n",
      "\t\t\t\tDisc: 5.326697\t\tSym: 9.546345\t\tSpars: 10.676893\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530490 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 203 [4000/8000 (50%)]\tBatch Loss: 27.071884\tLearning Rate (w_theta): 0.001000\t TIME:818.7s\n",
      "\t\t\t\tDisc: 5.754538\t\tSym: 10.249649\t\tSpars: 11.067697\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530490 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 203...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1414101.3744404407\n",
      "Average validation loss: 988296.2016166302\n",
      "Training epoch 204...\n",
      "\n",
      "Train Epoch: 204 [0/8000 (0%)]\tBatch Loss: 26.825484\tLearning Rate (w_theta): 0.001000\t TIME:820.9s\n",
      "\t\t\t\tDisc: 5.633609\t\tSym: 10.197556\t\tSpars: 10.994320\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530489 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 204 [4000/8000 (50%)]\tBatch Loss: 24.934468\tLearning Rate (w_theta): 0.001000\t TIME:822.7s\n",
      "\t\t\t\tDisc: 5.202609\t\tSym: 9.219297\t\tSpars: 10.512562\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530489 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 204...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1407169.6324513743\n",
      "Average validation loss: 983451.7362881866\n",
      "Training epoch 205...\n",
      "\n",
      "Train Epoch: 205 [0/8000 (0%)]\tBatch Loss: 26.945006\tLearning Rate (w_theta): 0.001000\t TIME:825.0s\n",
      "\t\t\t\tDisc: 5.649762\t\tSym: 10.299839\t\tSpars: 10.995405\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530489 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 205 [4000/8000 (50%)]\tBatch Loss: 25.043176\tLearning Rate (w_theta): 0.001000\t TIME:826.7s\n",
      "\t\t\t\tDisc: 5.229311\t\tSym: 9.210535\t\tSpars: 10.603330\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530489 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 205...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1400305.51682341\n",
      "Average validation loss: 978654.5336480807\n",
      "Training epoch 206...\n",
      "\n",
      "Train Epoch: 206 [0/8000 (0%)]\tBatch Loss: 26.591505\tLearning Rate (w_theta): 0.001000\t TIME:829.0s\n",
      "\t\t\t\tDisc: 5.757820\t\tSym: 9.888582\t\tSpars: 10.945103\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530488 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 206 [4000/8000 (50%)]\tBatch Loss: 25.344181\tLearning Rate (w_theta): 0.001000\t TIME:830.7s\n",
      "\t\t\t\tDisc: 5.252520\t\tSym: 9.413024\t\tSpars: 10.678637\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530488 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 206...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1393508.0427011452\n",
      "Average validation loss: 973903.9054155248\n",
      "Training epoch 207...\n",
      "\n",
      "Train Epoch: 207 [0/8000 (0%)]\tBatch Loss: 26.435340\tLearning Rate (w_theta): 0.001000\t TIME:832.9s\n",
      "\t\t\t\tDisc: 5.683418\t\tSym: 9.847780\t\tSpars: 10.904141\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530488 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 207 [4000/8000 (50%)]\tBatch Loss: 25.439705\tLearning Rate (w_theta): 0.001000\t TIME:834.7s\n",
      "\t\t\t\tDisc: 5.227715\t\tSym: 9.406548\t\tSpars: 10.805443\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530488 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 207...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1386776.2442736703\n",
      "Average validation loss: 969199.1766023583\n",
      "Training epoch 208...\n",
      "\n",
      "Train Epoch: 208 [0/8000 (0%)]\tBatch Loss: 25.811177\tLearning Rate (w_theta): 0.001000\t TIME:837.1s\n",
      "\t\t\t\tDisc: 5.391673\t\tSym: 9.614784\t\tSpars: 10.804719\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530488 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 208 [4000/8000 (50%)]\tBatch Loss: 25.365560\tLearning Rate (w_theta): 0.001000\t TIME:838.9s\n",
      "\t\t\t\tDisc: 5.213429\t\tSym: 9.484523\t\tSpars: 10.667608\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530487 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 208...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1380109.1743186086\n",
      "Average validation loss: 964539.6851957771\n",
      "Training epoch 209...\n",
      "\n",
      "Train Epoch: 209 [0/8000 (0%)]\tBatch Loss: 24.797791\tLearning Rate (w_theta): 0.001000\t TIME:841.2s\n",
      "\t\t\t\tDisc: 5.237461\t\tSym: 8.957342\t\tSpars: 10.602987\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530487 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 209 [4000/8000 (50%)]\tBatch Loss: 24.551237\tLearning Rate (w_theta): 0.001000\t TIME:842.9s\n",
      "\t\t\t\tDisc: 5.027905\t\tSym: 9.027025\t\tSpars: 10.496307\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530487 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 209...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1373505.9037023631\n",
      "Average validation loss: 959924.7818490255\n",
      "Training epoch 210...\n",
      "\n",
      "Train Epoch: 210 [0/8000 (0%)]\tBatch Loss: 25.753519\tLearning Rate (w_theta): 0.001000\t TIME:845.3s\n",
      "\t\t\t\tDisc: 5.348150\t\tSym: 9.647399\t\tSpars: 10.757971\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530487 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 210 [4000/8000 (50%)]\tBatch Loss: 26.583104\tLearning Rate (w_theta): 0.001000\t TIME:847.0s\n",
      "\t\t\t\tDisc: 5.521187\t\tSym: 10.105407\t\tSpars: 10.956510\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530486 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 210...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1366965.52098108\n",
      "Average validation loss: 955353.8296135754\n",
      "Training epoch 211...\n",
      "\n",
      "Train Epoch: 211 [0/8000 (0%)]\tBatch Loss: 24.601393\tLearning Rate (w_theta): 0.001000\t TIME:850.0s\n",
      "\t\t\t\tDisc: 5.158503\t\tSym: 9.037996\t\tSpars: 10.404894\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530486 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 211 [4000/8000 (50%)]\tBatch Loss: 25.299354\tLearning Rate (w_theta): 0.001000\t TIME:851.7s\n",
      "\t\t\t\tDisc: 5.315037\t\tSym: 9.385284\t\tSpars: 10.599032\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530486 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 211...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1360487.1320225298\n",
      "Average validation loss: 950826.2035582174\n",
      "Training epoch 212...\n",
      "\n",
      "Train Epoch: 212 [0/8000 (0%)]\tBatch Loss: 25.524051\tLearning Rate (w_theta): 0.001000\t TIME:854.0s\n",
      "\t\t\t\tDisc: 5.293155\t\tSym: 9.564840\t\tSpars: 10.666056\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530486 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 212 [4000/8000 (50%)]\tBatch Loss: 25.172046\tLearning Rate (w_theta): 0.001000\t TIME:855.7s\n",
      "\t\t\t\tDisc: 5.010490\t\tSym: 9.453606\t\tSpars: 10.707950\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530485 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 212...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1354069.8595784632\n",
      "Average validation loss: 946341.2905875222\n",
      "Training epoch 213...\n",
      "\n",
      "Train Epoch: 213 [0/8000 (0%)]\tBatch Loss: 25.185005\tLearning Rate (w_theta): 0.001000\t TIME:858.0s\n",
      "\t\t\t\tDisc: 5.129040\t\tSym: 9.354615\t\tSpars: 10.701349\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530485 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 213 [4000/8000 (50%)]\tBatch Loss: 25.059056\tLearning Rate (w_theta): 0.001000\t TIME:859.8s\n",
      "\t\t\t\tDisc: 5.147895\t\tSym: 9.322685\t\tSpars: 10.588476\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530485 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 213...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1347712.842839688\n",
      "Average validation loss: 941898.4891171026\n",
      "Training epoch 214...\n",
      "\n",
      "Train Epoch: 214 [0/8000 (0%)]\tBatch Loss: 25.793059\tLearning Rate (w_theta): 0.001000\t TIME:862.1s\n",
      "\t\t\t\tDisc: 5.336943\t\tSym: 9.681720\t\tSpars: 10.774396\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530485 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 214 [4000/8000 (50%)]\tBatch Loss: 25.179319\tLearning Rate (w_theta): 0.001000\t TIME:863.8s\n",
      "\t\t\t\tDisc: 5.184731\t\tSym: 9.327737\t\tSpars: 10.666851\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530484 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 214...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1341415.2371053705\n",
      "Average validation loss: 937497.2087986509\n",
      "Training epoch 215...\n",
      "\n",
      "Train Epoch: 215 [0/8000 (0%)]\tBatch Loss: 25.783668\tLearning Rate (w_theta): 0.001000\t TIME:866.0s\n",
      "\t\t\t\tDisc: 5.346672\t\tSym: 9.575000\t\tSpars: 10.861996\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530484 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 215 [4000/8000 (50%)]\tBatch Loss: 24.736831\tLearning Rate (w_theta): 0.001000\t TIME:867.8s\n",
      "\t\t\t\tDisc: 5.011132\t\tSym: 9.123000\t\tSpars: 10.602698\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530484 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 215...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1335176.2133852679\n",
      "Average validation loss: 933136.8702641183\n",
      "Training epoch 216...\n",
      "\n",
      "Train Epoch: 216 [0/8000 (0%)]\tBatch Loss: 24.680396\tLearning Rate (w_theta): 0.001000\t TIME:870.0s\n",
      "\t\t\t\tDisc: 5.031126\t\tSym: 9.185041\t\tSpars: 10.464229\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530484 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 216 [4000/8000 (50%)]\tBatch Loss: 24.315757\tLearning Rate (w_theta): 0.001000\t TIME:871.7s\n",
      "\t\t\t\tDisc: 5.057349\t\tSym: 8.822261\t\tSpars: 10.436147\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530483 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 216...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1328994.9580329973\n",
      "Average validation loss: 928816.9048802598\n",
      "Training epoch 217...\n",
      "\n",
      "Train Epoch: 217 [0/8000 (0%)]\tBatch Loss: 26.926069\tLearning Rate (w_theta): 0.001000\t TIME:874.1s\n",
      "\t\t\t\tDisc: 5.635931\t\tSym: 10.312401\t\tSpars: 10.977737\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530483 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 217 [4000/8000 (50%)]\tBatch Loss: 24.162051\tLearning Rate (w_theta): 0.001000\t TIME:875.8s\n",
      "\t\t\t\tDisc: 4.989346\t\tSym: 8.743646\t\tSpars: 10.429060\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530483 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 217...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1322870.6724463408\n",
      "Average validation loss: 924536.7544911219\n",
      "Training epoch 218...\n",
      "\n",
      "Train Epoch: 218 [0/8000 (0%)]\tBatch Loss: 25.555800\tLearning Rate (w_theta): 0.001000\t TIME:878.1s\n",
      "\t\t\t\tDisc: 5.140534\t\tSym: 9.516402\t\tSpars: 10.898864\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530483 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 218 [4000/8000 (50%)]\tBatch Loss: 24.612743\tLearning Rate (w_theta): 0.001000\t TIME:879.9s\n",
      "\t\t\t\tDisc: 4.975373\t\tSym: 9.137718\t\tSpars: 10.499652\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530483 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 218...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1316802.5725860803\n",
      "Average validation loss: 920295.871205664\n",
      "Training epoch 219...\n",
      "\n",
      "Train Epoch: 219 [0/8000 (0%)]\tBatch Loss: 24.090955\tLearning Rate (w_theta): 0.001000\t TIME:882.2s\n",
      "\t\t\t\tDisc: 4.716587\t\tSym: 8.872934\t\tSpars: 10.501433\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530482 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 219 [4000/8000 (50%)]\tBatch Loss: 24.140925\tLearning Rate (w_theta): 0.001000\t TIME:884.0s\n",
      "\t\t\t\tDisc: 4.819396\t\tSym: 8.917223\t\tSpars: 10.404306\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530482 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 219...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1310789.8888202691\n",
      "Average validation loss: 916093.7171012717\n",
      "Training epoch 220...\n",
      "\n",
      "Train Epoch: 220 [0/8000 (0%)]\tBatch Loss: 23.805678\tLearning Rate (w_theta): 0.001000\t TIME:886.3s\n",
      "\t\t\t\tDisc: 4.776087\t\tSym: 8.716728\t\tSpars: 10.312862\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530482 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 220 [4000/8000 (50%)]\tBatch Loss: 25.303450\tLearning Rate (w_theta): 0.001000\t TIME:888.0s\n",
      "\t\t\t\tDisc: 5.144084\t\tSym: 9.410159\t\tSpars: 10.749207\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530482 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 220...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1304831.8654522607\n",
      "Average validation loss: 911929.7640479364\n",
      "Training epoch 221...\n",
      "\n",
      "Train Epoch: 221 [0/8000 (0%)]\tBatch Loss: 24.709982\tLearning Rate (w_theta): 0.001000\t TIME:890.9s\n",
      "\t\t\t\tDisc: 4.917144\t\tSym: 9.208228\t\tSpars: 10.584610\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530481 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 221 [4000/8000 (50%)]\tBatch Loss: 25.140060\tLearning Rate (w_theta): 0.001000\t TIME:892.7s\n",
      "\t\t\t\tDisc: 5.066875\t\tSym: 9.465298\t\tSpars: 10.607887\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530481 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 221...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1298927.7604956946\n",
      "Average validation loss: 907803.4934946191\n",
      "Training epoch 222...\n",
      "\n",
      "Train Epoch: 222 [0/8000 (0%)]\tBatch Loss: 25.508408\tLearning Rate (w_theta): 0.001000\t TIME:895.0s\n",
      "\t\t\t\tDisc: 5.195415\t\tSym: 9.588036\t\tSpars: 10.724957\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530481 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 222 [4000/8000 (50%)]\tBatch Loss: 23.107491\tLearning Rate (w_theta): 0.001000\t TIME:896.7s\n",
      "\t\t\t\tDisc: 4.670630\t\tSym: 8.283913\t\tSpars: 10.152948\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530481 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 222...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1293076.8453590132\n",
      "Average validation loss: 903714.3962148427\n",
      "Training epoch 223...\n",
      "\n",
      "Train Epoch: 223 [0/8000 (0%)]\tBatch Loss: 24.497347\tLearning Rate (w_theta): 0.001000\t TIME:899.1s\n",
      "\t\t\t\tDisc: 4.960229\t\tSym: 8.970510\t\tSpars: 10.566608\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530480 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 223 [4000/8000 (50%)]\tBatch Loss: 24.205210\tLearning Rate (w_theta): 0.001000\t TIME:900.8s\n",
      "\t\t\t\tDisc: 4.777499\t\tSym: 8.910655\t\tSpars: 10.517056\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530480 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 223...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1287278.4044273968\n",
      "Average validation loss: 899661.9721264174\n",
      "Training epoch 224...\n",
      "\n",
      "Train Epoch: 224 [0/8000 (0%)]\tBatch Loss: 24.545885\tLearning Rate (w_theta): 0.001000\t TIME:903.1s\n",
      "\t\t\t\tDisc: 4.963294\t\tSym: 9.072692\t\tSpars: 10.509899\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530480 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 224 [4000/8000 (50%)]\tBatch Loss: 24.743993\tLearning Rate (w_theta): 0.001000\t TIME:904.8s\n",
      "\t\t\t\tDisc: 4.882578\t\tSym: 9.249915\t\tSpars: 10.611500\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530480 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 224...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1281531.7349391752\n",
      "Average validation loss: 895645.7300731499\n",
      "Training epoch 225...\n",
      "\n",
      "Train Epoch: 225 [0/8000 (0%)]\tBatch Loss: 24.455422\tLearning Rate (w_theta): 0.001000\t TIME:907.0s\n",
      "\t\t\t\tDisc: 4.917020\t\tSym: 9.025797\t\tSpars: 10.512606\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530479 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 225 [4000/8000 (50%)]\tBatch Loss: 25.009071\tLearning Rate (w_theta): 0.001000\t TIME:908.7s\n",
      "\t\t\t\tDisc: 5.001471\t\tSym: 9.342708\t\tSpars: 10.664892\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530479 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 225...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1275836.146637672\n",
      "Average validation loss: 891665.1876161335\n",
      "Training epoch 226...\n",
      "\n",
      "Train Epoch: 226 [0/8000 (0%)]\tBatch Loss: 23.885516\tLearning Rate (w_theta): 0.001000\t TIME:911.1s\n",
      "\t\t\t\tDisc: 4.607351\t\tSym: 8.789828\t\tSpars: 10.488338\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530479 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 226 [4000/8000 (50%)]\tBatch Loss: 23.723103\tLearning Rate (w_theta): 0.001000\t TIME:912.9s\n",
      "\t\t\t\tDisc: 4.635989\t\tSym: 8.741798\t\tSpars: 10.345316\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530479 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "Validating epoch 226...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1270190.961409354\n",
      "Average validation loss: 887719.8708791037\n",
      "Training epoch 227...\n",
      "\n",
      "Train Epoch: 227 [0/8000 (0%)]\tBatch Loss: 24.346226\tLearning Rate (w_theta): 0.001000\t TIME:915.3s\n",
      "\t\t\t\tDisc: 4.873531\t\tSym: 9.013667\t\tSpars: 10.459027\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530478 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026646\n",
      "\n",
      "Train Epoch: 227 [4000/8000 (50%)]\tBatch Loss: 25.185459\tLearning Rate (w_theta): 0.001000\t TIME:917.0s\n",
      "\t\t\t\tDisc: 5.057226\t\tSym: 9.423908\t\tSpars: 10.704325\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530478 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 227...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1264595.5131780286\n",
      "Average validation loss: 883809.3143218654\n",
      "Training epoch 228...\n",
      "\n",
      "Train Epoch: 228 [0/8000 (0%)]\tBatch Loss: 23.922594\tLearning Rate (w_theta): 0.001000\t TIME:919.3s\n",
      "\t\t\t\tDisc: 4.718776\t\tSym: 8.789536\t\tSpars: 10.414282\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530478 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 228 [4000/8000 (50%)]\tBatch Loss: 23.788509\tLearning Rate (w_theta): 0.001000\t TIME:921.1s\n",
      "\t\t\t\tDisc: 4.710140\t\tSym: 8.797696\t\tSpars: 10.280673\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530478 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 228...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1259049.1475010985\n",
      "Average validation loss: 879933.0605831676\n",
      "Training epoch 229...\n",
      "\n",
      "Train Epoch: 229 [0/8000 (0%)]\tBatch Loss: 23.303691\tLearning Rate (w_theta): 0.001000\t TIME:923.3s\n",
      "\t\t\t\tDisc: 4.610953\t\tSym: 8.528106\t\tSpars: 10.164632\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530478 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 229 [4000/8000 (50%)]\tBatch Loss: 24.321652\tLearning Rate (w_theta): 0.001000\t TIME:925.1s\n",
      "\t\t\t\tDisc: 4.797058\t\tSym: 8.953175\t\tSpars: 10.571419\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530477 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 229...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1253551.2213531306\n",
      "Average validation loss: 876090.6602684365\n",
      "Training epoch 230...\n",
      "\n",
      "Train Epoch: 230 [0/8000 (0%)]\tBatch Loss: 23.264581\tLearning Rate (w_theta): 0.001000\t TIME:927.5s\n",
      "\t\t\t\tDisc: 4.578300\t\tSym: 8.400051\t\tSpars: 10.286230\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530477 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 230 [4000/8000 (50%)]\tBatch Loss: 23.558054\tLearning Rate (w_theta): 0.001000\t TIME:929.2s\n",
      "\t\t\t\tDisc: 4.716395\t\tSym: 8.570336\t\tSpars: 10.271323\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530477 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 230...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1248101.1029346206\n",
      "Average validation loss: 872281.6718186683\n",
      "Training epoch 231...\n",
      "\n",
      "Train Epoch: 231 [0/8000 (0%)]\tBatch Loss: 23.566640\tLearning Rate (w_theta): 0.001000\t TIME:932.2s\n",
      "\t\t\t\tDisc: 4.575076\t\tSym: 8.727259\t\tSpars: 10.264306\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530477 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 231 [4000/8000 (50%)]\tBatch Loss: 25.515976\tLearning Rate (w_theta): 0.001000\t TIME:933.9s\n",
      "\t\t\t\tDisc: 5.056147\t\tSym: 9.792172\t\tSpars: 10.667656\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530476 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 231...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1242698.1713637481\n",
      "Average validation loss: 868505.6613166708\n",
      "Training epoch 232...\n",
      "\n",
      "Train Epoch: 232 [0/8000 (0%)]\tBatch Loss: 24.819770\tLearning Rate (w_theta): 0.001000\t TIME:936.2s\n",
      "\t\t\t\tDisc: 4.955978\t\tSym: 9.288411\t\tSpars: 10.575380\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530476 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 232 [4000/8000 (50%)]\tBatch Loss: 24.210002\tLearning Rate (w_theta): 0.001000\t TIME:937.9s\n",
      "\t\t\t\tDisc: 4.800949\t\tSym: 8.868438\t\tSpars: 10.540615\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530476 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 232...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1237341.816480983\n",
      "Average validation loss: 864762.2023246235\n",
      "Training epoch 233...\n",
      "\n",
      "Train Epoch: 233 [0/8000 (0%)]\tBatch Loss: 23.982659\tLearning Rate (w_theta): 0.001000\t TIME:940.2s\n",
      "\t\t\t\tDisc: 4.729022\t\tSym: 8.832253\t\tSpars: 10.421384\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530476 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 233 [4000/8000 (50%)]\tBatch Loss: 24.909108\tLearning Rate (w_theta): 0.001000\t TIME:941.9s\n",
      "\t\t\t\tDisc: 4.873942\t\tSym: 9.444524\t\tSpars: 10.590643\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530475 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 233...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1232031.438579325\n",
      "Average validation loss: 861050.8757344121\n",
      "Training epoch 234...\n",
      "\n",
      "Train Epoch: 234 [0/8000 (0%)]\tBatch Loss: 23.324497\tLearning Rate (w_theta): 0.001000\t TIME:944.1s\n",
      "\t\t\t\tDisc: 4.422488\t\tSym: 8.558871\t\tSpars: 10.343138\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530475 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 234 [4000/8000 (50%)]\tBatch Loss: 23.936634\tLearning Rate (w_theta): 0.001000\t TIME:945.8s\n",
      "\t\t\t\tDisc: 4.638189\t\tSym: 8.957690\t\tSpars: 10.340755\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530475 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 234...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1226766.4481937399\n",
      "Average validation loss: 857371.2695840672\n",
      "Training epoch 235...\n",
      "\n",
      "Train Epoch: 235 [0/8000 (0%)]\tBatch Loss: 22.497627\tLearning Rate (w_theta): 0.001000\t TIME:948.3s\n",
      "\t\t\t\tDisc: 4.313413\t\tSym: 8.074127\t\tSpars: 10.110086\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530475 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 235 [4000/8000 (50%)]\tBatch Loss: 23.395680\tLearning Rate (w_theta): 0.001000\t TIME:950.0s\n",
      "\t\t\t\tDisc: 4.615740\t\tSym: 8.561025\t\tSpars: 10.218915\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530474 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 235...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1221546.2659338184\n",
      "Average validation loss: 853722.9789298725\n",
      "Training epoch 236...\n",
      "\n",
      "Train Epoch: 236 [0/8000 (0%)]\tBatch Loss: 22.904627\tLearning Rate (w_theta): 0.001000\t TIME:952.3s\n",
      "\t\t\t\tDisc: 4.474184\t\tSym: 8.351364\t\tSpars: 10.079079\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530474 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 236 [4000/8000 (50%)]\tBatch Loss: 24.649409\tLearning Rate (w_theta): 0.001000\t TIME:954.0s\n",
      "\t\t\t\tDisc: 4.762547\t\tSym: 9.215566\t\tSpars: 10.671297\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530474 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 236...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1216370.322199773\n",
      "Average validation loss: 850105.605701545\n",
      "Training epoch 237...\n",
      "\n",
      "Train Epoch: 237 [0/8000 (0%)]\tBatch Loss: 22.500069\tLearning Rate (w_theta): 0.001000\t TIME:956.2s\n",
      "\t\t\t\tDisc: 4.222917\t\tSym: 8.068940\t\tSpars: 10.208212\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530474 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 237 [4000/8000 (50%)]\tBatch Loss: 23.137404\tLearning Rate (w_theta): 0.001000\t TIME:957.9s\n",
      "\t\t\t\tDisc: 4.476018\t\tSym: 8.418714\t\tSpars: 10.242673\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530473 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 237...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1211238.0570056438\n",
      "Average validation loss: 846518.7585400963\n",
      "Training epoch 238...\n",
      "\n",
      "Train Epoch: 238 [0/8000 (0%)]\tBatch Loss: 24.158103\tLearning Rate (w_theta): 0.001000\t TIME:960.3s\n",
      "\t\t\t\tDisc: 4.733623\t\tSym: 8.950995\t\tSpars: 10.473485\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530473 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 238 [4000/8000 (50%)]\tBatch Loss: 24.051603\tLearning Rate (w_theta): 0.001000\t TIME:962.0s\n",
      "\t\t\t\tDisc: 4.687060\t\tSym: 8.938194\t\tSpars: 10.426349\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530473 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 238...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1206148.9198016382\n",
      "Average validation loss: 842962.0526627767\n",
      "Training epoch 239...\n",
      "\n",
      "Train Epoch: 239 [0/8000 (0%)]\tBatch Loss: 23.365915\tLearning Rate (w_theta): 0.001000\t TIME:964.4s\n",
      "\t\t\t\tDisc: 4.523825\t\tSym: 8.544924\t\tSpars: 10.297167\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530473 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 239 [4000/8000 (50%)]\tBatch Loss: 22.980549\tLearning Rate (w_theta): 0.001000\t TIME:966.1s\n",
      "\t\t\t\tDisc: 4.297412\t\tSym: 8.474550\t\tSpars: 10.208587\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530473 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 239...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1201102.369213042\n",
      "Average validation loss: 839435.1097322284\n",
      "Training epoch 240...\n",
      "\n",
      "Train Epoch: 240 [0/8000 (0%)]\tBatch Loss: 22.396909\tLearning Rate (w_theta): 0.001000\t TIME:968.5s\n",
      "\t\t\t\tDisc: 4.217486\t\tSym: 8.074327\t\tSpars: 10.105096\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530472 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 240 [4000/8000 (50%)]\tBatch Loss: 24.403765\tLearning Rate (w_theta): 0.001000\t TIME:970.2s\n",
      "\t\t\t\tDisc: 4.690709\t\tSym: 9.140767\t\tSpars: 10.572289\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530472 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 240...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1196097.8729167944\n",
      "Average validation loss: 835937.557707762\n",
      "Training epoch 241...\n",
      "\n",
      "Train Epoch: 241 [0/8000 (0%)]\tBatch Loss: 22.109038\tLearning Rate (w_theta): 0.001000\t TIME:973.5s\n",
      "\t\t\t\tDisc: 4.221756\t\tSym: 7.892227\t\tSpars: 9.995054\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530472 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 241 [4000/8000 (50%)]\tBatch Loss: 23.164244\tLearning Rate (w_theta): 0.001000\t TIME:975.2s\n",
      "\t\t\t\tDisc: 4.306032\t\tSym: 8.560181\t\tSpars: 10.298031\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530472 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 241...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1191134.9074137907\n",
      "Average validation loss: 832469.030727018\n",
      "Training epoch 242...\n",
      "\n",
      "Train Epoch: 242 [0/8000 (0%)]\tBatch Loss: 22.444351\tLearning Rate (w_theta): 0.001000\t TIME:977.4s\n",
      "\t\t\t\tDisc: 4.234138\t\tSym: 8.138957\t\tSpars: 10.071256\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530471 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 242 [4000/8000 (50%)]\tBatch Loss: 24.378043\tLearning Rate (w_theta): 0.001000\t TIME:979.1s\n",
      "\t\t\t\tDisc: 4.728264\t\tSym: 9.166617\t\tSpars: 10.483162\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530471 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 242...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1186212.9578646515\n",
      "Average validation loss: 829029.1689758749\n",
      "Training epoch 243...\n",
      "\n",
      "Train Epoch: 243 [0/8000 (0%)]\tBatch Loss: 22.981395\tLearning Rate (w_theta): 0.001000\t TIME:981.3s\n",
      "\t\t\t\tDisc: 4.459465\t\tSym: 8.394979\t\tSpars: 10.126951\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530471 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 243 [4000/8000 (50%)]\tBatch Loss: 23.094354\tLearning Rate (w_theta): 0.001000\t TIME:983.1s\n",
      "\t\t\t\tDisc: 4.386586\t\tSym: 8.460181\t\tSpars: 10.247586\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530471 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 243...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1181331.5179004003\n",
      "Average validation loss: 825617.6185639788\n",
      "Training epoch 244...\n",
      "\n",
      "Train Epoch: 244 [0/8000 (0%)]\tBatch Loss: 23.302651\tLearning Rate (w_theta): 0.001000\t TIME:985.5s\n",
      "\t\t\t\tDisc: 4.337332\t\tSym: 8.640864\t\tSpars: 10.324455\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530470 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 244 [4000/8000 (50%)]\tBatch Loss: 23.590812\tLearning Rate (w_theta): 0.001000\t TIME:987.2s\n",
      "\t\t\t\tDisc: 4.444118\t\tSym: 8.696978\t\tSpars: 10.449717\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530470 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 244...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1176490.0894410838\n",
      "Average validation loss: 822234.031407766\n",
      "Training epoch 245...\n",
      "\n",
      "Train Epoch: 245 [0/8000 (0%)]\tBatch Loss: 23.167884\tLearning Rate (w_theta): 0.001000\t TIME:989.5s\n",
      "\t\t\t\tDisc: 4.353515\t\tSym: 8.579511\t\tSpars: 10.234859\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530470 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 245 [4000/8000 (50%)]\tBatch Loss: 23.140996\tLearning Rate (w_theta): 0.001000\t TIME:991.3s\n",
      "\t\t\t\tDisc: 4.441396\t\tSym: 8.497040\t\tSpars: 10.202560\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530470 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 245...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1171688.1825673543\n",
      "Average validation loss: 818878.0650905812\n",
      "Training epoch 246...\n",
      "\n",
      "Train Epoch: 246 [0/8000 (0%)]\tBatch Loss: 22.780702\tLearning Rate (w_theta): 0.001000\t TIME:993.5s\n",
      "\t\t\t\tDisc: 4.345569\t\tSym: 8.277403\t\tSpars: 10.157730\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530469 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 246 [4000/8000 (50%)]\tBatch Loss: 23.267739\tLearning Rate (w_theta): 0.001000\t TIME:995.2s\n",
      "\t\t\t\tDisc: 4.346206\t\tSym: 8.591308\t\tSpars: 10.330225\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530469 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 246...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1166925.3152919982\n",
      "Average validation loss: 815549.3827776166\n",
      "Training epoch 247...\n",
      "\n",
      "Train Epoch: 247 [0/8000 (0%)]\tBatch Loss: 22.148350\tLearning Rate (w_theta): 0.001000\t TIME:997.7s\n",
      "\t\t\t\tDisc: 4.091970\t\tSym: 8.002376\t\tSpars: 10.054004\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530469 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 247 [4000/8000 (50%)]\tBatch Loss: 23.646347\tLearning Rate (w_theta): 0.001000\t TIME:999.4s\n",
      "\t\t\t\tDisc: 4.511595\t\tSym: 8.780179\t\tSpars: 10.354573\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530469 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 247...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1162201.013469964\n",
      "Average validation loss: 812247.6530885573\n",
      "Training epoch 248...\n",
      "\n",
      "Train Epoch: 248 [0/8000 (0%)]\tBatch Loss: 22.141382\tLearning Rate (w_theta): 0.001000\t TIME:1001.7s\n",
      "\t\t\t\tDisc: 4.122040\t\tSym: 8.041299\t\tSpars: 9.978043\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530468 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 248 [4000/8000 (50%)]\tBatch Loss: 23.199801\tLearning Rate (w_theta): 0.001000\t TIME:1003.4s\n",
      "\t\t\t\tDisc: 4.461108\t\tSym: 8.478775\t\tSpars: 10.259918\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530468 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 248...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1157514.8105713092\n",
      "Average validation loss: 808972.5499893943\n",
      "Training epoch 249...\n",
      "\n",
      "Train Epoch: 249 [0/8000 (0%)]\tBatch Loss: 23.224060\tLearning Rate (w_theta): 0.001000\t TIME:1005.6s\n",
      "\t\t\t\tDisc: 4.336748\t\tSym: 8.575294\t\tSpars: 10.312017\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530468 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 249 [4000/8000 (50%)]\tBatch Loss: 22.138484\tLearning Rate (w_theta): 0.001000\t TIME:1007.3s\n",
      "\t\t\t\tDisc: 4.113197\t\tSym: 8.001582\t\tSpars: 10.023705\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530468 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 249...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1152866.2475728802\n",
      "Average validation loss: 805723.7526690519\n",
      "Training epoch 250...\n",
      "\n",
      "Train Epoch: 250 [0/8000 (0%)]\tBatch Loss: 22.245263\tLearning Rate (w_theta): 0.001000\t TIME:1009.6s\n",
      "\t\t\t\tDisc: 4.114116\t\tSym: 8.007518\t\tSpars: 10.123629\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530468 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 250 [4000/8000 (50%)]\tBatch Loss: 23.267884\tLearning Rate (w_theta): 0.001000\t TIME:1011.4s\n",
      "\t\t\t\tDisc: 4.432320\t\tSym: 8.608675\t\tSpars: 10.226889\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530467 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 250...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1148254.8728078248\n",
      "Average validation loss: 802500.9454588983\n",
      "Training epoch 251...\n",
      "\n",
      "Train Epoch: 251 [0/8000 (0%)]\tBatch Loss: 22.341489\tLearning Rate (w_theta): 0.001000\t TIME:1014.5s\n",
      "\t\t\t\tDisc: 4.167602\t\tSym: 8.081697\t\tSpars: 10.092190\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530467 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 251 [4000/8000 (50%)]\tBatch Loss: 22.608816\tLearning Rate (w_theta): 0.001000\t TIME:1016.3s\n",
      "\t\t\t\tDisc: 4.190736\t\tSym: 8.260142\t\tSpars: 10.157938\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530467 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 251...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1143680.2417911228\n",
      "Average validation loss: 799303.817733105\n",
      "Training epoch 252...\n",
      "\n",
      "Train Epoch: 252 [0/8000 (0%)]\tBatch Loss: 22.356169\tLearning Rate (w_theta): 0.001000\t TIME:1018.5s\n",
      "\t\t\t\tDisc: 4.119432\t\tSym: 8.107089\t\tSpars: 10.129648\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530467 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 252 [4000/8000 (50%)]\tBatch Loss: 21.690522\tLearning Rate (w_theta): 0.001000\t TIME:1020.3s\n",
      "\t\t\t\tDisc: 4.014706\t\tSym: 7.822052\t\tSpars: 9.853764\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530466 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 252...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1139141.9170856397\n",
      "Average validation loss: 796132.0637706326\n",
      "Training epoch 253...\n",
      "\n",
      "Train Epoch: 253 [0/8000 (0%)]\tBatch Loss: 22.735307\tLearning Rate (w_theta): 0.001000\t TIME:1022.5s\n",
      "\t\t\t\tDisc: 4.164308\t\tSym: 8.319293\t\tSpars: 10.251705\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530466 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 253 [4000/8000 (50%)]\tBatch Loss: 22.070879\tLearning Rate (w_theta): 0.001000\t TIME:1024.3s\n",
      "\t\t\t\tDisc: 4.031958\t\tSym: 8.008183\t\tSpars: 10.030739\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530466 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 253...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1134639.468214503\n",
      "Average validation loss: 792985.3827110897\n",
      "Training epoch 254...\n",
      "\n",
      "Train Epoch: 254 [0/8000 (0%)]\tBatch Loss: 22.393963\tLearning Rate (w_theta): 0.001000\t TIME:1026.6s\n",
      "\t\t\t\tDisc: 4.079351\t\tSym: 8.215014\t\tSpars: 10.099597\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530466 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 254 [4000/8000 (50%)]\tBatch Loss: 22.201054\tLearning Rate (w_theta): 0.001000\t TIME:1028.4s\n",
      "\t\t\t\tDisc: 4.194104\t\tSym: 7.971056\t\tSpars: 10.035894\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530465 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 254...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1130172.4714176923\n",
      "Average validation loss: 789863.4784076234\n",
      "Training epoch 255...\n",
      "\n",
      "Train Epoch: 255 [0/8000 (0%)]\tBatch Loss: 22.128816\tLearning Rate (w_theta): 0.001000\t TIME:1030.8s\n",
      "\t\t\t\tDisc: 4.110382\t\tSym: 7.992674\t\tSpars: 10.025759\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530465 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 255 [4000/8000 (50%)]\tBatch Loss: 21.941940\tLearning Rate (w_theta): 0.001000\t TIME:1032.5s\n",
      "\t\t\t\tDisc: 4.056339\t\tSym: 7.941722\t\tSpars: 9.943878\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530465 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 255...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1125740.5096191654\n",
      "Average validation loss: 786766.059370525\n",
      "Training epoch 256...\n",
      "\n",
      "Train Epoch: 256 [0/8000 (0%)]\tBatch Loss: 22.009623\tLearning Rate (w_theta): 0.001000\t TIME:1034.8s\n",
      "\t\t\t\tDisc: 3.944226\t\tSym: 8.051065\t\tSpars: 10.014332\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530465 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 256 [4000/8000 (50%)]\tBatch Loss: 22.376924\tLearning Rate (w_theta): 0.001000\t TIME:1036.5s\n",
      "\t\t\t\tDisc: 4.118349\t\tSym: 8.216684\t\tSpars: 10.041890\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530464 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 256...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1121343.1722611445\n",
      "Average validation loss: 783692.8386666598\n",
      "Training epoch 257...\n",
      "\n",
      "Train Epoch: 257 [0/8000 (0%)]\tBatch Loss: 22.581878\tLearning Rate (w_theta): 0.001000\t TIME:1038.9s\n",
      "\t\t\t\tDisc: 4.143699\t\tSym: 8.273112\t\tSpars: 10.165067\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530464 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 257 [4000/8000 (50%)]\tBatch Loss: 21.098936\tLearning Rate (w_theta): 0.001000\t TIME:1040.6s\n",
      "\t\t\t\tDisc: 3.813898\t\tSym: 7.590618\t\tSpars: 9.694420\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530464 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 257...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1116980.0551723035\n",
      "Average validation loss: 780643.533827803\n",
      "Training epoch 258...\n",
      "\n",
      "Train Epoch: 258 [0/8000 (0%)]\tBatch Loss: 22.052268\tLearning Rate (w_theta): 0.001000\t TIME:1042.9s\n",
      "\t\t\t\tDisc: 4.068078\t\tSym: 8.052299\t\tSpars: 9.931891\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530464 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "\n",
      "Train Epoch: 258 [4000/8000 (50%)]\tBatch Loss: 21.862891\tLearning Rate (w_theta): 0.001000\t TIME:1044.6s\n",
      "\t\t\t\tDisc: 3.972877\t\tSym: 7.910405\t\tSpars: 9.979609\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530463 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n",
      "Validating epoch 258...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1112650.760440305\n",
      "Average validation loss: 777617.8667752775\n",
      "Training epoch 259...\n",
      "\n",
      "Train Epoch: 259 [0/8000 (0%)]\tBatch Loss: 21.766099\tLearning Rate (w_theta): 0.001000\t TIME:1047.0s\n",
      "\t\t\t\tDisc: 4.042749\t\tSym: 7.843737\t\tSpars: 9.879613\t\tPred Spars: 0.000000\n",
      "\t TVw: -0.530463 | TVb: -2.027457 | GSw: -0.226717 | GSb: 0.073338 | TSUw: 0.473236 | TSUb: 0.026647\n"
     ]
    }
   ],
   "source": [
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504e485-5480-4fae-a0e1-4382092f3fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a993b5-8bff-4192-8e0a-389d302c2c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2186b40-3acc-4d32-9620-ae8dac4a8731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ecgenv)",
   "language": "python",
   "name": "ecgenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
