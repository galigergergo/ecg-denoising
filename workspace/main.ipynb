{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7baaefd-888e-4894-9776-d7291899f1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.fistanet.M5FISTANet import FISTANet\n",
    "from src.fistanet.loader import DataSplit\n",
    "from src.fistanet.solver import Solver\n",
    "from os.path import join as pjoin\n",
    "from torchsummary import summary\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9846d1b1-46fe-471c-b4a9-93e7a8ce0ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data'\n",
    "DATA_FILE_GEN = 'generated/BW_master_10000_2024-04-07-12-43-32.pkl'\n",
    "DATA_FILE_SIGS = 'steinbrinker/testing_data_mvg_avg.npy'\n",
    "DATA_FILE_BW = 'mit-bih/bw'\n",
    "DATA_FILE_GAUSS = 'generated/gaussian_noise.npy'\n",
    "# DATA_FILE_BPDN = 'generated/BW_alphas-BPDN_10000_2024-04-07-12-43-32.npy'\n",
    "DATA_FILE_BPDN = 'generated/BW_alphas-BPDN-1iters_10000_2024-04-07-12-43-32.npy'\n",
    "DICT_FILE_BW = 'steinbrinker/dictionary_BW_real_data.npy'\n",
    "NOISE_TYPE = 'bw'\n",
    "if NOISE_TYPE == 'bw':\n",
    "    DATA_FILE_NOISE = DATA_FILE_BW\n",
    "elif NOISE_TYPE == 'gauss':\n",
    "    DATA_FILE_NOISE = DATA_FILE_GAUSS\n",
    "DATA_SIZE = 10000\n",
    "BATCH_SIZE = 1000\n",
    "TVT_SPLIT = {\n",
    "    'train': 80,\n",
    "    'valid': 10,\n",
    "    'test': 10\n",
    "}\n",
    "\n",
    "FNET_LAYER_NO = 4\n",
    "FNET_FEATURE_NO = 16\n",
    "LAMBDA_SP_LOSS = 1\n",
    "LAMBDA_SYM_LOSS = 1e-1\n",
    "\n",
    "EPOCH_NO = 2500\n",
    "TEST_EPOCH = 10001\n",
    "LR_DEC_AFTER = 10000\n",
    "LR_DEC_EVERY = 10\n",
    "START_EPOCH = 2000\n",
    "START_RUN = '2024-04-23-20-09-05'\n",
    "LOG_INTERVAL = 4\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "\n",
    "\n",
    "# DATA_FILE_GEN = 'generated/BW_master_7999-8000_2024-04-07-12-43-32.pkl'\n",
    "# DATA_SIZE = 2\n",
    "# BATCH_SIZE = 1\n",
    "# TVT_SPLIT = {\n",
    "#     'train': 50,\n",
    "#     'valid': 50,\n",
    "#     'test': 0\n",
    "# }\n",
    "# FNET_LAYER_NO = 4\n",
    "# FNET_FEATURE_NO = 16\n",
    "# LEARNING_RATE = 1e-3\n",
    "# LAMBDA_SP_LOSS = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74e188c4-1bdd-43bd-8fad-aa3c615aefbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ldr, val_ldr, tst_ldr = DataSplit(DATA_DIR, NOISE_TYPE, DATA_FILE_GEN, DATA_FILE_SIGS, DATA_FILE_NOISE, DATA_FILE_BPDN, TVT_SPLIT, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45bcd124-d0c4-4140-8607-2ed4ff8a8003",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36276fd7-c4b4-49e2-859c-6d09d87aae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Psi = np.load(pjoin(DATA_DIR, DICT_FILE_BW))\n",
    "Psi = torch.from_numpy(Psi)\n",
    "Psi = Psi.clone().detach().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03f7f9ea-e218-4790-84e8-caf0a10489d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fista_net = FISTANet(FNET_LAYER_NO, FNET_FEATURE_NO)\n",
    "fista_net = fista_net.to(device)# define arguments of fista_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f12c4823-35ea-41b9-97a1-bf6746dc204d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters fista net: 18871\n"
     ]
    }
   ],
   "source": [
    "# summary(fista_net, input_size=(1, 64, 298), device=str(device))\n",
    "print('Total number of parameters fista net:',\n",
    "          sum(p.numel() for p in fista_net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3579c675-faba-4918-bffe-7a3ee0c8afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "if START_EPOCH:\n",
    "    dt = START_RUN\n",
    "args = {\n",
    "    'model_name': 'FISTANet',\n",
    "    'num_epochs': EPOCH_NO,\n",
    "    'lr': LEARNING_RATE,\n",
    "    'data_dir': DATA_DIR,\n",
    "    'save_path': f'./runs/{dt}',\n",
    "    'start_epoch': START_EPOCH,\n",
    "    'start_run': START_RUN,\n",
    "    'multi_gpu': False,\n",
    "    'device': device,\n",
    "    'log_interval': LOG_INTERVAL,\n",
    "    'test_epoch': TEST_EPOCH,\n",
    "    'lr_dec_after': LR_DEC_AFTER,\n",
    "    'lr_dec_every': LR_DEC_EVERY,\n",
    "    'lambda_sp_loss': LAMBDA_SP_LOSS,\n",
    "    'lambda_sym_loss': LAMBDA_SYM_LOSS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37c787d6-372b-4189-b428-133486557995",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Solver(fista_net, Psi, trn_ldr, val_ldr, BATCH_SIZE, args, tst_ldr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dba58ed-bcde-4a91-994f-1b69c8decd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 2001...\n",
      "\n",
      "Train Epoch: 2001 [0/8000 (0%)]\tBatch Loss: 0.020926\tLearning Rate (w_theta): 0.001000\t TIME:2.5s\n",
      "\t\t\t\tDisc: 0.015068\t\tSym: 0.000719\t\tSpars: 0.005139\n",
      "\t TVw: -0.569591 | TVb: -1.975530 | GSw: -0.407429 | GSb: -0.116712 | TSUw: 0.277423 | TSUb: 0.182713\n",
      "\n",
      "Train Epoch: 2001 [4000/8000 (50%)]\tBatch Loss: 0.020287\tLearning Rate (w_theta): 0.001000\t TIME:4.1s\n",
      "\t\t\t\tDisc: 0.014451\t\tSym: 0.000690\t\tSpars: 0.005145\n",
      "\t TVw: -0.569636 | TVb: -1.975549 | GSw: -0.407490 | GSb: -0.116794 | TSUw: 0.277345 | TSUb: 0.182731\n",
      "Validating epoch 2001...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.020150147874561875\n",
      "Average validation loss: 0.01958809211242233\n",
      "Training epoch 2002...\n",
      "\n",
      "Train Epoch: 2002 [0/8000 (0%)]\tBatch Loss: 0.019837\tLearning Rate (w_theta): 0.001000\t TIME:6.3s\n",
      "\t\t\t\tDisc: 0.014033\t\tSym: 0.000670\t\tSpars: 0.005134\n",
      "\t TVw: -0.569685 | TVb: -1.975568 | GSw: -0.407549 | GSb: -0.116875 | TSUw: 0.277269 | TSUb: 0.182747\n",
      "\n",
      "Train Epoch: 2002 [4000/8000 (50%)]\tBatch Loss: 0.020201\tLearning Rate (w_theta): 0.001000\t TIME:7.8s\n",
      "\t\t\t\tDisc: 0.014364\t\tSym: 0.000677\t\tSpars: 0.005160\n",
      "\t TVw: -0.569715 | TVb: -1.975577 | GSw: -0.407606 | GSb: -0.116952 | TSUw: 0.277195 | TSUb: 0.182762\n",
      "Validating epoch 2002...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.020018815548202822\n",
      "Average validation loss: 0.019454889337119086\n",
      "Training epoch 2003...\n",
      "\n",
      "Train Epoch: 2003 [0/8000 (0%)]\tBatch Loss: 0.019641\tLearning Rate (w_theta): 0.001000\t TIME:10.1s\n",
      "\t\t\t\tDisc: 0.013833\t\tSym: 0.000666\t\tSpars: 0.005142\n",
      "\t TVw: -0.569728 | TVb: -1.975575 | GSw: -0.407663 | GSb: -0.117030 | TSUw: 0.277120 | TSUb: 0.182778\n",
      "\n",
      "Train Epoch: 2003 [4000/8000 (50%)]\tBatch Loss: 0.019810\tLearning Rate (w_theta): 0.001000\t TIME:11.6s\n",
      "\t\t\t\tDisc: 0.014071\t\tSym: 0.000633\t\tSpars: 0.005106\n",
      "\t TVw: -0.569734 | TVb: -1.975568 | GSw: -0.407720 | GSb: -0.117107 | TSUw: 0.277044 | TSUb: 0.182794\n",
      "Validating epoch 2003...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01998897745470206\n",
      "Average validation loss: 0.019438554042582504\n",
      "Training epoch 2004...\n",
      "\n",
      "Train Epoch: 2004 [0/8000 (0%)]\tBatch Loss: 0.020468\tLearning Rate (w_theta): 0.001000\t TIME:13.8s\n",
      "\t\t\t\tDisc: 0.014606\t\tSym: 0.000676\t\tSpars: 0.005186\n",
      "\t TVw: -0.569728 | TVb: -1.975554 | GSw: -0.407779 | GSb: -0.117187 | TSUw: 0.276966 | TSUb: 0.182811\n",
      "\n",
      "Train Epoch: 2004 [4000/8000 (50%)]\tBatch Loss: 0.020262\tLearning Rate (w_theta): 0.001000\t TIME:15.3s\n",
      "\t\t\t\tDisc: 0.014405\t\tSym: 0.000680\t\tSpars: 0.005178\n",
      "\t TVw: -0.569704 | TVb: -1.975526 | GSw: -0.407838 | GSb: -0.117266 | TSUw: 0.276888 | TSUb: 0.182829\n",
      "Validating epoch 2004...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01995523406775373\n",
      "Average validation loss: 0.019408430345704518\n",
      "Training epoch 2005...\n",
      "\n",
      "Train Epoch: 2005 [0/8000 (0%)]\tBatch Loss: 0.019744\tLearning Rate (w_theta): 0.001000\t TIME:17.7s\n",
      "\t\t\t\tDisc: 0.014040\t\tSym: 0.000639\t\tSpars: 0.005065\n",
      "\t TVw: -0.569671 | TVb: -1.975494 | GSw: -0.407895 | GSb: -0.117342 | TSUw: 0.276811 | TSUb: 0.182845\n",
      "\n",
      "Train Epoch: 2005 [4000/8000 (50%)]\tBatch Loss: 0.019725\tLearning Rate (w_theta): 0.001000\t TIME:19.2s\n",
      "\t\t\t\tDisc: 0.014028\t\tSym: 0.000651\t\tSpars: 0.005046\n",
      "\t TVw: -0.569646 | TVb: -1.975466 | GSw: -0.407953 | GSb: -0.117421 | TSUw: 0.276733 | TSUb: 0.182862\n",
      "Validating epoch 2005...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019920119842969417\n",
      "Average validation loss: 0.019359965339652507\n",
      "Training epoch 2006...\n",
      "\n",
      "Train Epoch: 2006 [0/8000 (0%)]\tBatch Loss: 0.019955\tLearning Rate (w_theta): 0.001000\t TIME:21.5s\n",
      "\t\t\t\tDisc: 0.014231\t\tSym: 0.000659\t\tSpars: 0.005065\n",
      "\t TVw: -0.569636 | TVb: -1.975447 | GSw: -0.408011 | GSb: -0.117499 | TSUw: 0.276658 | TSUb: 0.182878\n",
      "\n",
      "Train Epoch: 2006 [4000/8000 (50%)]\tBatch Loss: 0.019853\tLearning Rate (w_theta): 0.001000\t TIME:23.0s\n",
      "\t\t\t\tDisc: 0.014131\t\tSym: 0.000659\t\tSpars: 0.005063\n",
      "\t TVw: -0.569625 | TVb: -1.975429 | GSw: -0.408068 | GSb: -0.117577 | TSUw: 0.276583 | TSUb: 0.182893\n",
      "Validating epoch 2006...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019890408060079023\n",
      "Average validation loss: 0.019320762192256424\n",
      "Training epoch 2007...\n",
      "\n",
      "Train Epoch: 2007 [0/8000 (0%)]\tBatch Loss: 0.020032\tLearning Rate (w_theta): 0.001000\t TIME:25.3s\n",
      "\t\t\t\tDisc: 0.014336\t\tSym: 0.000656\t\tSpars: 0.005041\n",
      "\t TVw: -0.569616 | TVb: -1.975411 | GSw: -0.408124 | GSb: -0.117654 | TSUw: 0.276509 | TSUb: 0.182907\n",
      "\n",
      "Train Epoch: 2007 [4000/8000 (50%)]\tBatch Loss: 0.019457\tLearning Rate (w_theta): 0.001000\t TIME:26.8s\n",
      "\t\t\t\tDisc: 0.013779\t\tSym: 0.000653\t\tSpars: 0.005024\n",
      "\t TVw: -0.569612 | TVb: -1.975396 | GSw: -0.408180 | GSb: -0.117730 | TSUw: 0.276437 | TSUb: 0.182920\n",
      "Validating epoch 2007...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01987046077588368\n",
      "Average validation loss: 0.019320852963889697\n",
      "Training epoch 2008...\n",
      "\n",
      "Train Epoch: 2008 [0/8000 (0%)]\tBatch Loss: 0.019489\tLearning Rate (w_theta): 0.001000\t TIME:29.2s\n",
      "\t\t\t\tDisc: 0.013827\t\tSym: 0.000653\t\tSpars: 0.005010\n",
      "\t TVw: -0.569608 | TVb: -1.975380 | GSw: -0.408236 | GSb: -0.117808 | TSUw: 0.276364 | TSUb: 0.182934\n",
      "\n",
      "Train Epoch: 2008 [4000/8000 (50%)]\tBatch Loss: 0.020052\tLearning Rate (w_theta): 0.001000\t TIME:30.7s\n",
      "\t\t\t\tDisc: 0.014288\t\tSym: 0.000679\t\tSpars: 0.005085\n",
      "\t TVw: -0.569610 | TVb: -1.975369 | GSw: -0.408292 | GSb: -0.117885 | TSUw: 0.276292 | TSUb: 0.182947\n",
      "Validating epoch 2008...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019841954441007538\n",
      "Average validation loss: 0.019281633457237334\n",
      "Training epoch 2009...\n",
      "\n",
      "Train Epoch: 2009 [0/8000 (0%)]\tBatch Loss: 0.020026\tLearning Rate (w_theta): 0.001000\t TIME:33.0s\n",
      "\t\t\t\tDisc: 0.014259\t\tSym: 0.000683\t\tSpars: 0.005083\n",
      "\t TVw: -0.569602 | TVb: -1.975350 | GSw: -0.408350 | GSb: -0.117964 | TSUw: 0.276217 | TSUb: 0.182961\n",
      "\n",
      "Train Epoch: 2009 [4000/8000 (50%)]\tBatch Loss: 0.019725\tLearning Rate (w_theta): 0.001000\t TIME:34.5s\n",
      "\t\t\t\tDisc: 0.014084\t\tSym: 0.000648\t\tSpars: 0.004993\n",
      "\t TVw: -0.569600 | TVb: -1.975332 | GSw: -0.408408 | GSb: -0.118045 | TSUw: 0.276142 | TSUb: 0.182976\n",
      "Validating epoch 2009...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019827948559993695\n",
      "Average validation loss: 0.01928169580790679\n",
      "Training epoch 2010...\n",
      "\n",
      "Train Epoch: 2010 [0/8000 (0%)]\tBatch Loss: 0.020063\tLearning Rate (w_theta): 0.001000\t TIME:36.8s\n",
      "\t\t\t\tDisc: 0.014328\t\tSym: 0.000675\t\tSpars: 0.005060\n",
      "\t TVw: -0.569602 | TVb: -1.975320 | GSw: -0.408467 | GSb: -0.118125 | TSUw: 0.276066 | TSUb: 0.182991\n",
      "\n",
      "Train Epoch: 2010 [4000/8000 (50%)]\tBatch Loss: 0.019677\tLearning Rate (w_theta): 0.001000\t TIME:38.3s\n",
      "\t\t\t\tDisc: 0.013987\t\tSym: 0.000667\t\tSpars: 0.005023\n",
      "\t TVw: -0.569590 | TVb: -1.975298 | GSw: -0.408527 | GSb: -0.118207 | TSUw: 0.275989 | TSUb: 0.183007\n",
      "Validating epoch 2010...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019806628859950506\n",
      "Average validation loss: 0.01927392073465585\n",
      "Training epoch 2011...\n",
      "\n",
      "Train Epoch: 2011 [0/8000 (0%)]\tBatch Loss: 0.019345\tLearning Rate (w_theta): 0.001000\t TIME:41.4s\n",
      "\t\t\t\tDisc: 0.013804\t\tSym: 0.000628\t\tSpars: 0.004914\n",
      "\t TVw: -0.569573 | TVb: -1.975274 | GSw: -0.408584 | GSb: -0.118285 | TSUw: 0.275914 | TSUb: 0.183021\n",
      "\n",
      "Train Epoch: 2011 [4000/8000 (50%)]\tBatch Loss: 0.019552\tLearning Rate (w_theta): 0.001000\t TIME:43.0s\n",
      "\t\t\t\tDisc: 0.013859\t\tSym: 0.000671\t\tSpars: 0.005022\n",
      "\t TVw: -0.569569 | TVb: -1.975260 | GSw: -0.408642 | GSb: -0.118365 | TSUw: 0.275838 | TSUb: 0.183036\n",
      "Validating epoch 2011...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019787683174296244\n",
      "Average validation loss: 0.01923680424365298\n",
      "Training epoch 2012...\n",
      "\n",
      "Train Epoch: 2012 [0/8000 (0%)]\tBatch Loss: 0.019179\tLearning Rate (w_theta): 0.001000\t TIME:45.2s\n",
      "\t\t\t\tDisc: 0.013561\t\tSym: 0.000652\t\tSpars: 0.004966\n",
      "\t TVw: -0.569580 | TVb: -1.975254 | GSw: -0.408702 | GSb: -0.118447 | TSUw: 0.275762 | TSUb: 0.183050\n",
      "\n",
      "Train Epoch: 2012 [4000/8000 (50%)]\tBatch Loss: 0.019545\tLearning Rate (w_theta): 0.001000\t TIME:46.7s\n",
      "\t\t\t\tDisc: 0.013883\t\tSym: 0.000660\t\tSpars: 0.005002\n",
      "\t TVw: -0.569584 | TVb: -1.975244 | GSw: -0.408760 | GSb: -0.118527 | TSUw: 0.275687 | TSUb: 0.183064\n",
      "Validating epoch 2012...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019764014034724907\n",
      "Average validation loss: 0.019235477232787634\n",
      "Training epoch 2013...\n",
      "\n",
      "Train Epoch: 2013 [0/8000 (0%)]\tBatch Loss: 0.019711\tLearning Rate (w_theta): 0.001000\t TIME:49.1s\n",
      "\t\t\t\tDisc: 0.014008\t\tSym: 0.000675\t\tSpars: 0.005028\n",
      "\t TVw: -0.569571 | TVb: -1.975221 | GSw: -0.408819 | GSb: -0.118608 | TSUw: 0.275610 | TSUb: 0.183080\n",
      "\n",
      "Train Epoch: 2013 [4000/8000 (50%)]\tBatch Loss: 0.019303\tLearning Rate (w_theta): 0.001000\t TIME:50.6s\n",
      "\t\t\t\tDisc: 0.013746\t\tSym: 0.000637\t\tSpars: 0.004920\n",
      "\t TVw: -0.569565 | TVb: -1.975201 | GSw: -0.408879 | GSb: -0.118690 | TSUw: 0.275533 | TSUb: 0.183095\n",
      "Validating epoch 2013...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01975374982777364\n",
      "Average validation loss: 0.019218402775739732\n",
      "Training epoch 2014...\n",
      "\n",
      "Train Epoch: 2014 [0/8000 (0%)]\tBatch Loss: 0.019636\tLearning Rate (w_theta): 0.001000\t TIME:52.9s\n",
      "\t\t\t\tDisc: 0.014022\t\tSym: 0.000659\t\tSpars: 0.004955\n",
      "\t TVw: -0.569567 | TVb: -1.975189 | GSw: -0.408939 | GSb: -0.118772 | TSUw: 0.275456 | TSUb: 0.183110\n",
      "\n",
      "Train Epoch: 2014 [4000/8000 (50%)]\tBatch Loss: 0.019002\tLearning Rate (w_theta): 0.001000\t TIME:54.4s\n",
      "\t\t\t\tDisc: 0.013449\t\tSym: 0.000637\t\tSpars: 0.004916\n",
      "\t TVw: -0.569567 | TVb: -1.975177 | GSw: -0.408998 | GSb: -0.118853 | TSUw: 0.275380 | TSUb: 0.183124\n",
      "Validating epoch 2014...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01973429792579661\n",
      "Average validation loss: 0.019221526543308144\n",
      "Training epoch 2015...\n",
      "\n",
      "Train Epoch: 2015 [0/8000 (0%)]\tBatch Loss: 0.019737\tLearning Rate (w_theta): 0.001000\t TIME:56.7s\n",
      "\t\t\t\tDisc: 0.014064\t\tSym: 0.000674\t\tSpars: 0.004999\n",
      "\t TVw: -0.569563 | TVb: -1.975161 | GSw: -0.409057 | GSb: -0.118934 | TSUw: 0.275304 | TSUb: 0.183139\n",
      "\n",
      "Train Epoch: 2015 [4000/8000 (50%)]\tBatch Loss: 0.019631\tLearning Rate (w_theta): 0.001000\t TIME:58.2s\n",
      "\t\t\t\tDisc: 0.014002\t\tSym: 0.000658\t\tSpars: 0.004971\n",
      "\t TVw: -0.569565 | TVb: -1.975146 | GSw: -0.409119 | GSb: -0.119019 | TSUw: 0.275224 | TSUb: 0.183155\n",
      "Validating epoch 2015...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019725524649466624\n",
      "Average validation loss: 0.019199984167971366\n",
      "Training epoch 2016...\n",
      "\n",
      "Train Epoch: 2016 [0/8000 (0%)]\tBatch Loss: 0.019626\tLearning Rate (w_theta): 0.001000\t TIME:60.6s\n",
      "\t\t\t\tDisc: 0.014066\t\tSym: 0.000645\t\tSpars: 0.004916\n",
      "\t TVw: -0.569561 | TVb: -1.975127 | GSw: -0.409180 | GSb: -0.119103 | TSUw: 0.275145 | TSUb: 0.183171\n",
      "\n",
      "Train Epoch: 2016 [4000/8000 (50%)]\tBatch Loss: 0.019134\tLearning Rate (w_theta): 0.001000\t TIME:62.1s\n",
      "\t\t\t\tDisc: 0.013547\t\tSym: 0.000651\t\tSpars: 0.004937\n",
      "\t TVw: -0.569556 | TVb: -1.975110 | GSw: -0.409241 | GSb: -0.119187 | TSUw: 0.275066 | TSUb: 0.183187\n",
      "Validating epoch 2016...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01971493680967684\n",
      "Average validation loss: 0.019183949788022875\n",
      "Training epoch 2017...\n",
      "\n",
      "Train Epoch: 2017 [0/8000 (0%)]\tBatch Loss: 0.020447\tLearning Rate (w_theta): 0.001000\t TIME:64.4s\n",
      "\t\t\t\tDisc: 0.014688\t\tSym: 0.000704\t\tSpars: 0.005054\n",
      "\t TVw: -0.569554 | TVb: -1.975095 | GSw: -0.409302 | GSb: -0.119270 | TSUw: 0.274988 | TSUb: 0.183202\n",
      "\n",
      "Train Epoch: 2017 [4000/8000 (50%)]\tBatch Loss: 0.020052\tLearning Rate (w_theta): 0.001000\t TIME:65.9s\n",
      "\t\t\t\tDisc: 0.014348\t\tSym: 0.000688\t\tSpars: 0.005015\n",
      "\t TVw: -0.569558 | TVb: -1.975083 | GSw: -0.409364 | GSb: -0.119355 | TSUw: 0.274909 | TSUb: 0.183218\n",
      "Validating epoch 2017...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01969644047287667\n",
      "Average validation loss: 0.019190979357893878\n",
      "Training epoch 2018...\n",
      "\n",
      "Train Epoch: 2018 [0/8000 (0%)]\tBatch Loss: 0.019512\tLearning Rate (w_theta): 0.001000\t TIME:68.2s\n",
      "\t\t\t\tDisc: 0.013908\t\tSym: 0.000663\t\tSpars: 0.004941\n",
      "\t TVw: -0.569561 | TVb: -1.975071 | GSw: -0.409425 | GSb: -0.119439 | TSUw: 0.274831 | TSUb: 0.183233\n",
      "\n",
      "Train Epoch: 2018 [4000/8000 (50%)]\tBatch Loss: 0.019937\tLearning Rate (w_theta): 0.001000\t TIME:69.7s\n",
      "\t\t\t\tDisc: 0.014365\t\tSym: 0.000654\t\tSpars: 0.004918\n",
      "\t TVw: -0.569559 | TVb: -1.975057 | GSw: -0.409486 | GSb: -0.119522 | TSUw: 0.274753 | TSUb: 0.183248\n",
      "Validating epoch 2018...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01976697290439049\n",
      "Average validation loss: 0.0192600766661351\n",
      "Training epoch 2019...\n",
      "\n",
      "Train Epoch: 2019 [0/8000 (0%)]\tBatch Loss: 0.019966\tLearning Rate (w_theta): 0.001000\t TIME:72.1s\n",
      "\t\t\t\tDisc: 0.014308\t\tSym: 0.000672\t\tSpars: 0.004985\n",
      "\t TVw: -0.569576 | TVb: -1.975054 | GSw: -0.409548 | GSb: -0.119607 | TSUw: 0.274673 | TSUb: 0.183264\n",
      "\n",
      "Train Epoch: 2019 [4000/8000 (50%)]\tBatch Loss: 0.019601\tLearning Rate (w_theta): 0.001000\t TIME:73.6s\n",
      "\t\t\t\tDisc: 0.014038\t\tSym: 0.000646\t\tSpars: 0.004917\n",
      "\t TVw: -0.569583 | TVb: -1.975046 | GSw: -0.409609 | GSb: -0.119691 | TSUw: 0.274595 | TSUb: 0.183279\n",
      "Validating epoch 2019...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01977994289231961\n",
      "Average validation loss: 0.01919306107868567\n",
      "Training epoch 2020...\n",
      "\n",
      "Train Epoch: 2020 [0/8000 (0%)]\tBatch Loss: 0.019664\tLearning Rate (w_theta): 0.001000\t TIME:75.9s\n",
      "\t\t\t\tDisc: 0.014020\t\tSym: 0.000662\t\tSpars: 0.004983\n",
      "\t TVw: -0.569600 | TVb: -1.975043 | GSw: -0.409671 | GSb: -0.119776 | TSUw: 0.274516 | TSUb: 0.183294\n",
      "\n",
      "Train Epoch: 2020 [4000/8000 (50%)]\tBatch Loss: 0.019613\tLearning Rate (w_theta): 0.001000\t TIME:77.4s\n",
      "\t\t\t\tDisc: 0.013930\t\tSym: 0.000664\t\tSpars: 0.005018\n",
      "\t TVw: -0.569629 | TVb: -1.975044 | GSw: -0.409733 | GSb: -0.119861 | TSUw: 0.274437 | TSUb: 0.183309\n",
      "Validating epoch 2020...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019769117056786217\n",
      "Average validation loss: 0.01922815491044512\n",
      "Training epoch 2021...\n",
      "\n",
      "Train Epoch: 2021 [0/8000 (0%)]\tBatch Loss: 0.019427\tLearning Rate (w_theta): 0.001000\t TIME:80.4s\n",
      "\t\t\t\tDisc: 0.013819\t\tSym: 0.000643\t\tSpars: 0.004965\n",
      "\t TVw: -0.569636 | TVb: -1.975035 | GSw: -0.409794 | GSb: -0.119944 | TSUw: 0.274359 | TSUb: 0.183324\n",
      "\n",
      "Train Epoch: 2021 [4000/8000 (50%)]\tBatch Loss: 0.019847\tLearning Rate (w_theta): 0.001000\t TIME:81.9s\n",
      "\t\t\t\tDisc: 0.014193\t\tSym: 0.000661\t\tSpars: 0.004993\n",
      "\t TVw: -0.569630 | TVb: -1.975017 | GSw: -0.409854 | GSb: -0.120027 | TSUw: 0.274280 | TSUb: 0.183339\n",
      "Validating epoch 2021...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01973637839273686\n",
      "Average validation loss: 0.0192157041885362\n",
      "Training epoch 2022...\n",
      "\n",
      "Train Epoch: 2022 [0/8000 (0%)]\tBatch Loss: 0.019238\tLearning Rate (w_theta): 0.001000\t TIME:84.2s\n",
      "\t\t\t\tDisc: 0.013669\t\tSym: 0.000632\t\tSpars: 0.004938\n",
      "\t TVw: -0.569645 | TVb: -1.975013 | GSw: -0.409916 | GSb: -0.120112 | TSUw: 0.274200 | TSUb: 0.183354\n",
      "\n",
      "Train Epoch: 2022 [4000/8000 (50%)]\tBatch Loss: 0.019866\tLearning Rate (w_theta): 0.001000\t TIME:85.7s\n",
      "\t\t\t\tDisc: 0.014180\t\tSym: 0.000665\t\tSpars: 0.005020\n",
      "\t TVw: -0.569644 | TVb: -1.975001 | GSw: -0.409977 | GSb: -0.120195 | TSUw: 0.274121 | TSUb: 0.183370\n",
      "Validating epoch 2022...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019700588752178217\n",
      "Average validation loss: 0.019168530356537747\n",
      "Training epoch 2023...\n",
      "\n",
      "Train Epoch: 2023 [0/8000 (0%)]\tBatch Loss: 0.020083\tLearning Rate (w_theta): 0.001000\t TIME:88.0s\n",
      "\t\t\t\tDisc: 0.014344\t\tSym: 0.000687\t\tSpars: 0.005051\n",
      "\t TVw: -0.569639 | TVb: -1.974982 | GSw: -0.410039 | GSb: -0.120280 | TSUw: 0.274041 | TSUb: 0.183385\n",
      "\n",
      "Train Epoch: 2023 [4000/8000 (50%)]\tBatch Loss: 0.019218\tLearning Rate (w_theta): 0.001000\t TIME:89.6s\n",
      "\t\t\t\tDisc: 0.013668\t\tSym: 0.000627\t\tSpars: 0.004922\n",
      "\t TVw: -0.569631 | TVb: -1.974962 | GSw: -0.410102 | GSb: -0.120365 | TSUw: 0.273960 | TSUb: 0.183401\n",
      "Validating epoch 2023...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019685707185198117\n",
      "Average validation loss: 0.01915335271653549\n",
      "Training epoch 2024...\n",
      "\n",
      "Train Epoch: 2024 [0/8000 (0%)]\tBatch Loss: 0.020176\tLearning Rate (w_theta): 0.001000\t TIME:91.9s\n",
      "\t\t\t\tDisc: 0.014544\t\tSym: 0.000662\t\tSpars: 0.004970\n",
      "\t TVw: -0.569623 | TVb: -1.974943 | GSw: -0.410163 | GSb: -0.120448 | TSUw: 0.273880 | TSUb: 0.183417\n",
      "\n",
      "Train Epoch: 2024 [4000/8000 (50%)]\tBatch Loss: 0.019652\tLearning Rate (w_theta): 0.001000\t TIME:93.4s\n",
      "\t\t\t\tDisc: 0.014061\t\tSym: 0.000648\t\tSpars: 0.004943\n",
      "\t TVw: -0.569620 | TVb: -1.974926 | GSw: -0.410224 | GSb: -0.120532 | TSUw: 0.273800 | TSUb: 0.183432\n",
      "Validating epoch 2024...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01966895589119137\n",
      "Average validation loss: 0.019137621639958823\n",
      "Training epoch 2025...\n",
      "\n",
      "Train Epoch: 2025 [0/8000 (0%)]\tBatch Loss: 0.019386\tLearning Rate (w_theta): 0.001000\t TIME:95.8s\n",
      "\t\t\t\tDisc: 0.013792\t\tSym: 0.000652\t\tSpars: 0.004941\n",
      "\t TVw: -0.569624 | TVb: -1.974914 | GSw: -0.410287 | GSb: -0.120618 | TSUw: 0.273720 | TSUb: 0.183447\n",
      "\n",
      "Train Epoch: 2025 [4000/8000 (50%)]\tBatch Loss: 0.020119\tLearning Rate (w_theta): 0.001000\t TIME:97.3s\n",
      "\t\t\t\tDisc: 0.014478\t\tSym: 0.000667\t\tSpars: 0.004974\n",
      "\t TVw: -0.569623 | TVb: -1.974901 | GSw: -0.410347 | GSb: -0.120701 | TSUw: 0.273643 | TSUb: 0.183460\n",
      "Validating epoch 2025...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019642331296651373\n",
      "Average validation loss: 0.01912752294143842\n",
      "Training epoch 2026...\n",
      "\n",
      "Train Epoch: 2026 [0/8000 (0%)]\tBatch Loss: 0.019718\tLearning Rate (w_theta): 0.001000\t TIME:99.6s\n",
      "\t\t\t\tDisc: 0.014099\t\tSym: 0.000668\t\tSpars: 0.004951\n",
      "\t TVw: -0.569608 | TVb: -1.974876 | GSw: -0.410408 | GSb: -0.120784 | TSUw: 0.273563 | TSUb: 0.183475\n",
      "\n",
      "Train Epoch: 2026 [4000/8000 (50%)]\tBatch Loss: 0.019228\tLearning Rate (w_theta): 0.001000\t TIME:101.1s\n",
      "\t\t\t\tDisc: 0.013660\t\tSym: 0.000653\t\tSpars: 0.004915\n",
      "\t TVw: -0.569601 | TVb: -1.974859 | GSw: -0.410469 | GSb: -0.120868 | TSUw: 0.273484 | TSUb: 0.183489\n",
      "Validating epoch 2026...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01963040582431583\n",
      "Average validation loss: 0.019103988820315485\n",
      "Training epoch 2027...\n",
      "\n",
      "Train Epoch: 2027 [0/8000 (0%)]\tBatch Loss: 0.019477\tLearning Rate (w_theta): 0.001000\t TIME:103.4s\n",
      "\t\t\t\tDisc: 0.013908\t\tSym: 0.000651\t\tSpars: 0.004918\n",
      "\t TVw: -0.569610 | TVb: -1.974851 | GSw: -0.410532 | GSb: -0.120954 | TSUw: 0.273404 | TSUb: 0.183504\n",
      "\n",
      "Train Epoch: 2027 [4000/8000 (50%)]\tBatch Loss: 0.019448\tLearning Rate (w_theta): 0.001000\t TIME:105.0s\n",
      "\t\t\t\tDisc: 0.013792\t\tSym: 0.000679\t\tSpars: 0.004977\n",
      "\t TVw: -0.569620 | TVb: -1.974842 | GSw: -0.410595 | GSb: -0.121040 | TSUw: 0.273324 | TSUb: 0.183519\n",
      "Validating epoch 2027...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019626216588737113\n",
      "Average validation loss: 0.01909383058673916\n",
      "Training epoch 2028...\n",
      "\n",
      "Train Epoch: 2028 [0/8000 (0%)]\tBatch Loss: 0.019976\tLearning Rate (w_theta): 0.001000\t TIME:107.3s\n",
      "\t\t\t\tDisc: 0.014324\t\tSym: 0.000674\t\tSpars: 0.004977\n",
      "\t TVw: -0.569616 | TVb: -1.974824 | GSw: -0.410658 | GSb: -0.121127 | TSUw: 0.273242 | TSUb: 0.183534\n",
      "\n",
      "Train Epoch: 2028 [4000/8000 (50%)]\tBatch Loss: 0.019532\tLearning Rate (w_theta): 0.001000\t TIME:108.8s\n",
      "\t\t\t\tDisc: 0.013982\t\tSym: 0.000647\t\tSpars: 0.004904\n",
      "\t TVw: -0.569615 | TVb: -1.974808 | GSw: -0.410721 | GSb: -0.121214 | TSUw: 0.273161 | TSUb: 0.183550\n",
      "Validating epoch 2028...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01962103638336304\n",
      "Average validation loss: 0.0191062603475908\n",
      "Training epoch 2029...\n",
      "\n",
      "Train Epoch: 2029 [0/8000 (0%)]\tBatch Loss: 0.019652\tLearning Rate (w_theta): 0.001000\t TIME:111.1s\n",
      "\t\t\t\tDisc: 0.014039\t\tSym: 0.000663\t\tSpars: 0.004950\n",
      "\t TVw: -0.569616 | TVb: -1.974795 | GSw: -0.410784 | GSb: -0.121300 | TSUw: 0.273079 | TSUb: 0.183565\n",
      "\n",
      "Train Epoch: 2029 [4000/8000 (50%)]\tBatch Loss: 0.019378\tLearning Rate (w_theta): 0.001000\t TIME:112.6s\n",
      "\t\t\t\tDisc: 0.013839\t\tSym: 0.000643\t\tSpars: 0.004896\n",
      "\t TVw: -0.569621 | TVb: -1.974785 | GSw: -0.410848 | GSb: -0.121387 | TSUw: 0.272998 | TSUb: 0.183580\n",
      "Validating epoch 2029...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019595462272768843\n",
      "Average validation loss: 0.0191292870006209\n",
      "Training epoch 2030...\n",
      "\n",
      "Train Epoch: 2030 [0/8000 (0%)]\tBatch Loss: 0.019657\tLearning Rate (w_theta): 0.001000\t TIME:115.0s\n",
      "\t\t\t\tDisc: 0.014126\t\tSym: 0.000645\t\tSpars: 0.004885\n",
      "\t TVw: -0.569611 | TVb: -1.974764 | GSw: -0.410911 | GSb: -0.121473 | TSUw: 0.272916 | TSUb: 0.183596\n",
      "\n",
      "Train Epoch: 2030 [4000/8000 (50%)]\tBatch Loss: 0.019357\tLearning Rate (w_theta): 0.001000\t TIME:116.5s\n",
      "\t\t\t\tDisc: 0.013796\t\tSym: 0.000649\t\tSpars: 0.004912\n",
      "\t TVw: -0.569615 | TVb: -1.974754 | GSw: -0.410975 | GSb: -0.121561 | TSUw: 0.272833 | TSUb: 0.183612\n",
      "Validating epoch 2030...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01964042145030255\n",
      "Average validation loss: 0.019092309283688824\n",
      "Training epoch 2031...\n",
      "\n",
      "Train Epoch: 2031 [0/8000 (0%)]\tBatch Loss: 0.019894\tLearning Rate (w_theta): 0.001000\t TIME:119.5s\n",
      "\t\t\t\tDisc: 0.014241\t\tSym: 0.000678\t\tSpars: 0.004976\n",
      "\t TVw: -0.569622 | TVb: -1.974743 | GSw: -0.411040 | GSb: -0.121650 | TSUw: 0.272750 | TSUb: 0.183628\n",
      "\n",
      "Train Epoch: 2031 [4000/8000 (50%)]\tBatch Loss: 0.019413\tLearning Rate (w_theta): 0.001000\t TIME:121.1s\n",
      "\t\t\t\tDisc: 0.013859\t\tSym: 0.000645\t\tSpars: 0.004909\n",
      "\t TVw: -0.569637 | TVb: -1.974736 | GSw: -0.411106 | GSb: -0.121740 | TSUw: 0.272666 | TSUb: 0.183644\n",
      "Validating epoch 2031...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01964491042473085\n",
      "Average validation loss: 0.019088457842816924\n",
      "Training epoch 2032...\n",
      "\n",
      "Train Epoch: 2032 [0/8000 (0%)]\tBatch Loss: 0.019467\tLearning Rate (w_theta): 0.001000\t TIME:123.4s\n",
      "\t\t\t\tDisc: 0.013909\t\tSym: 0.000649\t\tSpars: 0.004910\n",
      "\t TVw: -0.569642 | TVb: -1.974724 | GSw: -0.411170 | GSb: -0.121827 | TSUw: 0.272584 | TSUb: 0.183659\n",
      "\n",
      "Train Epoch: 2032 [4000/8000 (50%)]\tBatch Loss: 0.019448\tLearning Rate (w_theta): 0.001000\t TIME:124.9s\n",
      "\t\t\t\tDisc: 0.013898\t\tSym: 0.000638\t\tSpars: 0.004912\n",
      "\t TVw: -0.569647 | TVb: -1.974713 | GSw: -0.411232 | GSb: -0.121913 | TSUw: 0.272503 | TSUb: 0.183673\n",
      "Validating epoch 2032...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019607018140008634\n",
      "Average validation loss: 0.019086438910099385\n",
      "Training epoch 2033...\n",
      "\n",
      "Train Epoch: 2033 [0/8000 (0%)]\tBatch Loss: 0.019594\tLearning Rate (w_theta): 0.001000\t TIME:127.2s\n",
      "\t\t\t\tDisc: 0.013995\t\tSym: 0.000656\t\tSpars: 0.004943\n",
      "\t TVw: -0.569657 | TVb: -1.974706 | GSw: -0.411295 | GSb: -0.122000 | TSUw: 0.272422 | TSUb: 0.183688\n",
      "\n",
      "Train Epoch: 2033 [4000/8000 (50%)]\tBatch Loss: 0.019647\tLearning Rate (w_theta): 0.001000\t TIME:128.7s\n",
      "\t\t\t\tDisc: 0.014035\t\tSym: 0.000654\t\tSpars: 0.004958\n",
      "\t TVw: -0.569665 | TVb: -1.974697 | GSw: -0.411359 | GSb: -0.122086 | TSUw: 0.272341 | TSUb: 0.183702\n",
      "Validating epoch 2033...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019594604334157318\n",
      "Average validation loss: 0.019089026112823083\n",
      "Training epoch 2034...\n",
      "\n",
      "Train Epoch: 2034 [0/8000 (0%)]\tBatch Loss: 0.019683\tLearning Rate (w_theta): 0.001000\t TIME:131.1s\n",
      "\t\t\t\tDisc: 0.014058\t\tSym: 0.000657\t\tSpars: 0.004967\n",
      "\t TVw: -0.569675 | TVb: -1.974689 | GSw: -0.411423 | GSb: -0.122174 | TSUw: 0.272258 | TSUb: 0.183717\n",
      "\n",
      "Train Epoch: 2034 [4000/8000 (50%)]\tBatch Loss: 0.019537\tLearning Rate (w_theta): 0.001000\t TIME:132.6s\n",
      "\t\t\t\tDisc: 0.013990\t\tSym: 0.000641\t\tSpars: 0.004906\n",
      "\t TVw: -0.569675 | TVb: -1.974676 | GSw: -0.411487 | GSb: -0.122262 | TSUw: 0.272175 | TSUb: 0.183733\n",
      "Validating epoch 2034...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019603018821846882\n",
      "Average validation loss: 0.019043039806298255\n",
      "Training epoch 2035...\n",
      "\n",
      "Train Epoch: 2035 [0/8000 (0%)]\tBatch Loss: 0.019132\tLearning Rate (w_theta): 0.001000\t TIME:134.9s\n",
      "\t\t\t\tDisc: 0.013589\t\tSym: 0.000643\t\tSpars: 0.004901\n",
      "\t TVw: -0.569664 | TVb: -1.974654 | GSw: -0.411551 | GSb: -0.122349 | TSUw: 0.272092 | TSUb: 0.183748\n",
      "\n",
      "Train Epoch: 2035 [4000/8000 (50%)]\tBatch Loss: 0.019464\tLearning Rate (w_theta): 0.001000\t TIME:136.5s\n",
      "\t\t\t\tDisc: 0.013903\t\tSym: 0.000646\t\tSpars: 0.004915\n",
      "\t TVw: -0.569672 | TVb: -1.974645 | GSw: -0.411616 | GSb: -0.122438 | TSUw: 0.272008 | TSUb: 0.183764\n",
      "Validating epoch 2035...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019593554275906182\n",
      "Average validation loss: 0.019082647565217686\n",
      "Training epoch 2036...\n",
      "\n",
      "Train Epoch: 2036 [0/8000 (0%)]\tBatch Loss: 0.019953\tLearning Rate (w_theta): 0.001000\t TIME:138.8s\n",
      "\t\t\t\tDisc: 0.014354\t\tSym: 0.000662\t\tSpars: 0.004938\n",
      "\t TVw: -0.569655 | TVb: -1.974620 | GSw: -0.411680 | GSb: -0.122525 | TSUw: 0.271924 | TSUb: 0.183780\n",
      "\n",
      "Train Epoch: 2036 [4000/8000 (50%)]\tBatch Loss: 0.019878\tLearning Rate (w_theta): 0.001000\t TIME:140.3s\n",
      "\t\t\t\tDisc: 0.014238\t\tSym: 0.000670\t\tSpars: 0.004970\n",
      "\t TVw: -0.569642 | TVb: -1.974598 | GSw: -0.411745 | GSb: -0.122613 | TSUw: 0.271840 | TSUb: 0.183795\n",
      "Validating epoch 2036...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01957347346625554\n",
      "Average validation loss: 0.019065839791274117\n",
      "Training epoch 2037...\n",
      "\n",
      "Train Epoch: 2037 [0/8000 (0%)]\tBatch Loss: 0.019685\tLearning Rate (w_theta): 0.001000\t TIME:142.7s\n",
      "\t\t\t\tDisc: 0.014052\t\tSym: 0.000672\t\tSpars: 0.004962\n",
      "\t TVw: -0.569648 | TVb: -1.974587 | GSw: -0.411811 | GSb: -0.122704 | TSUw: 0.271755 | TSUb: 0.183811\n",
      "\n",
      "Train Epoch: 2037 [4000/8000 (50%)]\tBatch Loss: 0.019440\tLearning Rate (w_theta): 0.001000\t TIME:144.2s\n",
      "\t\t\t\tDisc: 0.013938\t\tSym: 0.000636\t\tSpars: 0.004865\n",
      "\t TVw: -0.569653 | TVb: -1.974576 | GSw: -0.411877 | GSb: -0.122793 | TSUw: 0.271671 | TSUb: 0.183826\n",
      "Validating epoch 2037...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019544376320784446\n",
      "Average validation loss: 0.019003518065660245\n",
      "Training epoch 2038...\n",
      "\n",
      "Train Epoch: 2038 [0/8000 (0%)]\tBatch Loss: 0.019054\tLearning Rate (w_theta): 0.001000\t TIME:146.6s\n",
      "\t\t\t\tDisc: 0.013545\t\tSym: 0.000640\t\tSpars: 0.004869\n",
      "\t TVw: -0.569650 | TVb: -1.974559 | GSw: -0.411941 | GSb: -0.122881 | TSUw: 0.271588 | TSUb: 0.183841\n",
      "\n",
      "Train Epoch: 2038 [4000/8000 (50%)]\tBatch Loss: 0.019618\tLearning Rate (w_theta): 0.001000\t TIME:148.1s\n",
      "\t\t\t\tDisc: 0.014015\t\tSym: 0.000671\t\tSpars: 0.004933\n",
      "\t TVw: -0.569649 | TVb: -1.974541 | GSw: -0.412007 | GSb: -0.122971 | TSUw: 0.271503 | TSUb: 0.183857\n",
      "Validating epoch 2038...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019527715198672323\n",
      "Average validation loss: 0.019010064388571925\n",
      "Training epoch 2039...\n",
      "\n",
      "Train Epoch: 2039 [0/8000 (0%)]\tBatch Loss: 0.019786\tLearning Rate (w_theta): 0.001000\t TIME:150.4s\n",
      "\t\t\t\tDisc: 0.014236\t\tSym: 0.000653\t\tSpars: 0.004897\n",
      "\t TVw: -0.569659 | TVb: -1.974531 | GSw: -0.412072 | GSb: -0.123060 | TSUw: 0.271420 | TSUb: 0.183872\n",
      "\n",
      "Train Epoch: 2039 [4000/8000 (50%)]\tBatch Loss: 0.019484\tLearning Rate (w_theta): 0.001000\t TIME:151.9s\n",
      "\t\t\t\tDisc: 0.013950\t\tSym: 0.000643\t\tSpars: 0.004891\n",
      "\t TVw: -0.569669 | TVb: -1.974520 | GSw: -0.412138 | GSb: -0.123151 | TSUw: 0.271335 | TSUb: 0.183887\n",
      "Validating epoch 2039...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019515946301411978\n",
      "Average validation loss: 0.019007788886884036\n",
      "Training epoch 2040...\n",
      "\n",
      "Train Epoch: 2040 [0/8000 (0%)]\tBatch Loss: 0.019019\tLearning Rate (w_theta): 0.001000\t TIME:154.3s\n",
      "\t\t\t\tDisc: 0.013492\t\tSym: 0.000639\t\tSpars: 0.004888\n",
      "\t TVw: -0.569677 | TVb: -1.974510 | GSw: -0.412203 | GSb: -0.123240 | TSUw: 0.271252 | TSUb: 0.183902\n",
      "\n",
      "Train Epoch: 2040 [4000/8000 (50%)]\tBatch Loss: 0.019461\tLearning Rate (w_theta): 0.001000\t TIME:155.8s\n",
      "\t\t\t\tDisc: 0.014012\t\tSym: 0.000621\t\tSpars: 0.004828\n",
      "\t TVw: -0.569687 | TVb: -1.974503 | GSw: -0.412267 | GSb: -0.123329 | TSUw: 0.271169 | TSUb: 0.183916\n",
      "Validating epoch 2040...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019513018921266872\n",
      "Average validation loss: 0.01898733524107036\n",
      "Training epoch 2041...\n",
      "\n",
      "Train Epoch: 2041 [0/8000 (0%)]\tBatch Loss: 0.019893\tLearning Rate (w_theta): 0.001000\t TIME:158.8s\n",
      "\t\t\t\tDisc: 0.014262\t\tSym: 0.000678\t\tSpars: 0.004954\n",
      "\t TVw: -0.569682 | TVb: -1.974485 | GSw: -0.412332 | GSb: -0.123418 | TSUw: 0.271085 | TSUb: 0.183931\n",
      "\n",
      "Train Epoch: 2041 [4000/8000 (50%)]\tBatch Loss: 0.019510\tLearning Rate (w_theta): 0.001000\t TIME:160.3s\n",
      "\t\t\t\tDisc: 0.013935\t\tSym: 0.000661\t\tSpars: 0.004915\n",
      "\t TVw: -0.569686 | TVb: -1.974473 | GSw: -0.412397 | GSb: -0.123507 | TSUw: 0.271001 | TSUb: 0.183945\n",
      "Validating epoch 2041...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01949957328378208\n",
      "Average validation loss: 0.018977522581076715\n",
      "Training epoch 2042...\n",
      "\n",
      "Train Epoch: 2042 [0/8000 (0%)]\tBatch Loss: 0.019858\tLearning Rate (w_theta): 0.001000\t TIME:162.6s\n",
      "\t\t\t\tDisc: 0.014237\t\tSym: 0.000671\t\tSpars: 0.004951\n",
      "\t TVw: -0.569698 | TVb: -1.974464 | GSw: -0.412464 | GSb: -0.123598 | TSUw: 0.270916 | TSUb: 0.183960\n",
      "\n",
      "Train Epoch: 2042 [4000/8000 (50%)]\tBatch Loss: 0.019418\tLearning Rate (w_theta): 0.001000\t TIME:164.1s\n",
      "\t\t\t\tDisc: 0.013863\t\tSym: 0.000646\t\tSpars: 0.004909\n",
      "\t TVw: -0.569705 | TVb: -1.974454 | GSw: -0.412530 | GSb: -0.123689 | TSUw: 0.270832 | TSUb: 0.183975\n",
      "Validating epoch 2042...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01948671899608689\n",
      "Average validation loss: 0.01897434960234929\n",
      "Training epoch 2043...\n",
      "\n",
      "Train Epoch: 2043 [0/8000 (0%)]\tBatch Loss: 0.019251\tLearning Rate (w_theta): 0.001000\t TIME:166.5s\n",
      "\t\t\t\tDisc: 0.013758\t\tSym: 0.000631\t\tSpars: 0.004862\n",
      "\t TVw: -0.569695 | TVb: -1.974433 | GSw: -0.412593 | GSb: -0.123777 | TSUw: 0.270748 | TSUb: 0.183989\n",
      "\n",
      "Train Epoch: 2043 [4000/8000 (50%)]\tBatch Loss: 0.019635\tLearning Rate (w_theta): 0.001000\t TIME:168.1s\n",
      "\t\t\t\tDisc: 0.014018\t\tSym: 0.000670\t\tSpars: 0.004947\n",
      "\t TVw: -0.569688 | TVb: -1.974414 | GSw: -0.412658 | GSb: -0.123866 | TSUw: 0.270663 | TSUb: 0.184004\n",
      "Validating epoch 2043...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019473626881273284\n",
      "Average validation loss: 0.018952624656253705\n",
      "Training epoch 2044...\n",
      "\n",
      "Train Epoch: 2044 [0/8000 (0%)]\tBatch Loss: 0.019786\tLearning Rate (w_theta): 0.001000\t TIME:170.5s\n",
      "\t\t\t\tDisc: 0.014237\t\tSym: 0.000654\t\tSpars: 0.004895\n",
      "\t TVw: -0.569694 | TVb: -1.974403 | GSw: -0.412725 | GSb: -0.123957 | TSUw: 0.270578 | TSUb: 0.184019\n",
      "\n",
      "Train Epoch: 2044 [4000/8000 (50%)]\tBatch Loss: 0.019347\tLearning Rate (w_theta): 0.001000\t TIME:172.0s\n",
      "\t\t\t\tDisc: 0.013881\t\tSym: 0.000630\t\tSpars: 0.004837\n",
      "\t TVw: -0.569704 | TVb: -1.974394 | GSw: -0.412792 | GSb: -0.124049 | TSUw: 0.270492 | TSUb: 0.184034\n",
      "Validating epoch 2044...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019458635487607987\n",
      "Average validation loss: 0.01894283118145429\n",
      "Training epoch 2045...\n",
      "\n",
      "Train Epoch: 2045 [0/8000 (0%)]\tBatch Loss: 0.019290\tLearning Rate (w_theta): 0.001000\t TIME:174.3s\n",
      "\t\t\t\tDisc: 0.013824\t\tSym: 0.000635\t\tSpars: 0.004831\n",
      "\t TVw: -0.569693 | TVb: -1.974371 | GSw: -0.412857 | GSb: -0.124138 | TSUw: 0.270407 | TSUb: 0.184049\n",
      "\n",
      "Train Epoch: 2045 [4000/8000 (50%)]\tBatch Loss: 0.019920\tLearning Rate (w_theta): 0.001000\t TIME:175.8s\n",
      "\t\t\t\tDisc: 0.014327\t\tSym: 0.000669\t\tSpars: 0.004924\n",
      "\t TVw: -0.569694 | TVb: -1.974354 | GSw: -0.412923 | GSb: -0.124228 | TSUw: 0.270323 | TSUb: 0.184063\n",
      "Validating epoch 2045...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01944653600218616\n",
      "Average validation loss: 0.01893415335629664\n",
      "Training epoch 2046...\n",
      "\n",
      "Train Epoch: 2046 [0/8000 (0%)]\tBatch Loss: 0.019092\tLearning Rate (w_theta): 0.001000\t TIME:178.2s\n",
      "\t\t\t\tDisc: 0.013630\t\tSym: 0.000630\t\tSpars: 0.004832\n",
      "\t TVw: -0.569704 | TVb: -1.974344 | GSw: -0.412989 | GSb: -0.124319 | TSUw: 0.270238 | TSUb: 0.184078\n",
      "\n",
      "Train Epoch: 2046 [4000/8000 (50%)]\tBatch Loss: 0.019330\tLearning Rate (w_theta): 0.001000\t TIME:179.7s\n",
      "\t\t\t\tDisc: 0.013858\t\tSym: 0.000631\t\tSpars: 0.004841\n",
      "\t TVw: -0.569716 | TVb: -1.974336 | GSw: -0.413056 | GSb: -0.124411 | TSUw: 0.270153 | TSUb: 0.184092\n",
      "Validating epoch 2046...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019450729646463723\n",
      "Average validation loss: 0.018929315367464304\n",
      "Training epoch 2047...\n",
      "\n",
      "Train Epoch: 2047 [0/8000 (0%)]\tBatch Loss: 0.020044\tLearning Rate (w_theta): 0.001000\t TIME:182.0s\n",
      "\t\t\t\tDisc: 0.014423\t\tSym: 0.000676\t\tSpars: 0.004944\n",
      "\t TVw: -0.569704 | TVb: -1.974312 | GSw: -0.413121 | GSb: -0.124501 | TSUw: 0.270067 | TSUb: 0.184107\n",
      "\n",
      "Train Epoch: 2047 [4000/8000 (50%)]\tBatch Loss: 0.019048\tLearning Rate (w_theta): 0.001000\t TIME:183.5s\n",
      "\t\t\t\tDisc: 0.013564\t\tSym: 0.000639\t\tSpars: 0.004844\n",
      "\t TVw: -0.569707 | TVb: -1.974298 | GSw: -0.413188 | GSb: -0.124592 | TSUw: 0.269980 | TSUb: 0.184122\n",
      "Validating epoch 2047...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019449052745156018\n",
      "Average validation loss: 0.018918780302823228\n",
      "Training epoch 2048...\n",
      "\n",
      "Train Epoch: 2048 [0/8000 (0%)]\tBatch Loss: 0.019670\tLearning Rate (w_theta): 0.001000\t TIME:185.9s\n",
      "\t\t\t\tDisc: 0.014200\t\tSym: 0.000634\t\tSpars: 0.004836\n",
      "\t TVw: -0.569725 | TVb: -1.974294 | GSw: -0.413255 | GSb: -0.124685 | TSUw: 0.269894 | TSUb: 0.184137\n",
      "\n",
      "Train Epoch: 2048 [4000/8000 (50%)]\tBatch Loss: 0.019196\tLearning Rate (w_theta): 0.001000\t TIME:187.4s\n",
      "\t\t\t\tDisc: 0.013697\t\tSym: 0.000638\t\tSpars: 0.004861\n",
      "\t TVw: -0.569735 | TVb: -1.974285 | GSw: -0.413321 | GSb: -0.124776 | TSUw: 0.269809 | TSUb: 0.184151\n",
      "Validating epoch 2048...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019432710175816797\n",
      "Average validation loss: 0.018930312530561433\n",
      "Training epoch 2049...\n",
      "\n",
      "Train Epoch: 2049 [0/8000 (0%)]\tBatch Loss: 0.019715\tLearning Rate (w_theta): 0.001000\t TIME:189.7s\n",
      "\t\t\t\tDisc: 0.014179\t\tSym: 0.000654\t\tSpars: 0.004882\n",
      "\t TVw: -0.569735 | TVb: -1.974270 | GSw: -0.413387 | GSb: -0.124868 | TSUw: 0.269722 | TSUb: 0.184166\n",
      "\n",
      "Train Epoch: 2049 [4000/8000 (50%)]\tBatch Loss: 0.019376\tLearning Rate (w_theta): 0.001000\t TIME:191.2s\n",
      "\t\t\t\tDisc: 0.013889\t\tSym: 0.000637\t\tSpars: 0.004850\n",
      "\t TVw: -0.569730 | TVb: -1.974251 | GSw: -0.413455 | GSb: -0.124961 | TSUw: 0.269634 | TSUb: 0.184182\n",
      "Validating epoch 2049...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019412249784555254\n",
      "Average validation loss: 0.018895574523329326\n",
      "Training epoch 2050...\n",
      "\n",
      "Train Epoch: 2050 [0/8000 (0%)]\tBatch Loss: 0.020095\tLearning Rate (w_theta): 0.001000\t TIME:193.6s\n",
      "\t\t\t\tDisc: 0.014440\t\tSym: 0.000691\t\tSpars: 0.004964\n",
      "\t TVw: -0.569729 | TVb: -1.974235 | GSw: -0.413522 | GSb: -0.125052 | TSUw: 0.269548 | TSUb: 0.184196\n",
      "\n",
      "Train Epoch: 2050 [4000/8000 (50%)]\tBatch Loss: 0.019559\tLearning Rate (w_theta): 0.001000\t TIME:195.2s\n",
      "\t\t\t\tDisc: 0.013993\t\tSym: 0.000664\t\tSpars: 0.004902\n",
      "\t TVw: -0.569734 | TVb: -1.974224 | GSw: -0.413588 | GSb: -0.125143 | TSUw: 0.269462 | TSUb: 0.184210\n",
      "Validating epoch 2050...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019402109746209293\n",
      "Average validation loss: 0.018899903023483614\n",
      "Training epoch 2051...\n",
      "\n",
      "Train Epoch: 2051 [0/8000 (0%)]\tBatch Loss: 0.019034\tLearning Rate (w_theta): 0.001000\t TIME:198.0s\n",
      "\t\t\t\tDisc: 0.013560\t\tSym: 0.000636\t\tSpars: 0.004838\n",
      "\t TVw: -0.569738 | TVb: -1.974212 | GSw: -0.413655 | GSb: -0.125236 | TSUw: 0.269376 | TSUb: 0.184224\n",
      "\n",
      "Train Epoch: 2051 [4000/8000 (50%)]\tBatch Loss: 0.019020\tLearning Rate (w_theta): 0.001000\t TIME:199.5s\n",
      "\t\t\t\tDisc: 0.013549\t\tSym: 0.000634\t\tSpars: 0.004838\n",
      "\t TVw: -0.569741 | TVb: -1.974200 | GSw: -0.413723 | GSb: -0.125329 | TSUw: 0.269288 | TSUb: 0.184239\n",
      "Validating epoch 2051...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019402078672578975\n",
      "Average validation loss: 0.019002379794874177\n",
      "Training epoch 2052...\n",
      "\n",
      "Train Epoch: 2052 [0/8000 (0%)]\tBatch Loss: 0.019359\tLearning Rate (w_theta): 0.001000\t TIME:202.0s\n",
      "\t\t\t\tDisc: 0.013848\t\tSym: 0.000643\t\tSpars: 0.004867\n",
      "\t TVw: -0.569741 | TVb: -1.974186 | GSw: -0.413790 | GSb: -0.125421 | TSUw: 0.269201 | TSUb: 0.184254\n",
      "\n",
      "Train Epoch: 2052 [4000/8000 (50%)]\tBatch Loss: 0.019725\tLearning Rate (w_theta): 0.001000\t TIME:203.5s\n",
      "\t\t\t\tDisc: 0.014193\t\tSym: 0.000661\t\tSpars: 0.004871\n",
      "\t TVw: -0.569743 | TVb: -1.974169 | GSw: -0.413859 | GSb: -0.125515 | TSUw: 0.269112 | TSUb: 0.184269\n",
      "Validating epoch 2052...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01947663359159982\n",
      "Average validation loss: 0.01889847823992469\n",
      "Training epoch 2053...\n",
      "\n",
      "Train Epoch: 2053 [0/8000 (0%)]\tBatch Loss: 0.019294\tLearning Rate (w_theta): 0.001000\t TIME:205.8s\n",
      "\t\t\t\tDisc: 0.013808\t\tSym: 0.000640\t\tSpars: 0.004847\n",
      "\t TVw: -0.569754 | TVb: -1.974161 | GSw: -0.413928 | GSb: -0.125609 | TSUw: 0.269024 | TSUb: 0.184284\n",
      "\n",
      "Train Epoch: 2053 [4000/8000 (50%)]\tBatch Loss: 0.019250\tLearning Rate (w_theta): 0.001000\t TIME:207.3s\n",
      "\t\t\t\tDisc: 0.013729\t\tSym: 0.000649\t\tSpars: 0.004872\n",
      "\t TVw: -0.569772 | TVb: -1.974156 | GSw: -0.413995 | GSb: -0.125702 | TSUw: 0.268936 | TSUb: 0.184299\n",
      "Validating epoch 2053...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01944797453056215\n",
      "Average validation loss: 0.018905113435122325\n",
      "Training epoch 2054...\n",
      "\n",
      "Train Epoch: 2054 [0/8000 (0%)]\tBatch Loss: 0.019659\tLearning Rate (w_theta): 0.001000\t TIME:209.6s\n",
      "\t\t\t\tDisc: 0.014067\t\tSym: 0.000662\t\tSpars: 0.004931\n",
      "\t TVw: -0.569797 | TVb: -1.974157 | GSw: -0.414063 | GSb: -0.125795 | TSUw: 0.268850 | TSUb: 0.184313\n",
      "\n",
      "Train Epoch: 2054 [4000/8000 (50%)]\tBatch Loss: 0.018970\tLearning Rate (w_theta): 0.001000\t TIME:211.2s\n",
      "\t\t\t\tDisc: 0.013519\t\tSym: 0.000617\t\tSpars: 0.004834\n",
      "\t TVw: -0.569816 | TVb: -1.974154 | GSw: -0.414130 | GSb: -0.125888 | TSUw: 0.268764 | TSUb: 0.184326\n",
      "Validating epoch 2054...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019414879524874\n",
      "Average validation loss: 0.01889242715136942\n",
      "Training epoch 2055...\n",
      "\n",
      "Train Epoch: 2055 [0/8000 (0%)]\tBatch Loss: 0.018890\tLearning Rate (w_theta): 0.001000\t TIME:213.5s\n",
      "\t\t\t\tDisc: 0.013480\t\tSym: 0.000610\t\tSpars: 0.004800\n",
      "\t TVw: -0.569829 | TVb: -1.974149 | GSw: -0.414196 | GSb: -0.125979 | TSUw: 0.268678 | TSUb: 0.184340\n",
      "\n",
      "Train Epoch: 2055 [4000/8000 (50%)]\tBatch Loss: 0.019883\tLearning Rate (w_theta): 0.001000\t TIME:215.0s\n",
      "\t\t\t\tDisc: 0.014308\t\tSym: 0.000654\t\tSpars: 0.004921\n",
      "\t TVw: -0.569839 | TVb: -1.974140 | GSw: -0.414263 | GSb: -0.126071 | TSUw: 0.268591 | TSUb: 0.184353\n",
      "Validating epoch 2055...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019398544275975142\n",
      "Average validation loss: 0.018869491210394787\n",
      "Training epoch 2056...\n",
      "\n",
      "Train Epoch: 2056 [0/8000 (0%)]\tBatch Loss: 0.019486\tLearning Rate (w_theta): 0.001000\t TIME:217.5s\n",
      "\t\t\t\tDisc: 0.013968\t\tSym: 0.000639\t\tSpars: 0.004880\n",
      "\t TVw: -0.569830 | TVb: -1.974119 | GSw: -0.414330 | GSb: -0.126163 | TSUw: 0.268502 | TSUb: 0.184368\n",
      "\n",
      "Train Epoch: 2056 [4000/8000 (50%)]\tBatch Loss: 0.019445\tLearning Rate (w_theta): 0.001000\t TIME:219.0s\n",
      "\t\t\t\tDisc: 0.013977\t\tSym: 0.000626\t\tSpars: 0.004843\n",
      "\t TVw: -0.569821 | TVb: -1.974099 | GSw: -0.414398 | GSb: -0.126256 | TSUw: 0.268412 | TSUb: 0.184384\n",
      "Validating epoch 2056...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019379174379116428\n",
      "Average validation loss: 0.0188480578003488\n",
      "Training epoch 2057...\n",
      "\n",
      "Train Epoch: 2057 [0/8000 (0%)]\tBatch Loss: 0.019822\tLearning Rate (w_theta): 0.001000\t TIME:221.3s\n",
      "\t\t\t\tDisc: 0.014271\t\tSym: 0.000649\t\tSpars: 0.004903\n",
      "\t TVw: -0.569820 | TVb: -1.974083 | GSw: -0.414467 | GSb: -0.126350 | TSUw: 0.268323 | TSUb: 0.184399\n",
      "\n",
      "Train Epoch: 2057 [4000/8000 (50%)]\tBatch Loss: 0.019272\tLearning Rate (w_theta): 0.001000\t TIME:222.9s\n",
      "\t\t\t\tDisc: 0.013763\t\tSym: 0.000645\t\tSpars: 0.004865\n",
      "\t TVw: -0.569813 | TVb: -1.974062 | GSw: -0.414534 | GSb: -0.126442 | TSUw: 0.268234 | TSUb: 0.184414\n",
      "Validating epoch 2057...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01936129241512496\n",
      "Average validation loss: 0.01883346444065597\n",
      "Training epoch 2058...\n",
      "\n",
      "Train Epoch: 2058 [0/8000 (0%)]\tBatch Loss: 0.018973\tLearning Rate (w_theta): 0.001000\t TIME:225.2s\n",
      "\t\t\t\tDisc: 0.013514\t\tSym: 0.000628\t\tSpars: 0.004831\n",
      "\t TVw: -0.569810 | TVb: -1.974044 | GSw: -0.414602 | GSb: -0.126535 | TSUw: 0.268145 | TSUb: 0.184428\n",
      "\n",
      "Train Epoch: 2058 [4000/8000 (50%)]\tBatch Loss: 0.019193\tLearning Rate (w_theta): 0.001000\t TIME:226.7s\n",
      "\t\t\t\tDisc: 0.013741\t\tSym: 0.000626\t\tSpars: 0.004826\n",
      "\t TVw: -0.569815 | TVb: -1.974030 | GSw: -0.414672 | GSb: -0.126631 | TSUw: 0.268055 | TSUb: 0.184443\n",
      "Validating epoch 2058...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01934751425673593\n",
      "Average validation loss: 0.018814851453133004\n",
      "Training epoch 2059...\n",
      "\n",
      "Train Epoch: 2059 [0/8000 (0%)]\tBatch Loss: 0.019567\tLearning Rate (w_theta): 0.001000\t TIME:229.0s\n",
      "\t\t\t\tDisc: 0.014024\t\tSym: 0.000658\t\tSpars: 0.004885\n",
      "\t TVw: -0.569796 | TVb: -1.974003 | GSw: -0.414739 | GSb: -0.126722 | TSUw: 0.267967 | TSUb: 0.184457\n",
      "\n",
      "Train Epoch: 2059 [4000/8000 (50%)]\tBatch Loss: 0.018911\tLearning Rate (w_theta): 0.001000\t TIME:230.5s\n",
      "\t\t\t\tDisc: 0.013503\t\tSym: 0.000621\t\tSpars: 0.004787\n",
      "\t TVw: -0.569796 | TVb: -1.973988 | GSw: -0.414806 | GSb: -0.126815 | TSUw: 0.267879 | TSUb: 0.184471\n",
      "Validating epoch 2059...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019334166425885535\n",
      "Average validation loss: 0.018806216795812594\n",
      "Training epoch 2060...\n",
      "\n",
      "Train Epoch: 2060 [0/8000 (0%)]\tBatch Loss: 0.018964\tLearning Rate (w_theta): 0.001000\t TIME:233.1s\n",
      "\t\t\t\tDisc: 0.013499\t\tSym: 0.000637\t\tSpars: 0.004829\n",
      "\t TVw: -0.569812 | TVb: -1.973983 | GSw: -0.414876 | GSb: -0.126911 | TSUw: 0.267791 | TSUb: 0.184484\n",
      "\n",
      "Train Epoch: 2060 [4000/8000 (50%)]\tBatch Loss: 0.019651\tLearning Rate (w_theta): 0.001000\t TIME:234.6s\n",
      "\t\t\t\tDisc: 0.014185\t\tSym: 0.000636\t\tSpars: 0.004829\n",
      "\t TVw: -0.569825 | TVb: -1.973976 | GSw: -0.414944 | GSb: -0.127005 | TSUw: 0.267704 | TSUb: 0.184497\n",
      "Validating epoch 2060...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019317930893349787\n",
      "Average validation loss: 0.018841770645100467\n",
      "Training epoch 2061...\n",
      "\n",
      "Train Epoch: 2061 [0/8000 (0%)]\tBatch Loss: 0.019354\tLearning Rate (w_theta): 0.001000\t TIME:237.6s\n",
      "\t\t\t\tDisc: 0.013854\t\tSym: 0.000645\t\tSpars: 0.004855\n",
      "\t TVw: -0.569818 | TVb: -1.973956 | GSw: -0.415011 | GSb: -0.127098 | TSUw: 0.267616 | TSUb: 0.184511\n",
      "\n",
      "Train Epoch: 2061 [4000/8000 (50%)]\tBatch Loss: 0.019362\tLearning Rate (w_theta): 0.001000\t TIME:239.1s\n",
      "\t\t\t\tDisc: 0.013918\t\tSym: 0.000638\t\tSpars: 0.004806\n",
      "\t TVw: -0.569819 | TVb: -1.973942 | GSw: -0.415079 | GSb: -0.127192 | TSUw: 0.267527 | TSUb: 0.184524\n",
      "Validating epoch 2061...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019305318911526256\n",
      "Average validation loss: 0.018787587402128707\n",
      "Training epoch 2062...\n",
      "\n",
      "Train Epoch: 2062 [0/8000 (0%)]\tBatch Loss: 0.019287\tLearning Rate (w_theta): 0.001000\t TIME:241.5s\n",
      "\t\t\t\tDisc: 0.013819\t\tSym: 0.000640\t\tSpars: 0.004828\n",
      "\t TVw: -0.569827 | TVb: -1.973932 | GSw: -0.415150 | GSb: -0.127288 | TSUw: 0.267437 | TSUb: 0.184539\n",
      "\n",
      "Train Epoch: 2062 [4000/8000 (50%)]\tBatch Loss: 0.019317\tLearning Rate (w_theta): 0.001000\t TIME:243.0s\n",
      "\t\t\t\tDisc: 0.013853\t\tSym: 0.000639\t\tSpars: 0.004825\n",
      "\t TVw: -0.569827 | TVb: -1.973915 | GSw: -0.415220 | GSb: -0.127384 | TSUw: 0.267346 | TSUb: 0.184554\n",
      "Validating epoch 2062...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019299066277448394\n",
      "Average validation loss: 0.018808327498316967\n",
      "Training epoch 2063...\n",
      "\n",
      "Train Epoch: 2063 [0/8000 (0%)]\tBatch Loss: 0.019694\tLearning Rate (w_theta): 0.001000\t TIME:245.3s\n",
      "\t\t\t\tDisc: 0.014166\t\tSym: 0.000653\t\tSpars: 0.004875\n",
      "\t TVw: -0.569835 | TVb: -1.973904 | GSw: -0.415290 | GSb: -0.127480 | TSUw: 0.267255 | TSUb: 0.184569\n",
      "\n",
      "Train Epoch: 2063 [4000/8000 (50%)]\tBatch Loss: 0.019328\tLearning Rate (w_theta): 0.001000\t TIME:246.9s\n",
      "\t\t\t\tDisc: 0.013845\t\tSym: 0.000644\t\tSpars: 0.004839\n",
      "\t TVw: -0.569850 | TVb: -1.973900 | GSw: -0.415361 | GSb: -0.127578 | TSUw: 0.267164 | TSUb: 0.184583\n",
      "Validating epoch 2063...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019295831514871947\n",
      "Average validation loss: 0.018788424207441933\n",
      "Training epoch 2064...\n",
      "\n",
      "Train Epoch: 2064 [0/8000 (0%)]\tBatch Loss: 0.019307\tLearning Rate (w_theta): 0.001000\t TIME:249.3s\n",
      "\t\t\t\tDisc: 0.013843\t\tSym: 0.000634\t\tSpars: 0.004830\n",
      "\t TVw: -0.569857 | TVb: -1.973890 | GSw: -0.415431 | GSb: -0.127673 | TSUw: 0.267074 | TSUb: 0.184597\n",
      "\n",
      "Train Epoch: 2064 [4000/8000 (50%)]\tBatch Loss: 0.019713\tLearning Rate (w_theta): 0.001000\t TIME:250.8s\n",
      "\t\t\t\tDisc: 0.014244\t\tSym: 0.000643\t\tSpars: 0.004826\n",
      "\t TVw: -0.569860 | TVb: -1.973873 | GSw: -0.415501 | GSb: -0.127770 | TSUw: 0.266982 | TSUb: 0.184612\n",
      "Validating epoch 2064...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019285296526618357\n",
      "Average validation loss: 0.018783802900208164\n",
      "Training epoch 2065...\n",
      "\n",
      "Train Epoch: 2065 [0/8000 (0%)]\tBatch Loss: 0.019291\tLearning Rate (w_theta): 0.001000\t TIME:253.1s\n",
      "\t\t\t\tDisc: 0.013841\t\tSym: 0.000637\t\tSpars: 0.004812\n",
      "\t TVw: -0.569869 | TVb: -1.973863 | GSw: -0.415571 | GSb: -0.127866 | TSUw: 0.266892 | TSUb: 0.184626\n",
      "\n",
      "Train Epoch: 2065 [4000/8000 (50%)]\tBatch Loss: 0.019455\tLearning Rate (w_theta): 0.001000\t TIME:254.6s\n",
      "\t\t\t\tDisc: 0.013986\t\tSym: 0.000640\t\tSpars: 0.004829\n",
      "\t TVw: -0.569876 | TVb: -1.973851 | GSw: -0.415642 | GSb: -0.127964 | TSUw: 0.266800 | TSUb: 0.184641\n",
      "Validating epoch 2065...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019267511472632233\n",
      "Average validation loss: 0.018760248560057563\n",
      "Training epoch 2066...\n",
      "\n",
      "Train Epoch: 2066 [0/8000 (0%)]\tBatch Loss: 0.019172\tLearning Rate (w_theta): 0.001000\t TIME:257.0s\n",
      "\t\t\t\tDisc: 0.013691\t\tSym: 0.000640\t\tSpars: 0.004840\n",
      "\t TVw: -0.569876 | TVb: -1.973836 | GSw: -0.415711 | GSb: -0.128059 | TSUw: 0.266710 | TSUb: 0.184655\n",
      "\n",
      "Train Epoch: 2066 [4000/8000 (50%)]\tBatch Loss: 0.019321\tLearning Rate (w_theta): 0.001000\t TIME:258.6s\n",
      "\t\t\t\tDisc: 0.013893\t\tSym: 0.000628\t\tSpars: 0.004800\n",
      "\t TVw: -0.569867 | TVb: -1.973816 | GSw: -0.415780 | GSb: -0.128153 | TSUw: 0.266621 | TSUb: 0.184668\n",
      "Validating epoch 2066...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019270467130453835\n",
      "Average validation loss: 0.01880466829245006\n",
      "Training epoch 2067...\n",
      "\n",
      "Train Epoch: 2067 [0/8000 (0%)]\tBatch Loss: 0.018896\tLearning Rate (w_theta): 0.001000\t TIME:260.9s\n",
      "\t\t\t\tDisc: 0.013506\t\tSym: 0.000623\t\tSpars: 0.004767\n",
      "\t TVw: -0.569879 | TVb: -1.973808 | GSw: -0.415851 | GSb: -0.128251 | TSUw: 0.266530 | TSUb: 0.184682\n",
      "\n",
      "Train Epoch: 2067 [4000/8000 (50%)]\tBatch Loss: 0.019450\tLearning Rate (w_theta): 0.001000\t TIME:262.4s\n",
      "\t\t\t\tDisc: 0.013914\t\tSym: 0.000661\t\tSpars: 0.004875\n",
      "\t TVw: -0.569891 | TVb: -1.973798 | GSw: -0.415924 | GSb: -0.128351 | TSUw: 0.266436 | TSUb: 0.184697\n",
      "Validating epoch 2067...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019271187010882606\n",
      "Average validation loss: 0.018783869807338656\n",
      "Training epoch 2068...\n",
      "\n",
      "Train Epoch: 2068 [0/8000 (0%)]\tBatch Loss: 0.019155\tLearning Rate (w_theta): 0.001000\t TIME:264.8s\n",
      "\t\t\t\tDisc: 0.013722\t\tSym: 0.000629\t\tSpars: 0.004804\n",
      "\t TVw: -0.569895 | TVb: -1.973784 | GSw: -0.415994 | GSb: -0.128447 | TSUw: 0.266344 | TSUb: 0.184712\n",
      "\n",
      "Train Epoch: 2068 [4000/8000 (50%)]\tBatch Loss: 0.018871\tLearning Rate (w_theta): 0.001000\t TIME:266.3s\n",
      "\t\t\t\tDisc: 0.013505\t\tSym: 0.000612\t\tSpars: 0.004754\n",
      "\t TVw: -0.569903 | TVb: -1.973773 | GSw: -0.416066 | GSb: -0.128545 | TSUw: 0.266252 | TSUb: 0.184726\n",
      "Validating epoch 2068...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01928645610797618\n",
      "Average validation loss: 0.01879259933625845\n",
      "Training epoch 2069...\n",
      "\n",
      "Train Epoch: 2069 [0/8000 (0%)]\tBatch Loss: 0.019043\tLearning Rate (w_theta): 0.001000\t TIME:268.7s\n",
      "\t\t\t\tDisc: 0.013624\t\tSym: 0.000623\t\tSpars: 0.004797\n",
      "\t TVw: -0.569918 | TVb: -1.973768 | GSw: -0.416135 | GSb: -0.128641 | TSUw: 0.266162 | TSUb: 0.184739\n",
      "\n",
      "Train Epoch: 2069 [4000/8000 (50%)]\tBatch Loss: 0.019547\tLearning Rate (w_theta): 0.001000\t TIME:270.2s\n",
      "\t\t\t\tDisc: 0.014062\t\tSym: 0.000635\t\tSpars: 0.004849\n",
      "\t TVw: -0.569943 | TVb: -1.973769 | GSw: -0.416206 | GSb: -0.128739 | TSUw: 0.266072 | TSUb: 0.184752\n",
      "Validating epoch 2069...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01926546574554321\n",
      "Average validation loss: 0.0187526162484905\n",
      "Training epoch 2070...\n",
      "\n",
      "Train Epoch: 2070 [0/8000 (0%)]\tBatch Loss: 0.019686\tLearning Rate (w_theta): 0.001000\t TIME:272.6s\n",
      "\t\t\t\tDisc: 0.014160\t\tSym: 0.000656\t\tSpars: 0.004870\n",
      "\t TVw: -0.569950 | TVb: -1.973759 | GSw: -0.416277 | GSb: -0.128836 | TSUw: 0.265980 | TSUb: 0.184766\n",
      "\n",
      "Train Epoch: 2070 [4000/8000 (50%)]\tBatch Loss: 0.019350\tLearning Rate (w_theta): 0.001000\t TIME:274.2s\n",
      "\t\t\t\tDisc: 0.013894\t\tSym: 0.000632\t\tSpars: 0.004824\n",
      "\t TVw: -0.569948 | TVb: -1.973742 | GSw: -0.416347 | GSb: -0.128932 | TSUw: 0.265887 | TSUb: 0.184780\n",
      "Validating epoch 2070...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01923787904964556\n",
      "Average validation loss: 0.018732089570596352\n",
      "Training epoch 2071...\n",
      "\n",
      "Train Epoch: 2071 [0/8000 (0%)]\tBatch Loss: 0.019035\tLearning Rate (w_theta): 0.001000\t TIME:277.0s\n",
      "\t\t\t\tDisc: 0.013600\t\tSym: 0.000631\t\tSpars: 0.004803\n",
      "\t TVw: -0.569945 | TVb: -1.973725 | GSw: -0.416419 | GSb: -0.129030 | TSUw: 0.265794 | TSUb: 0.184795\n",
      "\n",
      "Train Epoch: 2071 [4000/8000 (50%)]\tBatch Loss: 0.019678\tLearning Rate (w_theta): 0.001000\t TIME:278.6s\n",
      "\t\t\t\tDisc: 0.014184\t\tSym: 0.000645\t\tSpars: 0.004848\n",
      "\t TVw: -0.569947 | TVb: -1.973710 | GSw: -0.416490 | GSb: -0.129128 | TSUw: 0.265701 | TSUb: 0.184809\n",
      "Validating epoch 2071...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019219835018097795\n",
      "Average validation loss: 0.01872247318657113\n",
      "Training epoch 2072...\n",
      "\n",
      "Train Epoch: 2072 [0/8000 (0%)]\tBatch Loss: 0.019639\tLearning Rate (w_theta): 0.001000\t TIME:281.0s\n",
      "\t\t\t\tDisc: 0.014222\t\tSym: 0.000631\t\tSpars: 0.004785\n",
      "\t TVw: -0.569935 | TVb: -1.973686 | GSw: -0.416562 | GSb: -0.129226 | TSUw: 0.265606 | TSUb: 0.184824\n",
      "\n",
      "Train Epoch: 2072 [4000/8000 (50%)]\tBatch Loss: 0.019440\tLearning Rate (w_theta): 0.001000\t TIME:282.6s\n",
      "\t\t\t\tDisc: 0.014016\t\tSym: 0.000631\t\tSpars: 0.004793\n",
      "\t TVw: -0.569930 | TVb: -1.973664 | GSw: -0.416634 | GSb: -0.129325 | TSUw: 0.265512 | TSUb: 0.184839\n",
      "Validating epoch 2072...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019211355606578297\n",
      "Average validation loss: 0.018716158722885748\n",
      "Training epoch 2073...\n",
      "\n",
      "Train Epoch: 2073 [0/8000 (0%)]\tBatch Loss: 0.019926\tLearning Rate (w_theta): 0.001000\t TIME:284.9s\n",
      "\t\t\t\tDisc: 0.014419\t\tSym: 0.000664\t\tSpars: 0.004842\n",
      "\t TVw: -0.569934 | TVb: -1.973652 | GSw: -0.416706 | GSb: -0.129422 | TSUw: 0.265420 | TSUb: 0.184853\n",
      "\n",
      "Train Epoch: 2073 [4000/8000 (50%)]\tBatch Loss: 0.019576\tLearning Rate (w_theta): 0.001000\t TIME:286.5s\n",
      "\t\t\t\tDisc: 0.014176\t\tSym: 0.000629\t\tSpars: 0.004772\n",
      "\t TVw: -0.569945 | TVb: -1.973643 | GSw: -0.416778 | GSb: -0.129522 | TSUw: 0.265326 | TSUb: 0.184867\n",
      "Validating epoch 2073...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019227688896114013\n",
      "Average validation loss: 0.018695325371853803\n",
      "Training epoch 2074...\n",
      "\n",
      "Train Epoch: 2074 [0/8000 (0%)]\tBatch Loss: 0.018956\tLearning Rate (w_theta): 0.001000\t TIME:288.8s\n",
      "\t\t\t\tDisc: 0.013605\t\tSym: 0.000612\t\tSpars: 0.004739\n",
      "\t TVw: -0.569950 | TVb: -1.973631 | GSw: -0.416850 | GSb: -0.129620 | TSUw: 0.265234 | TSUb: 0.184880\n",
      "\n",
      "Train Epoch: 2074 [4000/8000 (50%)]\tBatch Loss: 0.019351\tLearning Rate (w_theta): 0.001000\t TIME:290.3s\n",
      "\t\t\t\tDisc: 0.013894\t\tSym: 0.000636\t\tSpars: 0.004821\n",
      "\t TVw: -0.569958 | TVb: -1.973620 | GSw: -0.416919 | GSb: -0.129716 | TSUw: 0.265144 | TSUb: 0.184892\n",
      "Validating epoch 2074...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019219406108710733\n",
      "Average validation loss: 0.018703276897505297\n",
      "Training epoch 2075...\n",
      "\n",
      "Train Epoch: 2075 [0/8000 (0%)]\tBatch Loss: 0.019139\tLearning Rate (w_theta): 0.001000\t TIME:292.7s\n",
      "\t\t\t\tDisc: 0.013718\t\tSym: 0.000631\t\tSpars: 0.004790\n",
      "\t TVw: -0.569970 | TVb: -1.973612 | GSw: -0.416991 | GSb: -0.129815 | TSUw: 0.265051 | TSUb: 0.184906\n",
      "\n",
      "Train Epoch: 2075 [4000/8000 (50%)]\tBatch Loss: 0.018874\tLearning Rate (w_theta): 0.001000\t TIME:294.2s\n",
      "\t\t\t\tDisc: 0.013523\t\tSym: 0.000601\t\tSpars: 0.004750\n",
      "\t TVw: -0.569977 | TVb: -1.973600 | GSw: -0.417064 | GSb: -0.129915 | TSUw: 0.264956 | TSUb: 0.184920\n",
      "Validating epoch 2075...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019224229826131107\n",
      "Average validation loss: 0.01868865369158677\n",
      "Training epoch 2076...\n",
      "\n",
      "Train Epoch: 2076 [0/8000 (0%)]\tBatch Loss: 0.019350\tLearning Rate (w_theta): 0.001000\t TIME:296.7s\n",
      "\t\t\t\tDisc: 0.013898\t\tSym: 0.000642\t\tSpars: 0.004809\n",
      "\t TVw: -0.569982 | TVb: -1.973588 | GSw: -0.417138 | GSb: -0.130015 | TSUw: 0.264861 | TSUb: 0.184935\n",
      "\n",
      "Train Epoch: 2076 [4000/8000 (50%)]\tBatch Loss: 0.018585\tLearning Rate (w_theta): 0.001000\t TIME:298.2s\n",
      "\t\t\t\tDisc: 0.013304\t\tSym: 0.000591\t\tSpars: 0.004690\n",
      "\t TVw: -0.569986 | TVb: -1.973574 | GSw: -0.417213 | GSb: -0.130117 | TSUw: 0.264765 | TSUb: 0.184950\n",
      "Validating epoch 2076...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019195030406779216\n",
      "Average validation loss: 0.01867689110858913\n",
      "Training epoch 2077...\n",
      "\n",
      "Train Epoch: 2077 [0/8000 (0%)]\tBatch Loss: 0.018915\tLearning Rate (w_theta): 0.001000\t TIME:300.6s\n",
      "\t\t\t\tDisc: 0.013509\t\tSym: 0.000623\t\tSpars: 0.004782\n",
      "\t TVw: -0.569972 | TVb: -1.973549 | GSw: -0.417284 | GSb: -0.130215 | TSUw: 0.264670 | TSUb: 0.184964\n",
      "\n",
      "Train Epoch: 2077 [4000/8000 (50%)]\tBatch Loss: 0.018859\tLearning Rate (w_theta): 0.001000\t TIME:302.1s\n",
      "\t\t\t\tDisc: 0.013540\t\tSym: 0.000607\t\tSpars: 0.004713\n",
      "\t TVw: -0.569969 | TVb: -1.973531 | GSw: -0.417356 | GSb: -0.130314 | TSUw: 0.264577 | TSUb: 0.184977\n",
      "Validating epoch 2077...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019165275596545267\n",
      "Average validation loss: 0.018669013729020516\n",
      "Training epoch 2078...\n",
      "\n",
      "Train Epoch: 2078 [0/8000 (0%)]\tBatch Loss: 0.018738\tLearning Rate (w_theta): 0.001000\t TIME:304.4s\n",
      "\t\t\t\tDisc: 0.013403\t\tSym: 0.000606\t\tSpars: 0.004729\n",
      "\t TVw: -0.569983 | TVb: -1.973525 | GSw: -0.417429 | GSb: -0.130414 | TSUw: 0.264483 | TSUb: 0.184991\n",
      "\n",
      "Train Epoch: 2078 [4000/8000 (50%)]\tBatch Loss: 0.019163\tLearning Rate (w_theta): 0.001000\t TIME:305.9s\n",
      "\t\t\t\tDisc: 0.013800\t\tSym: 0.000613\t\tSpars: 0.004750\n",
      "\t TVw: -0.569997 | TVb: -1.973521 | GSw: -0.417502 | GSb: -0.130514 | TSUw: 0.264389 | TSUb: 0.185004\n",
      "Validating epoch 2078...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019156337974604996\n",
      "Average validation loss: 0.01865841231993296\n",
      "Training epoch 2079...\n",
      "\n",
      "Train Epoch: 2079 [0/8000 (0%)]\tBatch Loss: 0.019608\tLearning Rate (w_theta): 0.001000\t TIME:308.3s\n",
      "\t\t\t\tDisc: 0.014153\t\tSym: 0.000641\t\tSpars: 0.004814\n",
      "\t TVw: -0.569995 | TVb: -1.973504 | GSw: -0.417575 | GSb: -0.130614 | TSUw: 0.264294 | TSUb: 0.185018\n",
      "\n",
      "Train Epoch: 2079 [4000/8000 (50%)]\tBatch Loss: 0.018945\tLearning Rate (w_theta): 0.001000\t TIME:309.8s\n",
      "\t\t\t\tDisc: 0.013615\t\tSym: 0.000611\t\tSpars: 0.004719\n",
      "\t TVw: -0.569990 | TVb: -1.973487 | GSw: -0.417648 | GSb: -0.130714 | TSUw: 0.264199 | TSUb: 0.185032\n",
      "Validating epoch 2079...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019148659232502075\n",
      "Average validation loss: 0.018654499213550037\n",
      "Training epoch 2080...\n",
      "\n",
      "Train Epoch: 2080 [0/8000 (0%)]\tBatch Loss: 0.018654\tLearning Rate (w_theta): 0.001000\t TIME:312.3s\n",
      "\t\t\t\tDisc: 0.013283\t\tSym: 0.000624\t\tSpars: 0.004748\n",
      "\t TVw: -0.570002 | TVb: -1.973477 | GSw: -0.417722 | GSb: -0.130815 | TSUw: 0.264104 | TSUb: 0.185046\n",
      "\n",
      "Train Epoch: 2080 [4000/8000 (50%)]\tBatch Loss: 0.019049\tLearning Rate (w_theta): 0.001000\t TIME:313.9s\n",
      "\t\t\t\tDisc: 0.013718\t\tSym: 0.000608\t\tSpars: 0.004723\n",
      "\t TVw: -0.570010 | TVb: -1.973465 | GSw: -0.417794 | GSb: -0.130915 | TSUw: 0.264010 | TSUb: 0.185059\n",
      "Validating epoch 2080...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01913710905773134\n",
      "Average validation loss: 0.018639733695992124\n",
      "Training epoch 2081...\n",
      "\n",
      "Train Epoch: 2081 [0/8000 (0%)]\tBatch Loss: 0.019321\tLearning Rate (w_theta): 0.001000\t TIME:316.7s\n",
      "\t\t\t\tDisc: 0.013912\t\tSym: 0.000634\t\tSpars: 0.004775\n",
      "\t TVw: -0.570019 | TVb: -1.973453 | GSw: -0.417868 | GSb: -0.131016 | TSUw: 0.263915 | TSUb: 0.185072\n",
      "\n",
      "Train Epoch: 2081 [4000/8000 (50%)]\tBatch Loss: 0.019269\tLearning Rate (w_theta): 0.001000\t TIME:318.3s\n",
      "\t\t\t\tDisc: 0.013831\t\tSym: 0.000637\t\tSpars: 0.004801\n",
      "\t TVw: -0.570028 | TVb: -1.973442 | GSw: -0.417941 | GSb: -0.131117 | TSUw: 0.263820 | TSUb: 0.185085\n",
      "Validating epoch 2081...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019132779093077257\n",
      "Average validation loss: 0.018649691509176065\n",
      "Training epoch 2082...\n",
      "\n",
      "Train Epoch: 2082 [0/8000 (0%)]\tBatch Loss: 0.018809\tLearning Rate (w_theta): 0.001000\t TIME:320.6s\n",
      "\t\t\t\tDisc: 0.013478\t\tSym: 0.000610\t\tSpars: 0.004720\n",
      "\t TVw: -0.570028 | TVb: -1.973426 | GSw: -0.418014 | GSb: -0.131218 | TSUw: 0.263725 | TSUb: 0.185099\n",
      "\n",
      "Train Epoch: 2082 [4000/8000 (50%)]\tBatch Loss: 0.019030\tLearning Rate (w_theta): 0.001000\t TIME:322.1s\n",
      "\t\t\t\tDisc: 0.013659\t\tSym: 0.000617\t\tSpars: 0.004754\n",
      "\t TVw: -0.570044 | TVb: -1.973420 | GSw: -0.418087 | GSb: -0.131318 | TSUw: 0.263631 | TSUb: 0.185111\n",
      "Validating epoch 2082...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01912248408766463\n",
      "Average validation loss: 0.018626324944182787\n",
      "Training epoch 2083...\n",
      "\n",
      "Train Epoch: 2083 [0/8000 (0%)]\tBatch Loss: 0.019088\tLearning Rate (w_theta): 0.001000\t TIME:324.5s\n",
      "\t\t\t\tDisc: 0.013715\t\tSym: 0.000621\t\tSpars: 0.004752\n",
      "\t TVw: -0.570053 | TVb: -1.973410 | GSw: -0.418161 | GSb: -0.131421 | TSUw: 0.263534 | TSUb: 0.185125\n",
      "\n",
      "Train Epoch: 2083 [4000/8000 (50%)]\tBatch Loss: 0.020050\tLearning Rate (w_theta): 0.001000\t TIME:326.0s\n",
      "\t\t\t\tDisc: 0.014527\t\tSym: 0.000650\t\tSpars: 0.004873\n",
      "\t TVw: -0.570062 | TVb: -1.973401 | GSw: -0.418238 | GSb: -0.131524 | TSUw: 0.263434 | TSUb: 0.185141\n",
      "Validating epoch 2083...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019546086504760037\n",
      "Average validation loss: 0.019361461863858263\n",
      "Training epoch 2084...\n",
      "\n",
      "Train Epoch: 2084 [0/8000 (0%)]\tBatch Loss: 0.019520\tLearning Rate (w_theta): 0.001000\t TIME:328.4s\n",
      "\t\t\t\tDisc: 0.014154\t\tSym: 0.000644\t\tSpars: 0.004722\n",
      "\t TVw: -0.570084 | TVb: -1.973400 | GSw: -0.418324 | GSb: -0.131635 | TSUw: 0.263326 | TSUb: 0.185162\n",
      "\n",
      "Train Epoch: 2084 [4000/8000 (50%)]\tBatch Loss: 0.019711\tLearning Rate (w_theta): 0.001000\t TIME:329.9s\n",
      "\t\t\t\tDisc: 0.014125\t\tSym: 0.000689\t\tSpars: 0.004897\n",
      "\t TVw: -0.570134 | TVb: -1.973417 | GSw: -0.418409 | GSb: -0.131747 | TSUw: 0.263218 | TSUb: 0.185182\n",
      "Validating epoch 2084...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019730918026218156\n",
      "Average validation loss: 0.018997584202169765\n",
      "Training epoch 2085...\n",
      "\n",
      "Train Epoch: 2085 [0/8000 (0%)]\tBatch Loss: 0.019380\tLearning Rate (w_theta): 0.001000\t TIME:332.2s\n",
      "\t\t\t\tDisc: 0.013866\t\tSym: 0.000629\t\tSpars: 0.004886\n",
      "\t TVw: -0.570205 | TVb: -1.973446 | GSw: -0.418490 | GSb: -0.131855 | TSUw: 0.263112 | TSUb: 0.185202\n",
      "\n",
      "Train Epoch: 2085 [4000/8000 (50%)]\tBatch Loss: 0.019293\tLearning Rate (w_theta): 0.001000\t TIME:333.7s\n",
      "\t\t\t\tDisc: 0.013825\t\tSym: 0.000604\t\tSpars: 0.004865\n",
      "\t TVw: -0.570270 | TVb: -1.973473 | GSw: -0.418570 | GSb: -0.131961 | TSUw: 0.263006 | TSUb: 0.185220\n",
      "Validating epoch 2085...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019468903763347454\n",
      "Average validation loss: 0.01881879489050441\n",
      "Training epoch 2086...\n",
      "\n",
      "Train Epoch: 2086 [0/8000 (0%)]\tBatch Loss: 0.018753\tLearning Rate (w_theta): 0.001000\t TIME:336.2s\n",
      "\t\t\t\tDisc: 0.013271\t\tSym: 0.000600\t\tSpars: 0.004882\n",
      "\t TVw: -0.570347 | TVb: -1.973509 | GSw: -0.418648 | GSb: -0.132067 | TSUw: 0.262904 | TSUb: 0.185237\n",
      "\n",
      "Train Epoch: 2086 [4000/8000 (50%)]\tBatch Loss: 0.019467\tLearning Rate (w_theta): 0.001000\t TIME:337.7s\n",
      "\t\t\t\tDisc: 0.013890\t\tSym: 0.000629\t\tSpars: 0.004948\n",
      "\t TVw: -0.570359 | TVb: -1.973505 | GSw: -0.418722 | GSb: -0.132166 | TSUw: 0.262803 | TSUb: 0.185253\n",
      "Validating epoch 2086...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01933099713804737\n",
      "Average validation loss: 0.01878890405903438\n",
      "Training epoch 2087...\n",
      "\n",
      "Train Epoch: 2087 [0/8000 (0%)]\tBatch Loss: 0.019411\tLearning Rate (w_theta): 0.001000\t TIME:340.0s\n",
      "\t\t\t\tDisc: 0.013882\t\tSym: 0.000613\t\tSpars: 0.004917\n",
      "\t TVw: -0.570338 | TVb: -1.973481 | GSw: -0.418796 | GSb: -0.132265 | TSUw: 0.262702 | TSUb: 0.185269\n",
      "\n",
      "Train Epoch: 2087 [4000/8000 (50%)]\tBatch Loss: 0.018987\tLearning Rate (w_theta): 0.001000\t TIME:341.5s\n",
      "\t\t\t\tDisc: 0.013572\t\tSym: 0.000583\t\tSpars: 0.004831\n",
      "\t TVw: -0.570319 | TVb: -1.973458 | GSw: -0.418870 | GSb: -0.132364 | TSUw: 0.262601 | TSUb: 0.185285\n",
      "Validating epoch 2087...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019269643457497425\n",
      "Average validation loss: 0.018711446280546985\n",
      "Training epoch 2088...\n",
      "\n",
      "Train Epoch: 2088 [0/8000 (0%)]\tBatch Loss: 0.018715\tLearning Rate (w_theta): 0.001000\t TIME:343.9s\n",
      "\t\t\t\tDisc: 0.013296\t\tSym: 0.000584\t\tSpars: 0.004834\n",
      "\t TVw: -0.570297 | TVb: -1.973431 | GSw: -0.418947 | GSb: -0.132465 | TSUw: 0.262499 | TSUb: 0.185301\n",
      "\n",
      "Train Epoch: 2088 [4000/8000 (50%)]\tBatch Loss: 0.019685\tLearning Rate (w_theta): 0.001000\t TIME:345.5s\n",
      "\t\t\t\tDisc: 0.014172\t\tSym: 0.000620\t\tSpars: 0.004892\n",
      "\t TVw: -0.570245 | TVb: -1.973383 | GSw: -0.419021 | GSb: -0.132564 | TSUw: 0.262397 | TSUb: 0.185317\n",
      "Validating epoch 2088...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01923398842062165\n",
      "Average validation loss: 0.018690057392654422\n",
      "Training epoch 2089...\n",
      "\n",
      "Train Epoch: 2089 [0/8000 (0%)]\tBatch Loss: 0.018833\tLearning Rate (w_theta): 0.001000\t TIME:347.8s\n",
      "\t\t\t\tDisc: 0.013433\t\tSym: 0.000606\t\tSpars: 0.004794\n",
      "\t TVw: -0.570191 | TVb: -1.973334 | GSw: -0.419093 | GSb: -0.132661 | TSUw: 0.262299 | TSUb: 0.185331\n",
      "\n",
      "Train Epoch: 2089 [4000/8000 (50%)]\tBatch Loss: 0.019145\tLearning Rate (w_theta): 0.001000\t TIME:349.3s\n",
      "\t\t\t\tDisc: 0.013756\t\tSym: 0.000601\t\tSpars: 0.004787\n",
      "\t TVw: -0.570190 | TVb: -1.973319 | GSw: -0.419166 | GSb: -0.132761 | TSUw: 0.262202 | TSUb: 0.185343\n",
      "Validating epoch 2089...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019203296522587402\n",
      "Average validation loss: 0.018654956896718575\n",
      "Training epoch 2090...\n",
      "\n",
      "Train Epoch: 2090 [0/8000 (0%)]\tBatch Loss: 0.019587\tLearning Rate (w_theta): 0.001000\t TIME:351.8s\n",
      "\t\t\t\tDisc: 0.014129\t\tSym: 0.000623\t\tSpars: 0.004835\n",
      "\t TVw: -0.570198 | TVb: -1.973309 | GSw: -0.419239 | GSb: -0.132859 | TSUw: 0.262109 | TSUb: 0.185354\n",
      "\n",
      "Train Epoch: 2090 [4000/8000 (50%)]\tBatch Loss: 0.018973\tLearning Rate (w_theta): 0.001000\t TIME:353.3s\n",
      "\t\t\t\tDisc: 0.013584\t\tSym: 0.000606\t\tSpars: 0.004783\n",
      "\t TVw: -0.570199 | TVb: -1.973295 | GSw: -0.419309 | GSb: -0.132955 | TSUw: 0.262019 | TSUb: 0.185363\n",
      "Validating epoch 2090...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01915649316178929\n",
      "Average validation loss: 0.018620524161841005\n",
      "Training epoch 2091...\n",
      "\n",
      "Train Epoch: 2091 [0/8000 (0%)]\tBatch Loss: 0.019064\tLearning Rate (w_theta): 0.001000\t TIME:356.2s\n",
      "\t\t\t\tDisc: 0.013685\t\tSym: 0.000602\t\tSpars: 0.004777\n",
      "\t TVw: -0.570194 | TVb: -1.973277 | GSw: -0.419380 | GSb: -0.133053 | TSUw: 0.261925 | TSUb: 0.185373\n",
      "\n",
      "Train Epoch: 2091 [4000/8000 (50%)]\tBatch Loss: 0.018761\tLearning Rate (w_theta): 0.001000\t TIME:357.8s\n",
      "\t\t\t\tDisc: 0.013443\t\tSym: 0.000593\t\tSpars: 0.004725\n",
      "\t TVw: -0.570194 | TVb: -1.973262 | GSw: -0.419453 | GSb: -0.133153 | TSUw: 0.261830 | TSUb: 0.185384\n",
      "Validating epoch 2091...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019122853434790664\n",
      "Average validation loss: 0.018593327970253815\n",
      "Training epoch 2092...\n",
      "\n",
      "Train Epoch: 2092 [0/8000 (0%)]\tBatch Loss: 0.019541\tLearning Rate (w_theta): 0.001000\t TIME:360.1s\n",
      "\t\t\t\tDisc: 0.014154\t\tSym: 0.000617\t\tSpars: 0.004770\n",
      "\t TVw: -0.570188 | TVb: -1.973242 | GSw: -0.419526 | GSb: -0.133252 | TSUw: 0.261736 | TSUb: 0.185395\n",
      "\n",
      "Train Epoch: 2092 [4000/8000 (50%)]\tBatch Loss: 0.019202\tLearning Rate (w_theta): 0.001000\t TIME:361.7s\n",
      "\t\t\t\tDisc: 0.013804\t\tSym: 0.000618\t\tSpars: 0.004780\n",
      "\t TVw: -0.570174 | TVb: -1.973216 | GSw: -0.419598 | GSb: -0.133351 | TSUw: 0.261642 | TSUb: 0.185405\n",
      "Validating epoch 2092...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01910088522103825\n",
      "Average validation loss: 0.018569149219033167\n",
      "Training epoch 2093...\n",
      "\n",
      "Train Epoch: 2093 [0/8000 (0%)]\tBatch Loss: 0.019278\tLearning Rate (w_theta): 0.001000\t TIME:364.1s\n",
      "\t\t\t\tDisc: 0.013826\t\tSym: 0.000637\t\tSpars: 0.004814\n",
      "\t TVw: -0.570190 | TVb: -1.973210 | GSw: -0.419673 | GSb: -0.133454 | TSUw: 0.261547 | TSUb: 0.185416\n",
      "\n",
      "Train Epoch: 2093 [4000/8000 (50%)]\tBatch Loss: 0.018920\tLearning Rate (w_theta): 0.001000\t TIME:365.6s\n",
      "\t\t\t\tDisc: 0.013595\t\tSym: 0.000597\t\tSpars: 0.004728\n",
      "\t TVw: -0.570189 | TVb: -1.973190 | GSw: -0.419747 | GSb: -0.133555 | TSUw: 0.261452 | TSUb: 0.185427\n",
      "Validating epoch 2093...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019092449006616587\n",
      "Average validation loss: 0.018597879216191587\n",
      "Training epoch 2094...\n",
      "\n",
      "Train Epoch: 2094 [0/8000 (0%)]\tBatch Loss: 0.019156\tLearning Rate (w_theta): 0.001000\t TIME:368.0s\n",
      "\t\t\t\tDisc: 0.013794\t\tSym: 0.000618\t\tSpars: 0.004744\n",
      "\t TVw: -0.570178 | TVb: -1.973167 | GSw: -0.419820 | GSb: -0.133655 | TSUw: 0.261356 | TSUb: 0.185438\n",
      "\n",
      "Train Epoch: 2094 [4000/8000 (50%)]\tBatch Loss: 0.019363\tLearning Rate (w_theta): 0.001000\t TIME:369.5s\n",
      "\t\t\t\tDisc: 0.014024\t\tSym: 0.000616\t\tSpars: 0.004723\n",
      "\t TVw: -0.570185 | TVb: -1.973156 | GSw: -0.419897 | GSb: -0.133759 | TSUw: 0.261258 | TSUb: 0.185450\n",
      "Validating epoch 2094...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019074043166367547\n",
      "Average validation loss: 0.018550350289898033\n",
      "Training epoch 2095...\n",
      "\n",
      "Train Epoch: 2095 [0/8000 (0%)]\tBatch Loss: 0.019204\tLearning Rate (w_theta): 0.001000\t TIME:371.8s\n",
      "\t\t\t\tDisc: 0.013892\t\tSym: 0.000611\t\tSpars: 0.004700\n",
      "\t TVw: -0.570183 | TVb: -1.973138 | GSw: -0.419972 | GSb: -0.133863 | TSUw: 0.261160 | TSUb: 0.185462\n",
      "\n",
      "Train Epoch: 2095 [4000/8000 (50%)]\tBatch Loss: 0.019453\tLearning Rate (w_theta): 0.001000\t TIME:373.3s\n",
      "\t\t\t\tDisc: 0.014095\t\tSym: 0.000621\t\tSpars: 0.004737\n",
      "\t TVw: -0.570176 | TVb: -1.973117 | GSw: -0.420048 | GSb: -0.133966 | TSUw: 0.261062 | TSUb: 0.185474\n",
      "Validating epoch 2095...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019068349697654082\n",
      "Average validation loss: 0.018538293485664593\n",
      "Training epoch 2096...\n",
      "\n",
      "Train Epoch: 2096 [0/8000 (0%)]\tBatch Loss: 0.019431\tLearning Rate (w_theta): 0.001000\t TIME:375.7s\n",
      "\t\t\t\tDisc: 0.014054\t\tSym: 0.000626\t\tSpars: 0.004751\n",
      "\t TVw: -0.570184 | TVb: -1.973105 | GSw: -0.420124 | GSb: -0.134070 | TSUw: 0.260964 | TSUb: 0.185486\n",
      "\n",
      "Train Epoch: 2096 [4000/8000 (50%)]\tBatch Loss: 0.018612\tLearning Rate (w_theta): 0.001000\t TIME:377.2s\n",
      "\t\t\t\tDisc: 0.013384\t\tSym: 0.000588\t\tSpars: 0.004639\n",
      "\t TVw: -0.570193 | TVb: -1.973095 | GSw: -0.420200 | GSb: -0.134175 | TSUw: 0.260867 | TSUb: 0.185497\n",
      "Validating epoch 2096...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019047611850819712\n",
      "Average validation loss: 0.018530960313764208\n",
      "Training epoch 2097...\n",
      "\n",
      "Train Epoch: 2097 [0/8000 (0%)]\tBatch Loss: 0.018961\tLearning Rate (w_theta): 0.001000\t TIME:379.7s\n",
      "\t\t\t\tDisc: 0.013680\t\tSym: 0.000605\t\tSpars: 0.004675\n",
      "\t TVw: -0.570189 | TVb: -1.973076 | GSw: -0.420277 | GSb: -0.134280 | TSUw: 0.260767 | TSUb: 0.185510\n",
      "\n",
      "Train Epoch: 2097 [4000/8000 (50%)]\tBatch Loss: 0.019173\tLearning Rate (w_theta): 0.001000\t TIME:381.2s\n",
      "\t\t\t\tDisc: 0.013827\t\tSym: 0.000624\t\tSpars: 0.004722\n",
      "\t TVw: -0.570201 | TVb: -1.973066 | GSw: -0.420356 | GSb: -0.134387 | TSUw: 0.260666 | TSUb: 0.185524\n",
      "Validating epoch 2097...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019016436829864106\n",
      "Average validation loss: 0.018508991305036127\n",
      "Training epoch 2098...\n",
      "\n",
      "Train Epoch: 2098 [0/8000 (0%)]\tBatch Loss: 0.019312\tLearning Rate (w_theta): 0.001000\t TIME:383.5s\n",
      "\t\t\t\tDisc: 0.013958\t\tSym: 0.000627\t\tSpars: 0.004727\n",
      "\t TVw: -0.570201 | TVb: -1.973049 | GSw: -0.420433 | GSb: -0.134493 | TSUw: 0.260566 | TSUb: 0.185536\n",
      "\n",
      "Train Epoch: 2098 [4000/8000 (50%)]\tBatch Loss: 0.019062\tLearning Rate (w_theta): 0.001000\t TIME:385.0s\n",
      "\t\t\t\tDisc: 0.013703\t\tSym: 0.000629\t\tSpars: 0.004730\n",
      "\t TVw: -0.570202 | TVb: -1.973033 | GSw: -0.420509 | GSb: -0.134597 | TSUw: 0.260467 | TSUb: 0.185548\n",
      "Validating epoch 2098...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019015898850380027\n",
      "Average validation loss: 0.018510313755480134\n",
      "Training epoch 2099...\n",
      "\n",
      "Train Epoch: 2099 [0/8000 (0%)]\tBatch Loss: 0.018912\tLearning Rate (w_theta): 0.001000\t TIME:387.4s\n",
      "\t\t\t\tDisc: 0.013555\t\tSym: 0.000633\t\tSpars: 0.004724\n",
      "\t TVw: -0.570227 | TVb: -1.973031 | GSw: -0.420589 | GSb: -0.134705 | TSUw: 0.260367 | TSUb: 0.185560\n",
      "\n",
      "Train Epoch: 2099 [4000/8000 (50%)]\tBatch Loss: 0.019275\tLearning Rate (w_theta): 0.001000\t TIME:388.9s\n",
      "\t\t\t\tDisc: 0.013919\t\tSym: 0.000628\t\tSpars: 0.004728\n",
      "\t TVw: -0.570233 | TVb: -1.973017 | GSw: -0.420667 | GSb: -0.134813 | TSUw: 0.260266 | TSUb: 0.185573\n",
      "Validating epoch 2099...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018990016622396924\n",
      "Average validation loss: 0.018511727483049367\n",
      "Training epoch 2100...\n",
      "\n",
      "Train Epoch: 2100 [0/8000 (0%)]\tBatch Loss: 0.019274\tLearning Rate (w_theta): 0.001000\t TIME:391.2s\n",
      "\t\t\t\tDisc: 0.013968\t\tSym: 0.000619\t\tSpars: 0.004686\n",
      "\t TVw: -0.570233 | TVb: -1.973000 | GSw: -0.420745 | GSb: -0.134919 | TSUw: 0.260165 | TSUb: 0.185586\n",
      "\n",
      "Train Epoch: 2100 [4000/8000 (50%)]\tBatch Loss: 0.019075\tLearning Rate (w_theta): 0.001000\t TIME:392.8s\n",
      "\t\t\t\tDisc: 0.013774\t\tSym: 0.000616\t\tSpars: 0.004686\n",
      "\t TVw: -0.570240 | TVb: -1.972990 | GSw: -0.420823 | GSb: -0.135025 | TSUw: 0.260066 | TSUb: 0.185597\n",
      "Validating epoch 2100...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018974231340135456\n",
      "Average validation loss: 0.018484554730975947\n",
      "Training epoch 2101...\n",
      "\n",
      "Train Epoch: 2101 [0/8000 (0%)]\tBatch Loss: 0.018593\tLearning Rate (w_theta): 0.001000\t TIME:395.8s\n",
      "\t\t\t\tDisc: 0.013347\t\tSym: 0.000599\t\tSpars: 0.004647\n",
      "\t TVw: -0.570262 | TVb: -1.972986 | GSw: -0.420902 | GSb: -0.135134 | TSUw: 0.259965 | TSUb: 0.185610\n",
      "\n",
      "Train Epoch: 2101 [4000/8000 (50%)]\tBatch Loss: 0.019428\tLearning Rate (w_theta): 0.001000\t TIME:397.3s\n",
      "\t\t\t\tDisc: 0.014035\t\tSym: 0.000646\t\tSpars: 0.004747\n",
      "\t TVw: -0.570279 | TVb: -1.972979 | GSw: -0.420985 | GSb: -0.135245 | TSUw: 0.259859 | TSUb: 0.185625\n",
      "Validating epoch 2101...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019214709411781924\n",
      "Average validation loss: 0.01890470318834084\n",
      "Training epoch 2102...\n",
      "\n",
      "Train Epoch: 2102 [0/8000 (0%)]\tBatch Loss: 0.019189\tLearning Rate (w_theta): 0.001000\t TIME:399.6s\n",
      "\t\t\t\tDisc: 0.013768\t\tSym: 0.000655\t\tSpars: 0.004766\n",
      "\t TVw: -0.570307 | TVb: -1.972979 | GSw: -0.421067 | GSb: -0.135356 | TSUw: 0.259753 | TSUb: 0.185640\n",
      "\n",
      "Train Epoch: 2102 [4000/8000 (50%)]\tBatch Loss: 0.018956\tLearning Rate (w_theta): 0.001000\t TIME:401.2s\n",
      "\t\t\t\tDisc: 0.013685\t\tSym: 0.000606\t\tSpars: 0.004666\n",
      "\t TVw: -0.570368 | TVb: -1.973002 | GSw: -0.421150 | GSb: -0.135468 | TSUw: 0.259646 | TSUb: 0.185656\n",
      "Validating epoch 2102...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019299856758435537\n",
      "Average validation loss: 0.018726368341598635\n",
      "Training epoch 2103...\n",
      "\n",
      "Train Epoch: 2103 [0/8000 (0%)]\tBatch Loss: 0.019523\tLearning Rate (w_theta): 0.001000\t TIME:403.6s\n",
      "\t\t\t\tDisc: 0.014112\t\tSym: 0.000619\t\tSpars: 0.004792\n",
      "\t TVw: -0.570444 | TVb: -1.973035 | GSw: -0.421234 | GSb: -0.135581 | TSUw: 0.259539 | TSUb: 0.185671\n",
      "\n",
      "Train Epoch: 2103 [4000/8000 (50%)]\tBatch Loss: 0.019150\tLearning Rate (w_theta): 0.001000\t TIME:405.1s\n",
      "\t\t\t\tDisc: 0.013730\t\tSym: 0.000606\t\tSpars: 0.004815\n",
      "\t TVw: -0.570487 | TVb: -1.973048 | GSw: -0.421313 | GSb: -0.135689 | TSUw: 0.259433 | TSUb: 0.185686\n",
      "Validating epoch 2103...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019218948550191087\n",
      "Average validation loss: 0.018650771907838207\n",
      "Training epoch 2104...\n",
      "\n",
      "Train Epoch: 2104 [0/8000 (0%)]\tBatch Loss: 0.019075\tLearning Rate (w_theta): 0.001000\t TIME:407.5s\n",
      "\t\t\t\tDisc: 0.013733\t\tSym: 0.000588\t\tSpars: 0.004754\n",
      "\t TVw: -0.570536 | TVb: -1.973065 | GSw: -0.421394 | GSb: -0.135797 | TSUw: 0.259327 | TSUb: 0.185701\n",
      "\n",
      "Train Epoch: 2104 [4000/8000 (50%)]\tBatch Loss: 0.019252\tLearning Rate (w_theta): 0.001000\t TIME:409.0s\n",
      "\t\t\t\tDisc: 0.013883\t\tSym: 0.000587\t\tSpars: 0.004782\n",
      "\t TVw: -0.570550 | TVb: -1.973059 | GSw: -0.421475 | GSb: -0.135905 | TSUw: 0.259220 | TSUb: 0.185717\n",
      "Validating epoch 2104...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019196114808677247\n",
      "Average validation loss: 0.018666240450629153\n",
      "Training epoch 2105...\n",
      "\n",
      "Train Epoch: 2105 [0/8000 (0%)]\tBatch Loss: 0.018649\tLearning Rate (w_theta): 0.001000\t TIME:411.4s\n",
      "\t\t\t\tDisc: 0.013253\t\tSym: 0.000597\t\tSpars: 0.004799\n",
      "\t TVw: -0.570537 | TVb: -1.973038 | GSw: -0.421555 | GSb: -0.136012 | TSUw: 0.259111 | TSUb: 0.185733\n",
      "\n",
      "Train Epoch: 2105 [4000/8000 (50%)]\tBatch Loss: 0.019340\tLearning Rate (w_theta): 0.001000\t TIME:412.9s\n",
      "\t\t\t\tDisc: 0.013876\t\tSym: 0.000614\t\tSpars: 0.004850\n",
      "\t TVw: -0.570509 | TVb: -1.973007 | GSw: -0.421634 | GSb: -0.136118 | TSUw: 0.259003 | TSUb: 0.185748\n",
      "Validating epoch 2105...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01912136896901891\n",
      "Average validation loss: 0.01868160787522685\n",
      "Training epoch 2106...\n",
      "\n",
      "Train Epoch: 2106 [0/8000 (0%)]\tBatch Loss: 0.019100\tLearning Rate (w_theta): 0.001000\t TIME:415.2s\n",
      "\t\t\t\tDisc: 0.013746\t\tSym: 0.000595\t\tSpars: 0.004759\n",
      "\t TVw: -0.570481 | TVb: -1.972975 | GSw: -0.421717 | GSb: -0.136226 | TSUw: 0.258893 | TSUb: 0.185765\n",
      "\n",
      "Train Epoch: 2106 [4000/8000 (50%)]\tBatch Loss: 0.018438\tLearning Rate (w_theta): 0.001000\t TIME:416.8s\n",
      "\t\t\t\tDisc: 0.013164\t\tSym: 0.000575\t\tSpars: 0.004699\n",
      "\t TVw: -0.570450 | TVb: -1.972940 | GSw: -0.421797 | GSb: -0.136333 | TSUw: 0.258784 | TSUb: 0.185781\n",
      "Validating epoch 2106...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01908340183530596\n",
      "Average validation loss: 0.018533492390106102\n",
      "Training epoch 2107...\n",
      "\n",
      "Train Epoch: 2107 [0/8000 (0%)]\tBatch Loss: 0.019096\tLearning Rate (w_theta): 0.001000\t TIME:419.2s\n",
      "\t\t\t\tDisc: 0.013701\t\tSym: 0.000615\t\tSpars: 0.004780\n",
      "\t TVw: -0.570432 | TVb: -1.972913 | GSw: -0.421877 | GSb: -0.136439 | TSUw: 0.258678 | TSUb: 0.185795\n",
      "\n",
      "Train Epoch: 2107 [4000/8000 (50%)]\tBatch Loss: 0.019180\tLearning Rate (w_theta): 0.001000\t TIME:420.7s\n",
      "\t\t\t\tDisc: 0.013864\t\tSym: 0.000598\t\tSpars: 0.004718\n",
      "\t TVw: -0.570427 | TVb: -1.972896 | GSw: -0.421956 | GSb: -0.136545 | TSUw: 0.258575 | TSUb: 0.185807\n",
      "Validating epoch 2107...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01902404109322787\n",
      "Average validation loss: 0.01849415304931797\n",
      "Training epoch 2108...\n",
      "\n",
      "Train Epoch: 2108 [0/8000 (0%)]\tBatch Loss: 0.019374\tLearning Rate (w_theta): 0.001000\t TIME:423.0s\n",
      "\t\t\t\tDisc: 0.014014\t\tSym: 0.000618\t\tSpars: 0.004742\n",
      "\t TVw: -0.570413 | TVb: -1.972869 | GSw: -0.422035 | GSb: -0.136652 | TSUw: 0.258472 | TSUb: 0.185819\n",
      "\n",
      "Train Epoch: 2108 [4000/8000 (50%)]\tBatch Loss: 0.018513\tLearning Rate (w_theta): 0.001000\t TIME:424.6s\n",
      "\t\t\t\tDisc: 0.013254\t\tSym: 0.000585\t\tSpars: 0.004675\n",
      "\t TVw: -0.570409 | TVb: -1.972850 | GSw: -0.422113 | GSb: -0.136758 | TSUw: 0.258370 | TSUb: 0.185831\n",
      "Validating epoch 2108...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019002149550426495\n",
      "Average validation loss: 0.018483317627066127\n",
      "Training epoch 2109...\n",
      "\n",
      "Train Epoch: 2109 [0/8000 (0%)]\tBatch Loss: 0.018816\tLearning Rate (w_theta): 0.001000\t TIME:427.0s\n",
      "\t\t\t\tDisc: 0.013550\t\tSym: 0.000593\t\tSpars: 0.004673\n",
      "\t TVw: -0.570408 | TVb: -1.972832 | GSw: -0.422191 | GSb: -0.136864 | TSUw: 0.258270 | TSUb: 0.185841\n",
      "\n",
      "Train Epoch: 2109 [4000/8000 (50%)]\tBatch Loss: 0.018668\tLearning Rate (w_theta): 0.001000\t TIME:428.5s\n",
      "\t\t\t\tDisc: 0.013444\t\tSym: 0.000582\t\tSpars: 0.004642\n",
      "\t TVw: -0.570418 | TVb: -1.972822 | GSw: -0.422269 | GSb: -0.136970 | TSUw: 0.258171 | TSUb: 0.185850\n",
      "Validating epoch 2109...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01896662477876157\n",
      "Average validation loss: 0.018437744783546133\n",
      "Training epoch 2110...\n",
      "\n",
      "Train Epoch: 2110 [0/8000 (0%)]\tBatch Loss: 0.018781\tLearning Rate (w_theta): 0.001000\t TIME:430.9s\n",
      "\t\t\t\tDisc: 0.013496\t\tSym: 0.000596\t\tSpars: 0.004688\n",
      "\t TVw: -0.570427 | TVb: -1.972811 | GSw: -0.422347 | GSb: -0.137077 | TSUw: 0.258070 | TSUb: 0.185860\n",
      "\n",
      "Train Epoch: 2110 [4000/8000 (50%)]\tBatch Loss: 0.019287\tLearning Rate (w_theta): 0.001000\t TIME:432.4s\n",
      "\t\t\t\tDisc: 0.013886\t\tSym: 0.000640\t\tSpars: 0.004761\n",
      "\t TVw: -0.570417 | TVb: -1.972786 | GSw: -0.422425 | GSb: -0.137184 | TSUw: 0.257970 | TSUb: 0.185870\n",
      "Validating epoch 2110...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01893591302088202\n",
      "Average validation loss: 0.01840420242380257\n",
      "Training epoch 2111...\n",
      "\n",
      "Train Epoch: 2111 [0/8000 (0%)]\tBatch Loss: 0.018700\tLearning Rate (w_theta): 0.001000\t TIME:435.4s\n",
      "\t\t\t\tDisc: 0.013483\t\tSym: 0.000587\t\tSpars: 0.004630\n",
      "\t TVw: -0.570428 | TVb: -1.972775 | GSw: -0.422504 | GSb: -0.137292 | TSUw: 0.257868 | TSUb: 0.185880\n",
      "\n",
      "Train Epoch: 2111 [4000/8000 (50%)]\tBatch Loss: 0.019617\tLearning Rate (w_theta): 0.001000\t TIME:436.9s\n",
      "\t\t\t\tDisc: 0.014251\t\tSym: 0.000632\t\tSpars: 0.004733\n",
      "\t TVw: -0.570418 | TVb: -1.972752 | GSw: -0.422582 | GSb: -0.137398 | TSUw: 0.257768 | TSUb: 0.185890\n",
      "Validating epoch 2111...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018911269227380154\n",
      "Average validation loss: 0.018408237109707577\n",
      "Training epoch 2112...\n",
      "\n",
      "Train Epoch: 2112 [0/8000 (0%)]\tBatch Loss: 0.018871\tLearning Rate (w_theta): 0.001000\t TIME:439.2s\n",
      "\t\t\t\tDisc: 0.013626\t\tSym: 0.000603\t\tSpars: 0.004642\n",
      "\t TVw: -0.570420 | TVb: -1.972735 | GSw: -0.422662 | GSb: -0.137507 | TSUw: 0.257665 | TSUb: 0.185901\n",
      "\n",
      "Train Epoch: 2112 [4000/8000 (50%)]\tBatch Loss: 0.018649\tLearning Rate (w_theta): 0.001000\t TIME:440.7s\n",
      "\t\t\t\tDisc: 0.013435\t\tSym: 0.000594\t\tSpars: 0.004620\n",
      "\t TVw: -0.570425 | TVb: -1.972719 | GSw: -0.422744 | GSb: -0.137619 | TSUw: 0.257559 | TSUb: 0.185914\n",
      "Validating epoch 2112...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018898543602760408\n",
      "Average validation loss: 0.01838875869199405\n",
      "Training epoch 2113...\n",
      "\n",
      "Train Epoch: 2113 [0/8000 (0%)]\tBatch Loss: 0.018367\tLearning Rate (w_theta): 0.001000\t TIME:443.2s\n",
      "\t\t\t\tDisc: 0.013143\t\tSym: 0.000592\t\tSpars: 0.004633\n",
      "\t TVw: -0.570432 | TVb: -1.972705 | GSw: -0.422823 | GSb: -0.137727 | TSUw: 0.257458 | TSUb: 0.185924\n",
      "\n",
      "Train Epoch: 2113 [4000/8000 (50%)]\tBatch Loss: 0.019292\tLearning Rate (w_theta): 0.001000\t TIME:444.7s\n",
      "\t\t\t\tDisc: 0.014028\t\tSym: 0.000614\t\tSpars: 0.004650\n",
      "\t TVw: -0.570444 | TVb: -1.972695 | GSw: -0.422904 | GSb: -0.137838 | TSUw: 0.257355 | TSUb: 0.185934\n",
      "Validating epoch 2113...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018882789254942023\n",
      "Average validation loss: 0.018386442930740883\n",
      "Training epoch 2114...\n",
      "\n",
      "Train Epoch: 2114 [0/8000 (0%)]\tBatch Loss: 0.018988\tLearning Rate (w_theta): 0.001000\t TIME:447.0s\n",
      "\t\t\t\tDisc: 0.013774\t\tSym: 0.000598\t\tSpars: 0.004616\n",
      "\t TVw: -0.570450 | TVb: -1.972679 | GSw: -0.422984 | GSb: -0.137947 | TSUw: 0.257253 | TSUb: 0.185944\n",
      "\n",
      "Train Epoch: 2114 [4000/8000 (50%)]\tBatch Loss: 0.018275\tLearning Rate (w_theta): 0.001000\t TIME:448.6s\n",
      "\t\t\t\tDisc: 0.013090\t\tSym: 0.000587\t\tSpars: 0.004598\n",
      "\t TVw: -0.570466 | TVb: -1.972671 | GSw: -0.423065 | GSb: -0.138059 | TSUw: 0.257148 | TSUb: 0.185955\n",
      "Validating epoch 2114...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01886337528600473\n",
      "Average validation loss: 0.01837988986987247\n",
      "Training epoch 2115...\n",
      "\n",
      "Train Epoch: 2115 [0/8000 (0%)]\tBatch Loss: 0.018920\tLearning Rate (w_theta): 0.001000\t TIME:450.9s\n",
      "\t\t\t\tDisc: 0.013635\t\tSym: 0.000611\t\tSpars: 0.004674\n",
      "\t TVw: -0.570488 | TVb: -1.972664 | GSw: -0.423146 | GSb: -0.138170 | TSUw: 0.257044 | TSUb: 0.185966\n",
      "\n",
      "Train Epoch: 2115 [4000/8000 (50%)]\tBatch Loss: 0.018781\tLearning Rate (w_theta): 0.001000\t TIME:452.4s\n",
      "\t\t\t\tDisc: 0.013545\t\tSym: 0.000604\t\tSpars: 0.004632\n",
      "\t TVw: -0.570510 | TVb: -1.972655 | GSw: -0.423229 | GSb: -0.138284 | TSUw: 0.256939 | TSUb: 0.185978\n",
      "Validating epoch 2115...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0188517062697112\n",
      "Average validation loss: 0.0183674543351516\n",
      "Training epoch 2116...\n",
      "\n",
      "Train Epoch: 2116 [0/8000 (0%)]\tBatch Loss: 0.019002\tLearning Rate (w_theta): 0.001000\t TIME:454.8s\n",
      "\t\t\t\tDisc: 0.013714\t\tSym: 0.000619\t\tSpars: 0.004670\n",
      "\t TVw: -0.570510 | TVb: -1.972636 | GSw: -0.423310 | GSb: -0.138394 | TSUw: 0.256833 | TSUb: 0.185989\n",
      "\n",
      "Train Epoch: 2116 [4000/8000 (50%)]\tBatch Loss: 0.018892\tLearning Rate (w_theta): 0.001000\t TIME:456.3s\n",
      "\t\t\t\tDisc: 0.013634\t\tSym: 0.000609\t\tSpars: 0.004649\n",
      "\t TVw: -0.570517 | TVb: -1.972622 | GSw: -0.423391 | GSb: -0.138506 | TSUw: 0.256728 | TSUb: 0.186000\n",
      "Validating epoch 2116...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018840791525204088\n",
      "Average validation loss: 0.018408452348432802\n",
      "Training epoch 2117...\n",
      "\n",
      "Train Epoch: 2117 [0/8000 (0%)]\tBatch Loss: 0.018688\tLearning Rate (w_theta): 0.001000\t TIME:458.7s\n",
      "\t\t\t\tDisc: 0.013482\t\tSym: 0.000591\t\tSpars: 0.004615\n",
      "\t TVw: -0.570533 | TVb: -1.972615 | GSw: -0.423474 | GSb: -0.138619 | TSUw: 0.256623 | TSUb: 0.186011\n",
      "\n",
      "Train Epoch: 2117 [4000/8000 (50%)]\tBatch Loss: 0.018553\tLearning Rate (w_theta): 0.001000\t TIME:460.2s\n",
      "\t\t\t\tDisc: 0.013352\t\tSym: 0.000596\t\tSpars: 0.004606\n",
      "\t TVw: -0.570549 | TVb: -1.972603 | GSw: -0.423558 | GSb: -0.138733 | TSUw: 0.256515 | TSUb: 0.186024\n",
      "Validating epoch 2117...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018870839074245898\n",
      "Average validation loss: 0.01840760922104079\n",
      "Training epoch 2118...\n",
      "\n",
      "Train Epoch: 2118 [0/8000 (0%)]\tBatch Loss: 0.019258\tLearning Rate (w_theta): 0.001000\t TIME:462.6s\n",
      "\t\t\t\tDisc: 0.013966\t\tSym: 0.000618\t\tSpars: 0.004674\n",
      "\t TVw: -0.570549 | TVb: -1.972583 | GSw: -0.423640 | GSb: -0.138845 | TSUw: 0.256409 | TSUb: 0.186035\n",
      "\n",
      "Train Epoch: 2118 [4000/8000 (50%)]\tBatch Loss: 0.018768\tLearning Rate (w_theta): 0.001000\t TIME:464.1s\n",
      "\t\t\t\tDisc: 0.013462\t\tSym: 0.000625\t\tSpars: 0.004681\n",
      "\t TVw: -0.570573 | TVb: -1.972581 | GSw: -0.423722 | GSb: -0.138958 | TSUw: 0.256303 | TSUb: 0.186046\n",
      "Validating epoch 2118...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018901024402739375\n",
      "Average validation loss: 0.018393622151176205\n",
      "Training epoch 2119...\n",
      "\n",
      "Train Epoch: 2119 [0/8000 (0%)]\tBatch Loss: 0.018835\tLearning Rate (w_theta): 0.001000\t TIME:466.5s\n",
      "\t\t\t\tDisc: 0.013617\t\tSym: 0.000596\t\tSpars: 0.004621\n",
      "\t TVw: -0.570580 | TVb: -1.972565 | GSw: -0.423806 | GSb: -0.139071 | TSUw: 0.256194 | TSUb: 0.186059\n",
      "\n",
      "Train Epoch: 2119 [4000/8000 (50%)]\tBatch Loss: 0.018843\tLearning Rate (w_theta): 0.001000\t TIME:468.0s\n",
      "\t\t\t\tDisc: 0.013598\t\tSym: 0.000594\t\tSpars: 0.004651\n",
      "\t TVw: -0.570588 | TVb: -1.972551 | GSw: -0.423888 | GSb: -0.139183 | TSUw: 0.256087 | TSUb: 0.186071\n",
      "Validating epoch 2119...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01888215474058809\n",
      "Average validation loss: 0.018383114997639692\n",
      "Training epoch 2120...\n",
      "\n",
      "Train Epoch: 2120 [0/8000 (0%)]\tBatch Loss: 0.018565\tLearning Rate (w_theta): 0.001000\t TIME:470.4s\n",
      "\t\t\t\tDisc: 0.013333\t\tSym: 0.000597\t\tSpars: 0.004634\n",
      "\t TVw: -0.570617 | TVb: -1.972553 | GSw: -0.423972 | GSb: -0.139298 | TSUw: 0.255979 | TSUb: 0.186082\n",
      "\n",
      "Train Epoch: 2120 [4000/8000 (50%)]\tBatch Loss: 0.018864\tLearning Rate (w_theta): 0.001000\t TIME:471.9s\n",
      "\t\t\t\tDisc: 0.013615\t\tSym: 0.000599\t\tSpars: 0.004649\n",
      "\t TVw: -0.570618 | TVb: -1.972538 | GSw: -0.424054 | GSb: -0.139409 | TSUw: 0.255872 | TSUb: 0.186093\n",
      "Validating epoch 2120...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018844540454498303\n",
      "Average validation loss: 0.018323046332637757\n",
      "Training epoch 2121...\n",
      "\n",
      "Train Epoch: 2121 [0/8000 (0%)]\tBatch Loss: 0.018800\tLearning Rate (w_theta): 0.001000\t TIME:475.0s\n",
      "\t\t\t\tDisc: 0.013579\t\tSym: 0.000596\t\tSpars: 0.004625\n",
      "\t TVw: -0.570610 | TVb: -1.972515 | GSw: -0.424136 | GSb: -0.139521 | TSUw: 0.255765 | TSUb: 0.186105\n",
      "\n",
      "Train Epoch: 2121 [4000/8000 (50%)]\tBatch Loss: 0.018551\tLearning Rate (w_theta): 0.001000\t TIME:476.5s\n",
      "\t\t\t\tDisc: 0.013288\t\tSym: 0.000611\t\tSpars: 0.004653\n",
      "\t TVw: -0.570611 | TVb: -1.972495 | GSw: -0.424222 | GSb: -0.139636 | TSUw: 0.255655 | TSUb: 0.186117\n",
      "Validating epoch 2121...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018823770622547833\n",
      "Average validation loss: 0.018333999422857\n",
      "Training epoch 2122...\n",
      "\n",
      "Train Epoch: 2122 [0/8000 (0%)]\tBatch Loss: 0.018894\tLearning Rate (w_theta): 0.001000\t TIME:478.8s\n",
      "\t\t\t\tDisc: 0.013650\t\tSym: 0.000607\t\tSpars: 0.004638\n",
      "\t TVw: -0.570617 | TVb: -1.972481 | GSw: -0.424306 | GSb: -0.139750 | TSUw: 0.255547 | TSUb: 0.186129\n",
      "\n",
      "Train Epoch: 2122 [4000/8000 (50%)]\tBatch Loss: 0.019170\tLearning Rate (w_theta): 0.001000\t TIME:480.3s\n",
      "\t\t\t\tDisc: 0.013834\t\tSym: 0.000634\t\tSpars: 0.004702\n",
      "\t TVw: -0.570609 | TVb: -1.972459 | GSw: -0.424389 | GSb: -0.139863 | TSUw: 0.255439 | TSUb: 0.186140\n",
      "Validating epoch 2122...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018819543459377586\n",
      "Average validation loss: 0.01832246437738967\n",
      "Training epoch 2123...\n",
      "\n",
      "Train Epoch: 2123 [0/8000 (0%)]\tBatch Loss: 0.019013\tLearning Rate (w_theta): 0.001000\t TIME:482.7s\n",
      "\t\t\t\tDisc: 0.013763\t\tSym: 0.000608\t\tSpars: 0.004642\n",
      "\t TVw: -0.570618 | TVb: -1.972445 | GSw: -0.424471 | GSb: -0.139975 | TSUw: 0.255334 | TSUb: 0.186149\n",
      "\n",
      "Train Epoch: 2123 [4000/8000 (50%)]\tBatch Loss: 0.018816\tLearning Rate (w_theta): 0.001000\t TIME:484.2s\n",
      "\t\t\t\tDisc: 0.013526\t\tSym: 0.000619\t\tSpars: 0.004671\n",
      "\t TVw: -0.570660 | TVb: -1.972454 | GSw: -0.424555 | GSb: -0.140091 | TSUw: 0.255229 | TSUb: 0.186159\n",
      "Validating epoch 2123...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01878923066648542\n",
      "Average validation loss: 0.018282837380253707\n",
      "Training epoch 2124...\n",
      "\n",
      "Train Epoch: 2124 [0/8000 (0%)]\tBatch Loss: 0.019096\tLearning Rate (w_theta): 0.001000\t TIME:486.6s\n",
      "\t\t\t\tDisc: 0.013861\t\tSym: 0.000608\t\tSpars: 0.004628\n",
      "\t TVw: -0.570649 | TVb: -1.972428 | GSw: -0.424637 | GSb: -0.140203 | TSUw: 0.255120 | TSUb: 0.186170\n",
      "\n",
      "Train Epoch: 2124 [4000/8000 (50%)]\tBatch Loss: 0.018369\tLearning Rate (w_theta): 0.001000\t TIME:488.1s\n",
      "\t\t\t\tDisc: 0.013222\t\tSym: 0.000579\t\tSpars: 0.004567\n",
      "\t TVw: -0.570653 | TVb: -1.972412 | GSw: -0.424721 | GSb: -0.140317 | TSUw: 0.255013 | TSUb: 0.186180\n",
      "Validating epoch 2124...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01878019586900164\n",
      "Average validation loss: 0.01830100799552932\n",
      "Training epoch 2125...\n",
      "\n",
      "Train Epoch: 2125 [0/8000 (0%)]\tBatch Loss: 0.018608\tLearning Rate (w_theta): 0.001000\t TIME:490.5s\n",
      "\t\t\t\tDisc: 0.013406\t\tSym: 0.000599\t\tSpars: 0.004603\n",
      "\t TVw: -0.570677 | TVb: -1.972407 | GSw: -0.424806 | GSb: -0.140433 | TSUw: 0.254904 | TSUb: 0.186191\n",
      "\n",
      "Train Epoch: 2125 [4000/8000 (50%)]\tBatch Loss: 0.019148\tLearning Rate (w_theta): 0.001000\t TIME:492.0s\n",
      "\t\t\t\tDisc: 0.013920\t\tSym: 0.000607\t\tSpars: 0.004621\n",
      "\t TVw: -0.570690 | TVb: -1.972396 | GSw: -0.424890 | GSb: -0.140548 | TSUw: 0.254796 | TSUb: 0.186202\n",
      "Validating epoch 2125...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018766988879944334\n",
      "Average validation loss: 0.018313267979633653\n",
      "Training epoch 2126...\n",
      "\n",
      "Train Epoch: 2126 [0/8000 (0%)]\tBatch Loss: 0.018725\tLearning Rate (w_theta): 0.001000\t TIME:494.4s\n",
      "\t\t\t\tDisc: 0.013545\t\tSym: 0.000598\t\tSpars: 0.004582\n",
      "\t TVw: -0.570677 | TVb: -1.972369 | GSw: -0.424973 | GSb: -0.140661 | TSUw: 0.254687 | TSUb: 0.186213\n",
      "\n",
      "Train Epoch: 2126 [4000/8000 (50%)]\tBatch Loss: 0.019387\tLearning Rate (w_theta): 0.001000\t TIME:495.9s\n",
      "\t\t\t\tDisc: 0.014118\t\tSym: 0.000616\t\tSpars: 0.004652\n",
      "\t TVw: -0.570696 | TVb: -1.972358 | GSw: -0.425058 | GSb: -0.140776 | TSUw: 0.254579 | TSUb: 0.186223\n",
      "Validating epoch 2126...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018768698101779946\n",
      "Average validation loss: 0.01829688691538524\n",
      "Training epoch 2127...\n",
      "\n",
      "Train Epoch: 2127 [0/8000 (0%)]\tBatch Loss: 0.018589\tLearning Rate (w_theta): 0.001000\t TIME:498.3s\n",
      "\t\t\t\tDisc: 0.013376\t\tSym: 0.000601\t\tSpars: 0.004611\n",
      "\t TVw: -0.570728 | TVb: -1.972358 | GSw: -0.425145 | GSb: -0.140894 | TSUw: 0.254470 | TSUb: 0.186234\n",
      "\n",
      "Train Epoch: 2127 [4000/8000 (50%)]\tBatch Loss: 0.018863\tLearning Rate (w_theta): 0.001000\t TIME:499.8s\n",
      "\t\t\t\tDisc: 0.013610\t\tSym: 0.000610\t\tSpars: 0.004642\n",
      "\t TVw: -0.570732 | TVb: -1.972340 | GSw: -0.425228 | GSb: -0.141008 | TSUw: 0.254361 | TSUb: 0.186244\n",
      "Validating epoch 2127...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018763401485539885\n",
      "Average validation loss: 0.018276417953038266\n",
      "Training epoch 2128...\n",
      "\n",
      "Train Epoch: 2128 [0/8000 (0%)]\tBatch Loss: 0.018932\tLearning Rate (w_theta): 0.001000\t TIME:502.3s\n",
      "\t\t\t\tDisc: 0.013666\t\tSym: 0.000620\t\tSpars: 0.004645\n",
      "\t TVw: -0.570734 | TVb: -1.972321 | GSw: -0.425313 | GSb: -0.141124 | TSUw: 0.254250 | TSUb: 0.186256\n",
      "\n",
      "Train Epoch: 2128 [4000/8000 (50%)]\tBatch Loss: 0.018110\tLearning Rate (w_theta): 0.001000\t TIME:503.8s\n",
      "\t\t\t\tDisc: 0.012965\t\tSym: 0.000585\t\tSpars: 0.004559\n",
      "\t TVw: -0.570743 | TVb: -1.972308 | GSw: -0.425399 | GSb: -0.141241 | TSUw: 0.254138 | TSUb: 0.186268\n",
      "Validating epoch 2128...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018749349320779537\n",
      "Average validation loss: 0.018270462718583316\n",
      "Training epoch 2129...\n",
      "\n",
      "Train Epoch: 2129 [0/8000 (0%)]\tBatch Loss: 0.018755\tLearning Rate (w_theta): 0.001000\t TIME:506.2s\n",
      "\t\t\t\tDisc: 0.013536\t\tSym: 0.000605\t\tSpars: 0.004614\n",
      "\t TVw: -0.570759 | TVb: -1.972297 | GSw: -0.425485 | GSb: -0.141357 | TSUw: 0.254029 | TSUb: 0.186278\n",
      "\n",
      "Train Epoch: 2129 [4000/8000 (50%)]\tBatch Loss: 0.019000\tLearning Rate (w_theta): 0.001000\t TIME:507.7s\n",
      "\t\t\t\tDisc: 0.013764\t\tSym: 0.000612\t\tSpars: 0.004624\n",
      "\t TVw: -0.570765 | TVb: -1.972279 | GSw: -0.425571 | GSb: -0.141473 | TSUw: 0.253920 | TSUb: 0.186288\n",
      "Validating epoch 2129...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01873072211468038\n",
      "Average validation loss: 0.018246693608560648\n",
      "Training epoch 2130...\n",
      "\n",
      "Train Epoch: 2130 [0/8000 (0%)]\tBatch Loss: 0.018692\tLearning Rate (w_theta): 0.001000\t TIME:510.1s\n",
      "\t\t\t\tDisc: 0.013480\t\tSym: 0.000605\t\tSpars: 0.004607\n",
      "\t TVw: -0.570768 | TVb: -1.972260 | GSw: -0.425656 | GSb: -0.141590 | TSUw: 0.253810 | TSUb: 0.186298\n",
      "\n",
      "Train Epoch: 2130 [4000/8000 (50%)]\tBatch Loss: 0.019047\tLearning Rate (w_theta): 0.001000\t TIME:511.7s\n",
      "\t\t\t\tDisc: 0.013841\t\tSym: 0.000603\t\tSpars: 0.004603\n",
      "\t TVw: -0.570780 | TVb: -1.972249 | GSw: -0.425743 | GSb: -0.141708 | TSUw: 0.253700 | TSUb: 0.186309\n",
      "Validating epoch 2130...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01872480385720579\n",
      "Average validation loss: 0.01826035548744129\n",
      "Training epoch 2131...\n",
      "\n",
      "Train Epoch: 2131 [0/8000 (0%)]\tBatch Loss: 0.018819\tLearning Rate (w_theta): 0.001000\t TIME:514.8s\n",
      "\t\t\t\tDisc: 0.013606\t\tSym: 0.000609\t\tSpars: 0.004605\n",
      "\t TVw: -0.570779 | TVb: -1.972227 | GSw: -0.425829 | GSb: -0.141824 | TSUw: 0.253590 | TSUb: 0.186319\n",
      "\n",
      "Train Epoch: 2131 [4000/8000 (50%)]\tBatch Loss: 0.018284\tLearning Rate (w_theta): 0.001000\t TIME:516.3s\n",
      "\t\t\t\tDisc: 0.013184\t\tSym: 0.000575\t\tSpars: 0.004525\n",
      "\t TVw: -0.570799 | TVb: -1.972218 | GSw: -0.425914 | GSb: -0.141941 | TSUw: 0.253480 | TSUb: 0.186329\n",
      "Validating epoch 2131...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018714522896445627\n",
      "Average validation loss: 0.018249425597641894\n",
      "Training epoch 2132...\n",
      "\n",
      "Train Epoch: 2132 [0/8000 (0%)]\tBatch Loss: 0.018719\tLearning Rate (w_theta): 0.001000\t TIME:518.7s\n",
      "\t\t\t\tDisc: 0.013524\t\tSym: 0.000594\t\tSpars: 0.004601\n",
      "\t TVw: -0.570829 | TVb: -1.972216 | GSw: -0.426001 | GSb: -0.142059 | TSUw: 0.253371 | TSUb: 0.186338\n",
      "\n",
      "Train Epoch: 2132 [4000/8000 (50%)]\tBatch Loss: 0.018488\tLearning Rate (w_theta): 0.001000\t TIME:520.3s\n",
      "\t\t\t\tDisc: 0.013317\t\tSym: 0.000600\t\tSpars: 0.004572\n",
      "\t TVw: -0.570840 | TVb: -1.972203 | GSw: -0.426085 | GSb: -0.142175 | TSUw: 0.253261 | TSUb: 0.186348\n",
      "Validating epoch 2132...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018713917293755676\n",
      "Average validation loss: 0.01820909595202217\n",
      "Training epoch 2133...\n",
      "\n",
      "Train Epoch: 2133 [0/8000 (0%)]\tBatch Loss: 0.018013\tLearning Rate (w_theta): 0.001000\t TIME:522.7s\n",
      "\t\t\t\tDisc: 0.012861\t\tSym: 0.000593\t\tSpars: 0.004560\n",
      "\t TVw: -0.570848 | TVb: -1.972186 | GSw: -0.426171 | GSb: -0.142292 | TSUw: 0.253150 | TSUb: 0.186358\n",
      "\n",
      "Train Epoch: 2133 [4000/8000 (50%)]\tBatch Loss: 0.019281\tLearning Rate (w_theta): 0.001000\t TIME:524.3s\n",
      "\t\t\t\tDisc: 0.014032\t\tSym: 0.000618\t\tSpars: 0.004631\n",
      "\t TVw: -0.570862 | TVb: -1.972173 | GSw: -0.426260 | GSb: -0.142412 | TSUw: 0.253037 | TSUb: 0.186369\n",
      "Validating epoch 2133...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0187293008238665\n",
      "Average validation loss: 0.01822876333121947\n",
      "Training epoch 2134...\n",
      "\n",
      "Train Epoch: 2134 [0/8000 (0%)]\tBatch Loss: 0.018870\tLearning Rate (w_theta): 0.001000\t TIME:526.6s\n",
      "\t\t\t\tDisc: 0.013680\t\tSym: 0.000599\t\tSpars: 0.004591\n",
      "\t TVw: -0.570875 | TVb: -1.972161 | GSw: -0.426348 | GSb: -0.142531 | TSUw: 0.252924 | TSUb: 0.186380\n",
      "\n",
      "Train Epoch: 2134 [4000/8000 (50%)]\tBatch Loss: 0.018671\tLearning Rate (w_theta): 0.001000\t TIME:528.1s\n",
      "\t\t\t\tDisc: 0.013485\t\tSym: 0.000597\t\tSpars: 0.004590\n",
      "\t TVw: -0.570874 | TVb: -1.972139 | GSw: -0.426434 | GSb: -0.142648 | TSUw: 0.252811 | TSUb: 0.186391\n",
      "Validating epoch 2134...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01870544628210145\n",
      "Average validation loss: 0.018262149433962423\n",
      "Training epoch 2135...\n",
      "\n",
      "Train Epoch: 2135 [0/8000 (0%)]\tBatch Loss: 0.019053\tLearning Rate (w_theta): 0.001000\t TIME:530.6s\n",
      "\t\t\t\tDisc: 0.013786\t\tSym: 0.000621\t\tSpars: 0.004647\n",
      "\t TVw: -0.570891 | TVb: -1.972129 | GSw: -0.426522 | GSb: -0.142768 | TSUw: 0.252698 | TSUb: 0.186402\n",
      "\n",
      "Train Epoch: 2135 [4000/8000 (50%)]\tBatch Loss: 0.018354\tLearning Rate (w_theta): 0.001000\t TIME:532.1s\n",
      "\t\t\t\tDisc: 0.013243\t\tSym: 0.000575\t\tSpars: 0.004535\n",
      "\t TVw: -0.570903 | TVb: -1.972116 | GSw: -0.426612 | GSb: -0.142889 | TSUw: 0.252584 | TSUb: 0.186413\n",
      "Validating epoch 2135...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018701091908013737\n",
      "Average validation loss: 0.01821437060394757\n",
      "Training epoch 2136...\n",
      "\n",
      "Train Epoch: 2136 [0/8000 (0%)]\tBatch Loss: 0.018560\tLearning Rate (w_theta): 0.001000\t TIME:534.5s\n",
      "\t\t\t\tDisc: 0.013462\t\tSym: 0.000578\t\tSpars: 0.004519\n",
      "\t TVw: -0.570900 | TVb: -1.972094 | GSw: -0.426698 | GSb: -0.143006 | TSUw: 0.252473 | TSUb: 0.186423\n",
      "\n",
      "Train Epoch: 2136 [4000/8000 (50%)]\tBatch Loss: 0.018766\tLearning Rate (w_theta): 0.001000\t TIME:536.0s\n",
      "\t\t\t\tDisc: 0.013577\t\tSym: 0.000601\t\tSpars: 0.004588\n",
      "\t TVw: -0.570906 | TVb: -1.972079 | GSw: -0.426784 | GSb: -0.143123 | TSUw: 0.252362 | TSUb: 0.186432\n",
      "Validating epoch 2136...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01867596286569648\n",
      "Average validation loss: 0.01819777719504546\n",
      "Training epoch 2137...\n",
      "\n",
      "Train Epoch: 2137 [0/8000 (0%)]\tBatch Loss: 0.018700\tLearning Rate (w_theta): 0.001000\t TIME:538.4s\n",
      "\t\t\t\tDisc: 0.013509\t\tSym: 0.000610\t\tSpars: 0.004581\n",
      "\t TVw: -0.570920 | TVb: -1.972068 | GSw: -0.426872 | GSb: -0.143243 | TSUw: 0.252250 | TSUb: 0.186442\n",
      "\n",
      "Train Epoch: 2137 [4000/8000 (50%)]\tBatch Loss: 0.018810\tLearning Rate (w_theta): 0.001000\t TIME:539.9s\n",
      "\t\t\t\tDisc: 0.013587\t\tSym: 0.000607\t\tSpars: 0.004616\n",
      "\t TVw: -0.570942 | TVb: -1.972058 | GSw: -0.426962 | GSb: -0.143364 | TSUw: 0.252136 | TSUb: 0.186452\n",
      "Validating epoch 2137...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018841250563298797\n",
      "Average validation loss: 0.018404618485309027\n",
      "Training epoch 2138...\n",
      "\n",
      "Train Epoch: 2138 [0/8000 (0%)]\tBatch Loss: 0.019044\tLearning Rate (w_theta): 0.001000\t TIME:542.3s\n",
      "\t\t\t\tDisc: 0.013810\t\tSym: 0.000632\t\tSpars: 0.004601\n",
      "\t TVw: -0.570977 | TVb: -1.972062 | GSw: -0.427055 | GSb: -0.143488 | TSUw: 0.252020 | TSUb: 0.186464\n",
      "\n",
      "Train Epoch: 2138 [4000/8000 (50%)]\tBatch Loss: 0.019473\tLearning Rate (w_theta): 0.001000\t TIME:543.8s\n",
      "\t\t\t\tDisc: 0.014087\t\tSym: 0.000664\t\tSpars: 0.004722\n",
      "\t TVw: -0.571018 | TVb: -1.972068 | GSw: -0.427148 | GSb: -0.143612 | TSUw: 0.251901 | TSUb: 0.186477\n",
      "Validating epoch 2138...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0189155559545607\n",
      "Average validation loss: 0.018405955178772797\n",
      "Training epoch 2139...\n",
      "\n",
      "Train Epoch: 2139 [0/8000 (0%)]\tBatch Loss: 0.019189\tLearning Rate (w_theta): 0.001000\t TIME:546.3s\n",
      "\t\t\t\tDisc: 0.013848\t\tSym: 0.000624\t\tSpars: 0.004717\n",
      "\t TVw: -0.571091 | TVb: -1.972095 | GSw: -0.427237 | GSb: -0.143734 | TSUw: 0.251786 | TSUb: 0.186488\n",
      "\n",
      "Train Epoch: 2139 [4000/8000 (50%)]\tBatch Loss: 0.018816\tLearning Rate (w_theta): 0.001000\t TIME:547.8s\n",
      "\t\t\t\tDisc: 0.013506\t\tSym: 0.000600\t\tSpars: 0.004710\n",
      "\t TVw: -0.571165 | TVb: -1.972124 | GSw: -0.427327 | GSb: -0.143856 | TSUw: 0.251670 | TSUb: 0.186499\n",
      "Validating epoch 2139...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018820658320740005\n",
      "Average validation loss: 0.018294874505102823\n",
      "Training epoch 2140...\n",
      "\n",
      "Train Epoch: 2140 [0/8000 (0%)]\tBatch Loss: 0.018992\tLearning Rate (w_theta): 0.001000\t TIME:550.2s\n",
      "\t\t\t\tDisc: 0.013706\t\tSym: 0.000597\t\tSpars: 0.004689\n",
      "\t TVw: -0.571199 | TVb: -1.972128 | GSw: -0.427413 | GSb: -0.143973 | TSUw: 0.251555 | TSUb: 0.186510\n",
      "\n",
      "Train Epoch: 2140 [4000/8000 (50%)]\tBatch Loss: 0.018622\tLearning Rate (w_theta): 0.001000\t TIME:551.7s\n",
      "\t\t\t\tDisc: 0.013403\t\tSym: 0.000575\t\tSpars: 0.004645\n",
      "\t TVw: -0.571229 | TVb: -1.972130 | GSw: -0.427501 | GSb: -0.144092 | TSUw: 0.251437 | TSUb: 0.186522\n",
      "Validating epoch 2140...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018812080138904865\n",
      "Average validation loss: 0.018267750044192517\n",
      "Training epoch 2141...\n",
      "\n",
      "Train Epoch: 2141 [0/8000 (0%)]\tBatch Loss: 0.018799\tLearning Rate (w_theta): 0.001000\t TIME:554.8s\n",
      "\t\t\t\tDisc: 0.013507\t\tSym: 0.000598\t\tSpars: 0.004694\n",
      "\t TVw: -0.571221 | TVb: -1.972110 | GSw: -0.427588 | GSb: -0.144209 | TSUw: 0.251320 | TSUb: 0.186534\n",
      "\n",
      "Train Epoch: 2141 [4000/8000 (50%)]\tBatch Loss: 0.018980\tLearning Rate (w_theta): 0.001000\t TIME:556.3s\n",
      "\t\t\t\tDisc: 0.013728\t\tSym: 0.000590\t\tSpars: 0.004663\n",
      "\t TVw: -0.571188 | TVb: -1.972076 | GSw: -0.427675 | GSb: -0.144325 | TSUw: 0.251203 | TSUb: 0.186545\n",
      "Validating epoch 2141...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01875482779415952\n",
      "Average validation loss: 0.018232325859326007\n",
      "Training epoch 2142...\n",
      "\n",
      "Train Epoch: 2142 [0/8000 (0%)]\tBatch Loss: 0.018174\tLearning Rate (w_theta): 0.001000\t TIME:558.7s\n",
      "\t\t\t\tDisc: 0.013017\t\tSym: 0.000569\t\tSpars: 0.004588\n",
      "\t TVw: -0.571139 | TVb: -1.972030 | GSw: -0.427761 | GSb: -0.144439 | TSUw: 0.251085 | TSUb: 0.186557\n",
      "\n",
      "Train Epoch: 2142 [4000/8000 (50%)]\tBatch Loss: 0.018640\tLearning Rate (w_theta): 0.001000\t TIME:560.2s\n",
      "\t\t\t\tDisc: 0.013437\t\tSym: 0.000586\t\tSpars: 0.004617\n",
      "\t TVw: -0.571119 | TVb: -1.972001 | GSw: -0.427850 | GSb: -0.144558 | TSUw: 0.250966 | TSUb: 0.186570\n",
      "Validating epoch 2142...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018721958517602357\n",
      "Average validation loss: 0.018173768936982634\n",
      "Training epoch 2143...\n",
      "\n",
      "Train Epoch: 2143 [0/8000 (0%)]\tBatch Loss: 0.018474\tLearning Rate (w_theta): 0.001000\t TIME:562.6s\n",
      "\t\t\t\tDisc: 0.013298\t\tSym: 0.000581\t\tSpars: 0.004596\n",
      "\t TVw: -0.571115 | TVb: -1.971982 | GSw: -0.427938 | GSb: -0.144676 | TSUw: 0.250850 | TSUb: 0.186580\n",
      "\n",
      "Train Epoch: 2143 [4000/8000 (50%)]\tBatch Loss: 0.018538\tLearning Rate (w_theta): 0.001000\t TIME:564.1s\n",
      "\t\t\t\tDisc: 0.013411\t\tSym: 0.000577\t\tSpars: 0.004550\n",
      "\t TVw: -0.571090 | TVb: -1.971946 | GSw: -0.428024 | GSb: -0.144792 | TSUw: 0.250736 | TSUb: 0.186589\n",
      "Validating epoch 2143...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018683056661879003\n",
      "Average validation loss: 0.018151418291942563\n",
      "Training epoch 2144...\n",
      "\n",
      "Train Epoch: 2144 [0/8000 (0%)]\tBatch Loss: 0.018808\tLearning Rate (w_theta): 0.001000\t TIME:566.5s\n",
      "\t\t\t\tDisc: 0.013681\t\tSym: 0.000574\t\tSpars: 0.004553\n",
      "\t TVw: -0.571088 | TVb: -1.971925 | GSw: -0.428111 | GSb: -0.144910 | TSUw: 0.250623 | TSUb: 0.186597\n",
      "\n",
      "Train Epoch: 2144 [4000/8000 (50%)]\tBatch Loss: 0.018702\tLearning Rate (w_theta): 0.001000\t TIME:568.0s\n",
      "\t\t\t\tDisc: 0.013521\t\tSym: 0.000591\t\tSpars: 0.004590\n",
      "\t TVw: -0.571084 | TVb: -1.971905 | GSw: -0.428197 | GSb: -0.145026 | TSUw: 0.250513 | TSUb: 0.186604\n",
      "Validating epoch 2144...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018660051235347756\n",
      "Average validation loss: 0.018158483345748128\n",
      "Training epoch 2145...\n",
      "\n",
      "Train Epoch: 2145 [0/8000 (0%)]\tBatch Loss: 0.018644\tLearning Rate (w_theta): 0.001000\t TIME:570.4s\n",
      "\t\t\t\tDisc: 0.013520\t\tSym: 0.000580\t\tSpars: 0.004544\n",
      "\t TVw: -0.571088 | TVb: -1.971888 | GSw: -0.428285 | GSb: -0.145145 | TSUw: 0.250402 | TSUb: 0.186611\n",
      "\n",
      "Train Epoch: 2145 [4000/8000 (50%)]\tBatch Loss: 0.018655\tLearning Rate (w_theta): 0.001000\t TIME:571.9s\n",
      "\t\t\t\tDisc: 0.013494\t\tSym: 0.000598\t\tSpars: 0.004563\n",
      "\t TVw: -0.571082 | TVb: -1.971866 | GSw: -0.428373 | GSb: -0.145264 | TSUw: 0.250288 | TSUb: 0.186619\n",
      "Validating epoch 2145...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01862795518568522\n",
      "Average validation loss: 0.018119810427603848\n",
      "Training epoch 2146...\n",
      "\n",
      "Train Epoch: 2146 [0/8000 (0%)]\tBatch Loss: 0.018497\tLearning Rate (w_theta): 0.001000\t TIME:574.4s\n",
      "\t\t\t\tDisc: 0.013389\t\tSym: 0.000580\t\tSpars: 0.004528\n",
      "\t TVw: -0.571106 | TVb: -1.971860 | GSw: -0.428462 | GSb: -0.145384 | TSUw: 0.250177 | TSUb: 0.186626\n",
      "\n",
      "Train Epoch: 2146 [4000/8000 (50%)]\tBatch Loss: 0.018767\tLearning Rate (w_theta): 0.001000\t TIME:575.9s\n",
      "\t\t\t\tDisc: 0.013630\t\tSym: 0.000595\t\tSpars: 0.004542\n",
      "\t TVw: -0.571107 | TVb: -1.971840 | GSw: -0.428548 | GSb: -0.145502 | TSUw: 0.250068 | TSUb: 0.186631\n",
      "Validating epoch 2146...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0186047328301735\n",
      "Average validation loss: 0.01811237888298623\n",
      "Training epoch 2147...\n",
      "\n",
      "Train Epoch: 2147 [0/8000 (0%)]\tBatch Loss: 0.018984\tLearning Rate (w_theta): 0.001000\t TIME:578.3s\n",
      "\t\t\t\tDisc: 0.013759\t\tSym: 0.000622\t\tSpars: 0.004603\n",
      "\t TVw: -0.571128 | TVb: -1.971832 | GSw: -0.428637 | GSb: -0.145623 | TSUw: 0.249956 | TSUb: 0.186638\n",
      "\n",
      "Train Epoch: 2147 [4000/8000 (50%)]\tBatch Loss: 0.018701\tLearning Rate (w_theta): 0.001000\t TIME:579.8s\n",
      "\t\t\t\tDisc: 0.013558\t\tSym: 0.000589\t\tSpars: 0.004554\n",
      "\t TVw: -0.571157 | TVb: -1.971830 | GSw: -0.428726 | GSb: -0.145743 | TSUw: 0.249846 | TSUb: 0.186643\n",
      "Validating epoch 2147...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018598695929147823\n",
      "Average validation loss: 0.018130875828758372\n",
      "Training epoch 2148...\n",
      "\n",
      "Train Epoch: 2148 [0/8000 (0%)]\tBatch Loss: 0.019311\tLearning Rate (w_theta): 0.001000\t TIME:582.1s\n",
      "\t\t\t\tDisc: 0.014082\t\tSym: 0.000623\t\tSpars: 0.004606\n",
      "\t TVw: -0.571154 | TVb: -1.971807 | GSw: -0.428814 | GSb: -0.145864 | TSUw: 0.249732 | TSUb: 0.186651\n",
      "\n",
      "Train Epoch: 2148 [4000/8000 (50%)]\tBatch Loss: 0.018328\tLearning Rate (w_theta): 0.001000\t TIME:583.7s\n",
      "\t\t\t\tDisc: 0.013221\t\tSym: 0.000590\t\tSpars: 0.004518\n",
      "\t TVw: -0.571170 | TVb: -1.971797 | GSw: -0.428907 | GSb: -0.145988 | TSUw: 0.249615 | TSUb: 0.186661\n",
      "Validating epoch 2148...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018593204100252347\n",
      "Average validation loss: 0.0181420552252141\n",
      "Training epoch 2149...\n",
      "\n",
      "Train Epoch: 2149 [0/8000 (0%)]\tBatch Loss: 0.018333\tLearning Rate (w_theta): 0.001000\t TIME:586.1s\n",
      "\t\t\t\tDisc: 0.013206\t\tSym: 0.000593\t\tSpars: 0.004535\n",
      "\t TVw: -0.571193 | TVb: -1.971791 | GSw: -0.428998 | GSb: -0.146112 | TSUw: 0.249500 | TSUb: 0.186669\n",
      "\n",
      "Train Epoch: 2149 [4000/8000 (50%)]\tBatch Loss: 0.019083\tLearning Rate (w_theta): 0.001000\t TIME:587.6s\n",
      "\t\t\t\tDisc: 0.013817\t\tSym: 0.000629\t\tSpars: 0.004637\n",
      "\t TVw: -0.571216 | TVb: -1.971780 | GSw: -0.429089 | GSb: -0.146235 | TSUw: 0.249385 | TSUb: 0.186677\n",
      "Validating epoch 2149...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01857710522290571\n",
      "Average validation loss: 0.018096293655666316\n",
      "Training epoch 2150...\n",
      "\n",
      "Train Epoch: 2150 [0/8000 (0%)]\tBatch Loss: 0.018417\tLearning Rate (w_theta): 0.001000\t TIME:590.1s\n",
      "\t\t\t\tDisc: 0.013276\t\tSym: 0.000597\t\tSpars: 0.004544\n",
      "\t TVw: -0.571226 | TVb: -1.971766 | GSw: -0.429180 | GSb: -0.146359 | TSUw: 0.249268 | TSUb: 0.186685\n",
      "\n",
      "Train Epoch: 2150 [4000/8000 (50%)]\tBatch Loss: 0.018580\tLearning Rate (w_theta): 0.001000\t TIME:591.6s\n",
      "\t\t\t\tDisc: 0.013450\t\tSym: 0.000599\t\tSpars: 0.004532\n",
      "\t TVw: -0.571238 | TVb: -1.971755 | GSw: -0.429270 | GSb: -0.146481 | TSUw: 0.249153 | TSUb: 0.186693\n",
      "Validating epoch 2150...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01865755776521783\n",
      "Average validation loss: 0.018080396303047013\n",
      "Training epoch 2151...\n",
      "\n",
      "Train Epoch: 2151 [0/8000 (0%)]\tBatch Loss: 0.018378\tLearning Rate (w_theta): 0.001000\t TIME:594.5s\n",
      "\t\t\t\tDisc: 0.013192\t\tSym: 0.000617\t\tSpars: 0.004569\n",
      "\t TVw: -0.571266 | TVb: -1.971751 | GSw: -0.429368 | GSb: -0.146611 | TSUw: 0.249030 | TSUb: 0.186705\n",
      "\n",
      "Train Epoch: 2151 [4000/8000 (50%)]\tBatch Loss: 0.018992\tLearning Rate (w_theta): 0.001000\t TIME:596.1s\n",
      "\t\t\t\tDisc: 0.013750\t\tSym: 0.000628\t\tSpars: 0.004613\n",
      "\t TVw: -0.571292 | TVb: -1.971746 | GSw: -0.429465 | GSb: -0.146740 | TSUw: 0.248905 | TSUb: 0.186718\n",
      "Validating epoch 2151...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01881146129183619\n",
      "Average validation loss: 0.018223883571404333\n",
      "Training epoch 2152...\n",
      "\n",
      "Train Epoch: 2152 [0/8000 (0%)]\tBatch Loss: 0.018922\tLearning Rate (w_theta): 0.001000\t TIME:598.5s\n",
      "\t\t\t\tDisc: 0.013764\t\tSym: 0.000603\t\tSpars: 0.004555\n",
      "\t TVw: -0.571335 | TVb: -1.971751 | GSw: -0.429562 | GSb: -0.146869 | TSUw: 0.248781 | TSUb: 0.186730\n",
      "\n",
      "Train Epoch: 2152 [4000/8000 (50%)]\tBatch Loss: 0.019054\tLearning Rate (w_theta): 0.001000\t TIME:600.0s\n",
      "\t\t\t\tDisc: 0.013886\t\tSym: 0.000589\t\tSpars: 0.004580\n",
      "\t TVw: -0.571391 | TVb: -1.971766 | GSw: -0.429658 | GSb: -0.146997 | TSUw: 0.248658 | TSUb: 0.186742\n",
      "Validating epoch 2152...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01874185526263296\n",
      "Average validation loss: 0.018266673026930146\n",
      "Training epoch 2153...\n",
      "\n",
      "Train Epoch: 2153 [0/8000 (0%)]\tBatch Loss: 0.018427\tLearning Rate (w_theta): 0.001000\t TIME:602.4s\n",
      "\t\t\t\tDisc: 0.013325\t\tSym: 0.000564\t\tSpars: 0.004538\n",
      "\t TVw: -0.571440 | TVb: -1.971775 | GSw: -0.429753 | GSb: -0.147124 | TSUw: 0.248535 | TSUb: 0.186753\n",
      "\n",
      "Train Epoch: 2153 [4000/8000 (50%)]\tBatch Loss: 0.018758\tLearning Rate (w_theta): 0.001000\t TIME:604.0s\n",
      "\t\t\t\tDisc: 0.013533\t\tSym: 0.000594\t\tSpars: 0.004630\n",
      "\t TVw: -0.571470 | TVb: -1.971774 | GSw: -0.429847 | GSb: -0.147250 | TSUw: 0.248413 | TSUb: 0.186764\n",
      "Validating epoch 2153...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018692908565196436\n",
      "Average validation loss: 0.018133997887701342\n",
      "Training epoch 2154...\n",
      "\n",
      "Train Epoch: 2154 [0/8000 (0%)]\tBatch Loss: 0.018304\tLearning Rate (w_theta): 0.001000\t TIME:606.3s\n",
      "\t\t\t\tDisc: 0.013137\t\tSym: 0.000580\t\tSpars: 0.004587\n",
      "\t TVw: -0.571465 | TVb: -1.971753 | GSw: -0.429940 | GSb: -0.147374 | TSUw: 0.248290 | TSUb: 0.186775\n",
      "\n",
      "Train Epoch: 2154 [4000/8000 (50%)]\tBatch Loss: 0.018841\tLearning Rate (w_theta): 0.001000\t TIME:607.8s\n",
      "\t\t\t\tDisc: 0.013583\t\tSym: 0.000607\t\tSpars: 0.004650\n",
      "\t TVw: -0.571451 | TVb: -1.971728 | GSw: -0.430034 | GSb: -0.147497 | TSUw: 0.248166 | TSUb: 0.186787\n",
      "Validating epoch 2154...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01862242645090976\n",
      "Average validation loss: 0.018123987504306813\n",
      "Training epoch 2155...\n",
      "\n",
      "Train Epoch: 2155 [0/8000 (0%)]\tBatch Loss: 0.018471\tLearning Rate (w_theta): 0.001000\t TIME:610.2s\n",
      "\t\t\t\tDisc: 0.013309\t\tSym: 0.000586\t\tSpars: 0.004576\n",
      "\t TVw: -0.571441 | TVb: -1.971702 | GSw: -0.430128 | GSb: -0.147622 | TSUw: 0.248043 | TSUb: 0.186797\n",
      "\n",
      "Train Epoch: 2155 [4000/8000 (50%)]\tBatch Loss: 0.018957\tLearning Rate (w_theta): 0.001000\t TIME:611.8s\n",
      "\t\t\t\tDisc: 0.013785\t\tSym: 0.000589\t\tSpars: 0.004584\n",
      "\t TVw: -0.571408 | TVb: -1.971662 | GSw: -0.430219 | GSb: -0.147744 | TSUw: 0.247922 | TSUb: 0.186807\n",
      "Validating epoch 2155...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018585664962239856\n",
      "Average validation loss: 0.018045340439174752\n",
      "Training epoch 2156...\n",
      "\n",
      "Train Epoch: 2156 [0/8000 (0%)]\tBatch Loss: 0.018821\tLearning Rate (w_theta): 0.001000\t TIME:614.1s\n",
      "\t\t\t\tDisc: 0.013653\t\tSym: 0.000595\t\tSpars: 0.004573\n",
      "\t TVw: -0.571395 | TVb: -1.971631 | GSw: -0.430312 | GSb: -0.147868 | TSUw: 0.247800 | TSUb: 0.186817\n",
      "\n",
      "Train Epoch: 2156 [4000/8000 (50%)]\tBatch Loss: 0.018475\tLearning Rate (w_theta): 0.001000\t TIME:615.7s\n",
      "\t\t\t\tDisc: 0.013331\t\tSym: 0.000592\t\tSpars: 0.004553\n",
      "\t TVw: -0.571396 | TVb: -1.971609 | GSw: -0.430406 | GSb: -0.147994 | TSUw: 0.247680 | TSUb: 0.186826\n",
      "Validating epoch 2156...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018551357410066145\n",
      "Average validation loss: 0.018032994140674774\n",
      "Training epoch 2157...\n",
      "\n",
      "Train Epoch: 2157 [0/8000 (0%)]\tBatch Loss: 0.018860\tLearning Rate (w_theta): 0.001000\t TIME:618.2s\n",
      "\t\t\t\tDisc: 0.013707\t\tSym: 0.000600\t\tSpars: 0.004553\n",
      "\t TVw: -0.571365 | TVb: -1.971568 | GSw: -0.430494 | GSb: -0.148113 | TSUw: 0.247565 | TSUb: 0.186832\n",
      "\n",
      "Train Epoch: 2157 [4000/8000 (50%)]\tBatch Loss: 0.018500\tLearning Rate (w_theta): 0.001000\t TIME:619.7s\n",
      "\t\t\t\tDisc: 0.013411\t\tSym: 0.000583\t\tSpars: 0.004507\n",
      "\t TVw: -0.571393 | TVb: -1.971563 | GSw: -0.430586 | GSb: -0.148237 | TSUw: 0.247450 | TSUb: 0.186837\n",
      "Validating epoch 2157...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01853395960514382\n",
      "Average validation loss: 0.01801111605226313\n",
      "Training epoch 2158...\n",
      "\n",
      "Train Epoch: 2158 [0/8000 (0%)]\tBatch Loss: 0.019258\tLearning Rate (w_theta): 0.001000\t TIME:622.0s\n",
      "\t\t\t\tDisc: 0.014043\t\tSym: 0.000623\t\tSpars: 0.004591\n",
      "\t TVw: -0.571436 | TVb: -1.971568 | GSw: -0.430680 | GSb: -0.148364 | TSUw: 0.247334 | TSUb: 0.186843\n",
      "\n",
      "Train Epoch: 2158 [4000/8000 (50%)]\tBatch Loss: 0.018495\tLearning Rate (w_theta): 0.001000\t TIME:623.6s\n",
      "\t\t\t\tDisc: 0.013426\t\tSym: 0.000580\t\tSpars: 0.004489\n",
      "\t TVw: -0.571424 | TVb: -1.971539 | GSw: -0.430770 | GSb: -0.148487 | TSUw: 0.247218 | TSUb: 0.186849\n",
      "Validating epoch 2158...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01851654877104114\n",
      "Average validation loss: 0.018034780782865897\n",
      "Training epoch 2159...\n",
      "\n",
      "Train Epoch: 2159 [0/8000 (0%)]\tBatch Loss: 0.018547\tLearning Rate (w_theta): 0.001000\t TIME:626.0s\n",
      "\t\t\t\tDisc: 0.013469\t\tSym: 0.000586\t\tSpars: 0.004493\n",
      "\t TVw: -0.571420 | TVb: -1.971516 | GSw: -0.430860 | GSb: -0.148609 | TSUw: 0.247103 | TSUb: 0.186854\n",
      "\n",
      "Train Epoch: 2159 [4000/8000 (50%)]\tBatch Loss: 0.018209\tLearning Rate (w_theta): 0.001000\t TIME:627.5s\n",
      "\t\t\t\tDisc: 0.013120\t\tSym: 0.000587\t\tSpars: 0.004502\n",
      "\t TVw: -0.571467 | TVb: -1.971525 | GSw: -0.430953 | GSb: -0.148735 | TSUw: 0.246988 | TSUb: 0.186858\n",
      "Validating epoch 2159...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01848950067213563\n",
      "Average validation loss: 0.018000632029541858\n",
      "Training epoch 2160...\n",
      "\n",
      "Train Epoch: 2160 [0/8000 (0%)]\tBatch Loss: 0.018339\tLearning Rate (w_theta): 0.001000\t TIME:629.9s\n",
      "\t\t\t\tDisc: 0.013273\t\tSym: 0.000584\t\tSpars: 0.004483\n",
      "\t TVw: -0.571494 | TVb: -1.971519 | GSw: -0.431047 | GSb: -0.148862 | TSUw: 0.246871 | TSUb: 0.186865\n",
      "\n",
      "Train Epoch: 2160 [4000/8000 (50%)]\tBatch Loss: 0.018385\tLearning Rate (w_theta): 0.001000\t TIME:631.4s\n",
      "\t\t\t\tDisc: 0.013278\t\tSym: 0.000601\t\tSpars: 0.004507\n",
      "\t TVw: -0.571483 | TVb: -1.971491 | GSw: -0.431137 | GSb: -0.148985 | TSUw: 0.246755 | TSUb: 0.186870\n",
      "Validating epoch 2160...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01847059667087734\n",
      "Average validation loss: 0.01798942775060218\n",
      "Training epoch 2161...\n",
      "\n",
      "Train Epoch: 2161 [0/8000 (0%)]\tBatch Loss: 0.018375\tLearning Rate (w_theta): 0.001000\t TIME:634.5s\n",
      "\t\t\t\tDisc: 0.013319\t\tSym: 0.000585\t\tSpars: 0.004471\n",
      "\t TVw: -0.571494 | TVb: -1.971477 | GSw: -0.431230 | GSb: -0.149111 | TSUw: 0.246637 | TSUb: 0.186876\n",
      "\n",
      "Train Epoch: 2161 [4000/8000 (50%)]\tBatch Loss: 0.018126\tLearning Rate (w_theta): 0.001000\t TIME:636.0s\n",
      "\t\t\t\tDisc: 0.013065\t\tSym: 0.000583\t\tSpars: 0.004478\n",
      "\t TVw: -0.571528 | TVb: -1.971478 | GSw: -0.431328 | GSb: -0.149242 | TSUw: 0.246515 | TSUb: 0.186884\n",
      "Validating epoch 2161...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0184575953604807\n",
      "Average validation loss: 0.01797383045841923\n",
      "Training epoch 2162...\n",
      "\n",
      "Train Epoch: 2162 [0/8000 (0%)]\tBatch Loss: 0.017852\tLearning Rate (w_theta): 0.001000\t TIME:638.4s\n",
      "\t\t\t\tDisc: 0.012886\t\tSym: 0.000560\t\tSpars: 0.004405\n",
      "\t TVw: -0.571530 | TVb: -1.971457 | GSw: -0.431421 | GSb: -0.149368 | TSUw: 0.246396 | TSUb: 0.186890\n",
      "\n",
      "Train Epoch: 2162 [4000/8000 (50%)]\tBatch Loss: 0.018785\tLearning Rate (w_theta): 0.001000\t TIME:639.9s\n",
      "\t\t\t\tDisc: 0.013701\t\tSym: 0.000598\t\tSpars: 0.004486\n",
      "\t TVw: -0.571518 | TVb: -1.971424 | GSw: -0.431514 | GSb: -0.149494 | TSUw: 0.246274 | TSUb: 0.186898\n",
      "Validating epoch 2162...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01845128661825603\n",
      "Average validation loss: 0.01795626120654422\n",
      "Training epoch 2163...\n",
      "\n",
      "Train Epoch: 2163 [0/8000 (0%)]\tBatch Loss: 0.018800\tLearning Rate (w_theta): 0.001000\t TIME:642.3s\n",
      "\t\t\t\tDisc: 0.013702\t\tSym: 0.000597\t\tSpars: 0.004501\n",
      "\t TVw: -0.571579 | TVb: -1.971438 | GSw: -0.431614 | GSb: -0.149628 | TSUw: 0.246153 | TSUb: 0.186906\n",
      "\n",
      "Train Epoch: 2163 [4000/8000 (50%)]\tBatch Loss: 0.018747\tLearning Rate (w_theta): 0.001000\t TIME:643.8s\n",
      "\t\t\t\tDisc: 0.013602\t\tSym: 0.000610\t\tSpars: 0.004536\n",
      "\t TVw: -0.571595 | TVb: -1.971424 | GSw: -0.431710 | GSb: -0.149758 | TSUw: 0.246032 | TSUb: 0.186913\n",
      "Validating epoch 2163...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018451182473599764\n",
      "Average validation loss: 0.0179725173241937\n",
      "Training epoch 2164...\n",
      "\n",
      "Train Epoch: 2164 [0/8000 (0%)]\tBatch Loss: 0.017985\tLearning Rate (w_theta): 0.001000\t TIME:646.3s\n",
      "\t\t\t\tDisc: 0.012955\t\tSym: 0.000585\t\tSpars: 0.004446\n",
      "\t TVw: -0.571586 | TVb: -1.971396 | GSw: -0.431802 | GSb: -0.149883 | TSUw: 0.245912 | TSUb: 0.186919\n",
      "\n",
      "Train Epoch: 2164 [4000/8000 (50%)]\tBatch Loss: 0.018735\tLearning Rate (w_theta): 0.001000\t TIME:647.8s\n",
      "\t\t\t\tDisc: 0.013635\t\tSym: 0.000594\t\tSpars: 0.004506\n",
      "\t TVw: -0.571630 | TVb: -1.971405 | GSw: -0.431897 | GSb: -0.150013 | TSUw: 0.245794 | TSUb: 0.186924\n",
      "Validating epoch 2164...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018437842522992288\n",
      "Average validation loss: 0.017939672393119437\n",
      "Training epoch 2165...\n",
      "\n",
      "Train Epoch: 2165 [0/8000 (0%)]\tBatch Loss: 0.018232\tLearning Rate (w_theta): 0.001000\t TIME:650.2s\n",
      "\t\t\t\tDisc: 0.013173\t\tSym: 0.000586\t\tSpars: 0.004473\n",
      "\t TVw: -0.571647 | TVb: -1.971394 | GSw: -0.431993 | GSb: -0.150142 | TSUw: 0.245672 | TSUb: 0.186932\n",
      "\n",
      "Train Epoch: 2165 [4000/8000 (50%)]\tBatch Loss: 0.018461\tLearning Rate (w_theta): 0.001000\t TIME:651.8s\n",
      "\t\t\t\tDisc: 0.013398\t\tSym: 0.000586\t\tSpars: 0.004478\n",
      "\t TVw: -0.571655 | TVb: -1.971377 | GSw: -0.432089 | GSb: -0.150272 | TSUw: 0.245550 | TSUb: 0.186939\n",
      "Validating epoch 2165...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01842019403493142\n",
      "Average validation loss: 0.0179769415582395\n",
      "Training epoch 2166...\n",
      "\n",
      "Train Epoch: 2166 [0/8000 (0%)]\tBatch Loss: 0.018685\tLearning Rate (w_theta): 0.001000\t TIME:654.1s\n",
      "\t\t\t\tDisc: 0.013570\t\tSym: 0.000607\t\tSpars: 0.004508\n",
      "\t TVw: -0.571642 | TVb: -1.971346 | GSw: -0.432184 | GSb: -0.150400 | TSUw: 0.245426 | TSUb: 0.186947\n",
      "\n",
      "Train Epoch: 2166 [4000/8000 (50%)]\tBatch Loss: 0.018067\tLearning Rate (w_theta): 0.001000\t TIME:655.6s\n",
      "\t\t\t\tDisc: 0.013030\t\tSym: 0.000580\t\tSpars: 0.004458\n",
      "\t TVw: -0.571660 | TVb: -1.971334 | GSw: -0.432284 | GSb: -0.150533 | TSUw: 0.245300 | TSUb: 0.186955\n",
      "Validating epoch 2166...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018428380690964394\n",
      "Average validation loss: 0.017921248581371348\n",
      "Training epoch 2167...\n",
      "\n",
      "Train Epoch: 2167 [0/8000 (0%)]\tBatch Loss: 0.018129\tLearning Rate (w_theta): 0.001000\t TIME:658.0s\n",
      "\t\t\t\tDisc: 0.013085\t\tSym: 0.000584\t\tSpars: 0.004461\n",
      "\t TVw: -0.571673 | TVb: -1.971319 | GSw: -0.432382 | GSb: -0.150664 | TSUw: 0.245176 | TSUb: 0.186963\n",
      "\n",
      "Train Epoch: 2167 [4000/8000 (50%)]\tBatch Loss: 0.018537\tLearning Rate (w_theta): 0.001000\t TIME:659.5s\n",
      "\t\t\t\tDisc: 0.013470\t\tSym: 0.000592\t\tSpars: 0.004475\n",
      "\t TVw: -0.571691 | TVb: -1.971308 | GSw: -0.432477 | GSb: -0.150792 | TSUw: 0.245056 | TSUb: 0.186968\n",
      "Validating epoch 2167...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018396463262547697\n",
      "Average validation loss: 0.017919916503407025\n",
      "Training epoch 2168...\n",
      "\n",
      "Train Epoch: 2168 [0/8000 (0%)]\tBatch Loss: 0.018081\tLearning Rate (w_theta): 0.001000\t TIME:662.0s\n",
      "\t\t\t\tDisc: 0.013060\t\tSym: 0.000579\t\tSpars: 0.004442\n",
      "\t TVw: -0.571695 | TVb: -1.971289 | GSw: -0.432573 | GSb: -0.150922 | TSUw: 0.244933 | TSUb: 0.186975\n",
      "\n",
      "Train Epoch: 2168 [4000/8000 (50%)]\tBatch Loss: 0.018520\tLearning Rate (w_theta): 0.001000\t TIME:663.5s\n",
      "\t\t\t\tDisc: 0.013483\t\tSym: 0.000583\t\tSpars: 0.004453\n",
      "\t TVw: -0.571724 | TVb: -1.971287 | GSw: -0.432670 | GSb: -0.151052 | TSUw: 0.244811 | TSUb: 0.186981\n",
      "Validating epoch 2168...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018397608809121627\n",
      "Average validation loss: 0.017892884229331295\n",
      "Training epoch 2169...\n",
      "\n",
      "Train Epoch: 2169 [0/8000 (0%)]\tBatch Loss: 0.018471\tLearning Rate (w_theta): 0.001000\t TIME:665.9s\n",
      "\t\t\t\tDisc: 0.013411\t\tSym: 0.000595\t\tSpars: 0.004465\n",
      "\t TVw: -0.571736 | TVb: -1.971272 | GSw: -0.432767 | GSb: -0.151183 | TSUw: 0.244688 | TSUb: 0.186988\n",
      "\n",
      "Train Epoch: 2169 [4000/8000 (50%)]\tBatch Loss: 0.018118\tLearning Rate (w_theta): 0.001000\t TIME:667.4s\n",
      "\t\t\t\tDisc: 0.013093\t\tSym: 0.000580\t\tSpars: 0.004445\n",
      "\t TVw: -0.571745 | TVb: -1.971253 | GSw: -0.432864 | GSb: -0.151314 | TSUw: 0.244564 | TSUb: 0.186995\n",
      "Validating epoch 2169...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018380619826315305\n",
      "Average validation loss: 0.017897280482127985\n",
      "Training epoch 2170...\n",
      "\n",
      "Train Epoch: 2170 [0/8000 (0%)]\tBatch Loss: 0.018877\tLearning Rate (w_theta): 0.001000\t TIME:669.8s\n",
      "\t\t\t\tDisc: 0.013767\t\tSym: 0.000605\t\tSpars: 0.004506\n",
      "\t TVw: -0.571771 | TVb: -1.971247 | GSw: -0.432962 | GSb: -0.151447 | TSUw: 0.244441 | TSUb: 0.187001\n",
      "\n",
      "Train Epoch: 2170 [4000/8000 (50%)]\tBatch Loss: 0.018154\tLearning Rate (w_theta): 0.001000\t TIME:671.3s\n",
      "\t\t\t\tDisc: 0.013194\t\tSym: 0.000566\t\tSpars: 0.004394\n",
      "\t TVw: -0.571781 | TVb: -1.971235 | GSw: -0.433058 | GSb: -0.151576 | TSUw: 0.244320 | TSUb: 0.187006\n",
      "Validating epoch 2170...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018391262905956683\n",
      "Average validation loss: 0.017960990665934533\n",
      "Training epoch 2171...\n",
      "\n",
      "Train Epoch: 2171 [0/8000 (0%)]\tBatch Loss: 0.018487\tLearning Rate (w_theta): 0.001000\t TIME:674.4s\n",
      "\t\t\t\tDisc: 0.013395\t\tSym: 0.000601\t\tSpars: 0.004492\n",
      "\t TVw: -0.571792 | TVb: -1.971219 | GSw: -0.433157 | GSb: -0.151708 | TSUw: 0.244194 | TSUb: 0.187013\n",
      "\n",
      "Train Epoch: 2171 [4000/8000 (50%)]\tBatch Loss: 0.018513\tLearning Rate (w_theta): 0.001000\t TIME:675.9s\n",
      "\t\t\t\tDisc: 0.013526\t\tSym: 0.000567\t\tSpars: 0.004419\n",
      "\t TVw: -0.571822 | TVb: -1.971215 | GSw: -0.433256 | GSb: -0.151842 | TSUw: 0.244068 | TSUb: 0.187021\n",
      "Validating epoch 2171...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018432865934495852\n",
      "Average validation loss: 0.017955638976007247\n",
      "Training epoch 2172...\n",
      "\n",
      "Train Epoch: 2172 [0/8000 (0%)]\tBatch Loss: 0.018442\tLearning Rate (w_theta): 0.001000\t TIME:678.3s\n",
      "\t\t\t\tDisc: 0.013431\t\tSym: 0.000573\t\tSpars: 0.004439\n",
      "\t TVw: -0.571830 | TVb: -1.971198 | GSw: -0.433353 | GSb: -0.151973 | TSUw: 0.243943 | TSUb: 0.187027\n",
      "\n",
      "Train Epoch: 2172 [4000/8000 (50%)]\tBatch Loss: 0.018263\tLearning Rate (w_theta): 0.001000\t TIME:679.8s\n",
      "\t\t\t\tDisc: 0.013243\t\tSym: 0.000577\t\tSpars: 0.004443\n",
      "\t TVw: -0.571851 | TVb: -1.971189 | GSw: -0.433453 | GSb: -0.152107 | TSUw: 0.243817 | TSUb: 0.187034\n",
      "Validating epoch 2172...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018416789525809735\n",
      "Average validation loss: 0.017903269829148895\n",
      "Training epoch 2173...\n",
      "\n",
      "Train Epoch: 2173 [0/8000 (0%)]\tBatch Loss: 0.018559\tLearning Rate (w_theta): 0.001000\t TIME:682.2s\n",
      "\t\t\t\tDisc: 0.013497\t\tSym: 0.000583\t\tSpars: 0.004479\n",
      "\t TVw: -0.571874 | TVb: -1.971181 | GSw: -0.433552 | GSb: -0.152240 | TSUw: 0.243690 | TSUb: 0.187041\n",
      "\n",
      "Train Epoch: 2173 [4000/8000 (50%)]\tBatch Loss: 0.018518\tLearning Rate (w_theta): 0.001000\t TIME:683.8s\n",
      "\t\t\t\tDisc: 0.013424\t\tSym: 0.000598\t\tSpars: 0.004496\n",
      "\t TVw: -0.571884 | TVb: -1.971161 | GSw: -0.433650 | GSb: -0.152372 | TSUw: 0.243565 | TSUb: 0.187048\n",
      "Validating epoch 2173...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018373606037778885\n",
      "Average validation loss: 0.01787051185146021\n",
      "Training epoch 2174...\n",
      "\n",
      "Train Epoch: 2174 [0/8000 (0%)]\tBatch Loss: 0.018689\tLearning Rate (w_theta): 0.001000\t TIME:686.1s\n",
      "\t\t\t\tDisc: 0.013595\t\tSym: 0.000601\t\tSpars: 0.004493\n",
      "\t TVw: -0.571893 | TVb: -1.971145 | GSw: -0.433749 | GSb: -0.152504 | TSUw: 0.243440 | TSUb: 0.187054\n",
      "\n",
      "Train Epoch: 2174 [4000/8000 (50%)]\tBatch Loss: 0.018335\tLearning Rate (w_theta): 0.001000\t TIME:687.7s\n",
      "\t\t\t\tDisc: 0.013312\t\tSym: 0.000582\t\tSpars: 0.004441\n",
      "\t TVw: -0.571886 | TVb: -1.971122 | GSw: -0.433847 | GSb: -0.152636 | TSUw: 0.243314 | TSUb: 0.187060\n",
      "Validating epoch 2174...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01834867131105776\n",
      "Average validation loss: 0.017854580745186824\n",
      "Training epoch 2175...\n",
      "\n",
      "Train Epoch: 2175 [0/8000 (0%)]\tBatch Loss: 0.018323\tLearning Rate (w_theta): 0.001000\t TIME:690.1s\n",
      "\t\t\t\tDisc: 0.013319\t\tSym: 0.000579\t\tSpars: 0.004425\n",
      "\t TVw: -0.571886 | TVb: -1.971102 | GSw: -0.433944 | GSb: -0.152766 | TSUw: 0.243191 | TSUb: 0.187065\n",
      "\n",
      "Train Epoch: 2175 [4000/8000 (50%)]\tBatch Loss: 0.018187\tLearning Rate (w_theta): 0.001000\t TIME:691.6s\n",
      "\t\t\t\tDisc: 0.013174\t\tSym: 0.000583\t\tSpars: 0.004430\n",
      "\t TVw: -0.571912 | TVb: -1.971092 | GSw: -0.434044 | GSb: -0.152900 | TSUw: 0.243066 | TSUb: 0.187070\n",
      "Validating epoch 2175...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018333550140547415\n",
      "Average validation loss: 0.017827506165700804\n",
      "Training epoch 2176...\n",
      "\n",
      "Train Epoch: 2176 [0/8000 (0%)]\tBatch Loss: 0.018158\tLearning Rate (w_theta): 0.001000\t TIME:694.1s\n",
      "\t\t\t\tDisc: 0.013208\t\tSym: 0.000565\t\tSpars: 0.004385\n",
      "\t TVw: -0.571918 | TVb: -1.971073 | GSw: -0.434141 | GSb: -0.153031 | TSUw: 0.242944 | TSUb: 0.187074\n",
      "\n",
      "Train Epoch: 2176 [4000/8000 (50%)]\tBatch Loss: 0.017720\tLearning Rate (w_theta): 0.001000\t TIME:695.6s\n",
      "\t\t\t\tDisc: 0.012771\t\tSym: 0.000564\t\tSpars: 0.004384\n",
      "\t TVw: -0.571928 | TVb: -1.971059 | GSw: -0.434238 | GSb: -0.153162 | TSUw: 0.242821 | TSUb: 0.187078\n",
      "Validating epoch 2176...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0183192030940115\n",
      "Average validation loss: 0.017844668239261785\n",
      "Training epoch 2177...\n",
      "\n",
      "Train Epoch: 2177 [0/8000 (0%)]\tBatch Loss: 0.018354\tLearning Rate (w_theta): 0.001000\t TIME:698.0s\n",
      "\t\t\t\tDisc: 0.013350\t\tSym: 0.000584\t\tSpars: 0.004420\n",
      "\t TVw: -0.571966 | TVb: -1.971061 | GSw: -0.434339 | GSb: -0.153297 | TSUw: 0.242696 | TSUb: 0.187083\n",
      "\n",
      "Train Epoch: 2177 [4000/8000 (50%)]\tBatch Loss: 0.018110\tLearning Rate (w_theta): 0.001000\t TIME:699.6s\n",
      "\t\t\t\tDisc: 0.013093\t\tSym: 0.000580\t\tSpars: 0.004437\n",
      "\t TVw: -0.571983 | TVb: -1.971051 | GSw: -0.434439 | GSb: -0.153432 | TSUw: 0.242571 | TSUb: 0.187088\n",
      "Validating epoch 2177...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018315772114004602\n",
      "Average validation loss: 0.01782373181091429\n",
      "Training epoch 2178...\n",
      "\n",
      "Train Epoch: 2178 [0/8000 (0%)]\tBatch Loss: 0.017941\tLearning Rate (w_theta): 0.001000\t TIME:702.0s\n",
      "\t\t\t\tDisc: 0.012969\t\tSym: 0.000573\t\tSpars: 0.004399\n",
      "\t TVw: -0.571973 | TVb: -1.971025 | GSw: -0.434536 | GSb: -0.153563 | TSUw: 0.242446 | TSUb: 0.187093\n",
      "\n",
      "Train Epoch: 2178 [4000/8000 (50%)]\tBatch Loss: 0.018438\tLearning Rate (w_theta): 0.001000\t TIME:703.5s\n",
      "\t\t\t\tDisc: 0.013413\t\tSym: 0.000591\t\tSpars: 0.004434\n",
      "\t TVw: -0.572016 | TVb: -1.971032 | GSw: -0.434638 | GSb: -0.153700 | TSUw: 0.242319 | TSUb: 0.187099\n",
      "Validating epoch 2178...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018324849447007564\n",
      "Average validation loss: 0.017811902114652178\n",
      "Training epoch 2179...\n",
      "\n",
      "Train Epoch: 2179 [0/8000 (0%)]\tBatch Loss: 0.018338\tLearning Rate (w_theta): 0.001000\t TIME:705.9s\n",
      "\t\t\t\tDisc: 0.013332\t\tSym: 0.000584\t\tSpars: 0.004422\n",
      "\t TVw: -0.572058 | TVb: -1.971033 | GSw: -0.434741 | GSb: -0.153838 | TSUw: 0.242191 | TSUb: 0.187105\n",
      "\n",
      "Train Epoch: 2179 [4000/8000 (50%)]\tBatch Loss: 0.018329\tLearning Rate (w_theta): 0.001000\t TIME:707.4s\n",
      "\t\t\t\tDisc: 0.013313\t\tSym: 0.000576\t\tSpars: 0.004440\n",
      "\t TVw: -0.572056 | TVb: -1.971010 | GSw: -0.434843 | GSb: -0.153973 | TSUw: 0.242061 | TSUb: 0.187111\n",
      "Validating epoch 2179...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018302061975024927\n",
      "Average validation loss: 0.017844371808119885\n",
      "Training epoch 2180...\n",
      "\n",
      "Train Epoch: 2180 [0/8000 (0%)]\tBatch Loss: 0.018553\tLearning Rate (w_theta): 0.001000\t TIME:709.7s\n",
      "\t\t\t\tDisc: 0.013464\t\tSym: 0.000608\t\tSpars: 0.004482\n",
      "\t TVw: -0.572029 | TVb: -1.970969 | GSw: -0.434940 | GSb: -0.154105 | TSUw: 0.241933 | TSUb: 0.187117\n",
      "\n",
      "Train Epoch: 2180 [4000/8000 (50%)]\tBatch Loss: 0.018226\tLearning Rate (w_theta): 0.001000\t TIME:711.2s\n",
      "\t\t\t\tDisc: 0.013262\t\tSym: 0.000578\t\tSpars: 0.004385\n",
      "\t TVw: -0.572059 | TVb: -1.970960 | GSw: -0.435044 | GSb: -0.154243 | TSUw: 0.241803 | TSUb: 0.187124\n",
      "Validating epoch 2180...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01830571089886614\n",
      "Average validation loss: 0.017817620280300896\n",
      "Training epoch 2181...\n",
      "\n",
      "Train Epoch: 2181 [0/8000 (0%)]\tBatch Loss: 0.018441\tLearning Rate (w_theta): 0.001000\t TIME:714.4s\n",
      "\t\t\t\tDisc: 0.013434\t\tSym: 0.000581\t\tSpars: 0.004426\n",
      "\t TVw: -0.572116 | TVb: -1.970973 | GSw: -0.435149 | GSb: -0.154383 | TSUw: 0.241674 | TSUb: 0.187130\n",
      "\n",
      "Train Epoch: 2181 [4000/8000 (50%)]\tBatch Loss: 0.018135\tLearning Rate (w_theta): 0.001000\t TIME:716.0s\n",
      "\t\t\t\tDisc: 0.013139\t\tSym: 0.000578\t\tSpars: 0.004418\n",
      "\t TVw: -0.572099 | TVb: -1.970936 | GSw: -0.435248 | GSb: -0.154515 | TSUw: 0.241547 | TSUb: 0.187135\n",
      "Validating epoch 2181...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018469057155344176\n",
      "Average validation loss: 0.01864228679792856\n",
      "Training epoch 2182...\n",
      "\n",
      "Train Epoch: 2182 [0/8000 (0%)]\tBatch Loss: 0.019313\tLearning Rate (w_theta): 0.001000\t TIME:718.3s\n",
      "\t\t\t\tDisc: 0.014137\t\tSym: 0.000632\t\tSpars: 0.004544\n",
      "\t TVw: -0.572122 | TVb: -1.970930 | GSw: -0.435358 | GSb: -0.154658 | TSUw: 0.241410 | TSUb: 0.187145\n",
      "\n",
      "Train Epoch: 2182 [4000/8000 (50%)]\tBatch Loss: 0.020204\tLearning Rate (w_theta): 0.001000\t TIME:719.8s\n",
      "\t\t\t\tDisc: 0.015076\t\tSym: 0.000585\t\tSpars: 0.004544\n",
      "\t TVw: -0.572452 | TVb: -1.971129 | GSw: -0.435620 | GSb: -0.154932 | TSUw: 0.241121 | TSUb: 0.187237\n",
      "Validating epoch 2182...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.024973336124294934\n",
      "Average validation loss: 0.027834146592797968\n",
      "Training epoch 2183...\n",
      "\n",
      "Train Epoch: 2183 [0/8000 (0%)]\tBatch Loss: 0.029230\tLearning Rate (w_theta): 0.001000\t TIME:722.3s\n",
      "\t\t\t\tDisc: 0.022540\t\tSym: 0.001291\t\tSpars: 0.005399\n",
      "\t TVw: -0.573549 | TVb: -1.971826 | GSw: -0.435977 | GSb: -0.155288 | TSUw: 0.240765 | TSUb: 0.187366\n",
      "\n",
      "Train Epoch: 2183 [4000/8000 (50%)]\tBatch Loss: 0.031718\tLearning Rate (w_theta): 0.001000\t TIME:723.8s\n",
      "\t\t\t\tDisc: 0.024116\t\tSym: 0.001431\t\tSpars: 0.006171\n",
      "\t TVw: -0.575138 | TVb: -1.972849 | GSw: -0.436277 | GSb: -0.155596 | TSUw: 0.240506 | TSUb: 0.187441\n",
      "Validating epoch 2183...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.031021625780214324\n",
      "Average validation loss: 0.027400099113854277\n",
      "Training epoch 2184...\n",
      "\n",
      "Train Epoch: 2184 [0/8000 (0%)]\tBatch Loss: 0.028237\tLearning Rate (w_theta): 0.001000\t TIME:726.1s\n",
      "\t\t\t\tDisc: 0.020719\t\tSym: 0.000882\t\tSpars: 0.006635\n",
      "\t TVw: -0.576195 | TVb: -1.973545 | GSw: -0.436491 | GSb: -0.155846 | TSUw: 0.240315 | TSUb: 0.187479\n",
      "\n",
      "Train Epoch: 2184 [4000/8000 (50%)]\tBatch Loss: 0.024079\tLearning Rate (w_theta): 0.001000\t TIME:727.7s\n",
      "\t\t\t\tDisc: 0.016515\t\tSym: 0.000619\t\tSpars: 0.006945\n",
      "\t TVw: -0.577445 | TVb: -1.974357 | GSw: -0.436668 | GSb: -0.156064 | TSUw: 0.240170 | TSUb: 0.187491\n",
      "Validating epoch 2184...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.024952854997356985\n",
      "Average validation loss: 0.02179009706693706\n",
      "Training epoch 2185...\n",
      "\n",
      "Train Epoch: 2185 [0/8000 (0%)]\tBatch Loss: 0.022896\tLearning Rate (w_theta): 0.001000\t TIME:730.1s\n",
      "\t\t\t\tDisc: 0.014608\t\tSym: 0.000848\t\tSpars: 0.007439\n",
      "\t TVw: -0.578582 | TVb: -1.975089 | GSw: -0.436816 | GSb: -0.156252 | TSUw: 0.240025 | TSUb: 0.187504\n",
      "\n",
      "Train Epoch: 2185 [4000/8000 (50%)]\tBatch Loss: 0.022854\tLearning Rate (w_theta): 0.001000\t TIME:731.6s\n",
      "\t\t\t\tDisc: 0.014310\t\tSym: 0.000950\t\tSpars: 0.007593\n",
      "\t TVw: -0.579033 | TVb: -1.975378 | GSw: -0.436943 | GSb: -0.156412 | TSUw: 0.239844 | TSUb: 0.187537\n",
      "Validating epoch 2185...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.02273288746130036\n",
      "Average validation loss: 0.021893613635853505\n",
      "Training epoch 2186...\n",
      "\n",
      "Train Epoch: 2186 [0/8000 (0%)]\tBatch Loss: 0.023073\tLearning Rate (w_theta): 0.001000\t TIME:734.0s\n",
      "\t\t\t\tDisc: 0.014572\t\tSym: 0.000827\t\tSpars: 0.007674\n",
      "\t TVw: -0.579403 | TVb: -1.975618 | GSw: -0.437121 | GSb: -0.156621 | TSUw: 0.239596 | TSUb: 0.187606\n",
      "\n",
      "Train Epoch: 2186 [4000/8000 (50%)]\tBatch Loss: 0.022517\tLearning Rate (w_theta): 0.001000\t TIME:735.5s\n",
      "\t\t\t\tDisc: 0.014271\t\tSym: 0.000613\t\tSpars: 0.007632\n",
      "\t TVw: -0.579449 | TVb: -1.975647 | GSw: -0.437310 | GSb: -0.156832 | TSUw: 0.239315 | TSUb: 0.187693\n",
      "Validating epoch 2186...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.022403428174995525\n",
      "Average validation loss: 0.021354930839225076\n",
      "Training epoch 2187...\n",
      "\n",
      "Train Epoch: 2187 [0/8000 (0%)]\tBatch Loss: 0.021942\tLearning Rate (w_theta): 0.001000\t TIME:737.8s\n",
      "\t\t\t\tDisc: 0.013865\t\tSym: 0.000538\t\tSpars: 0.007539\n",
      "\t TVw: -0.579184 | TVb: -1.975473 | GSw: -0.437479 | GSb: -0.157016 | TSUw: 0.239037 | TSUb: 0.187779\n",
      "\n",
      "Train Epoch: 2187 [4000/8000 (50%)]\tBatch Loss: 0.021234\tLearning Rate (w_theta): 0.001000\t TIME:739.3s\n",
      "\t\t\t\tDisc: 0.013295\t\tSym: 0.000529\t\tSpars: 0.007410\n",
      "\t TVw: -0.579066 | TVb: -1.975390 | GSw: -0.437649 | GSb: -0.157205 | TSUw: 0.238774 | TSUb: 0.187856\n",
      "Validating epoch 2187...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.021722713558521047\n",
      "Average validation loss: 0.021084026694726424\n",
      "Training epoch 2188...\n",
      "\n",
      "Train Epoch: 2188 [0/8000 (0%)]\tBatch Loss: 0.021268\tLearning Rate (w_theta): 0.001000\t TIME:741.8s\n",
      "\t\t\t\tDisc: 0.013365\t\tSym: 0.000531\t\tSpars: 0.007372\n",
      "\t TVw: -0.578954 | TVb: -1.975308 | GSw: -0.437794 | GSb: -0.157370 | TSUw: 0.238547 | TSUb: 0.187913\n",
      "\n",
      "Train Epoch: 2188 [4000/8000 (50%)]\tBatch Loss: 0.021167\tLearning Rate (w_theta): 0.001000\t TIME:743.3s\n",
      "\t\t\t\tDisc: 0.013387\t\tSym: 0.000540\t\tSpars: 0.007240\n",
      "\t TVw: -0.578737 | TVb: -1.975158 | GSw: -0.437907 | GSb: -0.157504 | TSUw: 0.238353 | TSUb: 0.187952\n",
      "Validating epoch 2188...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.02154362181341661\n",
      "Average validation loss: 0.020861649899355947\n",
      "Training epoch 2189...\n",
      "\n",
      "Train Epoch: 2189 [0/8000 (0%)]\tBatch Loss: 0.021628\tLearning Rate (w_theta): 0.001000\t TIME:745.8s\n",
      "\t\t\t\tDisc: 0.013852\t\tSym: 0.000547\t\tSpars: 0.007229\n",
      "\t TVw: -0.578732 | TVb: -1.975142 | GSw: -0.438011 | GSb: -0.157632 | TSUw: 0.238188 | TSUb: 0.187976\n",
      "\n",
      "Train Epoch: 2189 [4000/8000 (50%)]\tBatch Loss: 0.021245\tLearning Rate (w_theta): 0.001000\t TIME:747.3s\n",
      "\t\t\t\tDisc: 0.013547\t\tSym: 0.000526\t\tSpars: 0.007172\n",
      "\t TVw: -0.578722 | TVb: -1.975123 | GSw: -0.438101 | GSb: -0.157747 | TSUw: 0.238041 | TSUb: 0.187989\n",
      "Validating epoch 2189...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.021331226126594657\n",
      "Average validation loss: 0.020696259937439114\n",
      "Training epoch 2190...\n",
      "\n",
      "Train Epoch: 2190 [0/8000 (0%)]\tBatch Loss: 0.021552\tLearning Rate (w_theta): 0.001000\t TIME:749.6s\n",
      "\t\t\t\tDisc: 0.013906\t\tSym: 0.000530\t\tSpars: 0.007116\n",
      "\t TVw: -0.578641 | TVb: -1.975058 | GSw: -0.438185 | GSb: -0.157855 | TSUw: 0.237899 | TSUb: 0.187999\n",
      "\n",
      "Train Epoch: 2190 [4000/8000 (50%)]\tBatch Loss: 0.021262\tLearning Rate (w_theta): 0.001000\t TIME:751.1s\n",
      "\t\t\t\tDisc: 0.013652\t\tSym: 0.000532\t\tSpars: 0.007078\n",
      "\t TVw: -0.578646 | TVb: -1.975049 | GSw: -0.438275 | GSb: -0.157972 | TSUw: 0.237756 | TSUb: 0.188009\n",
      "Validating epoch 2190...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.02114037951323185\n",
      "Average validation loss: 0.02054269374260434\n",
      "Training epoch 2191...\n",
      "\n",
      "Train Epoch: 2191 [0/8000 (0%)]\tBatch Loss: 0.021025\tLearning Rate (w_theta): 0.001000\t TIME:754.3s\n",
      "\t\t\t\tDisc: 0.013507\t\tSym: 0.000526\t\tSpars: 0.006991\n",
      "\t TVw: -0.578592 | TVb: -1.975001 | GSw: -0.438364 | GSb: -0.158085 | TSUw: 0.237614 | TSUb: 0.188019\n",
      "\n",
      "Train Epoch: 2191 [4000/8000 (50%)]\tBatch Loss: 0.020720\tLearning Rate (w_theta): 0.001000\t TIME:755.8s\n",
      "\t\t\t\tDisc: 0.013299\t\tSym: 0.000515\t\tSpars: 0.006906\n",
      "\t TVw: -0.578495 | TVb: -1.974926 | GSw: -0.438451 | GSb: -0.158197 | TSUw: 0.237472 | TSUb: 0.188029\n",
      "Validating epoch 2191...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.020978790453685343\n",
      "Average validation loss: 0.02039033266842057\n",
      "Training epoch 2192...\n",
      "\n",
      "Train Epoch: 2192 [0/8000 (0%)]\tBatch Loss: 0.021283\tLearning Rate (w_theta): 0.001000\t TIME:758.1s\n",
      "\t\t\t\tDisc: 0.013790\t\tSym: 0.000544\t\tSpars: 0.006950\n",
      "\t TVw: -0.578442 | TVb: -1.974879 | GSw: -0.438543 | GSb: -0.158314 | TSUw: 0.237328 | TSUb: 0.188040\n",
      "\n",
      "Train Epoch: 2192 [4000/8000 (50%)]\tBatch Loss: 0.020694\tLearning Rate (w_theta): 0.001000\t TIME:759.6s\n",
      "\t\t\t\tDisc: 0.013326\t\tSym: 0.000535\t\tSpars: 0.006833\n",
      "\t TVw: -0.578357 | TVb: -1.974811 | GSw: -0.438636 | GSb: -0.158433 | TSUw: 0.237182 | TSUb: 0.188051\n",
      "Validating epoch 2192...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.020818431982296808\n",
      "Average validation loss: 0.020242839847108778\n",
      "Training epoch 2193...\n",
      "\n",
      "Train Epoch: 2193 [0/8000 (0%)]\tBatch Loss: 0.021048\tLearning Rate (w_theta): 0.001000\t TIME:762.1s\n",
      "\t\t\t\tDisc: 0.013789\t\tSym: 0.000522\t\tSpars: 0.006738\n",
      "\t TVw: -0.578232 | TVb: -1.974718 | GSw: -0.438722 | GSb: -0.158544 | TSUw: 0.237042 | TSUb: 0.188059\n",
      "\n",
      "Train Epoch: 2193 [4000/8000 (50%)]\tBatch Loss: 0.020509\tLearning Rate (w_theta): 0.001000\t TIME:763.6s\n",
      "\t\t\t\tDisc: 0.013339\t\tSym: 0.000518\t\tSpars: 0.006652\n",
      "\t TVw: -0.578162 | TVb: -1.974662 | GSw: -0.438810 | GSb: -0.158657 | TSUw: 0.236906 | TSUb: 0.188064\n",
      "Validating epoch 2193...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.02066768686836843\n",
      "Average validation loss: 0.020104121723385476\n",
      "Training epoch 2194...\n",
      "\n",
      "Train Epoch: 2194 [0/8000 (0%)]\tBatch Loss: 0.020844\tLearning Rate (w_theta): 0.001000\t TIME:765.9s\n",
      "\t\t\t\tDisc: 0.013645\t\tSym: 0.000538\t\tSpars: 0.006661\n",
      "\t TVw: -0.578112 | TVb: -1.974617 | GSw: -0.438897 | GSb: -0.158771 | TSUw: 0.236772 | TSUb: 0.188069\n",
      "\n",
      "Train Epoch: 2194 [4000/8000 (50%)]\tBatch Loss: 0.020578\tLearning Rate (w_theta): 0.001000\t TIME:767.5s\n",
      "\t\t\t\tDisc: 0.013383\t\tSym: 0.000554\t\tSpars: 0.006642\n",
      "\t TVw: -0.578029 | TVb: -1.974552 | GSw: -0.438983 | GSb: -0.158883 | TSUw: 0.236637 | TSUb: 0.188073\n",
      "Validating epoch 2194...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.020522660440446983\n",
      "Average validation loss: 0.01997560432439094\n",
      "Training epoch 2195...\n",
      "\n",
      "Train Epoch: 2195 [0/8000 (0%)]\tBatch Loss: 0.020129\tLearning Rate (w_theta): 0.001000\t TIME:769.8s\n",
      "\t\t\t\tDisc: 0.013126\t\tSym: 0.000519\t\tSpars: 0.006484\n",
      "\t TVw: -0.577942 | TVb: -1.974483 | GSw: -0.439067 | GSb: -0.158993 | TSUw: 0.236505 | TSUb: 0.188076\n",
      "\n",
      "Train Epoch: 2195 [4000/8000 (50%)]\tBatch Loss: 0.020639\tLearning Rate (w_theta): 0.001000\t TIME:771.3s\n",
      "\t\t\t\tDisc: 0.013606\t\tSym: 0.000537\t\tSpars: 0.006496\n",
      "\t TVw: -0.577915 | TVb: -1.974454 | GSw: -0.439154 | GSb: -0.159108 | TSUw: 0.236375 | TSUb: 0.188078\n",
      "Validating epoch 2195...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.020396110494431765\n",
      "Average validation loss: 0.019848849464990406\n",
      "Training epoch 2196...\n",
      "\n",
      "Train Epoch: 2196 [0/8000 (0%)]\tBatch Loss: 0.020324\tLearning Rate (w_theta): 0.001000\t TIME:773.8s\n",
      "\t\t\t\tDisc: 0.013399\t\tSym: 0.000527\t\tSpars: 0.006398\n",
      "\t TVw: -0.577827 | TVb: -1.974387 | GSw: -0.439239 | GSb: -0.159219 | TSUw: 0.236243 | TSUb: 0.188080\n",
      "\n",
      "Train Epoch: 2196 [4000/8000 (50%)]\tBatch Loss: 0.020196\tLearning Rate (w_theta): 0.001000\t TIME:775.3s\n",
      "\t\t\t\tDisc: 0.013310\t\tSym: 0.000536\t\tSpars: 0.006351\n",
      "\t TVw: -0.577731 | TVb: -1.974313 | GSw: -0.439324 | GSb: -0.159332 | TSUw: 0.236110 | TSUb: 0.188083\n",
      "Validating epoch 2196...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.020256845064012423\n",
      "Average validation loss: 0.01972253590188604\n",
      "Training epoch 2197...\n",
      "\n",
      "Train Epoch: 2197 [0/8000 (0%)]\tBatch Loss: 0.019997\tLearning Rate (w_theta): 0.001000\t TIME:777.7s\n",
      "\t\t\t\tDisc: 0.013133\t\tSym: 0.000541\t\tSpars: 0.006323\n",
      "\t TVw: -0.577690 | TVb: -1.974276 | GSw: -0.439416 | GSb: -0.159450 | TSUw: 0.235976 | TSUb: 0.188086\n",
      "\n",
      "Train Epoch: 2197 [4000/8000 (50%)]\tBatch Loss: 0.020323\tLearning Rate (w_theta): 0.001000\t TIME:779.3s\n",
      "\t\t\t\tDisc: 0.013472\t\tSym: 0.000549\t\tSpars: 0.006301\n",
      "\t TVw: -0.577596 | TVb: -1.974204 | GSw: -0.439503 | GSb: -0.159564 | TSUw: 0.235841 | TSUb: 0.188090\n",
      "Validating epoch 2197...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.02012535988091347\n",
      "Average validation loss: 0.019606970638576724\n",
      "Training epoch 2198...\n",
      "\n",
      "Train Epoch: 2198 [0/8000 (0%)]\tBatch Loss: 0.019821\tLearning Rate (w_theta): 0.001000\t TIME:781.7s\n",
      "\t\t\t\tDisc: 0.013145\t\tSym: 0.000519\t\tSpars: 0.006158\n",
      "\t TVw: -0.577510 | TVb: -1.974138 | GSw: -0.439590 | GSb: -0.159678 | TSUw: 0.235709 | TSUb: 0.188092\n",
      "\n",
      "Train Epoch: 2198 [4000/8000 (50%)]\tBatch Loss: 0.020079\tLearning Rate (w_theta): 0.001000\t TIME:783.2s\n",
      "\t\t\t\tDisc: 0.013343\t\tSym: 0.000545\t\tSpars: 0.006191\n",
      "\t TVw: -0.577464 | TVb: -1.974097 | GSw: -0.439680 | GSb: -0.159796 | TSUw: 0.235577 | TSUb: 0.188093\n",
      "Validating epoch 2198...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.02000186667722401\n",
      "Average validation loss: 0.019496571773885023\n",
      "Training epoch 2199...\n",
      "\n",
      "Train Epoch: 2199 [0/8000 (0%)]\tBatch Loss: 0.019290\tLearning Rate (w_theta): 0.001000\t TIME:785.6s\n",
      "\t\t\t\tDisc: 0.012739\t\tSym: 0.000518\t\tSpars: 0.006034\n",
      "\t TVw: -0.577375 | TVb: -1.974029 | GSw: -0.439766 | GSb: -0.159910 | TSUw: 0.235446 | TSUb: 0.188094\n",
      "\n",
      "Train Epoch: 2199 [4000/8000 (50%)]\tBatch Loss: 0.020079\tLearning Rate (w_theta): 0.001000\t TIME:787.1s\n",
      "\t\t\t\tDisc: 0.013432\t\tSym: 0.000553\t\tSpars: 0.006095\n",
      "\t TVw: -0.577338 | TVb: -1.973995 | GSw: -0.439854 | GSb: -0.160027 | TSUw: 0.235318 | TSUb: 0.188093\n",
      "Validating epoch 2199...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019897192460050013\n",
      "Average validation loss: 0.01940513727625766\n",
      "Training epoch 2200...\n",
      "\n",
      "Train Epoch: 2200 [0/8000 (0%)]\tBatch Loss: 0.019862\tLearning Rate (w_theta): 0.001000\t TIME:789.5s\n",
      "\t\t\t\tDisc: 0.013274\t\tSym: 0.000543\t\tSpars: 0.006045\n",
      "\t TVw: -0.577273 | TVb: -1.973941 | GSw: -0.439943 | GSb: -0.160144 | TSUw: 0.235186 | TSUb: 0.188094\n",
      "\n",
      "Train Epoch: 2200 [4000/8000 (50%)]\tBatch Loss: 0.020029\tLearning Rate (w_theta): 0.001000\t TIME:791.0s\n",
      "\t\t\t\tDisc: 0.013504\t\tSym: 0.000538\t\tSpars: 0.005987\n",
      "\t TVw: -0.577185 | TVb: -1.973874 | GSw: -0.440030 | GSb: -0.160259 | TSUw: 0.235055 | TSUb: 0.188094\n",
      "Validating epoch 2200...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01978385296197384\n",
      "Average validation loss: 0.01930144713074823\n",
      "Training epoch 2201...\n",
      "\n",
      "Train Epoch: 2201 [0/8000 (0%)]\tBatch Loss: 0.019643\tLearning Rate (w_theta): 0.001000\t TIME:794.2s\n",
      "\t\t\t\tDisc: 0.013205\t\tSym: 0.000530\t\tSpars: 0.005908\n",
      "\t TVw: -0.577132 | TVb: -1.973827 | GSw: -0.440122 | GSb: -0.160379 | TSUw: 0.234921 | TSUb: 0.188096\n",
      "\n",
      "Train Epoch: 2201 [4000/8000 (50%)]\tBatch Loss: 0.019349\tLearning Rate (w_theta): 0.001000\t TIME:795.8s\n",
      "\t\t\t\tDisc: 0.012938\t\tSym: 0.000538\t\tSpars: 0.005872\n",
      "\t TVw: -0.577068 | TVb: -1.973774 | GSw: -0.440213 | GSb: -0.160498 | TSUw: 0.234789 | TSUb: 0.188096\n",
      "Validating epoch 2201...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01967922803490551\n",
      "Average validation loss: 0.019203953734867843\n",
      "Training epoch 2202...\n",
      "\n",
      "Train Epoch: 2202 [0/8000 (0%)]\tBatch Loss: 0.019852\tLearning Rate (w_theta): 0.001000\t TIME:798.1s\n",
      "\t\t\t\tDisc: 0.013453\t\tSym: 0.000547\t\tSpars: 0.005852\n",
      "\t TVw: -0.576986 | TVb: -1.973709 | GSw: -0.440302 | GSb: -0.160617 | TSUw: 0.234656 | TSUb: 0.188097\n",
      "\n",
      "Train Epoch: 2202 [4000/8000 (50%)]\tBatch Loss: 0.019473\tLearning Rate (w_theta): 0.001000\t TIME:799.6s\n",
      "\t\t\t\tDisc: 0.013125\t\tSym: 0.000549\t\tSpars: 0.005799\n",
      "\t TVw: -0.576921 | TVb: -1.973654 | GSw: -0.440391 | GSb: -0.160734 | TSUw: 0.234526 | TSUb: 0.188096\n",
      "Validating epoch 2202...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019584618223567617\n",
      "Average validation loss: 0.019113597383646038\n",
      "Training epoch 2203...\n",
      "\n",
      "Train Epoch: 2203 [0/8000 (0%)]\tBatch Loss: 0.019184\tLearning Rate (w_theta): 0.001000\t TIME:802.0s\n",
      "\t\t\t\tDisc: 0.012901\t\tSym: 0.000534\t\tSpars: 0.005748\n",
      "\t TVw: -0.576881 | TVb: -1.973615 | GSw: -0.440483 | GSb: -0.160856 | TSUw: 0.234395 | TSUb: 0.188095\n",
      "\n",
      "Train Epoch: 2203 [4000/8000 (50%)]\tBatch Loss: 0.019376\tLearning Rate (w_theta): 0.001000\t TIME:803.5s\n",
      "\t\t\t\tDisc: 0.013126\t\tSym: 0.000538\t\tSpars: 0.005713\n",
      "\t TVw: -0.576815 | TVb: -1.973561 | GSw: -0.440573 | GSb: -0.160976 | TSUw: 0.234266 | TSUb: 0.188093\n",
      "Validating epoch 2203...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019494632004741413\n",
      "Average validation loss: 0.01903143206146369\n",
      "Training epoch 2204...\n",
      "\n",
      "Train Epoch: 2204 [0/8000 (0%)]\tBatch Loss: 0.018887\tLearning Rate (w_theta): 0.001000\t TIME:806.0s\n",
      "\t\t\t\tDisc: 0.012738\t\tSym: 0.000520\t\tSpars: 0.005629\n",
      "\t TVw: -0.576774 | TVb: -1.973521 | GSw: -0.440665 | GSb: -0.161097 | TSUw: 0.234136 | TSUb: 0.188091\n",
      "\n",
      "Train Epoch: 2204 [4000/8000 (50%)]\tBatch Loss: 0.019531\tLearning Rate (w_theta): 0.001000\t TIME:807.5s\n",
      "\t\t\t\tDisc: 0.013306\t\tSym: 0.000550\t\tSpars: 0.005675\n",
      "\t TVw: -0.576698 | TVb: -1.973460 | GSw: -0.440755 | GSb: -0.161216 | TSUw: 0.234006 | TSUb: 0.188090\n",
      "Validating epoch 2204...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019403608584401814\n",
      "Average validation loss: 0.018939302212383016\n",
      "Training epoch 2205...\n",
      "\n",
      "Train Epoch: 2205 [0/8000 (0%)]\tBatch Loss: 0.019406\tLearning Rate (w_theta): 0.001000\t TIME:809.9s\n",
      "\t\t\t\tDisc: 0.013210\t\tSym: 0.000558\t\tSpars: 0.005638\n",
      "\t TVw: -0.576650 | TVb: -1.973415 | GSw: -0.440847 | GSb: -0.161339 | TSUw: 0.233875 | TSUb: 0.188089\n",
      "\n",
      "Train Epoch: 2205 [4000/8000 (50%)]\tBatch Loss: 0.019617\tLearning Rate (w_theta): 0.001000\t TIME:811.4s\n",
      "\t\t\t\tDisc: 0.013415\t\tSym: 0.000564\t\tSpars: 0.005638\n",
      "\t TVw: -0.576599 | TVb: -1.973367 | GSw: -0.440940 | GSb: -0.161462 | TSUw: 0.233744 | TSUb: 0.188087\n",
      "Validating epoch 2205...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019314834139365855\n",
      "Average validation loss: 0.018854853978486463\n",
      "Training epoch 2206...\n",
      "\n",
      "Train Epoch: 2206 [0/8000 (0%)]\tBatch Loss: 0.018908\tLearning Rate (w_theta): 0.001000\t TIME:813.8s\n",
      "\t\t\t\tDisc: 0.012865\t\tSym: 0.000534\t\tSpars: 0.005509\n",
      "\t TVw: -0.576517 | TVb: -1.973299 | GSw: -0.441031 | GSb: -0.161583 | TSUw: 0.233612 | TSUb: 0.188086\n",
      "\n",
      "Train Epoch: 2206 [4000/8000 (50%)]\tBatch Loss: 0.019079\tLearning Rate (w_theta): 0.001000\t TIME:815.3s\n",
      "\t\t\t\tDisc: 0.013032\t\tSym: 0.000548\t\tSpars: 0.005499\n",
      "\t TVw: -0.576458 | TVb: -1.973245 | GSw: -0.441124 | GSb: -0.161707 | TSUw: 0.233480 | TSUb: 0.188084\n",
      "Validating epoch 2206...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01922211659171238\n",
      "Average validation loss: 0.01877004394349405\n",
      "Training epoch 2207...\n",
      "\n",
      "Train Epoch: 2207 [0/8000 (0%)]\tBatch Loss: 0.018807\tLearning Rate (w_theta): 0.001000\t TIME:817.6s\n",
      "\t\t\t\tDisc: 0.012814\t\tSym: 0.000541\t\tSpars: 0.005452\n",
      "\t TVw: -0.576428 | TVb: -1.973209 | GSw: -0.441220 | GSb: -0.161833 | TSUw: 0.233349 | TSUb: 0.188082\n",
      "\n",
      "Train Epoch: 2207 [4000/8000 (50%)]\tBatch Loss: 0.019014\tLearning Rate (w_theta): 0.001000\t TIME:819.2s\n",
      "\t\t\t\tDisc: 0.013025\t\tSym: 0.000547\t\tSpars: 0.005442\n",
      "\t TVw: -0.576351 | TVb: -1.973143 | GSw: -0.441312 | GSb: -0.161955 | TSUw: 0.233217 | TSUb: 0.188080\n",
      "Validating epoch 2207...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019140481588616823\n",
      "Average validation loss: 0.01869187109168549\n",
      "Training epoch 2208...\n",
      "\n",
      "Train Epoch: 2208 [0/8000 (0%)]\tBatch Loss: 0.019266\tLearning Rate (w_theta): 0.001000\t TIME:821.6s\n",
      "\t\t\t\tDisc: 0.013271\t\tSym: 0.000563\t\tSpars: 0.005433\n",
      "\t TVw: -0.576279 | TVb: -1.973082 | GSw: -0.441404 | GSb: -0.162078 | TSUw: 0.233087 | TSUb: 0.188077\n",
      "\n",
      "Train Epoch: 2208 [4000/8000 (50%)]\tBatch Loss: 0.018995\tLearning Rate (w_theta): 0.001000\t TIME:823.1s\n",
      "\t\t\t\tDisc: 0.013097\t\tSym: 0.000544\t\tSpars: 0.005354\n",
      "\t TVw: -0.576237 | TVb: -1.973040 | GSw: -0.441499 | GSb: -0.162204 | TSUw: 0.232955 | TSUb: 0.188075\n",
      "Validating epoch 2208...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.019060563465471747\n",
      "Average validation loss: 0.01860836945315164\n",
      "Training epoch 2209...\n",
      "\n",
      "Train Epoch: 2209 [0/8000 (0%)]\tBatch Loss: 0.019149\tLearning Rate (w_theta): 0.001000\t TIME:825.6s\n",
      "\t\t\t\tDisc: 0.013281\t\tSym: 0.000543\t\tSpars: 0.005325\n",
      "\t TVw: -0.576193 | TVb: -1.972994 | GSw: -0.441594 | GSb: -0.162331 | TSUw: 0.232825 | TSUb: 0.188072\n",
      "\n",
      "Train Epoch: 2209 [4000/8000 (50%)]\tBatch Loss: 0.019372\tLearning Rate (w_theta): 0.001000\t TIME:827.1s\n",
      "\t\t\t\tDisc: 0.013443\t\tSym: 0.000571\t\tSpars: 0.005357\n",
      "\t TVw: -0.576129 | TVb: -1.972932 | GSw: -0.441688 | GSb: -0.162456 | TSUw: 0.232693 | TSUb: 0.188069\n",
      "Validating epoch 2209...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018983286310814425\n",
      "Average validation loss: 0.01853238713463993\n",
      "Training epoch 2210...\n",
      "\n",
      "Train Epoch: 2210 [0/8000 (0%)]\tBatch Loss: 0.019229\tLearning Rate (w_theta): 0.001000\t TIME:829.5s\n",
      "\t\t\t\tDisc: 0.013372\t\tSym: 0.000565\t\tSpars: 0.005291\n",
      "\t TVw: -0.576070 | TVb: -1.972878 | GSw: -0.441783 | GSb: -0.162583 | TSUw: 0.232562 | TSUb: 0.188066\n",
      "\n",
      "Train Epoch: 2210 [4000/8000 (50%)]\tBatch Loss: 0.018568\tLearning Rate (w_theta): 0.001000\t TIME:831.0s\n",
      "\t\t\t\tDisc: 0.012818\t\tSym: 0.000542\t\tSpars: 0.005209\n",
      "\t TVw: -0.576011 | TVb: -1.972825 | GSw: -0.441877 | GSb: -0.162708 | TSUw: 0.232431 | TSUb: 0.188062\n",
      "Validating epoch 2210...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018909388494813217\n",
      "Average validation loss: 0.018460276623892977\n",
      "Training epoch 2211...\n",
      "\n",
      "Train Epoch: 2211 [0/8000 (0%)]\tBatch Loss: 0.018750\tLearning Rate (w_theta): 0.001000\t TIME:834.0s\n",
      "\t\t\t\tDisc: 0.012982\t\tSym: 0.000556\t\tSpars: 0.005212\n",
      "\t TVw: -0.575970 | TVb: -1.972780 | GSw: -0.441975 | GSb: -0.162837 | TSUw: 0.232300 | TSUb: 0.188059\n",
      "\n",
      "Train Epoch: 2211 [4000/8000 (50%)]\tBatch Loss: 0.018687\tLearning Rate (w_theta): 0.001000\t TIME:835.5s\n",
      "\t\t\t\tDisc: 0.012988\t\tSym: 0.000541\t\tSpars: 0.005158\n",
      "\t TVw: -0.575913 | TVb: -1.972719 | GSw: -0.442071 | GSb: -0.162966 | TSUw: 0.232168 | TSUb: 0.188055\n",
      "Validating epoch 2211...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018839412466944778\n",
      "Average validation loss: 0.01839410274913875\n",
      "Training epoch 2212...\n",
      "\n",
      "Train Epoch: 2212 [0/8000 (0%)]\tBatch Loss: 0.018584\tLearning Rate (w_theta): 0.001000\t TIME:838.0s\n",
      "\t\t\t\tDisc: 0.012894\t\tSym: 0.000552\t\tSpars: 0.005138\n",
      "\t TVw: -0.575832 | TVb: -1.972648 | GSw: -0.442166 | GSb: -0.163092 | TSUw: 0.232037 | TSUb: 0.188051\n",
      "\n",
      "Train Epoch: 2212 [4000/8000 (50%)]\tBatch Loss: 0.018985\tLearning Rate (w_theta): 0.001000\t TIME:839.5s\n",
      "\t\t\t\tDisc: 0.013318\t\tSym: 0.000557\t\tSpars: 0.005110\n",
      "\t TVw: -0.575786 | TVb: -1.972602 | GSw: -0.442262 | GSb: -0.163220 | TSUw: 0.231908 | TSUb: 0.188046\n",
      "Validating epoch 2212...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01876899503116288\n",
      "Average validation loss: 0.018320195773563964\n",
      "Training epoch 2213...\n",
      "\n",
      "Train Epoch: 2213 [0/8000 (0%)]\tBatch Loss: 0.018709\tLearning Rate (w_theta): 0.001000\t TIME:841.9s\n",
      "\t\t\t\tDisc: 0.013094\t\tSym: 0.000546\t\tSpars: 0.005069\n",
      "\t TVw: -0.575733 | TVb: -1.972548 | GSw: -0.442361 | GSb: -0.163351 | TSUw: 0.231774 | TSUb: 0.188043\n",
      "\n",
      "Train Epoch: 2213 [4000/8000 (50%)]\tBatch Loss: 0.018457\tLearning Rate (w_theta): 0.001000\t TIME:843.4s\n",
      "\t\t\t\tDisc: 0.012862\t\tSym: 0.000553\t\tSpars: 0.005042\n",
      "\t TVw: -0.575669 | TVb: -1.972480 | GSw: -0.442461 | GSb: -0.163482 | TSUw: 0.231640 | TSUb: 0.188040\n",
      "Validating epoch 2213...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018696828636984648\n",
      "Average validation loss: 0.018261579455972378\n",
      "Training epoch 2214...\n",
      "\n",
      "Train Epoch: 2214 [0/8000 (0%)]\tBatch Loss: 0.018867\tLearning Rate (w_theta): 0.001000\t TIME:845.8s\n",
      "\t\t\t\tDisc: 0.013339\t\tSym: 0.000542\t\tSpars: 0.004985\n",
      "\t TVw: -0.575600 | TVb: -1.972411 | GSw: -0.442558 | GSb: -0.163612 | TSUw: 0.231508 | TSUb: 0.188036\n",
      "\n",
      "Train Epoch: 2214 [4000/8000 (50%)]\tBatch Loss: 0.018721\tLearning Rate (w_theta): 0.001000\t TIME:847.3s\n",
      "\t\t\t\tDisc: 0.013200\t\tSym: 0.000555\t\tSpars: 0.004966\n",
      "\t TVw: -0.575551 | TVb: -1.972351 | GSw: -0.442660 | GSb: -0.163746 | TSUw: 0.231372 | TSUb: 0.188033\n",
      "Validating epoch 2214...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01862887660358764\n",
      "Average validation loss: 0.01818368909795383\n",
      "Training epoch 2215...\n",
      "\n",
      "Train Epoch: 2215 [0/8000 (0%)]\tBatch Loss: 0.018680\tLearning Rate (w_theta): 0.001000\t TIME:849.6s\n",
      "\t\t\t\tDisc: 0.013190\t\tSym: 0.000548\t\tSpars: 0.004942\n",
      "\t TVw: -0.575501 | TVb: -1.972296 | GSw: -0.442759 | GSb: -0.163878 | TSUw: 0.231241 | TSUb: 0.188028\n",
      "\n",
      "Train Epoch: 2215 [4000/8000 (50%)]\tBatch Loss: 0.018112\tLearning Rate (w_theta): 0.001000\t TIME:851.2s\n",
      "\t\t\t\tDisc: 0.012726\t\tSym: 0.000533\t\tSpars: 0.004853\n",
      "\t TVw: -0.575430 | TVb: -1.972224 | GSw: -0.442859 | GSb: -0.164010 | TSUw: 0.231107 | TSUb: 0.188024\n",
      "Validating epoch 2215...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01856367049814048\n",
      "Average validation loss: 0.018124902955621636\n",
      "Training epoch 2216...\n",
      "\n",
      "Train Epoch: 2216 [0/8000 (0%)]\tBatch Loss: 0.018342\tLearning Rate (w_theta): 0.001000\t TIME:853.5s\n",
      "\t\t\t\tDisc: 0.012937\t\tSym: 0.000543\t\tSpars: 0.004862\n",
      "\t TVw: -0.575390 | TVb: -1.972174 | GSw: -0.442957 | GSb: -0.164141 | TSUw: 0.230978 | TSUb: 0.188018\n",
      "\n",
      "Train Epoch: 2216 [4000/8000 (50%)]\tBatch Loss: 0.018252\tLearning Rate (w_theta): 0.001000\t TIME:855.0s\n",
      "\t\t\t\tDisc: 0.012881\t\tSym: 0.000543\t\tSpars: 0.004828\n",
      "\t TVw: -0.575347 | TVb: -1.972126 | GSw: -0.443057 | GSb: -0.164275 | TSUw: 0.230848 | TSUb: 0.188011\n",
      "Validating epoch 2216...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018503996379890576\n",
      "Average validation loss: 0.01806368961443964\n",
      "Training epoch 2217...\n",
      "\n",
      "Train Epoch: 2217 [0/8000 (0%)]\tBatch Loss: 0.018204\tLearning Rate (w_theta): 0.001000\t TIME:857.6s\n",
      "\t\t\t\tDisc: 0.012854\t\tSym: 0.000541\t\tSpars: 0.004808\n",
      "\t TVw: -0.575268 | TVb: -1.972049 | GSw: -0.443156 | GSb: -0.164406 | TSUw: 0.230716 | TSUb: 0.188006\n",
      "\n",
      "Train Epoch: 2217 [4000/8000 (50%)]\tBatch Loss: 0.018636\tLearning Rate (w_theta): 0.001000\t TIME:859.1s\n",
      "\t\t\t\tDisc: 0.013265\t\tSym: 0.000560\t\tSpars: 0.004812\n",
      "\t TVw: -0.575217 | TVb: -1.971993 | GSw: -0.443258 | GSb: -0.164542 | TSUw: 0.230583 | TSUb: 0.188001\n",
      "Validating epoch 2217...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018436866609161003\n",
      "Average validation loss: 0.018001264318389942\n",
      "Training epoch 2218...\n",
      "\n",
      "Train Epoch: 2218 [0/8000 (0%)]\tBatch Loss: 0.018132\tLearning Rate (w_theta): 0.001000\t TIME:861.5s\n",
      "\t\t\t\tDisc: 0.012823\t\tSym: 0.000548\t\tSpars: 0.004761\n",
      "\t TVw: -0.575165 | TVb: -1.971934 | GSw: -0.443360 | GSb: -0.164676 | TSUw: 0.230451 | TSUb: 0.187995\n",
      "\n",
      "Train Epoch: 2218 [4000/8000 (50%)]\tBatch Loss: 0.018306\tLearning Rate (w_theta): 0.001000\t TIME:863.0s\n",
      "\t\t\t\tDisc: 0.013034\t\tSym: 0.000549\t\tSpars: 0.004723\n",
      "\t TVw: -0.575101 | TVb: -1.971867 | GSw: -0.443461 | GSb: -0.164810 | TSUw: 0.230320 | TSUb: 0.187989\n",
      "Validating epoch 2218...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018375278142913832\n",
      "Average validation loss: 0.017935996049480166\n",
      "Training epoch 2219...\n",
      "\n",
      "Train Epoch: 2219 [0/8000 (0%)]\tBatch Loss: 0.018290\tLearning Rate (w_theta): 0.001000\t TIME:865.3s\n",
      "\t\t\t\tDisc: 0.013109\t\tSym: 0.000528\t\tSpars: 0.004653\n",
      "\t TVw: -0.575066 | TVb: -1.971814 | GSw: -0.443566 | GSb: -0.164948 | TSUw: 0.230188 | TSUb: 0.187982\n",
      "\n",
      "Train Epoch: 2219 [4000/8000 (50%)]\tBatch Loss: 0.017932\tLearning Rate (w_theta): 0.001000\t TIME:866.8s\n",
      "\t\t\t\tDisc: 0.012668\t\tSym: 0.000562\t\tSpars: 0.004702\n",
      "\t TVw: -0.575024 | TVb: -1.971758 | GSw: -0.443670 | GSb: -0.165086 | TSUw: 0.230055 | TSUb: 0.187976\n",
      "Validating epoch 2219...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018312102947015966\n",
      "Average validation loss: 0.017879685468663017\n",
      "Training epoch 2220...\n",
      "\n",
      "Train Epoch: 2220 [0/8000 (0%)]\tBatch Loss: 0.017985\tLearning Rate (w_theta): 0.001000\t TIME:869.2s\n",
      "\t\t\t\tDisc: 0.012806\t\tSym: 0.000546\t\tSpars: 0.004634\n",
      "\t TVw: -0.574939 | TVb: -1.971676 | GSw: -0.443770 | GSb: -0.165219 | TSUw: 0.229923 | TSUb: 0.187970\n",
      "\n",
      "Train Epoch: 2220 [4000/8000 (50%)]\tBatch Loss: 0.018294\tLearning Rate (w_theta): 0.001000\t TIME:870.7s\n",
      "\t\t\t\tDisc: 0.013136\t\tSym: 0.000547\t\tSpars: 0.004610\n",
      "\t TVw: -0.574898 | TVb: -1.971622 | GSw: -0.443873 | GSb: -0.165355 | TSUw: 0.229794 | TSUb: 0.187962\n",
      "Validating epoch 2220...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01827175121992598\n",
      "Average validation loss: 0.017860773330536917\n",
      "Training epoch 2221...\n",
      "\n",
      "Train Epoch: 2221 [0/8000 (0%)]\tBatch Loss: 0.017949\tLearning Rate (w_theta): 0.001000\t TIME:874.0s\n",
      "\t\t\t\tDisc: 0.012819\t\tSym: 0.000542\t\tSpars: 0.004588\n",
      "\t TVw: -0.574866 | TVb: -1.971572 | GSw: -0.443979 | GSb: -0.165495 | TSUw: 0.229660 | TSUb: 0.187955\n",
      "\n",
      "Train Epoch: 2221 [4000/8000 (50%)]\tBatch Loss: 0.018400\tLearning Rate (w_theta): 0.001000\t TIME:875.5s\n",
      "\t\t\t\tDisc: 0.013224\t\tSym: 0.000568\t\tSpars: 0.004608\n",
      "\t TVw: -0.574811 | TVb: -1.971513 | GSw: -0.444087 | GSb: -0.165637 | TSUw: 0.229525 | TSUb: 0.187950\n",
      "Validating epoch 2221...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018289492269101038\n",
      "Average validation loss: 0.01784547980461924\n",
      "Training epoch 2222...\n",
      "\n",
      "Train Epoch: 2222 [0/8000 (0%)]\tBatch Loss: 0.018414\tLearning Rate (w_theta): 0.001000\t TIME:877.9s\n",
      "\t\t\t\tDisc: 0.013286\t\tSym: 0.000561\t\tSpars: 0.004567\n",
      "\t TVw: -0.574768 | TVb: -1.971459 | GSw: -0.444190 | GSb: -0.165775 | TSUw: 0.229394 | TSUb: 0.187942\n",
      "\n",
      "Train Epoch: 2222 [4000/8000 (50%)]\tBatch Loss: 0.017912\tLearning Rate (w_theta): 0.001000\t TIME:879.4s\n",
      "\t\t\t\tDisc: 0.012819\t\tSym: 0.000546\t\tSpars: 0.004547\n",
      "\t TVw: -0.574751 | TVb: -1.971422 | GSw: -0.444291 | GSb: -0.165911 | TSUw: 0.229267 | TSUb: 0.187932\n",
      "Validating epoch 2222...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018250131682539007\n",
      "Average validation loss: 0.017777500722388446\n",
      "Training epoch 2223...\n",
      "\n",
      "Train Epoch: 2223 [0/8000 (0%)]\tBatch Loss: 0.018915\tLearning Rate (w_theta): 0.001000\t TIME:881.7s\n",
      "\t\t\t\tDisc: 0.013683\t\tSym: 0.000583\t\tSpars: 0.004649\n",
      "\t TVw: -0.574776 | TVb: -1.971413 | GSw: -0.444399 | GSb: -0.166055 | TSUw: 0.229137 | TSUb: 0.187923\n",
      "\n",
      "Train Epoch: 2223 [4000/8000 (50%)]\tBatch Loss: 0.018283\tLearning Rate (w_theta): 0.001000\t TIME:883.2s\n",
      "\t\t\t\tDisc: 0.013166\t\tSym: 0.000554\t\tSpars: 0.004563\n",
      "\t TVw: -0.574711 | TVb: -1.971350 | GSw: -0.444501 | GSb: -0.166192 | TSUw: 0.229004 | TSUb: 0.187915\n",
      "Validating epoch 2223...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01818369657607922\n",
      "Average validation loss: 0.01774059334419055\n",
      "Training epoch 2224...\n",
      "\n",
      "Train Epoch: 2224 [0/8000 (0%)]\tBatch Loss: 0.018244\tLearning Rate (w_theta): 0.001000\t TIME:885.7s\n",
      "\t\t\t\tDisc: 0.013199\t\tSym: 0.000545\t\tSpars: 0.004500\n",
      "\t TVw: -0.574637 | TVb: -1.971283 | GSw: -0.444601 | GSb: -0.166326 | TSUw: 0.228874 | TSUb: 0.187906\n",
      "\n",
      "Train Epoch: 2224 [4000/8000 (50%)]\tBatch Loss: 0.018270\tLearning Rate (w_theta): 0.001000\t TIME:887.3s\n",
      "\t\t\t\tDisc: 0.013222\t\tSym: 0.000550\t\tSpars: 0.004498\n",
      "\t TVw: -0.574610 | TVb: -1.971247 | GSw: -0.444707 | GSb: -0.166466 | TSUw: 0.228743 | TSUb: 0.187898\n",
      "Validating epoch 2224...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.018122522227409704\n",
      "Average validation loss: 0.01765496142011281\n",
      "Training epoch 2225...\n",
      "\n",
      "Train Epoch: 2225 [0/8000 (0%)]\tBatch Loss: 0.017823\tLearning Rate (w_theta): 0.001000\t TIME:889.7s\n",
      "\t\t\t\tDisc: 0.012821\t\tSym: 0.000545\t\tSpars: 0.004458\n",
      "\t TVw: -0.574566 | TVb: -1.971198 | GSw: -0.444812 | GSb: -0.166605 | TSUw: 0.228612 | TSUb: 0.187889\n",
      "\n",
      "Train Epoch: 2225 [4000/8000 (50%)]\tBatch Loss: 0.017900\tLearning Rate (w_theta): 0.001000\t TIME:891.2s\n",
      "\t\t\t\tDisc: 0.012926\t\tSym: 0.000544\t\tSpars: 0.004429\n",
      "\t TVw: -0.574493 | TVb: -1.971127 | GSw: -0.444915 | GSb: -0.166742 | TSUw: 0.228481 | TSUb: 0.187880\n",
      "Validating epoch 2225...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01805813663612104\n",
      "Average validation loss: 0.017602789050005146\n",
      "Training epoch 2226...\n",
      "\n",
      "Train Epoch: 2226 [0/8000 (0%)]\tBatch Loss: 0.018059\tLearning Rate (w_theta): 0.001000\t TIME:893.5s\n",
      "\t\t\t\tDisc: 0.013066\t\tSym: 0.000566\t\tSpars: 0.004428\n",
      "\t TVw: -0.574449 | TVb: -1.971079 | GSw: -0.445019 | GSb: -0.166881 | TSUw: 0.228351 | TSUb: 0.187870\n",
      "\n",
      "Train Epoch: 2226 [4000/8000 (50%)]\tBatch Loss: 0.017789\tLearning Rate (w_theta): 0.001000\t TIME:895.0s\n",
      "\t\t\t\tDisc: 0.012822\t\tSym: 0.000557\t\tSpars: 0.004409\n",
      "\t TVw: -0.574452 | TVb: -1.971056 | GSw: -0.445128 | GSb: -0.167026 | TSUw: 0.228222 | TSUb: 0.187859\n",
      "Validating epoch 2226...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01801271668804045\n",
      "Average validation loss: 0.017538754644902465\n",
      "Training epoch 2227...\n",
      "\n",
      "Train Epoch: 2227 [0/8000 (0%)]\tBatch Loss: 0.018106\tLearning Rate (w_theta): 0.001000\t TIME:897.4s\n",
      "\t\t\t\tDisc: 0.013178\t\tSym: 0.000559\t\tSpars: 0.004369\n",
      "\t TVw: -0.574412 | TVb: -1.971009 | GSw: -0.445233 | GSb: -0.167167 | TSUw: 0.228093 | TSUb: 0.187848\n",
      "\n",
      "Train Epoch: 2227 [4000/8000 (50%)]\tBatch Loss: 0.018102\tLearning Rate (w_theta): 0.001000\t TIME:898.9s\n",
      "\t\t\t\tDisc: 0.013156\t\tSym: 0.000568\t\tSpars: 0.004378\n",
      "\t TVw: -0.574367 | TVb: -1.970956 | GSw: -0.445338 | GSb: -0.167309 | TSUw: 0.227963 | TSUb: 0.187838\n",
      "Validating epoch 2227...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017981722088856494\n",
      "Average validation loss: 0.01753840400397901\n",
      "Training epoch 2228...\n",
      "\n",
      "Train Epoch: 2228 [0/8000 (0%)]\tBatch Loss: 0.017384\tLearning Rate (w_theta): 0.001000\t TIME:901.3s\n",
      "\t\t\t\tDisc: 0.012497\t\tSym: 0.000551\t\tSpars: 0.004335\n",
      "\t TVw: -0.574378 | TVb: -1.970934 | GSw: -0.445450 | GSb: -0.167458 | TSUw: 0.227831 | TSUb: 0.187828\n",
      "\n",
      "Train Epoch: 2228 [4000/8000 (50%)]\tBatch Loss: 0.018264\tLearning Rate (w_theta): 0.001000\t TIME:902.8s\n",
      "\t\t\t\tDisc: 0.013313\t\tSym: 0.000568\t\tSpars: 0.004384\n",
      "\t TVw: -0.574376 | TVb: -1.970903 | GSw: -0.445564 | GSb: -0.167607 | TSUw: 0.227698 | TSUb: 0.187819\n",
      "Validating epoch 2228...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017966886975819694\n",
      "Average validation loss: 0.0174741230658868\n",
      "Training epoch 2229...\n",
      "\n",
      "Train Epoch: 2229 [0/8000 (0%)]\tBatch Loss: 0.018040\tLearning Rate (w_theta): 0.001000\t TIME:905.2s\n",
      "\t\t\t\tDisc: 0.013130\t\tSym: 0.000567\t\tSpars: 0.004343\n",
      "\t TVw: -0.574335 | TVb: -1.970851 | GSw: -0.445671 | GSb: -0.167752 | TSUw: 0.227565 | TSUb: 0.187809\n",
      "\n",
      "Train Epoch: 2229 [4000/8000 (50%)]\tBatch Loss: 0.017694\tLearning Rate (w_theta): 0.001000\t TIME:906.8s\n",
      "\t\t\t\tDisc: 0.012868\t\tSym: 0.000539\t\tSpars: 0.004287\n",
      "\t TVw: -0.574333 | TVb: -1.970820 | GSw: -0.445784 | GSb: -0.167902 | TSUw: 0.227431 | TSUb: 0.187800\n",
      "Validating epoch 2229...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017920595193425322\n",
      "Average validation loss: 0.017435639335618067\n",
      "Training epoch 2230...\n",
      "\n",
      "Train Epoch: 2230 [0/8000 (0%)]\tBatch Loss: 0.017811\tLearning Rate (w_theta): 0.001000\t TIME:909.1s\n",
      "\t\t\t\tDisc: 0.012959\t\tSym: 0.000552\t\tSpars: 0.004300\n",
      "\t TVw: -0.574349 | TVb: -1.970801 | GSw: -0.445898 | GSb: -0.168054 | TSUw: 0.227297 | TSUb: 0.187791\n",
      "\n",
      "Train Epoch: 2230 [4000/8000 (50%)]\tBatch Loss: 0.017900\tLearning Rate (w_theta): 0.001000\t TIME:910.6s\n",
      "\t\t\t\tDisc: 0.012986\t\tSym: 0.000573\t\tSpars: 0.004341\n",
      "\t TVw: -0.574348 | TVb: -1.970770 | GSw: -0.446011 | GSb: -0.168205 | TSUw: 0.227161 | TSUb: 0.187782\n",
      "Validating epoch 2230...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01789316549416828\n",
      "Average validation loss: 0.017419435157709644\n",
      "Training epoch 2231...\n",
      "\n",
      "Train Epoch: 2231 [0/8000 (0%)]\tBatch Loss: 0.017948\tLearning Rate (w_theta): 0.001000\t TIME:913.7s\n",
      "\t\t\t\tDisc: 0.013125\t\tSym: 0.000548\t\tSpars: 0.004275\n",
      "\t TVw: -0.574326 | TVb: -1.970730 | GSw: -0.446124 | GSb: -0.168356 | TSUw: 0.227025 | TSUb: 0.187773\n",
      "\n",
      "Train Epoch: 2231 [4000/8000 (50%)]\tBatch Loss: 0.017965\tLearning Rate (w_theta): 0.001000\t TIME:915.2s\n",
      "\t\t\t\tDisc: 0.013157\t\tSym: 0.000545\t\tSpars: 0.004263\n",
      "\t TVw: -0.574324 | TVb: -1.970706 | GSw: -0.446237 | GSb: -0.168507 | TSUw: 0.226890 | TSUb: 0.187764\n",
      "Validating epoch 2231...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01788217228931362\n",
      "Average validation loss: 0.0174008990758642\n",
      "Training epoch 2232...\n",
      "\n",
      "Train Epoch: 2232 [0/8000 (0%)]\tBatch Loss: 0.017913\tLearning Rate (w_theta): 0.001000\t TIME:917.5s\n",
      "\t\t\t\tDisc: 0.013043\t\tSym: 0.000563\t\tSpars: 0.004306\n",
      "\t TVw: -0.574354 | TVb: -1.970703 | GSw: -0.446353 | GSb: -0.168662 | TSUw: 0.226755 | TSUb: 0.187754\n",
      "\n",
      "Train Epoch: 2232 [4000/8000 (50%)]\tBatch Loss: 0.017906\tLearning Rate (w_theta): 0.001000\t TIME:919.0s\n",
      "\t\t\t\tDisc: 0.013053\t\tSym: 0.000567\t\tSpars: 0.004285\n",
      "\t TVw: -0.574339 | TVb: -1.970670 | GSw: -0.446467 | GSb: -0.168814 | TSUw: 0.226619 | TSUb: 0.187744\n",
      "Validating epoch 2232...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017872281640870843\n",
      "Average validation loss: 0.01740785333897773\n",
      "Training epoch 2233...\n",
      "\n",
      "Train Epoch: 2233 [0/8000 (0%)]\tBatch Loss: 0.017896\tLearning Rate (w_theta): 0.001000\t TIME:921.5s\n",
      "\t\t\t\tDisc: 0.013027\t\tSym: 0.000576\t\tSpars: 0.004293\n",
      "\t TVw: -0.574319 | TVb: -1.970631 | GSw: -0.446579 | GSb: -0.168965 | TSUw: 0.226483 | TSUb: 0.187735\n",
      "\n",
      "Train Epoch: 2233 [4000/8000 (50%)]\tBatch Loss: 0.017831\tLearning Rate (w_theta): 0.001000\t TIME:923.0s\n",
      "\t\t\t\tDisc: 0.013029\t\tSym: 0.000548\t\tSpars: 0.004254\n",
      "\t TVw: -0.574368 | TVb: -1.970637 | GSw: -0.446699 | GSb: -0.169124 | TSUw: 0.226344 | TSUb: 0.187727\n",
      "Validating epoch 2233...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017856877079401545\n",
      "Average validation loss: 0.01737263341267029\n",
      "Training epoch 2234...\n",
      "\n",
      "Train Epoch: 2234 [0/8000 (0%)]\tBatch Loss: 0.017500\tLearning Rate (w_theta): 0.001000\t TIME:925.4s\n",
      "\t\t\t\tDisc: 0.012694\t\tSym: 0.000558\t\tSpars: 0.004247\n",
      "\t TVw: -0.574349 | TVb: -1.970598 | GSw: -0.446813 | GSb: -0.169276 | TSUw: 0.226206 | TSUb: 0.187718\n",
      "\n",
      "Train Epoch: 2234 [4000/8000 (50%)]\tBatch Loss: 0.017772\tLearning Rate (w_theta): 0.001000\t TIME:926.9s\n",
      "\t\t\t\tDisc: 0.012907\t\tSym: 0.000575\t\tSpars: 0.004290\n",
      "\t TVw: -0.574352 | TVb: -1.970573 | GSw: -0.446931 | GSb: -0.169433 | TSUw: 0.226066 | TSUb: 0.187710\n",
      "Validating epoch 2234...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017834805012434875\n",
      "Average validation loss: 0.017365810741117437\n",
      "Training epoch 2235...\n",
      "\n",
      "Train Epoch: 2235 [0/8000 (0%)]\tBatch Loss: 0.017713\tLearning Rate (w_theta): 0.001000\t TIME:929.3s\n",
      "\t\t\t\tDisc: 0.012964\t\tSym: 0.000550\t\tSpars: 0.004199\n",
      "\t TVw: -0.574353 | TVb: -1.970550 | GSw: -0.447046 | GSb: -0.169586 | TSUw: 0.225928 | TSUb: 0.187700\n",
      "\n",
      "Train Epoch: 2235 [4000/8000 (50%)]\tBatch Loss: 0.017767\tLearning Rate (w_theta): 0.001000\t TIME:930.8s\n",
      "\t\t\t\tDisc: 0.012949\t\tSym: 0.000567\t\tSpars: 0.004251\n",
      "\t TVw: -0.574365 | TVb: -1.970533 | GSw: -0.447164 | GSb: -0.169742 | TSUw: 0.225789 | TSUb: 0.187691\n",
      "Validating epoch 2235...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01782592041202625\n",
      "Average validation loss: 0.017353712892691282\n",
      "Training epoch 2236...\n",
      "\n",
      "Train Epoch: 2236 [0/8000 (0%)]\tBatch Loss: 0.018051\tLearning Rate (w_theta): 0.001000\t TIME:933.1s\n",
      "\t\t\t\tDisc: 0.013227\t\tSym: 0.000571\t\tSpars: 0.004253\n",
      "\t TVw: -0.574383 | TVb: -1.970518 | GSw: -0.447283 | GSb: -0.169900 | TSUw: 0.225648 | TSUb: 0.187683\n",
      "\n",
      "Train Epoch: 2236 [4000/8000 (50%)]\tBatch Loss: 0.017400\tLearning Rate (w_theta): 0.001000\t TIME:934.6s\n",
      "\t\t\t\tDisc: 0.012578\t\tSym: 0.000573\t\tSpars: 0.004248\n",
      "\t TVw: -0.574399 | TVb: -1.970502 | GSw: -0.447403 | GSb: -0.170059 | TSUw: 0.225507 | TSUb: 0.187675\n",
      "Validating epoch 2236...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01781165351588468\n",
      "Average validation loss: 0.01734416491249441\n",
      "Training epoch 2237...\n",
      "\n",
      "Train Epoch: 2237 [0/8000 (0%)]\tBatch Loss: 0.017328\tLearning Rate (w_theta): 0.001000\t TIME:937.0s\n",
      "\t\t\t\tDisc: 0.012594\t\tSym: 0.000548\t\tSpars: 0.004187\n",
      "\t TVw: -0.574402 | TVb: -1.970477 | GSw: -0.447521 | GSb: -0.170215 | TSUw: 0.225367 | TSUb: 0.187666\n",
      "\n",
      "Train Epoch: 2237 [4000/8000 (50%)]\tBatch Loss: 0.017790\tLearning Rate (w_theta): 0.001000\t TIME:938.6s\n",
      "\t\t\t\tDisc: 0.012938\t\tSym: 0.000582\t\tSpars: 0.004270\n",
      "\t TVw: -0.574428 | TVb: -1.970469 | GSw: -0.447642 | GSb: -0.170375 | TSUw: 0.225224 | TSUb: 0.187658\n",
      "Validating epoch 2237...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017805101188793634\n",
      "Average validation loss: 0.0173689291755572\n",
      "Training epoch 2238...\n",
      "\n",
      "Train Epoch: 2238 [0/8000 (0%)]\tBatch Loss: 0.017713\tLearning Rate (w_theta): 0.001000\t TIME:941.1s\n",
      "\t\t\t\tDisc: 0.012913\t\tSym: 0.000565\t\tSpars: 0.004234\n",
      "\t TVw: -0.574420 | TVb: -1.970431 | GSw: -0.447763 | GSb: -0.170535 | TSUw: 0.225078 | TSUb: 0.187652\n",
      "\n",
      "Train Epoch: 2238 [4000/8000 (50%)]\tBatch Loss: 0.017915\tLearning Rate (w_theta): 0.001000\t TIME:942.6s\n",
      "\t\t\t\tDisc: 0.013101\t\tSym: 0.000580\t\tSpars: 0.004234\n",
      "\t TVw: -0.574452 | TVb: -1.970419 | GSw: -0.447891 | GSb: -0.170701 | TSUw: 0.224928 | TSUb: 0.187647\n",
      "Validating epoch 2238...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017857406754119357\n",
      "Average validation loss: 0.017372558971121978\n",
      "Training epoch 2239...\n",
      "\n",
      "Train Epoch: 2239 [0/8000 (0%)]\tBatch Loss: 0.018007\tLearning Rate (w_theta): 0.001000\t TIME:945.0s\n",
      "\t\t\t\tDisc: 0.013157\t\tSym: 0.000579\t\tSpars: 0.004271\n",
      "\t TVw: -0.574470 | TVb: -1.970403 | GSw: -0.448011 | GSb: -0.170860 | TSUw: 0.224783 | TSUb: 0.187640\n",
      "\n",
      "Train Epoch: 2239 [4000/8000 (50%)]\tBatch Loss: 0.017981\tLearning Rate (w_theta): 0.001000\t TIME:946.5s\n",
      "\t\t\t\tDisc: 0.013119\t\tSym: 0.000582\t\tSpars: 0.004280\n",
      "\t TVw: -0.574501 | TVb: -1.970393 | GSw: -0.448134 | GSb: -0.171021 | TSUw: 0.224636 | TSUb: 0.187633\n",
      "Validating epoch 2239...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017855411014379707\n",
      "Average validation loss: 0.017344371562774706\n",
      "Training epoch 2240...\n",
      "\n",
      "Train Epoch: 2240 [0/8000 (0%)]\tBatch Loss: 0.017685\tLearning Rate (w_theta): 0.001000\t TIME:948.8s\n",
      "\t\t\t\tDisc: 0.012873\t\tSym: 0.000563\t\tSpars: 0.004248\n",
      "\t TVw: -0.574508 | TVb: -1.970376 | GSw: -0.448253 | GSb: -0.171178 | TSUw: 0.224490 | TSUb: 0.187626\n",
      "\n",
      "Train Epoch: 2240 [4000/8000 (50%)]\tBatch Loss: 0.017761\tLearning Rate (w_theta): 0.001000\t TIME:950.4s\n",
      "\t\t\t\tDisc: 0.012965\t\tSym: 0.000562\t\tSpars: 0.004234\n",
      "\t TVw: -0.574517 | TVb: -1.970363 | GSw: -0.448374 | GSb: -0.171338 | TSUw: 0.224343 | TSUb: 0.187619\n",
      "Validating epoch 2240...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01780810656415896\n",
      "Average validation loss: 0.01730862513824971\n",
      "Training epoch 2241...\n",
      "\n",
      "Train Epoch: 2241 [0/8000 (0%)]\tBatch Loss: 0.017657\tLearning Rate (w_theta): 0.001000\t TIME:953.5s\n",
      "\t\t\t\tDisc: 0.012879\t\tSym: 0.000563\t\tSpars: 0.004214\n",
      "\t TVw: -0.574524 | TVb: -1.970343 | GSw: -0.448499 | GSb: -0.171499 | TSUw: 0.224193 | TSUb: 0.187613\n",
      "\n",
      "Train Epoch: 2241 [4000/8000 (50%)]\tBatch Loss: 0.018112\tLearning Rate (w_theta): 0.001000\t TIME:955.0s\n",
      "\t\t\t\tDisc: 0.013253\t\tSym: 0.000591\t\tSpars: 0.004268\n",
      "\t TVw: -0.574484 | TVb: -1.970291 | GSw: -0.448620 | GSb: -0.171656 | TSUw: 0.224044 | TSUb: 0.187607\n",
      "Validating epoch 2241...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017764853936801547\n",
      "Average validation loss: 0.0172646117817463\n",
      "Training epoch 2242...\n",
      "\n",
      "Train Epoch: 2242 [0/8000 (0%)]\tBatch Loss: 0.018250\tLearning Rate (w_theta): 0.001000\t TIME:957.4s\n",
      "\t\t\t\tDisc: 0.013409\t\tSym: 0.000593\t\tSpars: 0.004249\n",
      "\t TVw: -0.574486 | TVb: -1.970267 | GSw: -0.448744 | GSb: -0.171818 | TSUw: 0.223896 | TSUb: 0.187600\n",
      "\n",
      "Train Epoch: 2242 [4000/8000 (50%)]\tBatch Loss: 0.017445\tLearning Rate (w_theta): 0.001000\t TIME:958.9s\n",
      "\t\t\t\tDisc: 0.012787\t\tSym: 0.000537\t\tSpars: 0.004120\n",
      "\t TVw: -0.574490 | TVb: -1.970239 | GSw: -0.448870 | GSb: -0.171982 | TSUw: 0.223748 | TSUb: 0.187593\n",
      "Validating epoch 2242...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017738597872242762\n",
      "Average validation loss: 0.017251360094220083\n",
      "Training epoch 2243...\n",
      "\n",
      "Train Epoch: 2243 [0/8000 (0%)]\tBatch Loss: 0.017710\tLearning Rate (w_theta): 0.001000\t TIME:961.3s\n",
      "\t\t\t\tDisc: 0.012936\t\tSym: 0.000568\t\tSpars: 0.004205\n",
      "\t TVw: -0.574502 | TVb: -1.970223 | GSw: -0.448992 | GSb: -0.172142 | TSUw: 0.223604 | TSUb: 0.187583\n",
      "\n",
      "Train Epoch: 2243 [4000/8000 (50%)]\tBatch Loss: 0.017069\tLearning Rate (w_theta): 0.001000\t TIME:962.8s\n",
      "\t\t\t\tDisc: 0.012414\t\tSym: 0.000540\t\tSpars: 0.004115\n",
      "\t TVw: -0.574532 | TVb: -1.970219 | GSw: -0.449113 | GSb: -0.172301 | TSUw: 0.223464 | TSUb: 0.187572\n",
      "Validating epoch 2243...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01772541357839167\n",
      "Average validation loss: 0.017241962422522045\n",
      "Training epoch 2244...\n",
      "\n",
      "Train Epoch: 2244 [0/8000 (0%)]\tBatch Loss: 0.017405\tLearning Rate (w_theta): 0.001000\t TIME:965.2s\n",
      "\t\t\t\tDisc: 0.012690\t\tSym: 0.000555\t\tSpars: 0.004160\n",
      "\t TVw: -0.574564 | TVb: -1.970210 | GSw: -0.449237 | GSb: -0.172464 | TSUw: 0.223321 | TSUb: 0.187562\n",
      "\n",
      "Train Epoch: 2244 [4000/8000 (50%)]\tBatch Loss: 0.017740\tLearning Rate (w_theta): 0.001000\t TIME:966.7s\n",
      "\t\t\t\tDisc: 0.012959\t\tSym: 0.000576\t\tSpars: 0.004205\n",
      "\t TVw: -0.574599 | TVb: -1.970199 | GSw: -0.449363 | GSb: -0.172630 | TSUw: 0.223175 | TSUb: 0.187552\n",
      "Validating epoch 2244...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017702315351092048\n",
      "Average validation loss: 0.01722988650190378\n",
      "Training epoch 2245...\n",
      "\n",
      "Train Epoch: 2245 [0/8000 (0%)]\tBatch Loss: 0.017680\tLearning Rate (w_theta): 0.001000\t TIME:969.1s\n",
      "\t\t\t\tDisc: 0.012954\t\tSym: 0.000565\t\tSpars: 0.004161\n",
      "\t TVw: -0.574596 | TVb: -1.970170 | GSw: -0.449486 | GSb: -0.172791 | TSUw: 0.223028 | TSUb: 0.187543\n",
      "\n",
      "Train Epoch: 2245 [4000/8000 (50%)]\tBatch Loss: 0.018183\tLearning Rate (w_theta): 0.001000\t TIME:970.6s\n",
      "\t\t\t\tDisc: 0.013343\t\tSym: 0.000595\t\tSpars: 0.004245\n",
      "\t TVw: -0.574626 | TVb: -1.970162 | GSw: -0.449613 | GSb: -0.172957 | TSUw: 0.222881 | TSUb: 0.187535\n",
      "Validating epoch 2245...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01769068066439744\n",
      "Average validation loss: 0.017225786281478372\n",
      "Training epoch 2246...\n",
      "\n",
      "Train Epoch: 2246 [0/8000 (0%)]\tBatch Loss: 0.018037\tLearning Rate (w_theta): 0.001000\t TIME:973.1s\n",
      "\t\t\t\tDisc: 0.013225\t\tSym: 0.000585\t\tSpars: 0.004227\n",
      "\t TVw: -0.574664 | TVb: -1.970160 | GSw: -0.449740 | GSb: -0.173123 | TSUw: 0.222733 | TSUb: 0.187526\n",
      "\n",
      "Train Epoch: 2246 [4000/8000 (50%)]\tBatch Loss: 0.017594\tLearning Rate (w_theta): 0.001000\t TIME:974.6s\n",
      "\t\t\t\tDisc: 0.012851\t\tSym: 0.000562\t\tSpars: 0.004181\n",
      "\t TVw: -0.574653 | TVb: -1.970128 | GSw: -0.449863 | GSb: -0.173285 | TSUw: 0.222585 | TSUb: 0.187517\n",
      "Validating epoch 2246...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017679373369135488\n",
      "Average validation loss: 0.017208918502464175\n",
      "Training epoch 2247...\n",
      "\n",
      "Train Epoch: 2247 [0/8000 (0%)]\tBatch Loss: 0.017592\tLearning Rate (w_theta): 0.001000\t TIME:977.0s\n",
      "\t\t\t\tDisc: 0.012848\t\tSym: 0.000572\t\tSpars: 0.004172\n",
      "\t TVw: -0.574660 | TVb: -1.970106 | GSw: -0.449989 | GSb: -0.173449 | TSUw: 0.222435 | TSUb: 0.187509\n",
      "\n",
      "Train Epoch: 2247 [4000/8000 (50%)]\tBatch Loss: 0.017395\tLearning Rate (w_theta): 0.001000\t TIME:978.5s\n",
      "\t\t\t\tDisc: 0.012686\t\tSym: 0.000555\t\tSpars: 0.004153\n",
      "\t TVw: -0.574682 | TVb: -1.970094 | GSw: -0.450117 | GSb: -0.173615 | TSUw: 0.222285 | TSUb: 0.187501\n",
      "Validating epoch 2247...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01766734243784021\n",
      "Average validation loss: 0.01720037065269874\n",
      "Training epoch 2248...\n",
      "\n",
      "Train Epoch: 2248 [0/8000 (0%)]\tBatch Loss: 0.017535\tLearning Rate (w_theta): 0.001000\t TIME:980.9s\n",
      "\t\t\t\tDisc: 0.012796\t\tSym: 0.000575\t\tSpars: 0.004164\n",
      "\t TVw: -0.574660 | TVb: -1.970051 | GSw: -0.450240 | GSb: -0.173776 | TSUw: 0.222136 | TSUb: 0.187492\n",
      "\n",
      "Train Epoch: 2248 [4000/8000 (50%)]\tBatch Loss: 0.017880\tLearning Rate (w_theta): 0.001000\t TIME:982.4s\n",
      "\t\t\t\tDisc: 0.013084\t\tSym: 0.000588\t\tSpars: 0.004208\n",
      "\t TVw: -0.574712 | TVb: -1.970053 | GSw: -0.450372 | GSb: -0.173947 | TSUw: 0.221985 | TSUb: 0.187484\n",
      "Validating epoch 2248...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0176579115846842\n",
      "Average validation loss: 0.017188277803653555\n",
      "Training epoch 2249...\n",
      "\n",
      "Train Epoch: 2249 [0/8000 (0%)]\tBatch Loss: 0.017459\tLearning Rate (w_theta): 0.001000\t TIME:984.8s\n",
      "\t\t\t\tDisc: 0.012764\t\tSym: 0.000557\t\tSpars: 0.004139\n",
      "\t TVw: -0.574718 | TVb: -1.970027 | GSw: -0.450498 | GSb: -0.174112 | TSUw: 0.221835 | TSUb: 0.187475\n",
      "\n",
      "Train Epoch: 2249 [4000/8000 (50%)]\tBatch Loss: 0.017699\tLearning Rate (w_theta): 0.001000\t TIME:986.3s\n",
      "\t\t\t\tDisc: 0.012986\t\tSym: 0.000565\t\tSpars: 0.004148\n",
      "\t TVw: -0.574724 | TVb: -1.970009 | GSw: -0.450625 | GSb: -0.174276 | TSUw: 0.221685 | TSUb: 0.187466\n",
      "Validating epoch 2249...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017725250408738957\n",
      "Average validation loss: 0.01720904009813583\n",
      "Training epoch 2250...\n",
      "\n",
      "Train Epoch: 2250 [0/8000 (0%)]\tBatch Loss: 0.018131\tLearning Rate (w_theta): 0.001000\t TIME:988.7s\n",
      "\t\t\t\tDisc: 0.013355\t\tSym: 0.000586\t\tSpars: 0.004190\n",
      "\t TVw: -0.574786 | TVb: -1.970023 | GSw: -0.450755 | GSb: -0.174446 | TSUw: 0.221533 | TSUb: 0.187457\n",
      "\n",
      "Train Epoch: 2250 [4000/8000 (50%)]\tBatch Loss: 0.017581\tLearning Rate (w_theta): 0.001000\t TIME:990.2s\n",
      "\t\t\t\tDisc: 0.012813\t\tSym: 0.000568\t\tSpars: 0.004199\n",
      "\t TVw: -0.574814 | TVb: -1.970016 | GSw: -0.450883 | GSb: -0.174613 | TSUw: 0.221378 | TSUb: 0.187450\n",
      "Validating epoch 2250...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01770865318927401\n",
      "Average validation loss: 0.01720293833291927\n",
      "Training epoch 2251...\n",
      "\n",
      "Train Epoch: 2251 [0/8000 (0%)]\tBatch Loss: 0.017743\tLearning Rate (w_theta): 0.001000\t TIME:993.3s\n",
      "\t\t\t\tDisc: 0.012978\t\tSym: 0.000568\t\tSpars: 0.004197\n",
      "\t TVw: -0.574837 | TVb: -1.970006 | GSw: -0.451011 | GSb: -0.174779 | TSUw: 0.221224 | TSUb: 0.187442\n",
      "\n",
      "Train Epoch: 2251 [4000/8000 (50%)]\tBatch Loss: 0.018021\tLearning Rate (w_theta): 0.001000\t TIME:994.8s\n",
      "\t\t\t\tDisc: 0.013206\t\tSym: 0.000586\t\tSpars: 0.004229\n",
      "\t TVw: -0.574830 | TVb: -1.969974 | GSw: -0.451138 | GSb: -0.174944 | TSUw: 0.221070 | TSUb: 0.187434\n",
      "Validating epoch 2251...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01766316328199627\n",
      "Average validation loss: 0.01717757407545542\n",
      "Training epoch 2252...\n",
      "\n",
      "Train Epoch: 2252 [0/8000 (0%)]\tBatch Loss: 0.017691\tLearning Rate (w_theta): 0.001000\t TIME:997.2s\n",
      "\t\t\t\tDisc: 0.012951\t\tSym: 0.000569\t\tSpars: 0.004170\n",
      "\t TVw: -0.574843 | TVb: -1.969955 | GSw: -0.451269 | GSb: -0.175113 | TSUw: 0.220914 | TSUb: 0.187428\n",
      "\n",
      "Train Epoch: 2252 [4000/8000 (50%)]\tBatch Loss: 0.017665\tLearning Rate (w_theta): 0.001000\t TIME:998.7s\n",
      "\t\t\t\tDisc: 0.012904\t\tSym: 0.000576\t\tSpars: 0.004185\n",
      "\t TVw: -0.574843 | TVb: -1.969928 | GSw: -0.451398 | GSb: -0.175279 | TSUw: 0.220760 | TSUb: 0.187419\n",
      "Validating epoch 2252...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017627982822981808\n",
      "Average validation loss: 0.01714318678337092\n",
      "Training epoch 2253...\n",
      "\n",
      "Train Epoch: 2253 [0/8000 (0%)]\tBatch Loss: 0.017453\tLearning Rate (w_theta): 0.001000\t TIME:1001.1s\n",
      "\t\t\t\tDisc: 0.012758\t\tSym: 0.000565\t\tSpars: 0.004130\n",
      "\t TVw: -0.574817 | TVb: -1.969887 | GSw: -0.451526 | GSb: -0.175444 | TSUw: 0.220606 | TSUb: 0.187410\n",
      "\n",
      "Train Epoch: 2253 [4000/8000 (50%)]\tBatch Loss: 0.017617\tLearning Rate (w_theta): 0.001000\t TIME:1002.6s\n",
      "\t\t\t\tDisc: 0.012873\t\tSym: 0.000577\t\tSpars: 0.004167\n",
      "\t TVw: -0.574834 | TVb: -1.969875 | GSw: -0.451655 | GSb: -0.175611 | TSUw: 0.220455 | TSUb: 0.187400\n",
      "Validating epoch 2253...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01760655831406329\n",
      "Average validation loss: 0.017124963044457476\n",
      "Training epoch 2254...\n",
      "\n",
      "Train Epoch: 2254 [0/8000 (0%)]\tBatch Loss: 0.017243\tLearning Rate (w_theta): 0.001000\t TIME:1005.1s\n",
      "\t\t\t\tDisc: 0.012528\t\tSym: 0.000574\t\tSpars: 0.004141\n",
      "\t TVw: -0.574858 | TVb: -1.969868 | GSw: -0.451783 | GSb: -0.175778 | TSUw: 0.220307 | TSUb: 0.187388\n",
      "\n",
      "Train Epoch: 2254 [4000/8000 (50%)]\tBatch Loss: 0.017831\tLearning Rate (w_theta): 0.001000\t TIME:1006.6s\n",
      "\t\t\t\tDisc: 0.013079\t\tSym: 0.000583\t\tSpars: 0.004169\n",
      "\t TVw: -0.574869 | TVb: -1.969850 | GSw: -0.451909 | GSb: -0.175941 | TSUw: 0.220159 | TSUb: 0.187376\n",
      "Validating epoch 2254...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017659081251905812\n",
      "Average validation loss: 0.017244891818580223\n",
      "Training epoch 2255...\n",
      "\n",
      "Train Epoch: 2255 [0/8000 (0%)]\tBatch Loss: 0.017893\tLearning Rate (w_theta): 0.001000\t TIME:1009.0s\n",
      "\t\t\t\tDisc: 0.013204\t\tSym: 0.000569\t\tSpars: 0.004120\n",
      "\t TVw: -0.574946 | TVb: -1.969872 | GSw: -0.452041 | GSb: -0.176113 | TSUw: 0.220008 | TSUb: 0.187365\n",
      "\n",
      "Train Epoch: 2255 [4000/8000 (50%)]\tBatch Loss: 0.017638\tLearning Rate (w_theta): 0.001000\t TIME:1010.5s\n",
      "\t\t\t\tDisc: 0.012868\t\tSym: 0.000570\t\tSpars: 0.004200\n",
      "\t TVw: -0.575015 | TVb: -1.969884 | GSw: -0.452170 | GSb: -0.176281 | TSUw: 0.219858 | TSUb: 0.187353\n",
      "Validating epoch 2255...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01771150238493828\n",
      "Average validation loss: 0.01720025585574841\n",
      "Training epoch 2256...\n",
      "\n",
      "Train Epoch: 2256 [0/8000 (0%)]\tBatch Loss: 0.017892\tLearning Rate (w_theta): 0.001000\t TIME:1012.8s\n",
      "\t\t\t\tDisc: 0.013126\t\tSym: 0.000570\t\tSpars: 0.004195\n",
      "\t TVw: -0.575058 | TVb: -1.969884 | GSw: -0.452299 | GSb: -0.176448 | TSUw: 0.219703 | TSUb: 0.187344\n",
      "\n",
      "Train Epoch: 2256 [4000/8000 (50%)]\tBatch Loss: 0.017472\tLearning Rate (w_theta): 0.001000\t TIME:1014.4s\n",
      "\t\t\t\tDisc: 0.012752\t\tSym: 0.000548\t\tSpars: 0.004173\n",
      "\t TVw: -0.575088 | TVb: -1.969877 | GSw: -0.452429 | GSb: -0.176617 | TSUw: 0.219545 | TSUb: 0.187336\n",
      "Validating epoch 2256...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017648080388216515\n",
      "Average validation loss: 0.017165179070643542\n",
      "Training epoch 2257...\n",
      "\n",
      "Train Epoch: 2257 [0/8000 (0%)]\tBatch Loss: 0.017906\tLearning Rate (w_theta): 0.001000\t TIME:1016.8s\n",
      "\t\t\t\tDisc: 0.013145\t\tSym: 0.000566\t\tSpars: 0.004195\n",
      "\t TVw: -0.575075 | TVb: -1.969845 | GSw: -0.452559 | GSb: -0.176784 | TSUw: 0.219386 | TSUb: 0.187328\n",
      "\n",
      "Train Epoch: 2257 [4000/8000 (50%)]\tBatch Loss: 0.017600\tLearning Rate (w_theta): 0.001000\t TIME:1018.3s\n",
      "\t\t\t\tDisc: 0.012880\t\tSym: 0.000565\t\tSpars: 0.004155\n",
      "\t TVw: -0.575048 | TVb: -1.969802 | GSw: -0.452690 | GSb: -0.176952 | TSUw: 0.219227 | TSUb: 0.187320\n",
      "Validating epoch 2257...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017610752671360284\n",
      "Average validation loss: 0.01711358019481928\n",
      "Training epoch 2258...\n",
      "\n",
      "Train Epoch: 2258 [0/8000 (0%)]\tBatch Loss: 0.017709\tLearning Rate (w_theta): 0.001000\t TIME:1020.7s\n",
      "\t\t\t\tDisc: 0.012969\t\tSym: 0.000572\t\tSpars: 0.004168\n",
      "\t TVw: -0.575034 | TVb: -1.969769 | GSw: -0.452821 | GSb: -0.177120 | TSUw: 0.219069 | TSUb: 0.187311\n",
      "\n",
      "Train Epoch: 2258 [4000/8000 (50%)]\tBatch Loss: 0.017493\tLearning Rate (w_theta): 0.001000\t TIME:1022.2s\n",
      "\t\t\t\tDisc: 0.012802\t\tSym: 0.000569\t\tSpars: 0.004122\n",
      "\t TVw: -0.575007 | TVb: -1.969727 | GSw: -0.452952 | GSb: -0.177288 | TSUw: 0.218912 | TSUb: 0.187302\n",
      "Validating epoch 2258...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017564954841961838\n",
      "Average validation loss: 0.01707956604064011\n",
      "Training epoch 2259...\n",
      "\n",
      "Train Epoch: 2259 [0/8000 (0%)]\tBatch Loss: 0.017289\tLearning Rate (w_theta): 0.001000\t TIME:1024.5s\n",
      "\t\t\t\tDisc: 0.012691\t\tSym: 0.000538\t\tSpars: 0.004061\n",
      "\t TVw: -0.575028 | TVb: -1.969719 | GSw: -0.453083 | GSb: -0.177456 | TSUw: 0.218759 | TSUb: 0.187290\n",
      "\n",
      "Train Epoch: 2259 [4000/8000 (50%)]\tBatch Loss: 0.017042\tLearning Rate (w_theta): 0.001000\t TIME:1026.0s\n",
      "\t\t\t\tDisc: 0.012421\t\tSym: 0.000548\t\tSpars: 0.004073\n",
      "\t TVw: -0.575062 | TVb: -1.969723 | GSw: -0.453212 | GSb: -0.177622 | TSUw: 0.218613 | TSUb: 0.187275\n",
      "Validating epoch 2259...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017544718165644523\n",
      "Average validation loss: 0.017087301846845784\n",
      "Training epoch 2260...\n",
      "\n",
      "Train Epoch: 2260 [0/8000 (0%)]\tBatch Loss: 0.017726\tLearning Rate (w_theta): 0.001000\t TIME:1028.5s\n",
      "\t\t\t\tDisc: 0.013031\t\tSym: 0.000574\t\tSpars: 0.004121\n",
      "\t TVw: -0.575033 | TVb: -1.969682 | GSw: -0.453336 | GSb: -0.177784 | TSUw: 0.218464 | TSUb: 0.187261\n",
      "\n",
      "Train Epoch: 2260 [4000/8000 (50%)]\tBatch Loss: 0.017045\tLearning Rate (w_theta): 0.001000\t TIME:1030.0s\n",
      "\t\t\t\tDisc: 0.012450\t\tSym: 0.000547\t\tSpars: 0.004048\n",
      "\t TVw: -0.575092 | TVb: -1.969688 | GSw: -0.453472 | GSb: -0.177959 | TSUw: 0.218308 | TSUb: 0.187250\n",
      "Validating epoch 2260...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017540766805052788\n",
      "Average validation loss: 0.017060348933188023\n",
      "Training epoch 2261...\n",
      "\n",
      "Train Epoch: 2261 [0/8000 (0%)]\tBatch Loss: 0.017434\tLearning Rate (w_theta): 0.001000\t TIME:1033.0s\n",
      "\t\t\t\tDisc: 0.012767\t\tSym: 0.000556\t\tSpars: 0.004111\n",
      "\t TVw: -0.575164 | TVb: -1.969705 | GSw: -0.453606 | GSb: -0.178132 | TSUw: 0.218157 | TSUb: 0.187237\n",
      "\n",
      "Train Epoch: 2261 [4000/8000 (50%)]\tBatch Loss: 0.017200\tLearning Rate (w_theta): 0.001000\t TIME:1034.5s\n",
      "\t\t\t\tDisc: 0.012557\t\tSym: 0.000554\t\tSpars: 0.004089\n",
      "\t TVw: -0.575152 | TVb: -1.969670 | GSw: -0.453737 | GSb: -0.178302 | TSUw: 0.218002 | TSUb: 0.187225\n",
      "Validating epoch 2261...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01753311791797781\n",
      "Average validation loss: 0.01706317553004333\n",
      "Training epoch 2262...\n",
      "\n",
      "Train Epoch: 2262 [0/8000 (0%)]\tBatch Loss: 0.017794\tLearning Rate (w_theta): 0.001000\t TIME:1036.9s\n",
      "\t\t\t\tDisc: 0.013106\t\tSym: 0.000567\t\tSpars: 0.004122\n",
      "\t TVw: -0.575192 | TVb: -1.969666 | GSw: -0.453870 | GSb: -0.178474 | TSUw: 0.217848 | TSUb: 0.187212\n",
      "\n",
      "Train Epoch: 2262 [4000/8000 (50%)]\tBatch Loss: 0.017460\tLearning Rate (w_theta): 0.001000\t TIME:1038.4s\n",
      "\t\t\t\tDisc: 0.012778\t\tSym: 0.000567\t\tSpars: 0.004115\n",
      "\t TVw: -0.575233 | TVb: -1.969662 | GSw: -0.454006 | GSb: -0.178649 | TSUw: 0.217691 | TSUb: 0.187201\n",
      "Validating epoch 2262...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017519531791980864\n",
      "Average validation loss: 0.01704328236845136\n",
      "Training epoch 2263...\n",
      "\n",
      "Train Epoch: 2263 [0/8000 (0%)]\tBatch Loss: 0.017134\tLearning Rate (w_theta): 0.001000\t TIME:1040.8s\n",
      "\t\t\t\tDisc: 0.012470\t\tSym: 0.000563\t\tSpars: 0.004101\n",
      "\t TVw: -0.575253 | TVb: -1.969650 | GSw: -0.454138 | GSb: -0.178819 | TSUw: 0.217537 | TSUb: 0.187188\n",
      "\n",
      "Train Epoch: 2263 [4000/8000 (50%)]\tBatch Loss: 0.017487\tLearning Rate (w_theta): 0.001000\t TIME:1042.4s\n",
      "\t\t\t\tDisc: 0.012823\t\tSym: 0.000562\t\tSpars: 0.004102\n",
      "\t TVw: -0.575241 | TVb: -1.969615 | GSw: -0.454269 | GSb: -0.178987 | TSUw: 0.217381 | TSUb: 0.187176\n",
      "Validating epoch 2263...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017507083349600633\n",
      "Average validation loss: 0.017052801622565117\n",
      "Training epoch 2264...\n",
      "\n",
      "Train Epoch: 2264 [0/8000 (0%)]\tBatch Loss: 0.017318\tLearning Rate (w_theta): 0.001000\t TIME:1044.7s\n",
      "\t\t\t\tDisc: 0.012661\t\tSym: 0.000558\t\tSpars: 0.004099\n",
      "\t TVw: -0.575251 | TVb: -1.969596 | GSw: -0.454400 | GSb: -0.179156 | TSUw: 0.217226 | TSUb: 0.187163\n",
      "\n",
      "Train Epoch: 2264 [4000/8000 (50%)]\tBatch Loss: 0.017420\tLearning Rate (w_theta): 0.001000\t TIME:1046.2s\n",
      "\t\t\t\tDisc: 0.012743\t\tSym: 0.000563\t\tSpars: 0.004114\n",
      "\t TVw: -0.575293 | TVb: -1.969594 | GSw: -0.454536 | GSb: -0.179331 | TSUw: 0.217067 | TSUb: 0.187152\n",
      "Validating epoch 2264...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017489727481955358\n",
      "Average validation loss: 0.017018689417051414\n",
      "Training epoch 2265...\n",
      "\n",
      "Train Epoch: 2265 [0/8000 (0%)]\tBatch Loss: 0.017356\tLearning Rate (w_theta): 0.001000\t TIME:1048.6s\n",
      "\t\t\t\tDisc: 0.012739\t\tSym: 0.000549\t\tSpars: 0.004069\n",
      "\t TVw: -0.575299 | TVb: -1.969570 | GSw: -0.454669 | GSb: -0.179502 | TSUw: 0.216910 | TSUb: 0.187140\n",
      "\n",
      "Train Epoch: 2265 [4000/8000 (50%)]\tBatch Loss: 0.017518\tLearning Rate (w_theta): 0.001000\t TIME:1050.1s\n",
      "\t\t\t\tDisc: 0.012887\t\tSym: 0.000558\t\tSpars: 0.004073\n",
      "\t TVw: -0.575298 | TVb: -1.969536 | GSw: -0.454803 | GSb: -0.179673 | TSUw: 0.216751 | TSUb: 0.187128\n",
      "Validating epoch 2265...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017494048784416502\n",
      "Average validation loss: 0.01701369944966958\n",
      "Training epoch 2266...\n",
      "\n",
      "Train Epoch: 2266 [0/8000 (0%)]\tBatch Loss: 0.017569\tLearning Rate (w_theta): 0.001000\t TIME:1052.5s\n",
      "\t\t\t\tDisc: 0.012889\t\tSym: 0.000573\t\tSpars: 0.004108\n",
      "\t TVw: -0.575351 | TVb: -1.969544 | GSw: -0.454938 | GSb: -0.179847 | TSUw: 0.216597 | TSUb: 0.187114\n",
      "\n",
      "Train Epoch: 2266 [4000/8000 (50%)]\tBatch Loss: 0.017705\tLearning Rate (w_theta): 0.001000\t TIME:1054.0s\n",
      "\t\t\t\tDisc: 0.013036\t\tSym: 0.000573\t\tSpars: 0.004096\n",
      "\t TVw: -0.575362 | TVb: -1.969522 | GSw: -0.455070 | GSb: -0.180017 | TSUw: 0.216440 | TSUb: 0.187101\n",
      "Validating epoch 2266...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017476827982125208\n",
      "Average validation loss: 0.016992165806348457\n",
      "Training epoch 2267...\n",
      "\n",
      "Train Epoch: 2267 [0/8000 (0%)]\tBatch Loss: 0.017650\tLearning Rate (w_theta): 0.001000\t TIME:1056.3s\n",
      "\t\t\t\tDisc: 0.012994\t\tSym: 0.000561\t\tSpars: 0.004095\n",
      "\t TVw: -0.575399 | TVb: -1.969521 | GSw: -0.455204 | GSb: -0.180190 | TSUw: 0.216284 | TSUb: 0.187087\n",
      "\n",
      "Train Epoch: 2267 [4000/8000 (50%)]\tBatch Loss: 0.017541\tLearning Rate (w_theta): 0.001000\t TIME:1057.9s\n",
      "\t\t\t\tDisc: 0.012896\t\tSym: 0.000560\t\tSpars: 0.004085\n",
      "\t TVw: -0.575405 | TVb: -1.969498 | GSw: -0.455338 | GSb: -0.180362 | TSUw: 0.216126 | TSUb: 0.187075\n",
      "Validating epoch 2267...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017456884583262375\n",
      "Average validation loss: 0.016994456388956684\n",
      "Training epoch 2268...\n",
      "\n",
      "Train Epoch: 2268 [0/8000 (0%)]\tBatch Loss: 0.017736\tLearning Rate (w_theta): 0.001000\t TIME:1060.2s\n",
      "\t\t\t\tDisc: 0.013058\t\tSym: 0.000567\t\tSpars: 0.004111\n",
      "\t TVw: -0.575445 | TVb: -1.969497 | GSw: -0.455474 | GSb: -0.180538 | TSUw: 0.215968 | TSUb: 0.187061\n",
      "\n",
      "Train Epoch: 2268 [4000/8000 (50%)]\tBatch Loss: 0.017489\tLearning Rate (w_theta): 0.001000\t TIME:1061.7s\n",
      "\t\t\t\tDisc: 0.012821\t\tSym: 0.000572\t\tSpars: 0.004096\n",
      "\t TVw: -0.575445 | TVb: -1.969471 | GSw: -0.455610 | GSb: -0.180711 | TSUw: 0.215809 | TSUb: 0.187048\n",
      "Validating epoch 2268...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017443527151943396\n",
      "Average validation loss: 0.016973883846889214\n",
      "Training epoch 2269...\n",
      "\n",
      "Train Epoch: 2269 [0/8000 (0%)]\tBatch Loss: 0.017847\tLearning Rate (w_theta): 0.001000\t TIME:1064.2s\n",
      "\t\t\t\tDisc: 0.013168\t\tSym: 0.000574\t\tSpars: 0.004105\n",
      "\t TVw: -0.575444 | TVb: -1.969443 | GSw: -0.455743 | GSb: -0.180883 | TSUw: 0.215653 | TSUb: 0.187034\n",
      "\n",
      "Train Epoch: 2269 [4000/8000 (50%)]\tBatch Loss: 0.017411\tLearning Rate (w_theta): 0.001000\t TIME:1065.8s\n",
      "\t\t\t\tDisc: 0.012753\t\tSym: 0.000570\t\tSpars: 0.004087\n",
      "\t TVw: -0.575475 | TVb: -1.969437 | GSw: -0.455878 | GSb: -0.181056 | TSUw: 0.215498 | TSUb: 0.187018\n",
      "Validating epoch 2269...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017427788049100598\n",
      "Average validation loss: 0.016953997552836633\n",
      "Training epoch 2270...\n",
      "\n",
      "Train Epoch: 2270 [0/8000 (0%)]\tBatch Loss: 0.017242\tLearning Rate (w_theta): 0.001000\t TIME:1068.1s\n",
      "\t\t\t\tDisc: 0.012618\t\tSym: 0.000556\t\tSpars: 0.004067\n",
      "\t TVw: -0.575511 | TVb: -1.969434 | GSw: -0.456011 | GSb: -0.181227 | TSUw: 0.215346 | TSUb: 0.187002\n",
      "\n",
      "Train Epoch: 2270 [4000/8000 (50%)]\tBatch Loss: 0.017265\tLearning Rate (w_theta): 0.001000\t TIME:1069.6s\n",
      "\t\t\t\tDisc: 0.012599\t\tSym: 0.000566\t\tSpars: 0.004100\n",
      "\t TVw: -0.575528 | TVb: -1.969421 | GSw: -0.456144 | GSb: -0.181398 | TSUw: 0.215190 | TSUb: 0.186986\n",
      "Validating epoch 2270...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017455365592333325\n",
      "Average validation loss: 0.017039450368905883\n",
      "Training epoch 2271...\n",
      "\n",
      "Train Epoch: 2271 [0/8000 (0%)]\tBatch Loss: 0.017408\tLearning Rate (w_theta): 0.001000\t TIME:1072.6s\n",
      "\t\t\t\tDisc: 0.012814\t\tSym: 0.000554\t\tSpars: 0.004040\n",
      "\t TVw: -0.575546 | TVb: -1.969406 | GSw: -0.456279 | GSb: -0.181571 | TSUw: 0.215032 | TSUb: 0.186972\n",
      "\n",
      "Train Epoch: 2271 [4000/8000 (50%)]\tBatch Loss: 0.017923\tLearning Rate (w_theta): 0.001000\t TIME:1074.1s\n",
      "\t\t\t\tDisc: 0.013146\t\tSym: 0.000596\t\tSpars: 0.004181\n",
      "\t TVw: -0.575624 | TVb: -1.969431 | GSw: -0.456416 | GSb: -0.181747 | TSUw: 0.214874 | TSUb: 0.186957\n",
      "Validating epoch 2271...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01749860122363949\n",
      "Average validation loss: 0.017000921708274892\n",
      "Training epoch 2272...\n",
      "\n",
      "Train Epoch: 2272 [0/8000 (0%)]\tBatch Loss: 0.017641\tLearning Rate (w_theta): 0.001000\t TIME:1076.6s\n",
      "\t\t\t\tDisc: 0.012955\t\tSym: 0.000567\t\tSpars: 0.004119\n",
      "\t TVw: -0.575639 | TVb: -1.969414 | GSw: -0.456552 | GSb: -0.181921 | TSUw: 0.214711 | TSUb: 0.186945\n",
      "\n",
      "Train Epoch: 2272 [4000/8000 (50%)]\tBatch Loss: 0.017451\tLearning Rate (w_theta): 0.001000\t TIME:1078.1s\n",
      "\t\t\t\tDisc: 0.012811\t\tSym: 0.000557\t\tSpars: 0.004082\n",
      "\t TVw: -0.575648 | TVb: -1.969392 | GSw: -0.456687 | GSb: -0.182094 | TSUw: 0.214549 | TSUb: 0.186931\n",
      "Validating epoch 2272...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017457083769203248\n",
      "Average validation loss: 0.016953290885249054\n",
      "Training epoch 2273...\n",
      "\n",
      "Train Epoch: 2273 [0/8000 (0%)]\tBatch Loss: 0.017597\tLearning Rate (w_theta): 0.001000\t TIME:1080.5s\n",
      "\t\t\t\tDisc: 0.012926\t\tSym: 0.000559\t\tSpars: 0.004111\n",
      "\t TVw: -0.575668 | TVb: -1.969377 | GSw: -0.456828 | GSb: -0.182272 | TSUw: 0.214382 | TSUb: 0.186920\n",
      "\n",
      "Train Epoch: 2273 [4000/8000 (50%)]\tBatch Loss: 0.017708\tLearning Rate (w_theta): 0.001000\t TIME:1082.0s\n",
      "\t\t\t\tDisc: 0.013025\t\tSym: 0.000576\t\tSpars: 0.004107\n",
      "\t TVw: -0.575642 | TVb: -1.969334 | GSw: -0.456965 | GSb: -0.182446 | TSUw: 0.214216 | TSUb: 0.186909\n",
      "Validating epoch 2273...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017408042484304845\n",
      "Average validation loss: 0.01694954994032222\n",
      "Training epoch 2274...\n",
      "\n",
      "Train Epoch: 2274 [0/8000 (0%)]\tBatch Loss: 0.017688\tLearning Rate (w_theta): 0.001000\t TIME:1084.4s\n",
      "\t\t\t\tDisc: 0.013081\t\tSym: 0.000560\t\tSpars: 0.004047\n",
      "\t TVw: -0.575618 | TVb: -1.969295 | GSw: -0.457100 | GSb: -0.182618 | TSUw: 0.214055 | TSUb: 0.186894\n",
      "\n",
      "Train Epoch: 2274 [4000/8000 (50%)]\tBatch Loss: 0.017714\tLearning Rate (w_theta): 0.001000\t TIME:1085.9s\n",
      "\t\t\t\tDisc: 0.013089\t\tSym: 0.000569\t\tSpars: 0.004056\n",
      "\t TVw: -0.575655 | TVb: -1.969300 | GSw: -0.457237 | GSb: -0.182793 | TSUw: 0.213899 | TSUb: 0.186877\n",
      "Validating epoch 2274...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01738764637287181\n",
      "Average validation loss: 0.016916335600886578\n",
      "Training epoch 2275...\n",
      "\n",
      "Train Epoch: 2275 [0/8000 (0%)]\tBatch Loss: 0.017250\tLearning Rate (w_theta): 0.001000\t TIME:1088.3s\n",
      "\t\t\t\tDisc: 0.012622\t\tSym: 0.000562\t\tSpars: 0.004066\n",
      "\t TVw: -0.575670 | TVb: -1.969288 | GSw: -0.457372 | GSb: -0.182965 | TSUw: 0.213744 | TSUb: 0.186859\n",
      "\n",
      "Train Epoch: 2275 [4000/8000 (50%)]\tBatch Loss: 0.017407\tLearning Rate (w_theta): 0.001000\t TIME:1089.8s\n",
      "\t\t\t\tDisc: 0.012812\t\tSym: 0.000566\t\tSpars: 0.004028\n",
      "\t TVw: -0.575688 | TVb: -1.969268 | GSw: -0.457506 | GSb: -0.183138 | TSUw: 0.213591 | TSUb: 0.186840\n",
      "Validating epoch 2275...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01736830191033259\n",
      "Average validation loss: 0.016901232257969002\n",
      "Training epoch 2276...\n",
      "\n",
      "Train Epoch: 2276 [0/8000 (0%)]\tBatch Loss: 0.017515\tLearning Rate (w_theta): 0.001000\t TIME:1092.1s\n",
      "\t\t\t\tDisc: 0.012853\t\tSym: 0.000579\t\tSpars: 0.004084\n",
      "\t TVw: -0.575756 | TVb: -1.969281 | GSw: -0.457644 | GSb: -0.183315 | TSUw: 0.213437 | TSUb: 0.186822\n",
      "\n",
      "Train Epoch: 2276 [4000/8000 (50%)]\tBatch Loss: 0.017397\tLearning Rate (w_theta): 0.001000\t TIME:1093.7s\n",
      "\t\t\t\tDisc: 0.012792\t\tSym: 0.000558\t\tSpars: 0.004047\n",
      "\t TVw: -0.575789 | TVb: -1.969270 | GSw: -0.457783 | GSb: -0.183492 | TSUw: 0.213275 | TSUb: 0.186806\n",
      "Validating epoch 2276...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017357171581560804\n",
      "Average validation loss: 0.016892117957938962\n",
      "Training epoch 2277...\n",
      "\n",
      "Train Epoch: 2277 [0/8000 (0%)]\tBatch Loss: 0.017486\tLearning Rate (w_theta): 0.001000\t TIME:1096.0s\n",
      "\t\t\t\tDisc: 0.012834\t\tSym: 0.000574\t\tSpars: 0.004078\n",
      "\t TVw: -0.575830 | TVb: -1.969272 | GSw: -0.457921 | GSb: -0.183669 | TSUw: 0.213119 | TSUb: 0.186788\n",
      "\n",
      "Train Epoch: 2277 [4000/8000 (50%)]\tBatch Loss: 0.017244\tLearning Rate (w_theta): 0.001000\t TIME:1097.6s\n",
      "\t\t\t\tDisc: 0.012601\t\tSym: 0.000565\t\tSpars: 0.004079\n",
      "\t TVw: -0.575854 | TVb: -1.969265 | GSw: -0.458056 | GSb: -0.183843 | TSUw: 0.212964 | TSUb: 0.186769\n",
      "Validating epoch 2277...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017358886194020474\n",
      "Average validation loss: 0.016895106245852644\n",
      "Training epoch 2278...\n",
      "\n",
      "Train Epoch: 2278 [0/8000 (0%)]\tBatch Loss: 0.017149\tLearning Rate (w_theta): 0.001000\t TIME:1100.0s\n",
      "\t\t\t\tDisc: 0.012533\t\tSym: 0.000561\t\tSpars: 0.004055\n",
      "\t TVw: -0.575866 | TVb: -1.969248 | GSw: -0.458195 | GSb: -0.184019 | TSUw: 0.212804 | TSUb: 0.186753\n",
      "\n",
      "Train Epoch: 2278 [4000/8000 (50%)]\tBatch Loss: 0.017195\tLearning Rate (w_theta): 0.001000\t TIME:1101.6s\n",
      "\t\t\t\tDisc: 0.012573\t\tSym: 0.000563\t\tSpars: 0.004059\n",
      "\t TVw: -0.575905 | TVb: -1.969245 | GSw: -0.458337 | GSb: -0.184200 | TSUw: 0.212641 | TSUb: 0.186737\n",
      "Validating epoch 2278...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01734564208304161\n",
      "Average validation loss: 0.01693571701594404\n",
      "Training epoch 2279...\n",
      "\n",
      "Train Epoch: 2279 [0/8000 (0%)]\tBatch Loss: 0.017565\tLearning Rate (w_theta): 0.001000\t TIME:1103.9s\n",
      "\t\t\t\tDisc: 0.012959\t\tSym: 0.000568\t\tSpars: 0.004038\n",
      "\t TVw: -0.575867 | TVb: -1.969192 | GSw: -0.458472 | GSb: -0.184372 | TSUw: 0.212479 | TSUb: 0.186721\n",
      "\n",
      "Train Epoch: 2279 [4000/8000 (50%)]\tBatch Loss: 0.017062\tLearning Rate (w_theta): 0.001000\t TIME:1105.5s\n",
      "\t\t\t\tDisc: 0.012501\t\tSym: 0.000549\t\tSpars: 0.004012\n",
      "\t TVw: -0.575901 | TVb: -1.969188 | GSw: -0.458614 | GSb: -0.184550 | TSUw: 0.212315 | TSUb: 0.186705\n",
      "Validating epoch 2279...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017409693891628022\n",
      "Average validation loss: 0.01694708385743039\n",
      "Training epoch 2280...\n",
      "\n",
      "Train Epoch: 2280 [0/8000 (0%)]\tBatch Loss: 0.017146\tLearning Rate (w_theta): 0.001000\t TIME:1107.8s\n",
      "\t\t\t\tDisc: 0.012544\t\tSym: 0.000555\t\tSpars: 0.004047\n",
      "\t TVw: -0.575975 | TVb: -1.969210 | GSw: -0.458756 | GSb: -0.184730 | TSUw: 0.212153 | TSUb: 0.186689\n",
      "\n",
      "Train Epoch: 2280 [4000/8000 (50%)]\tBatch Loss: 0.017364\tLearning Rate (w_theta): 0.001000\t TIME:1109.4s\n",
      "\t\t\t\tDisc: 0.012777\t\tSym: 0.000554\t\tSpars: 0.004033\n",
      "\t TVw: -0.575941 | TVb: -1.969167 | GSw: -0.458890 | GSb: -0.184902 | TSUw: 0.211990 | TSUb: 0.186672\n",
      "Validating epoch 2280...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017397029482539905\n",
      "Average validation loss: 0.01689349098659947\n",
      "Training epoch 2281...\n",
      "\n",
      "Train Epoch: 2281 [0/8000 (0%)]\tBatch Loss: 0.017299\tLearning Rate (w_theta): 0.001000\t TIME:1112.5s\n",
      "\t\t\t\tDisc: 0.012697\t\tSym: 0.000549\t\tSpars: 0.004054\n",
      "\t TVw: -0.576024 | TVb: -1.969195 | GSw: -0.459034 | GSb: -0.185084 | TSUw: 0.211825 | TSUb: 0.186657\n",
      "\n",
      "Train Epoch: 2281 [4000/8000 (50%)]\tBatch Loss: 0.017549\tLearning Rate (w_theta): 0.001000\t TIME:1114.0s\n",
      "\t\t\t\tDisc: 0.012904\t\tSym: 0.000573\t\tSpars: 0.004071\n",
      "\t TVw: -0.576045 | TVb: -1.969175 | GSw: -0.459178 | GSb: -0.185266 | TSUw: 0.211653 | TSUb: 0.186644\n",
      "Validating epoch 2281...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01733582562169329\n",
      "Average validation loss: 0.016878543866581462\n",
      "Training epoch 2282...\n",
      "\n",
      "Train Epoch: 2282 [0/8000 (0%)]\tBatch Loss: 0.017648\tLearning Rate (w_theta): 0.001000\t TIME:1116.4s\n",
      "\t\t\t\tDisc: 0.013022\t\tSym: 0.000569\t\tSpars: 0.004056\n",
      "\t TVw: -0.576005 | TVb: -1.969124 | GSw: -0.459314 | GSb: -0.185440 | TSUw: 0.211489 | TSUb: 0.186627\n",
      "\n",
      "Train Epoch: 2282 [4000/8000 (50%)]\tBatch Loss: 0.016939\tLearning Rate (w_theta): 0.001000\t TIME:1117.9s\n",
      "\t\t\t\tDisc: 0.012428\t\tSym: 0.000537\t\tSpars: 0.003974\n",
      "\t TVw: -0.576026 | TVb: -1.969119 | GSw: -0.459459 | GSb: -0.185622 | TSUw: 0.211323 | TSUb: 0.186612\n",
      "Validating epoch 2282...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01742802357951335\n",
      "Average validation loss: 0.017146561943511412\n",
      "Training epoch 2283...\n",
      "\n",
      "Train Epoch: 2283 [0/8000 (0%)]\tBatch Loss: 0.017449\tLearning Rate (w_theta): 0.001000\t TIME:1120.2s\n",
      "\t\t\t\tDisc: 0.012830\t\tSym: 0.000574\t\tSpars: 0.004046\n",
      "\t TVw: -0.576112 | TVb: -1.969150 | GSw: -0.459611 | GSb: -0.185809 | TSUw: 0.211156 | TSUb: 0.186596\n",
      "\n",
      "Train Epoch: 2283 [4000/8000 (50%)]\tBatch Loss: 0.017861\tLearning Rate (w_theta): 0.001000\t TIME:1121.8s\n",
      "\t\t\t\tDisc: 0.013059\t\tSym: 0.000593\t\tSpars: 0.004210\n",
      "\t TVw: -0.576473 | TVb: -1.969365 | GSw: -0.459762 | GSb: -0.186000 | TSUw: 0.211010 | TSUb: 0.186570\n",
      "Validating epoch 2283...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017816041733011028\n",
      "Average validation loss: 0.017343049712405006\n",
      "Training epoch 2284...\n",
      "\n",
      "Train Epoch: 2284 [0/8000 (0%)]\tBatch Loss: 0.018055\tLearning Rate (w_theta): 0.001000\t TIME:1124.2s\n",
      "\t\t\t\tDisc: 0.013190\t\tSym: 0.000576\t\tSpars: 0.004290\n",
      "\t TVw: -0.576718 | TVb: -1.969500 | GSw: -0.459895 | GSb: -0.186174 | TSUw: 0.210867 | TSUb: 0.186542\n",
      "\n",
      "Train Epoch: 2284 [4000/8000 (50%)]\tBatch Loss: 0.017776\tLearning Rate (w_theta): 0.001000\t TIME:1125.7s\n",
      "\t\t\t\tDisc: 0.012951\t\tSym: 0.000556\t\tSpars: 0.004269\n",
      "\t TVw: -0.576953 | TVb: -1.969616 | GSw: -0.460025 | GSb: -0.186345 | TSUw: 0.210723 | TSUb: 0.186515\n",
      "Validating epoch 2284...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017763240493714114\n",
      "Average validation loss: 0.01724578128944887\n",
      "Training epoch 2285...\n",
      "\n",
      "Train Epoch: 2285 [0/8000 (0%)]\tBatch Loss: 0.017607\tLearning Rate (w_theta): 0.001000\t TIME:1128.0s\n",
      "\t\t\t\tDisc: 0.012750\t\tSym: 0.000549\t\tSpars: 0.004308\n",
      "\t TVw: -0.577189 | TVb: -1.969743 | GSw: -0.460160 | GSb: -0.186520 | TSUw: 0.210568 | TSUb: 0.186492\n",
      "\n",
      "Train Epoch: 2285 [4000/8000 (50%)]\tBatch Loss: 0.017800\tLearning Rate (w_theta): 0.001000\t TIME:1129.6s\n",
      "\t\t\t\tDisc: 0.012846\t\tSym: 0.000584\t\tSpars: 0.004371\n",
      "\t TVw: -0.577224 | TVb: -1.969729 | GSw: -0.460301 | GSb: -0.186696 | TSUw: 0.210387 | TSUb: 0.186482\n",
      "Validating epoch 2285...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017711293226638412\n",
      "Average validation loss: 0.017225248220848793\n",
      "Training epoch 2286...\n",
      "\n",
      "Train Epoch: 2286 [0/8000 (0%)]\tBatch Loss: 0.017472\tLearning Rate (w_theta): 0.001000\t TIME:1131.9s\n",
      "\t\t\t\tDisc: 0.012520\t\tSym: 0.000585\t\tSpars: 0.004366\n",
      "\t TVw: -0.577203 | TVb: -1.969687 | GSw: -0.460451 | GSb: -0.186880 | TSUw: 0.210190 | TSUb: 0.186479\n",
      "\n",
      "Train Epoch: 2286 [4000/8000 (50%)]\tBatch Loss: 0.017717\tLearning Rate (w_theta): 0.001000\t TIME:1133.4s\n",
      "\t\t\t\tDisc: 0.012849\t\tSym: 0.000563\t\tSpars: 0.004304\n",
      "\t TVw: -0.577105 | TVb: -1.969600 | GSw: -0.460601 | GSb: -0.187061 | TSUw: 0.209989 | TSUb: 0.186478\n",
      "Validating epoch 2286...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01760917743048644\n",
      "Average validation loss: 0.017090381003369667\n",
      "Training epoch 2287...\n",
      "\n",
      "Train Epoch: 2287 [0/8000 (0%)]\tBatch Loss: 0.017439\tLearning Rate (w_theta): 0.001000\t TIME:1135.9s\n",
      "\t\t\t\tDisc: 0.012680\t\tSym: 0.000554\t\tSpars: 0.004205\n",
      "\t TVw: -0.576944 | TVb: -1.969470 | GSw: -0.460752 | GSb: -0.187243 | TSUw: 0.209781 | TSUb: 0.186480\n",
      "\n",
      "Train Epoch: 2287 [4000/8000 (50%)]\tBatch Loss: 0.017077\tLearning Rate (w_theta): 0.001000\t TIME:1137.5s\n",
      "\t\t\t\tDisc: 0.012426\t\tSym: 0.000527\t\tSpars: 0.004124\n",
      "\t TVw: -0.576858 | TVb: -1.969376 | GSw: -0.460908 | GSb: -0.187430 | TSUw: 0.209579 | TSUb: 0.186479\n",
      "Validating epoch 2287...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01747727191619416\n",
      "Average validation loss: 0.016975548290968243\n",
      "Training epoch 2288...\n",
      "\n",
      "Train Epoch: 2288 [0/8000 (0%)]\tBatch Loss: 0.017739\tLearning Rate (w_theta): 0.001000\t TIME:1139.8s\n",
      "\t\t\t\tDisc: 0.012985\t\tSym: 0.000575\t\tSpars: 0.004179\n",
      "\t TVw: -0.576793 | TVb: -1.969300 | GSw: -0.461058 | GSb: -0.187614 | TSUw: 0.209388 | TSUb: 0.186472\n",
      "\n",
      "Train Epoch: 2288 [4000/8000 (50%)]\tBatch Loss: 0.016799\tLearning Rate (w_theta): 0.001000\t TIME:1141.3s\n",
      "\t\t\t\tDisc: 0.012191\t\tSym: 0.000540\t\tSpars: 0.004069\n",
      "\t TVw: -0.576715 | TVb: -1.969222 | GSw: -0.461197 | GSb: -0.187786 | TSUw: 0.209212 | TSUb: 0.186458\n",
      "Validating epoch 2288...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01737093642979715\n",
      "Average validation loss: 0.016893576204875173\n",
      "Training epoch 2289...\n",
      "\n",
      "Train Epoch: 2289 [0/8000 (0%)]\tBatch Loss: 0.017172\tLearning Rate (w_theta): 0.001000\t TIME:1143.7s\n",
      "\t\t\t\tDisc: 0.012546\t\tSym: 0.000557\t\tSpars: 0.004069\n",
      "\t TVw: -0.576722 | TVb: -1.969193 | GSw: -0.461341 | GSb: -0.187967 | TSUw: 0.209043 | TSUb: 0.186441\n",
      "\n",
      "Train Epoch: 2289 [4000/8000 (50%)]\tBatch Loss: 0.017201\tLearning Rate (w_theta): 0.001000\t TIME:1145.2s\n",
      "\t\t\t\tDisc: 0.012550\t\tSym: 0.000564\t\tSpars: 0.004088\n",
      "\t TVw: -0.576691 | TVb: -1.969143 | GSw: -0.461480 | GSb: -0.188141 | TSUw: 0.208878 | TSUb: 0.186421\n",
      "Validating epoch 2289...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01729025002541659\n",
      "Average validation loss: 0.016828798787150583\n",
      "Training epoch 2290...\n",
      "\n",
      "Train Epoch: 2290 [0/8000 (0%)]\tBatch Loss: 0.017346\tLearning Rate (w_theta): 0.001000\t TIME:1147.6s\n",
      "\t\t\t\tDisc: 0.012771\t\tSym: 0.000549\t\tSpars: 0.004026\n",
      "\t TVw: -0.576658 | TVb: -1.969086 | GSw: -0.461619 | GSb: -0.188316 | TSUw: 0.208713 | TSUb: 0.186402\n",
      "\n",
      "Train Epoch: 2290 [4000/8000 (50%)]\tBatch Loss: 0.017149\tLearning Rate (w_theta): 0.001000\t TIME:1149.1s\n",
      "\t\t\t\tDisc: 0.012541\t\tSym: 0.000561\t\tSpars: 0.004046\n",
      "\t TVw: -0.576684 | TVb: -1.969064 | GSw: -0.461763 | GSb: -0.188498 | TSUw: 0.208548 | TSUb: 0.186381\n",
      "Validating epoch 2290...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01723866420599909\n",
      "Average validation loss: 0.01676511873358345\n",
      "Training epoch 2291...\n",
      "\n",
      "Train Epoch: 2291 [0/8000 (0%)]\tBatch Loss: 0.017059\tLearning Rate (w_theta): 0.001000\t TIME:1152.2s\n",
      "\t\t\t\tDisc: 0.012475\t\tSym: 0.000557\t\tSpars: 0.004027\n",
      "\t TVw: -0.576665 | TVb: -1.969021 | GSw: -0.461903 | GSb: -0.188674 | TSUw: 0.208385 | TSUb: 0.186360\n",
      "\n",
      "Train Epoch: 2291 [4000/8000 (50%)]\tBatch Loss: 0.017032\tLearning Rate (w_theta): 0.001000\t TIME:1153.7s\n",
      "\t\t\t\tDisc: 0.012556\t\tSym: 0.000526\t\tSpars: 0.003950\n",
      "\t TVw: -0.576612 | TVb: -1.968953 | GSw: -0.462039 | GSb: -0.188847 | TSUw: 0.208222 | TSUb: 0.186338\n",
      "Validating epoch 2291...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0172108530023862\n",
      "Average validation loss: 0.016757718100065096\n",
      "Training epoch 2292...\n",
      "\n",
      "Train Epoch: 2292 [0/8000 (0%)]\tBatch Loss: 0.017586\tLearning Rate (w_theta): 0.001000\t TIME:1156.0s\n",
      "\t\t\t\tDisc: 0.012933\t\tSym: 0.000580\t\tSpars: 0.004073\n",
      "\t TVw: -0.576659 | TVb: -1.968952 | GSw: -0.462183 | GSb: -0.189028 | TSUw: 0.208062 | TSUb: 0.186315\n",
      "\n",
      "Train Epoch: 2292 [4000/8000 (50%)]\tBatch Loss: 0.016569\tLearning Rate (w_theta): 0.001000\t TIME:1157.5s\n",
      "\t\t\t\tDisc: 0.012091\t\tSym: 0.000521\t\tSpars: 0.003956\n",
      "\t TVw: -0.576674 | TVb: -1.968935 | GSw: -0.462322 | GSb: -0.189205 | TSUw: 0.207905 | TSUb: 0.186290\n",
      "Validating epoch 2292...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017204743864484298\n",
      "Average validation loss: 0.016768026445522936\n",
      "Training epoch 2293...\n",
      "\n",
      "Train Epoch: 2293 [0/8000 (0%)]\tBatch Loss: 0.017637\tLearning Rate (w_theta): 0.001000\t TIME:1159.9s\n",
      "\t\t\t\tDisc: 0.013054\t\tSym: 0.000567\t\tSpars: 0.004017\n",
      "\t TVw: -0.576638 | TVb: -1.968885 | GSw: -0.462455 | GSb: -0.189376 | TSUw: 0.207749 | TSUb: 0.186264\n",
      "\n",
      "Train Epoch: 2293 [4000/8000 (50%)]\tBatch Loss: 0.016976\tLearning Rate (w_theta): 0.001000\t TIME:1161.5s\n",
      "\t\t\t\tDisc: 0.012465\t\tSym: 0.000545\t\tSpars: 0.003966\n",
      "\t TVw: -0.576705 | TVb: -1.968896 | GSw: -0.462597 | GSb: -0.189556 | TSUw: 0.207590 | TSUb: 0.186239\n",
      "Validating epoch 2293...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017205126439875686\n",
      "Average validation loss: 0.016746121899953368\n",
      "Training epoch 2294...\n",
      "\n",
      "Train Epoch: 2294 [0/8000 (0%)]\tBatch Loss: 0.017171\tLearning Rate (w_theta): 0.001000\t TIME:1163.9s\n",
      "\t\t\t\tDisc: 0.012586\t\tSym: 0.000560\t\tSpars: 0.004026\n",
      "\t TVw: -0.576774 | TVb: -1.968915 | GSw: -0.462737 | GSb: -0.189734 | TSUw: 0.207436 | TSUb: 0.186212\n",
      "\n",
      "Train Epoch: 2294 [4000/8000 (50%)]\tBatch Loss: 0.017554\tLearning Rate (w_theta): 0.001000\t TIME:1165.5s\n",
      "\t\t\t\tDisc: 0.012970\t\tSym: 0.000571\t\tSpars: 0.004013\n",
      "\t TVw: -0.576736 | TVb: -1.968866 | GSw: -0.462868 | GSb: -0.189903 | TSUw: 0.207279 | TSUb: 0.186186\n",
      "Validating epoch 2294...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017189611168057856\n",
      "Average validation loss: 0.01678067816088315\n",
      "Training epoch 2295...\n",
      "\n",
      "Train Epoch: 2295 [0/8000 (0%)]\tBatch Loss: 0.017158\tLearning Rate (w_theta): 0.001000\t TIME:1167.9s\n",
      "\t\t\t\tDisc: 0.012661\t\tSym: 0.000540\t\tSpars: 0.003957\n",
      "\t TVw: -0.576778 | TVb: -1.968865 | GSw: -0.463009 | GSb: -0.190081 | TSUw: 0.207124 | TSUb: 0.186159\n",
      "\n",
      "Train Epoch: 2295 [4000/8000 (50%)]\tBatch Loss: 0.017430\tLearning Rate (w_theta): 0.001000\t TIME:1169.4s\n",
      "\t\t\t\tDisc: 0.012850\t\tSym: 0.000564\t\tSpars: 0.004017\n",
      "\t TVw: -0.576783 | TVb: -1.968842 | GSw: -0.463151 | GSb: -0.190260 | TSUw: 0.206965 | TSUb: 0.186134\n",
      "Validating epoch 2295...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017189733601557133\n",
      "Average validation loss: 0.016754313924822222\n",
      "Training epoch 2296...\n",
      "\n",
      "Train Epoch: 2296 [0/8000 (0%)]\tBatch Loss: 0.017193\tLearning Rate (w_theta): 0.001000\t TIME:1171.9s\n",
      "\t\t\t\tDisc: 0.012661\t\tSym: 0.000556\t\tSpars: 0.003976\n",
      "\t TVw: -0.576809 | TVb: -1.968832 | GSw: -0.463291 | GSb: -0.190437 | TSUw: 0.206808 | TSUb: 0.186107\n",
      "\n",
      "Train Epoch: 2296 [4000/8000 (50%)]\tBatch Loss: 0.017121\tLearning Rate (w_theta): 0.001000\t TIME:1173.4s\n",
      "\t\t\t\tDisc: 0.012512\t\tSym: 0.000576\t\tSpars: 0.004032\n",
      "\t TVw: -0.576890 | TVb: -1.968853 | GSw: -0.463430 | GSb: -0.190615 | TSUw: 0.206659 | TSUb: 0.186077\n",
      "Validating epoch 2296...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017204979918963716\n",
      "Average validation loss: 0.016746815318543645\n",
      "Training epoch 2297...\n",
      "\n",
      "Train Epoch: 2297 [0/8000 (0%)]\tBatch Loss: 0.016812\tLearning Rate (w_theta): 0.001000\t TIME:1175.8s\n",
      "\t\t\t\tDisc: 0.012297\t\tSym: 0.000541\t\tSpars: 0.003974\n",
      "\t TVw: -0.576938 | TVb: -1.968855 | GSw: -0.463569 | GSb: -0.190792 | TSUw: 0.206505 | TSUb: 0.186048\n",
      "\n",
      "Train Epoch: 2297 [4000/8000 (50%)]\tBatch Loss: 0.017125\tLearning Rate (w_theta): 0.001000\t TIME:1177.3s\n",
      "\t\t\t\tDisc: 0.012541\t\tSym: 0.000560\t\tSpars: 0.004024\n",
      "\t TVw: -0.576970 | TVb: -1.968849 | GSw: -0.463707 | GSb: -0.190968 | TSUw: 0.206348 | TSUb: 0.186021\n",
      "Validating epoch 2297...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01718074661967187\n",
      "Average validation loss: 0.0167174566864472\n",
      "Training epoch 2298...\n",
      "\n",
      "Train Epoch: 2298 [0/8000 (0%)]\tBatch Loss: 0.017094\tLearning Rate (w_theta): 0.001000\t TIME:1179.7s\n",
      "\t\t\t\tDisc: 0.012512\t\tSym: 0.000564\t\tSpars: 0.004019\n",
      "\t TVw: -0.576999 | TVb: -1.968837 | GSw: -0.463850 | GSb: -0.191148 | TSUw: 0.206187 | TSUb: 0.185995\n",
      "\n",
      "Train Epoch: 2298 [4000/8000 (50%)]\tBatch Loss: 0.017535\tLearning Rate (w_theta): 0.001000\t TIME:1181.2s\n",
      "\t\t\t\tDisc: 0.012921\t\tSym: 0.000574\t\tSpars: 0.004040\n",
      "\t TVw: -0.577005 | TVb: -1.968814 | GSw: -0.463992 | GSb: -0.191327 | TSUw: 0.206026 | TSUb: 0.185969\n",
      "Validating epoch 2298...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017148159775356667\n",
      "Average validation loss: 0.016679814399686847\n",
      "Training epoch 2299...\n",
      "\n",
      "Train Epoch: 2299 [0/8000 (0%)]\tBatch Loss: 0.016756\tLearning Rate (w_theta): 0.001000\t TIME:1183.5s\n",
      "\t\t\t\tDisc: 0.012254\t\tSym: 0.000550\t\tSpars: 0.003951\n",
      "\t TVw: -0.576984 | TVb: -1.968767 | GSw: -0.464137 | GSb: -0.191509 | TSUw: 0.205857 | TSUb: 0.185947\n",
      "\n",
      "Train Epoch: 2299 [4000/8000 (50%)]\tBatch Loss: 0.017231\tLearning Rate (w_theta): 0.001000\t TIME:1185.1s\n",
      "\t\t\t\tDisc: 0.012703\t\tSym: 0.000559\t\tSpars: 0.003969\n",
      "\t TVw: -0.576987 | TVb: -1.968734 | GSw: -0.464285 | GSb: -0.191693 | TSUw: 0.205686 | TSUb: 0.185925\n",
      "Validating epoch 2299...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017135088960692164\n",
      "Average validation loss: 0.016671490214020708\n",
      "Training epoch 2300...\n",
      "\n",
      "Train Epoch: 2300 [0/8000 (0%)]\tBatch Loss: 0.016799\tLearning Rate (w_theta): 0.001000\t TIME:1187.4s\n",
      "\t\t\t\tDisc: 0.012329\t\tSym: 0.000545\t\tSpars: 0.003925\n",
      "\t TVw: -0.577009 | TVb: -1.968717 | GSw: -0.464429 | GSb: -0.191875 | TSUw: 0.205523 | TSUb: 0.185899\n",
      "\n",
      "Train Epoch: 2300 [4000/8000 (50%)]\tBatch Loss: 0.017070\tLearning Rate (w_theta): 0.001000\t TIME:1189.0s\n",
      "\t\t\t\tDisc: 0.012556\t\tSym: 0.000560\t\tSpars: 0.003954\n",
      "\t TVw: -0.577034 | TVb: -1.968701 | GSw: -0.464574 | GSb: -0.192058 | TSUw: 0.205357 | TSUb: 0.185874\n",
      "Validating epoch 2300...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.017119773892372167\n",
      "Average validation loss: 0.0166543868789821\n",
      "Training epoch 2301...\n",
      "\n",
      "Train Epoch: 2301 [0/8000 (0%)]\tBatch Loss: 0.017040\tLearning Rate (w_theta): 0.001000\t TIME:1192.2s\n",
      "\t\t\t\tDisc: 0.012536\t\tSym: 0.000551\t\tSpars: 0.003953\n",
      "\t TVw: -0.577084 | TVb: -1.968704 | GSw: -0.464719 | GSb: -0.192240 | TSUw: 0.205198 | TSUb: 0.185846\n",
      "\n",
      "Train Epoch: 2301 [4000/8000 (50%)]\tBatch Loss: 0.016968\tLearning Rate (w_theta): 0.001000\t TIME:1193.8s\n",
      "\t\t\t\tDisc: 0.012489\t\tSym: 0.000547\t\tSpars: 0.003932\n",
      "\t TVw: -0.577089 | TVb: -1.968678 | GSw: -0.464862 | GSb: -0.192421 | TSUw: 0.205037 | TSUb: 0.185819\n",
      "Validating epoch 2301...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\galiger.gergo\\AppData\\Local\\Temp\\ipykernel_14380\\3719546261.py\", line 1, in <module>\n",
      "    solver.train()\n",
      "  File \"C:\\Users\\galiger.gergo\\Desktop\\ecg-denoising\\workspace\\src\\fistanet\\solver.py\", line 359, in train\n",
      "    plot_loss_curves(self.all_avg_train_losses, self.all_avg_val_losses, self.save_path, 'train_val_losses_ep0.png')\n",
      "  File \"C:\\Users\\galiger.gergo\\Desktop\\ecg-denoising\\workspace\\src\\fistanet\\solver.py\", line 34, in plot_loss_curves\n",
      "    plt.savefig(pjoin(save_path, 'plots', 'losses', file_name))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\", line 979, in savefig\n",
      "    res = fig.savefig(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py\", line 3046, in savefig\n",
      "    self.canvas.print_figure(fname, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\", line 2319, in print_figure\n",
      "    result = print_method(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\", line 1648, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\_api\\deprecation.py\", line 415, in wrapper\n",
      "    return func(*inner_args, **inner_kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\", line 540, in print_png\n",
      "    FigureCanvasAgg.draw(self)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\", line 436, in draw\n",
      "    self.figure.draw(self.renderer)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 73, in draw_wrapper\n",
      "    result = draw(artist, renderer, *args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 50, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py\", line 2837, in draw\n",
      "    mimage._draw_list_compositing_images(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\", line 132, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 50, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\", line 3091, in draw\n",
      "    mimage._draw_list_compositing_images(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\", line 132, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 50, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\", line 1158, in draw\n",
      "    ticks_to_draw = self._update_ticks()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\", line 1053, in _update_ticks\n",
      "    minor_locs = self.get_minorticklocs()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\", line 1282, in get_minorticklocs\n",
      "    major_locs = self.major.locator()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\ticker.py\", line 2115, in __call__\n",
      "    return self.tick_values(vmin, vmax)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\ticker.py\", line 2123, in tick_values\n",
      "    locs = self._raw_ticks(vmin, vmax)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\ticker.py\", line 2062, in _raw_ticks\n",
      "    nbins = np.clip(self.axis.get_tick_space(),\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\", line 2524, in get_tick_space\n",
      "    ends = ends.transformed(self.axes.transAxes -\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\", line 492, in transformed\n",
      "    ll, ul, lr = transform.transform(np.array(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\", line 1503, in transform\n",
      "    res = self.transform_affine(self.transform_non_affine(values))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\", line 2419, in transform_affine\n",
      "    return self.get_affine().transform(points)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\", line 2446, in get_affine\n",
      "    return Affine2D(np.dot(self._b.get_affine().get_matrix(),\n",
      "  File \"<__array_function__ internals>\", line 5, in dot\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1543, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1501, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 752, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 721, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 706, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\galiger.gergo\\AppData\\Local\\Temp\\ipykernel_14380\\3719546261.py\", line 1, in <module>\n",
      "    solver.train()\n",
      "  File \"C:\\Users\\galiger.gergo\\Desktop\\ecg-denoising\\workspace\\src\\fistanet\\solver.py\", line 359, in train\n",
      "    plot_loss_curves(self.all_avg_train_losses, self.all_avg_val_losses, self.save_path, 'train_val_losses_ep0.png')\n",
      "  File \"C:\\Users\\galiger.gergo\\Desktop\\ecg-denoising\\workspace\\src\\fistanet\\solver.py\", line 34, in plot_loss_curves\n",
      "    plt.savefig(pjoin(save_path, 'plots', 'losses', file_name))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\", line 979, in savefig\n",
      "    res = fig.savefig(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py\", line 3046, in savefig\n",
      "    self.canvas.print_figure(fname, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\", line 2319, in print_figure\n",
      "    result = print_method(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\", line 1648, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\_api\\deprecation.py\", line 415, in wrapper\n",
      "    return func(*inner_args, **inner_kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\", line 540, in print_png\n",
      "    FigureCanvasAgg.draw(self)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\", line 436, in draw\n",
      "    self.figure.draw(self.renderer)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 73, in draw_wrapper\n",
      "    result = draw(artist, renderer, *args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 50, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py\", line 2837, in draw\n",
      "    mimage._draw_list_compositing_images(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\", line 132, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 50, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\", line 3091, in draw\n",
      "    mimage._draw_list_compositing_images(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\", line 132, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 50, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\", line 1158, in draw\n",
      "    ticks_to_draw = self._update_ticks()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\", line 1053, in _update_ticks\n",
      "    minor_locs = self.get_minorticklocs()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\", line 1282, in get_minorticklocs\n",
      "    major_locs = self.major.locator()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\ticker.py\", line 2115, in __call__\n",
      "    return self.tick_values(vmin, vmax)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\ticker.py\", line 2123, in tick_values\n",
      "    locs = self._raw_ticks(vmin, vmax)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\ticker.py\", line 2062, in _raw_ticks\n",
      "    nbins = np.clip(self.axis.get_tick_space(),\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\", line 2524, in get_tick_space\n",
      "    ends = ends.transformed(self.axes.transAxes -\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\", line 492, in transformed\n",
      "    ll, ul, lr = transform.transform(np.array(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\", line 1503, in transform\n",
      "    res = self.transform_affine(self.transform_non_affine(values))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\", line 2419, in transform_affine\n",
      "    return self.get_affine().transform(points)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\", line 2446, in get_affine\n",
      "    return Affine2D(np.dot(self._b.get_affine().get_matrix(),\n",
      "  File \"<__array_function__ internals>\", line 5, in dot\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2079, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1543, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1501, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 755, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\ntpath.py\", line 647, in realpath\n",
      "    path = _getfinalpathname(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14380\\3719546261.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\ecg-denoising\\workspace\\src\\fistanet\\solver.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mplot_loss_curves\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_avg_train_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_avg_val_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train_val_losses_ep0.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\ecg-denoising\\workspace\\src\\fistanet\\solver.py\u001b[0m in \u001b[0;36mplot_loss_curves\u001b[1;34m(train_losses, val_losses, save_path, file_name)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Train Loss (MSE+Spa)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Validation Loss (MSE+Spa)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'plots'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'losses'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 979\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    980\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[0;32m   3045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3046\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3047\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2318\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2319\u001b[1;33m                     result = print_method(\n\u001b[0m\u001b[0;32m   2320\u001b[0m                         \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1648\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\_api\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[0;32m    414\u001b[0m                 **kwargs)\n\u001b[1;32m--> 415\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs, *args)\u001b[0m\n\u001b[0;32m    539\u001b[0m         \"\"\"\n\u001b[1;32m--> 540\u001b[1;33m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    541\u001b[0m         mpl.image.imsave(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    435\u001b[0m               else nullcontext()):\n\u001b[1;32m--> 436\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m             \u001b[1;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rasterizing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   2836\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2837\u001b[1;33m             mimage._draw_list_compositing_images(\n\u001b[0m\u001b[0;32m   2838\u001b[0m                 renderer, self, artists, self.suppressComposite)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3091\u001b[1;33m         mimage._draw_list_compositing_images(\n\u001b[0m\u001b[0;32m   3092\u001b[0m             renderer, self, artists, self.figure.suppressComposite)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1158\u001b[1;33m         \u001b[0mticks_to_draw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1159\u001b[0m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36m_update_ticks\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1052\u001b[0m             \u001b[0mtick\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_label2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1053\u001b[1;33m         \u001b[0mminor_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_minorticklocs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1054\u001b[0m         \u001b[0mminor_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_ticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminor_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36mget_minorticklocs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1281\u001b[0m         \u001b[1;31m# Remove minor ticks duplicating major ticks.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1282\u001b[1;33m         \u001b[0mmajor_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1283\u001b[0m         \u001b[0mminor_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\ticker.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2114\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_view_interval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2115\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtick_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\ticker.py\u001b[0m in \u001b[0;36mtick_values\u001b[1;34m(self, vmin, vmax)\u001b[0m\n\u001b[0;32m   2122\u001b[0m             vmin, vmax, expander=1e-13, tiny=1e-14)\n\u001b[1;32m-> 2123\u001b[1;33m         \u001b[0mlocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raw_ticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\ticker.py\u001b[0m in \u001b[0;36m_raw_ticks\u001b[1;34m(self, vmin, vmax)\u001b[0m\n\u001b[0;32m   2061\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2062\u001b[1;33m                 nbins = np.clip(self.axis.get_tick_space(),\n\u001b[0m\u001b[0;32m   2063\u001b[0m                                 max(1, self._min_n_ticks - 1), 9)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36mget_tick_space\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2523\u001b[0m         \u001b[0mends\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_bounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2524\u001b[1;33m         ends = ends.transformed(self.axes.transAxes -\n\u001b[0m\u001b[0;32m   2525\u001b[0m                                 self.figure.dpi_scale_trans)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36mtransformed\u001b[1;34m(self, transform)\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[0mpts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_points\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m         ll, ul, lr = transform.transform(np.array(\n\u001b[0m\u001b[0;32m    493\u001b[0m             [pts[0], [pts[0, 0], pts[1, 1]], [pts[1, 0], pts[0, 1]]]))\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, values)\u001b[0m\n\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Transform the values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1503\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_affine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_non_affine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36mtransform_affine\u001b[1;34m(self, points)\u001b[0m\n\u001b[0;32m   2418\u001b[0m         \u001b[1;31m# docstring inherited\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2419\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_affine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36mget_affine\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2445\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2446\u001b[1;33m             return Affine2D(np.dot(self._b.get_affine().get_matrix(),\n\u001b[0m\u001b[0;32m   2447\u001b[0m                                    self._a.get_affine().get_matrix()))\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2076\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2077\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2078\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[1;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[0;32m   3376\u001b[0m                         \u001b[0masy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3377\u001b[1;33m                     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0masync_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0masy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3378\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2078\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2079\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2080\u001b[0m                                             value, tb, tb_offset=tb_offset)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1125\u001b[0m                                                                tb_offset)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2076\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2077\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2078\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TypeError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\u001b[0m in \u001b[0;36m_pseudo_sync_runner\u001b[1;34m(coro)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[0mcoro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_async\u001b[1;34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple)\u001b[0m\n\u001b[0;32m   3183\u001b[0m                     \u001b[0minteractivity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'async'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3185\u001b[1;33m                 has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n\u001b[0m\u001b[0;32m   3186\u001b[0m                        interactivity=interactivity, compiler=compiler, result=result)\n\u001b[0;32m   3187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[1;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[0;32m   3394\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3395\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_before_exec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3396\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3397\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2077\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2078\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2079\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2080\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m             )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1140\u001b[0m         \u001b[0mchained_exc_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1142\u001b[1;33m             formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n\u001b[0m\u001b[0;32m   1143\u001b[0m                                                                      chained_exceptions_tb_offset)\n\u001b[0;32m   1144\u001b[0m             \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504e485-5480-4fae-a0e1-4382092f3fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a993b5-8bff-4192-8e0a-389d302c2c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2186b40-3acc-4d32-9620-ae8dac4a8731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ecgenv)",
   "language": "python",
   "name": "ecgenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
