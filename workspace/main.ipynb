{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7baaefd-888e-4894-9776-d7291899f1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.fistanet.M5FISTANet import FISTANet\n",
    "from src.fistanet.loader import DataSplit\n",
    "from src.fistanet.solver import Solver\n",
    "from os.path import join as pjoin\n",
    "from torchsummary import summary\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9846d1b1-46fe-471c-b4a9-93e7a8ce0ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data'\n",
    "DATA_FILE_GEN = 'generated/BW_master_10000_2024-04-07-12-43-32.pkl'\n",
    "DATA_FILE_SIGS = 'steinbrinker/testing_data_mvg_avg.npy'\n",
    "DATA_FILE_BW = 'mit-bih/bw'\n",
    "DATA_FILE_BPDN = 'generated/BW_alphas-BPDN_10000_2024-04-07-12-43-32.npy'\n",
    "DICT_FILE_BW = 'steinbrinker/dictionary_BW_real_data.npy'\n",
    "DATA_SIZE = 10000\n",
    "BATCH_SIZE = 1000\n",
    "TVT_SPLIT = {\n",
    "    'train': 80,\n",
    "    'valid': 10,\n",
    "    'test': 10\n",
    "}\n",
    "\n",
    "FNET_LAYER_NO = 4\n",
    "FNET_FEATURE_NO = 16\n",
    "LAMBDA_SP_LOSS = 1e-2\n",
    "\n",
    "EPOCH_NO = 1000\n",
    "START_EPOCH = 0\n",
    "TEST_EPOCH = 1001\n",
    "LR_DEC_AFTER = 1000\n",
    "LR_DEC_EVERY = 10\n",
    "LOG_INTERVAL = 4\n",
    "LEARNING_RATE = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74e188c4-1bdd-43bd-8fad-aa3c615aefbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ldr, val_ldr, tst_ldr = DataSplit(DATA_DIR, DATA_FILE_GEN, DATA_FILE_SIGS, DATA_FILE_BW, DATA_FILE_BPDN, TVT_SPLIT, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45bcd124-d0c4-4140-8607-2ed4ff8a8003",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36276fd7-c4b4-49e2-859c-6d09d87aae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Psi = np.load(pjoin(DATA_DIR, DICT_FILE_BW))\n",
    "Psi = torch.from_numpy(Psi)\n",
    "Psi = Psi.clone().detach().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03f7f9ea-e218-4790-84e8-caf0a10489d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fista_net = FISTANet(FNET_LAYER_NO, FNET_FEATURE_NO)\n",
    "fista_net = fista_net.to(device)# define arguments of fista_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f12c4823-35ea-41b9-97a1-bf6746dc204d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters fista net: 18871\n"
     ]
    }
   ],
   "source": [
    "# summary(fista_net, input_size=(1, 64, 298), device=str(device))\n",
    "print('Total number of parameters fista net:',\n",
    "          sum(p.numel() for p in fista_net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3579c675-faba-4918-bffe-7a3ee0c8afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "args = {\n",
    "    'model_name': 'FISTANet',\n",
    "    'num_epochs': EPOCH_NO,\n",
    "    'lr': LEARNING_RATE,\n",
    "    'data_dir': DATA_DIR,\n",
    "    'save_path': f'./runs/{dt}',\n",
    "    'start_epoch': START_EPOCH,\n",
    "    'multi_gpu': False,\n",
    "    'device': device,\n",
    "    'log_interval': LOG_INTERVAL,\n",
    "    'test_epoch': TEST_EPOCH,\n",
    "    'lr_dec_after': LR_DEC_AFTER,\n",
    "    'lr_dec_every': LR_DEC_EVERY,\n",
    "    'lambda_sp_loss': LAMBDA_SP_LOSS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37c787d6-372b-4189-b428-133486557995",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Solver(fista_net, Psi, trn_ldr, val_ldr, BATCH_SIZE, args, tst_ldr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dba58ed-bcde-4a91-994f-1b69c8decd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 1...\n",
      "\n",
      "Train Epoch: 1 [0/8000 (0%)]\tBatch Loss: 3834810.501187\tLearning Rate (w_theta): 0.000500\t TIME:2.5s\n",
      "\t\t\t\tDisc: 3834810.314863\t\tSpars: 0.186324\n",
      "\t TVw: -0.499000 | TVb: -1.999000 | GSw: -0.201000 | GSb: 0.099000 | TSUw: 0.499000 | TSUb: 0.001000\n",
      "\n",
      "Train Epoch: 1 [4000/8000 (50%)]\tBatch Loss: 3710654.421245\tLearning Rate (w_theta): 0.000500\t TIME:4.0s\n",
      "\t\t\t\tDisc: 3710654.258343\t\tSpars: 0.162902\n",
      "\t TVw: -0.496085 | TVb: -1.996202 | GSw: -0.205002 | GSb: 0.094998 | TSUw: 0.494998 | TSUb: 0.005002\n",
      "Validating epoch 1...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 4170957.5297497045\n",
      "Average validation loss: 3226582.7631571935\n",
      "Training epoch 2...\n",
      "\n",
      "Train Epoch: 2 [0/8000 (0%)]\tBatch Loss: 3723616.561829\tLearning Rate (w_theta): 0.000500\t TIME:5.9s\n",
      "\t\t\t\tDisc: 3723616.375653\t\tSpars: 0.186176\n",
      "\t TVw: -0.497391 | TVb: -1.998111 | GSw: -0.208972 | GSb: 0.091029 | TSUw: 0.491026 | TSUb: 0.008969\n",
      "\n",
      "Train Epoch: 2 [4000/8000 (50%)]\tBatch Loss: 3891223.414980\tLearning Rate (w_theta): 0.000500\t TIME:7.4s\n",
      "\t\t\t\tDisc: 3891223.195821\t\tSpars: 0.219159\n",
      "\t TVw: -0.500743 | TVb: -2.001664 | GSw: -0.212890 | GSb: 0.087110 | TSUw: 0.487103 | TSUb: 0.012883\n",
      "Validating epoch 2...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3656801.6911239866\n",
      "Average validation loss: 2815748.4796432164\n",
      "Training epoch 3...\n",
      "\n",
      "Train Epoch: 3 [0/8000 (0%)]\tBatch Loss: 3828539.472353\tLearning Rate (w_theta): 0.000500\t TIME:9.3s\n",
      "\t\t\t\tDisc: 3828539.192612\t\tSpars: 0.279742\n",
      "\t TVw: -0.504790 | TVb: -2.005773 | GSw: -0.216779 | GSb: 0.083222 | TSUw: 0.483205 | TSUb: 0.016762\n",
      "\n",
      "Train Epoch: 3 [4000/8000 (50%)]\tBatch Loss: 3163003.483425\tLearning Rate (w_theta): 0.000500\t TIME:10.8s\n",
      "\t\t\t\tDisc: 3163003.136632\t\tSpars: 0.346793\n",
      "\t TVw: -0.509233 | TVb: -2.010231 | GSw: -0.220566 | GSb: 0.079435 | TSUw: 0.479404 | TSUb: 0.020534\n",
      "Validating epoch 3...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 3164691.458711575\n",
      "Average validation loss: 2381482.2050627465\n",
      "Training epoch 4...\n",
      "\n",
      "Train Epoch: 4 [0/8000 (0%)]\tBatch Loss: 3376178.723377\tLearning Rate (w_theta): 0.000500\t TIME:12.6s\n",
      "\t\t\t\tDisc: 3376178.242136\t\tSpars: 0.481241\n",
      "\t TVw: -0.513984 | TVb: -2.014984 | GSw: -0.224258 | GSb: 0.075743 | TSUw: 0.475693 | TSUb: 0.024206\n",
      "\n",
      "Train Epoch: 4 [4000/8000 (50%)]\tBatch Loss: 2326376.851470\tLearning Rate (w_theta): 0.000500\t TIME:14.1s\n",
      "\t\t\t\tDisc: 2326376.285002\t\tSpars: 0.566469\n",
      "\t TVw: -0.519006 | TVb: -2.020002 | GSw: -0.227807 | GSb: 0.072193 | TSUw: 0.472120 | TSUb: 0.027728\n",
      "Validating epoch 4...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 2561163.19851453\n",
      "Average validation loss: 1735586.9839903982\n",
      "Training epoch 5...\n",
      "\n",
      "Train Epoch: 5 [0/8000 (0%)]\tBatch Loss: 1973650.831475\tLearning Rate (w_theta): 0.000500\t TIME:16.0s\n",
      "\t\t\t\tDisc: 1973650.065931\t\tSpars: 0.765544\n",
      "\t TVw: -0.524289 | TVb: -2.025276 | GSw: -0.231162 | GSb: 0.068838 | TSUw: 0.468735 | TSUb: 0.031051\n",
      "\n",
      "Train Epoch: 5 [4000/8000 (50%)]\tBatch Loss: 1415803.097578\tLearning Rate (w_theta): 0.000500\t TIME:17.4s\n",
      "\t\t\t\tDisc: 1415802.154332\t\tSpars: 0.943246\n",
      "\t TVw: -0.529790 | TVb: -2.030748 | GSw: -0.234217 | GSb: 0.065782 | TSUw: 0.465647 | TSUb: 0.034070\n",
      "Validating epoch 5...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1509751.692519612\n",
      "Average validation loss: 602872.2532050175\n",
      "Training epoch 6...\n",
      "\n",
      "Train Epoch: 6 [0/8000 (0%)]\tBatch Loss: 764956.223770\tLearning Rate (w_theta): 0.000500\t TIME:19.4s\n",
      "\t\t\t\tDisc: 764955.117266\t\tSpars: 1.106504\n",
      "\t TVw: -0.535420 | TVb: -2.036329 | GSw: -0.236866 | GSb: 0.063131 | TSUw: 0.462962 | TSUb: 0.036682\n",
      "\n",
      "Train Epoch: 6 [4000/8000 (50%)]\tBatch Loss: 147313.076452\tLearning Rate (w_theta): 0.000500\t TIME:20.8s\n",
      "\t\t\t\tDisc: 147312.135501\t\tSpars: 0.940951\n",
      "\t TVw: -0.540736 | TVb: -2.041538 | GSw: -0.238939 | GSb: 0.061055 | TSUw: 0.460858 | TSUb: 0.038724\n",
      "Validating epoch 6...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 282855.16001969314\n",
      "Average validation loss: 5796.08764182703\n",
      "Training epoch 7...\n",
      "\n",
      "Train Epoch: 7 [0/8000 (0%)]\tBatch Loss: 7980.388398\tLearning Rate (w_theta): 0.000500\t TIME:22.8s\n",
      "\t\t\t\tDisc: 7979.903200\t\tSpars: 0.485198\n",
      "\t TVw: -0.544974 | TVb: -2.045623 | GSw: -0.240409 | GSb: 0.059582 | TSUw: 0.459364 | TSUb: 0.040173\n",
      "\n",
      "Train Epoch: 7 [4000/8000 (50%)]\tBatch Loss: 36.161834\tLearning Rate (w_theta): 0.000500\t TIME:24.3s\n",
      "\t\t\t\tDisc: 35.976064\t\tSpars: 0.185770\n",
      "\t TVw: -0.547942 | TVb: -2.048468 | GSw: -0.241416 | GSb: 0.058573 | TSUw: 0.458342 | TSUb: 0.041165\n",
      "Validating epoch 7...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1400.3818624908247\n",
      "Average validation loss: 1.3860650216471189\n",
      "Training epoch 8...\n",
      "\n",
      "Train Epoch: 8 [0/8000 (0%)]\tBatch Loss: 1.447622\tLearning Rate (w_theta): 0.000500\t TIME:26.3s\n",
      "\t\t\t\tDisc: 1.322729\t\tSpars: 0.124893\n",
      "\t TVw: -0.549965 | TVb: -2.050406 | GSw: -0.242101 | GSb: 0.057887 | TSUw: 0.457646 | TSUb: 0.041840\n",
      "\n",
      "Train Epoch: 8 [4000/8000 (50%)]\tBatch Loss: 1.145004\tLearning Rate (w_theta): 0.000500\t TIME:27.7s\n",
      "\t\t\t\tDisc: 1.021853\t\tSpars: 0.123151\n",
      "\t TVw: -0.551340 | TVb: -2.051723 | GSw: -0.242567 | GSb: 0.057420 | TSUw: 0.457173 | TSUb: 0.042298\n",
      "Validating epoch 8...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1.1879237363253032\n",
      "Average validation loss: 0.8408607469114129\n",
      "Training epoch 9...\n",
      "\n",
      "Train Epoch: 9 [0/8000 (0%)]\tBatch Loss: 0.843357\tLearning Rate (w_theta): 0.000500\t TIME:29.7s\n",
      "\t\t\t\tDisc: 0.725031\t\tSpars: 0.118326\n",
      "\t TVw: -0.552272 | TVb: -2.052616 | GSw: -0.242882 | GSb: 0.057104 | TSUw: 0.456852 | TSUb: 0.042609\n",
      "\n",
      "Train Epoch: 9 [4000/8000 (50%)]\tBatch Loss: 0.668945\tLearning Rate (w_theta): 0.000500\t TIME:31.1s\n",
      "\t\t\t\tDisc: 0.552631\t\tSpars: 0.116313\n",
      "\t TVw: -0.552902 | TVb: -2.053220 | GSw: -0.243096 | GSb: 0.056890 | TSUw: 0.456635 | TSUb: 0.042820\n",
      "Validating epoch 9...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.7248501982760994\n",
      "Average validation loss: 0.5782723182707342\n",
      "Training epoch 10...\n",
      "\n",
      "Train Epoch: 10 [0/8000 (0%)]\tBatch Loss: 0.594435\tLearning Rate (w_theta): 0.000500\t TIME:33.1s\n",
      "\t\t\t\tDisc: 0.475922\t\tSpars: 0.118513\n",
      "\t TVw: -0.553329 | TVb: -2.053628 | GSw: -0.243240 | GSb: 0.056745 | TSUw: 0.456488 | TSUb: 0.042962\n",
      "\n",
      "Train Epoch: 10 [4000/8000 (50%)]\tBatch Loss: 0.558764\tLearning Rate (w_theta): 0.000500\t TIME:34.6s\n",
      "\t\t\t\tDisc: 0.439317\t\tSpars: 0.119447\n",
      "\t TVw: -0.553616 | TVb: -2.053904 | GSw: -0.243338 | GSb: 0.056647 | TSUw: 0.456389 | TSUb: 0.043058\n",
      "Validating epoch 10...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.5379584412224043\n",
      "Average validation loss: 0.4760277834205441\n",
      "Training epoch 11...\n",
      "\n",
      "Train Epoch: 11 [0/8000 (0%)]\tBatch Loss: 0.430585\tLearning Rate (w_theta): 0.000500\t TIME:37.8s\n",
      "\t\t\t\tDisc: 0.319560\t\tSpars: 0.111025\n",
      "\t TVw: -0.553810 | TVb: -2.054089 | GSw: -0.243403 | GSb: 0.056581 | TSUw: 0.456323 | TSUb: 0.043122\n",
      "\n",
      "Train Epoch: 11 [4000/8000 (50%)]\tBatch Loss: 0.477960\tLearning Rate (w_theta): 0.000500\t TIME:39.2s\n",
      "\t\t\t\tDisc: 0.359391\t\tSpars: 0.118569\n",
      "\t TVw: -0.553941 | TVb: -2.054214 | GSw: -0.243448 | GSb: 0.056537 | TSUw: 0.456278 | TSUb: 0.043166\n",
      "Validating epoch 11...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4632818463977675\n",
      "Average validation loss: 0.434224352293402\n",
      "Training epoch 12...\n",
      "\n",
      "Train Epoch: 12 [0/8000 (0%)]\tBatch Loss: 0.479781\tLearning Rate (w_theta): 0.000500\t TIME:41.3s\n",
      "\t\t\t\tDisc: 0.360255\t\tSpars: 0.119526\n",
      "\t TVw: -0.554028 | TVb: -2.054298 | GSw: -0.243477 | GSb: 0.056507 | TSUw: 0.456248 | TSUb: 0.043195\n",
      "\n",
      "Train Epoch: 12 [4000/8000 (50%)]\tBatch Loss: 0.434200\tLearning Rate (w_theta): 0.000500\t TIME:42.7s\n",
      "\t\t\t\tDisc: 0.314843\t\tSpars: 0.119357\n",
      "\t TVw: -0.554087 | TVb: -2.054355 | GSw: -0.243497 | GSb: 0.056487 | TSUw: 0.456227 | TSUb: 0.043215\n",
      "Validating epoch 12...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.43323373098031154\n",
      "Average validation loss: 0.41640586081831227\n",
      "Training epoch 13...\n",
      "\n",
      "Train Epoch: 13 [0/8000 (0%)]\tBatch Loss: 0.381646\tLearning Rate (w_theta): 0.000500\t TIME:44.7s\n",
      "\t\t\t\tDisc: 0.269564\t\tSpars: 0.112082\n",
      "\t TVw: -0.554127 | TVb: -2.054393 | GSw: -0.243511 | GSb: 0.056474 | TSUw: 0.456214 | TSUb: 0.043228\n",
      "\n",
      "Train Epoch: 13 [4000/8000 (50%)]\tBatch Loss: 0.437723\tLearning Rate (w_theta): 0.000500\t TIME:46.2s\n",
      "\t\t\t\tDisc: 0.317184\t\tSpars: 0.120538\n",
      "\t TVw: -0.554153 | TVb: -2.054418 | GSw: -0.243520 | GSb: 0.056465 | TSUw: 0.456205 | TSUb: 0.043237\n",
      "Validating epoch 13...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4197296442800972\n",
      "Average validation loss: 0.4085858999181857\n",
      "Training epoch 14...\n",
      "\n",
      "Train Epoch: 14 [0/8000 (0%)]\tBatch Loss: 0.411893\tLearning Rate (w_theta): 0.000500\t TIME:48.2s\n",
      "\t\t\t\tDisc: 0.298348\t\tSpars: 0.113546\n",
      "\t TVw: -0.554171 | TVb: -2.054435 | GSw: -0.243526 | GSb: 0.056459 | TSUw: 0.456198 | TSUb: 0.043243\n",
      "\n",
      "Train Epoch: 14 [4000/8000 (50%)]\tBatch Loss: 0.410963\tLearning Rate (w_theta): 0.000500\t TIME:49.7s\n",
      "\t\t\t\tDisc: 0.293467\t\tSpars: 0.117496\n",
      "\t TVw: -0.554183 | TVb: -2.054446 | GSw: -0.243530 | GSb: 0.056455 | TSUw: 0.456194 | TSUb: 0.043247\n",
      "Validating epoch 14...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4139305994930097\n",
      "Average validation loss: 0.405096910771793\n",
      "Training epoch 15...\n",
      "\n",
      "Train Epoch: 15 [0/8000 (0%)]\tBatch Loss: 0.388426\tLearning Rate (w_theta): 0.000500\t TIME:51.7s\n",
      "\t\t\t\tDisc: 0.276763\t\tSpars: 0.111663\n",
      "\t TVw: -0.554191 | TVb: -2.054454 | GSw: -0.243532 | GSb: 0.056452 | TSUw: 0.456192 | TSUb: 0.043249\n",
      "\n",
      "Train Epoch: 15 [4000/8000 (50%)]\tBatch Loss: 0.387594\tLearning Rate (w_theta): 0.000500\t TIME:53.1s\n",
      "\t\t\t\tDisc: 0.273922\t\tSpars: 0.113672\n",
      "\t TVw: -0.554196 | TVb: -2.054459 | GSw: -0.243534 | GSb: 0.056450 | TSUw: 0.456190 | TSUb: 0.043251\n",
      "Validating epoch 15...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.41132255858472133\n",
      "Average validation loss: 0.40351826765564275\n",
      "Training epoch 16...\n",
      "\n",
      "Train Epoch: 16 [0/8000 (0%)]\tBatch Loss: 0.394365\tLearning Rate (w_theta): 0.000500\t TIME:55.2s\n",
      "\t\t\t\tDisc: 0.278369\t\tSpars: 0.115996\n",
      "\t TVw: -0.554200 | TVb: -2.054463 | GSw: -0.243535 | GSb: 0.056449 | TSUw: 0.456188 | TSUb: 0.043252\n",
      "\n",
      "Train Epoch: 16 [4000/8000 (50%)]\tBatch Loss: 0.387196\tLearning Rate (w_theta): 0.000500\t TIME:56.7s\n",
      "\t\t\t\tDisc: 0.271684\t\tSpars: 0.115512\n",
      "\t TVw: -0.554202 | TVb: -2.054465 | GSw: -0.243536 | GSb: 0.056448 | TSUw: 0.456188 | TSUb: 0.043253\n",
      "Validating epoch 16...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.41011834548844794\n",
      "Average validation loss: 0.40278769801211406\n",
      "Training epoch 17...\n",
      "\n",
      "Train Epoch: 17 [0/8000 (0%)]\tBatch Loss: 0.413426\tLearning Rate (w_theta): 0.000500\t TIME:58.7s\n",
      "\t\t\t\tDisc: 0.296146\t\tSpars: 0.117280\n",
      "\t TVw: -0.554204 | TVb: -2.054466 | GSw: -0.243537 | GSb: 0.056448 | TSUw: 0.456187 | TSUb: 0.043254\n",
      "\n",
      "Train Epoch: 17 [4000/8000 (50%)]\tBatch Loss: 0.440515\tLearning Rate (w_theta): 0.000500\t TIME:60.1s\n",
      "\t\t\t\tDisc: 0.321140\t\tSpars: 0.119375\n",
      "\t TVw: -0.554205 | TVb: -2.054467 | GSw: -0.243537 | GSb: 0.056448 | TSUw: 0.456187 | TSUb: 0.043254\n",
      "Validating epoch 17...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40955835417898717\n",
      "Average validation loss: 0.40243369640033094\n",
      "Training epoch 18...\n",
      "\n",
      "Train Epoch: 18 [0/8000 (0%)]\tBatch Loss: 0.377471\tLearning Rate (w_theta): 0.000500\t TIME:62.2s\n",
      "\t\t\t\tDisc: 0.262613\t\tSpars: 0.114857\n",
      "\t TVw: -0.554206 | TVb: -2.054468 | GSw: -0.243537 | GSb: 0.056447 | TSUw: 0.456187 | TSUb: 0.043254\n",
      "\n",
      "Train Epoch: 18 [4000/8000 (50%)]\tBatch Loss: 0.435050\tLearning Rate (w_theta): 0.000500\t TIME:63.7s\n",
      "\t\t\t\tDisc: 0.315587\t\tSpars: 0.119462\n",
      "\t TVw: -0.554206 | TVb: -2.054468 | GSw: -0.243537 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043254\n",
      "Validating epoch 18...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4092789983576469\n",
      "Average validation loss: 0.40224628957038316\n",
      "Training epoch 19...\n",
      "\n",
      "Train Epoch: 19 [0/8000 (0%)]\tBatch Loss: 0.434977\tLearning Rate (w_theta): 0.000500\t TIME:65.7s\n",
      "\t\t\t\tDisc: 0.310653\t\tSpars: 0.124324\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 19 [4000/8000 (50%)]\tBatch Loss: 0.422735\tLearning Rate (w_theta): 0.000500\t TIME:67.1s\n",
      "\t\t\t\tDisc: 0.307576\t\tSpars: 0.115159\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 19...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4091213150483768\n",
      "Average validation loss: 0.4021323389570189\n",
      "Training epoch 20...\n",
      "\n",
      "Train Epoch: 20 [0/8000 (0%)]\tBatch Loss: 0.420409\tLearning Rate (w_theta): 0.000500\t TIME:69.1s\n",
      "\t\t\t\tDisc: 0.305732\t\tSpars: 0.114677\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 20 [4000/8000 (50%)]\tBatch Loss: 0.374776\tLearning Rate (w_theta): 0.000500\t TIME:70.6s\n",
      "\t\t\t\tDisc: 0.260728\t\tSpars: 0.114048\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 20...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40902084582722353\n",
      "Average validation loss: 0.40204945924025176\n",
      "Training epoch 21...\n",
      "\n",
      "Train Epoch: 21 [0/8000 (0%)]\tBatch Loss: 0.395053\tLearning Rate (w_theta): 0.000500\t TIME:74.0s\n",
      "\t\t\t\tDisc: 0.278049\t\tSpars: 0.117004\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 21 [4000/8000 (50%)]\tBatch Loss: 0.408808\tLearning Rate (w_theta): 0.000500\t TIME:75.5s\n",
      "\t\t\t\tDisc: 0.294342\t\tSpars: 0.114466\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 21...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40894063788684043\n",
      "Average validation loss: 0.40198043546480333\n",
      "Training epoch 22...\n",
      "\n",
      "Train Epoch: 22 [0/8000 (0%)]\tBatch Loss: 0.397744\tLearning Rate (w_theta): 0.000500\t TIME:77.7s\n",
      "\t\t\t\tDisc: 0.282767\t\tSpars: 0.114977\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 22 [4000/8000 (50%)]\tBatch Loss: 0.386194\tLearning Rate (w_theta): 0.000500\t TIME:79.1s\n",
      "\t\t\t\tDisc: 0.269359\t\tSpars: 0.116835\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 22...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4088727940477531\n",
      "Average validation loss: 0.40191647620023174\n",
      "Training epoch 23...\n",
      "\n",
      "Train Epoch: 23 [0/8000 (0%)]\tBatch Loss: 0.429876\tLearning Rate (w_theta): 0.000500\t TIME:81.2s\n",
      "\t\t\t\tDisc: 0.309004\t\tSpars: 0.120872\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 23 [4000/8000 (50%)]\tBatch Loss: 0.384078\tLearning Rate (w_theta): 0.000500\t TIME:82.7s\n",
      "\t\t\t\tDisc: 0.271321\t\tSpars: 0.112757\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 23...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4088076620333395\n",
      "Average validation loss: 0.4018546094583192\n",
      "Training epoch 24...\n",
      "\n",
      "Train Epoch: 24 [0/8000 (0%)]\tBatch Loss: 0.405238\tLearning Rate (w_theta): 0.000500\t TIME:84.8s\n",
      "\t\t\t\tDisc: 0.288064\t\tSpars: 0.117174\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 24 [4000/8000 (50%)]\tBatch Loss: 0.410833\tLearning Rate (w_theta): 0.000500\t TIME:86.2s\n",
      "\t\t\t\tDisc: 0.294836\t\tSpars: 0.115996\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 24...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.408743246278613\n",
      "Average validation loss: 0.4017927098179059\n",
      "Training epoch 25...\n",
      "\n",
      "Train Epoch: 25 [0/8000 (0%)]\tBatch Loss: 0.416071\tLearning Rate (w_theta): 0.000500\t TIME:88.3s\n",
      "\t\t\t\tDisc: 0.299220\t\tSpars: 0.116851\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 25 [4000/8000 (50%)]\tBatch Loss: 0.440248\tLearning Rate (w_theta): 0.000500\t TIME:89.8s\n",
      "\t\t\t\tDisc: 0.320590\t\tSpars: 0.119658\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 25...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4086789667042261\n",
      "Average validation loss: 0.40172942480377427\n",
      "Training epoch 26...\n",
      "\n",
      "Train Epoch: 26 [0/8000 (0%)]\tBatch Loss: 0.420853\tLearning Rate (w_theta): 0.000500\t TIME:91.9s\n",
      "\t\t\t\tDisc: 0.303233\t\tSpars: 0.117620\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 26 [4000/8000 (50%)]\tBatch Loss: 0.406327\tLearning Rate (w_theta): 0.000500\t TIME:93.4s\n",
      "\t\t\t\tDisc: 0.289380\t\tSpars: 0.116947\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 26...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40861216532215994\n",
      "Average validation loss: 0.40166540547313945\n",
      "Training epoch 27...\n",
      "\n",
      "Train Epoch: 27 [0/8000 (0%)]\tBatch Loss: 0.451343\tLearning Rate (w_theta): 0.000500\t TIME:95.5s\n",
      "\t\t\t\tDisc: 0.332190\t\tSpars: 0.119153\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 27 [4000/8000 (50%)]\tBatch Loss: 0.422688\tLearning Rate (w_theta): 0.000500\t TIME:97.0s\n",
      "\t\t\t\tDisc: 0.301002\t\tSpars: 0.121686\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 27...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40854523289377187\n",
      "Average validation loss: 0.40159945538516245\n",
      "Training epoch 28...\n",
      "\n",
      "Train Epoch: 28 [0/8000 (0%)]\tBatch Loss: 0.381926\tLearning Rate (w_theta): 0.000500\t TIME:99.1s\n",
      "\t\t\t\tDisc: 0.271805\t\tSpars: 0.110121\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 28 [4000/8000 (50%)]\tBatch Loss: 0.373402\tLearning Rate (w_theta): 0.000500\t TIME:100.5s\n",
      "\t\t\t\tDisc: 0.261499\t\tSpars: 0.111903\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 28...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40847531510956786\n",
      "Average validation loss: 0.4015325826672716\n",
      "Training epoch 29...\n",
      "\n",
      "Train Epoch: 29 [0/8000 (0%)]\tBatch Loss: 0.404851\tLearning Rate (w_theta): 0.000500\t TIME:102.7s\n",
      "\t\t\t\tDisc: 0.287454\t\tSpars: 0.117397\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 29 [4000/8000 (50%)]\tBatch Loss: 0.393035\tLearning Rate (w_theta): 0.000500\t TIME:104.2s\n",
      "\t\t\t\tDisc: 0.279550\t\tSpars: 0.113484\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 29...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40840606536689905\n",
      "Average validation loss: 0.4014628592532009\n",
      "Training epoch 30...\n",
      "\n",
      "Train Epoch: 30 [0/8000 (0%)]\tBatch Loss: 0.428188\tLearning Rate (w_theta): 0.000500\t TIME:106.3s\n",
      "\t\t\t\tDisc: 0.306550\t\tSpars: 0.121639\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 30 [4000/8000 (50%)]\tBatch Loss: 0.418463\tLearning Rate (w_theta): 0.000500\t TIME:107.7s\n",
      "\t\t\t\tDisc: 0.300636\t\tSpars: 0.117827\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 30...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4083326384011163\n",
      "Average validation loss: 0.40139230944258386\n",
      "Training epoch 31...\n",
      "\n",
      "Train Epoch: 31 [0/8000 (0%)]\tBatch Loss: 0.383596\tLearning Rate (w_theta): 0.000500\t TIME:111.1s\n",
      "\t\t\t\tDisc: 0.268766\t\tSpars: 0.114830\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 31 [4000/8000 (50%)]\tBatch Loss: 0.426741\tLearning Rate (w_theta): 0.000500\t TIME:112.6s\n",
      "\t\t\t\tDisc: 0.309319\t\tSpars: 0.117422\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 31...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.408259036235899\n",
      "Average validation loss: 0.40131980227461167\n",
      "Training epoch 32...\n",
      "\n",
      "Train Epoch: 32 [0/8000 (0%)]\tBatch Loss: 0.408087\tLearning Rate (w_theta): 0.000500\t TIME:114.7s\n",
      "\t\t\t\tDisc: 0.287712\t\tSpars: 0.120376\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 32 [4000/8000 (50%)]\tBatch Loss: 0.383136\tLearning Rate (w_theta): 0.000500\t TIME:116.1s\n",
      "\t\t\t\tDisc: 0.269614\t\tSpars: 0.113523\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 32...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4081835104858937\n",
      "Average validation loss: 0.40124540338544606\n",
      "Training epoch 33...\n",
      "\n",
      "Train Epoch: 33 [0/8000 (0%)]\tBatch Loss: 0.399532\tLearning Rate (w_theta): 0.000500\t TIME:118.3s\n",
      "\t\t\t\tDisc: 0.285248\t\tSpars: 0.114285\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 33 [4000/8000 (50%)]\tBatch Loss: 0.424557\tLearning Rate (w_theta): 0.000500\t TIME:119.7s\n",
      "\t\t\t\tDisc: 0.309420\t\tSpars: 0.115137\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 33...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40810504336208975\n",
      "Average validation loss: 0.40117014202616424\n",
      "Training epoch 34...\n",
      "\n",
      "Train Epoch: 34 [0/8000 (0%)]\tBatch Loss: 0.422332\tLearning Rate (w_theta): 0.000500\t TIME:121.9s\n",
      "\t\t\t\tDisc: 0.304965\t\tSpars: 0.117367\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 34 [4000/8000 (50%)]\tBatch Loss: 0.385489\tLearning Rate (w_theta): 0.000500\t TIME:123.4s\n",
      "\t\t\t\tDisc: 0.271732\t\tSpars: 0.113757\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 34...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4080263257423657\n",
      "Average validation loss: 0.40109282391486223\n",
      "Training epoch 35...\n",
      "\n",
      "Train Epoch: 35 [0/8000 (0%)]\tBatch Loss: 0.370372\tLearning Rate (w_theta): 0.000500\t TIME:125.5s\n",
      "\t\t\t\tDisc: 0.256772\t\tSpars: 0.113600\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 35 [4000/8000 (50%)]\tBatch Loss: 0.409876\tLearning Rate (w_theta): 0.000500\t TIME:126.9s\n",
      "\t\t\t\tDisc: 0.290813\t\tSpars: 0.119063\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 35...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4079456096750089\n",
      "Average validation loss: 0.4010137783012124\n",
      "Training epoch 36...\n",
      "\n",
      "Train Epoch: 36 [0/8000 (0%)]\tBatch Loss: 0.409940\tLearning Rate (w_theta): 0.000500\t TIME:129.0s\n",
      "\t\t\t\tDisc: 0.291681\t\tSpars: 0.118259\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 36 [4000/8000 (50%)]\tBatch Loss: 0.447391\tLearning Rate (w_theta): 0.000500\t TIME:130.4s\n",
      "\t\t\t\tDisc: 0.322566\t\tSpars: 0.124825\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 36...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40786325593190687\n",
      "Average validation loss: 0.4009329185954129\n",
      "Training epoch 37...\n",
      "\n",
      "Train Epoch: 37 [0/8000 (0%)]\tBatch Loss: 0.383745\tLearning Rate (w_theta): 0.000500\t TIME:132.5s\n",
      "\t\t\t\tDisc: 0.267811\t\tSpars: 0.115934\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 37 [4000/8000 (50%)]\tBatch Loss: 0.415765\tLearning Rate (w_theta): 0.000500\t TIME:134.0s\n",
      "\t\t\t\tDisc: 0.295795\t\tSpars: 0.119971\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 37...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40777777113483304\n",
      "Average validation loss: 0.4008513126023979\n",
      "Training epoch 38...\n",
      "\n",
      "Train Epoch: 38 [0/8000 (0%)]\tBatch Loss: 0.443167\tLearning Rate (w_theta): 0.000500\t TIME:136.1s\n",
      "\t\t\t\tDisc: 0.323364\t\tSpars: 0.119802\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 38 [4000/8000 (50%)]\tBatch Loss: 0.381388\tLearning Rate (w_theta): 0.000500\t TIME:137.6s\n",
      "\t\t\t\tDisc: 0.264720\t\tSpars: 0.116668\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 38...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40769281173896793\n",
      "Average validation loss: 0.4007671864008231\n",
      "Training epoch 39...\n",
      "\n",
      "Train Epoch: 39 [0/8000 (0%)]\tBatch Loss: 0.389532\tLearning Rate (w_theta): 0.000500\t TIME:139.7s\n",
      "\t\t\t\tDisc: 0.273475\t\tSpars: 0.116057\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 39 [4000/8000 (50%)]\tBatch Loss: 0.446522\tLearning Rate (w_theta): 0.000500\t TIME:141.2s\n",
      "\t\t\t\tDisc: 0.327767\t\tSpars: 0.118755\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 39...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4076046564539437\n",
      "Average validation loss: 0.4006815897383033\n",
      "Training epoch 40...\n",
      "\n",
      "Train Epoch: 40 [0/8000 (0%)]\tBatch Loss: 0.375672\tLearning Rate (w_theta): 0.000500\t TIME:143.3s\n",
      "\t\t\t\tDisc: 0.260069\t\tSpars: 0.115603\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 40 [4000/8000 (50%)]\tBatch Loss: 0.456287\tLearning Rate (w_theta): 0.000500\t TIME:144.7s\n",
      "\t\t\t\tDisc: 0.332306\t\tSpars: 0.123980\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 40...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40751443752158534\n",
      "Average validation loss: 0.4005947316370976\n",
      "Training epoch 41...\n",
      "\n",
      "Train Epoch: 41 [0/8000 (0%)]\tBatch Loss: 0.393976\tLearning Rate (w_theta): 0.000500\t TIME:148.2s\n",
      "\t\t\t\tDisc: 0.278575\t\tSpars: 0.115402\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 41 [4000/8000 (50%)]\tBatch Loss: 0.400450\tLearning Rate (w_theta): 0.000500\t TIME:149.7s\n",
      "\t\t\t\tDisc: 0.284290\t\tSpars: 0.116160\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 41...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4074237447368379\n",
      "Average validation loss: 0.40050541807761664\n",
      "Training epoch 42...\n",
      "\n",
      "Train Epoch: 42 [0/8000 (0%)]\tBatch Loss: 0.414867\tLearning Rate (w_theta): 0.000500\t TIME:151.8s\n",
      "\t\t\t\tDisc: 0.295808\t\tSpars: 0.119059\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 42 [4000/8000 (50%)]\tBatch Loss: 0.346633\tLearning Rate (w_theta): 0.000500\t TIME:153.3s\n",
      "\t\t\t\tDisc: 0.236949\t\tSpars: 0.109684\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 42...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.407330773546736\n",
      "Average validation loss: 0.40041406352619546\n",
      "Training epoch 43...\n",
      "\n",
      "Train Epoch: 43 [0/8000 (0%)]\tBatch Loss: 0.392819\tLearning Rate (w_theta): 0.000500\t TIME:155.5s\n",
      "\t\t\t\tDisc: 0.280937\t\tSpars: 0.111882\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 43 [4000/8000 (50%)]\tBatch Loss: 0.409836\tLearning Rate (w_theta): 0.000500\t TIME:157.0s\n",
      "\t\t\t\tDisc: 0.288511\t\tSpars: 0.121325\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 43...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4072355963636665\n",
      "Average validation loss: 0.4003209073878709\n",
      "Training epoch 44...\n",
      "\n",
      "Train Epoch: 44 [0/8000 (0%)]\tBatch Loss: 0.449372\tLearning Rate (w_theta): 0.000500\t TIME:159.3s\n",
      "\t\t\t\tDisc: 0.334173\t\tSpars: 0.115199\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 44 [4000/8000 (50%)]\tBatch Loss: 0.397230\tLearning Rate (w_theta): 0.000500\t TIME:160.7s\n",
      "\t\t\t\tDisc: 0.278776\t\tSpars: 0.118455\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 44...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4071391555767736\n",
      "Average validation loss: 0.4002254308075946\n",
      "Training epoch 45...\n",
      "\n",
      "Train Epoch: 45 [0/8000 (0%)]\tBatch Loss: 0.402429\tLearning Rate (w_theta): 0.000500\t TIME:163.0s\n",
      "\t\t\t\tDisc: 0.286563\t\tSpars: 0.115867\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 45 [4000/8000 (50%)]\tBatch Loss: 0.370342\tLearning Rate (w_theta): 0.000500\t TIME:164.4s\n",
      "\t\t\t\tDisc: 0.259122\t\tSpars: 0.111220\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 45...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40703929499964236\n",
      "Average validation loss: 0.40012894848053165\n",
      "Training epoch 46...\n",
      "\n",
      "Train Epoch: 46 [0/8000 (0%)]\tBatch Loss: 0.396052\tLearning Rate (w_theta): 0.000500\t TIME:166.5s\n",
      "\t\t\t\tDisc: 0.284668\t\tSpars: 0.111383\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 46 [4000/8000 (50%)]\tBatch Loss: 0.410344\tLearning Rate (w_theta): 0.000500\t TIME:168.0s\n",
      "\t\t\t\tDisc: 0.293487\t\tSpars: 0.116857\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 46...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4069377553186048\n",
      "Average validation loss: 0.40003121041112727\n",
      "Training epoch 47...\n",
      "\n",
      "Train Epoch: 47 [0/8000 (0%)]\tBatch Loss: 0.415859\tLearning Rate (w_theta): 0.000500\t TIME:170.2s\n",
      "\t\t\t\tDisc: 0.300370\t\tSpars: 0.115489\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 47 [4000/8000 (50%)]\tBatch Loss: 0.399543\tLearning Rate (w_theta): 0.000500\t TIME:171.7s\n",
      "\t\t\t\tDisc: 0.284173\t\tSpars: 0.115370\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 47...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40683606029553704\n",
      "Average validation loss: 0.39993085506897874\n",
      "Training epoch 48...\n",
      "\n",
      "Train Epoch: 48 [0/8000 (0%)]\tBatch Loss: 0.445573\tLearning Rate (w_theta): 0.000500\t TIME:173.9s\n",
      "\t\t\t\tDisc: 0.323415\t\tSpars: 0.122158\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 48 [4000/8000 (50%)]\tBatch Loss: 0.435735\tLearning Rate (w_theta): 0.000500\t TIME:175.3s\n",
      "\t\t\t\tDisc: 0.316120\t\tSpars: 0.119615\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 48...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40673222187531854\n",
      "Average validation loss: 0.3998280200762022\n",
      "Training epoch 49...\n",
      "\n",
      "Train Epoch: 49 [0/8000 (0%)]\tBatch Loss: 0.407627\tLearning Rate (w_theta): 0.000500\t TIME:177.5s\n",
      "\t\t\t\tDisc: 0.291278\t\tSpars: 0.116348\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 49 [4000/8000 (50%)]\tBatch Loss: 0.402013\tLearning Rate (w_theta): 0.000500\t TIME:178.9s\n",
      "\t\t\t\tDisc: 0.284575\t\tSpars: 0.117438\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 49...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40662361678775427\n",
      "Average validation loss: 0.39972489238114545\n",
      "Training epoch 50...\n",
      "\n",
      "Train Epoch: 50 [0/8000 (0%)]\tBatch Loss: 0.426150\tLearning Rate (w_theta): 0.000500\t TIME:181.1s\n",
      "\t\t\t\tDisc: 0.309038\t\tSpars: 0.117112\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 50 [4000/8000 (50%)]\tBatch Loss: 0.439101\tLearning Rate (w_theta): 0.000500\t TIME:182.5s\n",
      "\t\t\t\tDisc: 0.319821\t\tSpars: 0.119280\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 50...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4065160218130451\n",
      "Average validation loss: 0.3996190764778019\n",
      "Training epoch 51...\n",
      "\n",
      "Train Epoch: 51 [0/8000 (0%)]\tBatch Loss: 0.412385\tLearning Rate (w_theta): 0.000500\t TIME:186.0s\n",
      "\t\t\t\tDisc: 0.297456\t\tSpars: 0.114929\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 51 [4000/8000 (50%)]\tBatch Loss: 0.373779\tLearning Rate (w_theta): 0.000500\t TIME:187.4s\n",
      "\t\t\t\tDisc: 0.260618\t\tSpars: 0.113161\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 51...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4064050280149524\n",
      "Average validation loss: 0.3995117492426379\n",
      "Training epoch 52...\n",
      "\n",
      "Train Epoch: 52 [0/8000 (0%)]\tBatch Loss: 0.395980\tLearning Rate (w_theta): 0.000500\t TIME:189.6s\n",
      "\t\t\t\tDisc: 0.280561\t\tSpars: 0.115419\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 52 [4000/8000 (50%)]\tBatch Loss: 0.404953\tLearning Rate (w_theta): 0.000500\t TIME:191.1s\n",
      "\t\t\t\tDisc: 0.288300\t\tSpars: 0.116653\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 52...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.406292573318893\n",
      "Average validation loss: 0.3994023964815517\n",
      "Training epoch 53...\n",
      "\n",
      "Train Epoch: 53 [0/8000 (0%)]\tBatch Loss: 0.361655\tLearning Rate (w_theta): 0.000500\t TIME:193.2s\n",
      "\t\t\t\tDisc: 0.251694\t\tSpars: 0.109961\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 53 [4000/8000 (50%)]\tBatch Loss: 0.394783\tLearning Rate (w_theta): 0.000500\t TIME:194.7s\n",
      "\t\t\t\tDisc: 0.278458\t\tSpars: 0.116325\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 53...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4061777916512428\n",
      "Average validation loss: 0.39929116332996734\n",
      "Training epoch 54...\n",
      "\n",
      "Train Epoch: 54 [0/8000 (0%)]\tBatch Loss: 0.434930\tLearning Rate (w_theta): 0.000500\t TIME:196.8s\n",
      "\t\t\t\tDisc: 0.317893\t\tSpars: 0.117037\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 54 [4000/8000 (50%)]\tBatch Loss: 0.389521\tLearning Rate (w_theta): 0.000500\t TIME:198.2s\n",
      "\t\t\t\tDisc: 0.276060\t\tSpars: 0.113461\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 54...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4060616144656546\n",
      "Average validation loss: 0.3991774600498701\n",
      "Training epoch 55...\n",
      "\n",
      "Train Epoch: 55 [0/8000 (0%)]\tBatch Loss: 0.375822\tLearning Rate (w_theta): 0.000500\t TIME:200.4s\n",
      "\t\t\t\tDisc: 0.262885\t\tSpars: 0.112937\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 55 [4000/8000 (50%)]\tBatch Loss: 0.412983\tLearning Rate (w_theta): 0.000500\t TIME:201.9s\n",
      "\t\t\t\tDisc: 0.295137\t\tSpars: 0.117847\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 55...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4059440884028519\n",
      "Average validation loss: 0.39906066093746356\n",
      "Training epoch 56...\n",
      "\n",
      "Train Epoch: 56 [0/8000 (0%)]\tBatch Loss: 0.431048\tLearning Rate (w_theta): 0.000500\t TIME:204.1s\n",
      "\t\t\t\tDisc: 0.314221\t\tSpars: 0.116827\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 56 [4000/8000 (50%)]\tBatch Loss: 0.395018\tLearning Rate (w_theta): 0.000500\t TIME:205.6s\n",
      "\t\t\t\tDisc: 0.276233\t\tSpars: 0.118785\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 56...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4058211917080883\n",
      "Average validation loss: 0.398943235798835\n",
      "Training epoch 57...\n",
      "\n",
      "Train Epoch: 57 [0/8000 (0%)]\tBatch Loss: 0.347251\tLearning Rate (w_theta): 0.000500\t TIME:207.7s\n",
      "\t\t\t\tDisc: 0.236053\t\tSpars: 0.111198\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 57 [4000/8000 (50%)]\tBatch Loss: 0.398467\tLearning Rate (w_theta): 0.000500\t TIME:209.2s\n",
      "\t\t\t\tDisc: 0.286165\t\tSpars: 0.112302\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 57...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4056974247413566\n",
      "Average validation loss: 0.3988242213319501\n",
      "Training epoch 58...\n",
      "\n",
      "Train Epoch: 58 [0/8000 (0%)]\tBatch Loss: 0.397893\tLearning Rate (w_theta): 0.000500\t TIME:211.3s\n",
      "\t\t\t\tDisc: 0.284107\t\tSpars: 0.113786\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 58 [4000/8000 (50%)]\tBatch Loss: 0.404839\tLearning Rate (w_theta): 0.000500\t TIME:212.8s\n",
      "\t\t\t\tDisc: 0.289387\t\tSpars: 0.115452\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 58...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40557432621036016\n",
      "Average validation loss: 0.39870129330694926\n",
      "Training epoch 59...\n",
      "\n",
      "Train Epoch: 59 [0/8000 (0%)]\tBatch Loss: 0.391280\tLearning Rate (w_theta): 0.000500\t TIME:215.0s\n",
      "\t\t\t\tDisc: 0.272018\t\tSpars: 0.119261\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 59 [4000/8000 (50%)]\tBatch Loss: 0.460758\tLearning Rate (w_theta): 0.000500\t TIME:216.4s\n",
      "\t\t\t\tDisc: 0.338949\t\tSpars: 0.121809\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 59...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40544521423248503\n",
      "Average validation loss: 0.39857738116975333\n",
      "Training epoch 60...\n",
      "\n",
      "Train Epoch: 60 [0/8000 (0%)]\tBatch Loss: 0.404169\tLearning Rate (w_theta): 0.000500\t TIME:218.6s\n",
      "\t\t\t\tDisc: 0.289421\t\tSpars: 0.114748\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 60 [4000/8000 (50%)]\tBatch Loss: 0.381707\tLearning Rate (w_theta): 0.000500\t TIME:220.1s\n",
      "\t\t\t\tDisc: 0.267814\t\tSpars: 0.113893\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 60...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40531585421209565\n",
      "Average validation loss: 0.39845092797674136\n",
      "Training epoch 61...\n",
      "\n",
      "Train Epoch: 61 [0/8000 (0%)]\tBatch Loss: 0.376529\tLearning Rate (w_theta): 0.000500\t TIME:223.5s\n",
      "\t\t\t\tDisc: 0.265681\t\tSpars: 0.110848\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 61 [4000/8000 (50%)]\tBatch Loss: 0.449079\tLearning Rate (w_theta): 0.000500\t TIME:224.9s\n",
      "\t\t\t\tDisc: 0.327737\t\tSpars: 0.121342\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 61...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4051823013028396\n",
      "Average validation loss: 0.3983233293894593\n",
      "Training epoch 62...\n",
      "\n",
      "Train Epoch: 62 [0/8000 (0%)]\tBatch Loss: 0.373457\tLearning Rate (w_theta): 0.000500\t TIME:227.1s\n",
      "\t\t\t\tDisc: 0.259314\t\tSpars: 0.114143\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 62 [4000/8000 (50%)]\tBatch Loss: 0.414868\tLearning Rate (w_theta): 0.000500\t TIME:228.6s\n",
      "\t\t\t\tDisc: 0.296845\t\tSpars: 0.118024\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 62...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40505056099486586\n",
      "Average validation loss: 0.39819137305996727\n",
      "Training epoch 63...\n",
      "\n",
      "Train Epoch: 63 [0/8000 (0%)]\tBatch Loss: 0.419289\tLearning Rate (w_theta): 0.000500\t TIME:230.8s\n",
      "\t\t\t\tDisc: 0.302047\t\tSpars: 0.117242\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 63 [4000/8000 (50%)]\tBatch Loss: 0.412630\tLearning Rate (w_theta): 0.000500\t TIME:232.2s\n",
      "\t\t\t\tDisc: 0.294620\t\tSpars: 0.118009\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 63...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4049130877127559\n",
      "Average validation loss: 0.39805753676044586\n",
      "Training epoch 64...\n",
      "\n",
      "Train Epoch: 64 [0/8000 (0%)]\tBatch Loss: 0.419666\tLearning Rate (w_theta): 0.000500\t TIME:234.4s\n",
      "\t\t\t\tDisc: 0.301735\t\tSpars: 0.117931\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 64 [4000/8000 (50%)]\tBatch Loss: 0.378683\tLearning Rate (w_theta): 0.000500\t TIME:235.9s\n",
      "\t\t\t\tDisc: 0.264312\t\tSpars: 0.114372\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 64...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40477287327991934\n",
      "Average validation loss: 0.3979221367989295\n",
      "Training epoch 65...\n",
      "\n",
      "Train Epoch: 65 [0/8000 (0%)]\tBatch Loss: 0.408898\tLearning Rate (w_theta): 0.000500\t TIME:238.0s\n",
      "\t\t\t\tDisc: 0.291270\t\tSpars: 0.117628\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 65 [4000/8000 (50%)]\tBatch Loss: 0.386344\tLearning Rate (w_theta): 0.000500\t TIME:239.5s\n",
      "\t\t\t\tDisc: 0.271855\t\tSpars: 0.114489\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 65...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40463194710556166\n",
      "Average validation loss: 0.3977837252826566\n",
      "Training epoch 66...\n",
      "\n",
      "Train Epoch: 66 [0/8000 (0%)]\tBatch Loss: 0.402499\tLearning Rate (w_theta): 0.000500\t TIME:241.6s\n",
      "\t\t\t\tDisc: 0.285285\t\tSpars: 0.117214\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 66 [4000/8000 (50%)]\tBatch Loss: 0.400988\tLearning Rate (w_theta): 0.000500\t TIME:243.1s\n",
      "\t\t\t\tDisc: 0.285191\t\tSpars: 0.115797\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 66...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4044859900335106\n",
      "Average validation loss: 0.3976442012243767\n",
      "Training epoch 67...\n",
      "\n",
      "Train Epoch: 67 [0/8000 (0%)]\tBatch Loss: 0.401337\tLearning Rate (w_theta): 0.000500\t TIME:245.4s\n",
      "\t\t\t\tDisc: 0.286099\t\tSpars: 0.115238\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 67 [4000/8000 (50%)]\tBatch Loss: 0.373178\tLearning Rate (w_theta): 0.000500\t TIME:246.8s\n",
      "\t\t\t\tDisc: 0.259904\t\tSpars: 0.113274\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 67...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40434037682969515\n",
      "Average validation loss: 0.397501284148192\n",
      "Training epoch 68...\n",
      "\n",
      "Train Epoch: 68 [0/8000 (0%)]\tBatch Loss: 0.375572\tLearning Rate (w_theta): 0.000500\t TIME:249.0s\n",
      "\t\t\t\tDisc: 0.257307\t\tSpars: 0.118264\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 68 [4000/8000 (50%)]\tBatch Loss: 0.380957\tLearning Rate (w_theta): 0.000500\t TIME:250.5s\n",
      "\t\t\t\tDisc: 0.265076\t\tSpars: 0.115881\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 68...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40419066065582765\n",
      "Average validation loss: 0.3973561343520089\n",
      "Training epoch 69...\n",
      "\n",
      "Train Epoch: 69 [0/8000 (0%)]\tBatch Loss: 0.418011\tLearning Rate (w_theta): 0.000500\t TIME:252.8s\n",
      "\t\t\t\tDisc: 0.302000\t\tSpars: 0.116010\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 69 [4000/8000 (50%)]\tBatch Loss: 0.388855\tLearning Rate (w_theta): 0.000500\t TIME:254.2s\n",
      "\t\t\t\tDisc: 0.273634\t\tSpars: 0.115221\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 69...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40403984354488387\n",
      "Average validation loss: 0.3972075599176505\n",
      "Training epoch 70...\n",
      "\n",
      "Train Epoch: 70 [0/8000 (0%)]\tBatch Loss: 0.393919\tLearning Rate (w_theta): 0.000500\t TIME:256.4s\n",
      "\t\t\t\tDisc: 0.275482\t\tSpars: 0.118437\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 70 [4000/8000 (50%)]\tBatch Loss: 0.403072\tLearning Rate (w_theta): 0.000500\t TIME:257.8s\n",
      "\t\t\t\tDisc: 0.288366\t\tSpars: 0.114705\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 70...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4038827942107335\n",
      "Average validation loss: 0.397058326613351\n",
      "Training epoch 71...\n",
      "\n",
      "Train Epoch: 71 [0/8000 (0%)]\tBatch Loss: 0.417045\tLearning Rate (w_theta): 0.000500\t TIME:261.4s\n",
      "\t\t\t\tDisc: 0.296719\t\tSpars: 0.120326\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 71 [4000/8000 (50%)]\tBatch Loss: 0.403950\tLearning Rate (w_theta): 0.000500\t TIME:262.9s\n",
      "\t\t\t\tDisc: 0.287430\t\tSpars: 0.116520\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 71...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40372744785391435\n",
      "Average validation loss: 0.3969048712304146\n",
      "Training epoch 72...\n",
      "\n",
      "Train Epoch: 72 [0/8000 (0%)]\tBatch Loss: 0.404001\tLearning Rate (w_theta): 0.000500\t TIME:265.1s\n",
      "\t\t\t\tDisc: 0.288344\t\tSpars: 0.115657\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 72 [4000/8000 (50%)]\tBatch Loss: 0.405500\tLearning Rate (w_theta): 0.000500\t TIME:266.6s\n",
      "\t\t\t\tDisc: 0.290120\t\tSpars: 0.115379\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 72...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40356597837343694\n",
      "Average validation loss: 0.39674983657626683\n",
      "Training epoch 73...\n",
      "\n",
      "Train Epoch: 73 [0/8000 (0%)]\tBatch Loss: 0.420418\tLearning Rate (w_theta): 0.000500\t TIME:268.8s\n",
      "\t\t\t\tDisc: 0.301275\t\tSpars: 0.119144\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 73 [4000/8000 (50%)]\tBatch Loss: 0.391503\tLearning Rate (w_theta): 0.000500\t TIME:270.2s\n",
      "\t\t\t\tDisc: 0.276313\t\tSpars: 0.115190\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 73...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40340486930166425\n",
      "Average validation loss: 0.3965907228669808\n",
      "Training epoch 74...\n",
      "\n",
      "Train Epoch: 74 [0/8000 (0%)]\tBatch Loss: 0.370507\tLearning Rate (w_theta): 0.000500\t TIME:272.6s\n",
      "\t\t\t\tDisc: 0.257107\t\tSpars: 0.113399\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 74 [4000/8000 (50%)]\tBatch Loss: 0.420405\tLearning Rate (w_theta): 0.000500\t TIME:274.0s\n",
      "\t\t\t\tDisc: 0.303008\t\tSpars: 0.117397\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 74...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4032388899306783\n",
      "Average validation loss: 0.39642908427443746\n",
      "Training epoch 75...\n",
      "\n",
      "Train Epoch: 75 [0/8000 (0%)]\tBatch Loss: 0.411161\tLearning Rate (w_theta): 0.000500\t TIME:276.2s\n",
      "\t\t\t\tDisc: 0.293748\t\tSpars: 0.117413\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 75 [4000/8000 (50%)]\tBatch Loss: 0.403981\tLearning Rate (w_theta): 0.000500\t TIME:277.7s\n",
      "\t\t\t\tDisc: 0.283813\t\tSpars: 0.120168\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 75...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4030698906766531\n",
      "Average validation loss: 0.396264997776278\n",
      "Training epoch 76...\n",
      "\n",
      "Train Epoch: 76 [0/8000 (0%)]\tBatch Loss: 0.371900\tLearning Rate (w_theta): 0.000500\t TIME:279.9s\n",
      "\t\t\t\tDisc: 0.260136\t\tSpars: 0.111763\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 76 [4000/8000 (50%)]\tBatch Loss: 0.378129\tLearning Rate (w_theta): 0.000500\t TIME:281.3s\n",
      "\t\t\t\tDisc: 0.265275\t\tSpars: 0.112855\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 76...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40289848446453336\n",
      "Average validation loss: 0.3960980420192958\n",
      "Training epoch 77...\n",
      "\n",
      "Train Epoch: 77 [0/8000 (0%)]\tBatch Loss: 0.391226\tLearning Rate (w_theta): 0.000500\t TIME:283.5s\n",
      "\t\t\t\tDisc: 0.276440\t\tSpars: 0.114786\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 77 [4000/8000 (50%)]\tBatch Loss: 0.414278\tLearning Rate (w_theta): 0.000500\t TIME:285.0s\n",
      "\t\t\t\tDisc: 0.300325\t\tSpars: 0.113953\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 77...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40272293496845457\n",
      "Average validation loss: 0.39592899048005836\n",
      "Training epoch 78...\n",
      "\n",
      "Train Epoch: 78 [0/8000 (0%)]\tBatch Loss: 0.418286\tLearning Rate (w_theta): 0.000500\t TIME:287.1s\n",
      "\t\t\t\tDisc: 0.300322\t\tSpars: 0.117964\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 78 [4000/8000 (50%)]\tBatch Loss: 0.378721\tLearning Rate (w_theta): 0.000500\t TIME:288.7s\n",
      "\t\t\t\tDisc: 0.261196\t\tSpars: 0.117525\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 78...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4025471682384225\n",
      "Average validation loss: 0.3957556280455571\n",
      "Training epoch 79...\n",
      "\n",
      "Train Epoch: 79 [0/8000 (0%)]\tBatch Loss: 0.424738\tLearning Rate (w_theta): 0.000500\t TIME:290.8s\n",
      "\t\t\t\tDisc: 0.308763\t\tSpars: 0.115975\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 79 [4000/8000 (50%)]\tBatch Loss: 0.413801\tLearning Rate (w_theta): 0.000500\t TIME:292.3s\n",
      "\t\t\t\tDisc: 0.297734\t\tSpars: 0.116067\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 79...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40236703117370304\n",
      "Average validation loss: 0.3955789993836705\n",
      "Training epoch 80...\n",
      "\n",
      "Train Epoch: 80 [0/8000 (0%)]\tBatch Loss: 0.396968\tLearning Rate (w_theta): 0.000500\t TIME:294.5s\n",
      "\t\t\t\tDisc: 0.277291\t\tSpars: 0.119677\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 80 [4000/8000 (50%)]\tBatch Loss: 0.413984\tLearning Rate (w_theta): 0.000500\t TIME:295.9s\n",
      "\t\t\t\tDisc: 0.297291\t\tSpars: 0.116693\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 80...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4021819268679696\n",
      "Average validation loss: 0.39540037933088257\n",
      "Training epoch 81...\n",
      "\n",
      "Train Epoch: 81 [0/8000 (0%)]\tBatch Loss: 0.399062\tLearning Rate (w_theta): 0.000500\t TIME:299.4s\n",
      "\t\t\t\tDisc: 0.281690\t\tSpars: 0.117371\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 81 [4000/8000 (50%)]\tBatch Loss: 0.423820\tLearning Rate (w_theta): 0.000500\t TIME:300.8s\n",
      "\t\t\t\tDisc: 0.302438\t\tSpars: 0.121382\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 81...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40199550700673803\n",
      "Average validation loss: 0.3952181762472509\n",
      "Training epoch 82...\n",
      "\n",
      "Train Epoch: 82 [0/8000 (0%)]\tBatch Loss: 0.414019\tLearning Rate (w_theta): 0.000500\t TIME:303.0s\n",
      "\t\t\t\tDisc: 0.296026\t\tSpars: 0.117993\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 82 [4000/8000 (50%)]\tBatch Loss: 0.371694\tLearning Rate (w_theta): 0.000500\t TIME:304.5s\n",
      "\t\t\t\tDisc: 0.257954\t\tSpars: 0.113740\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 82...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40180681781694033\n",
      "Average validation loss: 0.39503161389330155\n",
      "Training epoch 83...\n",
      "\n",
      "Train Epoch: 83 [0/8000 (0%)]\tBatch Loss: 0.412932\tLearning Rate (w_theta): 0.000500\t TIME:306.7s\n",
      "\t\t\t\tDisc: 0.291768\t\tSpars: 0.121165\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 83 [4000/8000 (50%)]\tBatch Loss: 0.435825\tLearning Rate (w_theta): 0.000500\t TIME:308.1s\n",
      "\t\t\t\tDisc: 0.317358\t\tSpars: 0.118467\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 83...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40161202852063044\n",
      "Average validation loss: 0.39484280718157677\n",
      "Training epoch 84...\n",
      "\n",
      "Train Epoch: 84 [0/8000 (0%)]\tBatch Loss: 0.383513\tLearning Rate (w_theta): 0.000500\t TIME:310.3s\n",
      "\t\t\t\tDisc: 0.268263\t\tSpars: 0.115250\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 84 [4000/8000 (50%)]\tBatch Loss: 0.374524\tLearning Rate (w_theta): 0.000500\t TIME:311.7s\n",
      "\t\t\t\tDisc: 0.257991\t\tSpars: 0.116533\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 84...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4014138585445284\n",
      "Average validation loss: 0.3946516742084021\n",
      "Training epoch 85...\n",
      "\n",
      "Train Epoch: 85 [0/8000 (0%)]\tBatch Loss: 0.393430\tLearning Rate (w_theta): 0.000500\t TIME:314.0s\n",
      "\t\t\t\tDisc: 0.280810\t\tSpars: 0.112620\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 85 [4000/8000 (50%)]\tBatch Loss: 0.358776\tLearning Rate (w_theta): 0.000500\t TIME:315.4s\n",
      "\t\t\t\tDisc: 0.246165\t\tSpars: 0.112611\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 85...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4012140096347008\n",
      "Average validation loss: 0.39445673928816477\n",
      "Training epoch 86...\n",
      "\n",
      "Train Epoch: 86 [0/8000 (0%)]\tBatch Loss: 0.388934\tLearning Rate (w_theta): 0.000500\t TIME:317.6s\n",
      "\t\t\t\tDisc: 0.273782\t\tSpars: 0.115152\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 86 [4000/8000 (50%)]\tBatch Loss: 0.477741\tLearning Rate (w_theta): 0.000500\t TIME:319.0s\n",
      "\t\t\t\tDisc: 0.352617\t\tSpars: 0.125124\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 86...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4010104985260475\n",
      "Average validation loss: 0.3942580518157426\n",
      "Training epoch 87...\n",
      "\n",
      "Train Epoch: 87 [0/8000 (0%)]\tBatch Loss: 0.385324\tLearning Rate (w_theta): 0.000500\t TIME:321.3s\n",
      "\t\t\t\tDisc: 0.271125\t\tSpars: 0.114199\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 87 [4000/8000 (50%)]\tBatch Loss: 0.375632\tLearning Rate (w_theta): 0.000500\t TIME:322.7s\n",
      "\t\t\t\tDisc: 0.263494\t\tSpars: 0.112138\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 87...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4008019839672339\n",
      "Average validation loss: 0.3940566645760019\n",
      "Training epoch 88...\n",
      "\n",
      "Train Epoch: 88 [0/8000 (0%)]\tBatch Loss: 0.373914\tLearning Rate (w_theta): 0.000500\t TIME:324.9s\n",
      "\t\t\t\tDisc: 0.257781\t\tSpars: 0.116132\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 88 [4000/8000 (50%)]\tBatch Loss: 0.407284\tLearning Rate (w_theta): 0.000500\t TIME:326.3s\n",
      "\t\t\t\tDisc: 0.290023\t\tSpars: 0.117261\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 88...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.40059257191313\n",
      "Average validation loss: 0.3938503870153469\n",
      "Training epoch 89...\n",
      "\n",
      "Train Epoch: 89 [0/8000 (0%)]\tBatch Loss: 0.414020\tLearning Rate (w_theta): 0.000500\t TIME:328.5s\n",
      "\t\t\t\tDisc: 0.297451\t\tSpars: 0.116569\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 89 [4000/8000 (50%)]\tBatch Loss: 0.364468\tLearning Rate (w_theta): 0.000500\t TIME:330.0s\n",
      "\t\t\t\tDisc: 0.253809\t\tSpars: 0.110658\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 89...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4003773659909291\n",
      "Average validation loss: 0.39364070547166463\n",
      "Training epoch 90...\n",
      "\n",
      "Train Epoch: 90 [0/8000 (0%)]\tBatch Loss: 0.406958\tLearning Rate (w_theta): 0.000500\t TIME:332.2s\n",
      "\t\t\t\tDisc: 0.289422\t\tSpars: 0.117535\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 90 [4000/8000 (50%)]\tBatch Loss: 0.434853\tLearning Rate (w_theta): 0.000500\t TIME:333.6s\n",
      "\t\t\t\tDisc: 0.317012\t\tSpars: 0.117841\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 90...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.4001606322070012\n",
      "Average validation loss: 0.39342601419366624\n",
      "Training epoch 91...\n",
      "\n",
      "Train Epoch: 91 [0/8000 (0%)]\tBatch Loss: 0.416220\tLearning Rate (w_theta): 0.000500\t TIME:337.0s\n",
      "\t\t\t\tDisc: 0.297063\t\tSpars: 0.119157\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 91 [4000/8000 (50%)]\tBatch Loss: 0.406988\tLearning Rate (w_theta): 0.000500\t TIME:338.5s\n",
      "\t\t\t\tDisc: 0.287822\t\tSpars: 0.119166\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 91...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3999347525484804\n",
      "Average validation loss: 0.3932104100987924\n",
      "Training epoch 92...\n",
      "\n",
      "Train Epoch: 92 [0/8000 (0%)]\tBatch Loss: 0.369981\tLearning Rate (w_theta): 0.000500\t TIME:340.6s\n",
      "\t\t\t\tDisc: 0.256136\t\tSpars: 0.113845\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 92 [4000/8000 (50%)]\tBatch Loss: 0.363254\tLearning Rate (w_theta): 0.000500\t TIME:342.1s\n",
      "\t\t\t\tDisc: 0.248780\t\tSpars: 0.114474\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 92...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3997073676885645\n",
      "Average validation loss: 0.39299198715604966\n",
      "Training epoch 93...\n",
      "\n",
      "Train Epoch: 93 [0/8000 (0%)]\tBatch Loss: 0.389893\tLearning Rate (w_theta): 0.000500\t TIME:344.3s\n",
      "\t\t\t\tDisc: 0.277159\t\tSpars: 0.112734\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 93 [4000/8000 (50%)]\tBatch Loss: 0.394803\tLearning Rate (w_theta): 0.000500\t TIME:345.7s\n",
      "\t\t\t\tDisc: 0.278388\t\tSpars: 0.116415\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 93...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3994801205025927\n",
      "Average validation loss: 0.3927674302028935\n",
      "Training epoch 94...\n",
      "\n",
      "Train Epoch: 94 [0/8000 (0%)]\tBatch Loss: 0.403832\tLearning Rate (w_theta): 0.000500\t TIME:348.0s\n",
      "\t\t\t\tDisc: 0.285879\t\tSpars: 0.117953\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 94 [4000/8000 (50%)]\tBatch Loss: 0.377009\tLearning Rate (w_theta): 0.000500\t TIME:349.4s\n",
      "\t\t\t\tDisc: 0.263081\t\tSpars: 0.113928\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 94...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3992454285994287\n",
      "Average validation loss: 0.39253927451236775\n",
      "Training epoch 95...\n",
      "\n",
      "Train Epoch: 95 [0/8000 (0%)]\tBatch Loss: 0.408289\tLearning Rate (w_theta): 0.000500\t TIME:351.6s\n",
      "\t\t\t\tDisc: 0.292853\t\tSpars: 0.115436\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 95 [4000/8000 (50%)]\tBatch Loss: 0.394044\tLearning Rate (w_theta): 0.000500\t TIME:353.0s\n",
      "\t\t\t\tDisc: 0.279644\t\tSpars: 0.114400\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 95...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.39900533080203904\n",
      "Average validation loss: 0.3923083798761027\n",
      "Training epoch 96...\n",
      "\n",
      "Train Epoch: 96 [0/8000 (0%)]\tBatch Loss: 0.417661\tLearning Rate (w_theta): 0.000500\t TIME:355.2s\n",
      "\t\t\t\tDisc: 0.295331\t\tSpars: 0.122330\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 96 [4000/8000 (50%)]\tBatch Loss: 0.373401\tLearning Rate (w_theta): 0.000500\t TIME:356.6s\n",
      "\t\t\t\tDisc: 0.261866\t\tSpars: 0.111535\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 96...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3987688697527479\n",
      "Average validation loss: 0.39206855879690033\n",
      "Training epoch 97...\n",
      "\n",
      "Train Epoch: 97 [0/8000 (0%)]\tBatch Loss: 0.404849\tLearning Rate (w_theta): 0.000500\t TIME:358.8s\n",
      "\t\t\t\tDisc: 0.289118\t\tSpars: 0.115730\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 97 [4000/8000 (50%)]\tBatch Loss: 0.403442\tLearning Rate (w_theta): 0.000500\t TIME:360.3s\n",
      "\t\t\t\tDisc: 0.285220\t\tSpars: 0.118221\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 97...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3985160297766707\n",
      "Average validation loss: 0.391829090314619\n",
      "Training epoch 98...\n",
      "\n",
      "Train Epoch: 98 [0/8000 (0%)]\tBatch Loss: 0.409792\tLearning Rate (w_theta): 0.000500\t TIME:362.6s\n",
      "\t\t\t\tDisc: 0.294433\t\tSpars: 0.115359\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 98 [4000/8000 (50%)]\tBatch Loss: 0.398997\tLearning Rate (w_theta): 0.000500\t TIME:364.0s\n",
      "\t\t\t\tDisc: 0.283711\t\tSpars: 0.115286\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 98...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.39826637593772557\n",
      "Average validation loss: 0.3915837972745062\n",
      "Training epoch 99...\n",
      "\n",
      "Train Epoch: 99 [0/8000 (0%)]\tBatch Loss: 0.445667\tLearning Rate (w_theta): 0.000500\t TIME:366.2s\n",
      "\t\t\t\tDisc: 0.326583\t\tSpars: 0.119084\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 99 [4000/8000 (50%)]\tBatch Loss: 0.350989\tLearning Rate (w_theta): 0.000500\t TIME:367.6s\n",
      "\t\t\t\tDisc: 0.241675\t\tSpars: 0.109313\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 99...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3980095081801734\n",
      "Average validation loss: 0.3913351165307133\n",
      "Training epoch 100...\n",
      "\n",
      "Train Epoch: 100 [0/8000 (0%)]\tBatch Loss: 0.435048\tLearning Rate (w_theta): 0.000500\t TIME:369.8s\n",
      "\t\t\t\tDisc: 0.317993\t\tSpars: 0.117054\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 100 [4000/8000 (50%)]\tBatch Loss: 0.394947\tLearning Rate (w_theta): 0.000500\t TIME:371.3s\n",
      "\t\t\t\tDisc: 0.277914\t\tSpars: 0.117033\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 100...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.39774950634618544\n",
      "Average validation loss: 0.3910816746675815\n",
      "Training epoch 101...\n",
      "\n",
      "Train Epoch: 101 [0/8000 (0%)]\tBatch Loss: 0.356253\tLearning Rate (w_theta): 0.000500\t TIME:374.7s\n",
      "\t\t\t\tDisc: 0.244087\t\tSpars: 0.112166\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 101 [4000/8000 (50%)]\tBatch Loss: 0.385631\tLearning Rate (w_theta): 0.000500\t TIME:376.2s\n",
      "\t\t\t\tDisc: 0.269436\t\tSpars: 0.116195\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 101...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.39748331682379245\n",
      "Average validation loss: 0.39082474570246856\n",
      "Training epoch 102...\n",
      "\n",
      "Train Epoch: 102 [0/8000 (0%)]\tBatch Loss: 0.436975\tLearning Rate (w_theta): 0.000500\t TIME:378.5s\n",
      "\t\t\t\tDisc: 0.320623\t\tSpars: 0.116352\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 102 [4000/8000 (50%)]\tBatch Loss: 0.400923\tLearning Rate (w_theta): 0.000500\t TIME:379.9s\n",
      "\t\t\t\tDisc: 0.283743\t\tSpars: 0.117180\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 102...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3972186416419738\n",
      "Average validation loss: 0.39055926621998766\n",
      "Training epoch 103...\n",
      "\n",
      "Train Epoch: 103 [0/8000 (0%)]\tBatch Loss: 0.409910\tLearning Rate (w_theta): 0.000500\t TIME:382.1s\n",
      "\t\t\t\tDisc: 0.295520\t\tSpars: 0.114390\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 103 [4000/8000 (50%)]\tBatch Loss: 0.390407\tLearning Rate (w_theta): 0.000500\t TIME:383.5s\n",
      "\t\t\t\tDisc: 0.275363\t\tSpars: 0.115044\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 103...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.396941891446554\n",
      "Average validation loss: 0.3902907339907088\n",
      "Training epoch 104...\n",
      "\n",
      "Train Epoch: 104 [0/8000 (0%)]\tBatch Loss: 0.392508\tLearning Rate (w_theta): 0.000500\t TIME:385.7s\n",
      "\t\t\t\tDisc: 0.277716\t\tSpars: 0.114792\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 104 [4000/8000 (50%)]\tBatch Loss: 0.410307\tLearning Rate (w_theta): 0.000500\t TIME:387.2s\n",
      "\t\t\t\tDisc: 0.291228\t\tSpars: 0.119078\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 104...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3966607712911603\n",
      "Average validation loss: 0.3900186063567625\n",
      "Training epoch 105...\n",
      "\n",
      "Train Epoch: 105 [0/8000 (0%)]\tBatch Loss: 0.441038\tLearning Rate (w_theta): 0.000500\t TIME:389.4s\n",
      "\t\t\t\tDisc: 0.324396\t\tSpars: 0.116641\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 105 [4000/8000 (50%)]\tBatch Loss: 0.375947\tLearning Rate (w_theta): 0.000500\t TIME:390.9s\n",
      "\t\t\t\tDisc: 0.261117\t\tSpars: 0.114830\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 105...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.396378528949938\n",
      "Average validation loss: 0.38973962513697413\n",
      "Training epoch 106...\n",
      "\n",
      "Train Epoch: 106 [0/8000 (0%)]\tBatch Loss: 0.387941\tLearning Rate (w_theta): 0.000500\t TIME:393.2s\n",
      "\t\t\t\tDisc: 0.275594\t\tSpars: 0.112347\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 106 [4000/8000 (50%)]\tBatch Loss: 0.429089\tLearning Rate (w_theta): 0.000500\t TIME:394.6s\n",
      "\t\t\t\tDisc: 0.308721\t\tSpars: 0.120369\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 106...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.39608520925538476\n",
      "Average validation loss: 0.3894584851938233\n",
      "Training epoch 107...\n",
      "\n",
      "Train Epoch: 107 [0/8000 (0%)]\tBatch Loss: 0.419088\tLearning Rate (w_theta): 0.000500\t TIME:396.8s\n",
      "\t\t\t\tDisc: 0.303716\t\tSpars: 0.115372\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 107 [4000/8000 (50%)]\tBatch Loss: 0.393513\tLearning Rate (w_theta): 0.000500\t TIME:398.3s\n",
      "\t\t\t\tDisc: 0.274452\t\tSpars: 0.119061\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 107...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.39579122559498336\n",
      "Average validation loss: 0.3891714577563574\n",
      "Training epoch 108...\n",
      "\n",
      "Train Epoch: 108 [0/8000 (0%)]\tBatch Loss: 0.376689\tLearning Rate (w_theta): 0.000500\t TIME:400.5s\n",
      "\t\t\t\tDisc: 0.264543\t\tSpars: 0.112146\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 108 [4000/8000 (50%)]\tBatch Loss: 0.418084\tLearning Rate (w_theta): 0.000500\t TIME:402.0s\n",
      "\t\t\t\tDisc: 0.299368\t\tSpars: 0.118716\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 108...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.39548999041748406\n",
      "Average validation loss: 0.38887997600622826\n",
      "Training epoch 109...\n",
      "\n",
      "Train Epoch: 109 [0/8000 (0%)]\tBatch Loss: 0.410763\tLearning Rate (w_theta): 0.000500\t TIME:404.2s\n",
      "\t\t\t\tDisc: 0.293857\t\tSpars: 0.116906\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 109 [4000/8000 (50%)]\tBatch Loss: 0.336088\tLearning Rate (w_theta): 0.000500\t TIME:405.7s\n",
      "\t\t\t\tDisc: 0.227402\t\tSpars: 0.108685\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 109...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3951859028227567\n",
      "Average validation loss: 0.3885818878159832\n",
      "Training epoch 110...\n",
      "\n",
      "Train Epoch: 110 [0/8000 (0%)]\tBatch Loss: 0.393052\tLearning Rate (w_theta): 0.000500\t TIME:407.9s\n",
      "\t\t\t\tDisc: 0.278858\t\tSpars: 0.114194\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 110 [4000/8000 (50%)]\tBatch Loss: 0.373928\tLearning Rate (w_theta): 0.000500\t TIME:409.3s\n",
      "\t\t\t\tDisc: 0.261464\t\tSpars: 0.112463\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 110...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.39487513400578494\n",
      "Average validation loss: 0.38827740527315824\n",
      "Training epoch 111...\n",
      "\n",
      "Train Epoch: 111 [0/8000 (0%)]\tBatch Loss: 0.371361\tLearning Rate (w_theta): 0.000500\t TIME:412.8s\n",
      "\t\t\t\tDisc: 0.256404\t\tSpars: 0.114957\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 111 [4000/8000 (50%)]\tBatch Loss: 0.405623\tLearning Rate (w_theta): 0.000500\t TIME:414.3s\n",
      "\t\t\t\tDisc: 0.289550\t\tSpars: 0.116073\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 111...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3945587481748825\n",
      "Average validation loss: 0.38796677728860224\n",
      "Training epoch 112...\n",
      "\n",
      "Train Epoch: 112 [0/8000 (0%)]\tBatch Loss: 0.380507\tLearning Rate (w_theta): 0.000500\t TIME:416.5s\n",
      "\t\t\t\tDisc: 0.267120\t\tSpars: 0.113387\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 112 [4000/8000 (50%)]\tBatch Loss: 0.376780\tLearning Rate (w_theta): 0.000500\t TIME:418.0s\n",
      "\t\t\t\tDisc: 0.263226\t\tSpars: 0.113554\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 112...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3942339159587491\n",
      "Average validation loss: 0.3876519581971781\n",
      "Training epoch 113...\n",
      "\n",
      "Train Epoch: 113 [0/8000 (0%)]\tBatch Loss: 0.394192\tLearning Rate (w_theta): 0.000500\t TIME:420.3s\n",
      "\t\t\t\tDisc: 0.277747\t\tSpars: 0.116445\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 113 [4000/8000 (50%)]\tBatch Loss: 0.404593\tLearning Rate (w_theta): 0.000500\t TIME:421.7s\n",
      "\t\t\t\tDisc: 0.289402\t\tSpars: 0.115191\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 113...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.39390437408792833\n",
      "Average validation loss: 0.3873319543944055\n",
      "Training epoch 114...\n",
      "\n",
      "Train Epoch: 114 [0/8000 (0%)]\tBatch Loss: 0.364168\tLearning Rate (w_theta): 0.000500\t TIME:423.9s\n",
      "\t\t\t\tDisc: 0.253033\t\tSpars: 0.111135\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 114 [4000/8000 (50%)]\tBatch Loss: 0.407144\tLearning Rate (w_theta): 0.000500\t TIME:425.4s\n",
      "\t\t\t\tDisc: 0.290977\t\tSpars: 0.116167\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 114...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.39357087378777594\n",
      "Average validation loss: 0.3870049625465021\n",
      "Training epoch 115...\n",
      "\n",
      "Train Epoch: 115 [0/8000 (0%)]\tBatch Loss: 0.381196\tLearning Rate (w_theta): 0.000500\t TIME:427.6s\n",
      "\t\t\t\tDisc: 0.264344\t\tSpars: 0.116852\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 115 [4000/8000 (50%)]\tBatch Loss: 0.376748\tLearning Rate (w_theta): 0.000500\t TIME:429.0s\n",
      "\t\t\t\tDisc: 0.263292\t\tSpars: 0.113456\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 115...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3932318890755908\n",
      "Average validation loss: 0.3866703120966569\n",
      "Training epoch 116...\n",
      "\n",
      "Train Epoch: 116 [0/8000 (0%)]\tBatch Loss: 0.403858\tLearning Rate (w_theta): 0.000500\t TIME:431.2s\n",
      "\t\t\t\tDisc: 0.289288\t\tSpars: 0.114570\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 116 [4000/8000 (50%)]\tBatch Loss: 0.379105\tLearning Rate (w_theta): 0.000500\t TIME:432.7s\n",
      "\t\t\t\tDisc: 0.264022\t\tSpars: 0.115083\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 116...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3928862414879213\n",
      "Average validation loss: 0.38632818386861134\n",
      "Training epoch 117...\n",
      "\n",
      "Train Epoch: 117 [0/8000 (0%)]\tBatch Loss: 0.391026\tLearning Rate (w_theta): 0.000500\t TIME:434.8s\n",
      "\t\t\t\tDisc: 0.276817\t\tSpars: 0.114209\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 117 [4000/8000 (50%)]\tBatch Loss: 0.348730\tLearning Rate (w_theta): 0.000500\t TIME:436.3s\n",
      "\t\t\t\tDisc: 0.240099\t\tSpars: 0.108631\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 117...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3925259259057796\n",
      "Average validation loss: 0.3859848435154114\n",
      "Training epoch 118...\n",
      "\n",
      "Train Epoch: 118 [0/8000 (0%)]\tBatch Loss: 0.385642\tLearning Rate (w_theta): 0.000500\t TIME:438.5s\n",
      "\t\t\t\tDisc: 0.270380\t\tSpars: 0.115261\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 118 [4000/8000 (50%)]\tBatch Loss: 0.369460\tLearning Rate (w_theta): 0.000500\t TIME:440.0s\n",
      "\t\t\t\tDisc: 0.258062\t\tSpars: 0.111397\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 118...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3921661869265199\n",
      "Average validation loss: 0.3856344753685198\n",
      "Training epoch 119...\n",
      "\n",
      "Train Epoch: 119 [0/8000 (0%)]\tBatch Loss: 0.408167\tLearning Rate (w_theta): 0.000500\t TIME:442.3s\n",
      "\t\t\t\tDisc: 0.288820\t\tSpars: 0.119347\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 119 [4000/8000 (50%)]\tBatch Loss: 0.420499\tLearning Rate (w_theta): 0.000500\t TIME:443.7s\n",
      "\t\t\t\tDisc: 0.297339\t\tSpars: 0.123160\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 119...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3918061097468079\n",
      "Average validation loss: 0.3852718046266889\n",
      "Training epoch 120...\n",
      "\n",
      "Train Epoch: 120 [0/8000 (0%)]\tBatch Loss: 0.411387\tLearning Rate (w_theta): 0.000500\t TIME:445.9s\n",
      "\t\t\t\tDisc: 0.294652\t\tSpars: 0.116735\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 120 [4000/8000 (50%)]\tBatch Loss: 0.420753\tLearning Rate (w_theta): 0.000500\t TIME:447.3s\n",
      "\t\t\t\tDisc: 0.303359\t\tSpars: 0.117394\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 120...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3914267807831954\n",
      "Average validation loss: 0.3849064631112218\n",
      "Training epoch 121...\n",
      "\n",
      "Train Epoch: 121 [0/8000 (0%)]\tBatch Loss: 0.408611\tLearning Rate (w_theta): 0.000500\t TIME:450.9s\n",
      "\t\t\t\tDisc: 0.293313\t\tSpars: 0.115298\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 121 [4000/8000 (50%)]\tBatch Loss: 0.415418\tLearning Rate (w_theta): 0.000500\t TIME:452.4s\n",
      "\t\t\t\tDisc: 0.294629\t\tSpars: 0.120789\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 121...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.39104899524697484\n",
      "Average validation loss: 0.38453188046528486\n",
      "Training epoch 122...\n",
      "\n",
      "Train Epoch: 122 [0/8000 (0%)]\tBatch Loss: 0.412626\tLearning Rate (w_theta): 0.000500\t TIME:454.5s\n",
      "\t\t\t\tDisc: 0.297736\t\tSpars: 0.114890\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 122 [4000/8000 (50%)]\tBatch Loss: 0.400380\tLearning Rate (w_theta): 0.000500\t TIME:456.0s\n",
      "\t\t\t\tDisc: 0.284540\t\tSpars: 0.115840\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 122...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.390657126837552\n",
      "Average validation loss: 0.3841533090978296\n",
      "Training epoch 123...\n",
      "\n",
      "Train Epoch: 123 [0/8000 (0%)]\tBatch Loss: 0.392062\tLearning Rate (w_theta): 0.000500\t TIME:458.3s\n",
      "\t\t\t\tDisc: 0.273570\t\tSpars: 0.118492\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 123 [4000/8000 (50%)]\tBatch Loss: 0.411078\tLearning Rate (w_theta): 0.000500\t TIME:459.8s\n",
      "\t\t\t\tDisc: 0.296052\t\tSpars: 0.115026\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 123...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3902609165826107\n",
      "Average validation loss: 0.38376840720989475\n",
      "Training epoch 124...\n",
      "\n",
      "Train Epoch: 124 [0/8000 (0%)]\tBatch Loss: 0.433638\tLearning Rate (w_theta): 0.000500\t TIME:461.9s\n",
      "\t\t\t\tDisc: 0.314403\t\tSpars: 0.119235\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 124 [4000/8000 (50%)]\tBatch Loss: 0.398420\tLearning Rate (w_theta): 0.000500\t TIME:463.4s\n",
      "\t\t\t\tDisc: 0.281367\t\tSpars: 0.117053\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 124...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3898643288496096\n",
      "Average validation loss: 0.3833711337667985\n",
      "Training epoch 125...\n",
      "\n",
      "Train Epoch: 125 [0/8000 (0%)]\tBatch Loss: 0.368438\tLearning Rate (w_theta): 0.000500\t TIME:465.7s\n",
      "\t\t\t\tDisc: 0.255084\t\tSpars: 0.113353\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 125 [4000/8000 (50%)]\tBatch Loss: 0.393807\tLearning Rate (w_theta): 0.000500\t TIME:467.1s\n",
      "\t\t\t\tDisc: 0.277606\t\tSpars: 0.116201\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 125...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3894444508712857\n",
      "Average validation loss: 0.3829736430707393\n",
      "Training epoch 126...\n",
      "\n",
      "Train Epoch: 126 [0/8000 (0%)]\tBatch Loss: 0.402151\tLearning Rate (w_theta): 0.000500\t TIME:469.4s\n",
      "\t\t\t\tDisc: 0.288043\t\tSpars: 0.114108\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 126 [4000/8000 (50%)]\tBatch Loss: 0.401705\tLearning Rate (w_theta): 0.000500\t TIME:470.8s\n",
      "\t\t\t\tDisc: 0.286147\t\tSpars: 0.115558\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 126...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3890293441985438\n",
      "Average validation loss: 0.3825658320701874\n",
      "Training epoch 127...\n",
      "\n",
      "Train Epoch: 127 [0/8000 (0%)]\tBatch Loss: 0.405979\tLearning Rate (w_theta): 0.000500\t TIME:473.0s\n",
      "\t\t\t\tDisc: 0.284214\t\tSpars: 0.121765\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 127 [4000/8000 (50%)]\tBatch Loss: 0.385144\tLearning Rate (w_theta): 0.000500\t TIME:474.5s\n",
      "\t\t\t\tDisc: 0.272953\t\tSpars: 0.112191\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 127...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.38860733180558105\n",
      "Average validation loss: 0.3821467871884832\n",
      "Training epoch 128...\n",
      "\n",
      "Train Epoch: 128 [0/8000 (0%)]\tBatch Loss: 0.403433\tLearning Rate (w_theta): 0.000500\t TIME:476.7s\n",
      "\t\t\t\tDisc: 0.287448\t\tSpars: 0.115986\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 128 [4000/8000 (50%)]\tBatch Loss: 0.393956\tLearning Rate (w_theta): 0.000500\t TIME:478.1s\n",
      "\t\t\t\tDisc: 0.274265\t\tSpars: 0.119691\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 128...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.38817342171965724\n",
      "Average validation loss: 0.38171944182125883\n",
      "Training epoch 129...\n",
      "\n",
      "Train Epoch: 129 [0/8000 (0%)]\tBatch Loss: 0.389333\tLearning Rate (w_theta): 0.000500\t TIME:480.3s\n",
      "\t\t\t\tDisc: 0.273793\t\tSpars: 0.115539\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 129 [4000/8000 (50%)]\tBatch Loss: 0.405815\tLearning Rate (w_theta): 0.000500\t TIME:481.8s\n",
      "\t\t\t\tDisc: 0.291130\t\tSpars: 0.114685\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 129...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.38772078412773564\n",
      "Average validation loss: 0.38129163088551116\n",
      "Training epoch 130...\n",
      "\n",
      "Train Epoch: 130 [0/8000 (0%)]\tBatch Loss: 0.340852\tLearning Rate (w_theta): 0.000500\t TIME:484.0s\n",
      "\t\t\t\tDisc: 0.230343\t\tSpars: 0.110509\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 130 [4000/8000 (50%)]\tBatch Loss: 0.363551\tLearning Rate (w_theta): 0.000500\t TIME:485.5s\n",
      "\t\t\t\tDisc: 0.250371\t\tSpars: 0.113180\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 130...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.38727080428003163\n",
      "Average validation loss: 0.3808547436428213\n",
      "Training epoch 131...\n",
      "\n",
      "Train Epoch: 131 [0/8000 (0%)]\tBatch Loss: 0.389986\tLearning Rate (w_theta): 0.000500\t TIME:488.9s\n",
      "\t\t\t\tDisc: 0.272355\t\tSpars: 0.117631\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 131 [4000/8000 (50%)]\tBatch Loss: 0.357091\tLearning Rate (w_theta): 0.000500\t TIME:490.4s\n",
      "\t\t\t\tDisc: 0.245279\t\tSpars: 0.111812\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 131...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.38681794897016697\n",
      "Average validation loss: 0.38040398388584057\n",
      "Training epoch 132...\n",
      "\n",
      "Train Epoch: 132 [0/8000 (0%)]\tBatch Loss: 0.406184\tLearning Rate (w_theta): 0.000500\t TIME:492.5s\n",
      "\t\t\t\tDisc: 0.289925\t\tSpars: 0.116259\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 132 [4000/8000 (50%)]\tBatch Loss: 0.358864\tLearning Rate (w_theta): 0.000500\t TIME:494.0s\n",
      "\t\t\t\tDisc: 0.246884\t\tSpars: 0.111979\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 132...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.38634892055728826\n",
      "Average validation loss: 0.379945225708589\n",
      "Training epoch 133...\n",
      "\n",
      "Train Epoch: 133 [0/8000 (0%)]\tBatch Loss: 0.375976\tLearning Rate (w_theta): 0.000500\t TIME:496.2s\n",
      "\t\t\t\tDisc: 0.264138\t\tSpars: 0.111839\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 133 [4000/8000 (50%)]\tBatch Loss: 0.345836\tLearning Rate (w_theta): 0.000500\t TIME:497.7s\n",
      "\t\t\t\tDisc: 0.232484\t\tSpars: 0.113351\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 133...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3858678251962577\n",
      "Average validation loss: 0.37948068122392653\n",
      "Training epoch 134...\n",
      "\n",
      "Train Epoch: 134 [0/8000 (0%)]\tBatch Loss: 0.385128\tLearning Rate (w_theta): 0.000500\t TIME:499.9s\n",
      "\t\t\t\tDisc: 0.267554\t\tSpars: 0.117573\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 134 [4000/8000 (50%)]\tBatch Loss: 0.407020\tLearning Rate (w_theta): 0.000500\t TIME:501.4s\n",
      "\t\t\t\tDisc: 0.287285\t\tSpars: 0.119735\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 134...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3853823940995993\n",
      "Average validation loss: 0.3790062768808385\n",
      "Training epoch 135...\n",
      "\n",
      "Train Epoch: 135 [0/8000 (0%)]\tBatch Loss: 0.423978\tLearning Rate (w_theta): 0.000500\t TIME:503.5s\n",
      "\t\t\t\tDisc: 0.298945\t\tSpars: 0.125033\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 135 [4000/8000 (50%)]\tBatch Loss: 0.378663\tLearning Rate (w_theta): 0.000500\t TIME:505.0s\n",
      "\t\t\t\tDisc: 0.260389\t\tSpars: 0.118274\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 135...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3848895595298993\n",
      "Average validation loss: 0.37852017407571936\n",
      "Training epoch 136...\n",
      "\n",
      "Train Epoch: 136 [0/8000 (0%)]\tBatch Loss: 0.395814\tLearning Rate (w_theta): 0.000500\t TIME:507.2s\n",
      "\t\t\t\tDisc: 0.280465\t\tSpars: 0.115349\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 136 [4000/8000 (50%)]\tBatch Loss: 0.363002\tLearning Rate (w_theta): 0.000500\t TIME:508.7s\n",
      "\t\t\t\tDisc: 0.248200\t\tSpars: 0.114802\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 136...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3843847618590379\n",
      "Average validation loss: 0.3780240588180702\n",
      "Training epoch 137...\n",
      "\n",
      "Train Epoch: 137 [0/8000 (0%)]\tBatch Loss: 0.374560\tLearning Rate (w_theta): 0.000500\t TIME:510.9s\n",
      "\t\t\t\tDisc: 0.262154\t\tSpars: 0.112406\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 137 [4000/8000 (50%)]\tBatch Loss: 0.386916\tLearning Rate (w_theta): 0.000500\t TIME:512.3s\n",
      "\t\t\t\tDisc: 0.270248\t\tSpars: 0.116668\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 137...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3838633857075137\n",
      "Average validation loss: 0.3775230220103912\n",
      "Training epoch 138...\n",
      "\n",
      "Train Epoch: 138 [0/8000 (0%)]\tBatch Loss: 0.360703\tLearning Rate (w_theta): 0.000500\t TIME:514.6s\n",
      "\t\t\t\tDisc: 0.243842\t\tSpars: 0.116861\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 138 [4000/8000 (50%)]\tBatch Loss: 0.389863\tLearning Rate (w_theta): 0.000500\t TIME:516.1s\n",
      "\t\t\t\tDisc: 0.274623\t\tSpars: 0.115239\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 138...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.38333992012962553\n",
      "Average validation loss: 0.3770108854708228\n",
      "Training epoch 139...\n",
      "\n",
      "Train Epoch: 139 [0/8000 (0%)]\tBatch Loss: 0.388936\tLearning Rate (w_theta): 0.000500\t TIME:518.3s\n",
      "\t\t\t\tDisc: 0.272300\t\tSpars: 0.116636\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 139 [4000/8000 (50%)]\tBatch Loss: 0.355824\tLearning Rate (w_theta): 0.000500\t TIME:519.8s\n",
      "\t\t\t\tDisc: 0.243693\t\tSpars: 0.112132\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 139...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3828083239078879\n",
      "Average validation loss: 0.3764856734635793\n",
      "Training epoch 140...\n",
      "\n",
      "Train Epoch: 140 [0/8000 (0%)]\tBatch Loss: 0.374505\tLearning Rate (w_theta): 0.000500\t TIME:522.0s\n",
      "\t\t\t\tDisc: 0.259561\t\tSpars: 0.114944\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 140 [4000/8000 (50%)]\tBatch Loss: 0.381634\tLearning Rate (w_theta): 0.000500\t TIME:523.5s\n",
      "\t\t\t\tDisc: 0.266064\t\tSpars: 0.115569\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 140...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3822537668144126\n",
      "Average validation loss: 0.37595678986016\n",
      "Training epoch 141...\n",
      "\n",
      "Train Epoch: 141 [0/8000 (0%)]\tBatch Loss: 0.387729\tLearning Rate (w_theta): 0.000500\t TIME:526.9s\n",
      "\t\t\t\tDisc: 0.273789\t\tSpars: 0.113940\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 141 [4000/8000 (50%)]\tBatch Loss: 0.340771\tLearning Rate (w_theta): 0.000500\t TIME:528.4s\n",
      "\t\t\t\tDisc: 0.230634\t\tSpars: 0.110137\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 141...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.381706185954639\n",
      "Average validation loss: 0.3754104773985439\n",
      "Training epoch 142...\n",
      "\n",
      "Train Epoch: 142 [0/8000 (0%)]\tBatch Loss: 0.352068\tLearning Rate (w_theta): 0.000500\t TIME:530.6s\n",
      "\t\t\t\tDisc: 0.238277\t\tSpars: 0.113791\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 142 [4000/8000 (50%)]\tBatch Loss: 0.387013\tLearning Rate (w_theta): 0.000500\t TIME:532.1s\n",
      "\t\t\t\tDisc: 0.272113\t\tSpars: 0.114899\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 142...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3811325066884517\n",
      "Average validation loss: 0.3748580137661694\n",
      "Training epoch 143...\n",
      "\n",
      "Train Epoch: 143 [0/8000 (0%)]\tBatch Loss: 0.392127\tLearning Rate (w_theta): 0.000500\t TIME:534.3s\n",
      "\t\t\t\tDisc: 0.275676\t\tSpars: 0.116450\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 143 [4000/8000 (50%)]\tBatch Loss: 0.378707\tLearning Rate (w_theta): 0.000500\t TIME:535.7s\n",
      "\t\t\t\tDisc: 0.262137\t\tSpars: 0.116570\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 143...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3805569868792025\n",
      "Average validation loss: 0.3742920676013855\n",
      "Training epoch 144...\n",
      "\n",
      "Train Epoch: 144 [0/8000 (0%)]\tBatch Loss: 0.403960\tLearning Rate (w_theta): 0.000500\t TIME:538.0s\n",
      "\t\t\t\tDisc: 0.283698\t\tSpars: 0.120263\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 144 [4000/8000 (50%)]\tBatch Loss: 0.403005\tLearning Rate (w_theta): 0.000500\t TIME:539.5s\n",
      "\t\t\t\tDisc: 0.287054\t\tSpars: 0.115951\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 144...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.37996417507759883\n",
      "Average validation loss: 0.3737170329858957\n",
      "Training epoch 145...\n",
      "\n",
      "Train Epoch: 145 [0/8000 (0%)]\tBatch Loss: 0.381046\tLearning Rate (w_theta): 0.000500\t TIME:541.7s\n",
      "\t\t\t\tDisc: 0.266355\t\tSpars: 0.114691\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 145 [4000/8000 (50%)]\tBatch Loss: 0.362859\tLearning Rate (w_theta): 0.000500\t TIME:543.2s\n",
      "\t\t\t\tDisc: 0.250760\t\tSpars: 0.112099\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 145...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.37935476636805465\n",
      "Average validation loss: 0.3731366842167099\n",
      "Training epoch 146...\n",
      "\n",
      "Train Epoch: 146 [0/8000 (0%)]\tBatch Loss: 0.396615\tLearning Rate (w_theta): 0.000500\t TIME:545.4s\n",
      "\t\t\t\tDisc: 0.279561\t\tSpars: 0.117054\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 146 [4000/8000 (50%)]\tBatch Loss: 0.372756\tLearning Rate (w_theta): 0.000500\t TIME:546.8s\n",
      "\t\t\t\tDisc: 0.261412\t\tSpars: 0.111344\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 146...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.37875126739974235\n",
      "Average validation loss: 0.3725360397724652\n",
      "Training epoch 147...\n",
      "\n",
      "Train Epoch: 147 [0/8000 (0%)]\tBatch Loss: 0.398473\tLearning Rate (w_theta): 0.000500\t TIME:549.1s\n",
      "\t\t\t\tDisc: 0.280471\t\tSpars: 0.118002\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 147 [4000/8000 (50%)]\tBatch Loss: 0.383874\tLearning Rate (w_theta): 0.000500\t TIME:550.6s\n",
      "\t\t\t\tDisc: 0.265469\t\tSpars: 0.118405\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 147...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.37811993441796726\n",
      "Average validation loss: 0.3719270084822516\n",
      "Training epoch 148...\n",
      "\n",
      "Train Epoch: 148 [0/8000 (0%)]\tBatch Loss: 0.348697\tLearning Rate (w_theta): 0.000500\t TIME:552.8s\n",
      "\t\t\t\tDisc: 0.236645\t\tSpars: 0.112052\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 148 [4000/8000 (50%)]\tBatch Loss: 0.378613\tLearning Rate (w_theta): 0.000500\t TIME:554.3s\n",
      "\t\t\t\tDisc: 0.264306\t\tSpars: 0.114306\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 148...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.37747782023540094\n",
      "Average validation loss: 0.37130804131276945\n",
      "Training epoch 149...\n",
      "\n",
      "Train Epoch: 149 [0/8000 (0%)]\tBatch Loss: 0.384031\tLearning Rate (w_theta): 0.000500\t TIME:556.5s\n",
      "\t\t\t\tDisc: 0.267157\t\tSpars: 0.116874\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 149 [4000/8000 (50%)]\tBatch Loss: 0.390330\tLearning Rate (w_theta): 0.000500\t TIME:558.0s\n",
      "\t\t\t\tDisc: 0.273412\t\tSpars: 0.116918\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 149...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3768249321589276\n",
      "Average validation loss: 0.3706773762975733\n",
      "Training epoch 150...\n",
      "\n",
      "Train Epoch: 150 [0/8000 (0%)]\tBatch Loss: 0.376608\tLearning Rate (w_theta): 0.000500\t TIME:560.2s\n",
      "\t\t\t\tDisc: 0.262285\t\tSpars: 0.114323\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 150 [4000/8000 (50%)]\tBatch Loss: 0.367061\tLearning Rate (w_theta): 0.000500\t TIME:561.6s\n",
      "\t\t\t\tDisc: 0.257583\t\tSpars: 0.109478\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 150...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.37616549526144905\n",
      "Average validation loss: 0.3700301815279534\n",
      "Training epoch 151...\n",
      "\n",
      "Train Epoch: 151 [0/8000 (0%)]\tBatch Loss: 0.362739\tLearning Rate (w_theta): 0.000500\t TIME:565.2s\n",
      "\t\t\t\tDisc: 0.249428\t\tSpars: 0.113311\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 151 [4000/8000 (50%)]\tBatch Loss: 0.392192\tLearning Rate (w_theta): 0.000500\t TIME:566.6s\n",
      "\t\t\t\tDisc: 0.276276\t\tSpars: 0.115917\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 151...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3754873742009003\n",
      "Average validation loss: 0.36937071754221823\n",
      "Training epoch 152...\n",
      "\n",
      "Train Epoch: 152 [0/8000 (0%)]\tBatch Loss: 0.337899\tLearning Rate (w_theta): 0.000500\t TIME:568.8s\n",
      "\t\t\t\tDisc: 0.224002\t\tSpars: 0.113897\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 152 [4000/8000 (50%)]\tBatch Loss: 0.351653\tLearning Rate (w_theta): 0.000500\t TIME:570.3s\n",
      "\t\t\t\tDisc: 0.238459\t\tSpars: 0.113194\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 152...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.37480205442146175\n",
      "Average validation loss: 0.3686937437105169\n",
      "Training epoch 153...\n",
      "\n",
      "Train Epoch: 153 [0/8000 (0%)]\tBatch Loss: 0.392851\tLearning Rate (w_theta): 0.000500\t TIME:572.6s\n",
      "\t\t\t\tDisc: 0.276200\t\tSpars: 0.116651\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 153 [4000/8000 (50%)]\tBatch Loss: 0.340946\tLearning Rate (w_theta): 0.000500\t TIME:574.0s\n",
      "\t\t\t\tDisc: 0.228615\t\tSpars: 0.112331\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 153...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3740984004157434\n",
      "Average validation loss: 0.36800247175184814\n",
      "Training epoch 154...\n",
      "\n",
      "Train Epoch: 154 [0/8000 (0%)]\tBatch Loss: 0.368650\tLearning Rate (w_theta): 0.000500\t TIME:576.2s\n",
      "\t\t\t\tDisc: 0.254215\t\tSpars: 0.114435\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 154 [4000/8000 (50%)]\tBatch Loss: 0.361629\tLearning Rate (w_theta): 0.000500\t TIME:577.7s\n",
      "\t\t\t\tDisc: 0.249024\t\tSpars: 0.112606\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 154...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3733660272950769\n",
      "Average validation loss: 0.3673082164535261\n",
      "Training epoch 155...\n",
      "\n",
      "Train Epoch: 155 [0/8000 (0%)]\tBatch Loss: 0.374381\tLearning Rate (w_theta): 0.000500\t TIME:580.0s\n",
      "\t\t\t\tDisc: 0.259949\t\tSpars: 0.114432\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 155 [4000/8000 (50%)]\tBatch Loss: 0.394333\tLearning Rate (w_theta): 0.000500\t TIME:581.5s\n",
      "\t\t\t\tDisc: 0.278579\t\tSpars: 0.115754\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 155...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.37264306768884214\n",
      "Average validation loss: 0.36659289091873026\n",
      "Training epoch 156...\n",
      "\n",
      "Train Epoch: 156 [0/8000 (0%)]\tBatch Loss: 0.334394\tLearning Rate (w_theta): 0.000500\t TIME:583.7s\n",
      "\t\t\t\tDisc: 0.223189\t\tSpars: 0.111206\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 156 [4000/8000 (50%)]\tBatch Loss: 0.372487\tLearning Rate (w_theta): 0.000500\t TIME:585.1s\n",
      "\t\t\t\tDisc: 0.257029\t\tSpars: 0.115458\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 156...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.37188876955553063\n",
      "Average validation loss: 0.3658687639754685\n",
      "Training epoch 157...\n",
      "\n",
      "Train Epoch: 157 [0/8000 (0%)]\tBatch Loss: 0.358057\tLearning Rate (w_theta): 0.000500\t TIME:587.4s\n",
      "\t\t\t\tDisc: 0.247123\t\tSpars: 0.110934\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 157 [4000/8000 (50%)]\tBatch Loss: 0.371145\tLearning Rate (w_theta): 0.000500\t TIME:588.8s\n",
      "\t\t\t\tDisc: 0.255150\t\tSpars: 0.115995\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 157...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.37112794605702587\n",
      "Average validation loss: 0.3651295552949278\n",
      "Training epoch 158...\n",
      "\n",
      "Train Epoch: 158 [0/8000 (0%)]\tBatch Loss: 0.355983\tLearning Rate (w_theta): 0.000500\t TIME:591.0s\n",
      "\t\t\t\tDisc: 0.239783\t\tSpars: 0.116200\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 158 [4000/8000 (50%)]\tBatch Loss: 0.388424\tLearning Rate (w_theta): 0.000500\t TIME:592.5s\n",
      "\t\t\t\tDisc: 0.272083\t\tSpars: 0.116341\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 158...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3703530872193391\n",
      "Average validation loss: 0.3643743288047242\n",
      "Training epoch 159...\n",
      "\n",
      "Train Epoch: 159 [0/8000 (0%)]\tBatch Loss: 0.353739\tLearning Rate (w_theta): 0.000500\t TIME:594.7s\n",
      "\t\t\t\tDisc: 0.241466\t\tSpars: 0.112274\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 159 [4000/8000 (50%)]\tBatch Loss: 0.388064\tLearning Rate (w_theta): 0.000500\t TIME:596.2s\n",
      "\t\t\t\tDisc: 0.274187\t\tSpars: 0.113877\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 159...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.36956038948407965\n",
      "Average validation loss: 0.3636048031187562\n",
      "Training epoch 160...\n",
      "\n",
      "Train Epoch: 160 [0/8000 (0%)]\tBatch Loss: 0.355389\tLearning Rate (w_theta): 0.000500\t TIME:598.4s\n",
      "\t\t\t\tDisc: 0.240863\t\tSpars: 0.114527\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 160 [4000/8000 (50%)]\tBatch Loss: 0.389004\tLearning Rate (w_theta): 0.000500\t TIME:599.9s\n",
      "\t\t\t\tDisc: 0.271761\t\tSpars: 0.117243\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 160...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3687541687757235\n",
      "Average validation loss: 0.36282048646142645\n",
      "Training epoch 161...\n",
      "\n",
      "Train Epoch: 161 [0/8000 (0%)]\tBatch Loss: 0.370891\tLearning Rate (w_theta): 0.000500\t TIME:603.4s\n",
      "\t\t\t\tDisc: 0.257911\t\tSpars: 0.112980\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 161 [4000/8000 (50%)]\tBatch Loss: 0.369084\tLearning Rate (w_theta): 0.000500\t TIME:604.8s\n",
      "\t\t\t\tDisc: 0.253002\t\tSpars: 0.116083\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 161...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3679386303233354\n",
      "Average validation loss: 0.36201696107545567\n",
      "Training epoch 162...\n",
      "\n",
      "Train Epoch: 162 [0/8000 (0%)]\tBatch Loss: 0.371070\tLearning Rate (w_theta): 0.000500\t TIME:607.0s\n",
      "\t\t\t\tDisc: 0.257439\t\tSpars: 0.113632\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 162 [4000/8000 (50%)]\tBatch Loss: 0.372589\tLearning Rate (w_theta): 0.000500\t TIME:608.5s\n",
      "\t\t\t\tDisc: 0.257914\t\tSpars: 0.114675\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 162...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.36710017077449747\n",
      "Average validation loss: 0.36119939603432794\n",
      "Training epoch 163...\n",
      "\n",
      "Train Epoch: 163 [0/8000 (0%)]\tBatch Loss: 0.350287\tLearning Rate (w_theta): 0.000500\t TIME:610.7s\n",
      "\t\t\t\tDisc: 0.237095\t\tSpars: 0.113192\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 163 [4000/8000 (50%)]\tBatch Loss: 0.352356\tLearning Rate (w_theta): 0.000500\t TIME:612.2s\n",
      "\t\t\t\tDisc: 0.239962\t\tSpars: 0.112394\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 163...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3662359838726276\n",
      "Average validation loss: 0.3603750072756166\n",
      "Training epoch 164...\n",
      "\n",
      "Train Epoch: 164 [0/8000 (0%)]\tBatch Loss: 0.361813\tLearning Rate (w_theta): 0.000500\t TIME:614.4s\n",
      "\t\t\t\tDisc: 0.247540\t\tSpars: 0.114273\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 164 [4000/8000 (50%)]\tBatch Loss: 0.357674\tLearning Rate (w_theta): 0.000500\t TIME:615.8s\n",
      "\t\t\t\tDisc: 0.242651\t\tSpars: 0.115023\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 164...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3653733141088396\n",
      "Average validation loss: 0.35952833065044526\n",
      "Training epoch 165...\n",
      "\n",
      "Train Epoch: 165 [0/8000 (0%)]\tBatch Loss: 0.381510\tLearning Rate (w_theta): 0.000500\t TIME:618.2s\n",
      "\t\t\t\tDisc: 0.268606\t\tSpars: 0.112905\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 165 [4000/8000 (50%)]\tBatch Loss: 0.339084\tLearning Rate (w_theta): 0.000500\t TIME:619.6s\n",
      "\t\t\t\tDisc: 0.223957\t\tSpars: 0.115127\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 165...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3644839970197165\n",
      "Average validation loss: 0.3586683056432635\n",
      "Training epoch 166...\n",
      "\n",
      "Train Epoch: 166 [0/8000 (0%)]\tBatch Loss: 0.371417\tLearning Rate (w_theta): 0.000500\t TIME:621.8s\n",
      "\t\t\t\tDisc: 0.260575\t\tSpars: 0.110842\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 166 [4000/8000 (50%)]\tBatch Loss: 0.326433\tLearning Rate (w_theta): 0.000500\t TIME:623.3s\n",
      "\t\t\t\tDisc: 0.214556\t\tSpars: 0.111877\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 166...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3635886221332079\n",
      "Average validation loss: 0.3577874383474487\n",
      "Training epoch 167...\n",
      "\n",
      "Train Epoch: 167 [0/8000 (0%)]\tBatch Loss: 0.384069\tLearning Rate (w_theta): 0.000500\t TIME:625.5s\n",
      "\t\t\t\tDisc: 0.266997\t\tSpars: 0.117071\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 167 [4000/8000 (50%)]\tBatch Loss: 0.366422\tLearning Rate (w_theta): 0.000500\t TIME:626.9s\n",
      "\t\t\t\tDisc: 0.248734\t\tSpars: 0.117688\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 167...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3626691871590447\n",
      "Average validation loss: 0.3568907174168077\n",
      "Training epoch 168...\n",
      "\n",
      "Train Epoch: 168 [0/8000 (0%)]\tBatch Loss: 0.376690\tLearning Rate (w_theta): 0.000500\t TIME:629.1s\n",
      "\t\t\t\tDisc: 0.260605\t\tSpars: 0.116085\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 168 [4000/8000 (50%)]\tBatch Loss: 0.350274\tLearning Rate (w_theta): 0.000500\t TIME:630.5s\n",
      "\t\t\t\tDisc: 0.235443\t\tSpars: 0.114831\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 168...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.361731945614515\n",
      "Average validation loss: 0.3559782827816482\n",
      "Training epoch 169...\n",
      "\n",
      "Train Epoch: 169 [0/8000 (0%)]\tBatch Loss: 0.380633\tLearning Rate (w_theta): 0.000500\t TIME:632.9s\n",
      "\t\t\t\tDisc: 0.263511\t\tSpars: 0.117122\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 169 [4000/8000 (50%)]\tBatch Loss: 0.370568\tLearning Rate (w_theta): 0.000500\t TIME:634.3s\n",
      "\t\t\t\tDisc: 0.255068\t\tSpars: 0.115500\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 169...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3607711760634568\n",
      "Average validation loss: 0.3550543595230897\n",
      "Training epoch 170...\n",
      "\n",
      "Train Epoch: 170 [0/8000 (0%)]\tBatch Loss: 0.374930\tLearning Rate (w_theta): 0.000500\t TIME:636.5s\n",
      "\t\t\t\tDisc: 0.261511\t\tSpars: 0.113418\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 170 [4000/8000 (50%)]\tBatch Loss: 0.331191\tLearning Rate (w_theta): 0.000500\t TIME:638.0s\n",
      "\t\t\t\tDisc: 0.222222\t\tSpars: 0.108970\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 170...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.35980839012277427\n",
      "Average validation loss: 0.35410679576032505\n",
      "Training epoch 171...\n",
      "\n",
      "Train Epoch: 171 [0/8000 (0%)]\tBatch Loss: 0.337845\tLearning Rate (w_theta): 0.000500\t TIME:641.4s\n",
      "\t\t\t\tDisc: 0.225041\t\tSpars: 0.112804\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 171 [4000/8000 (50%)]\tBatch Loss: 0.372266\tLearning Rate (w_theta): 0.000500\t TIME:642.9s\n",
      "\t\t\t\tDisc: 0.254923\t\tSpars: 0.117343\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 171...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3588067060550032\n",
      "Average validation loss: 0.35315290295384194\n",
      "Training epoch 172...\n",
      "\n",
      "Train Epoch: 172 [0/8000 (0%)]\tBatch Loss: 0.361354\tLearning Rate (w_theta): 0.000500\t TIME:645.0s\n",
      "\t\t\t\tDisc: 0.249056\t\tSpars: 0.112299\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 172 [4000/8000 (50%)]\tBatch Loss: 0.366412\tLearning Rate (w_theta): 0.000500\t TIME:646.5s\n",
      "\t\t\t\tDisc: 0.252769\t\tSpars: 0.113642\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 172...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3578153096345201\n",
      "Average validation loss: 0.3521692061114529\n",
      "Training epoch 173...\n",
      "\n",
      "Train Epoch: 173 [0/8000 (0%)]\tBatch Loss: 0.358888\tLearning Rate (w_theta): 0.000500\t TIME:648.7s\n",
      "\t\t\t\tDisc: 0.241642\t\tSpars: 0.117246\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 173 [4000/8000 (50%)]\tBatch Loss: 0.365138\tLearning Rate (w_theta): 0.000500\t TIME:650.2s\n",
      "\t\t\t\tDisc: 0.252526\t\tSpars: 0.112613\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 173...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.35677802590496255\n",
      "Average validation loss: 0.35117790647170327\n",
      "Training epoch 174...\n",
      "\n",
      "Train Epoch: 174 [0/8000 (0%)]\tBatch Loss: 0.346072\tLearning Rate (w_theta): 0.000500\t TIME:652.5s\n",
      "\t\t\t\tDisc: 0.234883\t\tSpars: 0.111188\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 174 [4000/8000 (50%)]\tBatch Loss: 0.373287\tLearning Rate (w_theta): 0.000500\t TIME:654.0s\n",
      "\t\t\t\tDisc: 0.259743\t\tSpars: 0.113544\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 174...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.35573719365823325\n",
      "Average validation loss: 0.3501668476892678\n",
      "Training epoch 175...\n",
      "\n",
      "Train Epoch: 175 [0/8000 (0%)]\tBatch Loss: 0.349046\tLearning Rate (w_theta): 0.000500\t TIME:656.2s\n",
      "\t\t\t\tDisc: 0.235284\t\tSpars: 0.113762\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 175 [4000/8000 (50%)]\tBatch Loss: 0.384859\tLearning Rate (w_theta): 0.000500\t TIME:657.7s\n",
      "\t\t\t\tDisc: 0.267284\t\tSpars: 0.117576\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 175...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.35468156962608566\n",
      "Average validation loss: 0.34913255880227856\n",
      "Training epoch 176...\n",
      "\n",
      "Train Epoch: 176 [0/8000 (0%)]\tBatch Loss: 0.355410\tLearning Rate (w_theta): 0.000500\t TIME:659.9s\n",
      "\t\t\t\tDisc: 0.242268\t\tSpars: 0.113142\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 176 [4000/8000 (50%)]\tBatch Loss: 0.346433\tLearning Rate (w_theta): 0.000500\t TIME:661.3s\n",
      "\t\t\t\tDisc: 0.235836\t\tSpars: 0.110596\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 176...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3535983342804447\n",
      "Average validation loss: 0.34808209148146463\n",
      "Training epoch 177...\n",
      "\n",
      "Train Epoch: 177 [0/8000 (0%)]\tBatch Loss: 0.353805\tLearning Rate (w_theta): 0.000500\t TIME:663.6s\n",
      "\t\t\t\tDisc: 0.242365\t\tSpars: 0.111440\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 177 [4000/8000 (50%)]\tBatch Loss: 0.350480\tLearning Rate (w_theta): 0.000500\t TIME:665.0s\n",
      "\t\t\t\tDisc: 0.238821\t\tSpars: 0.111659\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 177...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.35251100777751876\n",
      "Average validation loss: 0.3470029376915056\n",
      "Training epoch 178...\n",
      "\n",
      "Train Epoch: 178 [0/8000 (0%)]\tBatch Loss: 0.370224\tLearning Rate (w_theta): 0.000500\t TIME:667.3s\n",
      "\t\t\t\tDisc: 0.253643\t\tSpars: 0.116581\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 178 [4000/8000 (50%)]\tBatch Loss: 0.362529\tLearning Rate (w_theta): 0.000500\t TIME:668.7s\n",
      "\t\t\t\tDisc: 0.251349\t\tSpars: 0.111180\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 178...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.35137865965958326\n",
      "Average validation loss: 0.3459152649416465\n",
      "Training epoch 179...\n",
      "\n",
      "Train Epoch: 179 [0/8000 (0%)]\tBatch Loss: 0.332499\tLearning Rate (w_theta): 0.000500\t TIME:671.0s\n",
      "\t\t\t\tDisc: 0.223809\t\tSpars: 0.108690\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 179 [4000/8000 (50%)]\tBatch Loss: 0.352245\tLearning Rate (w_theta): 0.000500\t TIME:672.5s\n",
      "\t\t\t\tDisc: 0.238295\t\tSpars: 0.113950\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 179...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3502417018598574\n",
      "Average validation loss: 0.3448068346152445\n",
      "Training epoch 180...\n",
      "\n",
      "Train Epoch: 180 [0/8000 (0%)]\tBatch Loss: 0.351997\tLearning Rate (w_theta): 0.000500\t TIME:674.7s\n",
      "\t\t\t\tDisc: 0.241403\t\tSpars: 0.110594\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 180 [4000/8000 (50%)]\tBatch Loss: 0.344208\tLearning Rate (w_theta): 0.000500\t TIME:676.1s\n",
      "\t\t\t\tDisc: 0.230527\t\tSpars: 0.113681\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 180...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.34908713591602597\n",
      "Average validation loss: 0.3436774518855239\n",
      "Training epoch 181...\n",
      "\n",
      "Train Epoch: 181 [0/8000 (0%)]\tBatch Loss: 0.363435\tLearning Rate (w_theta): 0.000500\t TIME:679.7s\n",
      "\t\t\t\tDisc: 0.246012\t\tSpars: 0.117424\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 181 [4000/8000 (50%)]\tBatch Loss: 0.348650\tLearning Rate (w_theta): 0.000500\t TIME:681.1s\n",
      "\t\t\t\tDisc: 0.238207\t\tSpars: 0.110443\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 181...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.34788854906705624\n",
      "Average validation loss: 0.3425470943614875\n",
      "Training epoch 182...\n",
      "\n",
      "Train Epoch: 182 [0/8000 (0%)]\tBatch Loss: 0.328640\tLearning Rate (w_theta): 0.000500\t TIME:683.4s\n",
      "\t\t\t\tDisc: 0.215705\t\tSpars: 0.112935\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 182 [4000/8000 (50%)]\tBatch Loss: 0.374941\tLearning Rate (w_theta): 0.000500\t TIME:684.8s\n",
      "\t\t\t\tDisc: 0.259646\t\tSpars: 0.115296\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 182...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3467055592676425\n",
      "Average validation loss: 0.34138705282585646\n",
      "Training epoch 183...\n",
      "\n",
      "Train Epoch: 183 [0/8000 (0%)]\tBatch Loss: 0.347001\tLearning Rate (w_theta): 0.000500\t TIME:687.1s\n",
      "\t\t\t\tDisc: 0.233136\t\tSpars: 0.113866\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 183 [4000/8000 (50%)]\tBatch Loss: 0.339559\tLearning Rate (w_theta): 0.000500\t TIME:688.5s\n",
      "\t\t\t\tDisc: 0.228185\t\tSpars: 0.111373\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 183...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.34550320810064805\n",
      "Average validation loss: 0.3401969069431753\n",
      "Training epoch 184...\n",
      "\n",
      "Train Epoch: 184 [0/8000 (0%)]\tBatch Loss: 0.365444\tLearning Rate (w_theta): 0.000500\t TIME:690.8s\n",
      "\t\t\t\tDisc: 0.249359\t\tSpars: 0.116085\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 184 [4000/8000 (50%)]\tBatch Loss: 0.334085\tLearning Rate (w_theta): 0.000500\t TIME:692.2s\n",
      "\t\t\t\tDisc: 0.222093\t\tSpars: 0.111992\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 184...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3442556671207084\n",
      "Average validation loss: 0.3389965573475998\n",
      "Training epoch 185...\n",
      "\n",
      "Train Epoch: 185 [0/8000 (0%)]\tBatch Loss: 0.349500\tLearning Rate (w_theta): 0.000500\t TIME:694.5s\n",
      "\t\t\t\tDisc: 0.236028\t\tSpars: 0.113472\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 185 [4000/8000 (50%)]\tBatch Loss: 0.359582\tLearning Rate (w_theta): 0.000500\t TIME:695.9s\n",
      "\t\t\t\tDisc: 0.244506\t\tSpars: 0.115076\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 185...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.34298816171966195\n",
      "Average validation loss: 0.3377856813303862\n",
      "Training epoch 186...\n",
      "\n",
      "Train Epoch: 186 [0/8000 (0%)]\tBatch Loss: 0.327808\tLearning Rate (w_theta): 0.000500\t TIME:698.2s\n",
      "\t\t\t\tDisc: 0.216575\t\tSpars: 0.111233\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 186 [4000/8000 (50%)]\tBatch Loss: 0.329805\tLearning Rate (w_theta): 0.000500\t TIME:699.6s\n",
      "\t\t\t\tDisc: 0.215896\t\tSpars: 0.113910\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 186...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3417208773278881\n",
      "Average validation loss: 0.33654841181495176\n",
      "Training epoch 187...\n",
      "\n",
      "Train Epoch: 187 [0/8000 (0%)]\tBatch Loss: 0.381430\tLearning Rate (w_theta): 0.000500\t TIME:701.8s\n",
      "\t\t\t\tDisc: 0.264354\t\tSpars: 0.117076\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 187 [4000/8000 (50%)]\tBatch Loss: 0.316544\tLearning Rate (w_theta): 0.000500\t TIME:703.3s\n",
      "\t\t\t\tDisc: 0.207923\t\tSpars: 0.108621\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 187...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3404336734779093\n",
      "Average validation loss: 0.33528315370624484\n",
      "Training epoch 188...\n",
      "\n",
      "Train Epoch: 188 [0/8000 (0%)]\tBatch Loss: 0.351820\tLearning Rate (w_theta): 0.000500\t TIME:705.5s\n",
      "\t\t\t\tDisc: 0.234165\t\tSpars: 0.117655\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 188 [4000/8000 (50%)]\tBatch Loss: 0.336621\tLearning Rate (w_theta): 0.000500\t TIME:707.0s\n",
      "\t\t\t\tDisc: 0.225116\t\tSpars: 0.111505\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 188...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3391081981869944\n",
      "Average validation loss: 0.33400347395005203\n",
      "Training epoch 189...\n",
      "\n",
      "Train Epoch: 189 [0/8000 (0%)]\tBatch Loss: 0.340419\tLearning Rate (w_theta): 0.000500\t TIME:709.3s\n",
      "\t\t\t\tDisc: 0.228709\t\tSpars: 0.111710\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 189 [4000/8000 (50%)]\tBatch Loss: 0.318971\tLearning Rate (w_theta): 0.000500\t TIME:710.7s\n",
      "\t\t\t\tDisc: 0.209712\t\tSpars: 0.109260\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 189...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3377555029091073\n",
      "Average validation loss: 0.3327163803414632\n",
      "Training epoch 190...\n",
      "\n",
      "Train Epoch: 190 [0/8000 (0%)]\tBatch Loss: 0.320191\tLearning Rate (w_theta): 0.000500\t TIME:713.0s\n",
      "\t\t\t\tDisc: 0.211487\t\tSpars: 0.108704\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 190 [4000/8000 (50%)]\tBatch Loss: 0.352272\tLearning Rate (w_theta): 0.000500\t TIME:714.4s\n",
      "\t\t\t\tDisc: 0.238835\t\tSpars: 0.113437\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 190...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.33641754667523466\n",
      "Average validation loss: 0.33139494084191945\n",
      "Training epoch 191...\n",
      "\n",
      "Train Epoch: 191 [0/8000 (0%)]\tBatch Loss: 0.360274\tLearning Rate (w_theta): 0.000500\t TIME:717.9s\n",
      "\t\t\t\tDisc: 0.245783\t\tSpars: 0.114491\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 191 [4000/8000 (50%)]\tBatch Loss: 0.333486\tLearning Rate (w_theta): 0.000500\t TIME:719.3s\n",
      "\t\t\t\tDisc: 0.219243\t\tSpars: 0.114243\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 191...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3350244841016511\n",
      "Average validation loss: 0.33006710488048097\n",
      "Training epoch 192...\n",
      "\n",
      "Train Epoch: 192 [0/8000 (0%)]\tBatch Loss: 0.332388\tLearning Rate (w_theta): 0.000500\t TIME:721.5s\n",
      "\t\t\t\tDisc: 0.222702\t\tSpars: 0.109686\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 192 [4000/8000 (50%)]\tBatch Loss: 0.317363\tLearning Rate (w_theta): 0.000500\t TIME:722.9s\n",
      "\t\t\t\tDisc: 0.205113\t\tSpars: 0.112250\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 192...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.33362157127133735\n",
      "Average validation loss: 0.3287259146503263\n",
      "Training epoch 193...\n",
      "\n",
      "Train Epoch: 193 [0/8000 (0%)]\tBatch Loss: 0.342420\tLearning Rate (w_theta): 0.000500\t TIME:725.1s\n",
      "\t\t\t\tDisc: 0.228679\t\tSpars: 0.113741\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 193 [4000/8000 (50%)]\tBatch Loss: 0.332145\tLearning Rate (w_theta): 0.000500\t TIME:726.6s\n",
      "\t\t\t\tDisc: 0.218520\t\tSpars: 0.113625\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 193...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.33223659966095187\n",
      "Average validation loss: 0.3273404697054305\n",
      "Training epoch 194...\n",
      "\n",
      "Train Epoch: 194 [0/8000 (0%)]\tBatch Loss: 0.330802\tLearning Rate (w_theta): 0.000500\t TIME:728.9s\n",
      "\t\t\t\tDisc: 0.218309\t\tSpars: 0.112493\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 194 [4000/8000 (50%)]\tBatch Loss: 0.322085\tLearning Rate (w_theta): 0.000500\t TIME:730.4s\n",
      "\t\t\t\tDisc: 0.210369\t\tSpars: 0.111716\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 194...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3307862904200861\n",
      "Average validation loss: 0.32594468903201507\n",
      "Training epoch 195...\n",
      "\n",
      "Train Epoch: 195 [0/8000 (0%)]\tBatch Loss: 0.332353\tLearning Rate (w_theta): 0.000500\t TIME:732.5s\n",
      "\t\t\t\tDisc: 0.221817\t\tSpars: 0.110535\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 195 [4000/8000 (50%)]\tBatch Loss: 0.347263\tLearning Rate (w_theta): 0.000500\t TIME:734.0s\n",
      "\t\t\t\tDisc: 0.235288\t\tSpars: 0.111975\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 195...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3293193224644369\n",
      "Average validation loss: 0.32453383694911647\n",
      "Training epoch 196...\n",
      "\n",
      "Train Epoch: 196 [0/8000 (0%)]\tBatch Loss: 0.325107\tLearning Rate (w_theta): 0.000500\t TIME:736.1s\n",
      "\t\t\t\tDisc: 0.212991\t\tSpars: 0.112116\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 196 [4000/8000 (50%)]\tBatch Loss: 0.318883\tLearning Rate (w_theta): 0.000500\t TIME:737.6s\n",
      "\t\t\t\tDisc: 0.209472\t\tSpars: 0.109411\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 196...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3278458069642168\n",
      "Average validation loss: 0.32309992275038346\n",
      "Training epoch 197...\n",
      "\n",
      "Train Epoch: 197 [0/8000 (0%)]\tBatch Loss: 0.331163\tLearning Rate (w_theta): 0.000500\t TIME:739.8s\n",
      "\t\t\t\tDisc: 0.218208\t\tSpars: 0.112955\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 197 [4000/8000 (50%)]\tBatch Loss: 0.325352\tLearning Rate (w_theta): 0.000500\t TIME:741.2s\n",
      "\t\t\t\tDisc: 0.214118\t\tSpars: 0.111234\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 197...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.32633966116207286\n",
      "Average validation loss: 0.3216511661212737\n",
      "Training epoch 198...\n",
      "\n",
      "Train Epoch: 198 [0/8000 (0%)]\tBatch Loss: 0.335346\tLearning Rate (w_theta): 0.000500\t TIME:743.4s\n",
      "\t\t\t\tDisc: 0.223852\t\tSpars: 0.111494\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 198 [4000/8000 (50%)]\tBatch Loss: 0.340714\tLearning Rate (w_theta): 0.000500\t TIME:744.8s\n",
      "\t\t\t\tDisc: 0.223748\t\tSpars: 0.116966\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 198...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3248405014282266\n",
      "Average validation loss: 0.3201652860439171\n",
      "Training epoch 199...\n",
      "\n",
      "Train Epoch: 199 [0/8000 (0%)]\tBatch Loss: 0.347196\tLearning Rate (w_theta): 0.000500\t TIME:747.1s\n",
      "\t\t\t\tDisc: 0.234057\t\tSpars: 0.113139\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 199 [4000/8000 (50%)]\tBatch Loss: 0.339886\tLearning Rate (w_theta): 0.000500\t TIME:748.6s\n",
      "\t\t\t\tDisc: 0.226754\t\tSpars: 0.113132\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 199...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.32328928313114336\n",
      "Average validation loss: 0.31866862634917176\n",
      "Training epoch 200...\n",
      "\n",
      "Train Epoch: 200 [0/8000 (0%)]\tBatch Loss: 0.343984\tLearning Rate (w_theta): 0.000500\t TIME:750.8s\n",
      "\t\t\t\tDisc: 0.227508\t\tSpars: 0.116477\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 200 [4000/8000 (50%)]\tBatch Loss: 0.330399\tLearning Rate (w_theta): 0.000500\t TIME:752.2s\n",
      "\t\t\t\tDisc: 0.217531\t\tSpars: 0.112869\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 200...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3217160479640347\n",
      "Average validation loss: 0.31716593280428984\n",
      "Training epoch 201...\n",
      "\n",
      "Train Epoch: 201 [0/8000 (0%)]\tBatch Loss: 0.312427\tLearning Rate (w_theta): 0.000500\t TIME:755.6s\n",
      "\t\t\t\tDisc: 0.202546\t\tSpars: 0.109881\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 201 [4000/8000 (50%)]\tBatch Loss: 0.317619\tLearning Rate (w_theta): 0.000500\t TIME:757.0s\n",
      "\t\t\t\tDisc: 0.204417\t\tSpars: 0.113201\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 201...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3201403092870251\n",
      "Average validation loss: 0.31564156109186337\n",
      "Training epoch 202...\n",
      "\n",
      "Train Epoch: 202 [0/8000 (0%)]\tBatch Loss: 0.329073\tLearning Rate (w_theta): 0.000500\t TIME:759.2s\n",
      "\t\t\t\tDisc: 0.216156\t\tSpars: 0.112917\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 202 [4000/8000 (50%)]\tBatch Loss: 0.293216\tLearning Rate (w_theta): 0.000500\t TIME:760.6s\n",
      "\t\t\t\tDisc: 0.187093\t\tSpars: 0.106124\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 202...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.31855885601098366\n",
      "Average validation loss: 0.31408330610565455\n",
      "Training epoch 203...\n",
      "\n",
      "Train Epoch: 203 [0/8000 (0%)]\tBatch Loss: 0.344653\tLearning Rate (w_theta): 0.000500\t TIME:762.9s\n",
      "\t\t\t\tDisc: 0.229050\t\tSpars: 0.115603\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 203 [4000/8000 (50%)]\tBatch Loss: 0.317928\tLearning Rate (w_theta): 0.000500\t TIME:764.4s\n",
      "\t\t\t\tDisc: 0.205100\t\tSpars: 0.112827\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 203...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.31692101191293787\n",
      "Average validation loss: 0.3125214498559029\n",
      "Training epoch 204...\n",
      "\n",
      "Train Epoch: 204 [0/8000 (0%)]\tBatch Loss: 0.318207\tLearning Rate (w_theta): 0.000500\t TIME:766.6s\n",
      "\t\t\t\tDisc: 0.206004\t\tSpars: 0.112203\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 204 [4000/8000 (50%)]\tBatch Loss: 0.325234\tLearning Rate (w_theta): 0.000500\t TIME:768.1s\n",
      "\t\t\t\tDisc: 0.209338\t\tSpars: 0.115897\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 204...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.31529792340251084\n",
      "Average validation loss: 0.3109302727973966\n",
      "Training epoch 205...\n",
      "\n",
      "Train Epoch: 205 [0/8000 (0%)]\tBatch Loss: 0.317732\tLearning Rate (w_theta): 0.000500\t TIME:770.3s\n",
      "\t\t\t\tDisc: 0.205727\t\tSpars: 0.112005\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 205 [4000/8000 (50%)]\tBatch Loss: 0.337352\tLearning Rate (w_theta): 0.000500\t TIME:771.7s\n",
      "\t\t\t\tDisc: 0.221141\t\tSpars: 0.116210\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 205...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3136295821952242\n",
      "Average validation loss: 0.30933056680795334\n",
      "Training epoch 206...\n",
      "\n",
      "Train Epoch: 206 [0/8000 (0%)]\tBatch Loss: 0.320292\tLearning Rate (w_theta): 0.000500\t TIME:773.9s\n",
      "\t\t\t\tDisc: 0.207774\t\tSpars: 0.112517\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 206 [4000/8000 (50%)]\tBatch Loss: 0.289208\tLearning Rate (w_theta): 0.000500\t TIME:775.3s\n",
      "\t\t\t\tDisc: 0.176777\t\tSpars: 0.112431\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 206...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.31195455813993617\n",
      "Average validation loss: 0.30771683738856415\n",
      "Training epoch 207...\n",
      "\n",
      "Train Epoch: 207 [0/8000 (0%)]\tBatch Loss: 0.321838\tLearning Rate (w_theta): 0.000500\t TIME:777.5s\n",
      "\t\t\t\tDisc: 0.210651\t\tSpars: 0.111187\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 207 [4000/8000 (50%)]\tBatch Loss: 0.287193\tLearning Rate (w_theta): 0.000500\t TIME:779.0s\n",
      "\t\t\t\tDisc: 0.178430\t\tSpars: 0.108763\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 207...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3102898332112389\n",
      "Average validation loss: 0.30606808209332126\n",
      "Training epoch 208...\n",
      "\n",
      "Train Epoch: 208 [0/8000 (0%)]\tBatch Loss: 0.286160\tLearning Rate (w_theta): 0.000500\t TIME:781.2s\n",
      "\t\t\t\tDisc: 0.180517\t\tSpars: 0.105643\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 208 [4000/8000 (50%)]\tBatch Loss: 0.311572\tLearning Rate (w_theta): 0.000500\t TIME:782.6s\n",
      "\t\t\t\tDisc: 0.201501\t\tSpars: 0.110072\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 208...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3085375716819943\n",
      "Average validation loss: 0.3044359930632492\n",
      "Training epoch 209...\n",
      "\n",
      "Train Epoch: 209 [0/8000 (0%)]\tBatch Loss: 0.292470\tLearning Rate (w_theta): 0.000500\t TIME:784.9s\n",
      "\t\t\t\tDisc: 0.187100\t\tSpars: 0.105371\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 209 [4000/8000 (50%)]\tBatch Loss: 0.287081\tLearning Rate (w_theta): 0.000500\t TIME:786.3s\n",
      "\t\t\t\tDisc: 0.179743\t\tSpars: 0.107337\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 209...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.30685003402550093\n",
      "Average validation loss: 0.3027596131814933\n",
      "Training epoch 210...\n",
      "\n",
      "Train Epoch: 210 [0/8000 (0%)]\tBatch Loss: 0.310548\tLearning Rate (w_theta): 0.000500\t TIME:788.5s\n",
      "\t\t\t\tDisc: 0.197871\t\tSpars: 0.112678\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 210 [4000/8000 (50%)]\tBatch Loss: 0.314729\tLearning Rate (w_theta): 0.000500\t TIME:789.9s\n",
      "\t\t\t\tDisc: 0.205663\t\tSpars: 0.109066\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 210...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.30509866597345153\n",
      "Average validation loss: 0.30107636629927365\n",
      "Training epoch 211...\n",
      "\n",
      "Train Epoch: 211 [0/8000 (0%)]\tBatch Loss: 0.305705\tLearning Rate (w_theta): 0.000500\t TIME:793.4s\n",
      "\t\t\t\tDisc: 0.194933\t\tSpars: 0.110772\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 211 [4000/8000 (50%)]\tBatch Loss: 0.313805\tLearning Rate (w_theta): 0.000500\t TIME:794.8s\n",
      "\t\t\t\tDisc: 0.201520\t\tSpars: 0.112285\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 211...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.30333654355267076\n",
      "Average validation loss: 0.29938102030147207\n",
      "Training epoch 212...\n",
      "\n",
      "Train Epoch: 212 [0/8000 (0%)]\tBatch Loss: 0.308961\tLearning Rate (w_theta): 0.000500\t TIME:797.0s\n",
      "\t\t\t\tDisc: 0.197868\t\tSpars: 0.111093\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 212 [4000/8000 (50%)]\tBatch Loss: 0.327853\tLearning Rate (w_theta): 0.000500\t TIME:798.4s\n",
      "\t\t\t\tDisc: 0.213346\t\tSpars: 0.114507\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 212...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.3015765724044184\n",
      "Average validation loss: 0.29766180214141696\n",
      "Training epoch 213...\n",
      "\n",
      "Train Epoch: 213 [0/8000 (0%)]\tBatch Loss: 0.322322\tLearning Rate (w_theta): 0.000500\t TIME:800.6s\n",
      "\t\t\t\tDisc: 0.209252\t\tSpars: 0.113071\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 213 [4000/8000 (50%)]\tBatch Loss: 0.298110\tLearning Rate (w_theta): 0.000500\t TIME:802.0s\n",
      "\t\t\t\tDisc: 0.188198\t\tSpars: 0.109912\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 213...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.2998088017391224\n",
      "Average validation loss: 0.29591642765038484\n",
      "Training epoch 214...\n",
      "\n",
      "Train Epoch: 214 [0/8000 (0%)]\tBatch Loss: 0.277787\tLearning Rate (w_theta): 0.000500\t TIME:804.3s\n",
      "\t\t\t\tDisc: 0.172012\t\tSpars: 0.105775\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 214 [4000/8000 (50%)]\tBatch Loss: 0.304745\tLearning Rate (w_theta): 0.000500\t TIME:805.8s\n",
      "\t\t\t\tDisc: 0.193912\t\tSpars: 0.110833\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 214...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.29796560879602657\n",
      "Average validation loss: 0.29418969790665966\n",
      "Training epoch 215...\n",
      "\n",
      "Train Epoch: 215 [0/8000 (0%)]\tBatch Loss: 0.303700\tLearning Rate (w_theta): 0.000500\t TIME:807.9s\n",
      "\t\t\t\tDisc: 0.191217\t\tSpars: 0.112483\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 215 [4000/8000 (50%)]\tBatch Loss: 0.293893\tLearning Rate (w_theta): 0.000500\t TIME:809.4s\n",
      "\t\t\t\tDisc: 0.186364\t\tSpars: 0.107529\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 215...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.29615692643412883\n",
      "Average validation loss: 0.29244603787806134\n",
      "Training epoch 216...\n",
      "\n",
      "Train Epoch: 216 [0/8000 (0%)]\tBatch Loss: 0.298325\tLearning Rate (w_theta): 0.000500\t TIME:811.6s\n",
      "\t\t\t\tDisc: 0.188787\t\tSpars: 0.109538\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 216 [4000/8000 (50%)]\tBatch Loss: 0.282377\tLearning Rate (w_theta): 0.000500\t TIME:813.0s\n",
      "\t\t\t\tDisc: 0.173851\t\tSpars: 0.108527\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 216...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.29434984692380506\n",
      "Average validation loss: 0.2906771884494619\n",
      "Training epoch 217...\n",
      "\n",
      "Train Epoch: 217 [0/8000 (0%)]\tBatch Loss: 0.310132\tLearning Rate (w_theta): 0.000500\t TIME:815.2s\n",
      "\t\t\t\tDisc: 0.196654\t\tSpars: 0.113478\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 217 [4000/8000 (50%)]\tBatch Loss: 0.281417\tLearning Rate (w_theta): 0.000500\t TIME:816.7s\n",
      "\t\t\t\tDisc: 0.174159\t\tSpars: 0.107258\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 217...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.29251396081208186\n",
      "Average validation loss: 0.28889794511152994\n",
      "Training epoch 218...\n",
      "\n",
      "Train Epoch: 218 [0/8000 (0%)]\tBatch Loss: 0.307935\tLearning Rate (w_theta): 0.000500\t TIME:818.8s\n",
      "\t\t\t\tDisc: 0.196513\t\tSpars: 0.111422\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 218 [4000/8000 (50%)]\tBatch Loss: 0.300277\tLearning Rate (w_theta): 0.000500\t TIME:820.3s\n",
      "\t\t\t\tDisc: 0.188191\t\tSpars: 0.112086\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 218...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.2906643737359796\n",
      "Average validation loss: 0.2871100561564386\n",
      "Training epoch 219...\n",
      "\n",
      "Train Epoch: 219 [0/8000 (0%)]\tBatch Loss: 0.302604\tLearning Rate (w_theta): 0.000500\t TIME:822.5s\n",
      "\t\t\t\tDisc: 0.193796\t\tSpars: 0.108808\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 219 [4000/8000 (50%)]\tBatch Loss: 0.293663\tLearning Rate (w_theta): 0.000500\t TIME:824.0s\n",
      "\t\t\t\tDisc: 0.182199\t\tSpars: 0.111463\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 219...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.2888222076181777\n",
      "Average validation loss: 0.28530059014347753\n",
      "Training epoch 220...\n",
      "\n",
      "Train Epoch: 220 [0/8000 (0%)]\tBatch Loss: 0.295801\tLearning Rate (w_theta): 0.000500\t TIME:826.2s\n",
      "\t\t\t\tDisc: 0.187377\t\tSpars: 0.108424\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 220 [4000/8000 (50%)]\tBatch Loss: 0.276445\tLearning Rate (w_theta): 0.000500\t TIME:827.7s\n",
      "\t\t\t\tDisc: 0.166415\t\tSpars: 0.110030\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 220...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.28693824289021974\n",
      "Average validation loss: 0.28350021134055975\n",
      "Training epoch 221...\n",
      "\n",
      "Train Epoch: 221 [0/8000 (0%)]\tBatch Loss: 0.287650\tLearning Rate (w_theta): 0.000500\t TIME:831.0s\n",
      "\t\t\t\tDisc: 0.177452\t\tSpars: 0.110197\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 221 [4000/8000 (50%)]\tBatch Loss: 0.290114\tLearning Rate (w_theta): 0.000500\t TIME:832.5s\n",
      "\t\t\t\tDisc: 0.179212\t\tSpars: 0.110902\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 221...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.28508602039656217\n",
      "Average validation loss: 0.28167895220863015\n",
      "Training epoch 222...\n",
      "\n",
      "Train Epoch: 222 [0/8000 (0%)]\tBatch Loss: 0.308379\tLearning Rate (w_theta): 0.000500\t TIME:834.6s\n",
      "\t\t\t\tDisc: 0.195636\t\tSpars: 0.112743\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 222 [4000/8000 (50%)]\tBatch Loss: 0.273385\tLearning Rate (w_theta): 0.000500\t TIME:836.1s\n",
      "\t\t\t\tDisc: 0.164324\t\tSpars: 0.109061\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 222...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.28318780369617763\n",
      "Average validation loss: 0.27986637408626447\n",
      "Training epoch 223...\n",
      "\n",
      "Train Epoch: 223 [0/8000 (0%)]\tBatch Loss: 0.271513\tLearning Rate (w_theta): 0.000500\t TIME:838.2s\n",
      "\t\t\t\tDisc: 0.163247\t\tSpars: 0.108266\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 223 [4000/8000 (50%)]\tBatch Loss: 0.295202\tLearning Rate (w_theta): 0.000500\t TIME:839.7s\n",
      "\t\t\t\tDisc: 0.184911\t\tSpars: 0.110291\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 223...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.28128681035916936\n",
      "Average validation loss: 0.27805757246722884\n",
      "Training epoch 224...\n",
      "\n",
      "Train Epoch: 224 [0/8000 (0%)]\tBatch Loss: 0.270049\tLearning Rate (w_theta): 0.000500\t TIME:842.1s\n",
      "\t\t\t\tDisc: 0.165229\t\tSpars: 0.104820\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 224 [4000/8000 (50%)]\tBatch Loss: 0.297531\tLearning Rate (w_theta): 0.000500\t TIME:843.5s\n",
      "\t\t\t\tDisc: 0.187606\t\tSpars: 0.109924\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 224...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.27942513310909345\n",
      "Average validation loss: 0.2762193306248335\n",
      "Training epoch 225...\n",
      "\n",
      "Train Epoch: 225 [0/8000 (0%)]\tBatch Loss: 0.273694\tLearning Rate (w_theta): 0.000500\t TIME:845.7s\n",
      "\t\t\t\tDisc: 0.163985\t\tSpars: 0.109709\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 225 [4000/8000 (50%)]\tBatch Loss: 0.278065\tLearning Rate (w_theta): 0.000500\t TIME:847.1s\n",
      "\t\t\t\tDisc: 0.168688\t\tSpars: 0.109377\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 225...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.2775240631179732\n",
      "Average validation loss: 0.2743827871694015\n",
      "Training epoch 226...\n",
      "\n",
      "Train Epoch: 226 [0/8000 (0%)]\tBatch Loss: 0.271601\tLearning Rate (w_theta): 0.000500\t TIME:849.3s\n",
      "\t\t\t\tDisc: 0.166342\t\tSpars: 0.105259\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 226 [4000/8000 (50%)]\tBatch Loss: 0.281159\tLearning Rate (w_theta): 0.000500\t TIME:850.7s\n",
      "\t\t\t\tDisc: 0.169145\t\tSpars: 0.112013\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 226...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.27561721357707714\n",
      "Average validation loss: 0.27255128902821124\n",
      "Training epoch 227...\n",
      "\n",
      "Train Epoch: 227 [0/8000 (0%)]\tBatch Loss: 0.261758\tLearning Rate (w_theta): 0.000500\t TIME:852.9s\n",
      "\t\t\t\tDisc: 0.155028\t\tSpars: 0.106730\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 227 [4000/8000 (50%)]\tBatch Loss: 0.279240\tLearning Rate (w_theta): 0.000500\t TIME:854.3s\n",
      "\t\t\t\tDisc: 0.173583\t\tSpars: 0.105656\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 227...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.2737236008455057\n",
      "Average validation loss: 0.27071111217522764\n",
      "Training epoch 228...\n",
      "\n",
      "Train Epoch: 228 [0/8000 (0%)]\tBatch Loss: 0.278395\tLearning Rate (w_theta): 0.000500\t TIME:856.5s\n",
      "\t\t\t\tDisc: 0.171390\t\tSpars: 0.107005\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 228 [4000/8000 (50%)]\tBatch Loss: 0.257277\tLearning Rate (w_theta): 0.000500\t TIME:858.0s\n",
      "\t\t\t\tDisc: 0.148924\t\tSpars: 0.108353\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 228...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.27182445925503707\n",
      "Average validation loss: 0.2688679836531187\n",
      "Training epoch 229...\n",
      "\n",
      "Train Epoch: 229 [0/8000 (0%)]\tBatch Loss: 0.271955\tLearning Rate (w_theta): 0.000500\t TIME:860.2s\n",
      "\t\t\t\tDisc: 0.163399\t\tSpars: 0.108557\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 229 [4000/8000 (50%)]\tBatch Loss: 0.278267\tLearning Rate (w_theta): 0.000500\t TIME:861.6s\n",
      "\t\t\t\tDisc: 0.166553\t\tSpars: 0.111715\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 229...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.26990734729770416\n",
      "Average validation loss: 0.2670380055771504\n",
      "Training epoch 230...\n",
      "\n",
      "Train Epoch: 230 [0/8000 (0%)]\tBatch Loss: 0.271112\tLearning Rate (w_theta): 0.000500\t TIME:863.9s\n",
      "\t\t\t\tDisc: 0.162961\t\tSpars: 0.108151\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 230 [4000/8000 (50%)]\tBatch Loss: 0.272825\tLearning Rate (w_theta): 0.000500\t TIME:865.3s\n",
      "\t\t\t\tDisc: 0.165347\t\tSpars: 0.107478\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 230...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.26799541087184253\n",
      "Average validation loss: 0.26521805089551476\n",
      "Training epoch 231...\n",
      "\n",
      "Train Epoch: 231 [0/8000 (0%)]\tBatch Loss: 0.266578\tLearning Rate (w_theta): 0.000500\t TIME:868.7s\n",
      "\t\t\t\tDisc: 0.156257\t\tSpars: 0.110320\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 231 [4000/8000 (50%)]\tBatch Loss: 0.265477\tLearning Rate (w_theta): 0.000500\t TIME:870.2s\n",
      "\t\t\t\tDisc: 0.159695\t\tSpars: 0.105782\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 231...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.2661063015228532\n",
      "Average validation loss: 0.2633927394186467\n",
      "Training epoch 232...\n",
      "\n",
      "Train Epoch: 232 [0/8000 (0%)]\tBatch Loss: 0.252103\tLearning Rate (w_theta): 0.000500\t TIME:872.3s\n",
      "\t\t\t\tDisc: 0.147797\t\tSpars: 0.104306\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 232 [4000/8000 (50%)]\tBatch Loss: 0.278679\tLearning Rate (w_theta): 0.000500\t TIME:873.8s\n",
      "\t\t\t\tDisc: 0.166980\t\tSpars: 0.111699\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 232...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.26420646758678185\n",
      "Average validation loss: 0.26157344487456863\n",
      "Training epoch 233...\n",
      "\n",
      "Train Epoch: 233 [0/8000 (0%)]\tBatch Loss: 0.259941\tLearning Rate (w_theta): 0.000500\t TIME:876.1s\n",
      "\t\t\t\tDisc: 0.153987\t\tSpars: 0.105954\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 233 [4000/8000 (50%)]\tBatch Loss: 0.272286\tLearning Rate (w_theta): 0.000500\t TIME:877.5s\n",
      "\t\t\t\tDisc: 0.166760\t\tSpars: 0.105526\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 233...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.26232902566166744\n",
      "Average validation loss: 0.25974804554703934\n",
      "Training epoch 234...\n",
      "\n",
      "Train Epoch: 234 [0/8000 (0%)]\tBatch Loss: 0.257529\tLearning Rate (w_theta): 0.000500\t TIME:879.6s\n",
      "\t\t\t\tDisc: 0.149009\t\tSpars: 0.108520\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 234 [4000/8000 (50%)]\tBatch Loss: 0.263306\tLearning Rate (w_theta): 0.000500\t TIME:881.1s\n",
      "\t\t\t\tDisc: 0.158388\t\tSpars: 0.104919\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 234...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.2604362550216316\n",
      "Average validation loss: 0.2579312061569348\n",
      "Training epoch 235...\n",
      "\n",
      "Train Epoch: 235 [0/8000 (0%)]\tBatch Loss: 0.260282\tLearning Rate (w_theta): 0.000500\t TIME:883.3s\n",
      "\t\t\t\tDisc: 0.151108\t\tSpars: 0.109174\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 235 [4000/8000 (50%)]\tBatch Loss: 0.264887\tLearning Rate (w_theta): 0.000500\t TIME:884.8s\n",
      "\t\t\t\tDisc: 0.159919\t\tSpars: 0.104968\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 235...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.2585502432917954\n",
      "Average validation loss: 0.25612112403224163\n",
      "Training epoch 236...\n",
      "\n",
      "Train Epoch: 236 [0/8000 (0%)]\tBatch Loss: 0.265888\tLearning Rate (w_theta): 0.000500\t TIME:887.0s\n",
      "\t\t\t\tDisc: 0.159438\t\tSpars: 0.106450\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 236 [4000/8000 (50%)]\tBatch Loss: 0.254767\tLearning Rate (w_theta): 0.000500\t TIME:888.4s\n",
      "\t\t\t\tDisc: 0.146812\t\tSpars: 0.107955\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 236...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.25666080099058425\n",
      "Average validation loss: 0.2543292223038368\n",
      "Training epoch 237...\n",
      "\n",
      "Train Epoch: 237 [0/8000 (0%)]\tBatch Loss: 0.236286\tLearning Rate (w_theta): 0.000500\t TIME:890.7s\n",
      "\t\t\t\tDisc: 0.134687\t\tSpars: 0.101599\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 237 [4000/8000 (50%)]\tBatch Loss: 0.230828\tLearning Rate (w_theta): 0.000500\t TIME:892.1s\n",
      "\t\t\t\tDisc: 0.126898\t\tSpars: 0.103930\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 237...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.2548005101733084\n",
      "Average validation loss: 0.25254105490186196\n",
      "Training epoch 238...\n",
      "\n",
      "Train Epoch: 238 [0/8000 (0%)]\tBatch Loss: 0.250630\tLearning Rate (w_theta): 0.000500\t TIME:894.3s\n",
      "\t\t\t\tDisc: 0.143827\t\tSpars: 0.106803\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 238 [4000/8000 (50%)]\tBatch Loss: 0.257266\tLearning Rate (w_theta): 0.000500\t TIME:895.7s\n",
      "\t\t\t\tDisc: 0.151124\t\tSpars: 0.106142\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 238...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.25294515417480823\n",
      "Average validation loss: 0.250759693954416\n",
      "Training epoch 239...\n",
      "\n",
      "Train Epoch: 239 [0/8000 (0%)]\tBatch Loss: 0.248092\tLearning Rate (w_theta): 0.000500\t TIME:897.9s\n",
      "\t\t\t\tDisc: 0.141644\t\tSpars: 0.106448\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 239 [4000/8000 (50%)]\tBatch Loss: 0.239725\tLearning Rate (w_theta): 0.000500\t TIME:899.3s\n",
      "\t\t\t\tDisc: 0.136304\t\tSpars: 0.103420\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 239...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.25109406892156777\n",
      "Average validation loss: 0.24898328858546953\n",
      "Training epoch 240...\n",
      "\n",
      "Train Epoch: 240 [0/8000 (0%)]\tBatch Loss: 0.254429\tLearning Rate (w_theta): 0.000500\t TIME:901.6s\n",
      "\t\t\t\tDisc: 0.150367\t\tSpars: 0.104062\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 240 [4000/8000 (50%)]\tBatch Loss: 0.258930\tLearning Rate (w_theta): 0.000500\t TIME:903.1s\n",
      "\t\t\t\tDisc: 0.146549\t\tSpars: 0.112380\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 240...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.2492649660581958\n",
      "Average validation loss: 0.24720939090152386\n",
      "Training epoch 241...\n",
      "\n",
      "Train Epoch: 241 [0/8000 (0%)]\tBatch Loss: 0.225305\tLearning Rate (w_theta): 0.000500\t TIME:906.6s\n",
      "\t\t\t\tDisc: 0.122196\t\tSpars: 0.103109\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 241 [4000/8000 (50%)]\tBatch Loss: 0.259669\tLearning Rate (w_theta): 0.000500\t TIME:908.0s\n",
      "\t\t\t\tDisc: 0.152691\t\tSpars: 0.106978\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 241...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.24741362623351681\n",
      "Average validation loss: 0.24546774288584206\n",
      "Training epoch 242...\n",
      "\n",
      "Train Epoch: 242 [0/8000 (0%)]\tBatch Loss: 0.245018\tLearning Rate (w_theta): 0.000500\t TIME:910.2s\n",
      "\t\t\t\tDisc: 0.142540\t\tSpars: 0.102478\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 242 [4000/8000 (50%)]\tBatch Loss: 0.233598\tLearning Rate (w_theta): 0.000500\t TIME:911.7s\n",
      "\t\t\t\tDisc: 0.130284\t\tSpars: 0.103313\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 242...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.24562559100135908\n",
      "Average validation loss: 0.24372172148631696\n",
      "Training epoch 243...\n",
      "\n",
      "Train Epoch: 243 [0/8000 (0%)]\tBatch Loss: 0.246830\tLearning Rate (w_theta): 0.000500\t TIME:913.8s\n",
      "\t\t\t\tDisc: 0.140994\t\tSpars: 0.105836\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 243 [4000/8000 (50%)]\tBatch Loss: 0.247074\tLearning Rate (w_theta): 0.000500\t TIME:915.3s\n",
      "\t\t\t\tDisc: 0.140770\t\tSpars: 0.106304\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 243...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.24382638359631278\n",
      "Average validation loss: 0.2419946515953664\n",
      "Training epoch 244...\n",
      "\n",
      "Train Epoch: 244 [0/8000 (0%)]\tBatch Loss: 0.253443\tLearning Rate (w_theta): 0.000500\t TIME:917.4s\n",
      "\t\t\t\tDisc: 0.145314\t\tSpars: 0.108129\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 244 [4000/8000 (50%)]\tBatch Loss: 0.261134\tLearning Rate (w_theta): 0.000500\t TIME:918.9s\n",
      "\t\t\t\tDisc: 0.156364\t\tSpars: 0.104770\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 244...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.24207407583011203\n",
      "Average validation loss: 0.240264478783577\n",
      "Training epoch 245...\n",
      "\n",
      "Train Epoch: 245 [0/8000 (0%)]\tBatch Loss: 0.248070\tLearning Rate (w_theta): 0.000500\t TIME:921.2s\n",
      "\t\t\t\tDisc: 0.143273\t\tSpars: 0.104798\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 245 [4000/8000 (50%)]\tBatch Loss: 0.234946\tLearning Rate (w_theta): 0.000500\t TIME:922.7s\n",
      "\t\t\t\tDisc: 0.130244\t\tSpars: 0.104702\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 245...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.24029596871559808\n",
      "Average validation loss: 0.23856619116285882\n",
      "Training epoch 246...\n",
      "\n",
      "Train Epoch: 246 [0/8000 (0%)]\tBatch Loss: 0.243808\tLearning Rate (w_theta): 0.000500\t TIME:924.9s\n",
      "\t\t\t\tDisc: 0.137285\t\tSpars: 0.106523\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 246 [4000/8000 (50%)]\tBatch Loss: 0.250600\tLearning Rate (w_theta): 0.000500\t TIME:926.3s\n",
      "\t\t\t\tDisc: 0.144937\t\tSpars: 0.105664\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 246...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.23857400098544818\n",
      "Average validation loss: 0.23686974290813673\n",
      "Training epoch 247...\n",
      "\n",
      "Train Epoch: 247 [0/8000 (0%)]\tBatch Loss: 0.239646\tLearning Rate (w_theta): 0.000500\t TIME:928.5s\n",
      "\t\t\t\tDisc: 0.135639\t\tSpars: 0.104007\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 247 [4000/8000 (50%)]\tBatch Loss: 0.220226\tLearning Rate (w_theta): 0.000500\t TIME:930.0s\n",
      "\t\t\t\tDisc: 0.117761\t\tSpars: 0.102464\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 247...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.23681613098503312\n",
      "Average validation loss: 0.23522583164798935\n",
      "Training epoch 248...\n",
      "\n",
      "Train Epoch: 248 [0/8000 (0%)]\tBatch Loss: 0.238159\tLearning Rate (w_theta): 0.000500\t TIME:932.2s\n",
      "\t\t\t\tDisc: 0.134574\t\tSpars: 0.103584\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 248 [4000/8000 (50%)]\tBatch Loss: 0.235430\tLearning Rate (w_theta): 0.000500\t TIME:933.6s\n",
      "\t\t\t\tDisc: 0.130824\t\tSpars: 0.104606\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 248...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.23516834563713665\n",
      "Average validation loss: 0.23356517328869497\n",
      "Training epoch 249...\n",
      "\n",
      "Train Epoch: 249 [0/8000 (0%)]\tBatch Loss: 0.245211\tLearning Rate (w_theta): 0.000500\t TIME:936.1s\n",
      "\t\t\t\tDisc: 0.140648\t\tSpars: 0.104563\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 249 [4000/8000 (50%)]\tBatch Loss: 0.235999\tLearning Rate (w_theta): 0.000500\t TIME:937.6s\n",
      "\t\t\t\tDisc: 0.128408\t\tSpars: 0.107591\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 249...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.23347157701007346\n",
      "Average validation loss: 0.23194029854466464\n",
      "Training epoch 250...\n",
      "\n",
      "Train Epoch: 250 [0/8000 (0%)]\tBatch Loss: 0.233298\tLearning Rate (w_theta): 0.000500\t TIME:939.9s\n",
      "\t\t\t\tDisc: 0.129605\t\tSpars: 0.103693\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 250 [4000/8000 (50%)]\tBatch Loss: 0.243549\tLearning Rate (w_theta): 0.000500\t TIME:941.3s\n",
      "\t\t\t\tDisc: 0.134814\t\tSpars: 0.108735\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 250...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.23179976915842393\n",
      "Average validation loss: 0.23035259450362677\n",
      "Training epoch 251...\n",
      "\n",
      "Train Epoch: 251 [0/8000 (0%)]\tBatch Loss: 0.232665\tLearning Rate (w_theta): 0.000500\t TIME:944.7s\n",
      "\t\t\t\tDisc: 0.128326\t\tSpars: 0.104339\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 251 [4000/8000 (50%)]\tBatch Loss: 0.233205\tLearning Rate (w_theta): 0.000500\t TIME:946.2s\n",
      "\t\t\t\tDisc: 0.129398\t\tSpars: 0.103807\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 251...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.23019239542712527\n",
      "Average validation loss: 0.228776643598073\n",
      "Training epoch 252...\n",
      "\n",
      "Train Epoch: 252 [0/8000 (0%)]\tBatch Loss: 0.228882\tLearning Rate (w_theta): 0.000500\t TIME:949.5s\n",
      "\t\t\t\tDisc: 0.121834\t\tSpars: 0.107048\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 252 [4000/8000 (50%)]\tBatch Loss: 0.223923\tLearning Rate (w_theta): 0.000500\t TIME:950.9s\n",
      "\t\t\t\tDisc: 0.118900\t\tSpars: 0.105023\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 252...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.22859010846312808\n",
      "Average validation loss: 0.22722847007105051\n",
      "Training epoch 253...\n",
      "\n",
      "Train Epoch: 253 [0/8000 (0%)]\tBatch Loss: 0.227953\tLearning Rate (w_theta): 0.000500\t TIME:953.2s\n",
      "\t\t\t\tDisc: 0.123896\t\tSpars: 0.104057\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 253 [4000/8000 (50%)]\tBatch Loss: 0.229656\tLearning Rate (w_theta): 0.000500\t TIME:954.7s\n",
      "\t\t\t\tDisc: 0.127384\t\tSpars: 0.102272\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 253...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.22701369668706567\n",
      "Average validation loss: 0.22569732209319862\n",
      "Training epoch 254...\n",
      "\n",
      "Train Epoch: 254 [0/8000 (0%)]\tBatch Loss: 0.213955\tLearning Rate (w_theta): 0.000500\t TIME:956.8s\n",
      "\t\t\t\tDisc: 0.111753\t\tSpars: 0.102202\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 254 [4000/8000 (50%)]\tBatch Loss: 0.211106\tLearning Rate (w_theta): 0.000500\t TIME:958.3s\n",
      "\t\t\t\tDisc: 0.109009\t\tSpars: 0.102097\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 254...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.22544752911527352\n",
      "Average validation loss: 0.2241903051803305\n",
      "Training epoch 255...\n",
      "\n",
      "Train Epoch: 255 [0/8000 (0%)]\tBatch Loss: 0.215954\tLearning Rate (w_theta): 0.000500\t TIME:960.5s\n",
      "\t\t\t\tDisc: 0.112433\t\tSpars: 0.103521\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 255 [4000/8000 (50%)]\tBatch Loss: 0.221258\tLearning Rate (w_theta): 0.000500\t TIME:962.0s\n",
      "\t\t\t\tDisc: 0.118711\t\tSpars: 0.102547\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 255...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.2239053774221815\n",
      "Average validation loss: 0.22270723477999682\n",
      "Training epoch 256...\n",
      "\n",
      "Train Epoch: 256 [0/8000 (0%)]\tBatch Loss: 0.228007\tLearning Rate (w_theta): 0.000500\t TIME:964.1s\n",
      "\t\t\t\tDisc: 0.124383\t\tSpars: 0.103623\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 256 [4000/8000 (50%)]\tBatch Loss: 0.216906\tLearning Rate (w_theta): 0.000500\t TIME:965.6s\n",
      "\t\t\t\tDisc: 0.114338\t\tSpars: 0.102568\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 256...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.22239699663395274\n",
      "Average validation loss: 0.22124436174332096\n",
      "Training epoch 257...\n",
      "\n",
      "Train Epoch: 257 [0/8000 (0%)]\tBatch Loss: 0.225387\tLearning Rate (w_theta): 0.000500\t TIME:967.8s\n",
      "\t\t\t\tDisc: 0.122534\t\tSpars: 0.102853\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 257 [4000/8000 (50%)]\tBatch Loss: 0.206124\tLearning Rate (w_theta): 0.000500\t TIME:969.3s\n",
      "\t\t\t\tDisc: 0.105198\t\tSpars: 0.100926\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 257...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.22090893529254021\n",
      "Average validation loss: 0.2198069889872074\n",
      "Training epoch 258...\n",
      "\n",
      "Train Epoch: 258 [0/8000 (0%)]\tBatch Loss: 0.230487\tLearning Rate (w_theta): 0.000500\t TIME:971.6s\n",
      "\t\t\t\tDisc: 0.127493\t\tSpars: 0.102994\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 258 [4000/8000 (50%)]\tBatch Loss: 0.206303\tLearning Rate (w_theta): 0.000500\t TIME:973.1s\n",
      "\t\t\t\tDisc: 0.105877\t\tSpars: 0.100426\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 258...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.21946726473199712\n",
      "Average validation loss: 0.21837792512176488\n",
      "Training epoch 259...\n",
      "\n",
      "Train Epoch: 259 [0/8000 (0%)]\tBatch Loss: 0.220190\tLearning Rate (w_theta): 0.000500\t TIME:975.3s\n",
      "\t\t\t\tDisc: 0.117455\t\tSpars: 0.102735\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 259 [4000/8000 (50%)]\tBatch Loss: 0.211497\tLearning Rate (w_theta): 0.000500\t TIME:976.7s\n",
      "\t\t\t\tDisc: 0.110879\t\tSpars: 0.100618\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 259...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.21800685433167444\n",
      "Average validation loss: 0.21699050203436027\n",
      "Training epoch 260...\n",
      "\n",
      "Train Epoch: 260 [0/8000 (0%)]\tBatch Loss: 0.232701\tLearning Rate (w_theta): 0.000500\t TIME:979.1s\n",
      "\t\t\t\tDisc: 0.127576\t\tSpars: 0.105125\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 260 [4000/8000 (50%)]\tBatch Loss: 0.204059\tLearning Rate (w_theta): 0.000500\t TIME:980.5s\n",
      "\t\t\t\tDisc: 0.104776\t\tSpars: 0.099282\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 260...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.2165979319770825\n",
      "Average validation loss: 0.21562269587765542\n",
      "Training epoch 261...\n",
      "\n",
      "Train Epoch: 261 [0/8000 (0%)]\tBatch Loss: 0.225522\tLearning Rate (w_theta): 0.000500\t TIME:984.0s\n",
      "\t\t\t\tDisc: 0.122090\t\tSpars: 0.103432\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 261 [4000/8000 (50%)]\tBatch Loss: 0.209555\tLearning Rate (w_theta): 0.000500\t TIME:985.5s\n",
      "\t\t\t\tDisc: 0.108689\t\tSpars: 0.100866\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 261...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.21521142425099457\n",
      "Average validation loss: 0.21427519815002216\n",
      "Training epoch 262...\n",
      "\n",
      "Train Epoch: 262 [0/8000 (0%)]\tBatch Loss: 0.217702\tLearning Rate (w_theta): 0.000500\t TIME:987.7s\n",
      "\t\t\t\tDisc: 0.113469\t\tSpars: 0.104233\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 262 [4000/8000 (50%)]\tBatch Loss: 0.222719\tLearning Rate (w_theta): 0.000500\t TIME:989.1s\n",
      "\t\t\t\tDisc: 0.120612\t\tSpars: 0.102107\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 262...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.2138650589421061\n",
      "Average validation loss: 0.21294215677736986\n",
      "Training epoch 263...\n",
      "\n",
      "Train Epoch: 263 [0/8000 (0%)]\tBatch Loss: 0.221259\tLearning Rate (w_theta): 0.000500\t TIME:991.3s\n",
      "\t\t\t\tDisc: 0.116191\t\tSpars: 0.105068\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 263 [4000/8000 (50%)]\tBatch Loss: 0.214322\tLearning Rate (w_theta): 0.000500\t TIME:992.8s\n",
      "\t\t\t\tDisc: 0.111901\t\tSpars: 0.102422\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 263...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.21252548224816653\n",
      "Average validation loss: 0.21163472067576578\n",
      "Training epoch 264...\n",
      "\n",
      "Train Epoch: 264 [0/8000 (0%)]\tBatch Loss: 0.215160\tLearning Rate (w_theta): 0.000500\t TIME:995.0s\n",
      "\t\t\t\tDisc: 0.110629\t\tSpars: 0.104531\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 264 [4000/8000 (50%)]\tBatch Loss: 0.215264\tLearning Rate (w_theta): 0.000500\t TIME:996.4s\n",
      "\t\t\t\tDisc: 0.110709\t\tSpars: 0.104555\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 264...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.21122483917600404\n",
      "Average validation loss: 0.21035160600821437\n",
      "Training epoch 265...\n",
      "\n",
      "Train Epoch: 265 [0/8000 (0%)]\tBatch Loss: 0.204734\tLearning Rate (w_theta): 0.000500\t TIME:998.6s\n",
      "\t\t\t\tDisc: 0.102260\t\tSpars: 0.102474\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 265 [4000/8000 (50%)]\tBatch Loss: 0.213508\tLearning Rate (w_theta): 0.000500\t TIME:1000.1s\n",
      "\t\t\t\tDisc: 0.112252\t\tSpars: 0.101256\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 265...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.20993669342397767\n",
      "Average validation loss: 0.20909927123550637\n",
      "Training epoch 266...\n",
      "\n",
      "Train Epoch: 266 [0/8000 (0%)]\tBatch Loss: 0.223132\tLearning Rate (w_theta): 0.000500\t TIME:1002.5s\n",
      "\t\t\t\tDisc: 0.118282\t\tSpars: 0.104850\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 266 [4000/8000 (50%)]\tBatch Loss: 0.204819\tLearning Rate (w_theta): 0.000500\t TIME:1003.9s\n",
      "\t\t\t\tDisc: 0.104039\t\tSpars: 0.100780\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 266...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.20868871020958646\n",
      "Average validation loss: 0.20786644514523223\n",
      "Training epoch 267...\n",
      "\n",
      "Train Epoch: 267 [0/8000 (0%)]\tBatch Loss: 0.210666\tLearning Rate (w_theta): 0.000500\t TIME:1006.1s\n",
      "\t\t\t\tDisc: 0.110431\t\tSpars: 0.100235\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 267 [4000/8000 (50%)]\tBatch Loss: 0.199154\tLearning Rate (w_theta): 0.000500\t TIME:1007.6s\n",
      "\t\t\t\tDisc: 0.101440\t\tSpars: 0.097714\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 267...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.2074700295037874\n",
      "Average validation loss: 0.20665097690624923\n",
      "Training epoch 268...\n",
      "\n",
      "Train Epoch: 268 [0/8000 (0%)]\tBatch Loss: 0.209179\tLearning Rate (w_theta): 0.000500\t TIME:1009.8s\n",
      "\t\t\t\tDisc: 0.108034\t\tSpars: 0.101145\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 268 [4000/8000 (50%)]\tBatch Loss: 0.202418\tLearning Rate (w_theta): 0.000500\t TIME:1011.2s\n",
      "\t\t\t\tDisc: 0.100072\t\tSpars: 0.102346\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 268...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.20625447929771978\n",
      "Average validation loss: 0.2054745066258729\n",
      "Training epoch 269...\n",
      "\n",
      "Train Epoch: 269 [0/8000 (0%)]\tBatch Loss: 0.206204\tLearning Rate (w_theta): 0.000500\t TIME:1013.5s\n",
      "\t\t\t\tDisc: 0.106675\t\tSpars: 0.099530\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 269 [4000/8000 (50%)]\tBatch Loss: 0.203311\tLearning Rate (w_theta): 0.000500\t TIME:1015.0s\n",
      "\t\t\t\tDisc: 0.098009\t\tSpars: 0.105302\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 269...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.2050817948956827\n",
      "Average validation loss: 0.2043252264613888\n",
      "Training epoch 270...\n",
      "\n",
      "Train Epoch: 270 [0/8000 (0%)]\tBatch Loss: 0.198996\tLearning Rate (w_theta): 0.000500\t TIME:1017.2s\n",
      "\t\t\t\tDisc: 0.094991\t\tSpars: 0.104005\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 270 [4000/8000 (50%)]\tBatch Loss: 0.198594\tLearning Rate (w_theta): 0.000500\t TIME:1018.7s\n",
      "\t\t\t\tDisc: 0.099199\t\tSpars: 0.099395\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 270...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.20393628656534474\n",
      "Average validation loss: 0.20320231111842418\n",
      "Training epoch 271...\n",
      "\n",
      "Train Epoch: 271 [0/8000 (0%)]\tBatch Loss: 0.202283\tLearning Rate (w_theta): 0.000500\t TIME:1022.4s\n",
      "\t\t\t\tDisc: 0.102076\t\tSpars: 0.100206\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 271 [4000/8000 (50%)]\tBatch Loss: 0.197818\tLearning Rate (w_theta): 0.000500\t TIME:1023.8s\n",
      "\t\t\t\tDisc: 0.096015\t\tSpars: 0.101803\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 271...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.20281624389905586\n",
      "Average validation loss: 0.2021061011014862\n",
      "Training epoch 272...\n",
      "\n",
      "Train Epoch: 272 [0/8000 (0%)]\tBatch Loss: 0.206208\tLearning Rate (w_theta): 0.000500\t TIME:1026.0s\n",
      "\t\t\t\tDisc: 0.101551\t\tSpars: 0.104657\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 272 [4000/8000 (50%)]\tBatch Loss: 0.202114\tLearning Rate (w_theta): 0.000500\t TIME:1027.4s\n",
      "\t\t\t\tDisc: 0.102919\t\tSpars: 0.099195\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 272...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.20173198747055038\n",
      "Average validation loss: 0.20102728270729414\n",
      "Training epoch 273...\n",
      "\n",
      "Train Epoch: 273 [0/8000 (0%)]\tBatch Loss: 0.192703\tLearning Rate (w_theta): 0.000500\t TIME:1029.6s\n",
      "\t\t\t\tDisc: 0.092146\t\tSpars: 0.100557\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 273 [4000/8000 (50%)]\tBatch Loss: 0.197981\tLearning Rate (w_theta): 0.000500\t TIME:1031.1s\n",
      "\t\t\t\tDisc: 0.097832\t\tSpars: 0.100149\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 273...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.20064677799107203\n",
      "Average validation loss: 0.1999846065743104\n",
      "Training epoch 274...\n",
      "\n",
      "Train Epoch: 274 [0/8000 (0%)]\tBatch Loss: 0.198020\tLearning Rate (w_theta): 0.000500\t TIME:1033.2s\n",
      "\t\t\t\tDisc: 0.098471\t\tSpars: 0.099549\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 274 [4000/8000 (50%)]\tBatch Loss: 0.209548\tLearning Rate (w_theta): 0.000500\t TIME:1034.7s\n",
      "\t\t\t\tDisc: 0.108563\t\tSpars: 0.100986\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 274...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.19962531447872647\n",
      "Average validation loss: 0.19894731313607428\n",
      "Training epoch 275...\n",
      "\n",
      "Train Epoch: 275 [0/8000 (0%)]\tBatch Loss: 0.199210\tLearning Rate (w_theta): 0.000500\t TIME:1036.9s\n",
      "\t\t\t\tDisc: 0.096962\t\tSpars: 0.102248\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 275 [4000/8000 (50%)]\tBatch Loss: 0.194819\tLearning Rate (w_theta): 0.000500\t TIME:1038.4s\n",
      "\t\t\t\tDisc: 0.097119\t\tSpars: 0.097701\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 275...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.19859789564225597\n",
      "Average validation loss: 0.19793794610435395\n",
      "Training epoch 276...\n",
      "\n",
      "Train Epoch: 276 [0/8000 (0%)]\tBatch Loss: 0.198034\tLearning Rate (w_theta): 0.000500\t TIME:1040.6s\n",
      "\t\t\t\tDisc: 0.097320\t\tSpars: 0.100714\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 276 [4000/8000 (50%)]\tBatch Loss: 0.199000\tLearning Rate (w_theta): 0.000500\t TIME:1042.1s\n",
      "\t\t\t\tDisc: 0.098675\t\tSpars: 0.100324\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 276...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1975960167984154\n",
      "Average validation loss: 0.19696372316159416\n",
      "Training epoch 277...\n",
      "\n",
      "Train Epoch: 277 [0/8000 (0%)]\tBatch Loss: 0.191790\tLearning Rate (w_theta): 0.000500\t TIME:1044.3s\n",
      "\t\t\t\tDisc: 0.094521\t\tSpars: 0.097269\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 277 [4000/8000 (50%)]\tBatch Loss: 0.205052\tLearning Rate (w_theta): 0.000500\t TIME:1045.7s\n",
      "\t\t\t\tDisc: 0.100323\t\tSpars: 0.104729\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 277...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.19662880519003642\n",
      "Average validation loss: 0.19601223027027817\n",
      "Training epoch 278...\n",
      "\n",
      "Train Epoch: 278 [0/8000 (0%)]\tBatch Loss: 0.191138\tLearning Rate (w_theta): 0.000500\t TIME:1047.9s\n",
      "\t\t\t\tDisc: 0.093210\t\tSpars: 0.097928\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 278 [4000/8000 (50%)]\tBatch Loss: 0.200382\tLearning Rate (w_theta): 0.000500\t TIME:1049.4s\n",
      "\t\t\t\tDisc: 0.099101\t\tSpars: 0.101281\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 278...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.19567616683144134\n",
      "Average validation loss: 0.19508771378175865\n",
      "Training epoch 279...\n",
      "\n",
      "Train Epoch: 279 [0/8000 (0%)]\tBatch Loss: 0.189544\tLearning Rate (w_theta): 0.000500\t TIME:1051.6s\n",
      "\t\t\t\tDisc: 0.092635\t\tSpars: 0.096909\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 279 [4000/8000 (50%)]\tBatch Loss: 0.203807\tLearning Rate (w_theta): 0.000500\t TIME:1053.0s\n",
      "\t\t\t\tDisc: 0.102802\t\tSpars: 0.101004\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 279...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.19476328610083454\n",
      "Average validation loss: 0.19417173828780204\n",
      "Training epoch 280...\n",
      "\n",
      "Train Epoch: 280 [0/8000 (0%)]\tBatch Loss: 0.197072\tLearning Rate (w_theta): 0.000500\t TIME:1055.2s\n",
      "\t\t\t\tDisc: 0.091273\t\tSpars: 0.105799\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 280 [4000/8000 (50%)]\tBatch Loss: 0.191061\tLearning Rate (w_theta): 0.000500\t TIME:1056.6s\n",
      "\t\t\t\tDisc: 0.095639\t\tSpars: 0.095422\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 280...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.19385727054358787\n",
      "Average validation loss: 0.19327967392869105\n",
      "Training epoch 281...\n",
      "\n",
      "Train Epoch: 281 [0/8000 (0%)]\tBatch Loss: 0.190738\tLearning Rate (w_theta): 0.000500\t TIME:1060.1s\n",
      "\t\t\t\tDisc: 0.090771\t\tSpars: 0.099967\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 281 [4000/8000 (50%)]\tBatch Loss: 0.189253\tLearning Rate (w_theta): 0.000500\t TIME:1061.6s\n",
      "\t\t\t\tDisc: 0.087898\t\tSpars: 0.101355\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 281...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1929600024996587\n",
      "Average validation loss: 0.19242030252685136\n",
      "Training epoch 282...\n",
      "\n",
      "Train Epoch: 282 [0/8000 (0%)]\tBatch Loss: 0.192430\tLearning Rate (w_theta): 0.000500\t TIME:1063.8s\n",
      "\t\t\t\tDisc: 0.092245\t\tSpars: 0.100185\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 282 [4000/8000 (50%)]\tBatch Loss: 0.183274\tLearning Rate (w_theta): 0.000500\t TIME:1065.3s\n",
      "\t\t\t\tDisc: 0.084910\t\tSpars: 0.098364\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 282...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.19210120650211432\n",
      "Average validation loss: 0.19157879443194725\n",
      "Training epoch 283...\n",
      "\n",
      "Train Epoch: 283 [0/8000 (0%)]\tBatch Loss: 0.191046\tLearning Rate (w_theta): 0.000500\t TIME:1067.5s\n",
      "\t\t\t\tDisc: 0.091635\t\tSpars: 0.099411\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 283 [4000/8000 (50%)]\tBatch Loss: 0.194050\tLearning Rate (w_theta): 0.000500\t TIME:1069.0s\n",
      "\t\t\t\tDisc: 0.095250\t\tSpars: 0.098801\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 283...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.19127141508210593\n",
      "Average validation loss: 0.19075202545477515\n",
      "Training epoch 284...\n",
      "\n",
      "Train Epoch: 284 [0/8000 (0%)]\tBatch Loss: 0.184741\tLearning Rate (w_theta): 0.000500\t TIME:1071.2s\n",
      "\t\t\t\tDisc: 0.086261\t\tSpars: 0.098480\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 284 [4000/8000 (50%)]\tBatch Loss: 0.192252\tLearning Rate (w_theta): 0.000500\t TIME:1072.6s\n",
      "\t\t\t\tDisc: 0.090298\t\tSpars: 0.101954\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 284...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.19044088545664764\n",
      "Average validation loss: 0.18995739760215974\n",
      "Training epoch 285...\n",
      "\n",
      "Train Epoch: 285 [0/8000 (0%)]\tBatch Loss: 0.186355\tLearning Rate (w_theta): 0.000500\t TIME:1074.8s\n",
      "\t\t\t\tDisc: 0.084891\t\tSpars: 0.101465\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 285 [4000/8000 (50%)]\tBatch Loss: 0.180476\tLearning Rate (w_theta): 0.000500\t TIME:1076.3s\n",
      "\t\t\t\tDisc: 0.084466\t\tSpars: 0.096010\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 285...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.18963529951287766\n",
      "Average validation loss: 0.18919160966790993\n",
      "Training epoch 286...\n",
      "\n",
      "Train Epoch: 286 [0/8000 (0%)]\tBatch Loss: 0.195102\tLearning Rate (w_theta): 0.000500\t TIME:1078.5s\n",
      "\t\t\t\tDisc: 0.092481\t\tSpars: 0.102621\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 286 [4000/8000 (50%)]\tBatch Loss: 0.183357\tLearning Rate (w_theta): 0.000500\t TIME:1080.0s\n",
      "\t\t\t\tDisc: 0.086299\t\tSpars: 0.097057\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 286...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.18887607292395955\n",
      "Average validation loss: 0.18843363307317795\n",
      "Training epoch 287...\n",
      "\n",
      "Train Epoch: 287 [0/8000 (0%)]\tBatch Loss: 0.188602\tLearning Rate (w_theta): 0.000500\t TIME:1082.4s\n",
      "\t\t\t\tDisc: 0.085314\t\tSpars: 0.103288\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 287 [4000/8000 (50%)]\tBatch Loss: 0.183080\tLearning Rate (w_theta): 0.000500\t TIME:1083.9s\n",
      "\t\t\t\tDisc: 0.084637\t\tSpars: 0.098443\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 287...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.18810032154572115\n",
      "Average validation loss: 0.18770740466285357\n",
      "Training epoch 288...\n",
      "\n",
      "Train Epoch: 288 [0/8000 (0%)]\tBatch Loss: 0.184724\tLearning Rate (w_theta): 0.000500\t TIME:1086.1s\n",
      "\t\t\t\tDisc: 0.085898\t\tSpars: 0.098826\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 288 [4000/8000 (50%)]\tBatch Loss: 0.181871\tLearning Rate (w_theta): 0.000500\t TIME:1087.6s\n",
      "\t\t\t\tDisc: 0.085294\t\tSpars: 0.096578\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 288...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1873751416526686\n",
      "Average validation loss: 0.18698355130075398\n",
      "Training epoch 289...\n",
      "\n",
      "Train Epoch: 289 [0/8000 (0%)]\tBatch Loss: 0.189097\tLearning Rate (w_theta): 0.000500\t TIME:1089.7s\n",
      "\t\t\t\tDisc: 0.089846\t\tSpars: 0.099251\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 289 [4000/8000 (50%)]\tBatch Loss: 0.187401\tLearning Rate (w_theta): 0.000500\t TIME:1091.2s\n",
      "\t\t\t\tDisc: 0.086160\t\tSpars: 0.101241\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 289...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.18663271073562135\n",
      "Average validation loss: 0.18628918107462203\n",
      "Training epoch 290...\n",
      "\n",
      "Train Epoch: 290 [0/8000 (0%)]\tBatch Loss: 0.187347\tLearning Rate (w_theta): 0.000500\t TIME:1093.3s\n",
      "\t\t\t\tDisc: 0.089285\t\tSpars: 0.098062\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 290 [4000/8000 (50%)]\tBatch Loss: 0.180805\tLearning Rate (w_theta): 0.000500\t TIME:1094.8s\n",
      "\t\t\t\tDisc: 0.080723\t\tSpars: 0.100082\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 290...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.18592475693411706\n",
      "Average validation loss: 0.1856104637886363\n",
      "Training epoch 291...\n",
      "\n",
      "Train Epoch: 291 [0/8000 (0%)]\tBatch Loss: 0.182205\tLearning Rate (w_theta): 0.000500\t TIME:1098.5s\n",
      "\t\t\t\tDisc: 0.083800\t\tSpars: 0.098405\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 291 [4000/8000 (50%)]\tBatch Loss: 0.192650\tLearning Rate (w_theta): 0.000500\t TIME:1099.9s\n",
      "\t\t\t\tDisc: 0.092137\t\tSpars: 0.100513\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 291...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.18523227989847577\n",
      "Average validation loss: 0.18494656228277997\n",
      "Training epoch 292...\n",
      "\n",
      "Train Epoch: 292 [0/8000 (0%)]\tBatch Loss: 0.177832\tLearning Rate (w_theta): 0.000500\t TIME:1102.1s\n",
      "\t\t\t\tDisc: 0.081060\t\tSpars: 0.096771\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 292 [4000/8000 (50%)]\tBatch Loss: 0.177515\tLearning Rate (w_theta): 0.000500\t TIME:1103.6s\n",
      "\t\t\t\tDisc: 0.078351\t\tSpars: 0.099163\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 292...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1845584928098276\n",
      "Average validation loss: 0.18429289930370188\n",
      "Training epoch 293...\n",
      "\n",
      "Train Epoch: 293 [0/8000 (0%)]\tBatch Loss: 0.184953\tLearning Rate (w_theta): 0.000500\t TIME:1105.9s\n",
      "\t\t\t\tDisc: 0.084592\t\tSpars: 0.100361\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 293 [4000/8000 (50%)]\tBatch Loss: 0.186937\tLearning Rate (w_theta): 0.000500\t TIME:1107.4s\n",
      "\t\t\t\tDisc: 0.087746\t\tSpars: 0.099191\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 293...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1838920168581439\n",
      "Average validation loss: 0.18365660996826838\n",
      "Training epoch 294...\n",
      "\n",
      "Train Epoch: 294 [0/8000 (0%)]\tBatch Loss: 0.180287\tLearning Rate (w_theta): 0.000500\t TIME:1109.7s\n",
      "\t\t\t\tDisc: 0.081779\t\tSpars: 0.098508\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 294 [4000/8000 (50%)]\tBatch Loss: 0.180968\tLearning Rate (w_theta): 0.000500\t TIME:1111.1s\n",
      "\t\t\t\tDisc: 0.081648\t\tSpars: 0.099320\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 294...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1832434662306318\n",
      "Average validation loss: 0.1830332120192258\n",
      "Training epoch 295...\n",
      "\n",
      "Train Epoch: 295 [0/8000 (0%)]\tBatch Loss: 0.188789\tLearning Rate (w_theta): 0.000500\t TIME:1113.3s\n",
      "\t\t\t\tDisc: 0.089976\t\tSpars: 0.098813\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 295 [4000/8000 (50%)]\tBatch Loss: 0.182196\tLearning Rate (w_theta): 0.000500\t TIME:1114.8s\n",
      "\t\t\t\tDisc: 0.080741\t\tSpars: 0.101455\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 295...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1826312068740626\n",
      "Average validation loss: 0.18240582812716977\n",
      "Training epoch 296...\n",
      "\n",
      "Train Epoch: 296 [0/8000 (0%)]\tBatch Loss: 0.176979\tLearning Rate (w_theta): 0.000500\t TIME:1117.0s\n",
      "\t\t\t\tDisc: 0.076815\t\tSpars: 0.100164\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 296 [4000/8000 (50%)]\tBatch Loss: 0.190190\tLearning Rate (w_theta): 0.000500\t TIME:1118.5s\n",
      "\t\t\t\tDisc: 0.090446\t\tSpars: 0.099744\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 296...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.18199262710441394\n",
      "Average validation loss: 0.18181129016722397\n",
      "Training epoch 297...\n",
      "\n",
      "Train Epoch: 297 [0/8000 (0%)]\tBatch Loss: 0.188491\tLearning Rate (w_theta): 0.000500\t TIME:1120.7s\n",
      "\t\t\t\tDisc: 0.088357\t\tSpars: 0.100134\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 297 [4000/8000 (50%)]\tBatch Loss: 0.184007\tLearning Rate (w_theta): 0.000500\t TIME:1122.1s\n",
      "\t\t\t\tDisc: 0.083741\t\tSpars: 0.100266\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 297...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.18139922232551353\n",
      "Average validation loss: 0.18122681872830776\n",
      "Training epoch 298...\n",
      "\n",
      "Train Epoch: 298 [0/8000 (0%)]\tBatch Loss: 0.177862\tLearning Rate (w_theta): 0.000500\t TIME:1124.3s\n",
      "\t\t\t\tDisc: 0.082161\t\tSpars: 0.095700\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 298 [4000/8000 (50%)]\tBatch Loss: 0.185930\tLearning Rate (w_theta): 0.000500\t TIME:1125.8s\n",
      "\t\t\t\tDisc: 0.085346\t\tSpars: 0.100585\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 298...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1808061496850748\n",
      "Average validation loss: 0.18066290404970267\n",
      "Training epoch 299...\n",
      "\n",
      "Train Epoch: 299 [0/8000 (0%)]\tBatch Loss: 0.183986\tLearning Rate (w_theta): 0.000500\t TIME:1128.1s\n",
      "\t\t\t\tDisc: 0.084822\t\tSpars: 0.099164\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 299 [4000/8000 (50%)]\tBatch Loss: 0.178566\tLearning Rate (w_theta): 0.000500\t TIME:1129.5s\n",
      "\t\t\t\tDisc: 0.081100\t\tSpars: 0.097466\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 299...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.18023610653298375\n",
      "Average validation loss: 0.18010706983508434\n",
      "Training epoch 300...\n",
      "\n",
      "Train Epoch: 300 [0/8000 (0%)]\tBatch Loss: 0.176622\tLearning Rate (w_theta): 0.000500\t TIME:1131.7s\n",
      "\t\t\t\tDisc: 0.077417\t\tSpars: 0.099205\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 300 [4000/8000 (50%)]\tBatch Loss: 0.180686\tLearning Rate (w_theta): 0.000500\t TIME:1133.2s\n",
      "\t\t\t\tDisc: 0.082604\t\tSpars: 0.098081\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 300...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.17967838299309152\n",
      "Average validation loss: 0.17956425883855517\n",
      "Training epoch 301...\n",
      "\n",
      "Train Epoch: 301 [0/8000 (0%)]\tBatch Loss: 0.177699\tLearning Rate (w_theta): 0.000500\t TIME:1136.6s\n",
      "\t\t\t\tDisc: 0.078731\t\tSpars: 0.098969\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 301 [4000/8000 (50%)]\tBatch Loss: 0.184754\tLearning Rate (w_theta): 0.000500\t TIME:1138.1s\n",
      "\t\t\t\tDisc: 0.084674\t\tSpars: 0.100080\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 301...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.17912701912376172\n",
      "Average validation loss: 0.1790350169711398\n",
      "Training epoch 302...\n",
      "\n",
      "Train Epoch: 302 [0/8000 (0%)]\tBatch Loss: 0.176396\tLearning Rate (w_theta): 0.000500\t TIME:1140.3s\n",
      "\t\t\t\tDisc: 0.080292\t\tSpars: 0.096104\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 302 [4000/8000 (50%)]\tBatch Loss: 0.182925\tLearning Rate (w_theta): 0.000500\t TIME:1141.7s\n",
      "\t\t\t\tDisc: 0.082925\t\tSpars: 0.100000\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 302...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1786015226827076\n",
      "Average validation loss: 0.17851438914024595\n",
      "Training epoch 303...\n",
      "\n",
      "Train Epoch: 303 [0/8000 (0%)]\tBatch Loss: 0.174489\tLearning Rate (w_theta): 0.000500\t TIME:1143.9s\n",
      "\t\t\t\tDisc: 0.076454\t\tSpars: 0.098035\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 303 [4000/8000 (50%)]\tBatch Loss: 0.175458\tLearning Rate (w_theta): 0.000500\t TIME:1145.4s\n",
      "\t\t\t\tDisc: 0.075964\t\tSpars: 0.099494\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 303...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1780768400382879\n",
      "Average validation loss: 0.17801505564550107\n",
      "Training epoch 304...\n",
      "\n",
      "Train Epoch: 304 [0/8000 (0%)]\tBatch Loss: 0.181780\tLearning Rate (w_theta): 0.000500\t TIME:1147.6s\n",
      "\t\t\t\tDisc: 0.082226\t\tSpars: 0.099555\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 304 [4000/8000 (50%)]\tBatch Loss: 0.178942\tLearning Rate (w_theta): 0.000500\t TIME:1149.1s\n",
      "\t\t\t\tDisc: 0.081704\t\tSpars: 0.097239\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 304...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1775770454673891\n",
      "Average validation loss: 0.17752834557788855\n",
      "Training epoch 305...\n",
      "\n",
      "Train Epoch: 305 [0/8000 (0%)]\tBatch Loss: 0.190121\tLearning Rate (w_theta): 0.000500\t TIME:1151.3s\n",
      "\t\t\t\tDisc: 0.088902\t\tSpars: 0.101219\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 305 [4000/8000 (50%)]\tBatch Loss: 0.171257\tLearning Rate (w_theta): 0.000500\t TIME:1152.7s\n",
      "\t\t\t\tDisc: 0.073352\t\tSpars: 0.097905\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 305...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.17709425595342151\n",
      "Average validation loss: 0.1770507150250563\n",
      "Training epoch 306...\n",
      "\n",
      "Train Epoch: 306 [0/8000 (0%)]\tBatch Loss: 0.173082\tLearning Rate (w_theta): 0.000500\t TIME:1155.0s\n",
      "\t\t\t\tDisc: 0.076439\t\tSpars: 0.096644\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 306 [4000/8000 (50%)]\tBatch Loss: 0.175495\tLearning Rate (w_theta): 0.000500\t TIME:1156.4s\n",
      "\t\t\t\tDisc: 0.079340\t\tSpars: 0.096154\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 306...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.17661166254433086\n",
      "Average validation loss: 0.17659254935611413\n",
      "Training epoch 307...\n",
      "\n",
      "Train Epoch: 307 [0/8000 (0%)]\tBatch Loss: 0.171252\tLearning Rate (w_theta): 0.000500\t TIME:1158.6s\n",
      "\t\t\t\tDisc: 0.076126\t\tSpars: 0.095127\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 307 [4000/8000 (50%)]\tBatch Loss: 0.186481\tLearning Rate (w_theta): 0.000500\t TIME:1160.1s\n",
      "\t\t\t\tDisc: 0.085786\t\tSpars: 0.100695\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 307...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.17614580916175296\n",
      "Average validation loss: 0.17614837297905697\n",
      "Training epoch 308...\n",
      "\n",
      "Train Epoch: 308 [0/8000 (0%)]\tBatch Loss: 0.176713\tLearning Rate (w_theta): 0.000500\t TIME:1162.3s\n",
      "\t\t\t\tDisc: 0.076957\t\tSpars: 0.099756\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 308 [4000/8000 (50%)]\tBatch Loss: 0.184153\tLearning Rate (w_theta): 0.000500\t TIME:1163.8s\n",
      "\t\t\t\tDisc: 0.082053\t\tSpars: 0.102100\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 308...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.17570506527327343\n",
      "Average validation loss: 0.17570603439814886\n",
      "Training epoch 309...\n",
      "\n",
      "Train Epoch: 309 [0/8000 (0%)]\tBatch Loss: 0.176888\tLearning Rate (w_theta): 0.000500\t TIME:1166.0s\n",
      "\t\t\t\tDisc: 0.079556\t\tSpars: 0.097332\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 309 [4000/8000 (50%)]\tBatch Loss: 0.173604\tLearning Rate (w_theta): 0.000500\t TIME:1167.4s\n",
      "\t\t\t\tDisc: 0.073671\t\tSpars: 0.099933\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 309...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.17525640380394283\n",
      "Average validation loss: 0.175280673841192\n",
      "Training epoch 310...\n",
      "\n",
      "Train Epoch: 310 [0/8000 (0%)]\tBatch Loss: 0.180152\tLearning Rate (w_theta): 0.000500\t TIME:1169.6s\n",
      "\t\t\t\tDisc: 0.082587\t\tSpars: 0.097565\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 310 [4000/8000 (50%)]\tBatch Loss: 0.174866\tLearning Rate (w_theta): 0.000500\t TIME:1171.1s\n",
      "\t\t\t\tDisc: 0.075988\t\tSpars: 0.098878\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 310...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1748326572875683\n",
      "Average validation loss: 0.17485918711274395\n",
      "Training epoch 311...\n",
      "\n",
      "Train Epoch: 311 [0/8000 (0%)]\tBatch Loss: 0.180984\tLearning Rate (w_theta): 0.000500\t TIME:1174.6s\n",
      "\t\t\t\tDisc: 0.080800\t\tSpars: 0.100184\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 311 [4000/8000 (50%)]\tBatch Loss: 0.175230\tLearning Rate (w_theta): 0.000500\t TIME:1176.1s\n",
      "\t\t\t\tDisc: 0.076532\t\tSpars: 0.098698\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 311...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1744099029511353\n",
      "Average validation loss: 0.17445004973777545\n",
      "Training epoch 312...\n",
      "\n",
      "Train Epoch: 312 [0/8000 (0%)]\tBatch Loss: 0.173562\tLearning Rate (w_theta): 0.000500\t TIME:1178.3s\n",
      "\t\t\t\tDisc: 0.073548\t\tSpars: 0.100014\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 312 [4000/8000 (50%)]\tBatch Loss: 0.169277\tLearning Rate (w_theta): 0.000500\t TIME:1179.8s\n",
      "\t\t\t\tDisc: 0.072823\t\tSpars: 0.096454\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 312...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.17398722187987084\n",
      "Average validation loss: 0.17405858138027652\n",
      "Training epoch 313...\n",
      "\n",
      "Train Epoch: 313 [0/8000 (0%)]\tBatch Loss: 0.168706\tLearning Rate (w_theta): 0.000500\t TIME:1182.0s\n",
      "\t\t\t\tDisc: 0.073178\t\tSpars: 0.095529\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 313 [4000/8000 (50%)]\tBatch Loss: 0.173649\tLearning Rate (w_theta): 0.000500\t TIME:1183.4s\n",
      "\t\t\t\tDisc: 0.077251\t\tSpars: 0.096398\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 313...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1735966317470544\n",
      "Average validation loss: 0.1736642388259636\n",
      "Training epoch 314...\n",
      "\n",
      "Train Epoch: 314 [0/8000 (0%)]\tBatch Loss: 0.176919\tLearning Rate (w_theta): 0.000500\t TIME:1185.6s\n",
      "\t\t\t\tDisc: 0.078183\t\tSpars: 0.098735\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 314 [4000/8000 (50%)]\tBatch Loss: 0.170491\tLearning Rate (w_theta): 0.000500\t TIME:1187.0s\n",
      "\t\t\t\tDisc: 0.072885\t\tSpars: 0.097606\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 314...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.17320303118432756\n",
      "Average validation loss: 0.17327601621875194\n",
      "Training epoch 315...\n",
      "\n",
      "Train Epoch: 315 [0/8000 (0%)]\tBatch Loss: 0.175345\tLearning Rate (w_theta): 0.000500\t TIME:1189.2s\n",
      "\t\t\t\tDisc: 0.072801\t\tSpars: 0.102544\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 315 [4000/8000 (50%)]\tBatch Loss: 0.174180\tLearning Rate (w_theta): 0.000500\t TIME:1190.7s\n",
      "\t\t\t\tDisc: 0.073836\t\tSpars: 0.100343\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 315...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.17280912708777282\n",
      "Average validation loss: 0.17289993291284322\n",
      "Training epoch 316...\n",
      "\n",
      "Train Epoch: 316 [0/8000 (0%)]\tBatch Loss: 0.173505\tLearning Rate (w_theta): 0.000500\t TIME:1192.9s\n",
      "\t\t\t\tDisc: 0.076683\t\tSpars: 0.096822\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 316 [4000/8000 (50%)]\tBatch Loss: 0.171983\tLearning Rate (w_theta): 0.000500\t TIME:1194.3s\n",
      "\t\t\t\tDisc: 0.072282\t\tSpars: 0.099701\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 316...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1724277809824936\n",
      "Average validation loss: 0.17253375530440165\n",
      "Training epoch 317...\n",
      "\n",
      "Train Epoch: 317 [0/8000 (0%)]\tBatch Loss: 0.172104\tLearning Rate (w_theta): 0.000500\t TIME:1196.7s\n",
      "\t\t\t\tDisc: 0.071252\t\tSpars: 0.100852\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 317 [4000/8000 (50%)]\tBatch Loss: 0.180856\tLearning Rate (w_theta): 0.000500\t TIME:1198.1s\n",
      "\t\t\t\tDisc: 0.079107\t\tSpars: 0.101749\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 317...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.17205122723193278\n",
      "Average validation loss: 0.1721797990150753\n",
      "Training epoch 318...\n",
      "\n",
      "Train Epoch: 318 [0/8000 (0%)]\tBatch Loss: 0.169126\tLearning Rate (w_theta): 0.000500\t TIME:1200.3s\n",
      "\t\t\t\tDisc: 0.073302\t\tSpars: 0.095824\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 318 [4000/8000 (50%)]\tBatch Loss: 0.168448\tLearning Rate (w_theta): 0.000500\t TIME:1201.7s\n",
      "\t\t\t\tDisc: 0.073678\t\tSpars: 0.094771\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 318...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1716937743842086\n",
      "Average validation loss: 0.17182598104263866\n",
      "Training epoch 319...\n",
      "\n",
      "Train Epoch: 319 [0/8000 (0%)]\tBatch Loss: 0.170773\tLearning Rate (w_theta): 0.000500\t TIME:1203.9s\n",
      "\t\t\t\tDisc: 0.074438\t\tSpars: 0.096335\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 319 [4000/8000 (50%)]\tBatch Loss: 0.166691\tLearning Rate (w_theta): 0.000500\t TIME:1205.3s\n",
      "\t\t\t\tDisc: 0.069700\t\tSpars: 0.096991\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 319...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.17133379318840825\n",
      "Average validation loss: 0.17147925365828465\n",
      "Training epoch 320...\n",
      "\n",
      "Train Epoch: 320 [0/8000 (0%)]\tBatch Loss: 0.167783\tLearning Rate (w_theta): 0.000500\t TIME:1207.5s\n",
      "\t\t\t\tDisc: 0.073893\t\tSpars: 0.093890\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 320 [4000/8000 (50%)]\tBatch Loss: 0.170566\tLearning Rate (w_theta): 0.000500\t TIME:1208.9s\n",
      "\t\t\t\tDisc: 0.071457\t\tSpars: 0.099108\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 320...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1709863747552482\n",
      "Average validation loss: 0.17113502535095154\n",
      "Training epoch 321...\n",
      "\n",
      "Train Epoch: 321 [0/8000 (0%)]\tBatch Loss: 0.180201\tLearning Rate (w_theta): 0.000500\t TIME:1212.5s\n",
      "\t\t\t\tDisc: 0.079740\t\tSpars: 0.100461\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 321 [4000/8000 (50%)]\tBatch Loss: 0.164884\tLearning Rate (w_theta): 0.000500\t TIME:1213.9s\n",
      "\t\t\t\tDisc: 0.068783\t\tSpars: 0.096101\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 321...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.17063452738987758\n",
      "Average validation loss: 0.17080037831996997\n",
      "Training epoch 322...\n",
      "\n",
      "Train Epoch: 322 [0/8000 (0%)]\tBatch Loss: 0.166729\tLearning Rate (w_theta): 0.000500\t TIME:1216.1s\n",
      "\t\t\t\tDisc: 0.068646\t\tSpars: 0.098084\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 322 [4000/8000 (50%)]\tBatch Loss: 0.175769\tLearning Rate (w_theta): 0.000500\t TIME:1217.6s\n",
      "\t\t\t\tDisc: 0.076821\t\tSpars: 0.098949\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 322...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.170290643649192\n",
      "Average validation loss: 0.17047270460689748\n",
      "Training epoch 323...\n",
      "\n",
      "Train Epoch: 323 [0/8000 (0%)]\tBatch Loss: 0.168779\tLearning Rate (w_theta): 0.000500\t TIME:1219.8s\n",
      "\t\t\t\tDisc: 0.069643\t\tSpars: 0.099137\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 323 [4000/8000 (50%)]\tBatch Loss: 0.172158\tLearning Rate (w_theta): 0.000500\t TIME:1221.2s\n",
      "\t\t\t\tDisc: 0.071676\t\tSpars: 0.100482\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 323...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16996343120027324\n",
      "Average validation loss: 0.17014657016238305\n",
      "Training epoch 324...\n",
      "\n",
      "Train Epoch: 324 [0/8000 (0%)]\tBatch Loss: 0.164549\tLearning Rate (w_theta): 0.000500\t TIME:1223.4s\n",
      "\t\t\t\tDisc: 0.067397\t\tSpars: 0.097152\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 324 [4000/8000 (50%)]\tBatch Loss: 0.169478\tLearning Rate (w_theta): 0.000500\t TIME:1224.8s\n",
      "\t\t\t\tDisc: 0.072484\t\tSpars: 0.096994\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 324...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16963780796162808\n",
      "Average validation loss: 0.16982628101261707\n",
      "Training epoch 325...\n",
      "\n",
      "Train Epoch: 325 [0/8000 (0%)]\tBatch Loss: 0.169659\tLearning Rate (w_theta): 0.000500\t TIME:1227.2s\n",
      "\t\t\t\tDisc: 0.073421\t\tSpars: 0.096238\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 325 [4000/8000 (50%)]\tBatch Loss: 0.172315\tLearning Rate (w_theta): 0.000500\t TIME:1228.6s\n",
      "\t\t\t\tDisc: 0.073730\t\tSpars: 0.098585\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 325...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1693203602487251\n",
      "Average validation loss: 0.16950967774036618\n",
      "Training epoch 326...\n",
      "\n",
      "Train Epoch: 326 [0/8000 (0%)]\tBatch Loss: 0.173955\tLearning Rate (w_theta): 0.000500\t TIME:1230.8s\n",
      "\t\t\t\tDisc: 0.074311\t\tSpars: 0.099643\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 326 [4000/8000 (50%)]\tBatch Loss: 0.165303\tLearning Rate (w_theta): 0.000500\t TIME:1232.3s\n",
      "\t\t\t\tDisc: 0.067995\t\tSpars: 0.097307\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 326...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16900234474049547\n",
      "Average validation loss: 0.16920141024701868\n",
      "Training epoch 327...\n",
      "\n",
      "Train Epoch: 327 [0/8000 (0%)]\tBatch Loss: 0.164648\tLearning Rate (w_theta): 0.000500\t TIME:1234.5s\n",
      "\t\t\t\tDisc: 0.067326\t\tSpars: 0.097322\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 327 [4000/8000 (50%)]\tBatch Loss: 0.171573\tLearning Rate (w_theta): 0.000500\t TIME:1235.9s\n",
      "\t\t\t\tDisc: 0.070642\t\tSpars: 0.100932\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 327...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16869269327429157\n",
      "Average validation loss: 0.16889915897739222\n",
      "Training epoch 328...\n",
      "\n",
      "Train Epoch: 328 [0/8000 (0%)]\tBatch Loss: 0.168523\tLearning Rate (w_theta): 0.000500\t TIME:1238.1s\n",
      "\t\t\t\tDisc: 0.069117\t\tSpars: 0.099406\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 328 [4000/8000 (50%)]\tBatch Loss: 0.171584\tLearning Rate (w_theta): 0.000500\t TIME:1239.6s\n",
      "\t\t\t\tDisc: 0.071056\t\tSpars: 0.100528\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 328...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16838945136537592\n",
      "Average validation loss: 0.1686032658208428\n",
      "Training epoch 329...\n",
      "\n",
      "Train Epoch: 329 [0/8000 (0%)]\tBatch Loss: 0.168302\tLearning Rate (w_theta): 0.000500\t TIME:1241.8s\n",
      "\t\t\t\tDisc: 0.069223\t\tSpars: 0.099079\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 329 [4000/8000 (50%)]\tBatch Loss: 0.167150\tLearning Rate (w_theta): 0.000500\t TIME:1243.3s\n",
      "\t\t\t\tDisc: 0.067468\t\tSpars: 0.099682\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 329...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1680901699185206\n",
      "Average validation loss: 0.16831227235533147\n",
      "Training epoch 330...\n",
      "\n",
      "Train Epoch: 330 [0/8000 (0%)]\tBatch Loss: 0.169025\tLearning Rate (w_theta): 0.000500\t TIME:1245.7s\n",
      "\t\t\t\tDisc: 0.070944\t\tSpars: 0.098080\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 330 [4000/8000 (50%)]\tBatch Loss: 0.166358\tLearning Rate (w_theta): 0.000500\t TIME:1247.2s\n",
      "\t\t\t\tDisc: 0.068771\t\tSpars: 0.097587\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 330...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1678068760824043\n",
      "Average validation loss: 0.1680195715665017\n",
      "Training epoch 331...\n",
      "\n",
      "Train Epoch: 331 [0/8000 (0%)]\tBatch Loss: 0.163954\tLearning Rate (w_theta): 0.000500\t TIME:1250.7s\n",
      "\t\t\t\tDisc: 0.068191\t\tSpars: 0.095763\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 331 [4000/8000 (50%)]\tBatch Loss: 0.163690\tLearning Rate (w_theta): 0.000500\t TIME:1252.2s\n",
      "\t\t\t\tDisc: 0.067375\t\tSpars: 0.096315\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 331...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16751339691907138\n",
      "Average validation loss: 0.1677369850242171\n",
      "Training epoch 332...\n",
      "\n",
      "Train Epoch: 332 [0/8000 (0%)]\tBatch Loss: 0.169160\tLearning Rate (w_theta): 0.000500\t TIME:1254.4s\n",
      "\t\t\t\tDisc: 0.072678\t\tSpars: 0.096482\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 332 [4000/8000 (50%)]\tBatch Loss: 0.168106\tLearning Rate (w_theta): 0.000500\t TIME:1255.9s\n",
      "\t\t\t\tDisc: 0.069402\t\tSpars: 0.098704\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 332...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1672290776402518\n",
      "Average validation loss: 0.1674613468727439\n",
      "Training epoch 333...\n",
      "\n",
      "Train Epoch: 333 [0/8000 (0%)]\tBatch Loss: 0.168836\tLearning Rate (w_theta): 0.000500\t TIME:1258.2s\n",
      "\t\t\t\tDisc: 0.069761\t\tSpars: 0.099075\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 333 [4000/8000 (50%)]\tBatch Loss: 0.165128\tLearning Rate (w_theta): 0.000500\t TIME:1259.7s\n",
      "\t\t\t\tDisc: 0.069143\t\tSpars: 0.095985\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 333...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16695418976987525\n",
      "Average validation loss: 0.16718963874010023\n",
      "Training epoch 334...\n",
      "\n",
      "Train Epoch: 334 [0/8000 (0%)]\tBatch Loss: 0.162760\tLearning Rate (w_theta): 0.000500\t TIME:1261.8s\n",
      "\t\t\t\tDisc: 0.064039\t\tSpars: 0.098721\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 334 [4000/8000 (50%)]\tBatch Loss: 0.167763\tLearning Rate (w_theta): 0.000500\t TIME:1263.3s\n",
      "\t\t\t\tDisc: 0.066835\t\tSpars: 0.100928\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 334...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16668417351321388\n",
      "Average validation loss: 0.16692207893367672\n",
      "Training epoch 335...\n",
      "\n",
      "Train Epoch: 335 [0/8000 (0%)]\tBatch Loss: 0.173016\tLearning Rate (w_theta): 0.000500\t TIME:1265.5s\n",
      "\t\t\t\tDisc: 0.074651\t\tSpars: 0.098365\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 335 [4000/8000 (50%)]\tBatch Loss: 0.168995\tLearning Rate (w_theta): 0.000500\t TIME:1266.9s\n",
      "\t\t\t\tDisc: 0.066561\t\tSpars: 0.102433\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 335...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16641982582181433\n",
      "Average validation loss: 0.1666582886349136\n",
      "Training epoch 336...\n",
      "\n",
      "Train Epoch: 336 [0/8000 (0%)]\tBatch Loss: 0.163169\tLearning Rate (w_theta): 0.000500\t TIME:1269.2s\n",
      "\t\t\t\tDisc: 0.065043\t\tSpars: 0.098126\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 336 [4000/8000 (50%)]\tBatch Loss: 0.164586\tLearning Rate (w_theta): 0.000500\t TIME:1270.6s\n",
      "\t\t\t\tDisc: 0.063436\t\tSpars: 0.101149\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 336...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1661485237157029\n",
      "Average validation loss: 0.1664083893216961\n",
      "Training epoch 337...\n",
      "\n",
      "Train Epoch: 337 [0/8000 (0%)]\tBatch Loss: 0.171715\tLearning Rate (w_theta): 0.000500\t TIME:1273.0s\n",
      "\t\t\t\tDisc: 0.068806\t\tSpars: 0.102909\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 337 [4000/8000 (50%)]\tBatch Loss: 0.171208\tLearning Rate (w_theta): 0.000500\t TIME:1274.5s\n",
      "\t\t\t\tDisc: 0.072496\t\tSpars: 0.098712\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 337...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16590667173986304\n",
      "Average validation loss: 0.16615262622291865\n",
      "Training epoch 338...\n",
      "\n",
      "Train Epoch: 338 [0/8000 (0%)]\tBatch Loss: 0.163129\tLearning Rate (w_theta): 0.000500\t TIME:1276.7s\n",
      "\t\t\t\tDisc: 0.066449\t\tSpars: 0.096680\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 338 [4000/8000 (50%)]\tBatch Loss: 0.163198\tLearning Rate (w_theta): 0.000500\t TIME:1278.2s\n",
      "\t\t\t\tDisc: 0.065814\t\tSpars: 0.097384\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 338...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16565206815120842\n",
      "Average validation loss: 0.16590536187612828\n",
      "Training epoch 339...\n",
      "\n",
      "Train Epoch: 339 [0/8000 (0%)]\tBatch Loss: 0.166391\tLearning Rate (w_theta): 0.000500\t TIME:1280.4s\n",
      "\t\t\t\tDisc: 0.066885\t\tSpars: 0.099506\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 339 [4000/8000 (50%)]\tBatch Loss: 0.168421\tLearning Rate (w_theta): 0.000500\t TIME:1281.9s\n",
      "\t\t\t\tDisc: 0.069542\t\tSpars: 0.098879\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 339...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1654041792755264\n",
      "Average validation loss: 0.16566495681087562\n",
      "Training epoch 340...\n",
      "\n",
      "Train Epoch: 340 [0/8000 (0%)]\tBatch Loss: 0.171238\tLearning Rate (w_theta): 0.000500\t TIME:1284.1s\n",
      "\t\t\t\tDisc: 0.072268\t\tSpars: 0.098970\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 340 [4000/8000 (50%)]\tBatch Loss: 0.159339\tLearning Rate (w_theta): 0.000500\t TIME:1285.6s\n",
      "\t\t\t\tDisc: 0.062772\t\tSpars: 0.096566\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 340...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16516740004194785\n",
      "Average validation loss: 0.16542563801821625\n",
      "Training epoch 341...\n",
      "\n",
      "Train Epoch: 341 [0/8000 (0%)]\tBatch Loss: 0.164650\tLearning Rate (w_theta): 0.000500\t TIME:1289.1s\n",
      "\t\t\t\tDisc: 0.067325\t\tSpars: 0.097324\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 341 [4000/8000 (50%)]\tBatch Loss: 0.167587\tLearning Rate (w_theta): 0.000500\t TIME:1290.6s\n",
      "\t\t\t\tDisc: 0.069503\t\tSpars: 0.098084\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 341...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1649266600542464\n",
      "Average validation loss: 0.16519346269862212\n",
      "Training epoch 342...\n",
      "\n",
      "Train Epoch: 342 [0/8000 (0%)]\tBatch Loss: 0.159525\tLearning Rate (w_theta): 0.000500\t TIME:1292.8s\n",
      "\t\t\t\tDisc: 0.063372\t\tSpars: 0.096153\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 342 [4000/8000 (50%)]\tBatch Loss: 0.168892\tLearning Rate (w_theta): 0.000500\t TIME:1294.3s\n",
      "\t\t\t\tDisc: 0.069680\t\tSpars: 0.099213\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 342...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16469154273642683\n",
      "Average validation loss: 0.16496577685111616\n",
      "Training epoch 343...\n",
      "\n",
      "Train Epoch: 343 [0/8000 (0%)]\tBatch Loss: 0.163843\tLearning Rate (w_theta): 0.000500\t TIME:1296.6s\n",
      "\t\t\t\tDisc: 0.065291\t\tSpars: 0.098552\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 343 [4000/8000 (50%)]\tBatch Loss: 0.163078\tLearning Rate (w_theta): 0.000500\t TIME:1298.1s\n",
      "\t\t\t\tDisc: 0.065898\t\tSpars: 0.097179\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 343...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1644602317592384\n",
      "Average validation loss: 0.16474318669465757\n",
      "Training epoch 344...\n",
      "\n",
      "Train Epoch: 344 [0/8000 (0%)]\tBatch Loss: 0.166461\tLearning Rate (w_theta): 0.000500\t TIME:1300.3s\n",
      "\t\t\t\tDisc: 0.065344\t\tSpars: 0.101117\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 344 [4000/8000 (50%)]\tBatch Loss: 0.158049\tLearning Rate (w_theta): 0.000500\t TIME:1301.8s\n",
      "\t\t\t\tDisc: 0.061066\t\tSpars: 0.096983\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 344...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16423846939108866\n",
      "Average validation loss: 0.1645221247589246\n",
      "Training epoch 345...\n",
      "\n",
      "Train Epoch: 345 [0/8000 (0%)]\tBatch Loss: 0.163889\tLearning Rate (w_theta): 0.000500\t TIME:1304.0s\n",
      "\t\t\t\tDisc: 0.070522\t\tSpars: 0.093368\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 345 [4000/8000 (50%)]\tBatch Loss: 0.163676\tLearning Rate (w_theta): 0.000500\t TIME:1305.4s\n",
      "\t\t\t\tDisc: 0.067855\t\tSpars: 0.095821\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 345...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16401787998756004\n",
      "Average validation loss: 0.16430493724445588\n",
      "Training epoch 346...\n",
      "\n",
      "Train Epoch: 346 [0/8000 (0%)]\tBatch Loss: 0.156926\tLearning Rate (w_theta): 0.000500\t TIME:1307.7s\n",
      "\t\t\t\tDisc: 0.060896\t\tSpars: 0.096030\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 346 [4000/8000 (50%)]\tBatch Loss: 0.162290\tLearning Rate (w_theta): 0.000500\t TIME:1309.1s\n",
      "\t\t\t\tDisc: 0.065109\t\tSpars: 0.097181\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 346...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16380261044681196\n",
      "Average validation loss: 0.16409077533361577\n",
      "Training epoch 347...\n",
      "\n",
      "Train Epoch: 347 [0/8000 (0%)]\tBatch Loss: 0.162908\tLearning Rate (w_theta): 0.000500\t TIME:1311.3s\n",
      "\t\t\t\tDisc: 0.064248\t\tSpars: 0.098661\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 347 [4000/8000 (50%)]\tBatch Loss: 0.167698\tLearning Rate (w_theta): 0.000500\t TIME:1312.8s\n",
      "\t\t\t\tDisc: 0.067073\t\tSpars: 0.100625\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 347...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16358774558433514\n",
      "Average validation loss: 0.16387940906390286\n",
      "Training epoch 348...\n",
      "\n",
      "Train Epoch: 348 [0/8000 (0%)]\tBatch Loss: 0.160775\tLearning Rate (w_theta): 0.000500\t TIME:1314.9s\n",
      "\t\t\t\tDisc: 0.063034\t\tSpars: 0.097741\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 348 [4000/8000 (50%)]\tBatch Loss: 0.161387\tLearning Rate (w_theta): 0.000500\t TIME:1316.4s\n",
      "\t\t\t\tDisc: 0.063195\t\tSpars: 0.098192\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 348...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16337761887843735\n",
      "Average validation loss: 0.16367134317349685\n",
      "Training epoch 349...\n",
      "\n",
      "Train Epoch: 349 [0/8000 (0%)]\tBatch Loss: 0.161141\tLearning Rate (w_theta): 0.000500\t TIME:1318.7s\n",
      "\t\t\t\tDisc: 0.062093\t\tSpars: 0.099048\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 349 [4000/8000 (50%)]\tBatch Loss: 0.169124\tLearning Rate (w_theta): 0.000500\t TIME:1320.1s\n",
      "\t\t\t\tDisc: 0.071828\t\tSpars: 0.097296\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 349...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16317421785168046\n",
      "Average validation loss: 0.16346469262611857\n",
      "Training epoch 350...\n",
      "\n",
      "Train Epoch: 350 [0/8000 (0%)]\tBatch Loss: 0.162726\tLearning Rate (w_theta): 0.000500\t TIME:1322.4s\n",
      "\t\t\t\tDisc: 0.066863\t\tSpars: 0.095863\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 350 [4000/8000 (50%)]\tBatch Loss: 0.160188\tLearning Rate (w_theta): 0.000500\t TIME:1323.9s\n",
      "\t\t\t\tDisc: 0.065515\t\tSpars: 0.094672\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 350...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1629681739857392\n",
      "Average validation loss: 0.16326432365261367\n",
      "Training epoch 351...\n",
      "\n",
      "Train Epoch: 351 [0/8000 (0%)]\tBatch Loss: 0.159819\tLearning Rate (w_theta): 0.000500\t TIME:1327.5s\n",
      "\t\t\t\tDisc: 0.065015\t\tSpars: 0.094803\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 351 [4000/8000 (50%)]\tBatch Loss: 0.162440\tLearning Rate (w_theta): 0.000500\t TIME:1329.0s\n",
      "\t\t\t\tDisc: 0.064947\t\tSpars: 0.097493\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 351...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16276916909490902\n",
      "Average validation loss: 0.16306689496489757\n",
      "Training epoch 352...\n",
      "\n",
      "Train Epoch: 352 [0/8000 (0%)]\tBatch Loss: 0.164346\tLearning Rate (w_theta): 0.000500\t TIME:1331.2s\n",
      "\t\t\t\tDisc: 0.067736\t\tSpars: 0.096611\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 352 [4000/8000 (50%)]\tBatch Loss: 0.164399\tLearning Rate (w_theta): 0.000500\t TIME:1332.7s\n",
      "\t\t\t\tDisc: 0.067469\t\tSpars: 0.096930\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 352...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16257168054162716\n",
      "Average validation loss: 0.1628740365719109\n",
      "Training epoch 353...\n",
      "\n",
      "Train Epoch: 353 [0/8000 (0%)]\tBatch Loss: 0.168283\tLearning Rate (w_theta): 0.000500\t TIME:1334.9s\n",
      "\t\t\t\tDisc: 0.068001\t\tSpars: 0.100282\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 353 [4000/8000 (50%)]\tBatch Loss: 0.157430\tLearning Rate (w_theta): 0.000500\t TIME:1336.4s\n",
      "\t\t\t\tDisc: 0.061013\t\tSpars: 0.096417\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 353...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16237856705947062\n",
      "Average validation loss: 0.1626828634493684\n",
      "Training epoch 354...\n",
      "\n",
      "Train Epoch: 354 [0/8000 (0%)]\tBatch Loss: 0.162091\tLearning Rate (w_theta): 0.000500\t TIME:1338.7s\n",
      "\t\t\t\tDisc: 0.062339\t\tSpars: 0.099752\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 354 [4000/8000 (50%)]\tBatch Loss: 0.165110\tLearning Rate (w_theta): 0.000500\t TIME:1340.2s\n",
      "\t\t\t\tDisc: 0.067499\t\tSpars: 0.097611\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 354...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1621864473278268\n",
      "Average validation loss: 0.16249463154932103\n",
      "Training epoch 355...\n",
      "\n",
      "Train Epoch: 355 [0/8000 (0%)]\tBatch Loss: 0.165067\tLearning Rate (w_theta): 0.000500\t TIME:1342.5s\n",
      "\t\t\t\tDisc: 0.065261\t\tSpars: 0.099807\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 355 [4000/8000 (50%)]\tBatch Loss: 0.156969\tLearning Rate (w_theta): 0.000500\t TIME:1344.0s\n",
      "\t\t\t\tDisc: 0.061032\t\tSpars: 0.095937\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 355...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16200034673190986\n",
      "Average validation loss: 0.1623066152961852\n",
      "Training epoch 356...\n",
      "\n",
      "Train Epoch: 356 [0/8000 (0%)]\tBatch Loss: 0.162424\tLearning Rate (w_theta): 0.000500\t TIME:1346.2s\n",
      "\t\t\t\tDisc: 0.065483\t\tSpars: 0.096941\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 356 [4000/8000 (50%)]\tBatch Loss: 0.157946\tLearning Rate (w_theta): 0.000500\t TIME:1347.7s\n",
      "\t\t\t\tDisc: 0.062317\t\tSpars: 0.095630\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 356...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16180892032524608\n",
      "Average validation loss: 0.16212510894719964\n",
      "Training epoch 357...\n",
      "\n",
      "Train Epoch: 357 [0/8000 (0%)]\tBatch Loss: 0.161913\tLearning Rate (w_theta): 0.000500\t TIME:1349.9s\n",
      "\t\t\t\tDisc: 0.065970\t\tSpars: 0.095943\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 357 [4000/8000 (50%)]\tBatch Loss: 0.162019\tLearning Rate (w_theta): 0.000500\t TIME:1351.4s\n",
      "\t\t\t\tDisc: 0.064385\t\tSpars: 0.097635\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 357...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16162718608014529\n",
      "Average validation loss: 0.16194450498463506\n",
      "Training epoch 358...\n",
      "\n",
      "Train Epoch: 358 [0/8000 (0%)]\tBatch Loss: 0.170133\tLearning Rate (w_theta): 0.000500\t TIME:1353.6s\n",
      "\t\t\t\tDisc: 0.066577\t\tSpars: 0.103556\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 358 [4000/8000 (50%)]\tBatch Loss: 0.168474\tLearning Rate (w_theta): 0.000500\t TIME:1355.1s\n",
      "\t\t\t\tDisc: 0.066231\t\tSpars: 0.102243\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 358...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16144624454422207\n",
      "Average validation loss: 0.1617664160549798\n",
      "Training epoch 359...\n",
      "\n",
      "Train Epoch: 359 [0/8000 (0%)]\tBatch Loss: 0.158709\tLearning Rate (w_theta): 0.000500\t TIME:1357.3s\n",
      "\t\t\t\tDisc: 0.062832\t\tSpars: 0.095877\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 359 [4000/8000 (50%)]\tBatch Loss: 0.162634\tLearning Rate (w_theta): 0.000500\t TIME:1358.7s\n",
      "\t\t\t\tDisc: 0.065133\t\tSpars: 0.097502\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 359...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16126914573967224\n",
      "Average validation loss: 0.16158891314156026\n",
      "Training epoch 360...\n",
      "\n",
      "Train Epoch: 360 [0/8000 (0%)]\tBatch Loss: 0.161715\tLearning Rate (w_theta): 0.000500\t TIME:1360.9s\n",
      "\t\t\t\tDisc: 0.059234\t\tSpars: 0.102481\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 360 [4000/8000 (50%)]\tBatch Loss: 0.162550\tLearning Rate (w_theta): 0.000500\t TIME:1362.3s\n",
      "\t\t\t\tDisc: 0.064269\t\tSpars: 0.098281\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 360...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16109337279841554\n",
      "Average validation loss: 0.1614136203712777\n",
      "Training epoch 361...\n",
      "\n",
      "Train Epoch: 361 [0/8000 (0%)]\tBatch Loss: 0.162156\tLearning Rate (w_theta): 0.000500\t TIME:1365.9s\n",
      "\t\t\t\tDisc: 0.064881\t\tSpars: 0.097274\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 361 [4000/8000 (50%)]\tBatch Loss: 0.165120\tLearning Rate (w_theta): 0.000500\t TIME:1367.3s\n",
      "\t\t\t\tDisc: 0.067022\t\tSpars: 0.098099\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 361...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16091956742815716\n",
      "Average validation loss: 0.161240658545817\n",
      "Training epoch 362...\n",
      "\n",
      "Train Epoch: 362 [0/8000 (0%)]\tBatch Loss: 0.163923\tLearning Rate (w_theta): 0.000500\t TIME:1369.7s\n",
      "\t\t\t\tDisc: 0.063790\t\tSpars: 0.100133\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 362 [4000/8000 (50%)]\tBatch Loss: 0.156207\tLearning Rate (w_theta): 0.000500\t TIME:1371.2s\n",
      "\t\t\t\tDisc: 0.062958\t\tSpars: 0.093249\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 362...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16074660788846218\n",
      "Average validation loss: 0.16107065375386595\n",
      "Training epoch 363...\n",
      "\n",
      "Train Epoch: 363 [0/8000 (0%)]\tBatch Loss: 0.163715\tLearning Rate (w_theta): 0.000500\t TIME:1373.4s\n",
      "\t\t\t\tDisc: 0.066239\t\tSpars: 0.097476\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 363 [4000/8000 (50%)]\tBatch Loss: 0.163616\tLearning Rate (w_theta): 0.000500\t TIME:1374.8s\n",
      "\t\t\t\tDisc: 0.065291\t\tSpars: 0.098325\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 363...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16057712384348688\n",
      "Average validation loss: 0.16090427983282768\n",
      "Training epoch 364...\n",
      "\n",
      "Train Epoch: 364 [0/8000 (0%)]\tBatch Loss: 0.162594\tLearning Rate (w_theta): 0.000500\t TIME:1377.0s\n",
      "\t\t\t\tDisc: 0.063516\t\tSpars: 0.099078\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 364 [4000/8000 (50%)]\tBatch Loss: 0.161582\tLearning Rate (w_theta): 0.000500\t TIME:1378.5s\n",
      "\t\t\t\tDisc: 0.061904\t\tSpars: 0.099678\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 364...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1604125454399764\n",
      "Average validation loss: 0.1607388973421293\n",
      "Training epoch 365...\n",
      "\n",
      "Train Epoch: 365 [0/8000 (0%)]\tBatch Loss: 0.165750\tLearning Rate (w_theta): 0.000500\t TIME:1380.8s\n",
      "\t\t\t\tDisc: 0.065591\t\tSpars: 0.100159\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 365 [4000/8000 (50%)]\tBatch Loss: 0.158960\tLearning Rate (w_theta): 0.000500\t TIME:1382.2s\n",
      "\t\t\t\tDisc: 0.064744\t\tSpars: 0.094216\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 365...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.16025211907916456\n",
      "Average validation loss: 0.1605729203503043\n",
      "Training epoch 366...\n",
      "\n",
      "Train Epoch: 366 [0/8000 (0%)]\tBatch Loss: 0.151548\tLearning Rate (w_theta): 0.000500\t TIME:1384.5s\n",
      "\t\t\t\tDisc: 0.057147\t\tSpars: 0.094400\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 366 [4000/8000 (50%)]\tBatch Loss: 0.160571\tLearning Rate (w_theta): 0.000500\t TIME:1386.0s\n",
      "\t\t\t\tDisc: 0.063375\t\tSpars: 0.097196\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 366...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1600876717427671\n",
      "Average validation loss: 0.1604118555870308\n",
      "Training epoch 367...\n",
      "\n",
      "Train Epoch: 367 [0/8000 (0%)]\tBatch Loss: 0.160345\tLearning Rate (w_theta): 0.000500\t TIME:1388.3s\n",
      "\t\t\t\tDisc: 0.062832\t\tSpars: 0.097513\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 367 [4000/8000 (50%)]\tBatch Loss: 0.162457\tLearning Rate (w_theta): 0.000500\t TIME:1389.8s\n",
      "\t\t\t\tDisc: 0.066547\t\tSpars: 0.095910\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 367...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1599323679882636\n",
      "Average validation loss: 0.16024869403931896\n",
      "Training epoch 368...\n",
      "\n",
      "Train Epoch: 368 [0/8000 (0%)]\tBatch Loss: 0.157922\tLearning Rate (w_theta): 0.000500\t TIME:1392.2s\n",
      "\t\t\t\tDisc: 0.058884\t\tSpars: 0.099038\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 368 [4000/8000 (50%)]\tBatch Loss: 0.160899\tLearning Rate (w_theta): 0.000500\t TIME:1393.6s\n",
      "\t\t\t\tDisc: 0.062014\t\tSpars: 0.098885\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 368...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1597726819071833\n",
      "Average validation loss: 0.160089945671528\n",
      "Training epoch 369...\n",
      "\n",
      "Train Epoch: 369 [0/8000 (0%)]\tBatch Loss: 0.160707\tLearning Rate (w_theta): 0.000500\t TIME:1395.8s\n",
      "\t\t\t\tDisc: 0.062396\t\tSpars: 0.098311\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 369 [4000/8000 (50%)]\tBatch Loss: 0.161716\tLearning Rate (w_theta): 0.000500\t TIME:1397.3s\n",
      "\t\t\t\tDisc: 0.061931\t\tSpars: 0.099785\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 369...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15962078551908532\n",
      "Average validation loss: 0.15993121893086912\n",
      "Training epoch 370...\n",
      "\n",
      "Train Epoch: 370 [0/8000 (0%)]\tBatch Loss: 0.162486\tLearning Rate (w_theta): 0.000500\t TIME:1399.5s\n",
      "\t\t\t\tDisc: 0.061759\t\tSpars: 0.100727\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 370 [4000/8000 (50%)]\tBatch Loss: 0.158897\tLearning Rate (w_theta): 0.000500\t TIME:1401.0s\n",
      "\t\t\t\tDisc: 0.062606\t\tSpars: 0.096290\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 370...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1594665731763384\n",
      "Average validation loss: 0.15977537179692736\n",
      "Training epoch 371...\n",
      "\n",
      "Train Epoch: 371 [0/8000 (0%)]\tBatch Loss: 0.155248\tLearning Rate (w_theta): 0.000500\t TIME:1404.6s\n",
      "\t\t\t\tDisc: 0.059140\t\tSpars: 0.096108\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 371 [4000/8000 (50%)]\tBatch Loss: 0.157759\tLearning Rate (w_theta): 0.000500\t TIME:1406.0s\n",
      "\t\t\t\tDisc: 0.059068\t\tSpars: 0.098691\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 371...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15932065055133812\n",
      "Average validation loss: 0.15961845322894003\n",
      "Training epoch 372...\n",
      "\n",
      "Train Epoch: 372 [0/8000 (0%)]\tBatch Loss: 0.157798\tLearning Rate (w_theta): 0.000500\t TIME:1408.3s\n",
      "\t\t\t\tDisc: 0.060418\t\tSpars: 0.097381\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 372 [4000/8000 (50%)]\tBatch Loss: 0.158740\tLearning Rate (w_theta): 0.000500\t TIME:1409.7s\n",
      "\t\t\t\tDisc: 0.062643\t\tSpars: 0.096097\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 372...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15916919519630085\n",
      "Average validation loss: 0.1594660886133391\n",
      "Training epoch 373...\n",
      "\n",
      "Train Epoch: 373 [0/8000 (0%)]\tBatch Loss: 0.160639\tLearning Rate (w_theta): 0.000500\t TIME:1412.0s\n",
      "\t\t\t\tDisc: 0.060649\t\tSpars: 0.099990\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 373 [4000/8000 (50%)]\tBatch Loss: 0.157830\tLearning Rate (w_theta): 0.000500\t TIME:1413.5s\n",
      "\t\t\t\tDisc: 0.060863\t\tSpars: 0.096966\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 373...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15902479083965837\n",
      "Average validation loss: 0.15931404340393304\n",
      "Training epoch 374...\n",
      "\n",
      "Train Epoch: 374 [0/8000 (0%)]\tBatch Loss: 0.166058\tLearning Rate (w_theta): 0.000500\t TIME:1415.7s\n",
      "\t\t\t\tDisc: 0.065067\t\tSpars: 0.100991\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 374 [4000/8000 (50%)]\tBatch Loss: 0.160744\tLearning Rate (w_theta): 0.000500\t TIME:1417.2s\n",
      "\t\t\t\tDisc: 0.060529\t\tSpars: 0.100216\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 374...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15887953388675163\n",
      "Average validation loss: 0.15916448926615656\n",
      "Training epoch 375...\n",
      "\n",
      "Train Epoch: 375 [0/8000 (0%)]\tBatch Loss: 0.157110\tLearning Rate (w_theta): 0.000500\t TIME:1419.6s\n",
      "\t\t\t\tDisc: 0.060639\t\tSpars: 0.096471\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 375 [4000/8000 (50%)]\tBatch Loss: 0.155185\tLearning Rate (w_theta): 0.000500\t TIME:1421.0s\n",
      "\t\t\t\tDisc: 0.058644\t\tSpars: 0.096541\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 375...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15873379605340696\n",
      "Average validation loss: 0.1590202009491145\n",
      "Training epoch 376...\n",
      "\n",
      "Train Epoch: 376 [0/8000 (0%)]\tBatch Loss: 0.161742\tLearning Rate (w_theta): 0.000500\t TIME:1423.3s\n",
      "\t\t\t\tDisc: 0.062345\t\tSpars: 0.099396\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 376 [4000/8000 (50%)]\tBatch Loss: 0.161249\tLearning Rate (w_theta): 0.000500\t TIME:1424.8s\n",
      "\t\t\t\tDisc: 0.062146\t\tSpars: 0.099102\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 376...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15859710638951585\n",
      "Average validation loss: 0.15887332577091665\n",
      "Training epoch 377...\n",
      "\n",
      "Train Epoch: 377 [0/8000 (0%)]\tBatch Loss: 0.158588\tLearning Rate (w_theta): 0.000500\t TIME:1427.0s\n",
      "\t\t\t\tDisc: 0.062276\t\tSpars: 0.096312\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 377 [4000/8000 (50%)]\tBatch Loss: 0.153542\tLearning Rate (w_theta): 0.000500\t TIME:1428.4s\n",
      "\t\t\t\tDisc: 0.056574\t\tSpars: 0.096968\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 377...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15845554134951673\n",
      "Average validation loss: 0.15872951517394585\n",
      "Training epoch 378...\n",
      "\n",
      "Train Epoch: 378 [0/8000 (0%)]\tBatch Loss: 0.159163\tLearning Rate (w_theta): 0.000500\t TIME:1430.6s\n",
      "\t\t\t\tDisc: 0.063988\t\tSpars: 0.095175\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 378 [4000/8000 (50%)]\tBatch Loss: 0.155065\tLearning Rate (w_theta): 0.000500\t TIME:1432.1s\n",
      "\t\t\t\tDisc: 0.056143\t\tSpars: 0.098922\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 378...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15831631225966236\n",
      "Average validation loss: 0.1585886059155167\n",
      "Training epoch 379...\n",
      "\n",
      "Train Epoch: 379 [0/8000 (0%)]\tBatch Loss: 0.164379\tLearning Rate (w_theta): 0.000500\t TIME:1434.4s\n",
      "\t\t\t\tDisc: 0.065678\t\tSpars: 0.098701\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 379 [4000/8000 (50%)]\tBatch Loss: 0.156622\tLearning Rate (w_theta): 0.000500\t TIME:1435.9s\n",
      "\t\t\t\tDisc: 0.058253\t\tSpars: 0.098370\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 379...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1581817143396688\n",
      "Average validation loss: 0.15844801273260614\n",
      "Training epoch 380...\n",
      "\n",
      "Train Epoch: 380 [0/8000 (0%)]\tBatch Loss: 0.162729\tLearning Rate (w_theta): 0.000500\t TIME:1438.1s\n",
      "\t\t\t\tDisc: 0.063512\t\tSpars: 0.099217\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 380 [4000/8000 (50%)]\tBatch Loss: 0.153296\tLearning Rate (w_theta): 0.000500\t TIME:1439.6s\n",
      "\t\t\t\tDisc: 0.056770\t\tSpars: 0.096526\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 380...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1580455517974238\n",
      "Average validation loss: 0.15830997382474646\n",
      "Training epoch 381...\n",
      "\n",
      "Train Epoch: 381 [0/8000 (0%)]\tBatch Loss: 0.158458\tLearning Rate (w_theta): 0.000500\t TIME:1443.1s\n",
      "\t\t\t\tDisc: 0.060733\t\tSpars: 0.097725\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 381 [4000/8000 (50%)]\tBatch Loss: 0.162527\tLearning Rate (w_theta): 0.000500\t TIME:1444.6s\n",
      "\t\t\t\tDisc: 0.063979\t\tSpars: 0.098548\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 381...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15791281846077035\n",
      "Average validation loss: 0.15817431490918848\n",
      "Training epoch 382...\n",
      "\n",
      "Train Epoch: 382 [0/8000 (0%)]\tBatch Loss: 0.162099\tLearning Rate (w_theta): 0.000500\t TIME:1446.9s\n",
      "\t\t\t\tDisc: 0.060968\t\tSpars: 0.101131\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 382 [4000/8000 (50%)]\tBatch Loss: 0.161572\tLearning Rate (w_theta): 0.000500\t TIME:1448.4s\n",
      "\t\t\t\tDisc: 0.063044\t\tSpars: 0.098528\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 382...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15778236204904034\n",
      "Average validation loss: 0.158039474498467\n",
      "Training epoch 383...\n",
      "\n",
      "Train Epoch: 383 [0/8000 (0%)]\tBatch Loss: 0.160631\tLearning Rate (w_theta): 0.000500\t TIME:1450.6s\n",
      "\t\t\t\tDisc: 0.062760\t\tSpars: 0.097871\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 383 [4000/8000 (50%)]\tBatch Loss: 0.156549\tLearning Rate (w_theta): 0.000500\t TIME:1452.1s\n",
      "\t\t\t\tDisc: 0.058136\t\tSpars: 0.098413\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 383...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15765102254443575\n",
      "Average validation loss: 0.1579058580796911\n",
      "Training epoch 384...\n",
      "\n",
      "Train Epoch: 384 [0/8000 (0%)]\tBatch Loss: 0.153985\tLearning Rate (w_theta): 0.000500\t TIME:1454.3s\n",
      "\t\t\t\tDisc: 0.056677\t\tSpars: 0.097307\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 384 [4000/8000 (50%)]\tBatch Loss: 0.159240\tLearning Rate (w_theta): 0.000500\t TIME:1455.8s\n",
      "\t\t\t\tDisc: 0.060454\t\tSpars: 0.098787\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 384...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1575184594910748\n",
      "Average validation loss: 0.15777627005387368\n",
      "Training epoch 385...\n",
      "\n",
      "Train Epoch: 385 [0/8000 (0%)]\tBatch Loss: 0.159088\tLearning Rate (w_theta): 0.000500\t TIME:1458.0s\n",
      "\t\t\t\tDisc: 0.062507\t\tSpars: 0.096581\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 385 [4000/8000 (50%)]\tBatch Loss: 0.153609\tLearning Rate (w_theta): 0.000500\t TIME:1459.5s\n",
      "\t\t\t\tDisc: 0.056152\t\tSpars: 0.097457\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 385...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1573933394009902\n",
      "Average validation loss: 0.15764542926585776\n",
      "Training epoch 386...\n",
      "\n",
      "Train Epoch: 386 [0/8000 (0%)]\tBatch Loss: 0.160101\tLearning Rate (w_theta): 0.000500\t TIME:1461.7s\n",
      "\t\t\t\tDisc: 0.062240\t\tSpars: 0.097861\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 386 [4000/8000 (50%)]\tBatch Loss: 0.155855\tLearning Rate (w_theta): 0.000500\t TIME:1463.2s\n",
      "\t\t\t\tDisc: 0.057521\t\tSpars: 0.098335\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 386...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.157261942823281\n",
      "Average validation loss: 0.1575193664133575\n",
      "Training epoch 387...\n",
      "\n",
      "Train Epoch: 387 [0/8000 (0%)]\tBatch Loss: 0.160509\tLearning Rate (w_theta): 0.000500\t TIME:1465.4s\n",
      "\t\t\t\tDisc: 0.063291\t\tSpars: 0.097217\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 387 [4000/8000 (50%)]\tBatch Loss: 0.153546\tLearning Rate (w_theta): 0.000500\t TIME:1466.9s\n",
      "\t\t\t\tDisc: 0.059713\t\tSpars: 0.093833\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 387...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15713661347662836\n",
      "Average validation loss: 0.1573933568142778\n",
      "Training epoch 388...\n",
      "\n",
      "Train Epoch: 388 [0/8000 (0%)]\tBatch Loss: 0.155546\tLearning Rate (w_theta): 0.000500\t TIME:1469.2s\n",
      "\t\t\t\tDisc: 0.061041\t\tSpars: 0.094505\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 388 [4000/8000 (50%)]\tBatch Loss: 0.157961\tLearning Rate (w_theta): 0.000500\t TIME:1470.7s\n",
      "\t\t\t\tDisc: 0.059495\t\tSpars: 0.098465\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 388...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1570113350724252\n",
      "Average validation loss: 0.15726897722384997\n",
      "Training epoch 389...\n",
      "\n",
      "Train Epoch: 389 [0/8000 (0%)]\tBatch Loss: 0.155065\tLearning Rate (w_theta): 0.000500\t TIME:1472.9s\n",
      "\t\t\t\tDisc: 0.059659\t\tSpars: 0.095407\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 389 [4000/8000 (50%)]\tBatch Loss: 0.154698\tLearning Rate (w_theta): 0.000500\t TIME:1474.3s\n",
      "\t\t\t\tDisc: 0.058278\t\tSpars: 0.096420\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 389...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1568880406006958\n",
      "Average validation loss: 0.15714559725495397\n",
      "Training epoch 390...\n",
      "\n",
      "Train Epoch: 390 [0/8000 (0%)]\tBatch Loss: 0.154868\tLearning Rate (w_theta): 0.000500\t TIME:1476.6s\n",
      "\t\t\t\tDisc: 0.059311\t\tSpars: 0.095558\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 390 [4000/8000 (50%)]\tBatch Loss: 0.155442\tLearning Rate (w_theta): 0.000500\t TIME:1478.0s\n",
      "\t\t\t\tDisc: 0.061071\t\tSpars: 0.094372\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 390...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1567663706982245\n",
      "Average validation loss: 0.15702442592604984\n",
      "Training epoch 391...\n",
      "\n",
      "Train Epoch: 391 [0/8000 (0%)]\tBatch Loss: 0.160714\tLearning Rate (w_theta): 0.000500\t TIME:1481.6s\n",
      "\t\t\t\tDisc: 0.059739\t\tSpars: 0.100975\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 391 [4000/8000 (50%)]\tBatch Loss: 0.155947\tLearning Rate (w_theta): 0.000500\t TIME:1483.1s\n",
      "\t\t\t\tDisc: 0.058123\t\tSpars: 0.097824\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 391...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15664601638527081\n",
      "Average validation loss: 0.15690397574948806\n",
      "Training epoch 392...\n",
      "\n",
      "Train Epoch: 392 [0/8000 (0%)]\tBatch Loss: 0.157312\tLearning Rate (w_theta): 0.000500\t TIME:1485.4s\n",
      "\t\t\t\tDisc: 0.062009\t\tSpars: 0.095303\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 392 [4000/8000 (50%)]\tBatch Loss: 0.150548\tLearning Rate (w_theta): 0.000500\t TIME:1486.8s\n",
      "\t\t\t\tDisc: 0.055104\t\tSpars: 0.095444\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 392...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15652335412321114\n",
      "Average validation loss: 0.15678668258109016\n",
      "Training epoch 393...\n",
      "\n",
      "Train Epoch: 393 [0/8000 (0%)]\tBatch Loss: 0.159065\tLearning Rate (w_theta): 0.000500\t TIME:1489.1s\n",
      "\t\t\t\tDisc: 0.062832\t\tSpars: 0.096233\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 393 [4000/8000 (50%)]\tBatch Loss: 0.155352\tLearning Rate (w_theta): 0.000500\t TIME:1490.6s\n",
      "\t\t\t\tDisc: 0.056463\t\tSpars: 0.098888\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 393...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15640781303461643\n",
      "Average validation loss: 0.15666780714953876\n",
      "Training epoch 394...\n",
      "\n",
      "Train Epoch: 394 [0/8000 (0%)]\tBatch Loss: 0.159341\tLearning Rate (w_theta): 0.000500\t TIME:1492.8s\n",
      "\t\t\t\tDisc: 0.064261\t\tSpars: 0.095080\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 394 [4000/8000 (50%)]\tBatch Loss: 0.157709\tLearning Rate (w_theta): 0.000500\t TIME:1494.3s\n",
      "\t\t\t\tDisc: 0.059539\t\tSpars: 0.098171\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 394...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15628684263531994\n",
      "Average validation loss: 0.15655271997832199\n",
      "Training epoch 395...\n",
      "\n",
      "Train Epoch: 395 [0/8000 (0%)]\tBatch Loss: 0.155809\tLearning Rate (w_theta): 0.000500\t TIME:1496.7s\n",
      "\t\t\t\tDisc: 0.058635\t\tSpars: 0.097174\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 395 [4000/8000 (50%)]\tBatch Loss: 0.150865\tLearning Rate (w_theta): 0.000500\t TIME:1498.2s\n",
      "\t\t\t\tDisc: 0.054961\t\tSpars: 0.095904\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 395...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15617305632683617\n",
      "Average validation loss: 0.15643656472535541\n",
      "Training epoch 396...\n",
      "\n",
      "Train Epoch: 396 [0/8000 (0%)]\tBatch Loss: 0.149668\tLearning Rate (w_theta): 0.000500\t TIME:1500.4s\n",
      "\t\t\t\tDisc: 0.056545\t\tSpars: 0.093123\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 396 [4000/8000 (50%)]\tBatch Loss: 0.156890\tLearning Rate (w_theta): 0.000500\t TIME:1501.9s\n",
      "\t\t\t\tDisc: 0.059107\t\tSpars: 0.097783\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 396...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15605795060762742\n",
      "Average validation loss: 0.15632132811098665\n",
      "Training epoch 397...\n",
      "\n",
      "Train Epoch: 397 [0/8000 (0%)]\tBatch Loss: 0.154800\tLearning Rate (w_theta): 0.000500\t TIME:1504.1s\n",
      "\t\t\t\tDisc: 0.058238\t\tSpars: 0.096562\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 397 [4000/8000 (50%)]\tBatch Loss: 0.160193\tLearning Rate (w_theta): 0.000500\t TIME:1505.5s\n",
      "\t\t\t\tDisc: 0.063139\t\tSpars: 0.097054\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 397...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15594275264196195\n",
      "Average validation loss: 0.15620794241536065\n",
      "Training epoch 398...\n",
      "\n",
      "Train Epoch: 398 [0/8000 (0%)]\tBatch Loss: 0.156737\tLearning Rate (w_theta): 0.000500\t TIME:1507.7s\n",
      "\t\t\t\tDisc: 0.058021\t\tSpars: 0.098716\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 398 [4000/8000 (50%)]\tBatch Loss: 0.154090\tLearning Rate (w_theta): 0.000500\t TIME:1509.2s\n",
      "\t\t\t\tDisc: 0.058961\t\tSpars: 0.095129\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 398...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15583053638853223\n",
      "Average validation loss: 0.15609493726993082\n",
      "Training epoch 399...\n",
      "\n",
      "Train Epoch: 399 [0/8000 (0%)]\tBatch Loss: 0.154928\tLearning Rate (w_theta): 0.000500\t TIME:1511.4s\n",
      "\t\t\t\tDisc: 0.056367\t\tSpars: 0.098561\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 399 [4000/8000 (50%)]\tBatch Loss: 0.158914\tLearning Rate (w_theta): 0.000500\t TIME:1512.9s\n",
      "\t\t\t\tDisc: 0.058243\t\tSpars: 0.100671\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 399...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15571862948154838\n",
      "Average validation loss: 0.1559827695696704\n",
      "Training epoch 400...\n",
      "\n",
      "Train Epoch: 400 [0/8000 (0%)]\tBatch Loss: 0.152750\tLearning Rate (w_theta): 0.000500\t TIME:1515.1s\n",
      "\t\t\t\tDisc: 0.060796\t\tSpars: 0.091954\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 400 [4000/8000 (50%)]\tBatch Loss: 0.155541\tLearning Rate (w_theta): 0.000500\t TIME:1516.6s\n",
      "\t\t\t\tDisc: 0.055662\t\tSpars: 0.099879\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 400...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15560686373465765\n",
      "Average validation loss: 0.1558726194412994\n",
      "Training epoch 401...\n",
      "\n",
      "Train Epoch: 401 [0/8000 (0%)]\tBatch Loss: 0.156271\tLearning Rate (w_theta): 0.000500\t TIME:1520.3s\n",
      "\t\t\t\tDisc: 0.061233\t\tSpars: 0.095038\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 401 [4000/8000 (50%)]\tBatch Loss: 0.154041\tLearning Rate (w_theta): 0.000500\t TIME:1521.8s\n",
      "\t\t\t\tDisc: 0.060586\t\tSpars: 0.093455\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 401...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15550006939417718\n",
      "Average validation loss: 0.15576153761871386\n",
      "Training epoch 402...\n",
      "\n",
      "Train Epoch: 402 [0/8000 (0%)]\tBatch Loss: 0.152160\tLearning Rate (w_theta): 0.000500\t TIME:1524.2s\n",
      "\t\t\t\tDisc: 0.054667\t\tSpars: 0.097492\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 402 [4000/8000 (50%)]\tBatch Loss: 0.153090\tLearning Rate (w_theta): 0.000500\t TIME:1525.6s\n",
      "\t\t\t\tDisc: 0.057157\t\tSpars: 0.095934\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 402...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15539003385299419\n",
      "Average validation loss: 0.1556529161378618\n",
      "Training epoch 403...\n",
      "\n",
      "Train Epoch: 403 [0/8000 (0%)]\tBatch Loss: 0.156798\tLearning Rate (w_theta): 0.000500\t TIME:1527.9s\n",
      "\t\t\t\tDisc: 0.058916\t\tSpars: 0.097882\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 403 [4000/8000 (50%)]\tBatch Loss: 0.159196\tLearning Rate (w_theta): 0.000500\t TIME:1529.4s\n",
      "\t\t\t\tDisc: 0.060661\t\tSpars: 0.098535\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 403...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1552819969742786\n",
      "Average validation loss: 0.1555462094789753\n",
      "Training epoch 404...\n",
      "\n",
      "Train Epoch: 404 [0/8000 (0%)]\tBatch Loss: 0.155365\tLearning Rate (w_theta): 0.000500\t TIME:1531.7s\n",
      "\t\t\t\tDisc: 0.057438\t\tSpars: 0.097927\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 404 [4000/8000 (50%)]\tBatch Loss: 0.157851\tLearning Rate (w_theta): 0.000500\t TIME:1533.1s\n",
      "\t\t\t\tDisc: 0.062159\t\tSpars: 0.095691\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 404...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15517874554404848\n",
      "Average validation loss: 0.1554385150518172\n",
      "Training epoch 405...\n",
      "\n",
      "Train Epoch: 405 [0/8000 (0%)]\tBatch Loss: 0.155521\tLearning Rate (w_theta): 0.000500\t TIME:1535.4s\n",
      "\t\t\t\tDisc: 0.056757\t\tSpars: 0.098764\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 405 [4000/8000 (50%)]\tBatch Loss: 0.154696\tLearning Rate (w_theta): 0.000500\t TIME:1536.9s\n",
      "\t\t\t\tDisc: 0.057434\t\tSpars: 0.097262\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 405...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1550742910493929\n",
      "Average validation loss: 0.15533181997304749\n",
      "Training epoch 406...\n",
      "\n",
      "Train Epoch: 406 [0/8000 (0%)]\tBatch Loss: 0.152335\tLearning Rate (w_theta): 0.000500\t TIME:1539.2s\n",
      "\t\t\t\tDisc: 0.055859\t\tSpars: 0.096475\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 406 [4000/8000 (50%)]\tBatch Loss: 0.151484\tLearning Rate (w_theta): 0.000500\t TIME:1540.6s\n",
      "\t\t\t\tDisc: 0.057967\t\tSpars: 0.093517\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 406...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1549690897420875\n",
      "Average validation loss: 0.15522785465073186\n",
      "Training epoch 407...\n",
      "\n",
      "Train Epoch: 407 [0/8000 (0%)]\tBatch Loss: 0.154837\tLearning Rate (w_theta): 0.000500\t TIME:1542.9s\n",
      "\t\t\t\tDisc: 0.058082\t\tSpars: 0.096754\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 407 [4000/8000 (50%)]\tBatch Loss: 0.156846\tLearning Rate (w_theta): 0.000500\t TIME:1544.4s\n",
      "\t\t\t\tDisc: 0.059833\t\tSpars: 0.097013\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 407...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15486970963659308\n",
      "Average validation loss: 0.15512278325224058\n",
      "Training epoch 408...\n",
      "\n",
      "Train Epoch: 408 [0/8000 (0%)]\tBatch Loss: 0.151645\tLearning Rate (w_theta): 0.000500\t TIME:1546.7s\n",
      "\t\t\t\tDisc: 0.055944\t\tSpars: 0.095702\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 408 [4000/8000 (50%)]\tBatch Loss: 0.162508\tLearning Rate (w_theta): 0.000500\t TIME:1548.2s\n",
      "\t\t\t\tDisc: 0.064405\t\tSpars: 0.098103\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 408...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15476727532256693\n",
      "Average validation loss: 0.15501977962706842\n",
      "Training epoch 409...\n",
      "\n",
      "Train Epoch: 409 [0/8000 (0%)]\tBatch Loss: 0.152403\tLearning Rate (w_theta): 0.000500\t TIME:1550.6s\n",
      "\t\t\t\tDisc: 0.054862\t\tSpars: 0.097541\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 409 [4000/8000 (50%)]\tBatch Loss: 0.148013\tLearning Rate (w_theta): 0.000500\t TIME:1552.0s\n",
      "\t\t\t\tDisc: 0.054151\t\tSpars: 0.093862\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 409...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15466901776577802\n",
      "Average validation loss: 0.1549161366565499\n",
      "Training epoch 410...\n",
      "\n",
      "Train Epoch: 410 [0/8000 (0%)]\tBatch Loss: 0.155218\tLearning Rate (w_theta): 0.000500\t TIME:1554.3s\n",
      "\t\t\t\tDisc: 0.057509\t\tSpars: 0.097710\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 410 [4000/8000 (50%)]\tBatch Loss: 0.158163\tLearning Rate (w_theta): 0.000500\t TIME:1555.7s\n",
      "\t\t\t\tDisc: 0.060789\t\tSpars: 0.097374\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 410...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1545698131381826\n",
      "Average validation loss: 0.15481347098793377\n",
      "Training epoch 411...\n",
      "\n",
      "Train Epoch: 411 [0/8000 (0%)]\tBatch Loss: 0.149799\tLearning Rate (w_theta): 0.000500\t TIME:1559.3s\n",
      "\t\t\t\tDisc: 0.053692\t\tSpars: 0.096106\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 411 [4000/8000 (50%)]\tBatch Loss: 0.157463\tLearning Rate (w_theta): 0.000500\t TIME:1560.8s\n",
      "\t\t\t\tDisc: 0.060740\t\tSpars: 0.096723\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 411...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15446952026147193\n",
      "Average validation loss: 0.15471355454864424\n",
      "Training epoch 412...\n",
      "\n",
      "Train Epoch: 412 [0/8000 (0%)]\tBatch Loss: 0.156813\tLearning Rate (w_theta): 0.000500\t TIME:1563.1s\n",
      "\t\t\t\tDisc: 0.058729\t\tSpars: 0.098084\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 412 [4000/8000 (50%)]\tBatch Loss: 0.158435\tLearning Rate (w_theta): 0.000500\t TIME:1564.5s\n",
      "\t\t\t\tDisc: 0.059819\t\tSpars: 0.098615\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 412...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1543747908468771\n",
      "Average validation loss: 0.15461233851331158\n",
      "Training epoch 413...\n",
      "\n",
      "Train Epoch: 413 [0/8000 (0%)]\tBatch Loss: 0.153574\tLearning Rate (w_theta): 0.000500\t TIME:1566.8s\n",
      "\t\t\t\tDisc: 0.057438\t\tSpars: 0.096136\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 413 [4000/8000 (50%)]\tBatch Loss: 0.157496\tLearning Rate (w_theta): 0.000500\t TIME:1568.2s\n",
      "\t\t\t\tDisc: 0.061737\t\tSpars: 0.095759\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 413...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1542776083082899\n",
      "Average validation loss: 0.1545129415302877\n",
      "Training epoch 414...\n",
      "\n",
      "Train Epoch: 414 [0/8000 (0%)]\tBatch Loss: 0.147379\tLearning Rate (w_theta): 0.000500\t TIME:1570.5s\n",
      "\t\t\t\tDisc: 0.054872\t\tSpars: 0.092506\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 414 [4000/8000 (50%)]\tBatch Loss: 0.152694\tLearning Rate (w_theta): 0.000500\t TIME:1571.9s\n",
      "\t\t\t\tDisc: 0.054135\t\tSpars: 0.098559\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 414...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15418100566679643\n",
      "Average validation loss: 0.15441545860976097\n",
      "Training epoch 415...\n",
      "\n",
      "Train Epoch: 415 [0/8000 (0%)]\tBatch Loss: 0.158112\tLearning Rate (w_theta): 0.000500\t TIME:1574.2s\n",
      "\t\t\t\tDisc: 0.061143\t\tSpars: 0.096969\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 415 [4000/8000 (50%)]\tBatch Loss: 0.153028\tLearning Rate (w_theta): 0.000500\t TIME:1575.6s\n",
      "\t\t\t\tDisc: 0.057383\t\tSpars: 0.095645\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 415...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15408919962425024\n",
      "Average validation loss: 0.15431647602089776\n",
      "Training epoch 416...\n",
      "\n",
      "Train Epoch: 416 [0/8000 (0%)]\tBatch Loss: 0.154604\tLearning Rate (w_theta): 0.000500\t TIME:1578.0s\n",
      "\t\t\t\tDisc: 0.055584\t\tSpars: 0.099020\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 416 [4000/8000 (50%)]\tBatch Loss: 0.153572\tLearning Rate (w_theta): 0.000500\t TIME:1579.5s\n",
      "\t\t\t\tDisc: 0.058391\t\tSpars: 0.095181\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 416...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15399354389449152\n",
      "Average validation loss: 0.15421998871430612\n",
      "Training epoch 417...\n",
      "\n",
      "Train Epoch: 417 [0/8000 (0%)]\tBatch Loss: 0.156504\tLearning Rate (w_theta): 0.000500\t TIME:1581.7s\n",
      "\t\t\t\tDisc: 0.059703\t\tSpars: 0.096801\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 417 [4000/8000 (50%)]\tBatch Loss: 0.153405\tLearning Rate (w_theta): 0.000500\t TIME:1583.2s\n",
      "\t\t\t\tDisc: 0.057519\t\tSpars: 0.095886\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 417...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15390266811648545\n",
      "Average validation loss: 0.15412249994224594\n",
      "Training epoch 418...\n",
      "\n",
      "Train Epoch: 418 [0/8000 (0%)]\tBatch Loss: 0.150808\tLearning Rate (w_theta): 0.000500\t TIME:1585.4s\n",
      "\t\t\t\tDisc: 0.054440\t\tSpars: 0.096368\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 418 [4000/8000 (50%)]\tBatch Loss: 0.154491\tLearning Rate (w_theta): 0.000500\t TIME:1586.8s\n",
      "\t\t\t\tDisc: 0.053267\t\tSpars: 0.101223\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 418...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15381006050146975\n",
      "Average validation loss: 0.15402609800078365\n",
      "Training epoch 419...\n",
      "\n",
      "Train Epoch: 419 [0/8000 (0%)]\tBatch Loss: 0.153723\tLearning Rate (w_theta): 0.000500\t TIME:1589.0s\n",
      "\t\t\t\tDisc: 0.055222\t\tSpars: 0.098500\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 419 [4000/8000 (50%)]\tBatch Loss: 0.156395\tLearning Rate (w_theta): 0.000500\t TIME:1590.5s\n",
      "\t\t\t\tDisc: 0.058709\t\tSpars: 0.097686\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 419...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15371792295369288\n",
      "Average validation loss: 0.15393108543482137\n",
      "Training epoch 420...\n",
      "\n",
      "Train Epoch: 420 [0/8000 (0%)]\tBatch Loss: 0.160344\tLearning Rate (w_theta): 0.000500\t TIME:1592.8s\n",
      "\t\t\t\tDisc: 0.061084\t\tSpars: 0.099259\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 420 [4000/8000 (50%)]\tBatch Loss: 0.152467\tLearning Rate (w_theta): 0.000500\t TIME:1594.3s\n",
      "\t\t\t\tDisc: 0.056711\t\tSpars: 0.095756\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 420...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15362905446056696\n",
      "Average validation loss: 0.15383527390422888\n",
      "Training epoch 421...\n",
      "\n",
      "Train Epoch: 421 [0/8000 (0%)]\tBatch Loss: 0.155353\tLearning Rate (w_theta): 0.000500\t TIME:1597.9s\n",
      "\t\t\t\tDisc: 0.057244\t\tSpars: 0.098109\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 421 [4000/8000 (50%)]\tBatch Loss: 0.153766\tLearning Rate (w_theta): 0.000500\t TIME:1599.4s\n",
      "\t\t\t\tDisc: 0.056053\t\tSpars: 0.097712\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 421...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15353816471312304\n",
      "Average validation loss: 0.153741023052622\n",
      "Training epoch 422...\n",
      "\n",
      "Train Epoch: 422 [0/8000 (0%)]\tBatch Loss: 0.150199\tLearning Rate (w_theta): 0.000500\t TIME:1601.6s\n",
      "\t\t\t\tDisc: 0.052171\t\tSpars: 0.098028\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 422 [4000/8000 (50%)]\tBatch Loss: 0.155995\tLearning Rate (w_theta): 0.000500\t TIME:1603.0s\n",
      "\t\t\t\tDisc: 0.058383\t\tSpars: 0.097612\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 422...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15344781281804562\n",
      "Average validation loss: 0.15364834993247134\n",
      "Training epoch 423...\n",
      "\n",
      "Train Epoch: 423 [0/8000 (0%)]\tBatch Loss: 0.153585\tLearning Rate (w_theta): 0.000500\t TIME:1605.3s\n",
      "\t\t\t\tDisc: 0.055701\t\tSpars: 0.097884\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 423 [4000/8000 (50%)]\tBatch Loss: 0.153215\tLearning Rate (w_theta): 0.000500\t TIME:1606.7s\n",
      "\t\t\t\tDisc: 0.056260\t\tSpars: 0.096955\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 423...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15336099684552826\n",
      "Average validation loss: 0.1535546783305965\n",
      "Training epoch 424...\n",
      "\n",
      "Train Epoch: 424 [0/8000 (0%)]\tBatch Loss: 0.152400\tLearning Rate (w_theta): 0.000500\t TIME:1609.0s\n",
      "\t\t\t\tDisc: 0.056412\t\tSpars: 0.095988\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 424 [4000/8000 (50%)]\tBatch Loss: 0.150822\tLearning Rate (w_theta): 0.000500\t TIME:1610.5s\n",
      "\t\t\t\tDisc: 0.055000\t\tSpars: 0.095822\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 424...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1532723486988929\n",
      "Average validation loss: 0.1534621089888982\n",
      "Training epoch 425...\n",
      "\n",
      "Train Epoch: 425 [0/8000 (0%)]\tBatch Loss: 0.148447\tLearning Rate (w_theta): 0.000500\t TIME:1612.8s\n",
      "\t\t\t\tDisc: 0.051665\t\tSpars: 0.096782\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 425 [4000/8000 (50%)]\tBatch Loss: 0.155320\tLearning Rate (w_theta): 0.000500\t TIME:1614.3s\n",
      "\t\t\t\tDisc: 0.056057\t\tSpars: 0.099263\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 425...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15318410709165886\n",
      "Average validation loss: 0.15337099054724712\n",
      "Training epoch 426...\n",
      "\n",
      "Train Epoch: 426 [0/8000 (0%)]\tBatch Loss: 0.150367\tLearning Rate (w_theta): 0.000500\t TIME:1616.5s\n",
      "\t\t\t\tDisc: 0.053149\t\tSpars: 0.097217\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 426 [4000/8000 (50%)]\tBatch Loss: 0.153377\tLearning Rate (w_theta): 0.000500\t TIME:1618.0s\n",
      "\t\t\t\tDisc: 0.055889\t\tSpars: 0.097488\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 426...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15309825271684047\n",
      "Average validation loss: 0.15327983324054895\n",
      "Training epoch 427...\n",
      "\n",
      "Train Epoch: 427 [0/8000 (0%)]\tBatch Loss: 0.154831\tLearning Rate (w_theta): 0.000500\t TIME:1620.2s\n",
      "\t\t\t\tDisc: 0.055292\t\tSpars: 0.099539\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 427 [4000/8000 (50%)]\tBatch Loss: 0.152814\tLearning Rate (w_theta): 0.000500\t TIME:1621.7s\n",
      "\t\t\t\tDisc: 0.056567\t\tSpars: 0.096248\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 427...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1530142112015636\n",
      "Average validation loss: 0.15318766357233654\n",
      "Training epoch 428...\n",
      "\n",
      "Train Epoch: 428 [0/8000 (0%)]\tBatch Loss: 0.158088\tLearning Rate (w_theta): 0.000500\t TIME:1623.9s\n",
      "\t\t\t\tDisc: 0.060751\t\tSpars: 0.097337\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 428 [4000/8000 (50%)]\tBatch Loss: 0.158338\tLearning Rate (w_theta): 0.000500\t TIME:1625.4s\n",
      "\t\t\t\tDisc: 0.056331\t\tSpars: 0.102007\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 428...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1529275858970135\n",
      "Average validation loss: 0.1530969486664529\n",
      "Training epoch 429...\n",
      "\n",
      "Train Epoch: 429 [0/8000 (0%)]\tBatch Loss: 0.147580\tLearning Rate (w_theta): 0.000500\t TIME:1627.7s\n",
      "\t\t\t\tDisc: 0.051708\t\tSpars: 0.095873\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 429 [4000/8000 (50%)]\tBatch Loss: 0.148883\tLearning Rate (w_theta): 0.000500\t TIME:1629.1s\n",
      "\t\t\t\tDisc: 0.055149\t\tSpars: 0.093734\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 429...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15284178899800321\n",
      "Average validation loss: 0.1530074538233778\n",
      "Training epoch 430...\n",
      "\n",
      "Train Epoch: 430 [0/8000 (0%)]\tBatch Loss: 0.151563\tLearning Rate (w_theta): 0.000500\t TIME:1631.4s\n",
      "\t\t\t\tDisc: 0.056872\t\tSpars: 0.094690\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 430 [4000/8000 (50%)]\tBatch Loss: 0.151321\tLearning Rate (w_theta): 0.000500\t TIME:1632.8s\n",
      "\t\t\t\tDisc: 0.056274\t\tSpars: 0.095047\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 430...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15275882559751672\n",
      "Average validation loss: 0.15291724719759997\n",
      "Training epoch 431...\n",
      "\n",
      "Train Epoch: 431 [0/8000 (0%)]\tBatch Loss: 0.152120\tLearning Rate (w_theta): 0.000500\t TIME:1636.3s\n",
      "\t\t\t\tDisc: 0.055029\t\tSpars: 0.097091\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 431 [4000/8000 (50%)]\tBatch Loss: 0.149449\tLearning Rate (w_theta): 0.000500\t TIME:1637.7s\n",
      "\t\t\t\tDisc: 0.051816\t\tSpars: 0.097633\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 431...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15267332583521048\n",
      "Average validation loss: 0.152829031858738\n",
      "Training epoch 432...\n",
      "\n",
      "Train Epoch: 432 [0/8000 (0%)]\tBatch Loss: 0.150814\tLearning Rate (w_theta): 0.000500\t TIME:1640.0s\n",
      "\t\t\t\tDisc: 0.054897\t\tSpars: 0.095916\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 432 [4000/8000 (50%)]\tBatch Loss: 0.143488\tLearning Rate (w_theta): 0.000500\t TIME:1641.5s\n",
      "\t\t\t\tDisc: 0.053220\t\tSpars: 0.090268\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 432...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15259023386595819\n",
      "Average validation loss: 0.15274122804070425\n",
      "Training epoch 433...\n",
      "\n",
      "Train Epoch: 433 [0/8000 (0%)]\tBatch Loss: 0.154518\tLearning Rate (w_theta): 0.000500\t TIME:1643.7s\n",
      "\t\t\t\tDisc: 0.056445\t\tSpars: 0.098072\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 433 [4000/8000 (50%)]\tBatch Loss: 0.151836\tLearning Rate (w_theta): 0.000500\t TIME:1645.2s\n",
      "\t\t\t\tDisc: 0.055871\t\tSpars: 0.095965\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 433...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15250905040743998\n",
      "Average validation loss: 0.15265276940062808\n",
      "Training epoch 434...\n",
      "\n",
      "Train Epoch: 434 [0/8000 (0%)]\tBatch Loss: 0.152252\tLearning Rate (w_theta): 0.000500\t TIME:1647.4s\n",
      "\t\t\t\tDisc: 0.055914\t\tSpars: 0.096338\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 434 [4000/8000 (50%)]\tBatch Loss: 0.149986\tLearning Rate (w_theta): 0.000500\t TIME:1648.9s\n",
      "\t\t\t\tDisc: 0.056070\t\tSpars: 0.093916\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 434...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15242684289426547\n",
      "Average validation loss: 0.15256499935944343\n",
      "Training epoch 435...\n",
      "\n",
      "Train Epoch: 435 [0/8000 (0%)]\tBatch Loss: 0.151930\tLearning Rate (w_theta): 0.000500\t TIME:1651.1s\n",
      "\t\t\t\tDisc: 0.055650\t\tSpars: 0.096280\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 435 [4000/8000 (50%)]\tBatch Loss: 0.147841\tLearning Rate (w_theta): 0.000500\t TIME:1652.6s\n",
      "\t\t\t\tDisc: 0.053553\t\tSpars: 0.094288\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 435...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15234343687616378\n",
      "Average validation loss: 0.1524793968218786\n",
      "Training epoch 436...\n",
      "\n",
      "Train Epoch: 436 [0/8000 (0%)]\tBatch Loss: 0.155450\tLearning Rate (w_theta): 0.000500\t TIME:1654.9s\n",
      "\t\t\t\tDisc: 0.056036\t\tSpars: 0.099414\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 436 [4000/8000 (50%)]\tBatch Loss: 0.151136\tLearning Rate (w_theta): 0.000500\t TIME:1656.3s\n",
      "\t\t\t\tDisc: 0.054307\t\tSpars: 0.096829\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 436...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15226249279083612\n",
      "Average validation loss: 0.1523942809611521\n",
      "Training epoch 437...\n",
      "\n",
      "Train Epoch: 437 [0/8000 (0%)]\tBatch Loss: 0.151408\tLearning Rate (w_theta): 0.000500\t TIME:1658.5s\n",
      "\t\t\t\tDisc: 0.054266\t\tSpars: 0.097142\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 437 [4000/8000 (50%)]\tBatch Loss: 0.150985\tLearning Rate (w_theta): 0.000500\t TIME:1660.0s\n",
      "\t\t\t\tDisc: 0.054271\t\tSpars: 0.096714\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 437...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1521838310310239\n",
      "Average validation loss: 0.15230811136000433\n",
      "Training epoch 438...\n",
      "\n",
      "Train Epoch: 438 [0/8000 (0%)]\tBatch Loss: 0.152273\tLearning Rate (w_theta): 0.000500\t TIME:1662.2s\n",
      "\t\t\t\tDisc: 0.054743\t\tSpars: 0.097530\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 438 [4000/8000 (50%)]\tBatch Loss: 0.147485\tLearning Rate (w_theta): 0.000500\t TIME:1663.7s\n",
      "\t\t\t\tDisc: 0.053232\t\tSpars: 0.094253\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 438...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.152103030141014\n",
      "Average validation loss: 0.15222307739927135\n",
      "Training epoch 439...\n",
      "\n",
      "Train Epoch: 439 [0/8000 (0%)]\tBatch Loss: 0.151696\tLearning Rate (w_theta): 0.000500\t TIME:1666.0s\n",
      "\t\t\t\tDisc: 0.052614\t\tSpars: 0.099082\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 439 [4000/8000 (50%)]\tBatch Loss: 0.151896\tLearning Rate (w_theta): 0.000500\t TIME:1667.5s\n",
      "\t\t\t\tDisc: 0.056449\t\tSpars: 0.095447\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 439...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1520228531935921\n",
      "Average validation loss: 0.15213884644808262\n",
      "Training epoch 440...\n",
      "\n",
      "Train Epoch: 440 [0/8000 (0%)]\tBatch Loss: 0.154325\tLearning Rate (w_theta): 0.000500\t TIME:1669.7s\n",
      "\t\t\t\tDisc: 0.055664\t\tSpars: 0.098661\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 440 [4000/8000 (50%)]\tBatch Loss: 0.155818\tLearning Rate (w_theta): 0.000500\t TIME:1671.2s\n",
      "\t\t\t\tDisc: 0.055761\t\tSpars: 0.100057\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 440...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1519434276300566\n",
      "Average validation loss: 0.15205508615876737\n",
      "Training epoch 441...\n",
      "\n",
      "Train Epoch: 441 [0/8000 (0%)]\tBatch Loss: 0.150295\tLearning Rate (w_theta): 0.000500\t TIME:1674.8s\n",
      "\t\t\t\tDisc: 0.054636\t\tSpars: 0.095659\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 441 [4000/8000 (50%)]\tBatch Loss: 0.151407\tLearning Rate (w_theta): 0.000500\t TIME:1676.3s\n",
      "\t\t\t\tDisc: 0.052752\t\tSpars: 0.098656\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 441...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1518657095471906\n",
      "Average validation loss: 0.1519706915516582\n",
      "Training epoch 442...\n",
      "\n",
      "Train Epoch: 442 [0/8000 (0%)]\tBatch Loss: 0.156509\tLearning Rate (w_theta): 0.000500\t TIME:1678.5s\n",
      "\t\t\t\tDisc: 0.056662\t\tSpars: 0.099847\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 442 [4000/8000 (50%)]\tBatch Loss: 0.153516\tLearning Rate (w_theta): 0.000500\t TIME:1680.0s\n",
      "\t\t\t\tDisc: 0.055379\t\tSpars: 0.098137\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 442...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15178538089728072\n",
      "Average validation loss: 0.15188856354838198\n",
      "Training epoch 443...\n",
      "\n",
      "Train Epoch: 443 [0/8000 (0%)]\tBatch Loss: 0.153835\tLearning Rate (w_theta): 0.000500\t TIME:1682.2s\n",
      "\t\t\t\tDisc: 0.055669\t\tSpars: 0.098166\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 443 [4000/8000 (50%)]\tBatch Loss: 0.154108\tLearning Rate (w_theta): 0.000500\t TIME:1683.7s\n",
      "\t\t\t\tDisc: 0.056423\t\tSpars: 0.097685\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 443...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15170834830119925\n",
      "Average validation loss: 0.15180622030612917\n",
      "Training epoch 444...\n",
      "\n",
      "Train Epoch: 444 [0/8000 (0%)]\tBatch Loss: 0.152954\tLearning Rate (w_theta): 0.000500\t TIME:1685.9s\n",
      "\t\t\t\tDisc: 0.054476\t\tSpars: 0.098478\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 444 [4000/8000 (50%)]\tBatch Loss: 0.151319\tLearning Rate (w_theta): 0.000500\t TIME:1687.4s\n",
      "\t\t\t\tDisc: 0.053413\t\tSpars: 0.097906\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 444...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1516307848717699\n",
      "Average validation loss: 0.1517245082800137\n",
      "Training epoch 445...\n",
      "\n",
      "Train Epoch: 445 [0/8000 (0%)]\tBatch Loss: 0.148782\tLearning Rate (w_theta): 0.000500\t TIME:1689.6s\n",
      "\t\t\t\tDisc: 0.053324\t\tSpars: 0.095458\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 445 [4000/8000 (50%)]\tBatch Loss: 0.150349\tLearning Rate (w_theta): 0.000500\t TIME:1691.1s\n",
      "\t\t\t\tDisc: 0.054170\t\tSpars: 0.096179\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 445...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15155414769518172\n",
      "Average validation loss: 0.1516430872871683\n",
      "Training epoch 446...\n",
      "\n",
      "Train Epoch: 446 [0/8000 (0%)]\tBatch Loss: 0.152023\tLearning Rate (w_theta): 0.000500\t TIME:1693.3s\n",
      "\t\t\t\tDisc: 0.055992\t\tSpars: 0.096031\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 446 [4000/8000 (50%)]\tBatch Loss: 0.156384\tLearning Rate (w_theta): 0.000500\t TIME:1694.7s\n",
      "\t\t\t\tDisc: 0.056758\t\tSpars: 0.099626\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 446...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15147824579969\n",
      "Average validation loss: 0.1515618109568309\n",
      "Training epoch 447...\n",
      "\n",
      "Train Epoch: 447 [0/8000 (0%)]\tBatch Loss: 0.149195\tLearning Rate (w_theta): 0.000500\t TIME:1697.1s\n",
      "\t\t\t\tDisc: 0.052281\t\tSpars: 0.096913\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 447 [4000/8000 (50%)]\tBatch Loss: 0.151467\tLearning Rate (w_theta): 0.000500\t TIME:1698.5s\n",
      "\t\t\t\tDisc: 0.054580\t\tSpars: 0.096887\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 447...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1514007232867109\n",
      "Average validation loss: 0.15148273226595532\n",
      "Training epoch 448...\n",
      "\n",
      "Train Epoch: 448 [0/8000 (0%)]\tBatch Loss: 0.151062\tLearning Rate (w_theta): 0.000500\t TIME:1700.8s\n",
      "\t\t\t\tDisc: 0.054771\t\tSpars: 0.096291\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 448 [4000/8000 (50%)]\tBatch Loss: 0.151459\tLearning Rate (w_theta): 0.000500\t TIME:1702.3s\n",
      "\t\t\t\tDisc: 0.055277\t\tSpars: 0.096182\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 448...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15132686848325302\n",
      "Average validation loss: 0.15140315147708283\n",
      "Training epoch 449...\n",
      "\n",
      "Train Epoch: 449 [0/8000 (0%)]\tBatch Loss: 0.153225\tLearning Rate (w_theta): 0.000500\t TIME:1704.5s\n",
      "\t\t\t\tDisc: 0.054289\t\tSpars: 0.098935\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 449 [4000/8000 (50%)]\tBatch Loss: 0.152045\tLearning Rate (w_theta): 0.000500\t TIME:1706.0s\n",
      "\t\t\t\tDisc: 0.054604\t\tSpars: 0.097441\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 449...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15125089854248974\n",
      "Average validation loss: 0.15132511626759554\n",
      "Training epoch 450...\n",
      "\n",
      "Train Epoch: 450 [0/8000 (0%)]\tBatch Loss: 0.159839\tLearning Rate (w_theta): 0.000500\t TIME:1708.2s\n",
      "\t\t\t\tDisc: 0.059288\t\tSpars: 0.100551\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 450 [4000/8000 (50%)]\tBatch Loss: 0.147589\tLearning Rate (w_theta): 0.000500\t TIME:1709.6s\n",
      "\t\t\t\tDisc: 0.053107\t\tSpars: 0.094483\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 450...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15117920364130702\n",
      "Average validation loss: 0.15124539000335918\n",
      "Training epoch 451...\n",
      "\n",
      "Train Epoch: 451 [0/8000 (0%)]\tBatch Loss: 0.149680\tLearning Rate (w_theta): 0.000500\t TIME:1713.3s\n",
      "\t\t\t\tDisc: 0.051450\t\tSpars: 0.098230\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 451 [4000/8000 (50%)]\tBatch Loss: 0.154355\tLearning Rate (w_theta): 0.000500\t TIME:1714.9s\n",
      "\t\t\t\tDisc: 0.056333\t\tSpars: 0.098023\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 451...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15110216530616577\n",
      "Average validation loss: 0.1511690442427495\n",
      "Training epoch 452...\n",
      "\n",
      "Train Epoch: 452 [0/8000 (0%)]\tBatch Loss: 0.149300\tLearning Rate (w_theta): 0.000500\t TIME:1717.1s\n",
      "\t\t\t\tDisc: 0.053100\t\tSpars: 0.096200\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 452 [4000/8000 (50%)]\tBatch Loss: 0.155397\tLearning Rate (w_theta): 0.000500\t TIME:1718.6s\n",
      "\t\t\t\tDisc: 0.055573\t\tSpars: 0.099824\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 452...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15102951890954436\n",
      "Average validation loss: 0.1510929830319315\n",
      "Training epoch 453...\n",
      "\n",
      "Train Epoch: 453 [0/8000 (0%)]\tBatch Loss: 0.155280\tLearning Rate (w_theta): 0.000500\t TIME:1720.8s\n",
      "\t\t\t\tDisc: 0.056738\t\tSpars: 0.098542\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 453 [4000/8000 (50%)]\tBatch Loss: 0.152359\tLearning Rate (w_theta): 0.000500\t TIME:1722.3s\n",
      "\t\t\t\tDisc: 0.054295\t\tSpars: 0.098063\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 453...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15095807992768173\n",
      "Average validation loss: 0.15101623691065674\n",
      "Training epoch 454...\n",
      "\n",
      "Train Epoch: 454 [0/8000 (0%)]\tBatch Loss: 0.148624\tLearning Rate (w_theta): 0.000500\t TIME:1724.6s\n",
      "\t\t\t\tDisc: 0.051290\t\tSpars: 0.097335\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 454 [4000/8000 (50%)]\tBatch Loss: 0.154178\tLearning Rate (w_theta): 0.000500\t TIME:1726.0s\n",
      "\t\t\t\tDisc: 0.056077\t\tSpars: 0.098102\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 454...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15088428675298787\n",
      "Average validation loss: 0.15094118190603645\n",
      "Training epoch 455...\n",
      "\n",
      "Train Epoch: 455 [0/8000 (0%)]\tBatch Loss: 0.154014\tLearning Rate (w_theta): 0.000500\t TIME:1728.2s\n",
      "\t\t\t\tDisc: 0.057089\t\tSpars: 0.096925\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 455 [4000/8000 (50%)]\tBatch Loss: 0.151848\tLearning Rate (w_theta): 0.000500\t TIME:1729.7s\n",
      "\t\t\t\tDisc: 0.055041\t\tSpars: 0.096807\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 455...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15081248793293295\n",
      "Average validation loss: 0.15086660224630652\n",
      "Training epoch 456...\n",
      "\n",
      "Train Epoch: 456 [0/8000 (0%)]\tBatch Loss: 0.149659\tLearning Rate (w_theta): 0.000500\t TIME:1732.0s\n",
      "\t\t\t\tDisc: 0.052869\t\tSpars: 0.096790\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 456 [4000/8000 (50%)]\tBatch Loss: 0.146881\tLearning Rate (w_theta): 0.000500\t TIME:1733.5s\n",
      "\t\t\t\tDisc: 0.051515\t\tSpars: 0.095367\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 456...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15074162551530015\n",
      "Average validation loss: 0.15079200323065162\n",
      "Training epoch 457...\n",
      "\n",
      "Train Epoch: 457 [0/8000 (0%)]\tBatch Loss: 0.151795\tLearning Rate (w_theta): 0.000500\t TIME:1735.7s\n",
      "\t\t\t\tDisc: 0.056491\t\tSpars: 0.095304\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 457 [4000/8000 (50%)]\tBatch Loss: 0.152610\tLearning Rate (w_theta): 0.000500\t TIME:1737.1s\n",
      "\t\t\t\tDisc: 0.053285\t\tSpars: 0.099324\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 457...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15067059601434524\n",
      "Average validation loss: 0.15071792540341938\n",
      "Training epoch 458...\n",
      "\n",
      "Train Epoch: 458 [0/8000 (0%)]\tBatch Loss: 0.150508\tLearning Rate (w_theta): 0.000500\t TIME:1739.4s\n",
      "\t\t\t\tDisc: 0.053220\t\tSpars: 0.097288\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 458 [4000/8000 (50%)]\tBatch Loss: 0.153177\tLearning Rate (w_theta): 0.000500\t TIME:1740.8s\n",
      "\t\t\t\tDisc: 0.054333\t\tSpars: 0.098845\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 458...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1505999790676268\n",
      "Average validation loss: 0.15064469828340274\n",
      "Training epoch 459...\n",
      "\n",
      "Train Epoch: 459 [0/8000 (0%)]\tBatch Loss: 0.154680\tLearning Rate (w_theta): 0.000500\t TIME:1743.0s\n",
      "\t\t\t\tDisc: 0.055502\t\tSpars: 0.099178\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 459 [4000/8000 (50%)]\tBatch Loss: 0.147316\tLearning Rate (w_theta): 0.000500\t TIME:1744.5s\n",
      "\t\t\t\tDisc: 0.052956\t\tSpars: 0.094360\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 459...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15053113327773987\n",
      "Average validation loss: 0.15057134297802555\n",
      "Training epoch 460...\n",
      "\n",
      "Train Epoch: 460 [0/8000 (0%)]\tBatch Loss: 0.146397\tLearning Rate (w_theta): 0.000500\t TIME:1746.7s\n",
      "\t\t\t\tDisc: 0.051618\t\tSpars: 0.094779\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 460 [4000/8000 (50%)]\tBatch Loss: 0.154746\tLearning Rate (w_theta): 0.000500\t TIME:1748.1s\n",
      "\t\t\t\tDisc: 0.055847\t\tSpars: 0.098899\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 460...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15046151735490032\n",
      "Average validation loss: 0.15049890967733606\n",
      "Training epoch 461...\n",
      "\n",
      "Train Epoch: 461 [0/8000 (0%)]\tBatch Loss: 0.146917\tLearning Rate (w_theta): 0.000500\t TIME:1751.7s\n",
      "\t\t\t\tDisc: 0.051398\t\tSpars: 0.095518\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 461 [4000/8000 (50%)]\tBatch Loss: 0.149549\tLearning Rate (w_theta): 0.000500\t TIME:1753.2s\n",
      "\t\t\t\tDisc: 0.053191\t\tSpars: 0.096358\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 461...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15039226273636833\n",
      "Average validation loss: 0.15042748808193385\n",
      "Training epoch 462...\n",
      "\n",
      "Train Epoch: 462 [0/8000 (0%)]\tBatch Loss: 0.150709\tLearning Rate (w_theta): 0.000500\t TIME:1755.5s\n",
      "\t\t\t\tDisc: 0.055553\t\tSpars: 0.095156\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 462 [4000/8000 (50%)]\tBatch Loss: 0.151368\tLearning Rate (w_theta): 0.000500\t TIME:1757.0s\n",
      "\t\t\t\tDisc: 0.053681\t\tSpars: 0.097687\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 462...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15032453140580643\n",
      "Average validation loss: 0.1503563328011251\n",
      "Training epoch 463...\n",
      "\n",
      "Train Epoch: 463 [0/8000 (0%)]\tBatch Loss: 0.145583\tLearning Rate (w_theta): 0.000500\t TIME:1759.2s\n",
      "\t\t\t\tDisc: 0.051611\t\tSpars: 0.093972\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 463 [4000/8000 (50%)]\tBatch Loss: 0.149072\tLearning Rate (w_theta): 0.000500\t TIME:1760.7s\n",
      "\t\t\t\tDisc: 0.053253\t\tSpars: 0.095820\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 463...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15025687115050726\n",
      "Average validation loss: 0.1502858166591397\n",
      "Training epoch 464...\n",
      "\n",
      "Train Epoch: 464 [0/8000 (0%)]\tBatch Loss: 0.148389\tLearning Rate (w_theta): 0.000500\t TIME:1762.9s\n",
      "\t\t\t\tDisc: 0.052239\t\tSpars: 0.096150\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 464 [4000/8000 (50%)]\tBatch Loss: 0.146571\tLearning Rate (w_theta): 0.000500\t TIME:1764.4s\n",
      "\t\t\t\tDisc: 0.054060\t\tSpars: 0.092511\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 464...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15019056999207978\n",
      "Average validation loss: 0.15021503851610232\n",
      "Training epoch 465...\n",
      "\n",
      "Train Epoch: 465 [0/8000 (0%)]\tBatch Loss: 0.154341\tLearning Rate (w_theta): 0.000500\t TIME:1766.8s\n",
      "\t\t\t\tDisc: 0.054530\t\tSpars: 0.099812\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 465 [4000/8000 (50%)]\tBatch Loss: 0.147871\tLearning Rate (w_theta): 0.000500\t TIME:1768.3s\n",
      "\t\t\t\tDisc: 0.052013\t\tSpars: 0.095857\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 465...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.15012338056195057\n",
      "Average validation loss: 0.15014512587281773\n",
      "Training epoch 466...\n",
      "\n",
      "Train Epoch: 466 [0/8000 (0%)]\tBatch Loss: 0.151919\tLearning Rate (w_theta): 0.000500\t TIME:1770.6s\n",
      "\t\t\t\tDisc: 0.054130\t\tSpars: 0.097789\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 466 [4000/8000 (50%)]\tBatch Loss: 0.144918\tLearning Rate (w_theta): 0.000500\t TIME:1772.2s\n",
      "\t\t\t\tDisc: 0.050368\t\tSpars: 0.094551\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 466...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1500574694952527\n",
      "Average validation loss: 0.15007541818021589\n",
      "Training epoch 467...\n",
      "\n",
      "Train Epoch: 467 [0/8000 (0%)]\tBatch Loss: 0.149413\tLearning Rate (w_theta): 0.000500\t TIME:1774.4s\n",
      "\t\t\t\tDisc: 0.052804\t\tSpars: 0.096609\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 467 [4000/8000 (50%)]\tBatch Loss: 0.150609\tLearning Rate (w_theta): 0.000500\t TIME:1775.9s\n",
      "\t\t\t\tDisc: 0.053726\t\tSpars: 0.096883\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 467...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14999089923089245\n",
      "Average validation loss: 0.1500069178698814\n",
      "Training epoch 468...\n",
      "\n",
      "Train Epoch: 468 [0/8000 (0%)]\tBatch Loss: 0.150006\tLearning Rate (w_theta): 0.000500\t TIME:1778.1s\n",
      "\t\t\t\tDisc: 0.054437\t\tSpars: 0.095570\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 468 [4000/8000 (50%)]\tBatch Loss: 0.153056\tLearning Rate (w_theta): 0.000500\t TIME:1779.6s\n",
      "\t\t\t\tDisc: 0.055846\t\tSpars: 0.097210\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 468...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14992612111370704\n",
      "Average validation loss: 0.14993853272972768\n",
      "Training epoch 469...\n",
      "\n",
      "Train Epoch: 469 [0/8000 (0%)]\tBatch Loss: 0.148375\tLearning Rate (w_theta): 0.000500\t TIME:1781.8s\n",
      "\t\t\t\tDisc: 0.049917\t\tSpars: 0.098458\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 469 [4000/8000 (50%)]\tBatch Loss: 0.146626\tLearning Rate (w_theta): 0.000500\t TIME:1783.2s\n",
      "\t\t\t\tDisc: 0.051708\t\tSpars: 0.094918\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 469...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14986125955022433\n",
      "Average validation loss: 0.14987074928722166\n",
      "Training epoch 470...\n",
      "\n",
      "Train Epoch: 470 [0/8000 (0%)]\tBatch Loss: 0.153550\tLearning Rate (w_theta): 0.000500\t TIME:1785.4s\n",
      "\t\t\t\tDisc: 0.055842\t\tSpars: 0.097708\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 470 [4000/8000 (50%)]\tBatch Loss: 0.148481\tLearning Rate (w_theta): 0.000500\t TIME:1786.9s\n",
      "\t\t\t\tDisc: 0.052635\t\tSpars: 0.095846\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 470...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1497974581309817\n",
      "Average validation loss: 0.14980310999401047\n",
      "Training epoch 471...\n",
      "\n",
      "Train Epoch: 471 [0/8000 (0%)]\tBatch Loss: 0.150603\tLearning Rate (w_theta): 0.000500\t TIME:1790.4s\n",
      "\t\t\t\tDisc: 0.051785\t\tSpars: 0.098818\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 471 [4000/8000 (50%)]\tBatch Loss: 0.148689\tLearning Rate (w_theta): 0.000500\t TIME:1791.9s\n",
      "\t\t\t\tDisc: 0.052830\t\tSpars: 0.095859\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 471...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1497324213573542\n",
      "Average validation loss: 0.14973708586146933\n",
      "Training epoch 472...\n",
      "\n",
      "Train Epoch: 472 [0/8000 (0%)]\tBatch Loss: 0.154996\tLearning Rate (w_theta): 0.000500\t TIME:1794.2s\n",
      "\t\t\t\tDisc: 0.055170\t\tSpars: 0.099826\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 472 [4000/8000 (50%)]\tBatch Loss: 0.150269\tLearning Rate (w_theta): 0.000500\t TIME:1795.7s\n",
      "\t\t\t\tDisc: 0.052651\t\tSpars: 0.097618\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 472...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14967067397036227\n",
      "Average validation loss: 0.14967027419864923\n",
      "Training epoch 473...\n",
      "\n",
      "Train Epoch: 473 [0/8000 (0%)]\tBatch Loss: 0.150938\tLearning Rate (w_theta): 0.000500\t TIME:1797.9s\n",
      "\t\t\t\tDisc: 0.052937\t\tSpars: 0.098000\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 473 [4000/8000 (50%)]\tBatch Loss: 0.154967\tLearning Rate (w_theta): 0.000500\t TIME:1799.4s\n",
      "\t\t\t\tDisc: 0.059974\t\tSpars: 0.094993\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 473...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14960817841250315\n",
      "Average validation loss: 0.14960372302728905\n",
      "Training epoch 474...\n",
      "\n",
      "Train Epoch: 474 [0/8000 (0%)]\tBatch Loss: 0.154142\tLearning Rate (w_theta): 0.000500\t TIME:1801.7s\n",
      "\t\t\t\tDisc: 0.054612\t\tSpars: 0.099530\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 474 [4000/8000 (50%)]\tBatch Loss: 0.150279\tLearning Rate (w_theta): 0.000500\t TIME:1803.2s\n",
      "\t\t\t\tDisc: 0.052525\t\tSpars: 0.097754\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 474...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14954495885308003\n",
      "Average validation loss: 0.14953839056044657\n",
      "Training epoch 475...\n",
      "\n",
      "Train Epoch: 475 [0/8000 (0%)]\tBatch Loss: 0.151039\tLearning Rate (w_theta): 0.000500\t TIME:1805.4s\n",
      "\t\t\t\tDisc: 0.056235\t\tSpars: 0.094804\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 475 [4000/8000 (50%)]\tBatch Loss: 0.146429\tLearning Rate (w_theta): 0.000500\t TIME:1806.8s\n",
      "\t\t\t\tDisc: 0.049892\t\tSpars: 0.096538\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 475...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1494829040237359\n",
      "Average validation loss: 0.1494737961084467\n",
      "Training epoch 476...\n",
      "\n",
      "Train Epoch: 476 [0/8000 (0%)]\tBatch Loss: 0.149866\tLearning Rate (w_theta): 0.000500\t TIME:1809.0s\n",
      "\t\t\t\tDisc: 0.052831\t\tSpars: 0.097035\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 476 [4000/8000 (50%)]\tBatch Loss: 0.145309\tLearning Rate (w_theta): 0.000500\t TIME:1810.4s\n",
      "\t\t\t\tDisc: 0.052052\t\tSpars: 0.093257\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 476...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1494215229989436\n",
      "Average validation loss: 0.14940981977804557\n",
      "Training epoch 477...\n",
      "\n",
      "Train Epoch: 477 [0/8000 (0%)]\tBatch Loss: 0.151496\tLearning Rate (w_theta): 0.000500\t TIME:1812.6s\n",
      "\t\t\t\tDisc: 0.053020\t\tSpars: 0.098476\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 477 [4000/8000 (50%)]\tBatch Loss: 0.152379\tLearning Rate (w_theta): 0.000500\t TIME:1814.1s\n",
      "\t\t\t\tDisc: 0.052916\t\tSpars: 0.099463\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 477...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14936131868363764\n",
      "Average validation loss: 0.1493457634030198\n",
      "Training epoch 478...\n",
      "\n",
      "Train Epoch: 478 [0/8000 (0%)]\tBatch Loss: 0.151151\tLearning Rate (w_theta): 0.000500\t TIME:1816.2s\n",
      "\t\t\t\tDisc: 0.052297\t\tSpars: 0.098854\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 478 [4000/8000 (50%)]\tBatch Loss: 0.145703\tLearning Rate (w_theta): 0.000500\t TIME:1817.7s\n",
      "\t\t\t\tDisc: 0.052784\t\tSpars: 0.092919\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 478...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14930073107384112\n",
      "Average validation loss: 0.1492823808374042\n",
      "Training epoch 479...\n",
      "\n",
      "Train Epoch: 479 [0/8000 (0%)]\tBatch Loss: 0.150469\tLearning Rate (w_theta): 0.000500\t TIME:1820.1s\n",
      "\t\t\t\tDisc: 0.052399\t\tSpars: 0.098071\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 479 [4000/8000 (50%)]\tBatch Loss: 0.154460\tLearning Rate (w_theta): 0.000500\t TIME:1821.5s\n",
      "\t\t\t\tDisc: 0.054799\t\tSpars: 0.099661\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 479...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14924087416744836\n",
      "Average validation loss: 0.14921946217255305\n",
      "Training epoch 480...\n",
      "\n",
      "Train Epoch: 480 [0/8000 (0%)]\tBatch Loss: 0.149114\tLearning Rate (w_theta): 0.000500\t TIME:1823.7s\n",
      "\t\t\t\tDisc: 0.051242\t\tSpars: 0.097872\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 480 [4000/8000 (50%)]\tBatch Loss: 0.148548\tLearning Rate (w_theta): 0.000500\t TIME:1825.2s\n",
      "\t\t\t\tDisc: 0.052416\t\tSpars: 0.096133\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 480...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14918142555319006\n",
      "Average validation loss: 0.14915701047940483\n",
      "Training epoch 481...\n",
      "\n",
      "Train Epoch: 481 [0/8000 (0%)]\tBatch Loss: 0.149380\tLearning Rate (w_theta): 0.000500\t TIME:1828.7s\n",
      "\t\t\t\tDisc: 0.051570\t\tSpars: 0.097810\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 481 [4000/8000 (50%)]\tBatch Loss: 0.149341\tLearning Rate (w_theta): 0.000500\t TIME:1830.1s\n",
      "\t\t\t\tDisc: 0.052251\t\tSpars: 0.097090\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 481...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14912232273891615\n",
      "Average validation loss: 0.1490950656652032\n",
      "Training epoch 482...\n",
      "\n",
      "Train Epoch: 482 [0/8000 (0%)]\tBatch Loss: 0.150503\tLearning Rate (w_theta): 0.000500\t TIME:1832.3s\n",
      "\t\t\t\tDisc: 0.052386\t\tSpars: 0.098117\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 482 [4000/8000 (50%)]\tBatch Loss: 0.148689\tLearning Rate (w_theta): 0.000500\t TIME:1833.8s\n",
      "\t\t\t\tDisc: 0.051480\t\tSpars: 0.097209\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 482...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14906408584230765\n",
      "Average validation loss: 0.14903325345320254\n",
      "Training epoch 483...\n",
      "\n",
      "Train Epoch: 483 [0/8000 (0%)]\tBatch Loss: 0.150104\tLearning Rate (w_theta): 0.000500\t TIME:1836.0s\n",
      "\t\t\t\tDisc: 0.052410\t\tSpars: 0.097695\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 483 [4000/8000 (50%)]\tBatch Loss: 0.149629\tLearning Rate (w_theta): 0.000500\t TIME:1837.5s\n",
      "\t\t\t\tDisc: 0.053346\t\tSpars: 0.096283\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 483...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14900456055992098\n",
      "Average validation loss: 0.14897306818499428\n",
      "Training epoch 484...\n",
      "\n",
      "Train Epoch: 484 [0/8000 (0%)]\tBatch Loss: 0.145128\tLearning Rate (w_theta): 0.000500\t TIME:1839.6s\n",
      "\t\t\t\tDisc: 0.050860\t\tSpars: 0.094268\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 484 [4000/8000 (50%)]\tBatch Loss: 0.142528\tLearning Rate (w_theta): 0.000500\t TIME:1841.1s\n",
      "\t\t\t\tDisc: 0.049506\t\tSpars: 0.093022\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 484...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14894778479170737\n",
      "Average validation loss: 0.14891246022968674\n",
      "Training epoch 485...\n",
      "\n",
      "Train Epoch: 485 [0/8000 (0%)]\tBatch Loss: 0.149458\tLearning Rate (w_theta): 0.000500\t TIME:1843.3s\n",
      "\t\t\t\tDisc: 0.051098\t\tSpars: 0.098360\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 485 [4000/8000 (50%)]\tBatch Loss: 0.147883\tLearning Rate (w_theta): 0.000500\t TIME:1844.7s\n",
      "\t\t\t\tDisc: 0.052808\t\tSpars: 0.095075\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 485...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1488907103344277\n",
      "Average validation loss: 0.14885210011193198\n",
      "Training epoch 486...\n",
      "\n",
      "Train Epoch: 486 [0/8000 (0%)]\tBatch Loss: 0.152223\tLearning Rate (w_theta): 0.000500\t TIME:1846.9s\n",
      "\t\t\t\tDisc: 0.053786\t\tSpars: 0.098437\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 486 [4000/8000 (50%)]\tBatch Loss: 0.148511\tLearning Rate (w_theta): 0.000500\t TIME:1848.3s\n",
      "\t\t\t\tDisc: 0.052451\t\tSpars: 0.096060\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 486...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14883340468633488\n",
      "Average validation loss: 0.14879262231497992\n",
      "Training epoch 487...\n",
      "\n",
      "Train Epoch: 487 [0/8000 (0%)]\tBatch Loss: 0.141241\tLearning Rate (w_theta): 0.000500\t TIME:1850.6s\n",
      "\t\t\t\tDisc: 0.048077\t\tSpars: 0.093163\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 487 [4000/8000 (50%)]\tBatch Loss: 0.151444\tLearning Rate (w_theta): 0.000500\t TIME:1852.0s\n",
      "\t\t\t\tDisc: 0.053336\t\tSpars: 0.098108\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 487...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14877676967805306\n",
      "Average validation loss: 0.14873374132122336\n",
      "Training epoch 488...\n",
      "\n",
      "Train Epoch: 488 [0/8000 (0%)]\tBatch Loss: 0.150078\tLearning Rate (w_theta): 0.000500\t TIME:1854.3s\n",
      "\t\t\t\tDisc: 0.052113\t\tSpars: 0.097965\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 488 [4000/8000 (50%)]\tBatch Loss: 0.148228\tLearning Rate (w_theta): 0.000500\t TIME:1855.8s\n",
      "\t\t\t\tDisc: 0.054076\t\tSpars: 0.094152\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 488...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14872154960244527\n",
      "Average validation loss: 0.14867464821656484\n",
      "Training epoch 489...\n",
      "\n",
      "Train Epoch: 489 [0/8000 (0%)]\tBatch Loss: 0.150372\tLearning Rate (w_theta): 0.000500\t TIME:1858.0s\n",
      "\t\t\t\tDisc: 0.052470\t\tSpars: 0.097902\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 489 [4000/8000 (50%)]\tBatch Loss: 0.149647\tLearning Rate (w_theta): 0.000500\t TIME:1859.4s\n",
      "\t\t\t\tDisc: 0.051689\t\tSpars: 0.097958\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 489...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1486650256410046\n",
      "Average validation loss: 0.14861693386090535\n",
      "Training epoch 490...\n",
      "\n",
      "Train Epoch: 490 [0/8000 (0%)]\tBatch Loss: 0.145784\tLearning Rate (w_theta): 0.000500\t TIME:1861.6s\n",
      "\t\t\t\tDisc: 0.049605\t\tSpars: 0.096179\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 490 [4000/8000 (50%)]\tBatch Loss: 0.148127\tLearning Rate (w_theta): 0.000500\t TIME:1863.1s\n",
      "\t\t\t\tDisc: 0.050449\t\tSpars: 0.097678\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 490...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14861105458081653\n",
      "Average validation loss: 0.1485587820660739\n",
      "Training epoch 491...\n",
      "\n",
      "Train Epoch: 491 [0/8000 (0%)]\tBatch Loss: 0.152952\tLearning Rate (w_theta): 0.000500\t TIME:1866.7s\n",
      "\t\t\t\tDisc: 0.054514\t\tSpars: 0.098438\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 491 [4000/8000 (50%)]\tBatch Loss: 0.145586\tLearning Rate (w_theta): 0.000500\t TIME:1868.2s\n",
      "\t\t\t\tDisc: 0.052272\t\tSpars: 0.093315\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 491...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14855692673540222\n",
      "Average validation loss: 0.14850078269297384\n",
      "Training epoch 492...\n",
      "\n",
      "Train Epoch: 492 [0/8000 (0%)]\tBatch Loss: 0.149010\tLearning Rate (w_theta): 0.000500\t TIME:1870.4s\n",
      "\t\t\t\tDisc: 0.052655\t\tSpars: 0.096355\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 492 [4000/8000 (50%)]\tBatch Loss: 0.148283\tLearning Rate (w_theta): 0.000500\t TIME:1871.8s\n",
      "\t\t\t\tDisc: 0.051303\t\tSpars: 0.096980\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 492...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1485013551481107\n",
      "Average validation loss: 0.14844462088246632\n",
      "Training epoch 493...\n",
      "\n",
      "Train Epoch: 493 [0/8000 (0%)]\tBatch Loss: 0.149442\tLearning Rate (w_theta): 0.000500\t TIME:1874.0s\n",
      "\t\t\t\tDisc: 0.051600\t\tSpars: 0.097841\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 493 [4000/8000 (50%)]\tBatch Loss: 0.149576\tLearning Rate (w_theta): 0.000500\t TIME:1875.5s\n",
      "\t\t\t\tDisc: 0.052921\t\tSpars: 0.096655\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 493...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14844800097942656\n",
      "Average validation loss: 0.14838892760265057\n",
      "Training epoch 494...\n",
      "\n",
      "Train Epoch: 494 [0/8000 (0%)]\tBatch Loss: 0.153291\tLearning Rate (w_theta): 0.000500\t TIME:1877.6s\n",
      "\t\t\t\tDisc: 0.051744\t\tSpars: 0.101546\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 494 [4000/8000 (50%)]\tBatch Loss: 0.147559\tLearning Rate (w_theta): 0.000500\t TIME:1879.1s\n",
      "\t\t\t\tDisc: 0.050230\t\tSpars: 0.097329\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 494...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1483965828482182\n",
      "Average validation loss: 0.14833235579232937\n",
      "Training epoch 495...\n",
      "\n",
      "Train Epoch: 495 [0/8000 (0%)]\tBatch Loss: 0.146434\tLearning Rate (w_theta): 0.000500\t TIME:1881.3s\n",
      "\t\t\t\tDisc: 0.051724\t\tSpars: 0.094710\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 495 [4000/8000 (50%)]\tBatch Loss: 0.150531\tLearning Rate (w_theta): 0.000500\t TIME:1882.8s\n",
      "\t\t\t\tDisc: 0.054109\t\tSpars: 0.096422\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 495...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1483423546212464\n",
      "Average validation loss: 0.14827766580004179\n",
      "Training epoch 496...\n",
      "\n",
      "Train Epoch: 496 [0/8000 (0%)]\tBatch Loss: 0.146522\tLearning Rate (w_theta): 0.000500\t TIME:1885.1s\n",
      "\t\t\t\tDisc: 0.050742\t\tSpars: 0.095780\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 496 [4000/8000 (50%)]\tBatch Loss: 0.147807\tLearning Rate (w_theta): 0.000500\t TIME:1886.6s\n",
      "\t\t\t\tDisc: 0.050402\t\tSpars: 0.097405\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 496...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1482908132514732\n",
      "Average validation loss: 0.14822329151038355\n",
      "Training epoch 497...\n",
      "\n",
      "Train Epoch: 497 [0/8000 (0%)]\tBatch Loss: 0.147282\tLearning Rate (w_theta): 0.000500\t TIME:1888.8s\n",
      "\t\t\t\tDisc: 0.051813\t\tSpars: 0.095468\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 497 [4000/8000 (50%)]\tBatch Loss: 0.146584\tLearning Rate (w_theta): 0.000500\t TIME:1890.2s\n",
      "\t\t\t\tDisc: 0.054358\t\tSpars: 0.092226\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 497...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14823928091384747\n",
      "Average validation loss: 0.14816942599030966\n",
      "Training epoch 498...\n",
      "\n",
      "Train Epoch: 498 [0/8000 (0%)]\tBatch Loss: 0.148398\tLearning Rate (w_theta): 0.000500\t TIME:1892.4s\n",
      "\t\t\t\tDisc: 0.052397\t\tSpars: 0.096001\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 498 [4000/8000 (50%)]\tBatch Loss: 0.150943\tLearning Rate (w_theta): 0.000500\t TIME:1893.9s\n",
      "\t\t\t\tDisc: 0.054677\t\tSpars: 0.096266\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 498...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14818904373956107\n",
      "Average validation loss: 0.14811531638352235\n",
      "Training epoch 499...\n",
      "\n",
      "Train Epoch: 499 [0/8000 (0%)]\tBatch Loss: 0.149540\tLearning Rate (w_theta): 0.000500\t TIME:1896.1s\n",
      "\t\t\t\tDisc: 0.052423\t\tSpars: 0.097116\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 499 [4000/8000 (50%)]\tBatch Loss: 0.149305\tLearning Rate (w_theta): 0.000500\t TIME:1897.5s\n",
      "\t\t\t\tDisc: 0.052245\t\tSpars: 0.097060\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 499...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14813773087584023\n",
      "Average validation loss: 0.14806219140440108\n",
      "Training epoch 500...\n",
      "\n",
      "Train Epoch: 500 [0/8000 (0%)]\tBatch Loss: 0.148881\tLearning Rate (w_theta): 0.000500\t TIME:1899.8s\n",
      "\t\t\t\tDisc: 0.052461\t\tSpars: 0.096420\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 500 [4000/8000 (50%)]\tBatch Loss: 0.148436\tLearning Rate (w_theta): 0.000500\t TIME:1901.2s\n",
      "\t\t\t\tDisc: 0.054757\t\tSpars: 0.093679\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 500...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1480860813302677\n",
      "Average validation loss: 0.14801079045815102\n",
      "Training epoch 501...\n",
      "\n",
      "Train Epoch: 501 [0/8000 (0%)]\tBatch Loss: 0.146493\tLearning Rate (w_theta): 0.000500\t TIME:1904.7s\n",
      "\t\t\t\tDisc: 0.050764\t\tSpars: 0.095729\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 501 [4000/8000 (50%)]\tBatch Loss: 0.148839\tLearning Rate (w_theta): 0.000500\t TIME:1906.2s\n",
      "\t\t\t\tDisc: 0.051724\t\tSpars: 0.097115\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 501...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14803734078446243\n",
      "Average validation loss: 0.14795883805468768\n",
      "Training epoch 502...\n",
      "\n",
      "Train Epoch: 502 [0/8000 (0%)]\tBatch Loss: 0.147474\tLearning Rate (w_theta): 0.000500\t TIME:1908.3s\n",
      "\t\t\t\tDisc: 0.052131\t\tSpars: 0.095344\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 502 [4000/8000 (50%)]\tBatch Loss: 0.148466\tLearning Rate (w_theta): 0.000500\t TIME:1909.8s\n",
      "\t\t\t\tDisc: 0.050375\t\tSpars: 0.098091\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 502...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1479893422065899\n",
      "Average validation loss: 0.14790612563062433\n",
      "Training epoch 503...\n",
      "\n",
      "Train Epoch: 503 [0/8000 (0%)]\tBatch Loss: 0.148552\tLearning Rate (w_theta): 0.000500\t TIME:1912.0s\n",
      "\t\t\t\tDisc: 0.052420\t\tSpars: 0.096132\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 503 [4000/8000 (50%)]\tBatch Loss: 0.145088\tLearning Rate (w_theta): 0.000500\t TIME:1913.4s\n",
      "\t\t\t\tDisc: 0.050180\t\tSpars: 0.094909\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 503...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14793959322206154\n",
      "Average validation loss: 0.1478545467425689\n",
      "Training epoch 504...\n",
      "\n",
      "Train Epoch: 504 [0/8000 (0%)]\tBatch Loss: 0.148640\tLearning Rate (w_theta): 0.000500\t TIME:1915.6s\n",
      "\t\t\t\tDisc: 0.051332\t\tSpars: 0.097308\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 504 [4000/8000 (50%)]\tBatch Loss: 0.151840\tLearning Rate (w_theta): 0.000500\t TIME:1917.1s\n",
      "\t\t\t\tDisc: 0.052919\t\tSpars: 0.098921\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 504...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14789072706300166\n",
      "Average validation loss: 0.14780378798038263\n",
      "Training epoch 505...\n",
      "\n",
      "Train Epoch: 505 [0/8000 (0%)]\tBatch Loss: 0.146066\tLearning Rate (w_theta): 0.000500\t TIME:1919.2s\n",
      "\t\t\t\tDisc: 0.049327\t\tSpars: 0.096740\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 505 [4000/8000 (50%)]\tBatch Loss: 0.147305\tLearning Rate (w_theta): 0.000500\t TIME:1920.7s\n",
      "\t\t\t\tDisc: 0.050670\t\tSpars: 0.096635\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 505...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14784260890637235\n",
      "Average validation loss: 0.14775361127012215\n",
      "Training epoch 506...\n",
      "\n",
      "Train Epoch: 506 [0/8000 (0%)]\tBatch Loss: 0.144468\tLearning Rate (w_theta): 0.000500\t TIME:1923.0s\n",
      "\t\t\t\tDisc: 0.050661\t\tSpars: 0.093807\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 506 [4000/8000 (50%)]\tBatch Loss: 0.150878\tLearning Rate (w_theta): 0.000500\t TIME:1924.5s\n",
      "\t\t\t\tDisc: 0.052109\t\tSpars: 0.098770\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 506...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14779535683512504\n",
      "Average validation loss: 0.14770365950155595\n",
      "Training epoch 507...\n",
      "\n",
      "Train Epoch: 507 [0/8000 (0%)]\tBatch Loss: 0.144472\tLearning Rate (w_theta): 0.000500\t TIME:1926.6s\n",
      "\t\t\t\tDisc: 0.048119\t\tSpars: 0.096353\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 507 [4000/8000 (50%)]\tBatch Loss: 0.147047\tLearning Rate (w_theta): 0.000500\t TIME:1928.1s\n",
      "\t\t\t\tDisc: 0.051860\t\tSpars: 0.095187\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 507...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1477480587232624\n",
      "Average validation loss: 0.14765428410617104\n",
      "Training epoch 508...\n",
      "\n",
      "Train Epoch: 508 [0/8000 (0%)]\tBatch Loss: 0.148377\tLearning Rate (w_theta): 0.000500\t TIME:1930.4s\n",
      "\t\t\t\tDisc: 0.051267\t\tSpars: 0.097110\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 508 [4000/8000 (50%)]\tBatch Loss: 0.139249\tLearning Rate (w_theta): 0.000500\t TIME:1931.9s\n",
      "\t\t\t\tDisc: 0.048258\t\tSpars: 0.090991\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 508...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1477015739382289\n",
      "Average validation loss: 0.14760519332401484\n",
      "Training epoch 509...\n",
      "\n",
      "Train Epoch: 509 [0/8000 (0%)]\tBatch Loss: 0.145661\tLearning Rate (w_theta): 0.000500\t TIME:1934.0s\n",
      "\t\t\t\tDisc: 0.049554\t\tSpars: 0.096107\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 509 [4000/8000 (50%)]\tBatch Loss: 0.147508\tLearning Rate (w_theta): 0.000500\t TIME:1935.5s\n",
      "\t\t\t\tDisc: 0.051019\t\tSpars: 0.096490\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 509...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14765601828979097\n",
      "Average validation loss: 0.1475560307295635\n",
      "Training epoch 510...\n",
      "\n",
      "Train Epoch: 510 [0/8000 (0%)]\tBatch Loss: 0.148465\tLearning Rate (w_theta): 0.000500\t TIME:1937.6s\n",
      "\t\t\t\tDisc: 0.051146\t\tSpars: 0.097319\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 510 [4000/8000 (50%)]\tBatch Loss: 0.148655\tLearning Rate (w_theta): 0.000500\t TIME:1939.1s\n",
      "\t\t\t\tDisc: 0.052790\t\tSpars: 0.095865\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 510...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14760947091626336\n",
      "Average validation loss: 0.1475079998254329\n",
      "Training epoch 511...\n",
      "\n",
      "Train Epoch: 511 [0/8000 (0%)]\tBatch Loss: 0.142871\tLearning Rate (w_theta): 0.000500\t TIME:1942.6s\n",
      "\t\t\t\tDisc: 0.048712\t\tSpars: 0.094159\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 511 [4000/8000 (50%)]\tBatch Loss: 0.146779\tLearning Rate (w_theta): 0.000500\t TIME:1944.1s\n",
      "\t\t\t\tDisc: 0.049886\t\tSpars: 0.096893\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 511...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.147564751202282\n",
      "Average validation loss: 0.1474599168361404\n",
      "Training epoch 512...\n",
      "\n",
      "Train Epoch: 512 [0/8000 (0%)]\tBatch Loss: 0.145762\tLearning Rate (w_theta): 0.000500\t TIME:1946.3s\n",
      "\t\t\t\tDisc: 0.050707\t\tSpars: 0.095055\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 512 [4000/8000 (50%)]\tBatch Loss: 0.149632\tLearning Rate (w_theta): 0.000500\t TIME:1947.8s\n",
      "\t\t\t\tDisc: 0.051925\t\tSpars: 0.097707\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 512...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1475196071126279\n",
      "Average validation loss: 0.14741256659956328\n",
      "Training epoch 513...\n",
      "\n",
      "Train Epoch: 513 [0/8000 (0%)]\tBatch Loss: 0.147860\tLearning Rate (w_theta): 0.000500\t TIME:1950.0s\n",
      "\t\t\t\tDisc: 0.050414\t\tSpars: 0.097447\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 513 [4000/8000 (50%)]\tBatch Loss: 0.147662\tLearning Rate (w_theta): 0.000500\t TIME:1951.4s\n",
      "\t\t\t\tDisc: 0.053075\t\tSpars: 0.094587\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 513...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14747491699388593\n",
      "Average validation loss: 0.14736593670230985\n",
      "Training epoch 514...\n",
      "\n",
      "Train Epoch: 514 [0/8000 (0%)]\tBatch Loss: 0.146742\tLearning Rate (w_theta): 0.000500\t TIME:1953.6s\n",
      "\t\t\t\tDisc: 0.051173\t\tSpars: 0.095569\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 514 [4000/8000 (50%)]\tBatch Loss: 0.150499\tLearning Rate (w_theta): 0.000500\t TIME:1955.1s\n",
      "\t\t\t\tDisc: 0.050986\t\tSpars: 0.099513\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 514...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14743142162202516\n",
      "Average validation loss: 0.1473192083051894\n",
      "Training epoch 515...\n",
      "\n",
      "Train Epoch: 515 [0/8000 (0%)]\tBatch Loss: 0.152691\tLearning Rate (w_theta): 0.000500\t TIME:1957.3s\n",
      "\t\t\t\tDisc: 0.053333\t\tSpars: 0.099357\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 515 [4000/8000 (50%)]\tBatch Loss: 0.146710\tLearning Rate (w_theta): 0.000500\t TIME:1958.9s\n",
      "\t\t\t\tDisc: 0.052197\t\tSpars: 0.094513\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 515...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1473873383249553\n",
      "Average validation loss: 0.14727325037491573\n",
      "Training epoch 516...\n",
      "\n",
      "Train Epoch: 516 [0/8000 (0%)]\tBatch Loss: 0.150282\tLearning Rate (w_theta): 0.000500\t TIME:1961.0s\n",
      "\t\t\t\tDisc: 0.050358\t\tSpars: 0.099924\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 516 [4000/8000 (50%)]\tBatch Loss: 0.142319\tLearning Rate (w_theta): 0.000500\t TIME:1962.5s\n",
      "\t\t\t\tDisc: 0.050596\t\tSpars: 0.091723\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 516...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1473437348908595\n",
      "Average validation loss: 0.14722802877154895\n",
      "Training epoch 517...\n",
      "\n",
      "Train Epoch: 517 [0/8000 (0%)]\tBatch Loss: 0.145120\tLearning Rate (w_theta): 0.000500\t TIME:1964.7s\n",
      "\t\t\t\tDisc: 0.047533\t\tSpars: 0.097587\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 517 [4000/8000 (50%)]\tBatch Loss: 0.149345\tLearning Rate (w_theta): 0.000500\t TIME:1966.2s\n",
      "\t\t\t\tDisc: 0.050896\t\tSpars: 0.098449\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 517...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14730153046347372\n",
      "Average validation loss: 0.14718251502317334\n",
      "Training epoch 518...\n",
      "\n",
      "Train Epoch: 518 [0/8000 (0%)]\tBatch Loss: 0.144477\tLearning Rate (w_theta): 0.000500\t TIME:1968.4s\n",
      "\t\t\t\tDisc: 0.049848\t\tSpars: 0.094630\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 518 [4000/8000 (50%)]\tBatch Loss: 0.147836\tLearning Rate (w_theta): 0.000500\t TIME:1969.9s\n",
      "\t\t\t\tDisc: 0.052211\t\tSpars: 0.095625\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 518...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14725848448845974\n",
      "Average validation loss: 0.14713782975682127\n",
      "Training epoch 519...\n",
      "\n",
      "Train Epoch: 519 [0/8000 (0%)]\tBatch Loss: 0.145787\tLearning Rate (w_theta): 0.000500\t TIME:1972.1s\n",
      "\t\t\t\tDisc: 0.052097\t\tSpars: 0.093690\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 519 [4000/8000 (50%)]\tBatch Loss: 0.144478\tLearning Rate (w_theta): 0.000500\t TIME:1973.5s\n",
      "\t\t\t\tDisc: 0.049260\t\tSpars: 0.095218\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 519...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14721691882459986\n",
      "Average validation loss: 0.14709298408794835\n",
      "Training epoch 520...\n",
      "\n",
      "Train Epoch: 520 [0/8000 (0%)]\tBatch Loss: 0.143957\tLearning Rate (w_theta): 0.000500\t TIME:1975.7s\n",
      "\t\t\t\tDisc: 0.051353\t\tSpars: 0.092604\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 520 [4000/8000 (50%)]\tBatch Loss: 0.151706\tLearning Rate (w_theta): 0.000500\t TIME:1977.1s\n",
      "\t\t\t\tDisc: 0.051342\t\tSpars: 0.100363\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 520...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1471750885875407\n",
      "Average validation loss: 0.14704851963168097\n",
      "Training epoch 521...\n",
      "\n",
      "Train Epoch: 521 [0/8000 (0%)]\tBatch Loss: 0.141362\tLearning Rate (w_theta): 0.000500\t TIME:1980.7s\n",
      "\t\t\t\tDisc: 0.047015\t\tSpars: 0.094347\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 521 [4000/8000 (50%)]\tBatch Loss: 0.148630\tLearning Rate (w_theta): 0.000500\t TIME:1982.2s\n",
      "\t\t\t\tDisc: 0.052577\t\tSpars: 0.096052\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 521...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14713343621550373\n",
      "Average validation loss: 0.14700457302123182\n",
      "Training epoch 522...\n",
      "\n",
      "Train Epoch: 522 [0/8000 (0%)]\tBatch Loss: 0.144529\tLearning Rate (w_theta): 0.000500\t TIME:1984.3s\n",
      "\t\t\t\tDisc: 0.048121\t\tSpars: 0.096408\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 522 [4000/8000 (50%)]\tBatch Loss: 0.146965\tLearning Rate (w_theta): 0.000500\t TIME:1985.8s\n",
      "\t\t\t\tDisc: 0.052003\t\tSpars: 0.094962\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 522...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14709178768614523\n",
      "Average validation loss: 0.14696156590707726\n",
      "Training epoch 523...\n",
      "\n",
      "Train Epoch: 523 [0/8000 (0%)]\tBatch Loss: 0.147691\tLearning Rate (w_theta): 0.000500\t TIME:1988.0s\n",
      "\t\t\t\tDisc: 0.050774\t\tSpars: 0.096918\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 523 [4000/8000 (50%)]\tBatch Loss: 0.149884\tLearning Rate (w_theta): 0.000500\t TIME:1989.5s\n",
      "\t\t\t\tDisc: 0.050265\t\tSpars: 0.099620\n",
      "\t TVw: -0.554207 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 523...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14705197850113003\n",
      "Average validation loss: 0.14691821568487767\n",
      "Training epoch 524...\n",
      "\n",
      "Train Epoch: 524 [0/8000 (0%)]\tBatch Loss: 0.145751\tLearning Rate (w_theta): 0.000500\t TIME:1991.7s\n",
      "\t\t\t\tDisc: 0.050404\t\tSpars: 0.095347\n",
      "\t TVw: -0.554206 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 524 [4000/8000 (50%)]\tBatch Loss: 0.144740\tLearning Rate (w_theta): 0.000500\t TIME:1993.2s\n",
      "\t\t\t\tDisc: 0.049900\t\tSpars: 0.094840\n",
      "\t TVw: -0.554206 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 524...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14701123267874183\n",
      "Average validation loss: 0.14687571630831062\n",
      "Training epoch 525...\n",
      "\n",
      "Train Epoch: 525 [0/8000 (0%)]\tBatch Loss: 0.143174\tLearning Rate (w_theta): 0.000500\t TIME:1995.5s\n",
      "\t\t\t\tDisc: 0.050128\t\tSpars: 0.093046\n",
      "\t TVw: -0.554206 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 525 [4000/8000 (50%)]\tBatch Loss: 0.145011\tLearning Rate (w_theta): 0.000500\t TIME:1997.0s\n",
      "\t\t\t\tDisc: 0.050542\t\tSpars: 0.094470\n",
      "\t TVw: -0.554206 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 525...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14697179166113628\n",
      "Average validation loss: 0.14683319751060475\n",
      "Training epoch 526...\n",
      "\n",
      "Train Epoch: 526 [0/8000 (0%)]\tBatch Loss: 0.146309\tLearning Rate (w_theta): 0.000500\t TIME:1999.3s\n",
      "\t\t\t\tDisc: 0.050040\t\tSpars: 0.096268\n",
      "\t TVw: -0.554205 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 526 [4000/8000 (50%)]\tBatch Loss: 0.147588\tLearning Rate (w_theta): 0.000500\t TIME:2000.8s\n",
      "\t\t\t\tDisc: 0.051145\t\tSpars: 0.096443\n",
      "\t TVw: -0.554205 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 526...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1469316445476643\n",
      "Average validation loss: 0.1467916075150787\n",
      "Training epoch 527...\n",
      "\n",
      "Train Epoch: 527 [0/8000 (0%)]\tBatch Loss: 0.148349\tLearning Rate (w_theta): 0.000500\t TIME:2003.0s\n",
      "\t\t\t\tDisc: 0.050220\t\tSpars: 0.098128\n",
      "\t TVw: -0.554205 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 527 [4000/8000 (50%)]\tBatch Loss: 0.147146\tLearning Rate (w_theta): 0.000500\t TIME:2004.5s\n",
      "\t\t\t\tDisc: 0.050051\t\tSpars: 0.097094\n",
      "\t TVw: -0.554205 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 527...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1468924505967083\n",
      "Average validation loss: 0.1467505364096222\n",
      "Training epoch 528...\n",
      "\n",
      "Train Epoch: 528 [0/8000 (0%)]\tBatch Loss: 0.144068\tLearning Rate (w_theta): 0.000500\t TIME:2006.7s\n",
      "\t\t\t\tDisc: 0.048009\t\tSpars: 0.096059\n",
      "\t TVw: -0.554204 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 528 [4000/8000 (50%)]\tBatch Loss: 0.149231\tLearning Rate (w_theta): 0.000500\t TIME:2008.1s\n",
      "\t\t\t\tDisc: 0.049427\t\tSpars: 0.099803\n",
      "\t TVw: -0.554204 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 528...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1468540105601102\n",
      "Average validation loss: 0.1467095977851865\n",
      "Training epoch 529...\n",
      "\n",
      "Train Epoch: 529 [0/8000 (0%)]\tBatch Loss: 0.144567\tLearning Rate (w_theta): 0.000500\t TIME:2010.4s\n",
      "\t\t\t\tDisc: 0.049138\t\tSpars: 0.095428\n",
      "\t TVw: -0.554204 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 529 [4000/8000 (50%)]\tBatch Loss: 0.150481\tLearning Rate (w_theta): 0.000500\t TIME:2011.9s\n",
      "\t\t\t\tDisc: 0.048504\t\tSpars: 0.101977\n",
      "\t TVw: -0.554204 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 529...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14681514749150168\n",
      "Average validation loss: 0.1466695428084992\n",
      "Training epoch 530...\n",
      "\n",
      "Train Epoch: 530 [0/8000 (0%)]\tBatch Loss: 0.145561\tLearning Rate (w_theta): 0.000500\t TIME:2014.0s\n",
      "\t\t\t\tDisc: 0.048852\t\tSpars: 0.096709\n",
      "\t TVw: -0.554203 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 530 [4000/8000 (50%)]\tBatch Loss: 0.146307\tLearning Rate (w_theta): 0.000500\t TIME:2015.5s\n",
      "\t\t\t\tDisc: 0.050952\t\tSpars: 0.095356\n",
      "\t TVw: -0.554203 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 530...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14677809859612986\n",
      "Average validation loss: 0.14662900604860868\n",
      "Training epoch 531...\n",
      "\n",
      "Train Epoch: 531 [0/8000 (0%)]\tBatch Loss: 0.144941\tLearning Rate (w_theta): 0.000500\t TIME:2019.0s\n",
      "\t\t\t\tDisc: 0.049884\t\tSpars: 0.095057\n",
      "\t TVw: -0.554203 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 531 [4000/8000 (50%)]\tBatch Loss: 0.150169\tLearning Rate (w_theta): 0.000500\t TIME:2020.5s\n",
      "\t\t\t\tDisc: 0.052326\t\tSpars: 0.097843\n",
      "\t TVw: -0.554203 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 531...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.146739880212127\n",
      "Average validation loss: 0.1465893847930182\n",
      "Training epoch 532...\n",
      "\n",
      "Train Epoch: 532 [0/8000 (0%)]\tBatch Loss: 0.141646\tLearning Rate (w_theta): 0.000500\t TIME:2022.7s\n",
      "\t\t\t\tDisc: 0.049705\t\tSpars: 0.091941\n",
      "\t TVw: -0.554202 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 532 [4000/8000 (50%)]\tBatch Loss: 0.148947\tLearning Rate (w_theta): 0.000500\t TIME:2024.2s\n",
      "\t\t\t\tDisc: 0.050752\t\tSpars: 0.098194\n",
      "\t TVw: -0.554202 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 532...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14670284499874817\n",
      "Average validation loss: 0.14654999838730684\n",
      "Training epoch 533...\n",
      "\n",
      "Train Epoch: 533 [0/8000 (0%)]\tBatch Loss: 0.147322\tLearning Rate (w_theta): 0.000500\t TIME:2026.4s\n",
      "\t\t\t\tDisc: 0.049427\t\tSpars: 0.097895\n",
      "\t TVw: -0.554202 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 533 [4000/8000 (50%)]\tBatch Loss: 0.147698\tLearning Rate (w_theta): 0.000500\t TIME:2027.9s\n",
      "\t\t\t\tDisc: 0.050097\t\tSpars: 0.097600\n",
      "\t TVw: -0.554202 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 533...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14666588251330548\n",
      "Average validation loss: 0.14651118436348504\n",
      "Training epoch 534...\n",
      "\n",
      "Train Epoch: 534 [0/8000 (0%)]\tBatch Loss: 0.147826\tLearning Rate (w_theta): 0.000500\t TIME:2030.0s\n",
      "\t\t\t\tDisc: 0.051526\t\tSpars: 0.096300\n",
      "\t TVw: -0.554202 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 534 [4000/8000 (50%)]\tBatch Loss: 0.145056\tLearning Rate (w_theta): 0.000500\t TIME:2031.5s\n",
      "\t\t\t\tDisc: 0.049654\t\tSpars: 0.095401\n",
      "\t TVw: -0.554201 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 534...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14662956446210118\n",
      "Average validation loss: 0.14647264389177078\n",
      "Training epoch 535...\n",
      "\n",
      "Train Epoch: 535 [0/8000 (0%)]\tBatch Loss: 0.143416\tLearning Rate (w_theta): 0.000500\t TIME:2033.7s\n",
      "\t\t\t\tDisc: 0.047545\t\tSpars: 0.095870\n",
      "\t TVw: -0.554201 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 535 [4000/8000 (50%)]\tBatch Loss: 0.148221\tLearning Rate (w_theta): 0.000500\t TIME:2035.1s\n",
      "\t\t\t\tDisc: 0.051666\t\tSpars: 0.096555\n",
      "\t TVw: -0.554201 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 535...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14659355459177204\n",
      "Average validation loss: 0.14643439132568156\n",
      "Training epoch 536...\n",
      "\n",
      "Train Epoch: 536 [0/8000 (0%)]\tBatch Loss: 0.150495\tLearning Rate (w_theta): 0.000500\t TIME:2037.5s\n",
      "\t\t\t\tDisc: 0.052054\t\tSpars: 0.098441\n",
      "\t TVw: -0.554201 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 536 [4000/8000 (50%)]\tBatch Loss: 0.144605\tLearning Rate (w_theta): 0.000500\t TIME:2038.9s\n",
      "\t\t\t\tDisc: 0.048953\t\tSpars: 0.095652\n",
      "\t TVw: -0.554200 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 536...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14655780491319534\n",
      "Average validation loss: 0.14639653974406566\n",
      "Training epoch 537...\n",
      "\n",
      "Train Epoch: 537 [0/8000 (0%)]\tBatch Loss: 0.144536\tLearning Rate (w_theta): 0.000500\t TIME:2041.1s\n",
      "\t\t\t\tDisc: 0.051225\t\tSpars: 0.093311\n",
      "\t TVw: -0.554200 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 537 [4000/8000 (50%)]\tBatch Loss: 0.146728\tLearning Rate (w_theta): 0.000500\t TIME:2042.6s\n",
      "\t\t\t\tDisc: 0.048798\t\tSpars: 0.097929\n",
      "\t TVw: -0.554200 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 537...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14652226679835167\n",
      "Average validation loss: 0.14635921848120054\n",
      "Training epoch 538...\n",
      "\n",
      "Train Epoch: 538 [0/8000 (0%)]\tBatch Loss: 0.145944\tLearning Rate (w_theta): 0.000500\t TIME:2044.8s\n",
      "\t\t\t\tDisc: 0.050430\t\tSpars: 0.095514\n",
      "\t TVw: -0.554200 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 538 [4000/8000 (50%)]\tBatch Loss: 0.145152\tLearning Rate (w_theta): 0.000500\t TIME:2046.3s\n",
      "\t\t\t\tDisc: 0.050787\t\tSpars: 0.094365\n",
      "\t TVw: -0.554199 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 538...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14648749379821435\n",
      "Average validation loss: 0.14632207512846407\n",
      "Training epoch 539...\n",
      "\n",
      "Train Epoch: 539 [0/8000 (0%)]\tBatch Loss: 0.150076\tLearning Rate (w_theta): 0.000500\t TIME:2048.5s\n",
      "\t\t\t\tDisc: 0.051765\t\tSpars: 0.098311\n",
      "\t TVw: -0.554199 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 539 [4000/8000 (50%)]\tBatch Loss: 0.148064\tLearning Rate (w_theta): 0.000500\t TIME:2049.9s\n",
      "\t\t\t\tDisc: 0.051658\t\tSpars: 0.096406\n",
      "\t TVw: -0.554199 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 539...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14645190116455573\n",
      "Average validation loss: 0.14628609740478038\n",
      "Training epoch 540...\n",
      "\n",
      "Train Epoch: 540 [0/8000 (0%)]\tBatch Loss: 0.149616\tLearning Rate (w_theta): 0.000500\t TIME:2052.1s\n",
      "\t\t\t\tDisc: 0.051324\t\tSpars: 0.098292\n",
      "\t TVw: -0.554199 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 540 [4000/8000 (50%)]\tBatch Loss: 0.141318\tLearning Rate (w_theta): 0.000500\t TIME:2053.5s\n",
      "\t\t\t\tDisc: 0.050351\t\tSpars: 0.090967\n",
      "\t TVw: -0.554198 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 540...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1464186680778999\n",
      "Average validation loss: 0.1462495164338187\n",
      "Training epoch 541...\n",
      "\n",
      "Train Epoch: 541 [0/8000 (0%)]\tBatch Loss: 0.144942\tLearning Rate (w_theta): 0.000500\t TIME:2057.1s\n",
      "\t\t\t\tDisc: 0.046780\t\tSpars: 0.098162\n",
      "\t TVw: -0.554198 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 541 [4000/8000 (50%)]\tBatch Loss: 0.147364\tLearning Rate (w_theta): 0.000500\t TIME:2058.6s\n",
      "\t\t\t\tDisc: 0.053565\t\tSpars: 0.093799\n",
      "\t TVw: -0.554198 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 541...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1463842910121447\n",
      "Average validation loss: 0.14621362845520355\n",
      "Training epoch 542...\n",
      "\n",
      "Train Epoch: 542 [0/8000 (0%)]\tBatch Loss: 0.147519\tLearning Rate (w_theta): 0.000500\t TIME:2060.8s\n",
      "\t\t\t\tDisc: 0.049041\t\tSpars: 0.098479\n",
      "\t TVw: -0.554198 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 542 [4000/8000 (50%)]\tBatch Loss: 0.147854\tLearning Rate (w_theta): 0.000500\t TIME:2062.3s\n",
      "\t\t\t\tDisc: 0.051924\t\tSpars: 0.095929\n",
      "\t TVw: -0.554197 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 542...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14635118686942658\n",
      "Average validation loss: 0.146177737559958\n",
      "Training epoch 543...\n",
      "\n",
      "Train Epoch: 543 [0/8000 (0%)]\tBatch Loss: 0.143435\tLearning Rate (w_theta): 0.000500\t TIME:2064.4s\n",
      "\t\t\t\tDisc: 0.047918\t\tSpars: 0.095517\n",
      "\t TVw: -0.554197 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 543 [4000/8000 (50%)]\tBatch Loss: 0.146429\tLearning Rate (w_theta): 0.000500\t TIME:2065.9s\n",
      "\t\t\t\tDisc: 0.048466\t\tSpars: 0.097963\n",
      "\t TVw: -0.554197 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 543...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1463182725244059\n",
      "Average validation loss: 0.14614196565619153\n",
      "Training epoch 544...\n",
      "\n",
      "Train Epoch: 544 [0/8000 (0%)]\tBatch Loss: 0.143225\tLearning Rate (w_theta): 0.000500\t TIME:2068.1s\n",
      "\t\t\t\tDisc: 0.048562\t\tSpars: 0.094662\n",
      "\t TVw: -0.554197 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 544 [4000/8000 (50%)]\tBatch Loss: 0.147714\tLearning Rate (w_theta): 0.000500\t TIME:2069.6s\n",
      "\t\t\t\tDisc: 0.050391\t\tSpars: 0.097323\n",
      "\t TVw: -0.554197 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 544...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14628484929225224\n",
      "Average validation loss: 0.14610706020349043\n",
      "Training epoch 545...\n",
      "\n",
      "Train Epoch: 545 [0/8000 (0%)]\tBatch Loss: 0.148604\tLearning Rate (w_theta): 0.000500\t TIME:2071.7s\n",
      "\t\t\t\tDisc: 0.050094\t\tSpars: 0.098509\n",
      "\t TVw: -0.554196 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 545 [4000/8000 (50%)]\tBatch Loss: 0.144019\tLearning Rate (w_theta): 0.000500\t TIME:2073.2s\n",
      "\t\t\t\tDisc: 0.048449\t\tSpars: 0.095570\n",
      "\t TVw: -0.554196 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 545...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14625214910273768\n",
      "Average validation loss: 0.14607276842754413\n",
      "Training epoch 546...\n",
      "\n",
      "Train Epoch: 546 [0/8000 (0%)]\tBatch Loss: 0.144818\tLearning Rate (w_theta): 0.000500\t TIME:2075.6s\n",
      "\t\t\t\tDisc: 0.050248\t\tSpars: 0.094569\n",
      "\t TVw: -0.554196 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 546 [4000/8000 (50%)]\tBatch Loss: 0.142177\tLearning Rate (w_theta): 0.000500\t TIME:2077.0s\n",
      "\t\t\t\tDisc: 0.048646\t\tSpars: 0.093531\n",
      "\t TVw: -0.554196 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 546...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14622045516311233\n",
      "Average validation loss: 0.14603858165287706\n",
      "Training epoch 547...\n",
      "\n",
      "Train Epoch: 547 [0/8000 (0%)]\tBatch Loss: 0.151079\tLearning Rate (w_theta): 0.000500\t TIME:2079.2s\n",
      "\t\t\t\tDisc: 0.050677\t\tSpars: 0.100402\n",
      "\t TVw: -0.554195 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 547 [4000/8000 (50%)]\tBatch Loss: 0.147738\tLearning Rate (w_theta): 0.000500\t TIME:2080.7s\n",
      "\t\t\t\tDisc: 0.048102\t\tSpars: 0.099635\n",
      "\t TVw: -0.554195 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 547...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14618901699970066\n",
      "Average validation loss: 0.14600455877536164\n",
      "Training epoch 548...\n",
      "\n",
      "Train Epoch: 548 [0/8000 (0%)]\tBatch Loss: 0.151600\tLearning Rate (w_theta): 0.000500\t TIME:2082.9s\n",
      "\t\t\t\tDisc: 0.053041\t\tSpars: 0.098559\n",
      "\t TVw: -0.554195 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 548 [4000/8000 (50%)]\tBatch Loss: 0.141056\tLearning Rate (w_theta): 0.000500\t TIME:2084.3s\n",
      "\t\t\t\tDisc: 0.049261\t\tSpars: 0.091795\n",
      "\t TVw: -0.554195 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 548...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1461568586992738\n",
      "Average validation loss: 0.14597156351543167\n",
      "Training epoch 549...\n",
      "\n",
      "Train Epoch: 549 [0/8000 (0%)]\tBatch Loss: 0.144362\tLearning Rate (w_theta): 0.000500\t TIME:2086.5s\n",
      "\t\t\t\tDisc: 0.048444\t\tSpars: 0.095918\n",
      "\t TVw: -0.554194 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 549 [4000/8000 (50%)]\tBatch Loss: 0.147970\tLearning Rate (w_theta): 0.000500\t TIME:2088.0s\n",
      "\t\t\t\tDisc: 0.051499\t\tSpars: 0.096471\n",
      "\t TVw: -0.554194 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 549...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14612570408031622\n",
      "Average validation loss: 0.1459390124768682\n",
      "Training epoch 550...\n",
      "\n",
      "Train Epoch: 550 [0/8000 (0%)]\tBatch Loss: 0.144837\tLearning Rate (w_theta): 0.000500\t TIME:2090.2s\n",
      "\t\t\t\tDisc: 0.048486\t\tSpars: 0.096351\n",
      "\t TVw: -0.554194 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 550 [4000/8000 (50%)]\tBatch Loss: 0.145703\tLearning Rate (w_theta): 0.000500\t TIME:2091.7s\n",
      "\t\t\t\tDisc: 0.048493\t\tSpars: 0.097210\n",
      "\t TVw: -0.554194 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 550...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14609559946708706\n",
      "Average validation loss: 0.1459062071183303\n",
      "Training epoch 551...\n",
      "\n",
      "Train Epoch: 551 [0/8000 (0%)]\tBatch Loss: 0.144215\tLearning Rate (w_theta): 0.000500\t TIME:2095.3s\n",
      "\t\t\t\tDisc: 0.048282\t\tSpars: 0.095933\n",
      "\t TVw: -0.554193 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 551 [4000/8000 (50%)]\tBatch Loss: 0.145974\tLearning Rate (w_theta): 0.000500\t TIME:2096.8s\n",
      "\t\t\t\tDisc: 0.050999\t\tSpars: 0.094975\n",
      "\t TVw: -0.554193 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 551...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1460651689937693\n",
      "Average validation loss: 0.14587367170199772\n",
      "Training epoch 552...\n",
      "\n",
      "Train Epoch: 552 [0/8000 (0%)]\tBatch Loss: 0.149205\tLearning Rate (w_theta): 0.000500\t TIME:2099.0s\n",
      "\t\t\t\tDisc: 0.051613\t\tSpars: 0.097592\n",
      "\t TVw: -0.554193 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 552 [4000/8000 (50%)]\tBatch Loss: 0.143265\tLearning Rate (w_theta): 0.000500\t TIME:2100.4s\n",
      "\t\t\t\tDisc: 0.047582\t\tSpars: 0.095683\n",
      "\t TVw: -0.554193 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 552...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14603487910469143\n",
      "Average validation loss: 0.1458415542297004\n",
      "Training epoch 553...\n",
      "\n",
      "Train Epoch: 553 [0/8000 (0%)]\tBatch Loss: 0.144635\tLearning Rate (w_theta): 0.000500\t TIME:2102.6s\n",
      "\t\t\t\tDisc: 0.050262\t\tSpars: 0.094373\n",
      "\t TVw: -0.554192 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 553 [4000/8000 (50%)]\tBatch Loss: 0.150129\tLearning Rate (w_theta): 0.000500\t TIME:2104.1s\n",
      "\t\t\t\tDisc: 0.049466\t\tSpars: 0.100664\n",
      "\t TVw: -0.554192 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 553...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14600495786407414\n",
      "Average validation loss: 0.14580980793485657\n",
      "Training epoch 554...\n",
      "\n",
      "Train Epoch: 554 [0/8000 (0%)]\tBatch Loss: 0.144526\tLearning Rate (w_theta): 0.000500\t TIME:2106.3s\n",
      "\t\t\t\tDisc: 0.049553\t\tSpars: 0.094973\n",
      "\t TVw: -0.554192 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 554 [4000/8000 (50%)]\tBatch Loss: 0.149958\tLearning Rate (w_theta): 0.000500\t TIME:2107.8s\n",
      "\t\t\t\tDisc: 0.050328\t\tSpars: 0.099629\n",
      "\t TVw: -0.554192 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 554...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14597524167446566\n",
      "Average validation loss: 0.14577854166673318\n",
      "Training epoch 555...\n",
      "\n",
      "Train Epoch: 555 [0/8000 (0%)]\tBatch Loss: 0.144142\tLearning Rate (w_theta): 0.000500\t TIME:2110.0s\n",
      "\t\t\t\tDisc: 0.048714\t\tSpars: 0.095428\n",
      "\t TVw: -0.554192 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 555 [4000/8000 (50%)]\tBatch Loss: 0.144846\tLearning Rate (w_theta): 0.000500\t TIME:2111.4s\n",
      "\t\t\t\tDisc: 0.049748\t\tSpars: 0.095098\n",
      "\t TVw: -0.554191 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 555...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14594557126139734\n",
      "Average validation loss: 0.14574806355516598\n",
      "Training epoch 556...\n",
      "\n",
      "Train Epoch: 556 [0/8000 (0%)]\tBatch Loss: 0.144083\tLearning Rate (w_theta): 0.000500\t TIME:2113.8s\n",
      "\t\t\t\tDisc: 0.048557\t\tSpars: 0.095526\n",
      "\t TVw: -0.554191 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 556 [4000/8000 (50%)]\tBatch Loss: 0.145776\tLearning Rate (w_theta): 0.000500\t TIME:2115.2s\n",
      "\t\t\t\tDisc: 0.049232\t\tSpars: 0.096544\n",
      "\t TVw: -0.554191 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 556...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14591769634401253\n",
      "Average validation loss: 0.14571688899122504\n",
      "Training epoch 557...\n",
      "\n",
      "Train Epoch: 557 [0/8000 (0%)]\tBatch Loss: 0.148308\tLearning Rate (w_theta): 0.000500\t TIME:2117.4s\n",
      "\t\t\t\tDisc: 0.048156\t\tSpars: 0.100152\n",
      "\t TVw: -0.554191 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 557 [4000/8000 (50%)]\tBatch Loss: 0.143514\tLearning Rate (w_theta): 0.000500\t TIME:2118.9s\n",
      "\t\t\t\tDisc: 0.048936\t\tSpars: 0.094578\n",
      "\t TVw: -0.554190 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 557...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14588847885418588\n",
      "Average validation loss: 0.14568647833318235\n",
      "Training epoch 558...\n",
      "\n",
      "Train Epoch: 558 [0/8000 (0%)]\tBatch Loss: 0.145741\tLearning Rate (w_theta): 0.000500\t TIME:2121.1s\n",
      "\t\t\t\tDisc: 0.050150\t\tSpars: 0.095590\n",
      "\t TVw: -0.554190 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 558 [4000/8000 (50%)]\tBatch Loss: 0.146123\tLearning Rate (w_theta): 0.000500\t TIME:2122.6s\n",
      "\t\t\t\tDisc: 0.048983\t\tSpars: 0.097141\n",
      "\t TVw: -0.554190 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 558...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14585992312785073\n",
      "Average validation loss: 0.14565660473443034\n",
      "Training epoch 559...\n",
      "\n",
      "Train Epoch: 559 [0/8000 (0%)]\tBatch Loss: 0.147771\tLearning Rate (w_theta): 0.000500\t TIME:2124.8s\n",
      "\t\t\t\tDisc: 0.049667\t\tSpars: 0.098104\n",
      "\t TVw: -0.554190 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 559 [4000/8000 (50%)]\tBatch Loss: 0.145261\tLearning Rate (w_theta): 0.000500\t TIME:2126.3s\n",
      "\t\t\t\tDisc: 0.050326\t\tSpars: 0.094935\n",
      "\t TVw: -0.554189 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 559...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14583197321483454\n",
      "Average validation loss: 0.14562713912346553\n",
      "Training epoch 560...\n",
      "\n",
      "Train Epoch: 560 [0/8000 (0%)]\tBatch Loss: 0.149297\tLearning Rate (w_theta): 0.000500\t TIME:2128.4s\n",
      "\t\t\t\tDisc: 0.051479\t\tSpars: 0.097819\n",
      "\t TVw: -0.554189 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 560 [4000/8000 (50%)]\tBatch Loss: 0.144107\tLearning Rate (w_theta): 0.000500\t TIME:2129.9s\n",
      "\t\t\t\tDisc: 0.049382\t\tSpars: 0.094724\n",
      "\t TVw: -0.554189 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 560...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14580439742254112\n",
      "Average validation loss: 0.14559782932231585\n",
      "Training epoch 561...\n",
      "\n",
      "Train Epoch: 561 [0/8000 (0%)]\tBatch Loss: 0.149737\tLearning Rate (w_theta): 0.000500\t TIME:2133.4s\n",
      "\t\t\t\tDisc: 0.050548\t\tSpars: 0.099189\n",
      "\t TVw: -0.554189 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 561 [4000/8000 (50%)]\tBatch Loss: 0.145098\tLearning Rate (w_theta): 0.000500\t TIME:2134.9s\n",
      "\t\t\t\tDisc: 0.048837\t\tSpars: 0.096261\n",
      "\t TVw: -0.554188 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 561...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14577665939961545\n",
      "Average validation loss: 0.14556909527269296\n",
      "Training epoch 562...\n",
      "\n",
      "Train Epoch: 562 [0/8000 (0%)]\tBatch Loss: 0.140493\tLearning Rate (w_theta): 0.000500\t TIME:2137.1s\n",
      "\t\t\t\tDisc: 0.049487\t\tSpars: 0.091006\n",
      "\t TVw: -0.554188 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 562 [4000/8000 (50%)]\tBatch Loss: 0.144840\tLearning Rate (w_theta): 0.000500\t TIME:2138.6s\n",
      "\t\t\t\tDisc: 0.048563\t\tSpars: 0.096278\n",
      "\t TVw: -0.554188 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 562...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1457496555381776\n",
      "Average validation loss: 0.14554053464614308\n",
      "Training epoch 563...\n",
      "\n",
      "Train Epoch: 563 [0/8000 (0%)]\tBatch Loss: 0.142804\tLearning Rate (w_theta): 0.000500\t TIME:2140.8s\n",
      "\t\t\t\tDisc: 0.049041\t\tSpars: 0.093763\n",
      "\t TVw: -0.554188 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 563 [4000/8000 (50%)]\tBatch Loss: 0.145087\tLearning Rate (w_theta): 0.000500\t TIME:2142.2s\n",
      "\t\t\t\tDisc: 0.049646\t\tSpars: 0.095441\n",
      "\t TVw: -0.554187 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 563...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14572225044487774\n",
      "Average validation loss: 0.14551276007375655\n",
      "Training epoch 564...\n",
      "\n",
      "Train Epoch: 564 [0/8000 (0%)]\tBatch Loss: 0.149582\tLearning Rate (w_theta): 0.000500\t TIME:2144.4s\n",
      "\t\t\t\tDisc: 0.050710\t\tSpars: 0.098872\n",
      "\t TVw: -0.554187 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 564 [4000/8000 (50%)]\tBatch Loss: 0.141833\tLearning Rate (w_theta): 0.000500\t TIME:2145.9s\n",
      "\t\t\t\tDisc: 0.047728\t\tSpars: 0.094105\n",
      "\t TVw: -0.554187 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 564...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14569625822854282\n",
      "Average validation loss: 0.14548477806540006\n",
      "Training epoch 565...\n",
      "\n",
      "Train Epoch: 565 [0/8000 (0%)]\tBatch Loss: 0.140940\tLearning Rate (w_theta): 0.000500\t TIME:2148.1s\n",
      "\t\t\t\tDisc: 0.046510\t\tSpars: 0.094430\n",
      "\t TVw: -0.554187 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 565 [4000/8000 (50%)]\tBatch Loss: 0.145142\tLearning Rate (w_theta): 0.000500\t TIME:2149.5s\n",
      "\t\t\t\tDisc: 0.048504\t\tSpars: 0.096637\n",
      "\t TVw: -0.554187 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 565...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14566945750939103\n",
      "Average validation loss: 0.14545759446472267\n",
      "Training epoch 566...\n",
      "\n",
      "Train Epoch: 566 [0/8000 (0%)]\tBatch Loss: 0.147132\tLearning Rate (w_theta): 0.000500\t TIME:2151.8s\n",
      "\t\t\t\tDisc: 0.051954\t\tSpars: 0.095178\n",
      "\t TVw: -0.554186 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 566 [4000/8000 (50%)]\tBatch Loss: 0.145724\tLearning Rate (w_theta): 0.000500\t TIME:2153.3s\n",
      "\t\t\t\tDisc: 0.048727\t\tSpars: 0.096998\n",
      "\t TVw: -0.554186 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 566...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14564468581726323\n",
      "Average validation loss: 0.14542962896064637\n",
      "Training epoch 567...\n",
      "\n",
      "Train Epoch: 567 [0/8000 (0%)]\tBatch Loss: 0.146212\tLearning Rate (w_theta): 0.000500\t TIME:2155.6s\n",
      "\t\t\t\tDisc: 0.049027\t\tSpars: 0.097185\n",
      "\t TVw: -0.554186 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 567 [4000/8000 (50%)]\tBatch Loss: 0.146111\tLearning Rate (w_theta): 0.000500\t TIME:2157.0s\n",
      "\t\t\t\tDisc: 0.050996\t\tSpars: 0.095115\n",
      "\t TVw: -0.554186 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 567...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14561795352530285\n",
      "Average validation loss: 0.1454027504164682\n",
      "Training epoch 568...\n",
      "\n",
      "Train Epoch: 568 [0/8000 (0%)]\tBatch Loss: 0.143458\tLearning Rate (w_theta): 0.000500\t TIME:2159.2s\n",
      "\t\t\t\tDisc: 0.048817\t\tSpars: 0.094641\n",
      "\t TVw: -0.554185 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 568 [4000/8000 (50%)]\tBatch Loss: 0.144619\tLearning Rate (w_theta): 0.000500\t TIME:2160.7s\n",
      "\t\t\t\tDisc: 0.048898\t\tSpars: 0.095721\n",
      "\t TVw: -0.554185 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 568...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14559307915631836\n",
      "Average validation loss: 0.14537566179655012\n",
      "Training epoch 569...\n",
      "\n",
      "Train Epoch: 569 [0/8000 (0%)]\tBatch Loss: 0.147316\tLearning Rate (w_theta): 0.000500\t TIME:2162.9s\n",
      "\t\t\t\tDisc: 0.050800\t\tSpars: 0.096516\n",
      "\t TVw: -0.554185 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 569 [4000/8000 (50%)]\tBatch Loss: 0.146115\tLearning Rate (w_theta): 0.000500\t TIME:2164.3s\n",
      "\t\t\t\tDisc: 0.049408\t\tSpars: 0.096707\n",
      "\t TVw: -0.554185 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 569...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14556757677294926\n",
      "Average validation loss: 0.14534917229971245\n",
      "Training epoch 570...\n",
      "\n",
      "Train Epoch: 570 [0/8000 (0%)]\tBatch Loss: 0.149619\tLearning Rate (w_theta): 0.000500\t TIME:2166.5s\n",
      "\t\t\t\tDisc: 0.049699\t\tSpars: 0.099920\n",
      "\t TVw: -0.554184 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 570 [4000/8000 (50%)]\tBatch Loss: 0.147021\tLearning Rate (w_theta): 0.000500\t TIME:2168.0s\n",
      "\t\t\t\tDisc: 0.049370\t\tSpars: 0.097651\n",
      "\t TVw: -0.554184 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 570...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1455429220117688\n",
      "Average validation loss: 0.14532274174411294\n",
      "Training epoch 571...\n",
      "\n",
      "Train Epoch: 571 [0/8000 (0%)]\tBatch Loss: 0.142509\tLearning Rate (w_theta): 0.000500\t TIME:2171.7s\n",
      "\t\t\t\tDisc: 0.048343\t\tSpars: 0.094166\n",
      "\t TVw: -0.554184 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 571 [4000/8000 (50%)]\tBatch Loss: 0.142852\tLearning Rate (w_theta): 0.000500\t TIME:2173.1s\n",
      "\t\t\t\tDisc: 0.048080\t\tSpars: 0.094772\n",
      "\t TVw: -0.554184 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 571...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1455179881080316\n",
      "Average validation loss: 0.14529677516722206\n",
      "Training epoch 572...\n",
      "\n",
      "Train Epoch: 572 [0/8000 (0%)]\tBatch Loss: 0.146238\tLearning Rate (w_theta): 0.000500\t TIME:2175.3s\n",
      "\t\t\t\tDisc: 0.049694\t\tSpars: 0.096544\n",
      "\t TVw: -0.554183 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 572 [4000/8000 (50%)]\tBatch Loss: 0.144127\tLearning Rate (w_theta): 0.000500\t TIME:2176.8s\n",
      "\t\t\t\tDisc: 0.046354\t\tSpars: 0.097774\n",
      "\t TVw: -0.554183 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 572...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1454937227426142\n",
      "Average validation loss: 0.14527091471178483\n",
      "Training epoch 573...\n",
      "\n",
      "Train Epoch: 573 [0/8000 (0%)]\tBatch Loss: 0.148537\tLearning Rate (w_theta): 0.000500\t TIME:2179.0s\n",
      "\t\t\t\tDisc: 0.050028\t\tSpars: 0.098509\n",
      "\t TVw: -0.554183 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 573 [4000/8000 (50%)]\tBatch Loss: 0.145723\tLearning Rate (w_theta): 0.000500\t TIME:2180.5s\n",
      "\t\t\t\tDisc: 0.048560\t\tSpars: 0.097163\n",
      "\t TVw: -0.554183 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 573...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1454694311849851\n",
      "Average validation loss: 0.14524533236081222\n",
      "Training epoch 574...\n",
      "\n",
      "Train Epoch: 574 [0/8000 (0%)]\tBatch Loss: 0.147668\tLearning Rate (w_theta): 0.000500\t TIME:2182.7s\n",
      "\t\t\t\tDisc: 0.050404\t\tSpars: 0.097264\n",
      "\t TVw: -0.554182 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 574 [4000/8000 (50%)]\tBatch Loss: 0.141997\tLearning Rate (w_theta): 0.000500\t TIME:2184.1s\n",
      "\t\t\t\tDisc: 0.049073\t\tSpars: 0.092924\n",
      "\t TVw: -0.554182 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 574...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14544520325008084\n",
      "Average validation loss: 0.1452202585199171\n",
      "Training epoch 575...\n",
      "\n",
      "Train Epoch: 575 [0/8000 (0%)]\tBatch Loss: 0.142683\tLearning Rate (w_theta): 0.000500\t TIME:2186.4s\n",
      "\t\t\t\tDisc: 0.049376\t\tSpars: 0.093306\n",
      "\t TVw: -0.554182 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 575 [4000/8000 (50%)]\tBatch Loss: 0.142202\tLearning Rate (w_theta): 0.000500\t TIME:2187.8s\n",
      "\t\t\t\tDisc: 0.046785\t\tSpars: 0.095417\n",
      "\t TVw: -0.554182 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 575...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14542146823848326\n",
      "Average validation loss: 0.14519540995671867\n",
      "Training epoch 576...\n",
      "\n",
      "Train Epoch: 576 [0/8000 (0%)]\tBatch Loss: 0.143214\tLearning Rate (w_theta): 0.000500\t TIME:2190.0s\n",
      "\t\t\t\tDisc: 0.048235\t\tSpars: 0.094979\n",
      "\t TVw: -0.554182 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 576 [4000/8000 (50%)]\tBatch Loss: 0.148065\tLearning Rate (w_theta): 0.000500\t TIME:2191.5s\n",
      "\t\t\t\tDisc: 0.050754\t\tSpars: 0.097312\n",
      "\t TVw: -0.554181 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 576...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14539862142582272\n",
      "Average validation loss: 0.1451700532386938\n",
      "Training epoch 577...\n",
      "\n",
      "Train Epoch: 577 [0/8000 (0%)]\tBatch Loss: 0.145253\tLearning Rate (w_theta): 0.000500\t TIME:2193.8s\n",
      "\t\t\t\tDisc: 0.049092\t\tSpars: 0.096161\n",
      "\t TVw: -0.554181 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 577 [4000/8000 (50%)]\tBatch Loss: 0.149253\tLearning Rate (w_theta): 0.000500\t TIME:2195.3s\n",
      "\t\t\t\tDisc: 0.052475\t\tSpars: 0.096778\n",
      "\t TVw: -0.554181 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 577...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14537416269778947\n",
      "Average validation loss: 0.14514593633550882\n",
      "Training epoch 578...\n",
      "\n",
      "Train Epoch: 578 [0/8000 (0%)]\tBatch Loss: 0.146771\tLearning Rate (w_theta): 0.000500\t TIME:2197.5s\n",
      "\t\t\t\tDisc: 0.047779\t\tSpars: 0.098993\n",
      "\t TVw: -0.554181 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 578 [4000/8000 (50%)]\tBatch Loss: 0.144891\tLearning Rate (w_theta): 0.000500\t TIME:2199.0s\n",
      "\t\t\t\tDisc: 0.049828\t\tSpars: 0.095063\n",
      "\t TVw: -0.554180 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 578...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14535175579514228\n",
      "Average validation loss: 0.1451213834395979\n",
      "Training epoch 579...\n",
      "\n",
      "Train Epoch: 579 [0/8000 (0%)]\tBatch Loss: 0.142684\tLearning Rate (w_theta): 0.000500\t TIME:2201.2s\n",
      "\t\t\t\tDisc: 0.047363\t\tSpars: 0.095321\n",
      "\t TVw: -0.554180 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 579 [4000/8000 (50%)]\tBatch Loss: 0.140774\tLearning Rate (w_theta): 0.000500\t TIME:2202.7s\n",
      "\t\t\t\tDisc: 0.047624\t\tSpars: 0.093151\n",
      "\t TVw: -0.554180 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 579...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14532851891964116\n",
      "Average validation loss: 0.1450973331995308\n",
      "Training epoch 580...\n",
      "\n",
      "Train Epoch: 580 [0/8000 (0%)]\tBatch Loss: 0.144376\tLearning Rate (w_theta): 0.000500\t TIME:2204.9s\n",
      "\t\t\t\tDisc: 0.048677\t\tSpars: 0.095699\n",
      "\t TVw: -0.554180 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 580 [4000/8000 (50%)]\tBatch Loss: 0.144857\tLearning Rate (w_theta): 0.000500\t TIME:2206.3s\n",
      "\t\t\t\tDisc: 0.050112\t\tSpars: 0.094745\n",
      "\t TVw: -0.554179 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 580...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14530646523627988\n",
      "Average validation loss: 0.1450729767941906\n",
      "Training epoch 581...\n",
      "\n",
      "Train Epoch: 581 [0/8000 (0%)]\tBatch Loss: 0.147126\tLearning Rate (w_theta): 0.000500\t TIME:2209.9s\n",
      "\t\t\t\tDisc: 0.050431\t\tSpars: 0.096695\n",
      "\t TVw: -0.554179 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 581 [4000/8000 (50%)]\tBatch Loss: 0.147248\tLearning Rate (w_theta): 0.000500\t TIME:2211.3s\n",
      "\t\t\t\tDisc: 0.048994\t\tSpars: 0.098253\n",
      "\t TVw: -0.554179 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 581...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14528336645497286\n",
      "Average validation loss: 0.14504951645815856\n",
      "Training epoch 582...\n",
      "\n",
      "Train Epoch: 582 [0/8000 (0%)]\tBatch Loss: 0.143808\tLearning Rate (w_theta): 0.000500\t TIME:2213.5s\n",
      "\t\t\t\tDisc: 0.049145\t\tSpars: 0.094663\n",
      "\t TVw: -0.554179 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 582 [4000/8000 (50%)]\tBatch Loss: 0.143987\tLearning Rate (w_theta): 0.000500\t TIME:2214.9s\n",
      "\t\t\t\tDisc: 0.046549\t\tSpars: 0.097438\n",
      "\t TVw: -0.554178 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 582...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14526132297167788\n",
      "Average validation loss: 0.14502622289175587\n",
      "Training epoch 583...\n",
      "\n",
      "Train Epoch: 583 [0/8000 (0%)]\tBatch Loss: 0.146268\tLearning Rate (w_theta): 0.000500\t TIME:2217.1s\n",
      "\t\t\t\tDisc: 0.048308\t\tSpars: 0.097960\n",
      "\t TVw: -0.554178 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 583 [4000/8000 (50%)]\tBatch Loss: 0.145386\tLearning Rate (w_theta): 0.000500\t TIME:2218.6s\n",
      "\t\t\t\tDisc: 0.048825\t\tSpars: 0.096561\n",
      "\t TVw: -0.554178 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 583...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14523937516814117\n",
      "Average validation loss: 0.145003176855043\n",
      "Training epoch 584...\n",
      "\n",
      "Train Epoch: 584 [0/8000 (0%)]\tBatch Loss: 0.141408\tLearning Rate (w_theta): 0.000500\t TIME:2220.9s\n",
      "\t\t\t\tDisc: 0.047795\t\tSpars: 0.093614\n",
      "\t TVw: -0.554178 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 584 [4000/8000 (50%)]\tBatch Loss: 0.144683\tLearning Rate (w_theta): 0.000500\t TIME:2222.3s\n",
      "\t\t\t\tDisc: 0.049258\t\tSpars: 0.095424\n",
      "\t TVw: -0.554177 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 584...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14521771709970227\n",
      "Average validation loss: 0.14498037863402358\n",
      "Training epoch 585...\n",
      "\n",
      "Train Epoch: 585 [0/8000 (0%)]\tBatch Loss: 0.142576\tLearning Rate (w_theta): 0.000500\t TIME:2224.5s\n",
      "\t\t\t\tDisc: 0.050231\t\tSpars: 0.092345\n",
      "\t TVw: -0.554177 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 585 [4000/8000 (50%)]\tBatch Loss: 0.151783\tLearning Rate (w_theta): 0.000500\t TIME:2226.0s\n",
      "\t\t\t\tDisc: 0.051604\t\tSpars: 0.100180\n",
      "\t TVw: -0.554177 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 585...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14519633859152645\n",
      "Average validation loss: 0.14495771686922265\n",
      "Training epoch 586...\n",
      "\n",
      "Train Epoch: 586 [0/8000 (0%)]\tBatch Loss: 0.145468\tLearning Rate (w_theta): 0.000500\t TIME:2228.2s\n",
      "\t\t\t\tDisc: 0.049452\t\tSpars: 0.096016\n",
      "\t TVw: -0.554177 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 586 [4000/8000 (50%)]\tBatch Loss: 0.147268\tLearning Rate (w_theta): 0.000500\t TIME:2229.6s\n",
      "\t\t\t\tDisc: 0.049815\t\tSpars: 0.097454\n",
      "\t TVw: -0.554177 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 586...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1451751336334743\n",
      "Average validation loss: 0.1449352069620478\n",
      "Training epoch 587...\n",
      "\n",
      "Train Epoch: 587 [0/8000 (0%)]\tBatch Loss: 0.142244\tLearning Rate (w_theta): 0.000500\t TIME:2231.8s\n",
      "\t\t\t\tDisc: 0.044496\t\tSpars: 0.097748\n",
      "\t TVw: -0.554176 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 587 [4000/8000 (50%)]\tBatch Loss: 0.147026\tLearning Rate (w_theta): 0.000500\t TIME:2233.3s\n",
      "\t\t\t\tDisc: 0.050266\t\tSpars: 0.096760\n",
      "\t TVw: -0.554176 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 587...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14515409803112148\n",
      "Average validation loss: 0.14491287270332465\n",
      "Training epoch 588...\n",
      "\n",
      "Train Epoch: 588 [0/8000 (0%)]\tBatch Loss: 0.146312\tLearning Rate (w_theta): 0.000500\t TIME:2235.8s\n",
      "\t\t\t\tDisc: 0.048511\t\tSpars: 0.097800\n",
      "\t TVw: -0.554176 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 588 [4000/8000 (50%)]\tBatch Loss: 0.139195\tLearning Rate (w_theta): 0.000500\t TIME:2237.2s\n",
      "\t\t\t\tDisc: 0.046394\t\tSpars: 0.092801\n",
      "\t TVw: -0.554176 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 588...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1451337849748844\n",
      "Average validation loss: 0.14489022941213167\n",
      "Training epoch 589...\n",
      "\n",
      "Train Epoch: 589 [0/8000 (0%)]\tBatch Loss: 0.144899\tLearning Rate (w_theta): 0.000500\t TIME:2239.5s\n",
      "\t\t\t\tDisc: 0.048954\t\tSpars: 0.095945\n",
      "\t TVw: -0.554175 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 589 [4000/8000 (50%)]\tBatch Loss: 0.145197\tLearning Rate (w_theta): 0.000500\t TIME:2241.0s\n",
      "\t\t\t\tDisc: 0.050285\t\tSpars: 0.094912\n",
      "\t TVw: -0.554175 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 589...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14511202336630719\n",
      "Average validation loss: 0.14486871934697804\n",
      "Training epoch 590...\n",
      "\n",
      "Train Epoch: 590 [0/8000 (0%)]\tBatch Loss: 0.144491\tLearning Rate (w_theta): 0.000500\t TIME:2243.2s\n",
      "\t\t\t\tDisc: 0.049186\t\tSpars: 0.095305\n",
      "\t TVw: -0.554175 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 590 [4000/8000 (50%)]\tBatch Loss: 0.142708\tLearning Rate (w_theta): 0.000500\t TIME:2244.7s\n",
      "\t\t\t\tDisc: 0.048771\t\tSpars: 0.093937\n",
      "\t TVw: -0.554175 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 590...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14509178393458996\n",
      "Average validation loss: 0.14484716807314782\n",
      "Training epoch 591...\n",
      "\n",
      "Train Epoch: 591 [0/8000 (0%)]\tBatch Loss: 0.144565\tLearning Rate (w_theta): 0.000500\t TIME:2248.3s\n",
      "\t\t\t\tDisc: 0.048174\t\tSpars: 0.096390\n",
      "\t TVw: -0.554174 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 591 [4000/8000 (50%)]\tBatch Loss: 0.145726\tLearning Rate (w_theta): 0.000500\t TIME:2249.8s\n",
      "\t\t\t\tDisc: 0.047252\t\tSpars: 0.098474\n",
      "\t TVw: -0.554174 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 591...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14507178816624794\n",
      "Average validation loss: 0.14482551338320737\n",
      "Training epoch 592...\n",
      "\n",
      "Train Epoch: 592 [0/8000 (0%)]\tBatch Loss: 0.141558\tLearning Rate (w_theta): 0.000500\t TIME:2252.1s\n",
      "\t\t\t\tDisc: 0.046751\t\tSpars: 0.094807\n",
      "\t TVw: -0.554174 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 592 [4000/8000 (50%)]\tBatch Loss: 0.144314\tLearning Rate (w_theta): 0.000500\t TIME:2253.6s\n",
      "\t\t\t\tDisc: 0.044322\t\tSpars: 0.099992\n",
      "\t TVw: -0.554174 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 592...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14505118248351861\n",
      "Average validation loss: 0.1448043777149738\n",
      "Training epoch 593...\n",
      "\n",
      "Train Epoch: 593 [0/8000 (0%)]\tBatch Loss: 0.145249\tLearning Rate (w_theta): 0.000500\t TIME:2255.9s\n",
      "\t\t\t\tDisc: 0.049569\t\tSpars: 0.095680\n",
      "\t TVw: -0.554173 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 593 [4000/8000 (50%)]\tBatch Loss: 0.145091\tLearning Rate (w_theta): 0.000500\t TIME:2257.3s\n",
      "\t\t\t\tDisc: 0.048362\t\tSpars: 0.096730\n",
      "\t TVw: -0.554173 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 593...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14503124535848166\n",
      "Average validation loss: 0.14478321215007345\n",
      "Training epoch 594...\n",
      "\n",
      "Train Epoch: 594 [0/8000 (0%)]\tBatch Loss: 0.146340\tLearning Rate (w_theta): 0.000500\t TIME:2259.5s\n",
      "\t\t\t\tDisc: 0.049495\t\tSpars: 0.096845\n",
      "\t TVw: -0.554173 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 594 [4000/8000 (50%)]\tBatch Loss: 0.144032\tLearning Rate (w_theta): 0.000500\t TIME:2261.0s\n",
      "\t\t\t\tDisc: 0.049290\t\tSpars: 0.094742\n",
      "\t TVw: -0.554173 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 594...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1450113103678036\n",
      "Average validation loss: 0.14476219981175828\n",
      "Training epoch 595...\n",
      "\n",
      "Train Epoch: 595 [0/8000 (0%)]\tBatch Loss: 0.144327\tLearning Rate (w_theta): 0.000500\t TIME:2263.2s\n",
      "\t\t\t\tDisc: 0.048016\t\tSpars: 0.096311\n",
      "\t TVw: -0.554172 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 595 [4000/8000 (50%)]\tBatch Loss: 0.147417\tLearning Rate (w_theta): 0.000500\t TIME:2264.6s\n",
      "\t\t\t\tDisc: 0.048573\t\tSpars: 0.098844\n",
      "\t TVw: -0.554172 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 595...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14499138825680458\n",
      "Average validation loss: 0.14474147564210776\n",
      "Training epoch 596...\n",
      "\n",
      "Train Epoch: 596 [0/8000 (0%)]\tBatch Loss: 0.148732\tLearning Rate (w_theta): 0.000500\t TIME:2266.9s\n",
      "\t\t\t\tDisc: 0.050730\t\tSpars: 0.098002\n",
      "\t TVw: -0.554172 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 596 [4000/8000 (50%)]\tBatch Loss: 0.149795\tLearning Rate (w_theta): 0.000500\t TIME:2268.4s\n",
      "\t\t\t\tDisc: 0.048699\t\tSpars: 0.101096\n",
      "\t TVw: -0.554172 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 596...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14497189953905534\n",
      "Average validation loss: 0.14472083640175146\n",
      "Training epoch 597...\n",
      "\n",
      "Train Epoch: 597 [0/8000 (0%)]\tBatch Loss: 0.144133\tLearning Rate (w_theta): 0.000500\t TIME:2270.5s\n",
      "\t\t\t\tDisc: 0.048181\t\tSpars: 0.095953\n",
      "\t TVw: -0.554172 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 597 [4000/8000 (50%)]\tBatch Loss: 0.145305\tLearning Rate (w_theta): 0.000500\t TIME:2272.0s\n",
      "\t\t\t\tDisc: 0.051449\t\tSpars: 0.093856\n",
      "\t TVw: -0.554171 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 597...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14495231532993572\n",
      "Average validation loss: 0.1447005845542969\n",
      "Training epoch 598...\n",
      "\n",
      "Train Epoch: 598 [0/8000 (0%)]\tBatch Loss: 0.146411\tLearning Rate (w_theta): 0.000500\t TIME:2274.4s\n",
      "\t\t\t\tDisc: 0.049730\t\tSpars: 0.096681\n",
      "\t TVw: -0.554171 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 598 [4000/8000 (50%)]\tBatch Loss: 0.142505\tLearning Rate (w_theta): 0.000500\t TIME:2275.8s\n",
      "\t\t\t\tDisc: 0.048436\t\tSpars: 0.094069\n",
      "\t TVw: -0.554171 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 598...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14493297687935394\n",
      "Average validation loss: 0.14468058425314345\n",
      "Training epoch 599...\n",
      "\n",
      "Train Epoch: 599 [0/8000 (0%)]\tBatch Loss: 0.144796\tLearning Rate (w_theta): 0.000500\t TIME:2278.0s\n",
      "\t\t\t\tDisc: 0.048526\t\tSpars: 0.096269\n",
      "\t TVw: -0.554171 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 599 [4000/8000 (50%)]\tBatch Loss: 0.144010\tLearning Rate (w_theta): 0.000500\t TIME:2279.5s\n",
      "\t\t\t\tDisc: 0.046820\t\tSpars: 0.097190\n",
      "\t TVw: -0.554170 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 599...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14491400620603034\n",
      "Average validation loss: 0.14466070290721353\n",
      "Training epoch 600...\n",
      "\n",
      "Train Epoch: 600 [0/8000 (0%)]\tBatch Loss: 0.140392\tLearning Rate (w_theta): 0.000500\t TIME:2281.7s\n",
      "\t\t\t\tDisc: 0.046289\t\tSpars: 0.094104\n",
      "\t TVw: -0.554170 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 600 [4000/8000 (50%)]\tBatch Loss: 0.148455\tLearning Rate (w_theta): 0.000500\t TIME:2283.1s\n",
      "\t\t\t\tDisc: 0.050265\t\tSpars: 0.098190\n",
      "\t TVw: -0.554170 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 600...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1448951651475125\n",
      "Average validation loss: 0.14464104222757662\n",
      "Training epoch 601...\n",
      "\n",
      "Train Epoch: 601 [0/8000 (0%)]\tBatch Loss: 0.148816\tLearning Rate (w_theta): 0.000500\t TIME:2286.6s\n",
      "\t\t\t\tDisc: 0.051008\t\tSpars: 0.097808\n",
      "\t TVw: -0.554170 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 601 [4000/8000 (50%)]\tBatch Loss: 0.147686\tLearning Rate (w_theta): 0.000500\t TIME:2288.1s\n",
      "\t\t\t\tDisc: 0.048203\t\tSpars: 0.099483\n",
      "\t TVw: -0.554169 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 601...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14487647058208114\n",
      "Average validation loss: 0.1446215469688003\n",
      "Training epoch 602...\n",
      "\n",
      "Train Epoch: 602 [0/8000 (0%)]\tBatch Loss: 0.144719\tLearning Rate (w_theta): 0.000500\t TIME:2290.3s\n",
      "\t\t\t\tDisc: 0.047380\t\tSpars: 0.097339\n",
      "\t TVw: -0.554169 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 602 [4000/8000 (50%)]\tBatch Loss: 0.144710\tLearning Rate (w_theta): 0.000500\t TIME:2291.8s\n",
      "\t\t\t\tDisc: 0.047821\t\tSpars: 0.096889\n",
      "\t TVw: -0.554169 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 602...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1448583556344223\n",
      "Average validation loss: 0.14460188719325615\n",
      "Training epoch 603...\n",
      "\n",
      "Train Epoch: 603 [0/8000 (0%)]\tBatch Loss: 0.144792\tLearning Rate (w_theta): 0.000500\t TIME:2294.0s\n",
      "\t\t\t\tDisc: 0.050232\t\tSpars: 0.094561\n",
      "\t TVw: -0.554169 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 603 [4000/8000 (50%)]\tBatch Loss: 0.147978\tLearning Rate (w_theta): 0.000500\t TIME:2295.4s\n",
      "\t\t\t\tDisc: 0.049259\t\tSpars: 0.098720\n",
      "\t TVw: -0.554168 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 603...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14483990876721095\n",
      "Average validation loss: 0.14458254327064962\n",
      "Training epoch 604...\n",
      "\n",
      "Train Epoch: 604 [0/8000 (0%)]\tBatch Loss: 0.147085\tLearning Rate (w_theta): 0.000500\t TIME:2297.6s\n",
      "\t\t\t\tDisc: 0.051223\t\tSpars: 0.095862\n",
      "\t TVw: -0.554168 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 604 [4000/8000 (50%)]\tBatch Loss: 0.148212\tLearning Rate (w_theta): 0.000500\t TIME:2299.1s\n",
      "\t\t\t\tDisc: 0.048709\t\tSpars: 0.099502\n",
      "\t TVw: -0.554168 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 604...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14482124837369698\n",
      "Average validation loss: 0.1445639055989134\n",
      "Training epoch 605...\n",
      "\n",
      "Train Epoch: 605 [0/8000 (0%)]\tBatch Loss: 0.143488\tLearning Rate (w_theta): 0.000500\t TIME:2301.3s\n",
      "\t\t\t\tDisc: 0.049080\t\tSpars: 0.094408\n",
      "\t TVw: -0.554168 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 605 [4000/8000 (50%)]\tBatch Loss: 0.145106\tLearning Rate (w_theta): 0.000500\t TIME:2302.8s\n",
      "\t\t\t\tDisc: 0.050783\t\tSpars: 0.094322\n",
      "\t TVw: -0.554167 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 605...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1448040060859965\n",
      "Average validation loss: 0.14454474598114625\n",
      "Training epoch 606...\n",
      "\n",
      "Train Epoch: 606 [0/8000 (0%)]\tBatch Loss: 0.142460\tLearning Rate (w_theta): 0.000500\t TIME:2305.0s\n",
      "\t\t\t\tDisc: 0.046274\t\tSpars: 0.096186\n",
      "\t TVw: -0.554167 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 606 [4000/8000 (50%)]\tBatch Loss: 0.146115\tLearning Rate (w_theta): 0.000500\t TIME:2306.4s\n",
      "\t\t\t\tDisc: 0.049898\t\tSpars: 0.096217\n",
      "\t TVw: -0.554167 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 606...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1447857765063641\n",
      "Average validation loss: 0.14452624103709677\n",
      "Training epoch 607...\n",
      "\n",
      "Train Epoch: 607 [0/8000 (0%)]\tBatch Loss: 0.149347\tLearning Rate (w_theta): 0.000500\t TIME:2308.6s\n",
      "\t\t\t\tDisc: 0.050351\t\tSpars: 0.098997\n",
      "\t TVw: -0.554167 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 607 [4000/8000 (50%)]\tBatch Loss: 0.142649\tLearning Rate (w_theta): 0.000500\t TIME:2310.1s\n",
      "\t\t\t\tDisc: 0.047611\t\tSpars: 0.095038\n",
      "\t TVw: -0.554166 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 607...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1447685273321146\n",
      "Average validation loss: 0.1445076635422164\n",
      "Training epoch 608...\n",
      "\n",
      "Train Epoch: 608 [0/8000 (0%)]\tBatch Loss: 0.144381\tLearning Rate (w_theta): 0.000500\t TIME:2312.5s\n",
      "\t\t\t\tDisc: 0.048020\t\tSpars: 0.096361\n",
      "\t TVw: -0.554166 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 608 [4000/8000 (50%)]\tBatch Loss: 0.140192\tLearning Rate (w_theta): 0.000500\t TIME:2314.0s\n",
      "\t\t\t\tDisc: 0.046637\t\tSpars: 0.093555\n",
      "\t TVw: -0.554166 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 608...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.144751297370644\n",
      "Average validation loss: 0.14448908407935487\n",
      "Training epoch 609...\n",
      "\n",
      "Train Epoch: 609 [0/8000 (0%)]\tBatch Loss: 0.141575\tLearning Rate (w_theta): 0.000500\t TIME:2316.3s\n",
      "\t\t\t\tDisc: 0.047692\t\tSpars: 0.093884\n",
      "\t TVw: -0.554166 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 609 [4000/8000 (50%)]\tBatch Loss: 0.146416\tLearning Rate (w_theta): 0.000500\t TIME:2317.7s\n",
      "\t\t\t\tDisc: 0.048831\t\tSpars: 0.097585\n",
      "\t TVw: -0.554166 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 609...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1447336891520503\n",
      "Average validation loss: 0.1444710736252331\n",
      "Training epoch 610...\n",
      "\n",
      "Train Epoch: 610 [0/8000 (0%)]\tBatch Loss: 0.145025\tLearning Rate (w_theta): 0.000500\t TIME:2319.9s\n",
      "\t\t\t\tDisc: 0.049011\t\tSpars: 0.096014\n",
      "\t TVw: -0.554165 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 610 [4000/8000 (50%)]\tBatch Loss: 0.145172\tLearning Rate (w_theta): 0.000500\t TIME:2321.4s\n",
      "\t\t\t\tDisc: 0.049195\t\tSpars: 0.095978\n",
      "\t TVw: -0.554165 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 610...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14471671364477257\n",
      "Average validation loss: 0.1444531673441907\n",
      "Training epoch 611...\n",
      "\n",
      "Train Epoch: 611 [0/8000 (0%)]\tBatch Loss: 0.142562\tLearning Rate (w_theta): 0.000500\t TIME:2325.0s\n",
      "\t\t\t\tDisc: 0.045878\t\tSpars: 0.096684\n",
      "\t TVw: -0.554165 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 611 [4000/8000 (50%)]\tBatch Loss: 0.143455\tLearning Rate (w_theta): 0.000500\t TIME:2326.4s\n",
      "\t\t\t\tDisc: 0.048989\t\tSpars: 0.094466\n",
      "\t TVw: -0.554165 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 611...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14469981593707826\n",
      "Average validation loss: 0.1444354427293152\n",
      "Training epoch 612...\n",
      "\n",
      "Train Epoch: 612 [0/8000 (0%)]\tBatch Loss: 0.147179\tLearning Rate (w_theta): 0.000500\t TIME:2328.6s\n",
      "\t\t\t\tDisc: 0.048822\t\tSpars: 0.098357\n",
      "\t TVw: -0.554164 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 612 [4000/8000 (50%)]\tBatch Loss: 0.145571\tLearning Rate (w_theta): 0.000500\t TIME:2330.1s\n",
      "\t\t\t\tDisc: 0.050882\t\tSpars: 0.094689\n",
      "\t TVw: -0.554164 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 612...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14468315999090597\n",
      "Average validation loss: 0.1444178469222837\n",
      "Training epoch 613...\n",
      "\n",
      "Train Epoch: 613 [0/8000 (0%)]\tBatch Loss: 0.148543\tLearning Rate (w_theta): 0.000500\t TIME:2332.3s\n",
      "\t\t\t\tDisc: 0.050940\t\tSpars: 0.097602\n",
      "\t TVw: -0.554164 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 613 [4000/8000 (50%)]\tBatch Loss: 0.140354\tLearning Rate (w_theta): 0.000500\t TIME:2333.8s\n",
      "\t\t\t\tDisc: 0.047731\t\tSpars: 0.092624\n",
      "\t TVw: -0.554164 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 613...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14466663849574107\n",
      "Average validation loss: 0.1444003916203191\n",
      "Training epoch 614...\n",
      "\n",
      "Train Epoch: 614 [0/8000 (0%)]\tBatch Loss: 0.144678\tLearning Rate (w_theta): 0.000500\t TIME:2336.0s\n",
      "\t\t\t\tDisc: 0.048792\t\tSpars: 0.095886\n",
      "\t TVw: -0.554163 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 614 [4000/8000 (50%)]\tBatch Loss: 0.147688\tLearning Rate (w_theta): 0.000500\t TIME:2337.5s\n",
      "\t\t\t\tDisc: 0.050068\t\tSpars: 0.097620\n",
      "\t TVw: -0.554163 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 614...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14464964947730016\n",
      "Average validation loss: 0.14438382663793736\n",
      "Training epoch 615...\n",
      "\n",
      "Train Epoch: 615 [0/8000 (0%)]\tBatch Loss: 0.146356\tLearning Rate (w_theta): 0.000500\t TIME:2339.8s\n",
      "\t\t\t\tDisc: 0.049714\t\tSpars: 0.096641\n",
      "\t TVw: -0.554163 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 615 [4000/8000 (50%)]\tBatch Loss: 0.144997\tLearning Rate (w_theta): 0.000500\t TIME:2341.3s\n",
      "\t\t\t\tDisc: 0.046630\t\tSpars: 0.098367\n",
      "\t TVw: -0.554163 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 615...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14463405950344307\n",
      "Average validation loss: 0.14436684076608214\n",
      "Training epoch 616...\n",
      "\n",
      "Train Epoch: 616 [0/8000 (0%)]\tBatch Loss: 0.143003\tLearning Rate (w_theta): 0.000500\t TIME:2343.5s\n",
      "\t\t\t\tDisc: 0.049446\t\tSpars: 0.093556\n",
      "\t TVw: -0.554162 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 616 [4000/8000 (50%)]\tBatch Loss: 0.144722\tLearning Rate (w_theta): 0.000500\t TIME:2345.0s\n",
      "\t\t\t\tDisc: 0.048638\t\tSpars: 0.096085\n",
      "\t TVw: -0.554162 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 616...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14461772971465686\n",
      "Average validation loss: 0.14435025457141992\n",
      "Training epoch 617...\n",
      "\n",
      "Train Epoch: 617 [0/8000 (0%)]\tBatch Loss: 0.146555\tLearning Rate (w_theta): 0.000500\t TIME:2347.3s\n",
      "\t\t\t\tDisc: 0.049635\t\tSpars: 0.096920\n",
      "\t TVw: -0.554162 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 617 [4000/8000 (50%)]\tBatch Loss: 0.144535\tLearning Rate (w_theta): 0.000500\t TIME:2348.7s\n",
      "\t\t\t\tDisc: 0.050424\t\tSpars: 0.094111\n",
      "\t TVw: -0.554162 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 617...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14460202320298715\n",
      "Average validation loss: 0.1443338912861845\n",
      "Training epoch 618...\n",
      "\n",
      "Train Epoch: 618 [0/8000 (0%)]\tBatch Loss: 0.146502\tLearning Rate (w_theta): 0.000500\t TIME:2350.9s\n",
      "\t\t\t\tDisc: 0.049182\t\tSpars: 0.097320\n",
      "\t TVw: -0.554161 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 618 [4000/8000 (50%)]\tBatch Loss: 0.146899\tLearning Rate (w_theta): 0.000500\t TIME:2352.4s\n",
      "\t\t\t\tDisc: 0.049838\t\tSpars: 0.097061\n",
      "\t TVw: -0.554161 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 618...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14458623548435684\n",
      "Average validation loss: 0.14431779596208044\n",
      "Training epoch 619...\n",
      "\n",
      "Train Epoch: 619 [0/8000 (0%)]\tBatch Loss: 0.146581\tLearning Rate (w_theta): 0.000500\t TIME:2354.7s\n",
      "\t\t\t\tDisc: 0.050720\t\tSpars: 0.095860\n",
      "\t TVw: -0.554161 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 619 [4000/8000 (50%)]\tBatch Loss: 0.146281\tLearning Rate (w_theta): 0.000500\t TIME:2356.2s\n",
      "\t\t\t\tDisc: 0.049274\t\tSpars: 0.097007\n",
      "\t TVw: -0.554161 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 619...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1445708847270154\n",
      "Average validation loss: 0.14430168215714728\n",
      "Training epoch 620...\n",
      "\n",
      "Train Epoch: 620 [0/8000 (0%)]\tBatch Loss: 0.143393\tLearning Rate (w_theta): 0.000500\t TIME:2358.4s\n",
      "\t\t\t\tDisc: 0.047057\t\tSpars: 0.096335\n",
      "\t TVw: -0.554161 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 620 [4000/8000 (50%)]\tBatch Loss: 0.144853\tLearning Rate (w_theta): 0.000500\t TIME:2359.9s\n",
      "\t\t\t\tDisc: 0.049592\t\tSpars: 0.095261\n",
      "\t TVw: -0.554160 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 620...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1445551082709728\n",
      "Average validation loss: 0.14428611712765455\n",
      "Training epoch 621...\n",
      "\n",
      "Train Epoch: 621 [0/8000 (0%)]\tBatch Loss: 0.141136\tLearning Rate (w_theta): 0.000500\t TIME:2363.6s\n",
      "\t\t\t\tDisc: 0.047386\t\tSpars: 0.093750\n",
      "\t TVw: -0.554160 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 621 [4000/8000 (50%)]\tBatch Loss: 0.147729\tLearning Rate (w_theta): 0.000500\t TIME:2365.1s\n",
      "\t\t\t\tDisc: 0.049227\t\tSpars: 0.098502\n",
      "\t TVw: -0.554160 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 621...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1445399795904587\n",
      "Average validation loss: 0.1442706194377112\n",
      "Training epoch 622...\n",
      "\n",
      "Train Epoch: 622 [0/8000 (0%)]\tBatch Loss: 0.144838\tLearning Rate (w_theta): 0.000500\t TIME:2367.3s\n",
      "\t\t\t\tDisc: 0.046249\t\tSpars: 0.098590\n",
      "\t TVw: -0.554160 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 622 [4000/8000 (50%)]\tBatch Loss: 0.141832\tLearning Rate (w_theta): 0.000500\t TIME:2368.7s\n",
      "\t\t\t\tDisc: 0.048053\t\tSpars: 0.093779\n",
      "\t TVw: -0.554159 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 622...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14452507652063556\n",
      "Average validation loss: 0.14425511437357094\n",
      "Training epoch 623...\n",
      "\n",
      "Train Epoch: 623 [0/8000 (0%)]\tBatch Loss: 0.143063\tLearning Rate (w_theta): 0.000500\t TIME:2371.0s\n",
      "\t\t\t\tDisc: 0.047132\t\tSpars: 0.095930\n",
      "\t TVw: -0.554159 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 623 [4000/8000 (50%)]\tBatch Loss: 0.142280\tLearning Rate (w_theta): 0.000500\t TIME:2372.4s\n",
      "\t\t\t\tDisc: 0.047875\t\tSpars: 0.094405\n",
      "\t TVw: -0.554159 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 623...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14451030928585568\n",
      "Average validation loss: 0.14423958442259016\n",
      "Training epoch 624...\n",
      "\n",
      "Train Epoch: 624 [0/8000 (0%)]\tBatch Loss: 0.143328\tLearning Rate (w_theta): 0.000500\t TIME:2374.7s\n",
      "\t\t\t\tDisc: 0.047552\t\tSpars: 0.095776\n",
      "\t TVw: -0.554159 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 624 [4000/8000 (50%)]\tBatch Loss: 0.144794\tLearning Rate (w_theta): 0.000500\t TIME:2376.1s\n",
      "\t\t\t\tDisc: 0.048681\t\tSpars: 0.096113\n",
      "\t TVw: -0.554158 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 624...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14449517236650591\n",
      "Average validation loss: 0.14422447613069306\n",
      "Training epoch 625...\n",
      "\n",
      "Train Epoch: 625 [0/8000 (0%)]\tBatch Loss: 0.142197\tLearning Rate (w_theta): 0.000500\t TIME:2378.4s\n",
      "\t\t\t\tDisc: 0.048306\t\tSpars: 0.093890\n",
      "\t TVw: -0.554158 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 625 [4000/8000 (50%)]\tBatch Loss: 0.144774\tLearning Rate (w_theta): 0.000500\t TIME:2379.9s\n",
      "\t\t\t\tDisc: 0.046714\t\tSpars: 0.098060\n",
      "\t TVw: -0.554158 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 625...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14448064760751458\n",
      "Average validation loss: 0.1442090793769671\n",
      "Training epoch 626...\n",
      "\n",
      "Train Epoch: 626 [0/8000 (0%)]\tBatch Loss: 0.141263\tLearning Rate (w_theta): 0.000500\t TIME:2382.1s\n",
      "\t\t\t\tDisc: 0.047503\t\tSpars: 0.093760\n",
      "\t TVw: -0.554158 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 626 [4000/8000 (50%)]\tBatch Loss: 0.145620\tLearning Rate (w_theta): 0.000500\t TIME:2383.5s\n",
      "\t\t\t\tDisc: 0.049943\t\tSpars: 0.095677\n",
      "\t TVw: -0.554157 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 626...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1444660757477607\n",
      "Average validation loss: 0.1441938571155329\n",
      "Training epoch 627...\n",
      "\n",
      "Train Epoch: 627 [0/8000 (0%)]\tBatch Loss: 0.148620\tLearning Rate (w_theta): 0.000500\t TIME:2385.7s\n",
      "\t\t\t\tDisc: 0.049590\t\tSpars: 0.099030\n",
      "\t TVw: -0.554157 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 627 [4000/8000 (50%)]\tBatch Loss: 0.146930\tLearning Rate (w_theta): 0.000500\t TIME:2387.2s\n",
      "\t\t\t\tDisc: 0.050007\t\tSpars: 0.096922\n",
      "\t TVw: -0.554157 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 627...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1444520748073015\n",
      "Average validation loss: 0.1441783586687586\n",
      "Training epoch 628...\n",
      "\n",
      "Train Epoch: 628 [0/8000 (0%)]\tBatch Loss: 0.144573\tLearning Rate (w_theta): 0.000500\t TIME:2389.4s\n",
      "\t\t\t\tDisc: 0.047158\t\tSpars: 0.097415\n",
      "\t TVw: -0.554157 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 628 [4000/8000 (50%)]\tBatch Loss: 0.142702\tLearning Rate (w_theta): 0.000500\t TIME:2390.8s\n",
      "\t\t\t\tDisc: 0.049123\t\tSpars: 0.093579\n",
      "\t TVw: -0.554156 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 628...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14443717346931845\n",
      "Average validation loss: 0.1441635280068346\n",
      "Training epoch 629...\n",
      "\n",
      "Train Epoch: 629 [0/8000 (0%)]\tBatch Loss: 0.144207\tLearning Rate (w_theta): 0.000500\t TIME:2393.2s\n",
      "\t\t\t\tDisc: 0.047851\t\tSpars: 0.096355\n",
      "\t TVw: -0.554156 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 629 [4000/8000 (50%)]\tBatch Loss: 0.144379\tLearning Rate (w_theta): 0.000500\t TIME:2394.7s\n",
      "\t\t\t\tDisc: 0.048965\t\tSpars: 0.095414\n",
      "\t TVw: -0.554156 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 629...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14442301849747197\n",
      "Average validation loss: 0.14414889752667748\n",
      "Training epoch 630...\n",
      "\n",
      "Train Epoch: 630 [0/8000 (0%)]\tBatch Loss: 0.142115\tLearning Rate (w_theta): 0.000500\t TIME:2396.9s\n",
      "\t\t\t\tDisc: 0.050686\t\tSpars: 0.091428\n",
      "\t TVw: -0.554156 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 630 [4000/8000 (50%)]\tBatch Loss: 0.140447\tLearning Rate (w_theta): 0.000500\t TIME:2398.4s\n",
      "\t\t\t\tDisc: 0.045282\t\tSpars: 0.095165\n",
      "\t TVw: -0.554156 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 630...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14440933855225077\n",
      "Average validation loss: 0.1441340842508342\n",
      "Training epoch 631...\n",
      "\n",
      "Train Epoch: 631 [0/8000 (0%)]\tBatch Loss: 0.148286\tLearning Rate (w_theta): 0.000500\t TIME:2402.0s\n",
      "\t\t\t\tDisc: 0.047093\t\tSpars: 0.101193\n",
      "\t TVw: -0.554155 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 631 [4000/8000 (50%)]\tBatch Loss: 0.145275\tLearning Rate (w_theta): 0.000500\t TIME:2403.4s\n",
      "\t\t\t\tDisc: 0.048600\t\tSpars: 0.096675\n",
      "\t TVw: -0.554155 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 631...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14439507932011134\n",
      "Average validation loss: 0.14411986844080416\n",
      "Training epoch 632...\n",
      "\n",
      "Train Epoch: 632 [0/8000 (0%)]\tBatch Loss: 0.140230\tLearning Rate (w_theta): 0.000500\t TIME:2405.6s\n",
      "\t\t\t\tDisc: 0.046306\t\tSpars: 0.093924\n",
      "\t TVw: -0.554155 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 632 [4000/8000 (50%)]\tBatch Loss: 0.142284\tLearning Rate (w_theta): 0.000500\t TIME:2407.1s\n",
      "\t\t\t\tDisc: 0.047980\t\tSpars: 0.094305\n",
      "\t TVw: -0.554155 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 632...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14438150703023492\n",
      "Average validation loss: 0.14410566795511015\n",
      "Training epoch 633...\n",
      "\n",
      "Train Epoch: 633 [0/8000 (0%)]\tBatch Loss: 0.147783\tLearning Rate (w_theta): 0.000500\t TIME:2409.3s\n",
      "\t\t\t\tDisc: 0.050457\t\tSpars: 0.097326\n",
      "\t TVw: -0.554154 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 633 [4000/8000 (50%)]\tBatch Loss: 0.146766\tLearning Rate (w_theta): 0.000500\t TIME:2410.8s\n",
      "\t\t\t\tDisc: 0.048172\t\tSpars: 0.098594\n",
      "\t TVw: -0.554154 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 633...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14436828264759585\n",
      "Average validation loss: 0.14409127460070853\n",
      "Training epoch 634...\n",
      "\n",
      "Train Epoch: 634 [0/8000 (0%)]\tBatch Loss: 0.146160\tLearning Rate (w_theta): 0.000500\t TIME:2413.0s\n",
      "\t\t\t\tDisc: 0.049070\t\tSpars: 0.097090\n",
      "\t TVw: -0.554154 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 634 [4000/8000 (50%)]\tBatch Loss: 0.142143\tLearning Rate (w_theta): 0.000500\t TIME:2414.5s\n",
      "\t\t\t\tDisc: 0.046798\t\tSpars: 0.095345\n",
      "\t TVw: -0.554154 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 634...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1443544121882734\n",
      "Average validation loss: 0.14407730608664632\n",
      "Training epoch 635...\n",
      "\n",
      "Train Epoch: 635 [0/8000 (0%)]\tBatch Loss: 0.143195\tLearning Rate (w_theta): 0.000500\t TIME:2416.7s\n",
      "\t\t\t\tDisc: 0.049691\t\tSpars: 0.093504\n",
      "\t TVw: -0.554153 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 635 [4000/8000 (50%)]\tBatch Loss: 0.142840\tLearning Rate (w_theta): 0.000500\t TIME:2418.1s\n",
      "\t\t\t\tDisc: 0.048175\t\tSpars: 0.094665\n",
      "\t TVw: -0.554153 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 635...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1443408646495774\n",
      "Average validation loss: 0.14406349546041314\n",
      "Training epoch 636...\n",
      "\n",
      "Train Epoch: 636 [0/8000 (0%)]\tBatch Loss: 0.146486\tLearning Rate (w_theta): 0.000500\t TIME:2420.3s\n",
      "\t\t\t\tDisc: 0.047915\t\tSpars: 0.098571\n",
      "\t TVw: -0.554153 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 636 [4000/8000 (50%)]\tBatch Loss: 0.145402\tLearning Rate (w_theta): 0.000500\t TIME:2421.8s\n",
      "\t\t\t\tDisc: 0.047182\t\tSpars: 0.098220\n",
      "\t TVw: -0.554153 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 636...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1443275482665961\n",
      "Average validation loss: 0.14404982148038803\n",
      "Training epoch 637...\n",
      "\n",
      "Train Epoch: 637 [0/8000 (0%)]\tBatch Loss: 0.140820\tLearning Rate (w_theta): 0.000500\t TIME:2424.0s\n",
      "\t\t\t\tDisc: 0.047212\t\tSpars: 0.093608\n",
      "\t TVw: -0.554152 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 637 [4000/8000 (50%)]\tBatch Loss: 0.146485\tLearning Rate (w_theta): 0.000500\t TIME:2425.4s\n",
      "\t\t\t\tDisc: 0.048869\t\tSpars: 0.097615\n",
      "\t TVw: -0.554152 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 637...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14431458754544327\n",
      "Average validation loss: 0.14403608769935058\n",
      "Training epoch 638...\n",
      "\n",
      "Train Epoch: 638 [0/8000 (0%)]\tBatch Loss: 0.144690\tLearning Rate (w_theta): 0.000500\t TIME:2427.7s\n",
      "\t\t\t\tDisc: 0.050444\t\tSpars: 0.094246\n",
      "\t TVw: -0.554152 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 638 [4000/8000 (50%)]\tBatch Loss: 0.147241\tLearning Rate (w_theta): 0.000500\t TIME:2429.1s\n",
      "\t\t\t\tDisc: 0.050011\t\tSpars: 0.097231\n",
      "\t TVw: -0.554152 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 638...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14430144513743962\n",
      "Average validation loss: 0.14402257963679033\n",
      "Training epoch 639...\n",
      "\n",
      "Train Epoch: 639 [0/8000 (0%)]\tBatch Loss: 0.143615\tLearning Rate (w_theta): 0.000500\t TIME:2431.5s\n",
      "\t\t\t\tDisc: 0.048217\t\tSpars: 0.095399\n",
      "\t TVw: -0.554151 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 639 [4000/8000 (50%)]\tBatch Loss: 0.145396\tLearning Rate (w_theta): 0.000500\t TIME:2433.0s\n",
      "\t\t\t\tDisc: 0.047412\t\tSpars: 0.097984\n",
      "\t TVw: -0.554151 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 639...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14428831587548085\n",
      "Average validation loss: 0.1440093437272855\n",
      "Training epoch 640...\n",
      "\n",
      "Train Epoch: 640 [0/8000 (0%)]\tBatch Loss: 0.146867\tLearning Rate (w_theta): 0.000500\t TIME:2435.2s\n",
      "\t\t\t\tDisc: 0.048546\t\tSpars: 0.098320\n",
      "\t TVw: -0.554151 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 640 [4000/8000 (50%)]\tBatch Loss: 0.141038\tLearning Rate (w_theta): 0.000500\t TIME:2436.6s\n",
      "\t\t\t\tDisc: 0.045498\t\tSpars: 0.095540\n",
      "\t TVw: -0.554151 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 640...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14427585092582618\n",
      "Average validation loss: 0.14399587952048395\n",
      "Training epoch 641...\n",
      "\n",
      "Train Epoch: 641 [0/8000 (0%)]\tBatch Loss: 0.139351\tLearning Rate (w_theta): 0.000500\t TIME:2440.0s\n",
      "\t\t\t\tDisc: 0.047953\t\tSpars: 0.091398\n",
      "\t TVw: -0.554151 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 641 [4000/8000 (50%)]\tBatch Loss: 0.143001\tLearning Rate (w_theta): 0.000500\t TIME:2441.5s\n",
      "\t\t\t\tDisc: 0.046640\t\tSpars: 0.096361\n",
      "\t TVw: -0.554150 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 641...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14426285313478845\n",
      "Average validation loss: 0.14398302209463637\n",
      "Training epoch 642...\n",
      "\n",
      "Train Epoch: 642 [0/8000 (0%)]\tBatch Loss: 0.145166\tLearning Rate (w_theta): 0.000500\t TIME:2443.9s\n",
      "\t\t\t\tDisc: 0.047116\t\tSpars: 0.098049\n",
      "\t TVw: -0.554150 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 642 [4000/8000 (50%)]\tBatch Loss: 0.144028\tLearning Rate (w_theta): 0.000500\t TIME:2445.3s\n",
      "\t\t\t\tDisc: 0.047881\t\tSpars: 0.096147\n",
      "\t TVw: -0.554150 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 642...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14425068880903874\n",
      "Average validation loss: 0.1439699619572526\n",
      "Training epoch 643...\n",
      "\n",
      "Train Epoch: 643 [0/8000 (0%)]\tBatch Loss: 0.143824\tLearning Rate (w_theta): 0.000500\t TIME:2447.5s\n",
      "\t\t\t\tDisc: 0.048274\t\tSpars: 0.095549\n",
      "\t TVw: -0.554150 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 643 [4000/8000 (50%)]\tBatch Loss: 0.143185\tLearning Rate (w_theta): 0.000500\t TIME:2449.0s\n",
      "\t\t\t\tDisc: 0.048033\t\tSpars: 0.095152\n",
      "\t TVw: -0.554149 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 643...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14423845828582937\n",
      "Average validation loss: 0.1439568790402312\n",
      "Training epoch 644...\n",
      "\n",
      "Train Epoch: 644 [0/8000 (0%)]\tBatch Loss: 0.147733\tLearning Rate (w_theta): 0.000500\t TIME:2451.2s\n",
      "\t\t\t\tDisc: 0.049433\t\tSpars: 0.098300\n",
      "\t TVw: -0.554149 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 644 [4000/8000 (50%)]\tBatch Loss: 0.140746\tLearning Rate (w_theta): 0.000500\t TIME:2452.7s\n",
      "\t\t\t\tDisc: 0.046553\t\tSpars: 0.094193\n",
      "\t TVw: -0.554149 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 644...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1442257597809028\n",
      "Average validation loss: 0.14394431460220564\n",
      "Training epoch 645...\n",
      "\n",
      "Train Epoch: 645 [0/8000 (0%)]\tBatch Loss: 0.141125\tLearning Rate (w_theta): 0.000500\t TIME:2454.9s\n",
      "\t\t\t\tDisc: 0.046428\t\tSpars: 0.094697\n",
      "\t TVw: -0.554149 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 645 [4000/8000 (50%)]\tBatch Loss: 0.145087\tLearning Rate (w_theta): 0.000500\t TIME:2456.3s\n",
      "\t\t\t\tDisc: 0.049537\t\tSpars: 0.095550\n",
      "\t TVw: -0.554148 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 645...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14421341182171823\n",
      "Average validation loss: 0.14393204958903272\n",
      "Training epoch 646...\n",
      "\n",
      "Train Epoch: 646 [0/8000 (0%)]\tBatch Loss: 0.138198\tLearning Rate (w_theta): 0.000500\t TIME:2458.6s\n",
      "\t\t\t\tDisc: 0.046480\t\tSpars: 0.091718\n",
      "\t TVw: -0.554148 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 646 [4000/8000 (50%)]\tBatch Loss: 0.142410\tLearning Rate (w_theta): 0.000500\t TIME:2460.1s\n",
      "\t\t\t\tDisc: 0.046415\t\tSpars: 0.095995\n",
      "\t TVw: -0.554148 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 646...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1442015787503333\n",
      "Average validation loss: 0.14391969372873867\n",
      "Training epoch 647...\n",
      "\n",
      "Train Epoch: 647 [0/8000 (0%)]\tBatch Loss: 0.142700\tLearning Rate (w_theta): 0.000500\t TIME:2462.3s\n",
      "\t\t\t\tDisc: 0.046265\t\tSpars: 0.096435\n",
      "\t TVw: -0.554148 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 647 [4000/8000 (50%)]\tBatch Loss: 0.146092\tLearning Rate (w_theta): 0.000500\t TIME:2463.7s\n",
      "\t\t\t\tDisc: 0.049300\t\tSpars: 0.096792\n",
      "\t TVw: -0.554147 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 647...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.144189654429009\n",
      "Average validation loss: 0.14390736219568243\n",
      "Training epoch 648...\n",
      "\n",
      "Train Epoch: 648 [0/8000 (0%)]\tBatch Loss: 0.144371\tLearning Rate (w_theta): 0.000500\t TIME:2465.9s\n",
      "\t\t\t\tDisc: 0.046500\t\tSpars: 0.097871\n",
      "\t TVw: -0.554147 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 648 [4000/8000 (50%)]\tBatch Loss: 0.145253\tLearning Rate (w_theta): 0.000500\t TIME:2467.4s\n",
      "\t\t\t\tDisc: 0.047611\t\tSpars: 0.097642\n",
      "\t TVw: -0.554147 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 648...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14417772665642445\n",
      "Average validation loss: 0.14389516528550006\n",
      "Training epoch 649...\n",
      "\n",
      "Train Epoch: 649 [0/8000 (0%)]\tBatch Loss: 0.146664\tLearning Rate (w_theta): 0.000500\t TIME:2469.6s\n",
      "\t\t\t\tDisc: 0.049064\t\tSpars: 0.097600\n",
      "\t TVw: -0.554147 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 649 [4000/8000 (50%)]\tBatch Loss: 0.142889\tLearning Rate (w_theta): 0.000500\t TIME:2471.0s\n",
      "\t\t\t\tDisc: 0.046176\t\tSpars: 0.096713\n",
      "\t TVw: -0.554146 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 649...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14416585716145405\n",
      "Average validation loss: 0.14388318271751227\n",
      "Training epoch 650...\n",
      "\n",
      "Train Epoch: 650 [0/8000 (0%)]\tBatch Loss: 0.147423\tLearning Rate (w_theta): 0.000500\t TIME:2473.4s\n",
      "\t\t\t\tDisc: 0.047385\t\tSpars: 0.100038\n",
      "\t TVw: -0.554146 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 650 [4000/8000 (50%)]\tBatch Loss: 0.143700\tLearning Rate (w_theta): 0.000500\t TIME:2474.9s\n",
      "\t\t\t\tDisc: 0.048068\t\tSpars: 0.095632\n",
      "\t TVw: -0.554146 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 650...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14415446849382482\n",
      "Average validation loss: 0.14387106607115632\n",
      "Training epoch 651...\n",
      "\n",
      "Train Epoch: 651 [0/8000 (0%)]\tBatch Loss: 0.145796\tLearning Rate (w_theta): 0.000500\t TIME:2478.3s\n",
      "\t\t\t\tDisc: 0.049159\t\tSpars: 0.096636\n",
      "\t TVw: -0.554146 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 651 [4000/8000 (50%)]\tBatch Loss: 0.139813\tLearning Rate (w_theta): 0.000500\t TIME:2479.7s\n",
      "\t\t\t\tDisc: 0.048134\t\tSpars: 0.091679\n",
      "\t TVw: -0.554146 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 651...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14414266149679933\n",
      "Average validation loss: 0.14385927322554465\n",
      "Training epoch 652...\n",
      "\n",
      "Train Epoch: 652 [0/8000 (0%)]\tBatch Loss: 0.143693\tLearning Rate (w_theta): 0.000500\t TIME:2481.9s\n",
      "\t\t\t\tDisc: 0.047237\t\tSpars: 0.096456\n",
      "\t TVw: -0.554145 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 652 [4000/8000 (50%)]\tBatch Loss: 0.145967\tLearning Rate (w_theta): 0.000500\t TIME:2483.4s\n",
      "\t\t\t\tDisc: 0.049482\t\tSpars: 0.096484\n",
      "\t TVw: -0.554145 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 652...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14413122654883068\n",
      "Average validation loss: 0.14384759462435914\n",
      "Training epoch 653...\n",
      "\n",
      "Train Epoch: 653 [0/8000 (0%)]\tBatch Loss: 0.142804\tLearning Rate (w_theta): 0.000500\t TIME:2485.7s\n",
      "\t\t\t\tDisc: 0.047568\t\tSpars: 0.095236\n",
      "\t TVw: -0.554145 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 653 [4000/8000 (50%)]\tBatch Loss: 0.141149\tLearning Rate (w_theta): 0.000500\t TIME:2487.2s\n",
      "\t\t\t\tDisc: 0.047010\t\tSpars: 0.094138\n",
      "\t TVw: -0.554145 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 653...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14411976057530562\n",
      "Average validation loss: 0.14383615484013645\n",
      "Training epoch 654...\n",
      "\n",
      "Train Epoch: 654 [0/8000 (0%)]\tBatch Loss: 0.143707\tLearning Rate (w_theta): 0.000500\t TIME:2489.4s\n",
      "\t\t\t\tDisc: 0.049412\t\tSpars: 0.094295\n",
      "\t TVw: -0.554144 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 654 [4000/8000 (50%)]\tBatch Loss: 0.144908\tLearning Rate (w_theta): 0.000500\t TIME:2490.9s\n",
      "\t\t\t\tDisc: 0.048616\t\tSpars: 0.096292\n",
      "\t TVw: -0.554144 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 654...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1441090226494376\n",
      "Average validation loss: 0.143824348859937\n",
      "Training epoch 655...\n",
      "\n",
      "Train Epoch: 655 [0/8000 (0%)]\tBatch Loss: 0.139686\tLearning Rate (w_theta): 0.000500\t TIME:2493.1s\n",
      "\t\t\t\tDisc: 0.045608\t\tSpars: 0.094078\n",
      "\t TVw: -0.554144 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 655 [4000/8000 (50%)]\tBatch Loss: 0.142880\tLearning Rate (w_theta): 0.000500\t TIME:2494.6s\n",
      "\t\t\t\tDisc: 0.048130\t\tSpars: 0.094750\n",
      "\t TVw: -0.554144 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 655...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14409741014716035\n",
      "Average validation loss: 0.14381310252961707\n",
      "Training epoch 656...\n",
      "\n",
      "Train Epoch: 656 [0/8000 (0%)]\tBatch Loss: 0.141856\tLearning Rate (w_theta): 0.000500\t TIME:2496.8s\n",
      "\t\t\t\tDisc: 0.047175\t\tSpars: 0.094681\n",
      "\t TVw: -0.554143 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 656 [4000/8000 (50%)]\tBatch Loss: 0.145522\tLearning Rate (w_theta): 0.000500\t TIME:2498.3s\n",
      "\t\t\t\tDisc: 0.047919\t\tSpars: 0.097603\n",
      "\t TVw: -0.554143 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 656...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14408668465355184\n",
      "Average validation loss: 0.14380161678925546\n",
      "Training epoch 657...\n",
      "\n",
      "Train Epoch: 657 [0/8000 (0%)]\tBatch Loss: 0.141464\tLearning Rate (w_theta): 0.000500\t TIME:2500.4s\n",
      "\t\t\t\tDisc: 0.046737\t\tSpars: 0.094727\n",
      "\t TVw: -0.554143 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 657 [4000/8000 (50%)]\tBatch Loss: 0.141954\tLearning Rate (w_theta): 0.000500\t TIME:2501.9s\n",
      "\t\t\t\tDisc: 0.048436\t\tSpars: 0.093517\n",
      "\t TVw: -0.554143 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 657...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1440755345660731\n",
      "Average validation loss: 0.1437904172417535\n",
      "Training epoch 658...\n",
      "\n",
      "Train Epoch: 658 [0/8000 (0%)]\tBatch Loss: 0.141280\tLearning Rate (w_theta): 0.000500\t TIME:2504.1s\n",
      "\t\t\t\tDisc: 0.047616\t\tSpars: 0.093664\n",
      "\t TVw: -0.554142 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 658 [4000/8000 (50%)]\tBatch Loss: 0.143087\tLearning Rate (w_theta): 0.000500\t TIME:2505.5s\n",
      "\t\t\t\tDisc: 0.048318\t\tSpars: 0.094768\n",
      "\t TVw: -0.554142 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 658...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14406473847605739\n",
      "Average validation loss: 0.1437792566515127\n",
      "Training epoch 659...\n",
      "\n",
      "Train Epoch: 659 [0/8000 (0%)]\tBatch Loss: 0.148217\tLearning Rate (w_theta): 0.000500\t TIME:2507.8s\n",
      "\t\t\t\tDisc: 0.050540\t\tSpars: 0.097677\n",
      "\t TVw: -0.554142 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 659 [4000/8000 (50%)]\tBatch Loss: 0.144003\tLearning Rate (w_theta): 0.000500\t TIME:2509.2s\n",
      "\t\t\t\tDisc: 0.050035\t\tSpars: 0.093968\n",
      "\t TVw: -0.554142 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 659...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14405372150994677\n",
      "Average validation loss: 0.14376845491918375\n",
      "Training epoch 660...\n",
      "\n",
      "Train Epoch: 660 [0/8000 (0%)]\tBatch Loss: 0.142742\tLearning Rate (w_theta): 0.000500\t TIME:2511.4s\n",
      "\t\t\t\tDisc: 0.046653\t\tSpars: 0.096089\n",
      "\t TVw: -0.554141 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 660 [4000/8000 (50%)]\tBatch Loss: 0.143510\tLearning Rate (w_theta): 0.000500\t TIME:2512.9s\n",
      "\t\t\t\tDisc: 0.048083\t\tSpars: 0.095427\n",
      "\t TVw: -0.554141 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 660...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14404342221643937\n",
      "Average validation loss: 0.14375744072528232\n",
      "Training epoch 661...\n",
      "\n",
      "Train Epoch: 661 [0/8000 (0%)]\tBatch Loss: 0.143529\tLearning Rate (w_theta): 0.000500\t TIME:2516.4s\n",
      "\t\t\t\tDisc: 0.048326\t\tSpars: 0.095203\n",
      "\t TVw: -0.554141 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 661 [4000/8000 (50%)]\tBatch Loss: 0.144830\tLearning Rate (w_theta): 0.000500\t TIME:2517.9s\n",
      "\t\t\t\tDisc: 0.047463\t\tSpars: 0.097367\n",
      "\t TVw: -0.554141 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 661...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14403309778114162\n",
      "Average validation loss: 0.14374631265590398\n",
      "Training epoch 662...\n",
      "\n",
      "Train Epoch: 662 [0/8000 (0%)]\tBatch Loss: 0.141435\tLearning Rate (w_theta): 0.000500\t TIME:2520.0s\n",
      "\t\t\t\tDisc: 0.047303\t\tSpars: 0.094132\n",
      "\t TVw: -0.554141 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 662 [4000/8000 (50%)]\tBatch Loss: 0.143747\tLearning Rate (w_theta): 0.000500\t TIME:2521.5s\n",
      "\t\t\t\tDisc: 0.048549\t\tSpars: 0.095199\n",
      "\t TVw: -0.554140 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 662...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14402220228359944\n",
      "Average validation loss: 0.14373562667161593\n",
      "Training epoch 663...\n",
      "\n",
      "Train Epoch: 663 [0/8000 (0%)]\tBatch Loss: 0.145907\tLearning Rate (w_theta): 0.000500\t TIME:2523.8s\n",
      "\t\t\t\tDisc: 0.048754\t\tSpars: 0.097153\n",
      "\t TVw: -0.554140 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 663 [4000/8000 (50%)]\tBatch Loss: 0.147444\tLearning Rate (w_theta): 0.000500\t TIME:2525.2s\n",
      "\t\t\t\tDisc: 0.048659\t\tSpars: 0.098785\n",
      "\t TVw: -0.554140 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 663...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14401192572088475\n",
      "Average validation loss: 0.14372496188776962\n",
      "Training epoch 664...\n",
      "\n",
      "Train Epoch: 664 [0/8000 (0%)]\tBatch Loss: 0.147904\tLearning Rate (w_theta): 0.000500\t TIME:2527.6s\n",
      "\t\t\t\tDisc: 0.049933\t\tSpars: 0.097971\n",
      "\t TVw: -0.554140 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 664 [4000/8000 (50%)]\tBatch Loss: 0.143821\tLearning Rate (w_theta): 0.000500\t TIME:2529.1s\n",
      "\t\t\t\tDisc: 0.047244\t\tSpars: 0.096578\n",
      "\t TVw: -0.554139 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 664...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1440017416265084\n",
      "Average validation loss: 0.1437143209993171\n",
      "Training epoch 665...\n",
      "\n",
      "Train Epoch: 665 [0/8000 (0%)]\tBatch Loss: 0.143966\tLearning Rate (w_theta): 0.000500\t TIME:2531.2s\n",
      "\t\t\t\tDisc: 0.048876\t\tSpars: 0.095090\n",
      "\t TVw: -0.554139 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 665 [4000/8000 (50%)]\tBatch Loss: 0.146441\tLearning Rate (w_theta): 0.000500\t TIME:2532.7s\n",
      "\t\t\t\tDisc: 0.049650\t\tSpars: 0.096791\n",
      "\t TVw: -0.554139 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 665...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14399125966444326\n",
      "Average validation loss: 0.1437040100543477\n",
      "Training epoch 666...\n",
      "\n",
      "Train Epoch: 666 [0/8000 (0%)]\tBatch Loss: 0.142587\tLearning Rate (w_theta): 0.000500\t TIME:2534.9s\n",
      "\t\t\t\tDisc: 0.047715\t\tSpars: 0.094873\n",
      "\t TVw: -0.554139 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 666 [4000/8000 (50%)]\tBatch Loss: 0.140588\tLearning Rate (w_theta): 0.000500\t TIME:2536.4s\n",
      "\t\t\t\tDisc: 0.046438\t\tSpars: 0.094150\n",
      "\t TVw: -0.554138 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 666...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14398136464940284\n",
      "Average validation loss: 0.14369354233263504\n",
      "Training epoch 667...\n",
      "\n",
      "Train Epoch: 667 [0/8000 (0%)]\tBatch Loss: 0.140501\tLearning Rate (w_theta): 0.000500\t TIME:2538.6s\n",
      "\t\t\t\tDisc: 0.046104\t\tSpars: 0.094396\n",
      "\t TVw: -0.554138 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 667 [4000/8000 (50%)]\tBatch Loss: 0.141380\tLearning Rate (w_theta): 0.000500\t TIME:2540.1s\n",
      "\t\t\t\tDisc: 0.048724\t\tSpars: 0.092657\n",
      "\t TVw: -0.554138 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 667...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14397106784385824\n",
      "Average validation loss: 0.143683389920586\n",
      "Training epoch 668...\n",
      "\n",
      "Train Epoch: 668 [0/8000 (0%)]\tBatch Loss: 0.139267\tLearning Rate (w_theta): 0.000500\t TIME:2542.3s\n",
      "\t\t\t\tDisc: 0.045304\t\tSpars: 0.093963\n",
      "\t TVw: -0.554138 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 668 [4000/8000 (50%)]\tBatch Loss: 0.146841\tLearning Rate (w_theta): 0.000500\t TIME:2543.8s\n",
      "\t\t\t\tDisc: 0.048308\t\tSpars: 0.098532\n",
      "\t TVw: -0.554137 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 668...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.143961147409576\n",
      "Average validation loss: 0.1436732919155552\n",
      "Training epoch 669...\n",
      "\n",
      "Train Epoch: 669 [0/8000 (0%)]\tBatch Loss: 0.146505\tLearning Rate (w_theta): 0.000500\t TIME:2546.0s\n",
      "\t\t\t\tDisc: 0.047826\t\tSpars: 0.098679\n",
      "\t TVw: -0.554137 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 669 [4000/8000 (50%)]\tBatch Loss: 0.143991\tLearning Rate (w_theta): 0.000500\t TIME:2547.4s\n",
      "\t\t\t\tDisc: 0.049552\t\tSpars: 0.094439\n",
      "\t TVw: -0.554137 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 669...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14395140329230782\n",
      "Average validation loss: 0.14366321078433097\n",
      "Training epoch 670...\n",
      "\n",
      "Train Epoch: 670 [0/8000 (0%)]\tBatch Loss: 0.143921\tLearning Rate (w_theta): 0.000500\t TIME:2549.7s\n",
      "\t\t\t\tDisc: 0.046561\t\tSpars: 0.097360\n",
      "\t TVw: -0.554137 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 670 [4000/8000 (50%)]\tBatch Loss: 0.140467\tLearning Rate (w_theta): 0.000500\t TIME:2551.2s\n",
      "\t\t\t\tDisc: 0.046456\t\tSpars: 0.094011\n",
      "\t TVw: -0.554136 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 670...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14394150013542742\n",
      "Average validation loss: 0.14365335027662562\n",
      "Training epoch 671...\n",
      "\n",
      "Train Epoch: 671 [0/8000 (0%)]\tBatch Loss: 0.141697\tLearning Rate (w_theta): 0.000500\t TIME:2555.1s\n",
      "\t\t\t\tDisc: 0.047547\t\tSpars: 0.094150\n",
      "\t TVw: -0.554136 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 671 [4000/8000 (50%)]\tBatch Loss: 0.141968\tLearning Rate (w_theta): 0.000500\t TIME:2556.6s\n",
      "\t\t\t\tDisc: 0.047621\t\tSpars: 0.094347\n",
      "\t TVw: -0.554136 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 671...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14393184755435756\n",
      "Average validation loss: 0.14364355520818362\n",
      "Training epoch 672...\n",
      "\n",
      "Train Epoch: 672 [0/8000 (0%)]\tBatch Loss: 0.148560\tLearning Rate (w_theta): 0.000500\t TIME:2558.8s\n",
      "\t\t\t\tDisc: 0.049598\t\tSpars: 0.098962\n",
      "\t TVw: -0.554136 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 672 [4000/8000 (50%)]\tBatch Loss: 0.142181\tLearning Rate (w_theta): 0.000500\t TIME:2560.3s\n",
      "\t\t\t\tDisc: 0.048570\t\tSpars: 0.093611\n",
      "\t TVw: -0.554136 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 672...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14392229504439344\n",
      "Average validation loss: 0.1436337597429114\n",
      "Training epoch 673...\n",
      "\n",
      "Train Epoch: 673 [0/8000 (0%)]\tBatch Loss: 0.147276\tLearning Rate (w_theta): 0.000500\t TIME:2562.6s\n",
      "\t\t\t\tDisc: 0.047174\t\tSpars: 0.100102\n",
      "\t TVw: -0.554135 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 673 [4000/8000 (50%)]\tBatch Loss: 0.139334\tLearning Rate (w_theta): 0.000500\t TIME:2564.0s\n",
      "\t\t\t\tDisc: 0.045056\t\tSpars: 0.094278\n",
      "\t TVw: -0.554135 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 673...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14391257144031755\n",
      "Average validation loss: 0.14362429666850612\n",
      "Training epoch 674...\n",
      "\n",
      "Train Epoch: 674 [0/8000 (0%)]\tBatch Loss: 0.141475\tLearning Rate (w_theta): 0.000500\t TIME:2566.5s\n",
      "\t\t\t\tDisc: 0.047610\t\tSpars: 0.093865\n",
      "\t TVw: -0.554135 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 674 [4000/8000 (50%)]\tBatch Loss: 0.144763\tLearning Rate (w_theta): 0.000500\t TIME:2568.0s\n",
      "\t\t\t\tDisc: 0.049233\t\tSpars: 0.095530\n",
      "\t TVw: -0.554135 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 674...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1439033277070686\n",
      "Average validation loss: 0.14361473419709786\n",
      "Training epoch 675...\n",
      "\n",
      "Train Epoch: 675 [0/8000 (0%)]\tBatch Loss: 0.147556\tLearning Rate (w_theta): 0.000500\t TIME:2570.2s\n",
      "\t\t\t\tDisc: 0.049064\t\tSpars: 0.098492\n",
      "\t TVw: -0.554134 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 675 [4000/8000 (50%)]\tBatch Loss: 0.145411\tLearning Rate (w_theta): 0.000500\t TIME:2571.7s\n",
      "\t\t\t\tDisc: 0.048970\t\tSpars: 0.096442\n",
      "\t TVw: -0.554134 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 675...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14389403671400622\n",
      "Average validation loss: 0.14360516837698134\n",
      "Training epoch 676...\n",
      "\n",
      "Train Epoch: 676 [0/8000 (0%)]\tBatch Loss: 0.145602\tLearning Rate (w_theta): 0.000500\t TIME:2574.0s\n",
      "\t\t\t\tDisc: 0.047718\t\tSpars: 0.097884\n",
      "\t TVw: -0.554134 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 676 [4000/8000 (50%)]\tBatch Loss: 0.142791\tLearning Rate (w_theta): 0.000500\t TIME:2575.5s\n",
      "\t\t\t\tDisc: 0.047532\t\tSpars: 0.095259\n",
      "\t TVw: -0.554134 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 676...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14388463938264687\n",
      "Average validation loss: 0.14359577516708905\n",
      "Training epoch 677...\n",
      "\n",
      "Train Epoch: 677 [0/8000 (0%)]\tBatch Loss: 0.141724\tLearning Rate (w_theta): 0.000500\t TIME:2577.7s\n",
      "\t\t\t\tDisc: 0.048449\t\tSpars: 0.093275\n",
      "\t TVw: -0.554133 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 677 [4000/8000 (50%)]\tBatch Loss: 0.144632\tLearning Rate (w_theta): 0.000500\t TIME:2579.2s\n",
      "\t\t\t\tDisc: 0.048350\t\tSpars: 0.096282\n",
      "\t TVw: -0.554133 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 677...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14387548414314366\n",
      "Average validation loss: 0.14358632340543148\n",
      "Training epoch 678...\n",
      "\n",
      "Train Epoch: 678 [0/8000 (0%)]\tBatch Loss: 0.145279\tLearning Rate (w_theta): 0.000500\t TIME:2581.4s\n",
      "\t\t\t\tDisc: 0.050425\t\tSpars: 0.094854\n",
      "\t TVw: -0.554133 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 678 [4000/8000 (50%)]\tBatch Loss: 0.142790\tLearning Rate (w_theta): 0.000500\t TIME:2582.9s\n",
      "\t\t\t\tDisc: 0.047273\t\tSpars: 0.095517\n",
      "\t TVw: -0.554133 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 678...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14386656727730887\n",
      "Average validation loss: 0.14357663245474842\n",
      "Training epoch 679...\n",
      "\n",
      "Train Epoch: 679 [0/8000 (0%)]\tBatch Loss: 0.146257\tLearning Rate (w_theta): 0.000500\t TIME:2585.1s\n",
      "\t\t\t\tDisc: 0.047806\t\tSpars: 0.098451\n",
      "\t TVw: -0.554132 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 679 [4000/8000 (50%)]\tBatch Loss: 0.144142\tLearning Rate (w_theta): 0.000500\t TIME:2586.6s\n",
      "\t\t\t\tDisc: 0.049817\t\tSpars: 0.094325\n",
      "\t TVw: -0.554132 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 679...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14385719558436014\n",
      "Average validation loss: 0.14356722300666064\n",
      "Training epoch 680...\n",
      "\n",
      "Train Epoch: 680 [0/8000 (0%)]\tBatch Loss: 0.142587\tLearning Rate (w_theta): 0.000500\t TIME:2588.9s\n",
      "\t\t\t\tDisc: 0.047206\t\tSpars: 0.095381\n",
      "\t TVw: -0.554132 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 680 [4000/8000 (50%)]\tBatch Loss: 0.148529\tLearning Rate (w_theta): 0.000500\t TIME:2590.3s\n",
      "\t\t\t\tDisc: 0.050271\t\tSpars: 0.098259\n",
      "\t TVw: -0.554132 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 680...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1438482590027746\n",
      "Average validation loss: 0.1435577820780449\n",
      "Training epoch 681...\n",
      "\n",
      "Train Epoch: 681 [0/8000 (0%)]\tBatch Loss: 0.141424\tLearning Rate (w_theta): 0.000500\t TIME:2593.9s\n",
      "\t\t\t\tDisc: 0.045308\t\tSpars: 0.096116\n",
      "\t TVw: -0.554131 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 681 [4000/8000 (50%)]\tBatch Loss: 0.148404\tLearning Rate (w_theta): 0.000500\t TIME:2595.3s\n",
      "\t\t\t\tDisc: 0.047694\t\tSpars: 0.100710\n",
      "\t TVw: -0.554131 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 681...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1438392469113553\n",
      "Average validation loss: 0.14354842376645233\n",
      "Training epoch 682...\n",
      "\n",
      "Train Epoch: 682 [0/8000 (0%)]\tBatch Loss: 0.142630\tLearning Rate (w_theta): 0.000500\t TIME:2597.5s\n",
      "\t\t\t\tDisc: 0.047679\t\tSpars: 0.094952\n",
      "\t TVw: -0.554131 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 682 [4000/8000 (50%)]\tBatch Loss: 0.139700\tLearning Rate (w_theta): 0.000500\t TIME:2599.0s\n",
      "\t\t\t\tDisc: 0.046821\t\tSpars: 0.092879\n",
      "\t TVw: -0.554131 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 682...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14383003988621415\n",
      "Average validation loss: 0.14353941365449316\n",
      "Training epoch 683...\n",
      "\n",
      "Train Epoch: 683 [0/8000 (0%)]\tBatch Loss: 0.141275\tLearning Rate (w_theta): 0.000500\t TIME:2601.2s\n",
      "\t\t\t\tDisc: 0.046577\t\tSpars: 0.094698\n",
      "\t TVw: -0.554130 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 683 [4000/8000 (50%)]\tBatch Loss: 0.143310\tLearning Rate (w_theta): 0.000500\t TIME:2602.7s\n",
      "\t\t\t\tDisc: 0.047529\t\tSpars: 0.095781\n",
      "\t TVw: -0.554130 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 683...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1438213737157806\n",
      "Average validation loss: 0.1435302609338004\n",
      "Training epoch 684...\n",
      "\n",
      "Train Epoch: 684 [0/8000 (0%)]\tBatch Loss: 0.140992\tLearning Rate (w_theta): 0.000500\t TIME:2605.0s\n",
      "\t\t\t\tDisc: 0.046883\t\tSpars: 0.094109\n",
      "\t TVw: -0.554130 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 684 [4000/8000 (50%)]\tBatch Loss: 0.142831\tLearning Rate (w_theta): 0.000500\t TIME:2606.4s\n",
      "\t\t\t\tDisc: 0.046890\t\tSpars: 0.095940\n",
      "\t TVw: -0.554130 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 684...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1438127175730071\n",
      "Average validation loss: 0.14352099226447332\n",
      "Training epoch 685...\n",
      "\n",
      "Train Epoch: 685 [0/8000 (0%)]\tBatch Loss: 0.145858\tLearning Rate (w_theta): 0.000500\t TIME:2608.6s\n",
      "\t\t\t\tDisc: 0.047789\t\tSpars: 0.098069\n",
      "\t TVw: -0.554130 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 685 [4000/8000 (50%)]\tBatch Loss: 0.142817\tLearning Rate (w_theta): 0.000500\t TIME:2610.1s\n",
      "\t\t\t\tDisc: 0.048207\t\tSpars: 0.094610\n",
      "\t TVw: -0.554129 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 685...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14380377630293434\n",
      "Average validation loss: 0.14351177648905233\n",
      "Training epoch 686...\n",
      "\n",
      "Train Epoch: 686 [0/8000 (0%)]\tBatch Loss: 0.142424\tLearning Rate (w_theta): 0.000500\t TIME:2612.3s\n",
      "\t\t\t\tDisc: 0.047575\t\tSpars: 0.094849\n",
      "\t TVw: -0.554129 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 686 [4000/8000 (50%)]\tBatch Loss: 0.142778\tLearning Rate (w_theta): 0.000500\t TIME:2613.8s\n",
      "\t\t\t\tDisc: 0.047786\t\tSpars: 0.094993\n",
      "\t TVw: -0.554129 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 686...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14379498563098864\n",
      "Average validation loss: 0.1435027090456059\n",
      "Training epoch 687...\n",
      "\n",
      "Train Epoch: 687 [0/8000 (0%)]\tBatch Loss: 0.146589\tLearning Rate (w_theta): 0.000500\t TIME:2616.2s\n",
      "\t\t\t\tDisc: 0.049103\t\tSpars: 0.097486\n",
      "\t TVw: -0.554129 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 687 [4000/8000 (50%)]\tBatch Loss: 0.140878\tLearning Rate (w_theta): 0.000500\t TIME:2617.7s\n",
      "\t\t\t\tDisc: 0.046957\t\tSpars: 0.093921\n",
      "\t TVw: -0.554128 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 687...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14378637747169543\n",
      "Average validation loss: 0.1434937323487808\n",
      "Training epoch 688...\n",
      "\n",
      "Train Epoch: 688 [0/8000 (0%)]\tBatch Loss: 0.143208\tLearning Rate (w_theta): 0.000500\t TIME:2620.0s\n",
      "\t\t\t\tDisc: 0.046792\t\tSpars: 0.096416\n",
      "\t TVw: -0.554128 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 688 [4000/8000 (50%)]\tBatch Loss: 0.144470\tLearning Rate (w_theta): 0.000500\t TIME:2621.4s\n",
      "\t\t\t\tDisc: 0.048845\t\tSpars: 0.095624\n",
      "\t TVw: -0.554128 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 688...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1437779830648627\n",
      "Average validation loss: 0.14348466638307433\n",
      "Training epoch 689...\n",
      "\n",
      "Train Epoch: 689 [0/8000 (0%)]\tBatch Loss: 0.144535\tLearning Rate (w_theta): 0.000500\t TIME:2623.6s\n",
      "\t\t\t\tDisc: 0.046808\t\tSpars: 0.097726\n",
      "\t TVw: -0.554128 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 689 [4000/8000 (50%)]\tBatch Loss: 0.140117\tLearning Rate (w_theta): 0.000500\t TIME:2625.1s\n",
      "\t\t\t\tDisc: 0.046555\t\tSpars: 0.093562\n",
      "\t TVw: -0.554127 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 689...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1437694231309722\n",
      "Average validation loss: 0.14347571628135045\n",
      "Training epoch 690...\n",
      "\n",
      "Train Epoch: 690 [0/8000 (0%)]\tBatch Loss: 0.140875\tLearning Rate (w_theta): 0.000500\t TIME:2627.3s\n",
      "\t\t\t\tDisc: 0.047405\t\tSpars: 0.093470\n",
      "\t TVw: -0.554127 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 690 [4000/8000 (50%)]\tBatch Loss: 0.144602\tLearning Rate (w_theta): 0.000500\t TIME:2628.8s\n",
      "\t\t\t\tDisc: 0.049314\t\tSpars: 0.095288\n",
      "\t TVw: -0.554127 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 690...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14376084982271584\n",
      "Average validation loss: 0.14346694112995156\n",
      "Training epoch 691...\n",
      "\n",
      "Train Epoch: 691 [0/8000 (0%)]\tBatch Loss: 0.141228\tLearning Rate (w_theta): 0.000500\t TIME:2632.3s\n",
      "\t\t\t\tDisc: 0.047320\t\tSpars: 0.093908\n",
      "\t TVw: -0.554127 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 691 [4000/8000 (50%)]\tBatch Loss: 0.142498\tLearning Rate (w_theta): 0.000500\t TIME:2633.8s\n",
      "\t\t\t\tDisc: 0.047986\t\tSpars: 0.094512\n",
      "\t TVw: -0.554126 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 691...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14375255171012657\n",
      "Average validation loss: 0.1434581189594179\n",
      "Training epoch 692...\n",
      "\n",
      "Train Epoch: 692 [0/8000 (0%)]\tBatch Loss: 0.145283\tLearning Rate (w_theta): 0.000500\t TIME:2636.0s\n",
      "\t\t\t\tDisc: 0.048667\t\tSpars: 0.096616\n",
      "\t TVw: -0.554126 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 692 [4000/8000 (50%)]\tBatch Loss: 0.139379\tLearning Rate (w_theta): 0.000500\t TIME:2637.5s\n",
      "\t\t\t\tDisc: 0.046884\t\tSpars: 0.092495\n",
      "\t TVw: -0.554126 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 692...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14374412243186374\n",
      "Average validation loss: 0.14344944774336127\n",
      "Training epoch 693...\n",
      "\n",
      "Train Epoch: 693 [0/8000 (0%)]\tBatch Loss: 0.144945\tLearning Rate (w_theta): 0.000500\t TIME:2639.7s\n",
      "\t\t\t\tDisc: 0.047476\t\tSpars: 0.097469\n",
      "\t TVw: -0.554126 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 693 [4000/8000 (50%)]\tBatch Loss: 0.145875\tLearning Rate (w_theta): 0.000500\t TIME:2641.2s\n",
      "\t\t\t\tDisc: 0.047407\t\tSpars: 0.098467\n",
      "\t TVw: -0.554125 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 693...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1437358982380898\n",
      "Average validation loss: 0.14344074715834532\n",
      "Training epoch 694...\n",
      "\n",
      "Train Epoch: 694 [0/8000 (0%)]\tBatch Loss: 0.143383\tLearning Rate (w_theta): 0.000500\t TIME:2643.4s\n",
      "\t\t\t\tDisc: 0.047233\t\tSpars: 0.096151\n",
      "\t TVw: -0.554125 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 694 [4000/8000 (50%)]\tBatch Loss: 0.141412\tLearning Rate (w_theta): 0.000500\t TIME:2644.8s\n",
      "\t\t\t\tDisc: 0.049399\t\tSpars: 0.092013\n",
      "\t TVw: -0.554125 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 694...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.143727677879933\n",
      "Average validation loss: 0.14343210986588453\n",
      "Training epoch 695...\n",
      "\n",
      "Train Epoch: 695 [0/8000 (0%)]\tBatch Loss: 0.141833\tLearning Rate (w_theta): 0.000500\t TIME:2647.0s\n",
      "\t\t\t\tDisc: 0.045271\t\tSpars: 0.096562\n",
      "\t TVw: -0.554125 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 695 [4000/8000 (50%)]\tBatch Loss: 0.144061\tLearning Rate (w_theta): 0.000500\t TIME:2648.5s\n",
      "\t\t\t\tDisc: 0.047049\t\tSpars: 0.097012\n",
      "\t TVw: -0.554125 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 695...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14371939149341026\n",
      "Average validation loss: 0.143423684917532\n",
      "Training epoch 696...\n",
      "\n",
      "Train Epoch: 696 [0/8000 (0%)]\tBatch Loss: 0.140307\tLearning Rate (w_theta): 0.000500\t TIME:2650.7s\n",
      "\t\t\t\tDisc: 0.045032\t\tSpars: 0.095275\n",
      "\t TVw: -0.554124 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 696 [4000/8000 (50%)]\tBatch Loss: 0.140468\tLearning Rate (w_theta): 0.000500\t TIME:2652.2s\n",
      "\t\t\t\tDisc: 0.047178\t\tSpars: 0.093290\n",
      "\t TVw: -0.554124 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 696...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14371149717749448\n",
      "Average validation loss: 0.1434151182238242\n",
      "Training epoch 697...\n",
      "\n",
      "Train Epoch: 697 [0/8000 (0%)]\tBatch Loss: 0.141839\tLearning Rate (w_theta): 0.000500\t TIME:2654.4s\n",
      "\t\t\t\tDisc: 0.046856\t\tSpars: 0.094983\n",
      "\t TVw: -0.554124 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 697 [4000/8000 (50%)]\tBatch Loss: 0.141730\tLearning Rate (w_theta): 0.000500\t TIME:2655.9s\n",
      "\t\t\t\tDisc: 0.047568\t\tSpars: 0.094162\n",
      "\t TVw: -0.554124 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 697...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14370338586544879\n",
      "Average validation loss: 0.14340664530227776\n",
      "Training epoch 698...\n",
      "\n",
      "Train Epoch: 698 [0/8000 (0%)]\tBatch Loss: 0.141373\tLearning Rate (w_theta): 0.000500\t TIME:2658.1s\n",
      "\t\t\t\tDisc: 0.047204\t\tSpars: 0.094169\n",
      "\t TVw: -0.554123 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 698 [4000/8000 (50%)]\tBatch Loss: 0.140911\tLearning Rate (w_theta): 0.000500\t TIME:2659.6s\n",
      "\t\t\t\tDisc: 0.044470\t\tSpars: 0.096440\n",
      "\t TVw: -0.554123 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 698...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14369517842929805\n",
      "Average validation loss: 0.14339840464030834\n",
      "Training epoch 699...\n",
      "\n",
      "Train Epoch: 699 [0/8000 (0%)]\tBatch Loss: 0.147340\tLearning Rate (w_theta): 0.000500\t TIME:2662.0s\n",
      "\t\t\t\tDisc: 0.048797\t\tSpars: 0.098543\n",
      "\t TVw: -0.554123 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 699 [4000/8000 (50%)]\tBatch Loss: 0.139056\tLearning Rate (w_theta): 0.000500\t TIME:2663.4s\n",
      "\t\t\t\tDisc: 0.046832\t\tSpars: 0.092224\n",
      "\t TVw: -0.554123 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 699...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14368734987781046\n",
      "Average validation loss: 0.14339007129172487\n",
      "Training epoch 700...\n",
      "\n",
      "Train Epoch: 700 [0/8000 (0%)]\tBatch Loss: 0.147712\tLearning Rate (w_theta): 0.000500\t TIME:2665.6s\n",
      "\t\t\t\tDisc: 0.050490\t\tSpars: 0.097223\n",
      "\t TVw: -0.554122 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 700 [4000/8000 (50%)]\tBatch Loss: 0.141237\tLearning Rate (w_theta): 0.000500\t TIME:2667.1s\n",
      "\t\t\t\tDisc: 0.047810\t\tSpars: 0.093427\n",
      "\t TVw: -0.554122 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 700...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14367938416161918\n",
      "Average validation loss: 0.14338178346099678\n",
      "Training epoch 701...\n",
      "\n",
      "Train Epoch: 701 [0/8000 (0%)]\tBatch Loss: 0.141372\tLearning Rate (w_theta): 0.000500\t TIME:2670.5s\n",
      "\t\t\t\tDisc: 0.046182\t\tSpars: 0.095190\n",
      "\t TVw: -0.554122 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 701 [4000/8000 (50%)]\tBatch Loss: 0.141629\tLearning Rate (w_theta): 0.000500\t TIME:2672.0s\n",
      "\t\t\t\tDisc: 0.048569\t\tSpars: 0.093060\n",
      "\t TVw: -0.554122 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 701...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1436716679005658\n",
      "Average validation loss: 0.14337330624152023\n",
      "Training epoch 702...\n",
      "\n",
      "Train Epoch: 702 [0/8000 (0%)]\tBatch Loss: 0.141729\tLearning Rate (w_theta): 0.000500\t TIME:2674.4s\n",
      "\t\t\t\tDisc: 0.049186\t\tSpars: 0.092543\n",
      "\t TVw: -0.554121 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 702 [4000/8000 (50%)]\tBatch Loss: 0.141223\tLearning Rate (w_theta): 0.000500\t TIME:2675.8s\n",
      "\t\t\t\tDisc: 0.043989\t\tSpars: 0.097234\n",
      "\t TVw: -0.554121 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 702...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14366373326329387\n",
      "Average validation loss: 0.1433648923667526\n",
      "Training epoch 703...\n",
      "\n",
      "Train Epoch: 703 [0/8000 (0%)]\tBatch Loss: 0.144103\tLearning Rate (w_theta): 0.000500\t TIME:2678.1s\n",
      "\t\t\t\tDisc: 0.045461\t\tSpars: 0.098642\n",
      "\t TVw: -0.554121 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 703 [4000/8000 (50%)]\tBatch Loss: 0.141084\tLearning Rate (w_theta): 0.000500\t TIME:2679.6s\n",
      "\t\t\t\tDisc: 0.047027\t\tSpars: 0.094057\n",
      "\t TVw: -0.554121 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 703...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1436555572052541\n",
      "Average validation loss: 0.14335682432531138\n",
      "Training epoch 704...\n",
      "\n",
      "Train Epoch: 704 [0/8000 (0%)]\tBatch Loss: 0.149201\tLearning Rate (w_theta): 0.000500\t TIME:2681.8s\n",
      "\t\t\t\tDisc: 0.048107\t\tSpars: 0.101094\n",
      "\t TVw: -0.554120 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 704 [4000/8000 (50%)]\tBatch Loss: 0.146105\tLearning Rate (w_theta): 0.000500\t TIME:2683.3s\n",
      "\t\t\t\tDisc: 0.046988\t\tSpars: 0.099117\n",
      "\t TVw: -0.554120 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 704...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1436479444952448\n",
      "Average validation loss: 0.14334863691698593\n",
      "Training epoch 705...\n",
      "\n",
      "Train Epoch: 705 [0/8000 (0%)]\tBatch Loss: 0.147091\tLearning Rate (w_theta): 0.000500\t TIME:2685.5s\n",
      "\t\t\t\tDisc: 0.048720\t\tSpars: 0.098371\n",
      "\t TVw: -0.554120 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 705 [4000/8000 (50%)]\tBatch Loss: 0.144242\tLearning Rate (w_theta): 0.000500\t TIME:2686.9s\n",
      "\t\t\t\tDisc: 0.048230\t\tSpars: 0.096012\n",
      "\t TVw: -0.554120 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 705...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14364024719202276\n",
      "Average validation loss: 0.14334035845693752\n",
      "Training epoch 706...\n",
      "\n",
      "Train Epoch: 706 [0/8000 (0%)]\tBatch Loss: 0.141110\tLearning Rate (w_theta): 0.000500\t TIME:2689.2s\n",
      "\t\t\t\tDisc: 0.046957\t\tSpars: 0.094152\n",
      "\t TVw: -0.554120 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 706 [4000/8000 (50%)]\tBatch Loss: 0.139188\tLearning Rate (w_theta): 0.000500\t TIME:2690.6s\n",
      "\t\t\t\tDisc: 0.046256\t\tSpars: 0.092932\n",
      "\t TVw: -0.554119 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 706...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1436321465462367\n",
      "Average validation loss: 0.14333240664433733\n",
      "Training epoch 707...\n",
      "\n",
      "Train Epoch: 707 [0/8000 (0%)]\tBatch Loss: 0.139837\tLearning Rate (w_theta): 0.000500\t TIME:2692.8s\n",
      "\t\t\t\tDisc: 0.046497\t\tSpars: 0.093341\n",
      "\t TVw: -0.554119 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 707 [4000/8000 (50%)]\tBatch Loss: 0.143344\tLearning Rate (w_theta): 0.000500\t TIME:2694.3s\n",
      "\t\t\t\tDisc: 0.046951\t\tSpars: 0.096394\n",
      "\t TVw: -0.554119 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 707...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14362428900761803\n",
      "Average validation loss: 0.14332479571586904\n",
      "Training epoch 708...\n",
      "\n",
      "Train Epoch: 708 [0/8000 (0%)]\tBatch Loss: 0.144461\tLearning Rate (w_theta): 0.000500\t TIME:2696.5s\n",
      "\t\t\t\tDisc: 0.047641\t\tSpars: 0.096820\n",
      "\t TVw: -0.554119 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 708 [4000/8000 (50%)]\tBatch Loss: 0.143529\tLearning Rate (w_theta): 0.000500\t TIME:2697.9s\n",
      "\t\t\t\tDisc: 0.047008\t\tSpars: 0.096521\n",
      "\t TVw: -0.554118 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 708...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14361696560715737\n",
      "Average validation loss: 0.14331689334981704\n",
      "Training epoch 709...\n",
      "\n",
      "Train Epoch: 709 [0/8000 (0%)]\tBatch Loss: 0.145210\tLearning Rate (w_theta): 0.000500\t TIME:2700.2s\n",
      "\t\t\t\tDisc: 0.046905\t\tSpars: 0.098305\n",
      "\t TVw: -0.554118 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 709 [4000/8000 (50%)]\tBatch Loss: 0.137818\tLearning Rate (w_theta): 0.000500\t TIME:2701.7s\n",
      "\t\t\t\tDisc: 0.049042\t\tSpars: 0.088776\n",
      "\t TVw: -0.554118 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 709...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1436092304789788\n",
      "Average validation loss: 0.14330906765703158\n",
      "Training epoch 710...\n",
      "\n",
      "Train Epoch: 710 [0/8000 (0%)]\tBatch Loss: 0.142563\tLearning Rate (w_theta): 0.000500\t TIME:2704.1s\n",
      "\t\t\t\tDisc: 0.047833\t\tSpars: 0.094730\n",
      "\t TVw: -0.554118 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 710 [4000/8000 (50%)]\tBatch Loss: 0.141091\tLearning Rate (w_theta): 0.000500\t TIME:2705.5s\n",
      "\t\t\t\tDisc: 0.046367\t\tSpars: 0.094724\n",
      "\t TVw: -0.554117 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 710...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14360145638469993\n",
      "Average validation loss: 0.14330141598093854\n",
      "Training epoch 711...\n",
      "\n",
      "Train Epoch: 711 [0/8000 (0%)]\tBatch Loss: 0.143534\tLearning Rate (w_theta): 0.000500\t TIME:2708.9s\n",
      "\t\t\t\tDisc: 0.047520\t\tSpars: 0.096014\n",
      "\t TVw: -0.554117 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 711 [4000/8000 (50%)]\tBatch Loss: 0.138264\tLearning Rate (w_theta): 0.000500\t TIME:2710.3s\n",
      "\t\t\t\tDisc: 0.046626\t\tSpars: 0.091638\n",
      "\t TVw: -0.554117 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 711...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14359392070400037\n",
      "Average validation loss: 0.1432937051906376\n",
      "Training epoch 712...\n",
      "\n",
      "Train Epoch: 712 [0/8000 (0%)]\tBatch Loss: 0.140033\tLearning Rate (w_theta): 0.000500\t TIME:2712.6s\n",
      "\t\t\t\tDisc: 0.048636\t\tSpars: 0.091397\n",
      "\t TVw: -0.554117 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 712 [4000/8000 (50%)]\tBatch Loss: 0.145535\tLearning Rate (w_theta): 0.000500\t TIME:2714.0s\n",
      "\t\t\t\tDisc: 0.048268\t\tSpars: 0.097267\n",
      "\t TVw: -0.554116 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 712...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14358646264611666\n",
      "Average validation loss: 0.1432858209618616\n",
      "Training epoch 713...\n",
      "\n",
      "Train Epoch: 713 [0/8000 (0%)]\tBatch Loss: 0.145412\tLearning Rate (w_theta): 0.000500\t TIME:2716.3s\n",
      "\t\t\t\tDisc: 0.046451\t\tSpars: 0.098961\n",
      "\t TVw: -0.554116 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 713 [4000/8000 (50%)]\tBatch Loss: 0.147157\tLearning Rate (w_theta): 0.000500\t TIME:2717.7s\n",
      "\t\t\t\tDisc: 0.048528\t\tSpars: 0.098629\n",
      "\t TVw: -0.554116 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 713...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14357862115269202\n",
      "Average validation loss: 0.14327817086889325\n",
      "Training epoch 714...\n",
      "\n",
      "Train Epoch: 714 [0/8000 (0%)]\tBatch Loss: 0.143739\tLearning Rate (w_theta): 0.000500\t TIME:2720.1s\n",
      "\t\t\t\tDisc: 0.048395\t\tSpars: 0.095344\n",
      "\t TVw: -0.554116 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 714 [4000/8000 (50%)]\tBatch Loss: 0.144842\tLearning Rate (w_theta): 0.000500\t TIME:2721.6s\n",
      "\t\t\t\tDisc: 0.048611\t\tSpars: 0.096231\n",
      "\t TVw: -0.554115 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 714...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14357114432771945\n",
      "Average validation loss: 0.14327045996310495\n",
      "Training epoch 715...\n",
      "\n",
      "Train Epoch: 715 [0/8000 (0%)]\tBatch Loss: 0.147342\tLearning Rate (w_theta): 0.000500\t TIME:2723.8s\n",
      "\t\t\t\tDisc: 0.047371\t\tSpars: 0.099971\n",
      "\t TVw: -0.554115 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 715 [4000/8000 (50%)]\tBatch Loss: 0.145639\tLearning Rate (w_theta): 0.000500\t TIME:2725.3s\n",
      "\t\t\t\tDisc: 0.048790\t\tSpars: 0.096849\n",
      "\t TVw: -0.554115 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 715...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14356347035950132\n",
      "Average validation loss: 0.1432629437820506\n",
      "Training epoch 716...\n",
      "\n",
      "Train Epoch: 716 [0/8000 (0%)]\tBatch Loss: 0.141730\tLearning Rate (w_theta): 0.000500\t TIME:2727.5s\n",
      "\t\t\t\tDisc: 0.046901\t\tSpars: 0.094829\n",
      "\t TVw: -0.554115 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 716 [4000/8000 (50%)]\tBatch Loss: 0.139780\tLearning Rate (w_theta): 0.000500\t TIME:2729.0s\n",
      "\t\t\t\tDisc: 0.046752\t\tSpars: 0.093028\n",
      "\t TVw: -0.554115 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 716...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14355597329194517\n",
      "Average validation loss: 0.14325547877008515\n",
      "Training epoch 717...\n",
      "\n",
      "Train Epoch: 717 [0/8000 (0%)]\tBatch Loss: 0.142549\tLearning Rate (w_theta): 0.000500\t TIME:2731.2s\n",
      "\t\t\t\tDisc: 0.045035\t\tSpars: 0.097514\n",
      "\t TVw: -0.554114 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 717 [4000/8000 (50%)]\tBatch Loss: 0.144342\tLearning Rate (w_theta): 0.000500\t TIME:2732.7s\n",
      "\t\t\t\tDisc: 0.047159\t\tSpars: 0.097183\n",
      "\t TVw: -0.554114 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 717...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14354863254378075\n",
      "Average validation loss: 0.14324793754191598\n",
      "Training epoch 718...\n",
      "\n",
      "Train Epoch: 718 [0/8000 (0%)]\tBatch Loss: 0.145315\tLearning Rate (w_theta): 0.000500\t TIME:2734.9s\n",
      "\t\t\t\tDisc: 0.046692\t\tSpars: 0.098622\n",
      "\t TVw: -0.554114 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 718 [4000/8000 (50%)]\tBatch Loss: 0.145480\tLearning Rate (w_theta): 0.000500\t TIME:2736.4s\n",
      "\t\t\t\tDisc: 0.047440\t\tSpars: 0.098040\n",
      "\t TVw: -0.554114 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 718...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.143541168930858\n",
      "Average validation loss: 0.14324048567967845\n",
      "Training epoch 719...\n",
      "\n",
      "Train Epoch: 719 [0/8000 (0%)]\tBatch Loss: 0.140670\tLearning Rate (w_theta): 0.000500\t TIME:2738.6s\n",
      "\t\t\t\tDisc: 0.047636\t\tSpars: 0.093034\n",
      "\t TVw: -0.554113 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 719 [4000/8000 (50%)]\tBatch Loss: 0.145687\tLearning Rate (w_theta): 0.000500\t TIME:2740.1s\n",
      "\t\t\t\tDisc: 0.048013\t\tSpars: 0.097674\n",
      "\t TVw: -0.554113 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 719...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14353395065772015\n",
      "Average validation loss: 0.14323284223885527\n",
      "Training epoch 720...\n",
      "\n",
      "Train Epoch: 720 [0/8000 (0%)]\tBatch Loss: 0.144708\tLearning Rate (w_theta): 0.000500\t TIME:2742.3s\n",
      "\t\t\t\tDisc: 0.046380\t\tSpars: 0.098328\n",
      "\t TVw: -0.554113 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 720 [4000/8000 (50%)]\tBatch Loss: 0.144633\tLearning Rate (w_theta): 0.000500\t TIME:2743.7s\n",
      "\t\t\t\tDisc: 0.048815\t\tSpars: 0.095818\n",
      "\t TVw: -0.554113 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 720...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14352633343350313\n",
      "Average validation loss: 0.14322543982443556\n",
      "Training epoch 721...\n",
      "\n",
      "Train Epoch: 721 [0/8000 (0%)]\tBatch Loss: 0.147597\tLearning Rate (w_theta): 0.000500\t TIME:2747.4s\n",
      "\t\t\t\tDisc: 0.048611\t\tSpars: 0.098986\n",
      "\t TVw: -0.554112 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 721 [4000/8000 (50%)]\tBatch Loss: 0.140274\tLearning Rate (w_theta): 0.000500\t TIME:2748.9s\n",
      "\t\t\t\tDisc: 0.047344\t\tSpars: 0.092929\n",
      "\t TVw: -0.554112 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 721...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14351905296083858\n",
      "Average validation loss: 0.14321805450461886\n",
      "Training epoch 722...\n",
      "\n",
      "Train Epoch: 722 [0/8000 (0%)]\tBatch Loss: 0.138617\tLearning Rate (w_theta): 0.000500\t TIME:2751.1s\n",
      "\t\t\t\tDisc: 0.046811\t\tSpars: 0.091806\n",
      "\t TVw: -0.554112 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 722 [4000/8000 (50%)]\tBatch Loss: 0.142279\tLearning Rate (w_theta): 0.000500\t TIME:2752.5s\n",
      "\t\t\t\tDisc: 0.044925\t\tSpars: 0.097354\n",
      "\t TVw: -0.554112 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 722...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14351162739697945\n",
      "Average validation loss: 0.143210819399878\n",
      "Training epoch 723...\n",
      "\n",
      "Train Epoch: 723 [0/8000 (0%)]\tBatch Loss: 0.141948\tLearning Rate (w_theta): 0.000500\t TIME:2754.7s\n",
      "\t\t\t\tDisc: 0.046934\t\tSpars: 0.095014\n",
      "\t TVw: -0.554111 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 723 [4000/8000 (50%)]\tBatch Loss: 0.145931\tLearning Rate (w_theta): 0.000500\t TIME:2756.2s\n",
      "\t\t\t\tDisc: 0.048246\t\tSpars: 0.097685\n",
      "\t TVw: -0.554111 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 723...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14350458881282888\n",
      "Average validation loss: 0.1432033855536018\n",
      "Training epoch 724...\n",
      "\n",
      "Train Epoch: 724 [0/8000 (0%)]\tBatch Loss: 0.145006\tLearning Rate (w_theta): 0.000500\t TIME:2758.4s\n",
      "\t\t\t\tDisc: 0.047619\t\tSpars: 0.097387\n",
      "\t TVw: -0.554111 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 724 [4000/8000 (50%)]\tBatch Loss: 0.143275\tLearning Rate (w_theta): 0.000500\t TIME:2759.9s\n",
      "\t\t\t\tDisc: 0.048481\t\tSpars: 0.094794\n",
      "\t TVw: -0.554111 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 724...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14349706817264032\n",
      "Average validation loss: 0.14319635406143463\n",
      "Training epoch 725...\n",
      "\n",
      "Train Epoch: 725 [0/8000 (0%)]\tBatch Loss: 0.142027\tLearning Rate (w_theta): 0.000500\t TIME:2762.3s\n",
      "\t\t\t\tDisc: 0.045122\t\tSpars: 0.096904\n",
      "\t TVw: -0.554110 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 725 [4000/8000 (50%)]\tBatch Loss: 0.144286\tLearning Rate (w_theta): 0.000500\t TIME:2763.8s\n",
      "\t\t\t\tDisc: 0.050180\t\tSpars: 0.094106\n",
      "\t TVw: -0.554110 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 725...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14349006258245944\n",
      "Average validation loss: 0.14318921999238865\n",
      "Training epoch 726...\n",
      "\n",
      "Train Epoch: 726 [0/8000 (0%)]\tBatch Loss: 0.145153\tLearning Rate (w_theta): 0.000500\t TIME:2766.0s\n",
      "\t\t\t\tDisc: 0.047670\t\tSpars: 0.097483\n",
      "\t TVw: -0.554110 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 726 [4000/8000 (50%)]\tBatch Loss: 0.142033\tLearning Rate (w_theta): 0.000500\t TIME:2767.4s\n",
      "\t\t\t\tDisc: 0.047182\t\tSpars: 0.094850\n",
      "\t TVw: -0.554110 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 726...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14348293979668766\n",
      "Average validation loss: 0.14318206238254338\n",
      "Training epoch 727...\n",
      "\n",
      "Train Epoch: 727 [0/8000 (0%)]\tBatch Loss: 0.142794\tLearning Rate (w_theta): 0.000500\t TIME:2769.6s\n",
      "\t\t\t\tDisc: 0.046456\t\tSpars: 0.096338\n",
      "\t TVw: -0.554110 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 727 [4000/8000 (50%)]\tBatch Loss: 0.142320\tLearning Rate (w_theta): 0.000500\t TIME:2771.1s\n",
      "\t\t\t\tDisc: 0.048011\t\tSpars: 0.094309\n",
      "\t TVw: -0.554109 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 727...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14347561118531574\n",
      "Average validation loss: 0.14317507259540546\n",
      "Training epoch 728...\n",
      "\n",
      "Train Epoch: 728 [0/8000 (0%)]\tBatch Loss: 0.135892\tLearning Rate (w_theta): 0.000500\t TIME:2773.4s\n",
      "\t\t\t\tDisc: 0.043343\t\tSpars: 0.092549\n",
      "\t TVw: -0.554109 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 728 [4000/8000 (50%)]\tBatch Loss: 0.147229\tLearning Rate (w_theta): 0.000500\t TIME:2774.9s\n",
      "\t\t\t\tDisc: 0.049176\t\tSpars: 0.098053\n",
      "\t TVw: -0.554109 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 728...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14346856009801057\n",
      "Average validation loss: 0.1431680386195427\n",
      "Training epoch 729...\n",
      "\n",
      "Train Epoch: 729 [0/8000 (0%)]\tBatch Loss: 0.143076\tLearning Rate (w_theta): 0.000500\t TIME:2777.1s\n",
      "\t\t\t\tDisc: 0.048101\t\tSpars: 0.094975\n",
      "\t TVw: -0.554109 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 729 [4000/8000 (50%)]\tBatch Loss: 0.141506\tLearning Rate (w_theta): 0.000500\t TIME:2778.6s\n",
      "\t\t\t\tDisc: 0.049497\t\tSpars: 0.092009\n",
      "\t TVw: -0.554108 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 729...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1434615147838659\n",
      "Average validation loss: 0.14316098299005678\n",
      "Training epoch 730...\n",
      "\n",
      "Train Epoch: 730 [0/8000 (0%)]\tBatch Loss: 0.140709\tLearning Rate (w_theta): 0.000500\t TIME:2780.8s\n",
      "\t\t\t\tDisc: 0.045519\t\tSpars: 0.095190\n",
      "\t TVw: -0.554108 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 730 [4000/8000 (50%)]\tBatch Loss: 0.143490\tLearning Rate (w_theta): 0.000500\t TIME:2782.3s\n",
      "\t\t\t\tDisc: 0.045888\t\tSpars: 0.097602\n",
      "\t TVw: -0.554108 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 730...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14345447616606577\n",
      "Average validation loss: 0.14315390733413397\n",
      "Training epoch 731...\n",
      "\n",
      "Train Epoch: 731 [0/8000 (0%)]\tBatch Loss: 0.145924\tLearning Rate (w_theta): 0.000500\t TIME:2785.8s\n",
      "\t\t\t\tDisc: 0.048752\t\tSpars: 0.097172\n",
      "\t TVw: -0.554108 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 731 [4000/8000 (50%)]\tBatch Loss: 0.142982\tLearning Rate (w_theta): 0.000500\t TIME:2787.3s\n",
      "\t\t\t\tDisc: 0.047932\t\tSpars: 0.095050\n",
      "\t TVw: -0.554107 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 731...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14344727635832363\n",
      "Average validation loss: 0.1431469883187759\n",
      "Training epoch 732...\n",
      "\n",
      "Train Epoch: 732 [0/8000 (0%)]\tBatch Loss: 0.142578\tLearning Rate (w_theta): 0.000500\t TIME:2789.5s\n",
      "\t\t\t\tDisc: 0.046928\t\tSpars: 0.095650\n",
      "\t TVw: -0.554107 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 732 [4000/8000 (50%)]\tBatch Loss: 0.146948\tLearning Rate (w_theta): 0.000500\t TIME:2791.0s\n",
      "\t\t\t\tDisc: 0.048790\t\tSpars: 0.098158\n",
      "\t TVw: -0.554107 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 732...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14344038061904799\n",
      "Average validation loss: 0.14314000155712392\n",
      "Training epoch 733...\n",
      "\n",
      "Train Epoch: 733 [0/8000 (0%)]\tBatch Loss: 0.143196\tLearning Rate (w_theta): 0.000500\t TIME:2793.2s\n",
      "\t\t\t\tDisc: 0.048022\t\tSpars: 0.095174\n",
      "\t TVw: -0.554107 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 733 [4000/8000 (50%)]\tBatch Loss: 0.144971\tLearning Rate (w_theta): 0.000500\t TIME:2794.6s\n",
      "\t\t\t\tDisc: 0.047517\t\tSpars: 0.097453\n",
      "\t TVw: -0.554106 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 733...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14343330987694464\n",
      "Average validation loss: 0.14313317806690645\n",
      "Training epoch 734...\n",
      "\n",
      "Train Epoch: 734 [0/8000 (0%)]\tBatch Loss: 0.141585\tLearning Rate (w_theta): 0.000500\t TIME:2796.9s\n",
      "\t\t\t\tDisc: 0.047046\t\tSpars: 0.094539\n",
      "\t TVw: -0.554106 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 734 [4000/8000 (50%)]\tBatch Loss: 0.143462\tLearning Rate (w_theta): 0.000500\t TIME:2798.3s\n",
      "\t\t\t\tDisc: 0.047493\t\tSpars: 0.095970\n",
      "\t TVw: -0.554106 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 734...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14342639830290907\n",
      "Average validation loss: 0.14312639814752565\n",
      "Training epoch 735...\n",
      "\n",
      "Train Epoch: 735 [0/8000 (0%)]\tBatch Loss: 0.144306\tLearning Rate (w_theta): 0.000500\t TIME:2800.6s\n",
      "\t\t\t\tDisc: 0.046628\t\tSpars: 0.097677\n",
      "\t TVw: -0.554106 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 735 [4000/8000 (50%)]\tBatch Loss: 0.142465\tLearning Rate (w_theta): 0.000500\t TIME:2802.0s\n",
      "\t\t\t\tDisc: 0.047544\t\tSpars: 0.094921\n",
      "\t TVw: -0.554105 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 735...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14341966508744375\n",
      "Average validation loss: 0.14311950619084812\n",
      "Training epoch 736...\n",
      "\n",
      "Train Epoch: 736 [0/8000 (0%)]\tBatch Loss: 0.139106\tLearning Rate (w_theta): 0.000500\t TIME:2804.2s\n",
      "\t\t\t\tDisc: 0.043138\t\tSpars: 0.095968\n",
      "\t TVw: -0.554105 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 736 [4000/8000 (50%)]\tBatch Loss: 0.142429\tLearning Rate (w_theta): 0.000500\t TIME:2806.1s\n",
      "\t\t\t\tDisc: 0.047262\t\tSpars: 0.095167\n",
      "\t TVw: -0.554105 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 736...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14341272265938568\n",
      "Average validation loss: 0.1431127234342749\n",
      "Training epoch 737...\n",
      "\n",
      "Train Epoch: 737 [0/8000 (0%)]\tBatch Loss: 0.145491\tLearning Rate (w_theta): 0.000500\t TIME:2808.4s\n",
      "\t\t\t\tDisc: 0.049070\t\tSpars: 0.096421\n",
      "\t TVw: -0.554105 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 737 [4000/8000 (50%)]\tBatch Loss: 0.141837\tLearning Rate (w_theta): 0.000500\t TIME:2810.0s\n",
      "\t\t\t\tDisc: 0.047058\t\tSpars: 0.094780\n",
      "\t TVw: -0.554105 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 737...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14340591673070202\n",
      "Average validation loss: 0.1431059822921091\n",
      "Training epoch 738...\n",
      "\n",
      "Train Epoch: 738 [0/8000 (0%)]\tBatch Loss: 0.142163\tLearning Rate (w_theta): 0.000500\t TIME:2812.3s\n",
      "\t\t\t\tDisc: 0.046016\t\tSpars: 0.096147\n",
      "\t TVw: -0.554104 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 738 [4000/8000 (50%)]\tBatch Loss: 0.140838\tLearning Rate (w_theta): 0.000500\t TIME:2813.8s\n",
      "\t\t\t\tDisc: 0.043972\t\tSpars: 0.096866\n",
      "\t TVw: -0.554104 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 738...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1433991027216387\n",
      "Average validation loss: 0.14309928847624756\n",
      "Training epoch 739...\n",
      "\n",
      "Train Epoch: 739 [0/8000 (0%)]\tBatch Loss: 0.144817\tLearning Rate (w_theta): 0.000500\t TIME:2816.0s\n",
      "\t\t\t\tDisc: 0.048159\t\tSpars: 0.096658\n",
      "\t TVw: -0.554104 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 739 [4000/8000 (50%)]\tBatch Loss: 0.147366\tLearning Rate (w_theta): 0.000500\t TIME:2817.4s\n",
      "\t\t\t\tDisc: 0.048114\t\tSpars: 0.099252\n",
      "\t TVw: -0.554104 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 739...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14339234030626075\n",
      "Average validation loss: 0.1430926207755112\n",
      "Training epoch 740...\n",
      "\n",
      "Train Epoch: 740 [0/8000 (0%)]\tBatch Loss: 0.146904\tLearning Rate (w_theta): 0.000500\t TIME:2819.7s\n",
      "\t\t\t\tDisc: 0.048931\t\tSpars: 0.097973\n",
      "\t TVw: -0.554103 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 740 [4000/8000 (50%)]\tBatch Loss: 0.142237\tLearning Rate (w_theta): 0.000500\t TIME:2821.2s\n",
      "\t\t\t\tDisc: 0.045558\t\tSpars: 0.096679\n",
      "\t TVw: -0.554103 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 740...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14338561528979782\n",
      "Average validation loss: 0.14308598753140975\n",
      "Training epoch 741...\n",
      "\n",
      "Train Epoch: 741 [0/8000 (0%)]\tBatch Loss: 0.143067\tLearning Rate (w_theta): 0.000500\t TIME:2825.0s\n",
      "\t\t\t\tDisc: 0.046832\t\tSpars: 0.096235\n",
      "\t TVw: -0.554103 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 741 [4000/8000 (50%)]\tBatch Loss: 0.139858\tLearning Rate (w_theta): 0.000500\t TIME:2826.4s\n",
      "\t\t\t\tDisc: 0.045523\t\tSpars: 0.094335\n",
      "\t TVw: -0.554103 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 741...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14337886505484387\n",
      "Average validation loss: 0.1430794368649585\n",
      "Training epoch 742...\n",
      "\n",
      "Train Epoch: 742 [0/8000 (0%)]\tBatch Loss: 0.145661\tLearning Rate (w_theta): 0.000500\t TIME:2828.6s\n",
      "\t\t\t\tDisc: 0.047790\t\tSpars: 0.097871\n",
      "\t TVw: -0.554102 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 742 [4000/8000 (50%)]\tBatch Loss: 0.141793\tLearning Rate (w_theta): 0.000500\t TIME:2830.1s\n",
      "\t\t\t\tDisc: 0.046455\t\tSpars: 0.095338\n",
      "\t TVw: -0.554102 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 742...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14337236661237038\n",
      "Average validation loss: 0.14307274275260595\n",
      "Training epoch 743...\n",
      "\n",
      "Train Epoch: 743 [0/8000 (0%)]\tBatch Loss: 0.141030\tLearning Rate (w_theta): 0.000500\t TIME:2832.3s\n",
      "\t\t\t\tDisc: 0.044981\t\tSpars: 0.096049\n",
      "\t TVw: -0.554102 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 743 [4000/8000 (50%)]\tBatch Loss: 0.142302\tLearning Rate (w_theta): 0.000500\t TIME:2833.7s\n",
      "\t\t\t\tDisc: 0.048483\t\tSpars: 0.093819\n",
      "\t TVw: -0.554102 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 743...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14336562390799068\n",
      "Average validation loss: 0.1430661394334203\n",
      "Training epoch 744...\n",
      "\n",
      "Train Epoch: 744 [0/8000 (0%)]\tBatch Loss: 0.144826\tLearning Rate (w_theta): 0.000500\t TIME:2835.9s\n",
      "\t\t\t\tDisc: 0.047915\t\tSpars: 0.096911\n",
      "\t TVw: -0.554101 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 744 [4000/8000 (50%)]\tBatch Loss: 0.145939\tLearning Rate (w_theta): 0.000500\t TIME:2837.3s\n",
      "\t\t\t\tDisc: 0.048249\t\tSpars: 0.097691\n",
      "\t TVw: -0.554101 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 744...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14335920618999923\n",
      "Average validation loss: 0.143059303760128\n",
      "Training epoch 745...\n",
      "\n",
      "Train Epoch: 745 [0/8000 (0%)]\tBatch Loss: 0.146574\tLearning Rate (w_theta): 0.000500\t TIME:2839.5s\n",
      "\t\t\t\tDisc: 0.049167\t\tSpars: 0.097406\n",
      "\t TVw: -0.554101 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 745 [4000/8000 (50%)]\tBatch Loss: 0.143294\tLearning Rate (w_theta): 0.000500\t TIME:2841.0s\n",
      "\t\t\t\tDisc: 0.048334\t\tSpars: 0.094961\n",
      "\t TVw: -0.554101 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 745...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14335236782428554\n",
      "Average validation loss: 0.14305268172526672\n",
      "Training epoch 746...\n",
      "\n",
      "Train Epoch: 746 [0/8000 (0%)]\tBatch Loss: 0.143966\tLearning Rate (w_theta): 0.000500\t TIME:2843.2s\n",
      "\t\t\t\tDisc: 0.048956\t\tSpars: 0.095009\n",
      "\t TVw: -0.554100 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 746 [4000/8000 (50%)]\tBatch Loss: 0.144698\tLearning Rate (w_theta): 0.000500\t TIME:2844.6s\n",
      "\t\t\t\tDisc: 0.048038\t\tSpars: 0.096660\n",
      "\t TVw: -0.554100 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 746...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.143345589339093\n",
      "Average validation loss: 0.14304629005877265\n",
      "Training epoch 747...\n",
      "\n",
      "Train Epoch: 747 [0/8000 (0%)]\tBatch Loss: 0.144456\tLearning Rate (w_theta): 0.000500\t TIME:2846.8s\n",
      "\t\t\t\tDisc: 0.046943\t\tSpars: 0.097513\n",
      "\t TVw: -0.554100 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 747 [4000/8000 (50%)]\tBatch Loss: 0.141940\tLearning Rate (w_theta): 0.000500\t TIME:2848.2s\n",
      "\t\t\t\tDisc: 0.046408\t\tSpars: 0.095532\n",
      "\t TVw: -0.554100 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 747...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14333927812902286\n",
      "Average validation loss: 0.14303965453603917\n",
      "Training epoch 748...\n",
      "\n",
      "Train Epoch: 748 [0/8000 (0%)]\tBatch Loss: 0.140227\tLearning Rate (w_theta): 0.000500\t TIME:2850.4s\n",
      "\t\t\t\tDisc: 0.046321\t\tSpars: 0.093906\n",
      "\t TVw: -0.554100 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 748 [4000/8000 (50%)]\tBatch Loss: 0.140231\tLearning Rate (w_theta): 0.000500\t TIME:2851.9s\n",
      "\t\t\t\tDisc: 0.046265\t\tSpars: 0.093966\n",
      "\t TVw: -0.554099 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 748...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14333269574054935\n",
      "Average validation loss: 0.14303306802849536\n",
      "Training epoch 749...\n",
      "\n",
      "Train Epoch: 749 [0/8000 (0%)]\tBatch Loss: 0.141390\tLearning Rate (w_theta): 0.000500\t TIME:2854.2s\n",
      "\t\t\t\tDisc: 0.048849\t\tSpars: 0.092541\n",
      "\t TVw: -0.554099 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 749 [4000/8000 (50%)]\tBatch Loss: 0.144679\tLearning Rate (w_theta): 0.000500\t TIME:2855.7s\n",
      "\t\t\t\tDisc: 0.048791\t\tSpars: 0.095888\n",
      "\t TVw: -0.554099 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 749...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14332611839988757\n",
      "Average validation loss: 0.14302653860860504\n",
      "Training epoch 750...\n",
      "\n",
      "Train Epoch: 750 [0/8000 (0%)]\tBatch Loss: 0.146256\tLearning Rate (w_theta): 0.000500\t TIME:2857.8s\n",
      "\t\t\t\tDisc: 0.049478\t\tSpars: 0.096778\n",
      "\t TVw: -0.554099 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 750 [4000/8000 (50%)]\tBatch Loss: 0.144169\tLearning Rate (w_theta): 0.000500\t TIME:2859.3s\n",
      "\t\t\t\tDisc: 0.047017\t\tSpars: 0.097151\n",
      "\t TVw: -0.554098 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 750...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14331945770532936\n",
      "Average validation loss: 0.1430200641032213\n",
      "Training epoch 751...\n",
      "\n",
      "Train Epoch: 751 [0/8000 (0%)]\tBatch Loss: 0.145383\tLearning Rate (w_theta): 0.000500\t TIME:2862.7s\n",
      "\t\t\t\tDisc: 0.050217\t\tSpars: 0.095166\n",
      "\t TVw: -0.554098 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 751 [4000/8000 (50%)]\tBatch Loss: 0.139842\tLearning Rate (w_theta): 0.000500\t TIME:2864.1s\n",
      "\t\t\t\tDisc: 0.046180\t\tSpars: 0.093662\n",
      "\t TVw: -0.554098 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 751...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14331314665675451\n",
      "Average validation loss: 0.14301336973301337\n",
      "Training epoch 752...\n",
      "\n",
      "Train Epoch: 752 [0/8000 (0%)]\tBatch Loss: 0.144737\tLearning Rate (w_theta): 0.000500\t TIME:2866.3s\n",
      "\t\t\t\tDisc: 0.047894\t\tSpars: 0.096844\n",
      "\t TVw: -0.554098 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 752 [4000/8000 (50%)]\tBatch Loss: 0.143488\tLearning Rate (w_theta): 0.000500\t TIME:2867.8s\n",
      "\t\t\t\tDisc: 0.047661\t\tSpars: 0.095827\n",
      "\t TVw: -0.554097 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 752...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14330649892045566\n",
      "Average validation loss: 0.1430068282560458\n",
      "Training epoch 753...\n",
      "\n",
      "Train Epoch: 753 [0/8000 (0%)]\tBatch Loss: 0.144694\tLearning Rate (w_theta): 0.000500\t TIME:2870.1s\n",
      "\t\t\t\tDisc: 0.047117\t\tSpars: 0.097577\n",
      "\t TVw: -0.554097 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 753 [4000/8000 (50%)]\tBatch Loss: 0.141655\tLearning Rate (w_theta): 0.000500\t TIME:2871.6s\n",
      "\t\t\t\tDisc: 0.047020\t\tSpars: 0.094635\n",
      "\t TVw: -0.554097 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 753...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1433000944616655\n",
      "Average validation loss: 0.1430002519618873\n",
      "Training epoch 754...\n",
      "\n",
      "Train Epoch: 754 [0/8000 (0%)]\tBatch Loss: 0.140442\tLearning Rate (w_theta): 0.000500\t TIME:2873.8s\n",
      "\t\t\t\tDisc: 0.044983\t\tSpars: 0.095459\n",
      "\t TVw: -0.554097 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 754 [4000/8000 (50%)]\tBatch Loss: 0.143666\tLearning Rate (w_theta): 0.000500\t TIME:2875.2s\n",
      "\t\t\t\tDisc: 0.048339\t\tSpars: 0.095327\n",
      "\t TVw: -0.554096 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 754...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14329350019177864\n",
      "Average validation loss: 0.14299382667469307\n",
      "Training epoch 755...\n",
      "\n",
      "Train Epoch: 755 [0/8000 (0%)]\tBatch Loss: 0.145283\tLearning Rate (w_theta): 0.000500\t TIME:2877.4s\n",
      "\t\t\t\tDisc: 0.049437\t\tSpars: 0.095846\n",
      "\t TVw: -0.554096 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 755 [4000/8000 (50%)]\tBatch Loss: 0.147511\tLearning Rate (w_theta): 0.000500\t TIME:2878.9s\n",
      "\t\t\t\tDisc: 0.047731\t\tSpars: 0.099780\n",
      "\t TVw: -0.554096 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 755...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14328722713303366\n",
      "Average validation loss: 0.14298727566667857\n",
      "Training epoch 756...\n",
      "\n",
      "Train Epoch: 756 [0/8000 (0%)]\tBatch Loss: 0.141129\tLearning Rate (w_theta): 0.000500\t TIME:2881.0s\n",
      "\t\t\t\tDisc: 0.045855\t\tSpars: 0.095274\n",
      "\t TVw: -0.554096 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 756 [4000/8000 (50%)]\tBatch Loss: 0.139500\tLearning Rate (w_theta): 0.000500\t TIME:2882.5s\n",
      "\t\t\t\tDisc: 0.047581\t\tSpars: 0.091919\n",
      "\t TVw: -0.554095 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 756...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14328079288173204\n",
      "Average validation loss: 0.14298074942279876\n",
      "Training epoch 757...\n",
      "\n",
      "Train Epoch: 757 [0/8000 (0%)]\tBatch Loss: 0.148587\tLearning Rate (w_theta): 0.000500\t TIME:2884.7s\n",
      "\t\t\t\tDisc: 0.048000\t\tSpars: 0.100587\n",
      "\t TVw: -0.554095 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 757 [4000/8000 (50%)]\tBatch Loss: 0.141829\tLearning Rate (w_theta): 0.000500\t TIME:2886.2s\n",
      "\t\t\t\tDisc: 0.046207\t\tSpars: 0.095623\n",
      "\t TVw: -0.554095 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 757...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14327420937373592\n",
      "Average validation loss: 0.1429744382927987\n",
      "Training epoch 758...\n",
      "\n",
      "Train Epoch: 758 [0/8000 (0%)]\tBatch Loss: 0.143669\tLearning Rate (w_theta): 0.000500\t TIME:2888.3s\n",
      "\t\t\t\tDisc: 0.045830\t\tSpars: 0.097839\n",
      "\t TVw: -0.554095 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 758 [4000/8000 (50%)]\tBatch Loss: 0.140099\tLearning Rate (w_theta): 0.000500\t TIME:2889.8s\n",
      "\t\t\t\tDisc: 0.045939\t\tSpars: 0.094159\n",
      "\t TVw: -0.554094 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 758...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14326805953999167\n",
      "Average validation loss: 0.1429678603400122\n",
      "Training epoch 759...\n",
      "\n",
      "Train Epoch: 759 [0/8000 (0%)]\tBatch Loss: 0.140648\tLearning Rate (w_theta): 0.000500\t TIME:2892.0s\n",
      "\t\t\t\tDisc: 0.045408\t\tSpars: 0.095240\n",
      "\t TVw: -0.554094 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 759 [4000/8000 (50%)]\tBatch Loss: 0.148478\tLearning Rate (w_theta): 0.000500\t TIME:2893.4s\n",
      "\t\t\t\tDisc: 0.049484\t\tSpars: 0.098995\n",
      "\t TVw: -0.554094 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 759...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1432615642235891\n",
      "Average validation loss: 0.1429614284917553\n",
      "Training epoch 760...\n",
      "\n",
      "Train Epoch: 760 [0/8000 (0%)]\tBatch Loss: 0.142565\tLearning Rate (w_theta): 0.000500\t TIME:2895.6s\n",
      "\t\t\t\tDisc: 0.046920\t\tSpars: 0.095645\n",
      "\t TVw: -0.554094 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 760 [4000/8000 (50%)]\tBatch Loss: 0.146973\tLearning Rate (w_theta): 0.000500\t TIME:2897.1s\n",
      "\t\t\t\tDisc: 0.048342\t\tSpars: 0.098631\n",
      "\t TVw: -0.554093 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 760...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14325523565592654\n",
      "Average validation loss: 0.14295495979946787\n",
      "Training epoch 761...\n",
      "\n",
      "Train Epoch: 761 [0/8000 (0%)]\tBatch Loss: 0.142614\tLearning Rate (w_theta): 0.000500\t TIME:2900.5s\n",
      "\t\t\t\tDisc: 0.046072\t\tSpars: 0.096541\n",
      "\t TVw: -0.554093 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 761 [4000/8000 (50%)]\tBatch Loss: 0.143863\tLearning Rate (w_theta): 0.000500\t TIME:2902.0s\n",
      "\t\t\t\tDisc: 0.048599\t\tSpars: 0.095264\n",
      "\t TVw: -0.554092 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 761...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14324888321565915\n",
      "Average validation loss: 0.14294854558095418\n",
      "Training epoch 762...\n",
      "\n",
      "Train Epoch: 762 [0/8000 (0%)]\tBatch Loss: 0.144725\tLearning Rate (w_theta): 0.000500\t TIME:2904.2s\n",
      "\t\t\t\tDisc: 0.047455\t\tSpars: 0.097269\n",
      "\t TVw: -0.554092 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 762 [4000/8000 (50%)]\tBatch Loss: 0.143753\tLearning Rate (w_theta): 0.000500\t TIME:2905.6s\n",
      "\t\t\t\tDisc: 0.048266\t\tSpars: 0.095488\n",
      "\t TVw: -0.554091 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 762...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14324277487984258\n",
      "Average validation loss: 0.14294194790072295\n",
      "Training epoch 763...\n",
      "\n",
      "Train Epoch: 763 [0/8000 (0%)]\tBatch Loss: 0.146236\tLearning Rate (w_theta): 0.000500\t TIME:2907.9s\n",
      "\t\t\t\tDisc: 0.046841\t\tSpars: 0.099395\n",
      "\t TVw: -0.554091 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 763 [4000/8000 (50%)]\tBatch Loss: 0.145758\tLearning Rate (w_theta): 0.000500\t TIME:2909.3s\n",
      "\t\t\t\tDisc: 0.047989\t\tSpars: 0.097769\n",
      "\t TVw: -0.554090 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 763...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1432361245432751\n",
      "Average validation loss: 0.1429357999665804\n",
      "Training epoch 764...\n",
      "\n",
      "Train Epoch: 764 [0/8000 (0%)]\tBatch Loss: 0.145505\tLearning Rate (w_theta): 0.000500\t TIME:2911.5s\n",
      "\t\t\t\tDisc: 0.050535\t\tSpars: 0.094970\n",
      "\t TVw: -0.554090 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 764 [4000/8000 (50%)]\tBatch Loss: 0.145704\tLearning Rate (w_theta): 0.000500\t TIME:2913.1s\n",
      "\t\t\t\tDisc: 0.048981\t\tSpars: 0.096723\n",
      "\t TVw: -0.554090 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 764...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14323004826738128\n",
      "Average validation loss: 0.14292950560065415\n",
      "Training epoch 765...\n",
      "\n",
      "Train Epoch: 765 [0/8000 (0%)]\tBatch Loss: 0.139836\tLearning Rate (w_theta): 0.000500\t TIME:2915.3s\n",
      "\t\t\t\tDisc: 0.047619\t\tSpars: 0.092216\n",
      "\t TVw: -0.554089 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 765 [4000/8000 (50%)]\tBatch Loss: 0.146743\tLearning Rate (w_theta): 0.000500\t TIME:2916.8s\n",
      "\t\t\t\tDisc: 0.047741\t\tSpars: 0.099002\n",
      "\t TVw: -0.554089 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 765...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14322387054361355\n",
      "Average validation loss: 0.14292313286163347\n",
      "Training epoch 766...\n",
      "\n",
      "Train Epoch: 766 [0/8000 (0%)]\tBatch Loss: 0.144430\tLearning Rate (w_theta): 0.000500\t TIME:2918.9s\n",
      "\t\t\t\tDisc: 0.046403\t\tSpars: 0.098027\n",
      "\t TVw: -0.554088 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 766 [4000/8000 (50%)]\tBatch Loss: 0.144878\tLearning Rate (w_theta): 0.000500\t TIME:2920.4s\n",
      "\t\t\t\tDisc: 0.047825\t\tSpars: 0.097053\n",
      "\t TVw: -0.554088 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 766...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14321765866539019\n",
      "Average validation loss: 0.14291674917831781\n",
      "Training epoch 767...\n",
      "\n",
      "Train Epoch: 767 [0/8000 (0%)]\tBatch Loss: 0.141474\tLearning Rate (w_theta): 0.000500\t TIME:2922.6s\n",
      "\t\t\t\tDisc: 0.046731\t\tSpars: 0.094744\n",
      "\t TVw: -0.554087 | TVb: -2.054468 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 767 [4000/8000 (50%)]\tBatch Loss: 0.140856\tLearning Rate (w_theta): 0.000500\t TIME:2924.1s\n",
      "\t\t\t\tDisc: 0.048241\t\tSpars: 0.092615\n",
      "\t TVw: -0.554087 | TVb: -2.054467 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 767...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14321139678994835\n",
      "Average validation loss: 0.14291044608992914\n",
      "Training epoch 768...\n",
      "\n",
      "Train Epoch: 768 [0/8000 (0%)]\tBatch Loss: 0.146302\tLearning Rate (w_theta): 0.000500\t TIME:2926.3s\n",
      "\t\t\t\tDisc: 0.048392\t\tSpars: 0.097911\n",
      "\t TVw: -0.554086 | TVb: -2.054466 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 768 [4000/8000 (50%)]\tBatch Loss: 0.144420\tLearning Rate (w_theta): 0.000500\t TIME:2927.7s\n",
      "\t\t\t\tDisc: 0.048493\t\tSpars: 0.095928\n",
      "\t TVw: -0.554086 | TVb: -2.054466 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 768...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14320533545298914\n",
      "Average validation loss: 0.1429039908933244\n",
      "Training epoch 769...\n",
      "\n",
      "Train Epoch: 769 [0/8000 (0%)]\tBatch Loss: 0.146891\tLearning Rate (w_theta): 0.000500\t TIME:2929.9s\n",
      "\t\t\t\tDisc: 0.048908\t\tSpars: 0.097983\n",
      "\t TVw: -0.554085 | TVb: -2.054465 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 769 [4000/8000 (50%)]\tBatch Loss: 0.143796\tLearning Rate (w_theta): 0.000500\t TIME:2931.3s\n",
      "\t\t\t\tDisc: 0.049585\t\tSpars: 0.094212\n",
      "\t TVw: -0.554085 | TVb: -2.054464 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 769...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14319897776741342\n",
      "Average validation loss: 0.1428977058499997\n",
      "Training epoch 770...\n",
      "\n",
      "Train Epoch: 770 [0/8000 (0%)]\tBatch Loss: 0.145068\tLearning Rate (w_theta): 0.000500\t TIME:2933.5s\n",
      "\t\t\t\tDisc: 0.048567\t\tSpars: 0.096501\n",
      "\t TVw: -0.554084 | TVb: -2.054463 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 770 [4000/8000 (50%)]\tBatch Loss: 0.142802\tLearning Rate (w_theta): 0.000500\t TIME:2935.0s\n",
      "\t\t\t\tDisc: 0.046336\t\tSpars: 0.096466\n",
      "\t TVw: -0.554084 | TVb: -2.054462 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 770...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14319285084638506\n",
      "Average validation loss: 0.14289139641636098\n",
      "Training epoch 771...\n",
      "\n",
      "Train Epoch: 771 [0/8000 (0%)]\tBatch Loss: 0.144654\tLearning Rate (w_theta): 0.000500\t TIME:2938.5s\n",
      "\t\t\t\tDisc: 0.048149\t\tSpars: 0.096505\n",
      "\t TVw: -0.554083 | TVb: -2.054461 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 771 [4000/8000 (50%)]\tBatch Loss: 0.146396\tLearning Rate (w_theta): 0.000500\t TIME:2940.0s\n",
      "\t\t\t\tDisc: 0.049569\t\tSpars: 0.096827\n",
      "\t TVw: -0.554083 | TVb: -2.054460 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 771...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14318666019122386\n",
      "Average validation loss: 0.14288511022330738\n",
      "Training epoch 772...\n",
      "\n",
      "Train Epoch: 772 [0/8000 (0%)]\tBatch Loss: 0.142911\tLearning Rate (w_theta): 0.000500\t TIME:2942.2s\n",
      "\t\t\t\tDisc: 0.046752\t\tSpars: 0.096159\n",
      "\t TVw: -0.554082 | TVb: -2.054459 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 772 [4000/8000 (50%)]\tBatch Loss: 0.145857\tLearning Rate (w_theta): 0.000500\t TIME:2943.6s\n",
      "\t\t\t\tDisc: 0.050430\t\tSpars: 0.095427\n",
      "\t TVw: -0.554082 | TVb: -2.054458 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 772...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14318052540587217\n",
      "Average validation loss: 0.1428788309766063\n",
      "Training epoch 773...\n",
      "\n",
      "Train Epoch: 773 [0/8000 (0%)]\tBatch Loss: 0.140816\tLearning Rate (w_theta): 0.000500\t TIME:2945.8s\n",
      "\t\t\t\tDisc: 0.046990\t\tSpars: 0.093826\n",
      "\t TVw: -0.554081 | TVb: -2.054457 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 773 [4000/8000 (50%)]\tBatch Loss: 0.142632\tLearning Rate (w_theta): 0.000500\t TIME:2947.2s\n",
      "\t\t\t\tDisc: 0.047475\t\tSpars: 0.095157\n",
      "\t TVw: -0.554081 | TVb: -2.054456 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 773...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14317440937200313\n",
      "Average validation loss: 0.1428724985194317\n",
      "Training epoch 774...\n",
      "\n",
      "Train Epoch: 774 [0/8000 (0%)]\tBatch Loss: 0.141278\tLearning Rate (w_theta): 0.000500\t TIME:2949.4s\n",
      "\t\t\t\tDisc: 0.047749\t\tSpars: 0.093529\n",
      "\t TVw: -0.554080 | TVb: -2.054455 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 774 [4000/8000 (50%)]\tBatch Loss: 0.138524\tLearning Rate (w_theta): 0.000500\t TIME:2950.9s\n",
      "\t\t\t\tDisc: 0.045405\t\tSpars: 0.093119\n",
      "\t TVw: -0.554080 | TVb: -2.054454 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 774...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14316815271421415\n",
      "Average validation loss: 0.14286625526525104\n",
      "Training epoch 775...\n",
      "\n",
      "Train Epoch: 775 [0/8000 (0%)]\tBatch Loss: 0.146521\tLearning Rate (w_theta): 0.000500\t TIME:2953.0s\n",
      "\t\t\t\tDisc: 0.047375\t\tSpars: 0.099146\n",
      "\t TVw: -0.554080 | TVb: -2.054453 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 775 [4000/8000 (50%)]\tBatch Loss: 0.147346\tLearning Rate (w_theta): 0.000500\t TIME:2954.5s\n",
      "\t\t\t\tDisc: 0.050398\t\tSpars: 0.096948\n",
      "\t TVw: -0.554079 | TVb: -2.054452 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 775...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14316199836050264\n",
      "Average validation loss: 0.14286014126907046\n",
      "Training epoch 776...\n",
      "\n",
      "Train Epoch: 776 [0/8000 (0%)]\tBatch Loss: 0.139450\tLearning Rate (w_theta): 0.000500\t TIME:2956.7s\n",
      "\t\t\t\tDisc: 0.045207\t\tSpars: 0.094243\n",
      "\t TVw: -0.554079 | TVb: -2.054451 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 776 [4000/8000 (50%)]\tBatch Loss: 0.145161\tLearning Rate (w_theta): 0.000500\t TIME:2958.1s\n",
      "\t\t\t\tDisc: 0.047075\t\tSpars: 0.098086\n",
      "\t TVw: -0.554078 | TVb: -2.054450 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 776...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14315580027766955\n",
      "Average validation loss: 0.1428541997409461\n",
      "Training epoch 777...\n",
      "\n",
      "Train Epoch: 777 [0/8000 (0%)]\tBatch Loss: 0.141068\tLearning Rate (w_theta): 0.000500\t TIME:2960.3s\n",
      "\t\t\t\tDisc: 0.046562\t\tSpars: 0.094506\n",
      "\t TVw: -0.554078 | TVb: -2.054449 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 777 [4000/8000 (50%)]\tBatch Loss: 0.143941\tLearning Rate (w_theta): 0.000500\t TIME:2961.8s\n",
      "\t\t\t\tDisc: 0.046162\t\tSpars: 0.097779\n",
      "\t TVw: -0.554077 | TVb: -2.054448 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 777...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1431501252971581\n",
      "Average validation loss: 0.14284782695533996\n",
      "Training epoch 778...\n",
      "\n",
      "Train Epoch: 778 [0/8000 (0%)]\tBatch Loss: 0.144659\tLearning Rate (w_theta): 0.000500\t TIME:2964.2s\n",
      "\t\t\t\tDisc: 0.047707\t\tSpars: 0.096952\n",
      "\t TVw: -0.554077 | TVb: -2.054447 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 778 [4000/8000 (50%)]\tBatch Loss: 0.139510\tLearning Rate (w_theta): 0.000500\t TIME:2965.6s\n",
      "\t\t\t\tDisc: 0.045554\t\tSpars: 0.093956\n",
      "\t TVw: -0.554076 | TVb: -2.054446 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 778...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14314375035136273\n",
      "Average validation loss: 0.1428418119547196\n",
      "Training epoch 779...\n",
      "\n",
      "Train Epoch: 779 [0/8000 (0%)]\tBatch Loss: 0.145240\tLearning Rate (w_theta): 0.000500\t TIME:2967.8s\n",
      "\t\t\t\tDisc: 0.049650\t\tSpars: 0.095590\n",
      "\t TVw: -0.554076 | TVb: -2.054446 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 779 [4000/8000 (50%)]\tBatch Loss: 0.139854\tLearning Rate (w_theta): 0.000500\t TIME:2969.2s\n",
      "\t\t\t\tDisc: 0.046392\t\tSpars: 0.093462\n",
      "\t TVw: -0.554075 | TVb: -2.054445 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 779...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.143137883223184\n",
      "Average validation loss: 0.14283568947184727\n",
      "Training epoch 780...\n",
      "\n",
      "Train Epoch: 780 [0/8000 (0%)]\tBatch Loss: 0.138110\tLearning Rate (w_theta): 0.000500\t TIME:2971.5s\n",
      "\t\t\t\tDisc: 0.046705\t\tSpars: 0.091405\n",
      "\t TVw: -0.554075 | TVb: -2.054444 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 780 [4000/8000 (50%)]\tBatch Loss: 0.144949\tLearning Rate (w_theta): 0.000500\t TIME:2972.9s\n",
      "\t\t\t\tDisc: 0.048004\t\tSpars: 0.096945\n",
      "\t TVw: -0.554074 | TVb: -2.054443 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 780...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1431319249575271\n",
      "Average validation loss: 0.14282952914228356\n",
      "Training epoch 781...\n",
      "\n",
      "Train Epoch: 781 [0/8000 (0%)]\tBatch Loss: 0.144581\tLearning Rate (w_theta): 0.000500\t TIME:2976.5s\n",
      "\t\t\t\tDisc: 0.049490\t\tSpars: 0.095092\n",
      "\t TVw: -0.554074 | TVb: -2.054442 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 781 [4000/8000 (50%)]\tBatch Loss: 0.144588\tLearning Rate (w_theta): 0.000500\t TIME:2978.0s\n",
      "\t\t\t\tDisc: 0.048281\t\tSpars: 0.096307\n",
      "\t TVw: -0.554073 | TVb: -2.054441 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 781...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14312590973550543\n",
      "Average validation loss: 0.14282348288022756\n",
      "Training epoch 782...\n",
      "\n",
      "Train Epoch: 782 [0/8000 (0%)]\tBatch Loss: 0.139206\tLearning Rate (w_theta): 0.000500\t TIME:2980.1s\n",
      "\t\t\t\tDisc: 0.045430\t\tSpars: 0.093776\n",
      "\t TVw: -0.554073 | TVb: -2.054440 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 782 [4000/8000 (50%)]\tBatch Loss: 0.143037\tLearning Rate (w_theta): 0.000500\t TIME:2981.6s\n",
      "\t\t\t\tDisc: 0.045686\t\tSpars: 0.097351\n",
      "\t TVw: -0.554072 | TVb: -2.054439 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 782...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14312001164749688\n",
      "Average validation loss: 0.14281748783146295\n",
      "Training epoch 783...\n",
      "\n",
      "Train Epoch: 783 [0/8000 (0%)]\tBatch Loss: 0.143556\tLearning Rate (w_theta): 0.000500\t TIME:2983.8s\n",
      "\t\t\t\tDisc: 0.047011\t\tSpars: 0.096545\n",
      "\t TVw: -0.554072 | TVb: -2.054438 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 783 [4000/8000 (50%)]\tBatch Loss: 0.137899\tLearning Rate (w_theta): 0.000500\t TIME:2985.2s\n",
      "\t\t\t\tDisc: 0.047019\t\tSpars: 0.090881\n",
      "\t TVw: -0.554071 | TVb: -2.054437 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 783...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14311399822629517\n",
      "Average validation loss: 0.1428116521631811\n",
      "Training epoch 784...\n",
      "\n",
      "Train Epoch: 784 [0/8000 (0%)]\tBatch Loss: 0.139024\tLearning Rate (w_theta): 0.000500\t TIME:2987.5s\n",
      "\t\t\t\tDisc: 0.045461\t\tSpars: 0.093563\n",
      "\t TVw: -0.554071 | TVb: -2.054436 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 784 [4000/8000 (50%)]\tBatch Loss: 0.142663\tLearning Rate (w_theta): 0.000500\t TIME:2988.9s\n",
      "\t\t\t\tDisc: 0.048750\t\tSpars: 0.093913\n",
      "\t TVw: -0.554070 | TVb: -2.054435 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 784...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14310835202568772\n",
      "Average validation loss: 0.14280554396031275\n",
      "Training epoch 785...\n",
      "\n",
      "Train Epoch: 785 [0/8000 (0%)]\tBatch Loss: 0.141968\tLearning Rate (w_theta): 0.000500\t TIME:2991.1s\n",
      "\t\t\t\tDisc: 0.047054\t\tSpars: 0.094914\n",
      "\t TVw: -0.554070 | TVb: -2.054434 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 785 [4000/8000 (50%)]\tBatch Loss: 0.145268\tLearning Rate (w_theta): 0.000500\t TIME:2992.6s\n",
      "\t\t\t\tDisc: 0.048134\t\tSpars: 0.097134\n",
      "\t TVw: -0.554070 | TVb: -2.054433 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 785...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14310236239361795\n",
      "Average validation loss: 0.14279956679961436\n",
      "Training epoch 786...\n",
      "\n",
      "Train Epoch: 786 [0/8000 (0%)]\tBatch Loss: 0.143554\tLearning Rate (w_theta): 0.000500\t TIME:2994.8s\n",
      "\t\t\t\tDisc: 0.047006\t\tSpars: 0.096549\n",
      "\t TVw: -0.554069 | TVb: -2.054432 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 786 [4000/8000 (50%)]\tBatch Loss: 0.141730\tLearning Rate (w_theta): 0.000500\t TIME:2996.2s\n",
      "\t\t\t\tDisc: 0.047457\t\tSpars: 0.094272\n",
      "\t TVw: -0.554069 | TVb: -2.054431 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 786...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14309630492262412\n",
      "Average validation loss: 0.14279389171306056\n",
      "Training epoch 787...\n",
      "\n",
      "Train Epoch: 787 [0/8000 (0%)]\tBatch Loss: 0.143818\tLearning Rate (w_theta): 0.000500\t TIME:2998.4s\n",
      "\t\t\t\tDisc: 0.047374\t\tSpars: 0.096443\n",
      "\t TVw: -0.554068 | TVb: -2.054430 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 787 [4000/8000 (50%)]\tBatch Loss: 0.142258\tLearning Rate (w_theta): 0.000500\t TIME:2999.9s\n",
      "\t\t\t\tDisc: 0.045901\t\tSpars: 0.096357\n",
      "\t TVw: -0.554068 | TVb: -2.054429 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 787...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14309070273212732\n",
      "Average validation loss: 0.14278801978494668\n",
      "Training epoch 788...\n",
      "\n",
      "Train Epoch: 788 [0/8000 (0%)]\tBatch Loss: 0.149518\tLearning Rate (w_theta): 0.000500\t TIME:3002.1s\n",
      "\t\t\t\tDisc: 0.048798\t\tSpars: 0.100720\n",
      "\t TVw: -0.554067 | TVb: -2.054428 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 788 [4000/8000 (50%)]\tBatch Loss: 0.143809\tLearning Rate (w_theta): 0.000500\t TIME:3003.6s\n",
      "\t\t\t\tDisc: 0.049409\t\tSpars: 0.094400\n",
      "\t TVw: -0.554067 | TVb: -2.054427 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 788...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1430849850428078\n",
      "Average validation loss: 0.14278204091033536\n",
      "Training epoch 789...\n",
      "\n",
      "Train Epoch: 789 [0/8000 (0%)]\tBatch Loss: 0.142339\tLearning Rate (w_theta): 0.000500\t TIME:3005.8s\n",
      "\t\t\t\tDisc: 0.047015\t\tSpars: 0.095324\n",
      "\t TVw: -0.554066 | TVb: -2.054426 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 789 [4000/8000 (50%)]\tBatch Loss: 0.145553\tLearning Rate (w_theta): 0.000500\t TIME:3007.2s\n",
      "\t\t\t\tDisc: 0.047976\t\tSpars: 0.097577\n",
      "\t TVw: -0.554066 | TVb: -2.054425 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 789...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14307903170054806\n",
      "Average validation loss: 0.1427762188692654\n",
      "Training epoch 790...\n",
      "\n",
      "Train Epoch: 790 [0/8000 (0%)]\tBatch Loss: 0.138747\tLearning Rate (w_theta): 0.000500\t TIME:3009.6s\n",
      "\t\t\t\tDisc: 0.044550\t\tSpars: 0.094197\n",
      "\t TVw: -0.554065 | TVb: -2.054425 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 790 [4000/8000 (50%)]\tBatch Loss: 0.144755\tLearning Rate (w_theta): 0.000500\t TIME:3011.0s\n",
      "\t\t\t\tDisc: 0.049800\t\tSpars: 0.094955\n",
      "\t TVw: -0.554065 | TVb: -2.054424 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 790...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14307331170839513\n",
      "Average validation loss: 0.14277032268525358\n",
      "Training epoch 791...\n",
      "\n",
      "Train Epoch: 791 [0/8000 (0%)]\tBatch Loss: 0.140158\tLearning Rate (w_theta): 0.000500\t TIME:3014.4s\n",
      "\t\t\t\tDisc: 0.048340\t\tSpars: 0.091817\n",
      "\t TVw: -0.554064 | TVb: -2.054423 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 791 [4000/8000 (50%)]\tBatch Loss: 0.144580\tLearning Rate (w_theta): 0.000500\t TIME:3015.9s\n",
      "\t\t\t\tDisc: 0.045608\t\tSpars: 0.098972\n",
      "\t TVw: -0.554064 | TVb: -2.054422 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 791...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14306741885880997\n",
      "Average validation loss: 0.14276454857220314\n",
      "Training epoch 792...\n",
      "\n",
      "Train Epoch: 792 [0/8000 (0%)]\tBatch Loss: 0.142623\tLearning Rate (w_theta): 0.000500\t TIME:3018.0s\n",
      "\t\t\t\tDisc: 0.047495\t\tSpars: 0.095128\n",
      "\t TVw: -0.554063 | TVb: -2.054421 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 792 [4000/8000 (50%)]\tBatch Loss: 0.141440\tLearning Rate (w_theta): 0.000500\t TIME:3019.5s\n",
      "\t\t\t\tDisc: 0.046613\t\tSpars: 0.094827\n",
      "\t TVw: -0.554063 | TVb: -2.054420 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 792...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14306179729380938\n",
      "Average validation loss: 0.14275856609434245\n",
      "Training epoch 793...\n",
      "\n",
      "Train Epoch: 793 [0/8000 (0%)]\tBatch Loss: 0.144159\tLearning Rate (w_theta): 0.000500\t TIME:3021.7s\n",
      "\t\t\t\tDisc: 0.047314\t\tSpars: 0.096845\n",
      "\t TVw: -0.554062 | TVb: -2.054419 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 793 [4000/8000 (50%)]\tBatch Loss: 0.143170\tLearning Rate (w_theta): 0.000500\t TIME:3023.2s\n",
      "\t\t\t\tDisc: 0.046021\t\tSpars: 0.097149\n",
      "\t TVw: -0.554062 | TVb: -2.054418 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 793...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14305585944750132\n",
      "Average validation loss: 0.1427527931961552\n",
      "Training epoch 794...\n",
      "\n",
      "Train Epoch: 794 [0/8000 (0%)]\tBatch Loss: 0.142573\tLearning Rate (w_theta): 0.000500\t TIME:3025.6s\n",
      "\t\t\t\tDisc: 0.046097\t\tSpars: 0.096476\n",
      "\t TVw: -0.554061 | TVb: -2.054417 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 794 [4000/8000 (50%)]\tBatch Loss: 0.140680\tLearning Rate (w_theta): 0.000500\t TIME:3027.0s\n",
      "\t\t\t\tDisc: 0.047623\t\tSpars: 0.093057\n",
      "\t TVw: -0.554061 | TVb: -2.054416 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 794...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14305025032350793\n",
      "Average validation loss: 0.14274679075107025\n",
      "Training epoch 795...\n",
      "\n",
      "Train Epoch: 795 [0/8000 (0%)]\tBatch Loss: 0.139581\tLearning Rate (w_theta): 0.000500\t TIME:3029.2s\n",
      "\t\t\t\tDisc: 0.046900\t\tSpars: 0.092681\n",
      "\t TVw: -0.554060 | TVb: -2.054415 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 795 [4000/8000 (50%)]\tBatch Loss: 0.145844\tLearning Rate (w_theta): 0.000500\t TIME:3030.6s\n",
      "\t\t\t\tDisc: 0.048351\t\tSpars: 0.097493\n",
      "\t TVw: -0.554060 | TVb: -2.054414 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 795...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14304428859446672\n",
      "Average validation loss: 0.14274099415274752\n",
      "Training epoch 796...\n",
      "\n",
      "Train Epoch: 796 [0/8000 (0%)]\tBatch Loss: 0.143965\tLearning Rate (w_theta): 0.000500\t TIME:3032.8s\n",
      "\t\t\t\tDisc: 0.047094\t\tSpars: 0.096871\n",
      "\t TVw: -0.554060 | TVb: -2.054413 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 796 [4000/8000 (50%)]\tBatch Loss: 0.143729\tLearning Rate (w_theta): 0.000500\t TIME:3034.3s\n",
      "\t\t\t\tDisc: 0.047824\t\tSpars: 0.095905\n",
      "\t TVw: -0.554059 | TVb: -2.054412 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 796...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14303867750552524\n",
      "Average validation loss: 0.14273501060831162\n",
      "Training epoch 797...\n",
      "\n",
      "Train Epoch: 797 [0/8000 (0%)]\tBatch Loss: 0.143738\tLearning Rate (w_theta): 0.000500\t TIME:3036.6s\n",
      "\t\t\t\tDisc: 0.047594\t\tSpars: 0.096145\n",
      "\t TVw: -0.554059 | TVb: -2.054411 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 797 [4000/8000 (50%)]\tBatch Loss: 0.141332\tLearning Rate (w_theta): 0.000500\t TIME:3038.0s\n",
      "\t\t\t\tDisc: 0.046482\t\tSpars: 0.094850\n",
      "\t TVw: -0.554058 | TVb: -2.054410 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 797...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14303282164122536\n",
      "Average validation loss: 0.1427290970227501\n",
      "Training epoch 798...\n",
      "\n",
      "Train Epoch: 798 [0/8000 (0%)]\tBatch Loss: 0.141413\tLearning Rate (w_theta): 0.000500\t TIME:3040.2s\n",
      "\t\t\t\tDisc: 0.047014\t\tSpars: 0.094398\n",
      "\t TVw: -0.554058 | TVb: -2.054409 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 798 [4000/8000 (50%)]\tBatch Loss: 0.142744\tLearning Rate (w_theta): 0.000500\t TIME:3041.6s\n",
      "\t\t\t\tDisc: 0.046675\t\tSpars: 0.096069\n",
      "\t TVw: -0.554057 | TVb: -2.054408 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 798...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14302700795576032\n",
      "Average validation loss: 0.14272325058951135\n",
      "Training epoch 799...\n",
      "\n",
      "Train Epoch: 799 [0/8000 (0%)]\tBatch Loss: 0.142869\tLearning Rate (w_theta): 0.000500\t TIME:3043.8s\n",
      "\t\t\t\tDisc: 0.046679\t\tSpars: 0.096190\n",
      "\t TVw: -0.554057 | TVb: -2.054407 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 799 [4000/8000 (50%)]\tBatch Loss: 0.144119\tLearning Rate (w_theta): 0.000500\t TIME:3045.3s\n",
      "\t\t\t\tDisc: 0.047855\t\tSpars: 0.096264\n",
      "\t TVw: -0.554056 | TVb: -2.054406 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 799...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14302130377228647\n",
      "Average validation loss: 0.14271735144826891\n",
      "Training epoch 800...\n",
      "\n",
      "Train Epoch: 800 [0/8000 (0%)]\tBatch Loss: 0.144923\tLearning Rate (w_theta): 0.000500\t TIME:3047.5s\n",
      "\t\t\t\tDisc: 0.047354\t\tSpars: 0.097569\n",
      "\t TVw: -0.554056 | TVb: -2.054405 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 800 [4000/8000 (50%)]\tBatch Loss: 0.142599\tLearning Rate (w_theta): 0.000500\t TIME:3049.0s\n",
      "\t\t\t\tDisc: 0.047135\t\tSpars: 0.095464\n",
      "\t TVw: -0.554055 | TVb: -2.054404 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 800...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1430154488732976\n",
      "Average validation loss: 0.1427115458838956\n",
      "Training epoch 801...\n",
      "\n",
      "Train Epoch: 801 [0/8000 (0%)]\tBatch Loss: 0.144203\tLearning Rate (w_theta): 0.000500\t TIME:3052.7s\n",
      "\t\t\t\tDisc: 0.047538\t\tSpars: 0.096665\n",
      "\t TVw: -0.554055 | TVb: -2.054404 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 801 [4000/8000 (50%)]\tBatch Loss: 0.146116\tLearning Rate (w_theta): 0.000500\t TIME:3054.1s\n",
      "\t\t\t\tDisc: 0.048469\t\tSpars: 0.097647\n",
      "\t TVw: -0.554054 | TVb: -2.054403 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 801...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1430098358070115\n",
      "Average validation loss: 0.14270557321034416\n",
      "Training epoch 802...\n",
      "\n",
      "Train Epoch: 802 [0/8000 (0%)]\tBatch Loss: 0.143028\tLearning Rate (w_theta): 0.000500\t TIME:3056.3s\n",
      "\t\t\t\tDisc: 0.047245\t\tSpars: 0.095782\n",
      "\t TVw: -0.554054 | TVb: -2.054402 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 802 [4000/8000 (50%)]\tBatch Loss: 0.143463\tLearning Rate (w_theta): 0.000500\t TIME:3057.7s\n",
      "\t\t\t\tDisc: 0.047147\t\tSpars: 0.096315\n",
      "\t TVw: -0.554053 | TVb: -2.054401 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 802...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14300391934908196\n",
      "Average validation loss: 0.1426997458659652\n",
      "Training epoch 803...\n",
      "\n",
      "Train Epoch: 803 [0/8000 (0%)]\tBatch Loss: 0.144179\tLearning Rate (w_theta): 0.000500\t TIME:3059.9s\n",
      "\t\t\t\tDisc: 0.046393\t\tSpars: 0.097787\n",
      "\t TVw: -0.554053 | TVb: -2.054400 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 803 [4000/8000 (50%)]\tBatch Loss: 0.143239\tLearning Rate (w_theta): 0.000500\t TIME:3061.4s\n",
      "\t\t\t\tDisc: 0.046681\t\tSpars: 0.096558\n",
      "\t TVw: -0.554052 | TVb: -2.054399 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 803...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1429981072058939\n",
      "Average validation loss: 0.14269400794242212\n",
      "Training epoch 804...\n",
      "\n",
      "Train Epoch: 804 [0/8000 (0%)]\tBatch Loss: 0.144701\tLearning Rate (w_theta): 0.000500\t TIME:3063.6s\n",
      "\t\t\t\tDisc: 0.046170\t\tSpars: 0.098531\n",
      "\t TVw: -0.554052 | TVb: -2.054398 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 804 [4000/8000 (50%)]\tBatch Loss: 0.143679\tLearning Rate (w_theta): 0.000500\t TIME:3065.0s\n",
      "\t\t\t\tDisc: 0.047095\t\tSpars: 0.096583\n",
      "\t TVw: -0.554051 | TVb: -2.054397 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 804...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14299238521981952\n",
      "Average validation loss: 0.14268829193839008\n",
      "Training epoch 805...\n",
      "\n",
      "Train Epoch: 805 [0/8000 (0%)]\tBatch Loss: 0.143188\tLearning Rate (w_theta): 0.000500\t TIME:3067.3s\n",
      "\t\t\t\tDisc: 0.047613\t\tSpars: 0.095574\n",
      "\t TVw: -0.554051 | TVb: -2.054396 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 805 [4000/8000 (50%)]\tBatch Loss: 0.140062\tLearning Rate (w_theta): 0.000500\t TIME:3068.7s\n",
      "\t\t\t\tDisc: 0.045685\t\tSpars: 0.094377\n",
      "\t TVw: -0.554050 | TVb: -2.054395 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 805...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14298668133473885\n",
      "Average validation loss: 0.142682541293423\n",
      "Training epoch 806...\n",
      "\n",
      "Train Epoch: 806 [0/8000 (0%)]\tBatch Loss: 0.140304\tLearning Rate (w_theta): 0.000500\t TIME:3071.0s\n",
      "\t\t\t\tDisc: 0.046325\t\tSpars: 0.093979\n",
      "\t TVw: -0.554050 | TVb: -2.054394 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 806 [4000/8000 (50%)]\tBatch Loss: 0.144151\tLearning Rate (w_theta): 0.000500\t TIME:3072.4s\n",
      "\t\t\t\tDisc: 0.046729\t\tSpars: 0.097422\n",
      "\t TVw: -0.554049 | TVb: -2.054393 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 806...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14298101233373486\n",
      "Average validation loss: 0.14267670188066328\n",
      "Training epoch 807...\n",
      "\n",
      "Train Epoch: 807 [0/8000 (0%)]\tBatch Loss: 0.142430\tLearning Rate (w_theta): 0.000500\t TIME:3074.6s\n",
      "\t\t\t\tDisc: 0.048475\t\tSpars: 0.093954\n",
      "\t TVw: -0.554049 | TVb: -2.054392 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 807 [4000/8000 (50%)]\tBatch Loss: 0.141780\tLearning Rate (w_theta): 0.000500\t TIME:3076.1s\n",
      "\t\t\t\tDisc: 0.045192\t\tSpars: 0.096588\n",
      "\t TVw: -0.554049 | TVb: -2.054391 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 807...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14297530446998039\n",
      "Average validation loss: 0.1426708227568787\n",
      "Training epoch 808...\n",
      "\n",
      "Train Epoch: 808 [0/8000 (0%)]\tBatch Loss: 0.144493\tLearning Rate (w_theta): 0.000500\t TIME:3078.5s\n",
      "\t\t\t\tDisc: 0.047407\t\tSpars: 0.097086\n",
      "\t TVw: -0.554048 | TVb: -2.054390 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 808 [4000/8000 (50%)]\tBatch Loss: 0.142824\tLearning Rate (w_theta): 0.000500\t TIME:3079.9s\n",
      "\t\t\t\tDisc: 0.048406\t\tSpars: 0.094418\n",
      "\t TVw: -0.554048 | TVb: -2.054389 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 808...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14296952673066116\n",
      "Average validation loss: 0.14266495783827202\n",
      "Training epoch 809...\n",
      "\n",
      "Train Epoch: 809 [0/8000 (0%)]\tBatch Loss: 0.142318\tLearning Rate (w_theta): 0.000500\t TIME:3082.1s\n",
      "\t\t\t\tDisc: 0.047698\t\tSpars: 0.094620\n",
      "\t TVw: -0.554047 | TVb: -2.054388 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 809 [4000/8000 (50%)]\tBatch Loss: 0.144820\tLearning Rate (w_theta): 0.000500\t TIME:3083.6s\n",
      "\t\t\t\tDisc: 0.048187\t\tSpars: 0.096633\n",
      "\t TVw: -0.554047 | TVb: -2.054387 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 809...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1429638036307013\n",
      "Average validation loss: 0.1426590728163638\n",
      "Training epoch 810...\n",
      "\n",
      "Train Epoch: 810 [0/8000 (0%)]\tBatch Loss: 0.141384\tLearning Rate (w_theta): 0.000500\t TIME:3085.8s\n",
      "\t\t\t\tDisc: 0.044885\t\tSpars: 0.096499\n",
      "\t TVw: -0.554046 | TVb: -2.054386 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 810 [4000/8000 (50%)]\tBatch Loss: 0.147038\tLearning Rate (w_theta): 0.000500\t TIME:3087.2s\n",
      "\t\t\t\tDisc: 0.047368\t\tSpars: 0.099670\n",
      "\t TVw: -0.554046 | TVb: -2.054385 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 810...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14295790919988507\n",
      "Average validation loss: 0.1426533890102601\n",
      "Training epoch 811...\n",
      "\n",
      "Train Epoch: 811 [0/8000 (0%)]\tBatch Loss: 0.142543\tLearning Rate (w_theta): 0.000500\t TIME:3090.6s\n",
      "\t\t\t\tDisc: 0.048091\t\tSpars: 0.094452\n",
      "\t TVw: -0.554045 | TVb: -2.054384 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 811 [4000/8000 (50%)]\tBatch Loss: 0.138747\tLearning Rate (w_theta): 0.000500\t TIME:3092.2s\n",
      "\t\t\t\tDisc: 0.047362\t\tSpars: 0.091385\n",
      "\t TVw: -0.554045 | TVb: -2.054384 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 811...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1429523394200906\n",
      "Average validation loss: 0.14264754046738518\n",
      "Training epoch 812...\n",
      "\n",
      "Train Epoch: 812 [0/8000 (0%)]\tBatch Loss: 0.144005\tLearning Rate (w_theta): 0.000500\t TIME:3094.4s\n",
      "\t\t\t\tDisc: 0.050193\t\tSpars: 0.093813\n",
      "\t TVw: -0.554044 | TVb: -2.054383 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 812 [4000/8000 (50%)]\tBatch Loss: 0.144547\tLearning Rate (w_theta): 0.000500\t TIME:3095.9s\n",
      "\t\t\t\tDisc: 0.045972\t\tSpars: 0.098575\n",
      "\t TVw: -0.554044 | TVb: -2.054382 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 812...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14294663160567345\n",
      "Average validation loss: 0.14264171945695606\n",
      "Training epoch 813...\n",
      "\n",
      "Train Epoch: 813 [0/8000 (0%)]\tBatch Loss: 0.147484\tLearning Rate (w_theta): 0.000500\t TIME:3098.1s\n",
      "\t\t\t\tDisc: 0.047769\t\tSpars: 0.099715\n",
      "\t TVw: -0.554043 | TVb: -2.054381 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 813 [4000/8000 (50%)]\tBatch Loss: 0.140302\tLearning Rate (w_theta): 0.000500\t TIME:3099.6s\n",
      "\t\t\t\tDisc: 0.047741\t\tSpars: 0.092561\n",
      "\t TVw: -0.554043 | TVb: -2.054380 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 813...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14294081775349196\n",
      "Average validation loss: 0.14263608353587612\n",
      "Training epoch 814...\n",
      "\n",
      "Train Epoch: 814 [0/8000 (0%)]\tBatch Loss: 0.148309\tLearning Rate (w_theta): 0.000500\t TIME:3101.8s\n",
      "\t\t\t\tDisc: 0.048790\t\tSpars: 0.099519\n",
      "\t TVw: -0.554042 | TVb: -2.054379 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 814 [4000/8000 (50%)]\tBatch Loss: 0.144678\tLearning Rate (w_theta): 0.000500\t TIME:3103.3s\n",
      "\t\t\t\tDisc: 0.048410\t\tSpars: 0.096267\n",
      "\t TVw: -0.554042 | TVb: -2.054378 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 814...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1429353286905925\n",
      "Average validation loss: 0.14263020706279753\n",
      "Training epoch 815...\n",
      "\n",
      "Train Epoch: 815 [0/8000 (0%)]\tBatch Loss: 0.143876\tLearning Rate (w_theta): 0.000500\t TIME:3105.5s\n",
      "\t\t\t\tDisc: 0.048536\t\tSpars: 0.095340\n",
      "\t TVw: -0.554041 | TVb: -2.054377 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 815 [4000/8000 (50%)]\tBatch Loss: 0.144192\tLearning Rate (w_theta): 0.000500\t TIME:3106.9s\n",
      "\t\t\t\tDisc: 0.045900\t\tSpars: 0.098292\n",
      "\t TVw: -0.554041 | TVb: -2.054376 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 815...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14292952308962378\n",
      "Average validation loss: 0.14262444296244775\n",
      "Training epoch 816...\n",
      "\n",
      "Train Epoch: 816 [0/8000 (0%)]\tBatch Loss: 0.139013\tLearning Rate (w_theta): 0.000500\t TIME:3109.1s\n",
      "\t\t\t\tDisc: 0.045390\t\tSpars: 0.093623\n",
      "\t TVw: -0.554040 | TVb: -2.054375 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 816 [4000/8000 (50%)]\tBatch Loss: 0.142300\tLearning Rate (w_theta): 0.000500\t TIME:3110.6s\n",
      "\t\t\t\tDisc: 0.047836\t\tSpars: 0.094463\n",
      "\t TVw: -0.554040 | TVb: -2.054374 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 816...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14292380853575523\n",
      "Average validation loss: 0.14261876429591763\n",
      "Training epoch 817...\n",
      "\n",
      "Train Epoch: 817 [0/8000 (0%)]\tBatch Loss: 0.142932\tLearning Rate (w_theta): 0.000500\t TIME:3112.8s\n",
      "\t\t\t\tDisc: 0.048480\t\tSpars: 0.094452\n",
      "\t TVw: -0.554039 | TVb: -2.054373 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 817 [4000/8000 (50%)]\tBatch Loss: 0.140692\tLearning Rate (w_theta): 0.000500\t TIME:3114.2s\n",
      "\t\t\t\tDisc: 0.046079\t\tSpars: 0.094613\n",
      "\t TVw: -0.554039 | TVb: -2.054372 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 817...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14291813968438555\n",
      "Average validation loss: 0.14261308263648875\n",
      "Training epoch 818...\n",
      "\n",
      "Train Epoch: 818 [0/8000 (0%)]\tBatch Loss: 0.143643\tLearning Rate (w_theta): 0.000500\t TIME:3116.4s\n",
      "\t\t\t\tDisc: 0.047457\t\tSpars: 0.096186\n",
      "\t TVw: -0.554039 | TVb: -2.054371 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 818 [4000/8000 (50%)]\tBatch Loss: 0.142580\tLearning Rate (w_theta): 0.000500\t TIME:3117.9s\n",
      "\t\t\t\tDisc: 0.048528\t\tSpars: 0.094051\n",
      "\t TVw: -0.554038 | TVb: -2.054370 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 818...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14291250533686714\n",
      "Average validation loss: 0.1426073716828594\n",
      "Training epoch 819...\n",
      "\n",
      "Train Epoch: 819 [0/8000 (0%)]\tBatch Loss: 0.142317\tLearning Rate (w_theta): 0.000500\t TIME:3120.1s\n",
      "\t\t\t\tDisc: 0.045917\t\tSpars: 0.096400\n",
      "\t TVw: -0.554038 | TVb: -2.054369 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 819 [4000/8000 (50%)]\tBatch Loss: 0.146610\tLearning Rate (w_theta): 0.000500\t TIME:3121.5s\n",
      "\t\t\t\tDisc: 0.048111\t\tSpars: 0.098500\n",
      "\t TVw: -0.554037 | TVb: -2.054368 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 819...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14290688938103094\n",
      "Average validation loss: 0.14260158529425476\n",
      "Training epoch 820...\n",
      "\n",
      "Train Epoch: 820 [0/8000 (0%)]\tBatch Loss: 0.140931\tLearning Rate (w_theta): 0.000500\t TIME:3123.7s\n",
      "\t\t\t\tDisc: 0.046913\t\tSpars: 0.094017\n",
      "\t TVw: -0.554037 | TVb: -2.054367 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 820 [4000/8000 (50%)]\tBatch Loss: 0.144222\tLearning Rate (w_theta): 0.000500\t TIME:3125.1s\n",
      "\t\t\t\tDisc: 0.048319\t\tSpars: 0.095903\n",
      "\t TVw: -0.554036 | TVb: -2.054366 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 820...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14290122633742197\n",
      "Average validation loss: 0.14259579415336313\n",
      "Training epoch 821...\n",
      "\n",
      "Train Epoch: 821 [0/8000 (0%)]\tBatch Loss: 0.138527\tLearning Rate (w_theta): 0.000500\t TIME:3128.5s\n",
      "\t\t\t\tDisc: 0.045525\t\tSpars: 0.093002\n",
      "\t TVw: -0.554036 | TVb: -2.054365 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 821 [4000/8000 (50%)]\tBatch Loss: 0.145790\tLearning Rate (w_theta): 0.000500\t TIME:3129.9s\n",
      "\t\t\t\tDisc: 0.048091\t\tSpars: 0.097699\n",
      "\t TVw: -0.554035 | TVb: -2.054364 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 821...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14289548990495146\n",
      "Average validation loss: 0.1425900828743429\n",
      "Training epoch 822...\n",
      "\n",
      "Train Epoch: 822 [0/8000 (0%)]\tBatch Loss: 0.140284\tLearning Rate (w_theta): 0.000500\t TIME:3132.2s\n",
      "\t\t\t\tDisc: 0.047817\t\tSpars: 0.092467\n",
      "\t TVw: -0.554035 | TVb: -2.054363 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 822 [4000/8000 (50%)]\tBatch Loss: 0.147039\tLearning Rate (w_theta): 0.000500\t TIME:3133.6s\n",
      "\t\t\t\tDisc: 0.046900\t\tSpars: 0.100139\n",
      "\t TVw: -0.554034 | TVb: -2.054363 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 822...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14288983547610462\n",
      "Average validation loss: 0.1425844099600465\n",
      "Training epoch 823...\n",
      "\n",
      "Train Epoch: 823 [0/8000 (0%)]\tBatch Loss: 0.142237\tLearning Rate (w_theta): 0.000500\t TIME:3135.8s\n",
      "\t\t\t\tDisc: 0.045696\t\tSpars: 0.096541\n",
      "\t TVw: -0.554034 | TVb: -2.054362 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 823 [4000/8000 (50%)]\tBatch Loss: 0.145926\tLearning Rate (w_theta): 0.000500\t TIME:3137.3s\n",
      "\t\t\t\tDisc: 0.048545\t\tSpars: 0.097381\n",
      "\t TVw: -0.554033 | TVb: -2.054361 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 823...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14288440659402346\n",
      "Average validation loss: 0.14257849032175818\n",
      "Training epoch 824...\n",
      "\n",
      "Train Epoch: 824 [0/8000 (0%)]\tBatch Loss: 0.145644\tLearning Rate (w_theta): 0.000500\t TIME:3139.6s\n",
      "\t\t\t\tDisc: 0.046311\t\tSpars: 0.099333\n",
      "\t TVw: -0.554033 | TVb: -2.054360 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 824 [4000/8000 (50%)]\tBatch Loss: 0.141691\tLearning Rate (w_theta): 0.000500\t TIME:3141.1s\n",
      "\t\t\t\tDisc: 0.047879\t\tSpars: 0.093812\n",
      "\t TVw: -0.554032 | TVb: -2.054359 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 824...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1428785223990931\n",
      "Average validation loss: 0.14257287494369875\n",
      "Training epoch 825...\n",
      "\n",
      "Train Epoch: 825 [0/8000 (0%)]\tBatch Loss: 0.142662\tLearning Rate (w_theta): 0.000500\t TIME:3143.3s\n",
      "\t\t\t\tDisc: 0.047422\t\tSpars: 0.095240\n",
      "\t TVw: -0.554032 | TVb: -2.054358 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 825 [4000/8000 (50%)]\tBatch Loss: 0.139281\tLearning Rate (w_theta): 0.000500\t TIME:3144.8s\n",
      "\t\t\t\tDisc: 0.045648\t\tSpars: 0.093633\n",
      "\t TVw: -0.554031 | TVb: -2.054357 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 825...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1428729495104779\n",
      "Average validation loss: 0.14256719712684546\n",
      "Training epoch 826...\n",
      "\n",
      "Train Epoch: 826 [0/8000 (0%)]\tBatch Loss: 0.140815\tLearning Rate (w_theta): 0.000500\t TIME:3147.0s\n",
      "\t\t\t\tDisc: 0.047869\t\tSpars: 0.092946\n",
      "\t TVw: -0.554031 | TVb: -2.054356 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 826 [4000/8000 (50%)]\tBatch Loss: 0.139593\tLearning Rate (w_theta): 0.000500\t TIME:3148.4s\n",
      "\t\t\t\tDisc: 0.048870\t\tSpars: 0.090723\n",
      "\t TVw: -0.554030 | TVb: -2.054355 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 826...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14286732295028579\n",
      "Average validation loss: 0.14256149831602755\n",
      "Training epoch 827...\n",
      "\n",
      "Train Epoch: 827 [0/8000 (0%)]\tBatch Loss: 0.139156\tLearning Rate (w_theta): 0.000500\t TIME:3150.6s\n",
      "\t\t\t\tDisc: 0.047178\t\tSpars: 0.091978\n",
      "\t TVw: -0.554030 | TVb: -2.054354 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 827 [4000/8000 (50%)]\tBatch Loss: 0.142200\tLearning Rate (w_theta): 0.000500\t TIME:3152.1s\n",
      "\t\t\t\tDisc: 0.046688\t\tSpars: 0.095512\n",
      "\t TVw: -0.554029 | TVb: -2.054353 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 827...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14286164279487237\n",
      "Average validation loss: 0.14255587758511296\n",
      "Training epoch 828...\n",
      "\n",
      "Train Epoch: 828 [0/8000 (0%)]\tBatch Loss: 0.145391\tLearning Rate (w_theta): 0.000500\t TIME:3154.2s\n",
      "\t\t\t\tDisc: 0.046815\t\tSpars: 0.098577\n",
      "\t TVw: -0.554029 | TVb: -2.054352 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 828 [4000/8000 (50%)]\tBatch Loss: 0.145208\tLearning Rate (w_theta): 0.000500\t TIME:3155.7s\n",
      "\t\t\t\tDisc: 0.047660\t\tSpars: 0.097548\n",
      "\t TVw: -0.554029 | TVb: -2.054351 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 828...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14285611403126347\n",
      "Average validation loss: 0.142550104550226\n",
      "Training epoch 829...\n",
      "\n",
      "Train Epoch: 829 [0/8000 (0%)]\tBatch Loss: 0.140333\tLearning Rate (w_theta): 0.000500\t TIME:3157.9s\n",
      "\t\t\t\tDisc: 0.044600\t\tSpars: 0.095734\n",
      "\t TVw: -0.554028 | TVb: -2.054350 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 829 [4000/8000 (50%)]\tBatch Loss: 0.139227\tLearning Rate (w_theta): 0.000500\t TIME:3159.3s\n",
      "\t\t\t\tDisc: 0.045376\t\tSpars: 0.093852\n",
      "\t TVw: -0.554028 | TVb: -2.054349 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 829...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14285032038242954\n",
      "Average validation loss: 0.1425444768728843\n",
      "Training epoch 830...\n",
      "\n",
      "Train Epoch: 830 [0/8000 (0%)]\tBatch Loss: 0.144841\tLearning Rate (w_theta): 0.000500\t TIME:3161.5s\n",
      "\t\t\t\tDisc: 0.048881\t\tSpars: 0.095960\n",
      "\t TVw: -0.554027 | TVb: -2.054348 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 830 [4000/8000 (50%)]\tBatch Loss: 0.144435\tLearning Rate (w_theta): 0.000500\t TIME:3163.2s\n",
      "\t\t\t\tDisc: 0.046406\t\tSpars: 0.098028\n",
      "\t TVw: -0.554027 | TVb: -2.054347 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 830...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14284481054552767\n",
      "Average validation loss: 0.14253867977418344\n",
      "Training epoch 831...\n",
      "\n",
      "Train Epoch: 831 [0/8000 (0%)]\tBatch Loss: 0.140936\tLearning Rate (w_theta): 0.000500\t TIME:3167.5s\n",
      "\t\t\t\tDisc: 0.047009\t\tSpars: 0.093927\n",
      "\t TVw: -0.554026 | TVb: -2.054346 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 831 [4000/8000 (50%)]\tBatch Loss: 0.143450\tLearning Rate (w_theta): 0.000500\t TIME:3169.0s\n",
      "\t\t\t\tDisc: 0.047881\t\tSpars: 0.095569\n",
      "\t TVw: -0.554026 | TVb: -2.054345 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 831...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14283906133436106\n",
      "Average validation loss: 0.14253294318860288\n",
      "Training epoch 832...\n",
      "\n",
      "Train Epoch: 832 [0/8000 (0%)]\tBatch Loss: 0.147910\tLearning Rate (w_theta): 0.000500\t TIME:3171.1s\n",
      "\t\t\t\tDisc: 0.051398\t\tSpars: 0.096511\n",
      "\t TVw: -0.554025 | TVb: -2.054344 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 832 [4000/8000 (50%)]\tBatch Loss: 0.142539\tLearning Rate (w_theta): 0.000500\t TIME:3172.6s\n",
      "\t\t\t\tDisc: 0.047761\t\tSpars: 0.094778\n",
      "\t TVw: -0.554025 | TVb: -2.054343 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 832...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14283330854024862\n",
      "Average validation loss: 0.14252731845803765\n",
      "Training epoch 833...\n",
      "\n",
      "Train Epoch: 833 [0/8000 (0%)]\tBatch Loss: 0.149640\tLearning Rate (w_theta): 0.000500\t TIME:3174.8s\n",
      "\t\t\t\tDisc: 0.049030\t\tSpars: 0.100610\n",
      "\t TVw: -0.554024 | TVb: -2.054343 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 833 [4000/8000 (50%)]\tBatch Loss: 0.140192\tLearning Rate (w_theta): 0.000500\t TIME:3176.3s\n",
      "\t\t\t\tDisc: 0.046938\t\tSpars: 0.093254\n",
      "\t TVw: -0.554024 | TVb: -2.054342 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 833...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14282779367001008\n",
      "Average validation loss: 0.14252150909431854\n",
      "Training epoch 834...\n",
      "\n",
      "Train Epoch: 834 [0/8000 (0%)]\tBatch Loss: 0.143078\tLearning Rate (w_theta): 0.000500\t TIME:3178.6s\n",
      "\t\t\t\tDisc: 0.047689\t\tSpars: 0.095390\n",
      "\t TVw: -0.554023 | TVb: -2.054341 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 834 [4000/8000 (50%)]\tBatch Loss: 0.143239\tLearning Rate (w_theta): 0.000500\t TIME:3180.1s\n",
      "\t\t\t\tDisc: 0.047873\t\tSpars: 0.095366\n",
      "\t TVw: -0.554023 | TVb: -2.054340 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 834...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14282188621930075\n",
      "Average validation loss: 0.142515966206857\n",
      "Training epoch 835...\n",
      "\n",
      "Train Epoch: 835 [0/8000 (0%)]\tBatch Loss: 0.140219\tLearning Rate (w_theta): 0.000500\t TIME:3182.3s\n",
      "\t\t\t\tDisc: 0.046142\t\tSpars: 0.094077\n",
      "\t TVw: -0.554022 | TVb: -2.054339 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 835 [4000/8000 (50%)]\tBatch Loss: 0.140701\tLearning Rate (w_theta): 0.000500\t TIME:3183.8s\n",
      "\t\t\t\tDisc: 0.045705\t\tSpars: 0.094996\n",
      "\t TVw: -0.554022 | TVb: -2.054338 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 835...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14281643481236836\n",
      "Average validation loss: 0.14251015998330552\n",
      "Training epoch 836...\n",
      "\n",
      "Train Epoch: 836 [0/8000 (0%)]\tBatch Loss: 0.141281\tLearning Rate (w_theta): 0.000500\t TIME:3186.0s\n",
      "\t\t\t\tDisc: 0.046228\t\tSpars: 0.095054\n",
      "\t TVw: -0.554021 | TVb: -2.054337 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 836 [4000/8000 (50%)]\tBatch Loss: 0.139190\tLearning Rate (w_theta): 0.000500\t TIME:3187.5s\n",
      "\t\t\t\tDisc: 0.045411\t\tSpars: 0.093779\n",
      "\t TVw: -0.554021 | TVb: -2.054336 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 836...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14281058787784484\n",
      "Average validation loss: 0.1425045635905497\n",
      "Training epoch 837...\n",
      "\n",
      "Train Epoch: 837 [0/8000 (0%)]\tBatch Loss: 0.142931\tLearning Rate (w_theta): 0.000500\t TIME:3189.8s\n",
      "\t\t\t\tDisc: 0.047131\t\tSpars: 0.095801\n",
      "\t TVw: -0.554020 | TVb: -2.054335 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 837 [4000/8000 (50%)]\tBatch Loss: 0.142747\tLearning Rate (w_theta): 0.000500\t TIME:3191.2s\n",
      "\t\t\t\tDisc: 0.046955\t\tSpars: 0.095793\n",
      "\t TVw: -0.554020 | TVb: -2.054334 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 837...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14280499955086853\n",
      "Average validation loss: 0.1424988357128387\n",
      "Training epoch 838...\n",
      "\n",
      "Train Epoch: 838 [0/8000 (0%)]\tBatch Loss: 0.145360\tLearning Rate (w_theta): 0.000500\t TIME:3193.7s\n",
      "\t\t\t\tDisc: 0.045950\t\tSpars: 0.099410\n",
      "\t TVw: -0.554019 | TVb: -2.054333 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 838 [4000/8000 (50%)]\tBatch Loss: 0.143983\tLearning Rate (w_theta): 0.000500\t TIME:3195.2s\n",
      "\t\t\t\tDisc: 0.047694\t\tSpars: 0.096289\n",
      "\t TVw: -0.554019 | TVb: -2.054332 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 838...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14279921919213867\n",
      "Average validation loss: 0.14249319210865957\n",
      "Training epoch 839...\n",
      "\n",
      "Train Epoch: 839 [0/8000 (0%)]\tBatch Loss: 0.145420\tLearning Rate (w_theta): 0.000500\t TIME:3197.4s\n",
      "\t\t\t\tDisc: 0.047927\t\tSpars: 0.097493\n",
      "\t TVw: -0.554018 | TVb: -2.054331 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 839 [4000/8000 (50%)]\tBatch Loss: 0.139645\tLearning Rate (w_theta): 0.000500\t TIME:3198.9s\n",
      "\t\t\t\tDisc: 0.045548\t\tSpars: 0.094097\n",
      "\t TVw: -0.554018 | TVb: -2.054330 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 839...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14279371242065647\n",
      "Average validation loss: 0.1424873560607316\n",
      "Training epoch 840...\n",
      "\n",
      "Train Epoch: 840 [0/8000 (0%)]\tBatch Loss: 0.143813\tLearning Rate (w_theta): 0.000500\t TIME:3201.1s\n",
      "\t\t\t\tDisc: 0.049870\t\tSpars: 0.093943\n",
      "\t TVw: -0.554018 | TVb: -2.054329 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 840 [4000/8000 (50%)]\tBatch Loss: 0.142165\tLearning Rate (w_theta): 0.000500\t TIME:3202.5s\n",
      "\t\t\t\tDisc: 0.047122\t\tSpars: 0.095042\n",
      "\t TVw: -0.554017 | TVb: -2.054328 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 840...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.1427877634850993\n",
      "Average validation loss: 0.14248179300492547\n",
      "Training epoch 841...\n",
      "\n",
      "Train Epoch: 841 [0/8000 (0%)]\tBatch Loss: 0.141339\tLearning Rate (w_theta): 0.000500\t TIME:3206.0s\n",
      "\t\t\t\tDisc: 0.048747\t\tSpars: 0.092592\n",
      "\t TVw: -0.554017 | TVb: -2.054327 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 841 [4000/8000 (50%)]\tBatch Loss: 0.143552\tLearning Rate (w_theta): 0.000500\t TIME:3207.4s\n",
      "\t\t\t\tDisc: 0.046764\t\tSpars: 0.096788\n",
      "\t TVw: -0.554016 | TVb: -2.054326 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 841...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14278204122857266\n",
      "Average validation loss: 0.14247634498504214\n",
      "Training epoch 842...\n",
      "\n",
      "Train Epoch: 842 [0/8000 (0%)]\tBatch Loss: 0.140917\tLearning Rate (w_theta): 0.000500\t TIME:3209.7s\n",
      "\t\t\t\tDisc: 0.044756\t\tSpars: 0.096161\n",
      "\t TVw: -0.554016 | TVb: -2.054325 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 842 [4000/8000 (50%)]\tBatch Loss: 0.143311\tLearning Rate (w_theta): 0.000500\t TIME:3211.5s\n",
      "\t\t\t\tDisc: 0.048401\t\tSpars: 0.094910\n",
      "\t TVw: -0.554015 | TVb: -2.054324 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 842...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14277653627573775\n",
      "Average validation loss: 0.1424706822812266\n",
      "Training epoch 843...\n",
      "\n",
      "Train Epoch: 843 [0/8000 (0%)]\tBatch Loss: 0.143142\tLearning Rate (w_theta): 0.000500\t TIME:3213.7s\n",
      "\t\t\t\tDisc: 0.048894\t\tSpars: 0.094248\n",
      "\t TVw: -0.554015 | TVb: -2.054323 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 843 [4000/8000 (50%)]\tBatch Loss: 0.142865\tLearning Rate (w_theta): 0.000500\t TIME:3215.2s\n",
      "\t\t\t\tDisc: 0.047526\t\tSpars: 0.095340\n",
      "\t TVw: -0.554014 | TVb: -2.054322 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 843...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14277081790280144\n",
      "Average validation loss: 0.1424650454412051\n",
      "Training epoch 844...\n",
      "\n",
      "Train Epoch: 844 [0/8000 (0%)]\tBatch Loss: 0.140951\tLearning Rate (w_theta): 0.000500\t TIME:3217.4s\n",
      "\t\t\t\tDisc: 0.047085\t\tSpars: 0.093865\n",
      "\t TVw: -0.554014 | TVb: -2.054322 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 844 [4000/8000 (50%)]\tBatch Loss: 0.145570\tLearning Rate (w_theta): 0.000500\t TIME:3218.9s\n",
      "\t\t\t\tDisc: 0.046910\t\tSpars: 0.098661\n",
      "\t TVw: -0.554013 | TVb: -2.054321 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "Validating epoch 844...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.14276514605495216\n",
      "Average validation loss: 0.142459374372391\n",
      "Training epoch 845...\n",
      "\n",
      "Train Epoch: 845 [0/8000 (0%)]\tBatch Loss: 0.141217\tLearning Rate (w_theta): 0.000500\t TIME:3221.1s\n",
      "\t\t\t\tDisc: 0.046806\t\tSpars: 0.094412\n",
      "\t TVw: -0.554013 | TVb: -2.054320 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n",
      "\n",
      "Train Epoch: 845 [4000/8000 (50%)]\tBatch Loss: 0.143901\tLearning Rate (w_theta): 0.000500\t TIME:3222.6s\n",
      "\t\t\t\tDisc: 0.047540\t\tSpars: 0.096362\n",
      "\t TVw: -0.554012 | TVb: -2.054319 | GSw: -0.243538 | GSb: 0.056447 | TSUw: 0.456186 | TSUb: 0.043255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\galiger.gergo\\AppData\\Local\\Temp\\ipykernel_73536\\3719546261.py\", line 1, in <module>\n",
      "    solver.train()\n",
      "  File \"C:\\Users\\galiger.gergo\\Desktop\\ecg-denoising\\workspace\\src\\fistanet\\solver.py\", line 263, in train\n",
      "    self.train_losses.append(loss.item())\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1543, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1501, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 755, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\ntpath.py\", line 664, in realpath\n",
      "    if _getfinalpathname(spath) == path:\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\galiger.gergo\\AppData\\Local\\Temp\\ipykernel_73536\\3719546261.py\", line 1, in <module>\n",
      "    solver.train()\n",
      "  File \"C:\\Users\\galiger.gergo\\Desktop\\ecg-denoising\\workspace\\src\\fistanet\\solver.py\", line 263, in train\n",
      "    self.train_losses.append(loss.item())\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2079, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1543, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1501, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 755, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\ntpath.py\", line 647, in realpath\n",
      "    path = _getfinalpathname(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\galiger.gergo\\AppData\\Local\\Temp\\ipykernel_73536\\3719546261.py\", line 1, in <module>\n",
      "    solver.train()\n",
      "  File \"C:\\Users\\galiger.gergo\\Desktop\\ecg-denoising\\workspace\\src\\fistanet\\solver.py\", line 263, in train\n",
      "    self.train_losses.append(loss.item())\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2079, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3396, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2079, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1142, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1543, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1501, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 755, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\ntpath.py\", line 664, in realpath\n",
      "    if _getfinalpathname(spath) == path:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504e485-5480-4fae-a0e1-4382092f3fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a993b5-8bff-4192-8e0a-389d302c2c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2186b40-3acc-4d32-9620-ae8dac4a8731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ecgenv)",
   "language": "python",
   "name": "ecgenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
