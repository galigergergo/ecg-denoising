{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7baaefd-888e-4894-9776-d7291899f1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.fistanet.M5FISTANet import FISTANet\n",
    "from src.fistanet.M5FISTANetNoST import FISTANetNoST\n",
    "from src.fistanet.loader import DataSplit\n",
    "from src.fistanet.solver import Solver\n",
    "from os.path import join as pjoin\n",
    "from torchsummary import summary\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9846d1b1-46fe-471c-b4a9-93e7a8ce0ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data'\n",
    "DATA_FILE_GEN = 'generated/BW_master_10000_2024-04-07-12-43-32.pkl'\n",
    "DATA_FILE_SIGS = 'steinbrinker/testing_data_mvg_avg.npy'\n",
    "DATA_FILE_BW = 'mit-bih/bw'\n",
    "DATA_FILE_GAUSS = 'generated/gaussian_noise.npy'\n",
    "# DATA_FILE_BPDN = 'generated/BW_alphas-BPDN_10000_2024-04-07-12-43-32.npy'\n",
    "DATA_FILE_BPDN = 'generated/BW_alphas-BPDN-1iters_10000_2024-04-07-12-43-32.npy'\n",
    "DICT_FILE_BW = 'steinbrinker/dictionary_BW_real_data.npy'\n",
    "NOISE_TYPE = 'bw'\n",
    "if NOISE_TYPE == 'bw':\n",
    "    DATA_FILE_NOISE = DATA_FILE_BW\n",
    "elif NOISE_TYPE == 'gauss':\n",
    "    DATA_FILE_NOISE = DATA_FILE_GAUSS\n",
    "DATA_SIZE = 10000\n",
    "BATCH_SIZE = 1000\n",
    "TVT_SPLIT = {\n",
    "    'train': 80,\n",
    "    'valid': 10,\n",
    "    'test': 10\n",
    "}\n",
    "\n",
    "FNET_LAYER_NO = 4\n",
    "FNET_FEATURE_NO = 16\n",
    "LAMBDA_SP_LOSS = 1\n",
    "LAMBDA_SYM_LOSS = 1e-1\n",
    "\n",
    "EPOCH_NO = 2000\n",
    "TEST_EPOCH = 10001\n",
    "LR_DEC_AFTER = 10000\n",
    "LR_DEC_EVERY = 10\n",
    "START_EPOCH = 5000\n",
    "START_RUN = '2024-05-03-18-04-18'\n",
    "LOG_INTERVAL = 4\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "\n",
    "\n",
    "# DATA_FILE_GEN = 'generated/BW_master_7999-8000_2024-04-07-12-43-32.pkl'\n",
    "# DATA_SIZE = 2\n",
    "# BATCH_SIZE = 1\n",
    "# TVT_SPLIT = {\n",
    "#     'train': 50,\n",
    "#     'valid': 50,\n",
    "#     'test': 0\n",
    "# }\n",
    "# FNET_LAYER_NO = 4\n",
    "# FNET_FEATURE_NO = 16\n",
    "# LEARNING_RATE = 1e-3\n",
    "# LAMBDA_SP_LOSS = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74e188c4-1bdd-43bd-8fad-aa3c615aefbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ldr, val_ldr, tst_ldr = DataSplit(DATA_DIR, NOISE_TYPE, DATA_FILE_GEN, DATA_FILE_SIGS, DATA_FILE_NOISE, DATA_FILE_BPDN, TVT_SPLIT, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45bcd124-d0c4-4140-8607-2ed4ff8a8003",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36276fd7-c4b4-49e2-859c-6d09d87aae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Psi = np.load(pjoin(DATA_DIR, DICT_FILE_BW))\n",
    "Psi = torch.from_numpy(Psi)\n",
    "Psi = Psi.clone().detach().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03f7f9ea-e218-4790-84e8-caf0a10489d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fista_net = FISTANet(FNET_LAYER_NO, FNET_FEATURE_NO)\n",
    "fista_net = fista_net.to(device)# define arguments of fista_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42d7c70b-85c2-4256-b761-683d59095c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fista_net = FISTANetNoST(FNET_LAYER_NO, FNET_FEATURE_NO)\n",
    "fista_net = fista_net.to(device)# define arguments of fista_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f12c4823-35ea-41b9-97a1-bf6746dc204d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters fista net: 6\n"
     ]
    }
   ],
   "source": [
    "# summary(fista_net, input_size=(1, 64, 298), device=str(device))\n",
    "print('Total number of parameters fista net:',\n",
    "          sum(p.numel() for p in fista_net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3579c675-faba-4918-bffe-7a3ee0c8afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "if START_EPOCH:\n",
    "    dt = START_RUN\n",
    "args = {\n",
    "    'model_name': 'FISTANet',\n",
    "    'num_epochs': EPOCH_NO,\n",
    "    'lr': LEARNING_RATE,\n",
    "    'data_dir': DATA_DIR,\n",
    "    'save_path': f'./runs/{dt}',\n",
    "    'start_epoch': START_EPOCH,\n",
    "    'start_run': START_RUN,\n",
    "    'multi_gpu': False,\n",
    "    'device': device,\n",
    "    'log_interval': LOG_INTERVAL,\n",
    "    'test_epoch': TEST_EPOCH,\n",
    "    'lr_dec_after': LR_DEC_AFTER,\n",
    "    'lr_dec_every': LR_DEC_EVERY,\n",
    "    'lambda_sp_loss': LAMBDA_SP_LOSS,\n",
    "    'lambda_sym_loss': LAMBDA_SYM_LOSS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37c787d6-372b-4189-b428-133486557995",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Solver(fista_net, Psi, trn_ldr, val_ldr, BATCH_SIZE, args, tst_ldr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dba58ed-bcde-4a91-994f-1b69c8decd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 5001...\n",
      "\n",
      "Train Epoch: 5001 [0/8000 (0%)]\tBatch Loss: 0.013934\tLearning Rate (w_theta): 0.001000\t TIME:2.0s\n",
      "\t\t\t\tDisc: 0.012534\t\tSym: 0.000000\t\tSpars: 0.001400\n",
      "\t TVw: 1.165494 | TVb: 1.850893 | GSw: -0.705039 | GSb: -0.420869 | TSUw: -0.384406 | TSUb: 0.018520\n",
      "\n",
      "Train Epoch: 5001 [4000/8000 (50%)]\tBatch Loss: 0.013917\tLearning Rate (w_theta): 0.001000\t TIME:3.3s\n",
      "\t\t\t\tDisc: 0.012486\t\tSym: 0.000000\t\tSpars: 0.001431\n",
      "\t TVw: 1.164330 | TVb: 1.851845 | GSw: -0.704974 | GSb: -0.420784 | TSUw: -0.384281 | TSUb: 0.018457\n",
      "Validating epoch 5001...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013946397770614533\n",
      "Average validation loss: 0.014403944802090438\n",
      "Training epoch 5002...\n",
      "\n",
      "Train Epoch: 5002 [0/8000 (0%)]\tBatch Loss: 0.014045\tLearning Rate (w_theta): 0.001000\t TIME:5.4s\n",
      "\t\t\t\tDisc: 0.012400\t\tSym: 0.000000\t\tSpars: 0.001644\n",
      "\t TVw: 1.163457 | TVb: 1.852841 | GSw: -0.704910 | GSb: -0.420701 | TSUw: -0.384222 | TSUb: 0.018357\n",
      "\n",
      "Train Epoch: 5002 [4000/8000 (50%)]\tBatch Loss: 0.014078\tLearning Rate (w_theta): 0.001000\t TIME:6.7s\n",
      "\t\t\t\tDisc: 0.012448\t\tSym: 0.000000\t\tSpars: 0.001630\n",
      "\t TVw: 1.162554 | TVb: 1.853840 | GSw: -0.704850 | GSb: -0.420621 | TSUw: -0.384215 | TSUb: 0.018228\n",
      "Validating epoch 5002...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01394023039502111\n",
      "Average validation loss: 0.014397953347292021\n",
      "Training epoch 5003...\n",
      "\n",
      "Train Epoch: 5003 [0/8000 (0%)]\tBatch Loss: 0.014309\tLearning Rate (w_theta): 0.001000\t TIME:8.9s\n",
      "\t\t\t\tDisc: 0.012576\t\tSym: 0.000000\t\tSpars: 0.001734\n",
      "\t TVw: 1.161808 | TVb: 1.854846 | GSw: -0.704787 | GSb: -0.420539 | TSUw: -0.384192 | TSUb: 0.018108\n",
      "\n",
      "Train Epoch: 5003 [4000/8000 (50%)]\tBatch Loss: 0.013543\tLearning Rate (w_theta): 0.001000\t TIME:10.1s\n",
      "\t\t\t\tDisc: 0.012157\t\tSym: 0.000000\t\tSpars: 0.001386\n",
      "\t TVw: 1.161193 | TVb: 1.855864 | GSw: -0.704728 | GSb: -0.420460 | TSUw: -0.384214 | TSUb: 0.017964\n",
      "Validating epoch 5003...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013933522359293866\n",
      "Average validation loss: 0.01439170748583706\n",
      "Training epoch 5004...\n",
      "\n",
      "Train Epoch: 5004 [0/8000 (0%)]\tBatch Loss: 0.014445\tLearning Rate (w_theta): 0.001000\t TIME:12.3s\n",
      "\t\t\t\tDisc: 0.012475\t\tSym: 0.000000\t\tSpars: 0.001970\n",
      "\t TVw: 1.160390 | TVb: 1.856865 | GSw: -0.704667 | GSb: -0.420380 | TSUw: -0.384213 | TSUb: 0.017832\n",
      "\n",
      "Train Epoch: 5004 [4000/8000 (50%)]\tBatch Loss: 0.013741\tLearning Rate (w_theta): 0.001000\t TIME:13.6s\n",
      "\t\t\t\tDisc: 0.012307\t\tSym: 0.000000\t\tSpars: 0.001434\n",
      "\t TVw: 1.159454 | TVb: 1.857845 | GSw: -0.704604 | GSb: -0.420296 | TSUw: -0.384157 | TSUb: 0.017731\n",
      "Validating epoch 5004...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013926948418494227\n",
      "Average validation loss: 0.014385986237400014\n",
      "Training epoch 5005...\n",
      "\n",
      "Train Epoch: 5005 [0/8000 (0%)]\tBatch Loss: 0.013832\tLearning Rate (w_theta): 0.001000\t TIME:15.7s\n",
      "\t\t\t\tDisc: 0.012282\t\tSym: 0.000000\t\tSpars: 0.001549\n",
      "\t TVw: 1.158446 | TVb: 1.858815 | GSw: -0.704538 | GSb: -0.420209 | TSUw: -0.384058 | TSUb: 0.017653\n",
      "\n",
      "Train Epoch: 5005 [4000/8000 (50%)]\tBatch Loss: 0.014049\tLearning Rate (w_theta): 0.001000\t TIME:17.1s\n",
      "\t\t\t\tDisc: 0.012412\t\tSym: 0.000000\t\tSpars: 0.001638\n",
      "\t TVw: 1.157541 | TVb: 1.859787 | GSw: -0.704473 | GSb: -0.420124 | TSUw: -0.383990 | TSUb: 0.017558\n",
      "Validating epoch 5005...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013921000840405153\n",
      "Average validation loss: 0.014380218784863064\n",
      "Training epoch 5006...\n",
      "\n",
      "Train Epoch: 5006 [0/8000 (0%)]\tBatch Loss: 0.013732\tLearning Rate (w_theta): 0.001000\t TIME:19.2s\n",
      "\t\t\t\tDisc: 0.012246\t\tSym: 0.000000\t\tSpars: 0.001486\n",
      "\t TVw: 1.156593 | TVb: 1.860762 | GSw: -0.704405 | GSb: -0.420036 | TSUw: -0.383885 | TSUb: 0.017484\n",
      "\n",
      "Train Epoch: 5006 [4000/8000 (50%)]\tBatch Loss: 0.013876\tLearning Rate (w_theta): 0.001000\t TIME:20.5s\n",
      "\t\t\t\tDisc: 0.012265\t\tSym: 0.000000\t\tSpars: 0.001611\n",
      "\t TVw: 1.155709 | TVb: 1.861744 | GSw: -0.704342 | GSb: -0.419952 | TSUw: -0.383868 | TSUb: 0.017362\n",
      "Validating epoch 5006...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013914917034561079\n",
      "Average validation loss: 0.014374432839503315\n",
      "Training epoch 5007...\n",
      "\n",
      "Train Epoch: 5007 [0/8000 (0%)]\tBatch Loss: 0.014578\tLearning Rate (w_theta): 0.001000\t TIME:22.7s\n",
      "\t\t\t\tDisc: 0.012918\t\tSym: 0.000000\t\tSpars: 0.001660\n",
      "\t TVw: 1.154847 | TVb: 1.862729 | GSw: -0.704279 | GSb: -0.419869 | TSUw: -0.383842 | TSUb: 0.017244\n",
      "\n",
      "Train Epoch: 5007 [4000/8000 (50%)]\tBatch Loss: 0.013513\tLearning Rate (w_theta): 0.001000\t TIME:24.0s\n",
      "\t\t\t\tDisc: 0.012172\t\tSym: 0.000000\t\tSpars: 0.001341\n",
      "\t TVw: 1.154046 | TVb: 1.863716 | GSw: -0.704219 | GSb: -0.419789 | TSUw: -0.383865 | TSUb: 0.017100\n",
      "Validating epoch 5007...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013908683355955862\n",
      "Average validation loss: 0.014368605753131527\n",
      "Training epoch 5008...\n",
      "\n",
      "Train Epoch: 5008 [0/8000 (0%)]\tBatch Loss: 0.014096\tLearning Rate (w_theta): 0.001000\t TIME:26.2s\n",
      "\t\t\t\tDisc: 0.012402\t\tSym: 0.000000\t\tSpars: 0.001694\n",
      "\t TVw: 1.153149 | TVb: 1.864699 | GSw: -0.704156 | GSb: -0.419704 | TSUw: -0.383827 | TSUb: 0.016989\n",
      "\n",
      "Train Epoch: 5008 [4000/8000 (50%)]\tBatch Loss: 0.014968\tLearning Rate (w_theta): 0.001000\t TIME:27.5s\n",
      "\t\t\t\tDisc: 0.013037\t\tSym: 0.000000\t\tSpars: 0.001930\n",
      "\t TVw: 1.152313 | TVb: 1.865683 | GSw: -0.704089 | GSb: -0.419618 | TSUw: -0.383750 | TSUb: 0.016899\n",
      "Validating epoch 5008...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013902528949117829\n",
      "Average validation loss: 0.014362710684945146\n",
      "Training epoch 5009...\n",
      "\n",
      "Train Epoch: 5009 [0/8000 (0%)]\tBatch Loss: 0.013954\tLearning Rate (w_theta): 0.001000\t TIME:29.6s\n",
      "\t\t\t\tDisc: 0.012433\t\tSym: 0.000000\t\tSpars: 0.001521\n",
      "\t TVw: 1.151459 | TVb: 1.866654 | GSw: -0.704024 | GSb: -0.419532 | TSUw: -0.383706 | TSUb: 0.016792\n",
      "\n",
      "Train Epoch: 5009 [4000/8000 (50%)]\tBatch Loss: 0.013927\tLearning Rate (w_theta): 0.001000\t TIME:30.9s\n",
      "\t\t\t\tDisc: 0.012204\t\tSym: 0.000000\t\tSpars: 0.001723\n",
      "\t TVw: 1.150502 | TVb: 1.867617 | GSw: -0.703961 | GSb: -0.419449 | TSUw: -0.383687 | TSUb: 0.016671\n",
      "Validating epoch 5009...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013896419663065646\n",
      "Average validation loss: 0.014357077740768097\n",
      "Training epoch 5010...\n",
      "\n",
      "Train Epoch: 5010 [0/8000 (0%)]\tBatch Loss: 0.013451\tLearning Rate (w_theta): 0.001000\t TIME:33.0s\n",
      "\t\t\t\tDisc: 0.012122\t\tSym: 0.000000\t\tSpars: 0.001329\n",
      "\t TVw: 1.149626 | TVb: 1.868587 | GSw: -0.703893 | GSb: -0.419361 | TSUw: -0.383603 | TSUb: 0.016586\n",
      "\n",
      "Train Epoch: 5010 [4000/8000 (50%)]\tBatch Loss: 0.013536\tLearning Rate (w_theta): 0.001000\t TIME:34.2s\n",
      "\t\t\t\tDisc: 0.012098\t\tSym: 0.000000\t\tSpars: 0.001439\n",
      "\t TVw: 1.148818 | TVb: 1.869572 | GSw: -0.703827 | GSb: -0.419273 | TSUw: -0.383543 | TSUb: 0.016487\n",
      "Validating epoch 5010...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013890452691100315\n",
      "Average validation loss: 0.01435129750407458\n",
      "Training epoch 5011...\n",
      "\n",
      "Train Epoch: 5011 [0/8000 (0%)]\tBatch Loss: 0.014043\tLearning Rate (w_theta): 0.001000\t TIME:37.0s\n",
      "\t\t\t\tDisc: 0.012279\t\tSym: 0.000000\t\tSpars: 0.001764\n",
      "\t TVw: 1.147951 | TVb: 1.870550 | GSw: -0.703764 | GSb: -0.419189 | TSUw: -0.383522 | TSUb: 0.016368\n",
      "\n",
      "Train Epoch: 5011 [4000/8000 (50%)]\tBatch Loss: 0.013856\tLearning Rate (w_theta): 0.001000\t TIME:38.3s\n",
      "\t\t\t\tDisc: 0.012085\t\tSym: 0.000000\t\tSpars: 0.001771\n",
      "\t TVw: 1.147268 | TVb: 1.871538 | GSw: -0.703697 | GSb: -0.419101 | TSUw: -0.383470 | TSUb: 0.016264\n",
      "Validating epoch 5011...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013884299164849139\n",
      "Average validation loss: 0.014345301871040437\n",
      "Training epoch 5012...\n",
      "\n",
      "Train Epoch: 5012 [0/8000 (0%)]\tBatch Loss: 0.013681\tLearning Rate (w_theta): 0.001000\t TIME:40.5s\n",
      "\t\t\t\tDisc: 0.012409\t\tSym: 0.000000\t\tSpars: 0.001272\n",
      "\t TVw: 1.146406 | TVb: 1.872514 | GSw: -0.703631 | GSb: -0.419014 | TSUw: -0.383421 | TSUb: 0.016160\n",
      "\n",
      "Train Epoch: 5012 [4000/8000 (50%)]\tBatch Loss: 0.013575\tLearning Rate (w_theta): 0.001000\t TIME:41.8s\n",
      "\t\t\t\tDisc: 0.011942\t\tSym: 0.000000\t\tSpars: 0.001634\n",
      "\t TVw: 1.145580 | TVb: 1.873491 | GSw: -0.703566 | GSb: -0.418928 | TSUw: -0.383388 | TSUb: 0.016047\n",
      "Validating epoch 5012...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013878018536920124\n",
      "Average validation loss: 0.014339707411023759\n",
      "Training epoch 5013...\n",
      "\n",
      "Train Epoch: 5013 [0/8000 (0%)]\tBatch Loss: 0.013441\tLearning Rate (w_theta): 0.001000\t TIME:44.0s\n",
      "\t\t\t\tDisc: 0.011990\t\tSym: 0.000000\t\tSpars: 0.001451\n",
      "\t TVw: 1.144632 | TVb: 1.874457 | GSw: -0.703500 | GSb: -0.418841 | TSUw: -0.383333 | TSUb: 0.015946\n",
      "\n",
      "Train Epoch: 5013 [4000/8000 (50%)]\tBatch Loss: 0.013873\tLearning Rate (w_theta): 0.001000\t TIME:45.2s\n",
      "\t\t\t\tDisc: 0.012416\t\tSym: 0.000000\t\tSpars: 0.001457\n",
      "\t TVw: 1.143781 | TVb: 1.875425 | GSw: -0.703442 | GSb: -0.418762 | TSUw: -0.383387 | TSUb: 0.015787\n",
      "Validating epoch 5013...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013872047474659314\n",
      "Average validation loss: 0.014334240846082539\n",
      "Training epoch 5014...\n",
      "\n",
      "Train Epoch: 5014 [0/8000 (0%)]\tBatch Loss: 0.013909\tLearning Rate (w_theta): 0.001000\t TIME:47.4s\n",
      "\t\t\t\tDisc: 0.012351\t\tSym: 0.000000\t\tSpars: 0.001558\n",
      "\t TVw: 1.142866 | TVb: 1.876386 | GSw: -0.703376 | GSb: -0.418674 | TSUw: -0.383331 | TSUb: 0.015687\n",
      "\n",
      "Train Epoch: 5014 [4000/8000 (50%)]\tBatch Loss: 0.013971\tLearning Rate (w_theta): 0.001000\t TIME:48.7s\n",
      "\t\t\t\tDisc: 0.012512\t\tSym: 0.000000\t\tSpars: 0.001460\n",
      "\t TVw: 1.141920 | TVb: 1.877347 | GSw: -0.703311 | GSb: -0.418588 | TSUw: -0.383282 | TSUb: 0.015583\n",
      "Validating epoch 5014...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0138662302692786\n",
      "Average validation loss: 0.014328732105500713\n",
      "Training epoch 5015...\n",
      "\n",
      "Train Epoch: 5015 [0/8000 (0%)]\tBatch Loss: 0.014138\tLearning Rate (w_theta): 0.001000\t TIME:50.8s\n",
      "\t\t\t\tDisc: 0.012572\t\tSym: 0.000000\t\tSpars: 0.001566\n",
      "\t TVw: 1.141015 | TVb: 1.878314 | GSw: -0.703244 | GSb: -0.418500 | TSUw: -0.383222 | TSUb: 0.015485\n",
      "\n",
      "Train Epoch: 5015 [4000/8000 (50%)]\tBatch Loss: 0.014447\tLearning Rate (w_theta): 0.001000\t TIME:52.1s\n",
      "\t\t\t\tDisc: 0.012834\t\tSym: 0.000000\t\tSpars: 0.001613\n",
      "\t TVw: 1.140091 | TVb: 1.879287 | GSw: -0.703181 | GSb: -0.418415 | TSUw: -0.383196 | TSUb: 0.015369\n",
      "Validating epoch 5015...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013860412521134739\n",
      "Average validation loss: 0.01432314038454257\n",
      "Training epoch 5016...\n",
      "\n",
      "Train Epoch: 5016 [0/8000 (0%)]\tBatch Loss: 0.013659\tLearning Rate (w_theta): 0.001000\t TIME:54.2s\n",
      "\t\t\t\tDisc: 0.012103\t\tSym: 0.000000\t\tSpars: 0.001555\n",
      "\t TVw: 1.139256 | TVb: 1.880257 | GSw: -0.703111 | GSb: -0.418324 | TSUw: -0.383110 | TSUb: 0.015285\n",
      "\n",
      "Train Epoch: 5016 [4000/8000 (50%)]\tBatch Loss: 0.014064\tLearning Rate (w_theta): 0.001000\t TIME:55.6s\n",
      "\t\t\t\tDisc: 0.012289\t\tSym: 0.000000\t\tSpars: 0.001775\n",
      "\t TVw: 1.138547 | TVb: 1.881234 | GSw: -0.703047 | GSb: -0.418239 | TSUw: -0.383119 | TSUb: 0.015150\n",
      "Validating epoch 5016...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013854360614985354\n",
      "Average validation loss: 0.014317443940869975\n",
      "Training epoch 5017...\n",
      "\n",
      "Train Epoch: 5017 [0/8000 (0%)]\tBatch Loss: 0.014008\tLearning Rate (w_theta): 0.001000\t TIME:57.8s\n",
      "\t\t\t\tDisc: 0.012495\t\tSym: 0.000000\t\tSpars: 0.001513\n",
      "\t TVw: 1.137680 | TVb: 1.882196 | GSw: -0.702979 | GSb: -0.418149 | TSUw: -0.383060 | TSUb: 0.015052\n",
      "\n",
      "Train Epoch: 5017 [4000/8000 (50%)]\tBatch Loss: 0.013775\tLearning Rate (w_theta): 0.001000\t TIME:59.1s\n",
      "\t\t\t\tDisc: 0.012366\t\tSym: 0.000000\t\tSpars: 0.001408\n",
      "\t TVw: 1.136850 | TVb: 1.883149 | GSw: -0.702910 | GSb: -0.418058 | TSUw: -0.383002 | TSUb: 0.014953\n",
      "Validating epoch 5017...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013848388932065015\n",
      "Average validation loss: 0.014312042776918152\n",
      "Training epoch 5018...\n",
      "\n",
      "Train Epoch: 5018 [0/8000 (0%)]\tBatch Loss: 0.014021\tLearning Rate (w_theta): 0.001000\t TIME:61.4s\n",
      "\t\t\t\tDisc: 0.012189\t\tSym: 0.000000\t\tSpars: 0.001832\n",
      "\t TVw: 1.135980 | TVb: 1.884112 | GSw: -0.702846 | GSb: -0.417972 | TSUw: -0.382987 | TSUb: 0.014831\n",
      "\n",
      "Train Epoch: 5018 [4000/8000 (50%)]\tBatch Loss: 0.013695\tLearning Rate (w_theta): 0.001000\t TIME:62.6s\n",
      "\t\t\t\tDisc: 0.011939\t\tSym: 0.000000\t\tSpars: 0.001756\n",
      "\t TVw: 1.135164 | TVb: 1.885092 | GSw: -0.702789 | GSb: -0.417893 | TSUw: -0.383088 | TSUb: 0.014647\n",
      "Validating epoch 5018...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01384261256854368\n",
      "Average validation loss: 0.014306552851334114\n",
      "Training epoch 5019...\n",
      "\n",
      "Train Epoch: 5019 [0/8000 (0%)]\tBatch Loss: 0.013963\tLearning Rate (w_theta): 0.001000\t TIME:65.0s\n",
      "\t\t\t\tDisc: 0.012304\t\tSym: 0.000000\t\tSpars: 0.001659\n",
      "\t TVw: 1.134308 | TVb: 1.886052 | GSw: -0.702719 | GSb: -0.417801 | TSUw: -0.382995 | TSUb: 0.014568\n",
      "\n",
      "Train Epoch: 5019 [4000/8000 (50%)]\tBatch Loss: 0.014423\tLearning Rate (w_theta): 0.001000\t TIME:66.3s\n",
      "\t\t\t\tDisc: 0.012541\t\tSym: 0.000000\t\tSpars: 0.001882\n",
      "\t TVw: 1.133425 | TVb: 1.887004 | GSw: -0.702649 | GSb: -0.417709 | TSUw: -0.382899 | TSUb: 0.014490\n",
      "Validating epoch 5019...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01383661185014056\n",
      "Average validation loss: 0.014301128316728222\n",
      "Training epoch 5020...\n",
      "\n",
      "Train Epoch: 5020 [0/8000 (0%)]\tBatch Loss: 0.013524\tLearning Rate (w_theta): 0.001000\t TIME:68.5s\n",
      "\t\t\t\tDisc: 0.011910\t\tSym: 0.000000\t\tSpars: 0.001614\n",
      "\t TVw: 1.132542 | TVb: 1.887950 | GSw: -0.702581 | GSb: -0.417618 | TSUw: -0.382839 | TSUb: 0.014393\n",
      "\n",
      "Train Epoch: 5020 [4000/8000 (50%)]\tBatch Loss: 0.014765\tLearning Rate (w_theta): 0.001000\t TIME:69.7s\n",
      "\t\t\t\tDisc: 0.012686\t\tSym: 0.000000\t\tSpars: 0.002080\n",
      "\t TVw: 1.131719 | TVb: 1.888911 | GSw: -0.702509 | GSb: -0.417525 | TSUw: -0.382741 | TSUb: 0.014317\n",
      "Validating epoch 5020...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013830887274564815\n",
      "Average validation loss: 0.01429556995264455\n",
      "Training epoch 5021...\n",
      "\n",
      "Train Epoch: 5021 [0/8000 (0%)]\tBatch Loss: 0.013723\tLearning Rate (w_theta): 0.001000\t TIME:72.6s\n",
      "\t\t\t\tDisc: 0.012516\t\tSym: 0.000000\t\tSpars: 0.001207\n",
      "\t TVw: 1.130882 | TVb: 1.889862 | GSw: -0.702442 | GSb: -0.417436 | TSUw: -0.382707 | TSUb: 0.014206\n",
      "\n",
      "Train Epoch: 5021 [4000/8000 (50%)]\tBatch Loss: 0.013742\tLearning Rate (w_theta): 0.001000\t TIME:73.8s\n",
      "\t\t\t\tDisc: 0.012373\t\tSym: 0.000000\t\tSpars: 0.001369\n",
      "\t TVw: 1.129942 | TVb: 1.890794 | GSw: -0.702374 | GSb: -0.417345 | TSUw: -0.382635 | TSUb: 0.014116\n",
      "Validating epoch 5021...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013825106360540861\n",
      "Average validation loss: 0.01429037316435109\n",
      "Training epoch 5022...\n",
      "\n",
      "Train Epoch: 5022 [0/8000 (0%)]\tBatch Loss: 0.013820\tLearning Rate (w_theta): 0.001000\t TIME:76.1s\n",
      "\t\t\t\tDisc: 0.012305\t\tSym: 0.000000\t\tSpars: 0.001516\n",
      "\t TVw: 1.129014 | TVb: 1.891744 | GSw: -0.702306 | GSb: -0.417255 | TSUw: -0.382584 | TSUb: 0.014014\n",
      "\n",
      "Train Epoch: 5022 [4000/8000 (50%)]\tBatch Loss: 0.013806\tLearning Rate (w_theta): 0.001000\t TIME:77.4s\n",
      "\t\t\t\tDisc: 0.012440\t\tSym: 0.000000\t\tSpars: 0.001366\n",
      "\t TVw: 1.128130 | TVb: 1.892712 | GSw: -0.702239 | GSb: -0.417165 | TSUw: -0.382550 | TSUb: 0.013904\n",
      "Validating epoch 5022...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013819552641716188\n",
      "Average validation loss: 0.014284883731427913\n",
      "Training epoch 5023...\n",
      "\n",
      "Train Epoch: 5023 [0/8000 (0%)]\tBatch Loss: 0.014099\tLearning Rate (w_theta): 0.001000\t TIME:79.7s\n",
      "\t\t\t\tDisc: 0.012566\t\tSym: 0.000000\t\tSpars: 0.001533\n",
      "\t TVw: 1.127367 | TVb: 1.893677 | GSw: -0.702170 | GSb: -0.417075 | TSUw: -0.382512 | TSUb: 0.013795\n",
      "\n",
      "Train Epoch: 5023 [4000/8000 (50%)]\tBatch Loss: 0.013894\tLearning Rate (w_theta): 0.001000\t TIME:81.0s\n",
      "\t\t\t\tDisc: 0.012164\t\tSym: 0.000000\t\tSpars: 0.001731\n",
      "\t TVw: 1.126520 | TVb: 1.894631 | GSw: -0.702096 | GSb: -0.416977 | TSUw: -0.382371 | TSUb: 0.013743\n",
      "Validating epoch 5023...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01381373786699652\n",
      "Average validation loss: 0.014279254802084586\n",
      "Training epoch 5024...\n",
      "\n",
      "Train Epoch: 5024 [0/8000 (0%)]\tBatch Loss: 0.012696\tLearning Rate (w_theta): 0.001000\t TIME:83.4s\n",
      "\t\t\t\tDisc: 0.011552\t\tSym: 0.000000\t\tSpars: 0.001144\n",
      "\t TVw: 1.125726 | TVb: 1.895591 | GSw: -0.702032 | GSb: -0.416891 | TSUw: -0.382398 | TSUb: 0.013599\n",
      "\n",
      "Train Epoch: 5024 [4000/8000 (50%)]\tBatch Loss: 0.014917\tLearning Rate (w_theta): 0.001000\t TIME:84.7s\n",
      "\t\t\t\tDisc: 0.013080\t\tSym: 0.000000\t\tSpars: 0.001837\n",
      "\t TVw: 1.124942 | TVb: 1.896559 | GSw: -0.701971 | GSb: -0.416808 | TSUw: -0.382464 | TSUb: 0.013434\n",
      "Validating epoch 5024...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013807734421499296\n",
      "Average validation loss: 0.014273783478171815\n",
      "Training epoch 5025...\n",
      "\n",
      "Train Epoch: 5025 [0/8000 (0%)]\tBatch Loss: 0.013419\tLearning Rate (w_theta): 0.001000\t TIME:86.9s\n",
      "\t\t\t\tDisc: 0.011998\t\tSym: 0.000000\t\tSpars: 0.001422\n",
      "\t TVw: 1.124202 | TVb: 1.897531 | GSw: -0.701905 | GSb: -0.416719 | TSUw: -0.382462 | TSUb: 0.013306\n",
      "\n",
      "Train Epoch: 5025 [4000/8000 (50%)]\tBatch Loss: 0.014202\tLearning Rate (w_theta): 0.001000\t TIME:88.2s\n",
      "\t\t\t\tDisc: 0.012581\t\tSym: 0.000000\t\tSpars: 0.001621\n",
      "\t TVw: 1.123360 | TVb: 1.898481 | GSw: -0.701835 | GSb: -0.416627 | TSUw: -0.382395 | TSUb: 0.013214\n",
      "Validating epoch 5025...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013801732697534215\n",
      "Average validation loss: 0.014268298344346265\n",
      "Training epoch 5026...\n",
      "\n",
      "Train Epoch: 5026 [0/8000 (0%)]\tBatch Loss: 0.014446\tLearning Rate (w_theta): 0.001000\t TIME:90.4s\n",
      "\t\t\t\tDisc: 0.012386\t\tSym: 0.000000\t\tSpars: 0.002060\n",
      "\t TVw: 1.122657 | TVb: 1.899446 | GSw: -0.701768 | GSb: -0.416537 | TSUw: -0.382399 | TSUb: 0.013083\n",
      "\n",
      "Train Epoch: 5026 [4000/8000 (50%)]\tBatch Loss: 0.013784\tLearning Rate (w_theta): 0.001000\t TIME:91.6s\n",
      "\t\t\t\tDisc: 0.012402\t\tSym: 0.000000\t\tSpars: 0.001381\n",
      "\t TVw: 1.121894 | TVb: 1.900411 | GSw: -0.701701 | GSb: -0.416446 | TSUw: -0.382398 | TSUb: 0.012955\n",
      "Validating epoch 5026...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013795783156761\n",
      "Average validation loss: 0.014262727662790433\n",
      "Training epoch 5027...\n",
      "\n",
      "Train Epoch: 5027 [0/8000 (0%)]\tBatch Loss: 0.013166\tLearning Rate (w_theta): 0.001000\t TIME:93.8s\n",
      "\t\t\t\tDisc: 0.011831\t\tSym: 0.000000\t\tSpars: 0.001335\n",
      "\t TVw: 1.121098 | TVb: 1.901368 | GSw: -0.701630 | GSb: -0.416352 | TSUw: -0.382335 | TSUb: 0.012862\n",
      "\n",
      "Train Epoch: 5027 [4000/8000 (50%)]\tBatch Loss: 0.013733\tLearning Rate (w_theta): 0.001000\t TIME:95.0s\n",
      "\t\t\t\tDisc: 0.012119\t\tSym: 0.000000\t\tSpars: 0.001613\n",
      "\t TVw: 1.120237 | TVb: 1.902313 | GSw: -0.701553 | GSb: -0.416252 | TSUw: -0.382182 | TSUb: 0.012816\n",
      "Validating epoch 5027...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013789999325112635\n",
      "Average validation loss: 0.014257339808963413\n",
      "Training epoch 5028...\n",
      "\n",
      "Train Epoch: 5028 [0/8000 (0%)]\tBatch Loss: 0.014080\tLearning Rate (w_theta): 0.001000\t TIME:97.3s\n",
      "\t\t\t\tDisc: 0.012283\t\tSym: 0.000000\t\tSpars: 0.001797\n",
      "\t TVw: 1.119423 | TVb: 1.903273 | GSw: -0.701488 | GSb: -0.416164 | TSUw: -0.382199 | TSUb: 0.012679\n",
      "\n",
      "Train Epoch: 5028 [4000/8000 (50%)]\tBatch Loss: 0.013819\tLearning Rate (w_theta): 0.001000\t TIME:98.5s\n",
      "\t\t\t\tDisc: 0.012472\t\tSym: 0.000000\t\tSpars: 0.001347\n",
      "\t TVw: 1.118736 | TVb: 1.904245 | GSw: -0.701420 | GSb: -0.416073 | TSUw: -0.382206 | TSUb: 0.012546\n",
      "Validating epoch 5028...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013784094440848342\n",
      "Average validation loss: 0.014251871110385287\n",
      "Training epoch 5029...\n",
      "\n",
      "Train Epoch: 5029 [0/8000 (0%)]\tBatch Loss: 0.013652\tLearning Rate (w_theta): 0.001000\t TIME:100.7s\n",
      "\t\t\t\tDisc: 0.012280\t\tSym: 0.000000\t\tSpars: 0.001372\n",
      "\t TVw: 1.117811 | TVb: 1.905184 | GSw: -0.701352 | GSb: -0.415982 | TSUw: -0.382174 | TSUb: 0.012436\n",
      "\n",
      "Train Epoch: 5029 [4000/8000 (50%)]\tBatch Loss: 0.013511\tLearning Rate (w_theta): 0.001000\t TIME:101.9s\n",
      "\t\t\t\tDisc: 0.011996\t\tSym: 0.000000\t\tSpars: 0.001515\n",
      "\t TVw: 1.116748 | TVb: 1.906107 | GSw: -0.701277 | GSb: -0.415884 | TSUw: -0.382026 | TSUb: 0.012389\n",
      "Validating epoch 5029...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013778666273275843\n",
      "Average validation loss: 0.014246772429216199\n",
      "Training epoch 5030...\n",
      "\n",
      "Train Epoch: 5030 [0/8000 (0%)]\tBatch Loss: 0.013960\tLearning Rate (w_theta): 0.001000\t TIME:104.2s\n",
      "\t\t\t\tDisc: 0.012527\t\tSym: 0.000000\t\tSpars: 0.001433\n",
      "\t TVw: 1.115860 | TVb: 1.907056 | GSw: -0.701207 | GSb: -0.415791 | TSUw: -0.381983 | TSUb: 0.012284\n",
      "\n",
      "Train Epoch: 5030 [4000/8000 (50%)]\tBatch Loss: 0.013912\tLearning Rate (w_theta): 0.001000\t TIME:105.4s\n",
      "\t\t\t\tDisc: 0.012316\t\tSym: 0.000000\t\tSpars: 0.001595\n",
      "\t TVw: 1.115084 | TVb: 1.907999 | GSw: -0.701140 | GSb: -0.415700 | TSUw: -0.381970 | TSUb: 0.012164\n",
      "Validating epoch 5030...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013773073201973839\n",
      "Average validation loss: 0.0142414636797854\n",
      "Training epoch 5031...\n",
      "\n",
      "Train Epoch: 5031 [0/8000 (0%)]\tBatch Loss: 0.014205\tLearning Rate (w_theta): 0.001000\t TIME:108.2s\n",
      "\t\t\t\tDisc: 0.012654\t\tSym: 0.000000\t\tSpars: 0.001551\n",
      "\t TVw: 1.114232 | TVb: 1.908950 | GSw: -0.701072 | GSb: -0.415609 | TSUw: -0.381957 | TSUb: 0.012043\n",
      "\n",
      "Train Epoch: 5031 [4000/8000 (50%)]\tBatch Loss: 0.014520\tLearning Rate (w_theta): 0.001000\t TIME:109.4s\n",
      "\t\t\t\tDisc: 0.012664\t\tSym: 0.000000\t\tSpars: 0.001857\n",
      "\t TVw: 1.113288 | TVb: 1.909892 | GSw: -0.701003 | GSb: -0.415517 | TSUw: -0.381942 | TSUb: 0.011924\n",
      "Validating epoch 5031...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013767520701323985\n",
      "Average validation loss: 0.014236238409120841\n",
      "Training epoch 5032...\n",
      "\n",
      "Train Epoch: 5032 [0/8000 (0%)]\tBatch Loss: 0.014032\tLearning Rate (w_theta): 0.001000\t TIME:111.6s\n",
      "\t\t\t\tDisc: 0.012306\t\tSym: 0.000000\t\tSpars: 0.001726\n",
      "\t TVw: 1.112491 | TVb: 1.910857 | GSw: -0.700937 | GSb: -0.415427 | TSUw: -0.381968 | TSUb: 0.011783\n",
      "\n",
      "Train Epoch: 5032 [4000/8000 (50%)]\tBatch Loss: 0.013781\tLearning Rate (w_theta): 0.001000\t TIME:112.9s\n",
      "\t\t\t\tDisc: 0.012246\t\tSym: 0.000000\t\tSpars: 0.001535\n",
      "\t TVw: 1.111672 | TVb: 1.911814 | GSw: -0.700868 | GSb: -0.415334 | TSUw: -0.381931 | TSUb: 0.011676\n",
      "Validating epoch 5032...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013761836901768361\n",
      "Average validation loss: 0.01423091725894601\n",
      "Training epoch 5033...\n",
      "\n",
      "Train Epoch: 5033 [0/8000 (0%)]\tBatch Loss: 0.013835\tLearning Rate (w_theta): 0.001000\t TIME:115.1s\n",
      "\t\t\t\tDisc: 0.012134\t\tSym: 0.000000\t\tSpars: 0.001700\n",
      "\t TVw: 1.110829 | TVb: 1.912761 | GSw: -0.700800 | GSb: -0.415243 | TSUw: -0.381931 | TSUb: 0.011549\n",
      "\n",
      "Train Epoch: 5033 [4000/8000 (50%)]\tBatch Loss: 0.013870\tLearning Rate (w_theta): 0.001000\t TIME:116.4s\n",
      "\t\t\t\tDisc: 0.012725\t\tSym: 0.000000\t\tSpars: 0.001145\n",
      "\t TVw: 1.110224 | TVb: 1.913735 | GSw: -0.700737 | GSb: -0.415156 | TSUw: -0.382021 | TSUb: 0.011372\n",
      "Validating epoch 5033...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013756036953424363\n",
      "Average validation loss: 0.014225528702000624\n",
      "Training epoch 5034...\n",
      "\n",
      "Train Epoch: 5034 [0/8000 (0%)]\tBatch Loss: 0.014098\tLearning Rate (w_theta): 0.001000\t TIME:118.6s\n",
      "\t\t\t\tDisc: 0.012565\t\tSym: 0.000000\t\tSpars: 0.001533\n",
      "\t TVw: 1.109303 | TVb: 1.914670 | GSw: -0.700668 | GSb: -0.415063 | TSUw: -0.381999 | TSUb: 0.011258\n",
      "\n",
      "Train Epoch: 5034 [4000/8000 (50%)]\tBatch Loss: 0.013270\tLearning Rate (w_theta): 0.001000\t TIME:119.9s\n",
      "\t\t\t\tDisc: 0.012073\t\tSym: 0.000000\t\tSpars: 0.001197\n",
      "\t TVw: 1.108460 | TVb: 1.915625 | GSw: -0.700596 | GSb: -0.414967 | TSUw: -0.381946 | TSUb: 0.011160\n",
      "Validating epoch 5034...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013750348985518504\n",
      "Average validation loss: 0.014220285680553302\n",
      "Training epoch 5035...\n",
      "\n",
      "Train Epoch: 5035 [0/8000 (0%)]\tBatch Loss: 0.014646\tLearning Rate (w_theta): 0.001000\t TIME:122.0s\n",
      "\t\t\t\tDisc: 0.012644\t\tSym: 0.000000\t\tSpars: 0.002002\n",
      "\t TVw: 1.107620 | TVb: 1.916570 | GSw: -0.700526 | GSb: -0.414873 | TSUw: -0.381908 | TSUb: 0.011054\n",
      "\n",
      "Train Epoch: 5035 [4000/8000 (50%)]\tBatch Loss: 0.013456\tLearning Rate (w_theta): 0.001000\t TIME:123.3s\n",
      "\t\t\t\tDisc: 0.012214\t\tSym: 0.000000\t\tSpars: 0.001242\n",
      "\t TVw: 1.106717 | TVb: 1.917504 | GSw: -0.700453 | GSb: -0.414775 | TSUw: -0.381817 | TSUb: 0.010977\n",
      "Validating epoch 5035...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013744822543248297\n",
      "Average validation loss: 0.014215060321559744\n",
      "Training epoch 5036...\n",
      "\n",
      "Train Epoch: 5036 [0/8000 (0%)]\tBatch Loss: 0.014281\tLearning Rate (w_theta): 0.001000\t TIME:125.4s\n",
      "\t\t\t\tDisc: 0.012718\t\tSym: 0.000000\t\tSpars: 0.001563\n",
      "\t TVw: 1.105829 | TVb: 1.918435 | GSw: -0.700381 | GSb: -0.414679 | TSUw: -0.381752 | TSUb: 0.010886\n",
      "\n",
      "Train Epoch: 5036 [4000/8000 (50%)]\tBatch Loss: 0.013642\tLearning Rate (w_theta): 0.001000\t TIME:126.7s\n",
      "\t\t\t\tDisc: 0.012131\t\tSym: 0.000000\t\tSpars: 0.001511\n",
      "\t TVw: 1.105081 | TVb: 1.919387 | GSw: -0.700312 | GSb: -0.414586 | TSUw: -0.381748 | TSUb: 0.010762\n",
      "Validating epoch 5036...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013739345114695172\n",
      "Average validation loss: 0.01420973532006982\n",
      "Training epoch 5037...\n",
      "\n",
      "Train Epoch: 5037 [0/8000 (0%)]\tBatch Loss: 0.013336\tLearning Rate (w_theta): 0.001000\t TIME:128.9s\n",
      "\t\t\t\tDisc: 0.012096\t\tSym: 0.000000\t\tSpars: 0.001240\n",
      "\t TVw: 1.104211 | TVb: 1.920317 | GSw: -0.700239 | GSb: -0.414489 | TSUw: -0.381673 | TSUb: 0.010677\n",
      "\n",
      "Train Epoch: 5037 [4000/8000 (50%)]\tBatch Loss: 0.013476\tLearning Rate (w_theta): 0.001000\t TIME:130.2s\n",
      "\t\t\t\tDisc: 0.012036\t\tSym: 0.000000\t\tSpars: 0.001441\n",
      "\t TVw: 1.103212 | TVb: 1.921232 | GSw: -0.700166 | GSb: -0.414392 | TSUw: -0.381587 | TSUb: 0.010598\n",
      "Validating epoch 5037...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01373399739924896\n",
      "Average validation loss: 0.01420474128160398\n",
      "Training epoch 5038...\n",
      "\n",
      "Train Epoch: 5038 [0/8000 (0%)]\tBatch Loss: 0.013533\tLearning Rate (w_theta): 0.001000\t TIME:132.4s\n",
      "\t\t\t\tDisc: 0.012310\t\tSym: 0.000000\t\tSpars: 0.001223\n",
      "\t TVw: 1.102260 | TVb: 1.922159 | GSw: -0.700094 | GSb: -0.414295 | TSUw: -0.381517 | TSUb: 0.010510\n",
      "\n",
      "Train Epoch: 5038 [4000/8000 (50%)]\tBatch Loss: 0.014197\tLearning Rate (w_theta): 0.001000\t TIME:133.6s\n",
      "\t\t\t\tDisc: 0.012610\t\tSym: 0.000000\t\tSpars: 0.001588\n",
      "\t TVw: 1.101360 | TVb: 1.923079 | GSw: -0.700020 | GSb: -0.414197 | TSUw: -0.381457 | TSUb: 0.010417\n",
      "Validating epoch 5038...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013728819545598299\n",
      "Average validation loss: 0.014199635991613098\n",
      "Training epoch 5039...\n",
      "\n",
      "Train Epoch: 5039 [0/8000 (0%)]\tBatch Loss: 0.013823\tLearning Rate (w_theta): 0.001000\t TIME:135.9s\n",
      "\t\t\t\tDisc: 0.012442\t\tSym: 0.000000\t\tSpars: 0.001381\n",
      "\t TVw: 1.100560 | TVb: 1.924022 | GSw: -0.699950 | GSb: -0.414102 | TSUw: -0.381432 | TSUb: 0.010305\n",
      "\n",
      "Train Epoch: 5039 [4000/8000 (50%)]\tBatch Loss: 0.013881\tLearning Rate (w_theta): 0.001000\t TIME:137.2s\n",
      "\t\t\t\tDisc: 0.012175\t\tSym: 0.000000\t\tSpars: 0.001706\n",
      "\t TVw: 1.099747 | TVb: 1.924956 | GSw: -0.699879 | GSb: -0.414006 | TSUw: -0.381409 | TSUb: 0.010191\n",
      "Validating epoch 5039...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013723358619682907\n",
      "Average validation loss: 0.014194424135206043\n",
      "Training epoch 5040...\n",
      "\n",
      "Train Epoch: 5040 [0/8000 (0%)]\tBatch Loss: 0.013452\tLearning Rate (w_theta): 0.001000\t TIME:139.3s\n",
      "\t\t\t\tDisc: 0.012231\t\tSym: 0.000000\t\tSpars: 0.001221\n",
      "\t TVw: 1.098932 | TVb: 1.925897 | GSw: -0.699807 | GSb: -0.413909 | TSUw: -0.381367 | TSUb: 0.010089\n",
      "\n",
      "Train Epoch: 5040 [4000/8000 (50%)]\tBatch Loss: 0.013666\tLearning Rate (w_theta): 0.001000\t TIME:140.6s\n",
      "\t\t\t\tDisc: 0.012313\t\tSym: 0.000000\t\tSpars: 0.001353\n",
      "\t TVw: 1.097912 | TVb: 1.926804 | GSw: -0.699734 | GSb: -0.413811 | TSUw: -0.381303 | TSUb: 0.009998\n",
      "Validating epoch 5040...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013718049817137059\n",
      "Average validation loss: 0.014189467191515415\n",
      "Training epoch 5041...\n",
      "\n",
      "Train Epoch: 5041 [0/8000 (0%)]\tBatch Loss: 0.014005\tLearning Rate (w_theta): 0.001000\t TIME:143.4s\n",
      "\t\t\t\tDisc: 0.012328\t\tSym: 0.000000\t\tSpars: 0.001677\n",
      "\t TVw: 1.097187 | TVb: 1.927755 | GSw: -0.699665 | GSb: -0.413718 | TSUw: -0.381307 | TSUb: 0.009871\n",
      "\n",
      "Train Epoch: 5041 [4000/8000 (50%)]\tBatch Loss: 0.013347\tLearning Rate (w_theta): 0.001000\t TIME:144.6s\n",
      "\t\t\t\tDisc: 0.012012\t\tSym: 0.000000\t\tSpars: 0.001335\n",
      "\t TVw: 1.096581 | TVb: 1.928719 | GSw: -0.699599 | GSb: -0.413627 | TSUw: -0.381363 | TSUb: 0.009714\n",
      "Validating epoch 5041...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013712467713375996\n",
      "Average validation loss: 0.01418411051247143\n",
      "Training epoch 5042...\n",
      "\n",
      "Train Epoch: 5042 [0/8000 (0%)]\tBatch Loss: 0.013844\tLearning Rate (w_theta): 0.001000\t TIME:146.9s\n",
      "\t\t\t\tDisc: 0.012528\t\tSym: 0.000000\t\tSpars: 0.001315\n",
      "\t TVw: 1.095715 | TVb: 1.929646 | GSw: -0.699528 | GSb: -0.413532 | TSUw: -0.381334 | TSUb: 0.009605\n",
      "\n",
      "Train Epoch: 5042 [4000/8000 (50%)]\tBatch Loss: 0.014051\tLearning Rate (w_theta): 0.001000\t TIME:148.2s\n",
      "\t\t\t\tDisc: 0.012437\t\tSym: 0.000000\t\tSpars: 0.001614\n",
      "\t TVw: 1.094878 | TVb: 1.930575 | GSw: -0.699456 | GSb: -0.413435 | TSUw: -0.381297 | TSUb: 0.009501\n",
      "Validating epoch 5042...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013706937479651304\n",
      "Average validation loss: 0.014179034900886768\n",
      "Training epoch 5043...\n",
      "\n",
      "Train Epoch: 5043 [0/8000 (0%)]\tBatch Loss: 0.013679\tLearning Rate (w_theta): 0.001000\t TIME:150.4s\n",
      "\t\t\t\tDisc: 0.012216\t\tSym: 0.000000\t\tSpars: 0.001463\n",
      "\t TVw: 1.094027 | TVb: 1.931505 | GSw: -0.699382 | GSb: -0.413336 | TSUw: -0.381241 | TSUb: 0.009406\n",
      "\n",
      "Train Epoch: 5043 [4000/8000 (50%)]\tBatch Loss: 0.014097\tLearning Rate (w_theta): 0.001000\t TIME:151.7s\n",
      "\t\t\t\tDisc: 0.012369\t\tSym: 0.000000\t\tSpars: 0.001728\n",
      "\t TVw: 1.092998 | TVb: 1.932410 | GSw: -0.699302 | GSb: -0.413229 | TSUw: -0.381064 | TSUb: 0.009378\n",
      "Validating epoch 5043...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013701932648545726\n",
      "Average validation loss: 0.01417408416499327\n",
      "Training epoch 5044...\n",
      "\n",
      "Train Epoch: 5044 [0/8000 (0%)]\tBatch Loss: 0.013524\tLearning Rate (w_theta): 0.001000\t TIME:153.9s\n",
      "\t\t\t\tDisc: 0.012428\t\tSym: 0.000000\t\tSpars: 0.001096\n",
      "\t TVw: 1.092108 | TVb: 1.933323 | GSw: -0.699229 | GSb: -0.413131 | TSUw: -0.381014 | TSUb: 0.009280\n",
      "\n",
      "Train Epoch: 5044 [4000/8000 (50%)]\tBatch Loss: 0.013202\tLearning Rate (w_theta): 0.001000\t TIME:155.1s\n",
      "\t\t\t\tDisc: 0.011944\t\tSym: 0.000000\t\tSpars: 0.001258\n",
      "\t TVw: 1.091522 | TVb: 1.934281 | GSw: -0.699166 | GSb: -0.413044 | TSUw: -0.381132 | TSUb: 0.009091\n",
      "Validating epoch 5044...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013696605658414596\n",
      "Average validation loss: 0.014168883754322367\n",
      "Training epoch 5045...\n",
      "\n",
      "Train Epoch: 5045 [0/8000 (0%)]\tBatch Loss: 0.013400\tLearning Rate (w_theta): 0.001000\t TIME:157.3s\n",
      "\t\t\t\tDisc: 0.011969\t\tSym: 0.000000\t\tSpars: 0.001431\n",
      "\t TVw: 1.090741 | TVb: 1.935198 | GSw: -0.699096 | GSb: -0.412948 | TSUw: -0.381127 | TSUb: 0.008970\n",
      "\n",
      "Train Epoch: 5045 [4000/8000 (50%)]\tBatch Loss: 0.014131\tLearning Rate (w_theta): 0.001000\t TIME:158.5s\n",
      "\t\t\t\tDisc: 0.012661\t\tSym: 0.000000\t\tSpars: 0.001470\n",
      "\t TVw: 1.089954 | TVb: 1.936108 | GSw: -0.699021 | GSb: -0.412847 | TSUw: -0.381051 | TSUb: 0.008887\n",
      "Validating epoch 5045...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013690987114748135\n",
      "Average validation loss: 0.014163897070496988\n",
      "Training epoch 5046...\n",
      "\n",
      "Train Epoch: 5046 [0/8000 (0%)]\tBatch Loss: 0.013568\tLearning Rate (w_theta): 0.001000\t TIME:160.7s\n",
      "\t\t\t\tDisc: 0.012274\t\tSym: 0.000000\t\tSpars: 0.001294\n",
      "\t TVw: 1.089065 | TVb: 1.937018 | GSw: -0.698949 | GSb: -0.412750 | TSUw: -0.381022 | TSUb: 0.008778\n",
      "\n",
      "Train Epoch: 5046 [4000/8000 (50%)]\tBatch Loss: 0.014090\tLearning Rate (w_theta): 0.001000\t TIME:162.0s\n",
      "\t\t\t\tDisc: 0.012761\t\tSym: 0.000000\t\tSpars: 0.001329\n",
      "\t TVw: 1.088352 | TVb: 1.937960 | GSw: -0.698882 | GSb: -0.412657 | TSUw: -0.381072 | TSUb: 0.008627\n",
      "Validating epoch 5046...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013685851186976364\n",
      "Average validation loss: 0.01415878894650816\n",
      "Training epoch 5047...\n",
      "\n",
      "Train Epoch: 5047 [0/8000 (0%)]\tBatch Loss: 0.013866\tLearning Rate (w_theta): 0.001000\t TIME:164.2s\n",
      "\t\t\t\tDisc: 0.012417\t\tSym: 0.000000\t\tSpars: 0.001450\n",
      "\t TVw: 1.087514 | TVb: 1.938882 | GSw: -0.698809 | GSb: -0.412559 | TSUw: -0.381044 | TSUb: 0.008519\n",
      "\n",
      "Train Epoch: 5047 [4000/8000 (50%)]\tBatch Loss: 0.013623\tLearning Rate (w_theta): 0.001000\t TIME:165.5s\n",
      "\t\t\t\tDisc: 0.012467\t\tSym: 0.000000\t\tSpars: 0.001156\n",
      "\t TVw: 1.086717 | TVb: 1.939796 | GSw: -0.698734 | GSb: -0.412458 | TSUw: -0.380979 | TSUb: 0.008430\n",
      "Validating epoch 5047...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013680466602319485\n",
      "Average validation loss: 0.014153797182781456\n",
      "Training epoch 5048...\n",
      "\n",
      "Train Epoch: 5048 [0/8000 (0%)]\tBatch Loss: 0.014133\tLearning Rate (w_theta): 0.001000\t TIME:167.8s\n",
      "\t\t\t\tDisc: 0.012512\t\tSym: 0.000000\t\tSpars: 0.001622\n",
      "\t TVw: 1.085840 | TVb: 1.940706 | GSw: -0.698660 | GSb: -0.412359 | TSUw: -0.380931 | TSUb: 0.008333\n",
      "\n",
      "Train Epoch: 5048 [4000/8000 (50%)]\tBatch Loss: 0.013502\tLearning Rate (w_theta): 0.001000\t TIME:169.1s\n",
      "\t\t\t\tDisc: 0.012376\t\tSym: 0.000000\t\tSpars: 0.001126\n",
      "\t TVw: 1.085058 | TVb: 1.941630 | GSw: -0.698593 | GSb: -0.412265 | TSUw: -0.381008 | TSUb: 0.008168\n",
      "Validating epoch 5048...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013675317441331691\n",
      "Average validation loss: 0.014148783816795801\n",
      "Training epoch 5049...\n",
      "\n",
      "Train Epoch: 5049 [0/8000 (0%)]\tBatch Loss: 0.013549\tLearning Rate (w_theta): 0.001000\t TIME:171.2s\n",
      "\t\t\t\tDisc: 0.012101\t\tSym: 0.000000\t\tSpars: 0.001448\n",
      "\t TVw: 1.084270 | TVb: 1.942544 | GSw: -0.698519 | GSb: -0.412166 | TSUw: -0.380980 | TSUb: 0.008060\n",
      "\n",
      "Train Epoch: 5049 [4000/8000 (50%)]\tBatch Loss: 0.013807\tLearning Rate (w_theta): 0.001000\t TIME:172.5s\n",
      "\t\t\t\tDisc: 0.012235\t\tSym: 0.000000\t\tSpars: 0.001572\n",
      "\t TVw: 1.083388 | TVb: 1.943456 | GSw: -0.698448 | GSb: -0.412070 | TSUw: -0.380977 | TSUb: 0.007938\n",
      "Validating epoch 5049...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013670060178692921\n",
      "Average validation loss: 0.014143883158651378\n",
      "Training epoch 5050...\n",
      "\n",
      "Train Epoch: 5050 [0/8000 (0%)]\tBatch Loss: 0.013807\tLearning Rate (w_theta): 0.001000\t TIME:174.7s\n",
      "\t\t\t\tDisc: 0.012441\t\tSym: 0.000000\t\tSpars: 0.001366\n",
      "\t TVw: 1.082594 | TVb: 1.944363 | GSw: -0.698374 | GSb: -0.411970 | TSUw: -0.380942 | TSUb: 0.007835\n",
      "\n",
      "Train Epoch: 5050 [4000/8000 (50%)]\tBatch Loss: 0.013949\tLearning Rate (w_theta): 0.001000\t TIME:176.0s\n",
      "\t\t\t\tDisc: 0.012746\t\tSym: 0.000000\t\tSpars: 0.001204\n",
      "\t TVw: 1.081731 | TVb: 1.945260 | GSw: -0.698302 | GSb: -0.411872 | TSUw: -0.380918 | TSUb: 0.007725\n",
      "Validating epoch 5050...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013664995787771863\n",
      "Average validation loss: 0.014139009718062947\n",
      "Training epoch 5051...\n",
      "\n",
      "Train Epoch: 5051 [0/8000 (0%)]\tBatch Loss: 0.013417\tLearning Rate (w_theta): 0.001000\t TIME:178.9s\n",
      "\t\t\t\tDisc: 0.012088\t\tSym: 0.000000\t\tSpars: 0.001329\n",
      "\t TVw: 1.080894 | TVb: 1.946164 | GSw: -0.698225 | GSb: -0.411768 | TSUw: -0.380838 | TSUb: 0.007647\n",
      "\n",
      "Train Epoch: 5051 [4000/8000 (50%)]\tBatch Loss: 0.013924\tLearning Rate (w_theta): 0.001000\t TIME:180.2s\n",
      "\t\t\t\tDisc: 0.012205\t\tSym: 0.000000\t\tSpars: 0.001718\n",
      "\t TVw: 1.080090 | TVb: 1.947075 | GSw: -0.698147 | GSb: -0.411664 | TSUw: -0.380748 | TSUb: 0.007573\n",
      "Validating epoch 5051...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01365998417358628\n",
      "Average validation loss: 0.014133807038551136\n",
      "Training epoch 5052...\n",
      "\n",
      "Train Epoch: 5052 [0/8000 (0%)]\tBatch Loss: 0.013657\tLearning Rate (w_theta): 0.001000\t TIME:182.4s\n",
      "\t\t\t\tDisc: 0.012267\t\tSym: 0.000000\t\tSpars: 0.001390\n",
      "\t TVw: 1.079454 | TVb: 1.948002 | GSw: -0.698074 | GSb: -0.411564 | TSUw: -0.380744 | TSUb: 0.007452\n",
      "\n",
      "Train Epoch: 5052 [4000/8000 (50%)]\tBatch Loss: 0.013301\tLearning Rate (w_theta): 0.001000\t TIME:183.7s\n",
      "\t\t\t\tDisc: 0.012151\t\tSym: 0.000000\t\tSpars: 0.001150\n",
      "\t TVw: 1.078451 | TVb: 1.948877 | GSw: -0.697993 | GSb: -0.411457 | TSUw: -0.380589 | TSUb: 0.007414\n",
      "Validating epoch 5052...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01365492113964524\n",
      "Average validation loss: 0.014128897933274653\n",
      "Training epoch 5053...\n",
      "\n",
      "Train Epoch: 5053 [0/8000 (0%)]\tBatch Loss: 0.013947\tLearning Rate (w_theta): 0.001000\t TIME:186.0s\n",
      "\t\t\t\tDisc: 0.012450\t\tSym: 0.000000\t\tSpars: 0.001497\n",
      "\t TVw: 1.077773 | TVb: 1.949792 | GSw: -0.697918 | GSb: -0.411356 | TSUw: -0.380568 | TSUb: 0.007303\n",
      "\n",
      "Train Epoch: 5053 [4000/8000 (50%)]\tBatch Loss: 0.013010\tLearning Rate (w_theta): 0.001000\t TIME:187.3s\n",
      "\t\t\t\tDisc: 0.011982\t\tSym: 0.000000\t\tSpars: 0.001028\n",
      "\t TVw: 1.076955 | TVb: 1.950683 | GSw: -0.697837 | GSb: -0.411248 | TSUw: -0.380449 | TSUb: 0.007246\n",
      "Validating epoch 5053...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013649792183067826\n",
      "Average validation loss: 0.014123883586871111\n",
      "Training epoch 5054...\n",
      "\n",
      "Train Epoch: 5054 [0/8000 (0%)]\tBatch Loss: 0.013661\tLearning Rate (w_theta): 0.001000\t TIME:189.5s\n",
      "\t\t\t\tDisc: 0.012398\t\tSym: 0.000000\t\tSpars: 0.001263\n",
      "\t TVw: 1.076235 | TVb: 1.951598 | GSw: -0.697767 | GSb: -0.411151 | TSUw: -0.380484 | TSUb: 0.007105\n",
      "\n",
      "Train Epoch: 5054 [4000/8000 (50%)]\tBatch Loss: 0.012630\tLearning Rate (w_theta): 0.001000\t TIME:190.8s\n",
      "\t\t\t\tDisc: 0.011738\t\tSym: 0.000000\t\tSpars: 0.000893\n",
      "\t TVw: 1.075451 | TVb: 1.952509 | GSw: -0.697695 | GSb: -0.411053 | TSUw: -0.380507 | TSUb: 0.006971\n",
      "Validating epoch 5054...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013644575214589704\n",
      "Average validation loss: 0.014119019708387536\n",
      "Training epoch 5055...\n",
      "\n",
      "Train Epoch: 5055 [0/8000 (0%)]\tBatch Loss: 0.013885\tLearning Rate (w_theta): 0.001000\t TIME:193.0s\n",
      "\t\t\t\tDisc: 0.012397\t\tSym: 0.000000\t\tSpars: 0.001487\n",
      "\t TVw: 1.074754 | TVb: 1.953424 | GSw: -0.697625 | GSb: -0.410957 | TSUw: -0.380555 | TSUb: 0.006823\n",
      "\n",
      "Train Epoch: 5055 [4000/8000 (50%)]\tBatch Loss: 0.013851\tLearning Rate (w_theta): 0.001000\t TIME:194.3s\n",
      "\t\t\t\tDisc: 0.012193\t\tSym: 0.000000\t\tSpars: 0.001658\n",
      "\t TVw: 1.074332 | TVb: 1.954385 | GSw: -0.697557 | GSb: -0.410862 | TSUw: -0.380634 | TSUb: 0.006658\n",
      "Validating epoch 5055...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013639074758003095\n",
      "Average validation loss: 0.014113715185478777\n",
      "Training epoch 5056...\n",
      "\n",
      "Train Epoch: 5056 [0/8000 (0%)]\tBatch Loss: 0.013324\tLearning Rate (w_theta): 0.001000\t TIME:196.5s\n",
      "\t\t\t\tDisc: 0.012206\t\tSym: 0.000000\t\tSpars: 0.001118\n",
      "\t TVw: 1.073606 | TVb: 1.955282 | GSw: -0.697482 | GSb: -0.410760 | TSUw: -0.380627 | TSUb: 0.006541\n",
      "\n",
      "Train Epoch: 5056 [4000/8000 (50%)]\tBatch Loss: 0.013518\tLearning Rate (w_theta): 0.001000\t TIME:197.8s\n",
      "\t\t\t\tDisc: 0.012077\t\tSym: 0.000000\t\tSpars: 0.001442\n",
      "\t TVw: 1.072745 | TVb: 1.956145 | GSw: -0.697400 | GSb: -0.410650 | TSUw: -0.380498 | TSUb: 0.006490\n",
      "Validating epoch 5056...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01363377800342783\n",
      "Average validation loss: 0.014108975081611217\n",
      "Training epoch 5057...\n",
      "\n",
      "Train Epoch: 5057 [0/8000 (0%)]\tBatch Loss: 0.013429\tLearning Rate (w_theta): 0.001000\t TIME:200.1s\n",
      "\t\t\t\tDisc: 0.012282\t\tSym: 0.000000\t\tSpars: 0.001148\n",
      "\t TVw: 1.071938 | TVb: 1.957045 | GSw: -0.697324 | GSb: -0.410548 | TSUw: -0.380469 | TSUb: 0.006384\n",
      "\n",
      "Train Epoch: 5057 [4000/8000 (50%)]\tBatch Loss: 0.014109\tLearning Rate (w_theta): 0.001000\t TIME:201.4s\n",
      "\t\t\t\tDisc: 0.012715\t\tSym: 0.000000\t\tSpars: 0.001394\n",
      "\t TVw: 1.071033 | TVb: 1.957923 | GSw: -0.697255 | GSb: -0.410452 | TSUw: -0.380506 | TSUb: 0.006244\n",
      "Validating epoch 5057...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013628869868773347\n",
      "Average validation loss: 0.014104307063404414\n",
      "Training epoch 5058...\n",
      "\n",
      "Train Epoch: 5058 [0/8000 (0%)]\tBatch Loss: 0.013981\tLearning Rate (w_theta): 0.001000\t TIME:203.6s\n",
      "\t\t\t\tDisc: 0.012495\t\tSym: 0.000000\t\tSpars: 0.001485\n",
      "\t TVw: 1.070427 | TVb: 1.958844 | GSw: -0.697185 | GSb: -0.410355 | TSUw: -0.380557 | TSUb: 0.006096\n",
      "\n",
      "Train Epoch: 5058 [4000/8000 (50%)]\tBatch Loss: 0.013915\tLearning Rate (w_theta): 0.001000\t TIME:204.8s\n",
      "\t\t\t\tDisc: 0.012285\t\tSym: 0.000000\t\tSpars: 0.001629\n",
      "\t TVw: 1.069728 | TVb: 1.959768 | GSw: -0.697114 | GSb: -0.410257 | TSUw: -0.380585 | TSUb: 0.005961\n",
      "Validating epoch 5058...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013623624860238829\n",
      "Average validation loss: 0.014099299241496431\n",
      "Training epoch 5059...\n",
      "\n",
      "Train Epoch: 5059 [0/8000 (0%)]\tBatch Loss: 0.013334\tLearning Rate (w_theta): 0.001000\t TIME:207.1s\n",
      "\t\t\t\tDisc: 0.012187\t\tSym: 0.000000\t\tSpars: 0.001147\n",
      "\t TVw: 1.069029 | TVb: 1.960670 | GSw: -0.697037 | GSb: -0.410153 | TSUw: -0.380544 | TSUb: 0.005862\n",
      "\n",
      "Train Epoch: 5059 [4000/8000 (50%)]\tBatch Loss: 0.014062\tLearning Rate (w_theta): 0.001000\t TIME:208.3s\n",
      "\t\t\t\tDisc: 0.012830\t\tSym: 0.000000\t\tSpars: 0.001231\n",
      "\t TVw: 1.068211 | TVb: 1.961550 | GSw: -0.696957 | GSb: -0.410046 | TSUw: -0.380467 | TSUb: 0.005784\n",
      "Validating epoch 5059...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013618494175953266\n",
      "Average validation loss: 0.01409448082505256\n",
      "Training epoch 5060...\n",
      "\n",
      "Train Epoch: 5060 [0/8000 (0%)]\tBatch Loss: 0.013915\tLearning Rate (w_theta): 0.001000\t TIME:210.5s\n",
      "\t\t\t\tDisc: 0.012480\t\tSym: 0.000000\t\tSpars: 0.001435\n",
      "\t TVw: 1.067520 | TVb: 1.962453 | GSw: -0.696880 | GSb: -0.409941 | TSUw: -0.380426 | TSUb: 0.005686\n",
      "\n",
      "Train Epoch: 5060 [4000/8000 (50%)]\tBatch Loss: 0.013295\tLearning Rate (w_theta): 0.001000\t TIME:211.8s\n",
      "\t\t\t\tDisc: 0.012132\t\tSym: 0.000000\t\tSpars: 0.001163\n",
      "\t TVw: 1.066803 | TVb: 1.963361 | GSw: -0.696802 | GSb: -0.409836 | TSUw: -0.380375 | TSUb: 0.005594\n",
      "Validating epoch 5060...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013613473331978446\n",
      "Average validation loss: 0.014089577266825479\n",
      "Training epoch 5061...\n",
      "\n",
      "Train Epoch: 5061 [0/8000 (0%)]\tBatch Loss: 0.013237\tLearning Rate (w_theta): 0.001000\t TIME:214.8s\n",
      "\t\t\t\tDisc: 0.011799\t\tSym: 0.000000\t\tSpars: 0.001439\n",
      "\t TVw: 1.066019 | TVb: 1.964260 | GSw: -0.696728 | GSb: -0.409735 | TSUw: -0.380384 | TSUb: 0.005469\n",
      "\n",
      "Train Epoch: 5061 [4000/8000 (50%)]\tBatch Loss: 0.013270\tLearning Rate (w_theta): 0.001000\t TIME:216.1s\n",
      "\t\t\t\tDisc: 0.012245\t\tSym: 0.000000\t\tSpars: 0.001025\n",
      "\t TVw: 1.065306 | TVb: 1.965176 | GSw: -0.696657 | GSb: -0.409637 | TSUw: -0.380427 | TSUb: 0.005327\n",
      "Validating epoch 5061...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013608306497826832\n",
      "Average validation loss: 0.014084693263907211\n",
      "Training epoch 5062...\n",
      "\n",
      "Train Epoch: 5062 [0/8000 (0%)]\tBatch Loss: 0.013927\tLearning Rate (w_theta): 0.001000\t TIME:218.4s\n",
      "\t\t\t\tDisc: 0.012177\t\tSym: 0.000000\t\tSpars: 0.001751\n",
      "\t TVw: 1.064674 | TVb: 1.966078 | GSw: -0.696583 | GSb: -0.409535 | TSUw: -0.380441 | TSUb: 0.005200\n",
      "\n",
      "Train Epoch: 5062 [4000/8000 (50%)]\tBatch Loss: 0.013225\tLearning Rate (w_theta): 0.001000\t TIME:219.7s\n",
      "\t\t\t\tDisc: 0.012145\t\tSym: 0.000000\t\tSpars: 0.001081\n",
      "\t TVw: 1.064249 | TVb: 1.967008 | GSw: -0.696512 | GSb: -0.409437 | TSUw: -0.380529 | TSUb: 0.005033\n",
      "Validating epoch 5062...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01360286739016809\n",
      "Average validation loss: 0.014079635220763435\n",
      "Training epoch 5063...\n",
      "\n",
      "Train Epoch: 5063 [0/8000 (0%)]\tBatch Loss: 0.013438\tLearning Rate (w_theta): 0.001000\t TIME:221.9s\n",
      "\t\t\t\tDisc: 0.012491\t\tSym: 0.000000\t\tSpars: 0.000948\n",
      "\t TVw: 1.063371 | TVb: 1.967882 | GSw: -0.696432 | GSb: -0.409329 | TSUw: -0.380433 | TSUb: 0.004966\n",
      "\n",
      "Train Epoch: 5063 [4000/8000 (50%)]\tBatch Loss: 0.014055\tLearning Rate (w_theta): 0.001000\t TIME:223.1s\n",
      "\t\t\t\tDisc: 0.012351\t\tSym: 0.000000\t\tSpars: 0.001704\n",
      "\t TVw: 1.062533 | TVb: 1.968758 | GSw: -0.696355 | GSb: -0.409224 | TSUw: -0.380394 | TSUb: 0.004868\n",
      "Validating epoch 5063...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013597836479812013\n",
      "Average validation loss: 0.014075042304422098\n",
      "Training epoch 5064...\n",
      "\n",
      "Train Epoch: 5064 [0/8000 (0%)]\tBatch Loss: 0.013566\tLearning Rate (w_theta): 0.001000\t TIME:225.4s\n",
      "\t\t\t\tDisc: 0.012068\t\tSym: 0.000000\t\tSpars: 0.001498\n",
      "\t TVw: 1.061820 | TVb: 1.969643 | GSw: -0.696275 | GSb: -0.409117 | TSUw: -0.380338 | TSUb: 0.004780\n",
      "\n",
      "Train Epoch: 5064 [4000/8000 (50%)]\tBatch Loss: 0.013982\tLearning Rate (w_theta): 0.001000\t TIME:226.7s\n",
      "\t\t\t\tDisc: 0.012595\t\tSym: 0.000000\t\tSpars: 0.001387\n",
      "\t TVw: 1.061323 | TVb: 1.970569 | GSw: -0.696208 | GSb: -0.409023 | TSUw: -0.380433 | TSUb: 0.004611\n",
      "Validating epoch 5064...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013592762562119057\n",
      "Average validation loss: 0.014070089372358024\n",
      "Training epoch 5065...\n",
      "\n",
      "Train Epoch: 5065 [0/8000 (0%)]\tBatch Loss: 0.013387\tLearning Rate (w_theta): 0.001000\t TIME:228.8s\n",
      "\t\t\t\tDisc: 0.012165\t\tSym: 0.000000\t\tSpars: 0.001222\n",
      "\t TVw: 1.060568 | TVb: 1.971452 | GSw: -0.696128 | GSb: -0.408915 | TSUw: -0.380352 | TSUb: 0.004536\n",
      "\n",
      "Train Epoch: 5065 [4000/8000 (50%)]\tBatch Loss: 0.013264\tLearning Rate (w_theta): 0.001000\t TIME:230.1s\n",
      "\t\t\t\tDisc: 0.012004\t\tSym: 0.000000\t\tSpars: 0.001260\n",
      "\t TVw: 1.059929 | TVb: 1.972342 | GSw: -0.696043 | GSb: -0.408803 | TSUw: -0.380242 | TSUb: 0.004477\n",
      "Validating epoch 5065...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013587510729864086\n",
      "Average validation loss: 0.014065250305103551\n",
      "Training epoch 5066...\n",
      "\n",
      "Train Epoch: 5066 [0/8000 (0%)]\tBatch Loss: 0.013659\tLearning Rate (w_theta): 0.001000\t TIME:232.4s\n",
      "\t\t\t\tDisc: 0.012460\t\tSym: 0.000000\t\tSpars: 0.001199\n",
      "\t TVw: 1.059123 | TVb: 1.973233 | GSw: -0.695967 | GSb: -0.408698 | TSUw: -0.380223 | TSUb: 0.004370\n",
      "\n",
      "Train Epoch: 5066 [4000/8000 (50%)]\tBatch Loss: 0.013260\tLearning Rate (w_theta): 0.001000\t TIME:233.7s\n",
      "\t\t\t\tDisc: 0.012086\t\tSym: 0.000000\t\tSpars: 0.001174\n",
      "\t TVw: 1.058495 | TVb: 1.974136 | GSw: -0.695891 | GSb: -0.408594 | TSUw: -0.380208 | TSUb: 0.004260\n",
      "Validating epoch 5066...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013582519670927985\n",
      "Average validation loss: 0.014060461461444471\n",
      "Training epoch 5067...\n",
      "\n",
      "Train Epoch: 5067 [0/8000 (0%)]\tBatch Loss: 0.013731\tLearning Rate (w_theta): 0.001000\t TIME:235.9s\n",
      "\t\t\t\tDisc: 0.012539\t\tSym: 0.000000\t\tSpars: 0.001192\n",
      "\t TVw: 1.057684 | TVb: 1.975007 | GSw: -0.695810 | GSb: -0.408484 | TSUw: -0.380123 | TSUb: 0.004189\n",
      "\n",
      "Train Epoch: 5067 [4000/8000 (50%)]\tBatch Loss: 0.013942\tLearning Rate (w_theta): 0.001000\t TIME:237.2s\n",
      "\t\t\t\tDisc: 0.012580\t\tSym: 0.000000\t\tSpars: 0.001362\n",
      "\t TVw: 1.056901 | TVb: 1.975880 | GSw: -0.695731 | GSb: -0.408378 | TSUw: -0.380088 | TSUb: 0.004090\n",
      "Validating epoch 5067...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013577642627894838\n",
      "Average validation loss: 0.014055891985000638\n",
      "Training epoch 5068...\n",
      "\n",
      "Train Epoch: 5068 [0/8000 (0%)]\tBatch Loss: 0.013409\tLearning Rate (w_theta): 0.001000\t TIME:239.4s\n",
      "\t\t\t\tDisc: 0.012119\t\tSym: 0.000000\t\tSpars: 0.001290\n",
      "\t TVw: 1.056130 | TVb: 1.976767 | GSw: -0.695654 | GSb: -0.408272 | TSUw: -0.380051 | TSUb: 0.003992\n",
      "\n",
      "Train Epoch: 5068 [4000/8000 (50%)]\tBatch Loss: 0.012537\tLearning Rate (w_theta): 0.001000\t TIME:240.7s\n",
      "\t\t\t\tDisc: 0.011414\t\tSym: 0.000000\t\tSpars: 0.001123\n",
      "\t TVw: 1.055251 | TVb: 1.977623 | GSw: -0.695567 | GSb: -0.408157 | TSUw: -0.379875 | TSUb: 0.003970\n",
      "Validating epoch 5068...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013573049186172411\n",
      "Average validation loss: 0.014051269670804506\n",
      "Training epoch 5069...\n",
      "\n",
      "Train Epoch: 5069 [0/8000 (0%)]\tBatch Loss: 0.013001\tLearning Rate (w_theta): 0.001000\t TIME:242.9s\n",
      "\t\t\t\tDisc: 0.012046\t\tSym: 0.000000\t\tSpars: 0.000955\n",
      "\t TVw: 1.054482 | TVb: 1.978500 | GSw: -0.695489 | GSb: -0.408051 | TSUw: -0.379853 | TSUb: 0.003865\n",
      "\n",
      "Train Epoch: 5069 [4000/8000 (50%)]\tBatch Loss: 0.013986\tLearning Rate (w_theta): 0.001000\t TIME:244.1s\n",
      "\t\t\t\tDisc: 0.012379\t\tSym: 0.000000\t\tSpars: 0.001607\n",
      "\t TVw: 1.053641 | TVb: 1.979383 | GSw: -0.695413 | GSb: -0.407946 | TSUw: -0.379840 | TSUb: 0.003756\n",
      "Validating epoch 5069...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01356832639456476\n",
      "Average validation loss: 0.01404664746518854\n",
      "Training epoch 5070...\n",
      "\n",
      "Train Epoch: 5070 [0/8000 (0%)]\tBatch Loss: 0.013470\tLearning Rate (w_theta): 0.001000\t TIME:246.4s\n",
      "\t\t\t\tDisc: 0.012395\t\tSym: 0.000000\t\tSpars: 0.001075\n",
      "\t TVw: 1.053020 | TVb: 1.980277 | GSw: -0.695337 | GSb: -0.407842 | TSUw: -0.379862 | TSUb: 0.003627\n",
      "\n",
      "Train Epoch: 5070 [4000/8000 (50%)]\tBatch Loss: 0.013848\tLearning Rate (w_theta): 0.001000\t TIME:247.7s\n",
      "\t\t\t\tDisc: 0.012593\t\tSym: 0.000000\t\tSpars: 0.001255\n",
      "\t TVw: 1.052176 | TVb: 1.981167 | GSw: -0.695265 | GSb: -0.407741 | TSUw: -0.379913 | TSUb: 0.003483\n",
      "Validating epoch 5070...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013563376298526173\n",
      "Average validation loss: 0.01404220528466196\n",
      "Training epoch 5071...\n",
      "\n",
      "Train Epoch: 5071 [0/8000 (0%)]\tBatch Loss: 0.014416\tLearning Rate (w_theta): 0.001000\t TIME:250.7s\n",
      "\t\t\t\tDisc: 0.013111\t\tSym: 0.000000\t\tSpars: 0.001305\n",
      "\t TVw: 1.051438 | TVb: 1.982047 | GSw: -0.695187 | GSb: -0.407635 | TSUw: -0.379902 | TSUb: 0.003372\n",
      "\n",
      "Train Epoch: 5071 [4000/8000 (50%)]\tBatch Loss: 0.013487\tLearning Rate (w_theta): 0.001000\t TIME:252.0s\n",
      "\t\t\t\tDisc: 0.012211\t\tSym: 0.000000\t\tSpars: 0.001276\n",
      "\t TVw: 1.050541 | TVb: 1.982917 | GSw: -0.695108 | GSb: -0.407526 | TSUw: -0.379828 | TSUb: 0.003296\n",
      "Validating epoch 5071...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013558691159945535\n",
      "Average validation loss: 0.014037622901619244\n",
      "Training epoch 5072...\n",
      "\n",
      "Train Epoch: 5072 [0/8000 (0%)]\tBatch Loss: 0.013555\tLearning Rate (w_theta): 0.001000\t TIME:254.2s\n",
      "\t\t\t\tDisc: 0.011993\t\tSym: 0.000000\t\tSpars: 0.001562\n",
      "\t TVw: 1.049923 | TVb: 1.983809 | GSw: -0.695036 | GSb: -0.407425 | TSUw: -0.379901 | TSUb: 0.003141\n",
      "\n",
      "Train Epoch: 5072 [4000/8000 (50%)]\tBatch Loss: 0.013300\tLearning Rate (w_theta): 0.001000\t TIME:255.5s\n",
      "\t\t\t\tDisc: 0.012317\t\tSym: 0.000000\t\tSpars: 0.000983\n",
      "\t TVw: 1.049269 | TVb: 1.984698 | GSw: -0.694955 | GSb: -0.407314 | TSUw: -0.379840 | TSUb: 0.003057\n",
      "Validating epoch 5072...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013553706509108645\n",
      "Average validation loss: 0.014032726531297725\n",
      "Training epoch 5073...\n",
      "\n",
      "Train Epoch: 5073 [0/8000 (0%)]\tBatch Loss: 0.013685\tLearning Rate (w_theta): 0.001000\t TIME:257.7s\n",
      "\t\t\t\tDisc: 0.012549\t\tSym: 0.000000\t\tSpars: 0.001137\n",
      "\t TVw: 1.048617 | TVb: 1.985584 | GSw: -0.694874 | GSb: -0.407205 | TSUw: -0.379797 | TSUb: 0.002965\n",
      "\n",
      "Train Epoch: 5073 [4000/8000 (50%)]\tBatch Loss: 0.012979\tLearning Rate (w_theta): 0.001000\t TIME:259.0s\n",
      "\t\t\t\tDisc: 0.011754\t\tSym: 0.000000\t\tSpars: 0.001226\n",
      "\t TVw: 1.047821 | TVb: 1.986447 | GSw: -0.694790 | GSb: -0.407093 | TSUw: -0.379671 | TSUb: 0.002917\n",
      "Validating epoch 5073...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01354877747645704\n",
      "Average validation loss: 0.014028069816286872\n",
      "Training epoch 5074...\n",
      "\n",
      "Train Epoch: 5074 [0/8000 (0%)]\tBatch Loss: 0.013013\tLearning Rate (w_theta): 0.001000\t TIME:261.2s\n",
      "\t\t\t\tDisc: 0.011610\t\tSym: 0.000000\t\tSpars: 0.001403\n",
      "\t TVw: 1.047172 | TVb: 1.987340 | GSw: -0.694720 | GSb: -0.406994 | TSUw: -0.379783 | TSUb: 0.002741\n",
      "\n",
      "Train Epoch: 5074 [4000/8000 (50%)]\tBatch Loss: 0.013618\tLearning Rate (w_theta): 0.001000\t TIME:262.4s\n",
      "\t\t\t\tDisc: 0.012435\t\tSym: 0.000000\t\tSpars: 0.001183\n",
      "\t TVw: 1.046508 | TVb: 1.988232 | GSw: -0.694649 | GSb: -0.406895 | TSUw: -0.379892 | TSUb: 0.002567\n",
      "Validating epoch 5074...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01354376021633498\n",
      "Average validation loss: 0.014023445216674823\n",
      "Training epoch 5075...\n",
      "\n",
      "Train Epoch: 5075 [0/8000 (0%)]\tBatch Loss: 0.013386\tLearning Rate (w_theta): 0.001000\t TIME:264.7s\n",
      "\t\t\t\tDisc: 0.012153\t\tSym: 0.000000\t\tSpars: 0.001233\n",
      "\t TVw: 1.045893 | TVb: 1.989109 | GSw: -0.694569 | GSb: -0.406786 | TSUw: -0.379876 | TSUb: 0.002461\n",
      "\n",
      "Train Epoch: 5075 [4000/8000 (50%)]\tBatch Loss: 0.012934\tLearning Rate (w_theta): 0.001000\t TIME:266.0s\n",
      "\t\t\t\tDisc: 0.011833\t\tSym: 0.000000\t\tSpars: 0.001101\n",
      "\t TVw: 1.045145 | TVb: 1.989975 | GSw: -0.694494 | GSb: -0.406682 | TSUw: -0.379907 | TSUb: 0.002329\n",
      "Validating epoch 5075...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013538746773916638\n",
      "Average validation loss: 0.014019003432655311\n",
      "Training epoch 5076...\n",
      "\n",
      "Train Epoch: 5076 [0/8000 (0%)]\tBatch Loss: 0.013646\tLearning Rate (w_theta): 0.001000\t TIME:268.2s\n",
      "\t\t\t\tDisc: 0.012034\t\tSym: 0.000000\t\tSpars: 0.001612\n",
      "\t TVw: 1.044534 | TVb: 1.990851 | GSw: -0.694419 | GSb: -0.406578 | TSUw: -0.379963 | TSUb: 0.002185\n",
      "\n",
      "Train Epoch: 5076 [4000/8000 (50%)]\tBatch Loss: 0.013377\tLearning Rate (w_theta): 0.001000\t TIME:269.5s\n",
      "\t\t\t\tDisc: 0.012454\t\tSym: 0.000000\t\tSpars: 0.000923\n",
      "\t TVw: 1.043961 | TVb: 1.991757 | GSw: -0.694346 | GSb: -0.406477 | TSUw: -0.380034 | TSUb: 0.002031\n",
      "Validating epoch 5076...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013533826215435158\n",
      "Average validation loss: 0.014014329001031703\n",
      "Training epoch 5077...\n",
      "\n",
      "Train Epoch: 5077 [0/8000 (0%)]\tBatch Loss: 0.013628\tLearning Rate (w_theta): 0.001000\t TIME:271.8s\n",
      "\t\t\t\tDisc: 0.012386\t\tSym: 0.000000\t\tSpars: 0.001243\n",
      "\t TVw: 1.043143 | TVb: 1.992621 | GSw: -0.694263 | GSb: -0.406363 | TSUw: -0.379946 | TSUb: 0.001965\n",
      "\n",
      "Train Epoch: 5077 [4000/8000 (50%)]\tBatch Loss: 0.013558\tLearning Rate (w_theta): 0.001000\t TIME:273.1s\n",
      "\t\t\t\tDisc: 0.012308\t\tSym: 0.000000\t\tSpars: 0.001250\n",
      "\t TVw: 1.042412 | TVb: 1.993480 | GSw: -0.694180 | GSb: -0.406250 | TSUw: -0.379890 | TSUb: 0.001881\n",
      "Validating epoch 5077...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013529012040335586\n",
      "Average validation loss: 0.014009785059015158\n",
      "Training epoch 5078...\n",
      "\n",
      "Train Epoch: 5078 [0/8000 (0%)]\tBatch Loss: 0.013673\tLearning Rate (w_theta): 0.001000\t TIME:275.2s\n",
      "\t\t\t\tDisc: 0.012221\t\tSym: 0.000000\t\tSpars: 0.001452\n",
      "\t TVw: 1.041742 | TVb: 1.994351 | GSw: -0.694101 | GSb: -0.406142 | TSUw: -0.379891 | TSUb: 0.001767\n",
      "\n",
      "Train Epoch: 5078 [4000/8000 (50%)]\tBatch Loss: 0.012315\tLearning Rate (w_theta): 0.001000\t TIME:276.5s\n",
      "\t\t\t\tDisc: 0.011461\t\tSym: 0.000000\t\tSpars: 0.000854\n",
      "\t TVw: 1.041369 | TVb: 1.995245 | GSw: -0.694028 | GSb: -0.406040 | TSUw: -0.380014 | TSUb: 0.001586\n",
      "Validating epoch 5078...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013524085492520429\n",
      "Average validation loss: 0.014005166861859342\n",
      "Training epoch 5079...\n",
      "\n",
      "Train Epoch: 5079 [0/8000 (0%)]\tBatch Loss: 0.014077\tLearning Rate (w_theta): 0.001000\t TIME:278.8s\n",
      "\t\t\t\tDisc: 0.012363\t\tSym: 0.000000\t\tSpars: 0.001714\n",
      "\t TVw: 1.040629 | TVb: 1.996099 | GSw: -0.693947 | GSb: -0.405929 | TSUw: -0.379992 | TSUb: 0.001485\n",
      "\n",
      "Train Epoch: 5079 [4000/8000 (50%)]\tBatch Loss: 0.013522\tLearning Rate (w_theta): 0.001000\t TIME:280.1s\n",
      "\t\t\t\tDisc: 0.012355\t\tSym: 0.000000\t\tSpars: 0.001166\n",
      "\t TVw: 1.039798 | TVb: 1.996957 | GSw: -0.693868 | GSb: -0.405821 | TSUw: -0.380004 | TSUb: 0.001366\n",
      "Validating epoch 5079...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013519369292807117\n",
      "Average validation loss: 0.014000848621063149\n",
      "Training epoch 5080...\n",
      "\n",
      "Train Epoch: 5080 [0/8000 (0%)]\tBatch Loss: 0.013649\tLearning Rate (w_theta): 0.001000\t TIME:282.3s\n",
      "\t\t\t\tDisc: 0.012231\t\tSym: 0.000000\t\tSpars: 0.001418\n",
      "\t TVw: 1.039009 | TVb: 1.997799 | GSw: -0.693779 | GSb: -0.405702 | TSUw: -0.379855 | TSUb: 0.001334\n",
      "\n",
      "Train Epoch: 5080 [4000/8000 (50%)]\tBatch Loss: 0.013795\tLearning Rate (w_theta): 0.001000\t TIME:283.6s\n",
      "\t\t\t\tDisc: 0.012317\t\tSym: 0.000000\t\tSpars: 0.001478\n",
      "\t TVw: 1.038246 | TVb: 1.998636 | GSw: -0.693698 | GSb: -0.405591 | TSUw: -0.379814 | TSUb: 0.001244\n",
      "Validating epoch 5080...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01351489954532701\n",
      "Average validation loss: 0.013996562743298633\n",
      "Training epoch 5081...\n",
      "\n",
      "Train Epoch: 5081 [0/8000 (0%)]\tBatch Loss: 0.013887\tLearning Rate (w_theta): 0.001000\t TIME:286.5s\n",
      "\t\t\t\tDisc: 0.012746\t\tSym: 0.000000\t\tSpars: 0.001141\n",
      "\t TVw: 1.037414 | TVb: 1.999472 | GSw: -0.693613 | GSb: -0.405476 | TSUw: -0.379721 | TSUb: 0.001182\n",
      "\n",
      "Train Epoch: 5081 [4000/8000 (50%)]\tBatch Loss: 0.013498\tLearning Rate (w_theta): 0.001000\t TIME:287.9s\n",
      "\t\t\t\tDisc: 0.012135\t\tSym: 0.000000\t\tSpars: 0.001362\n",
      "\t TVw: 1.036691 | TVb: 2.000346 | GSw: -0.693533 | GSb: -0.405366 | TSUw: -0.379692 | TSUb: 0.001085\n",
      "Validating epoch 5081...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01351058793025158\n",
      "Average validation loss: 0.013992231437648784\n",
      "Training epoch 5082...\n",
      "\n",
      "Train Epoch: 5082 [0/8000 (0%)]\tBatch Loss: 0.014035\tLearning Rate (w_theta): 0.001000\t TIME:290.1s\n",
      "\t\t\t\tDisc: 0.012773\t\tSym: 0.000000\t\tSpars: 0.001262\n",
      "\t TVw: 1.035875 | TVb: 2.001184 | GSw: -0.693452 | GSb: -0.405255 | TSUw: -0.379669 | TSUb: 0.000985\n",
      "\n",
      "Train Epoch: 5082 [4000/8000 (50%)]\tBatch Loss: 0.013541\tLearning Rate (w_theta): 0.001000\t TIME:291.4s\n",
      "\t\t\t\tDisc: 0.012486\t\tSym: 0.000000\t\tSpars: 0.001054\n",
      "\t TVw: 1.035226 | TVb: 2.002048 | GSw: -0.693372 | GSb: -0.405145 | TSUw: -0.379663 | TSUb: 0.000877\n",
      "Validating epoch 5082...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013506080697777771\n",
      "Average validation loss: 0.013987901484524999\n",
      "Training epoch 5083...\n",
      "\n",
      "Train Epoch: 5083 [0/8000 (0%)]\tBatch Loss: 0.012971\tLearning Rate (w_theta): 0.001000\t TIME:293.6s\n",
      "\t\t\t\tDisc: 0.012105\t\tSym: 0.000000\t\tSpars: 0.000866\n",
      "\t TVw: 1.034373 | TVb: 2.002881 | GSw: -0.693290 | GSb: -0.405033 | TSUw: -0.379631 | TSUb: 0.000783\n",
      "\n",
      "Train Epoch: 5083 [4000/8000 (50%)]\tBatch Loss: 0.013717\tLearning Rate (w_theta): 0.001000\t TIME:294.9s\n",
      "\t\t\t\tDisc: 0.012128\t\tSym: 0.000000\t\tSpars: 0.001589\n",
      "\t TVw: 1.033510 | TVb: 2.003704 | GSw: -0.693207 | GSb: -0.404920 | TSUw: -0.379584 | TSUb: 0.000697\n",
      "Validating epoch 5083...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013501823449958606\n",
      "Average validation loss: 0.013983786841430696\n",
      "Training epoch 5084...\n",
      "\n",
      "Train Epoch: 5084 [0/8000 (0%)]\tBatch Loss: 0.013846\tLearning Rate (w_theta): 0.001000\t TIME:297.2s\n",
      "\t\t\t\tDisc: 0.012557\t\tSym: 0.000000\t\tSpars: 0.001290\n",
      "\t TVw: 1.032822 | TVb: 2.004555 | GSw: -0.693125 | GSb: -0.404806 | TSUw: -0.379554 | TSUb: 0.000601\n",
      "\n",
      "Train Epoch: 5084 [4000/8000 (50%)]\tBatch Loss: 0.013899\tLearning Rate (w_theta): 0.001000\t TIME:298.4s\n",
      "\t\t\t\tDisc: 0.012721\t\tSym: 0.000000\t\tSpars: 0.001177\n",
      "\t TVw: 1.031911 | TVb: 2.005385 | GSw: -0.693047 | GSb: -0.404700 | TSUw: -0.379584 | TSUb: 0.000474\n",
      "Validating epoch 5084...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01349743071559863\n",
      "Average validation loss: 0.013979729882059228\n",
      "Training epoch 5085...\n",
      "\n",
      "Train Epoch: 5085 [0/8000 (0%)]\tBatch Loss: 0.013448\tLearning Rate (w_theta): 0.001000\t TIME:300.6s\n",
      "\t\t\t\tDisc: 0.012055\t\tSym: 0.000000\t\tSpars: 0.001393\n",
      "\t TVw: 1.031275 | TVb: 2.006243 | GSw: -0.692970 | GSb: -0.404592 | TSUw: -0.379640 | TSUb: 0.000333\n",
      "\n",
      "Train Epoch: 5085 [4000/8000 (50%)]\tBatch Loss: 0.013571\tLearning Rate (w_theta): 0.001000\t TIME:301.9s\n",
      "\t\t\t\tDisc: 0.012456\t\tSym: 0.000000\t\tSpars: 0.001115\n",
      "\t TVw: 1.030588 | TVb: 2.007101 | GSw: -0.692893 | GSb: -0.404484 | TSUw: -0.379694 | TSUb: 0.000193\n",
      "Validating epoch 5085...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013492952533882429\n",
      "Average validation loss: 0.013975312817795077\n",
      "Training epoch 5086...\n",
      "\n",
      "Train Epoch: 5086 [0/8000 (0%)]\tBatch Loss: 0.013496\tLearning Rate (w_theta): 0.001000\t TIME:304.2s\n",
      "\t\t\t\tDisc: 0.012366\t\tSym: 0.000000\t\tSpars: 0.001130\n",
      "\t TVw: 1.029883 | TVb: 2.007953 | GSw: -0.692810 | GSb: -0.404370 | TSUw: -0.379641 | TSUb: 0.000110\n",
      "\n",
      "Train Epoch: 5086 [4000/8000 (50%)]\tBatch Loss: 0.013713\tLearning Rate (w_theta): 0.001000\t TIME:305.5s\n",
      "\t\t\t\tDisc: 0.012504\t\tSym: 0.000000\t\tSpars: 0.001209\n",
      "\t TVw: 1.029281 | TVb: 2.008796 | GSw: -0.692732 | GSb: -0.404262 | TSUw: -0.379701 | TSUb: -0.000033\n",
      "Validating epoch 5086...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01348825595444303\n",
      "Average validation loss: 0.01397110586555817\n",
      "Training epoch 5087...\n",
      "\n",
      "Train Epoch: 5087 [0/8000 (0%)]\tBatch Loss: 0.013761\tLearning Rate (w_theta): 0.001000\t TIME:307.7s\n",
      "\t\t\t\tDisc: 0.012588\t\tSym: 0.000000\t\tSpars: 0.001173\n",
      "\t TVw: 1.028513 | TVb: 2.009635 | GSw: -0.692651 | GSb: -0.404150 | TSUw: -0.379691 | TSUb: -0.000137\n",
      "\n",
      "Train Epoch: 5087 [4000/8000 (50%)]\tBatch Loss: 0.013182\tLearning Rate (w_theta): 0.001000\t TIME:308.9s\n",
      "\t\t\t\tDisc: 0.011873\t\tSym: 0.000000\t\tSpars: 0.001309\n",
      "\t TVw: 1.027631 | TVb: 2.010441 | GSw: -0.692559 | GSb: -0.404026 | TSUw: -0.379520 | TSUb: -0.000155\n",
      "Validating epoch 5087...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01348408676335479\n",
      "Average validation loss: 0.01396690112185661\n",
      "Training epoch 5088...\n",
      "\n",
      "Train Epoch: 5088 [0/8000 (0%)]\tBatch Loss: 0.013534\tLearning Rate (w_theta): 0.001000\t TIME:311.2s\n",
      "\t\t\t\tDisc: 0.012374\t\tSym: 0.000000\t\tSpars: 0.001161\n",
      "\t TVw: 1.026891 | TVb: 2.011289 | GSw: -0.692477 | GSb: -0.403914 | TSUw: -0.379507 | TSUb: -0.000258\n",
      "\n",
      "Train Epoch: 5088 [4000/8000 (50%)]\tBatch Loss: 0.013889\tLearning Rate (w_theta): 0.001000\t TIME:312.5s\n",
      "\t\t\t\tDisc: 0.012682\t\tSym: 0.000000\t\tSpars: 0.001207\n",
      "\t TVw: 1.025965 | TVb: 2.012116 | GSw: -0.692388 | GSb: -0.403793 | TSUw: -0.379369 | TSUb: -0.000292\n",
      "Validating epoch 5088...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013479982035079854\n",
      "Average validation loss: 0.013962700729927292\n",
      "Training epoch 5089...\n",
      "\n",
      "Train Epoch: 5089 [0/8000 (0%)]\tBatch Loss: 0.013552\tLearning Rate (w_theta): 0.001000\t TIME:314.7s\n",
      "\t\t\t\tDisc: 0.012213\t\tSym: 0.000000\t\tSpars: 0.001339\n",
      "\t TVw: 1.025321 | TVb: 2.012972 | GSw: -0.692312 | GSb: -0.403686 | TSUw: -0.379450 | TSUb: -0.000446\n",
      "\n",
      "Train Epoch: 5089 [4000/8000 (50%)]\tBatch Loss: 0.013588\tLearning Rate (w_theta): 0.001000\t TIME:315.9s\n",
      "\t\t\t\tDisc: 0.012466\t\tSym: 0.000000\t\tSpars: 0.001121\n",
      "\t TVw: 1.024744 | TVb: 2.013837 | GSw: -0.692235 | GSb: -0.403578 | TSUw: -0.379504 | TSUb: -0.000585\n",
      "Validating epoch 5089...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01347536575914601\n",
      "Average validation loss: 0.013958438856548785\n",
      "Training epoch 5090...\n",
      "\n",
      "Train Epoch: 5090 [0/8000 (0%)]\tBatch Loss: 0.013591\tLearning Rate (w_theta): 0.001000\t TIME:318.2s\n",
      "\t\t\t\tDisc: 0.012180\t\tSym: 0.000000\t\tSpars: 0.001411\n",
      "\t TVw: 1.024022 | TVb: 2.014676 | GSw: -0.692157 | GSb: -0.403469 | TSUw: -0.379565 | TSUb: -0.000726\n",
      "\n",
      "Train Epoch: 5090 [4000/8000 (50%)]\tBatch Loss: 0.013244\tLearning Rate (w_theta): 0.001000\t TIME:319.4s\n",
      "\t\t\t\tDisc: 0.012149\t\tSym: 0.000000\t\tSpars: 0.001095\n",
      "\t TVw: 1.023372 | TVb: 2.015513 | GSw: -0.692076 | GSb: -0.403357 | TSUw: -0.379586 | TSUb: -0.000846\n",
      "Validating epoch 5090...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013470784570953452\n",
      "Average validation loss: 0.01395427638002863\n",
      "Training epoch 5091...\n",
      "\n",
      "Train Epoch: 5091 [0/8000 (0%)]\tBatch Loss: 0.013338\tLearning Rate (w_theta): 0.001000\t TIME:322.4s\n",
      "\t\t\t\tDisc: 0.012185\t\tSym: 0.000000\t\tSpars: 0.001152\n",
      "\t TVw: 1.022567 | TVb: 2.016330 | GSw: -0.691992 | GSb: -0.403242 | TSUw: -0.379556 | TSUb: -0.000939\n",
      "\n",
      "Train Epoch: 5091 [4000/8000 (50%)]\tBatch Loss: 0.013810\tLearning Rate (w_theta): 0.001000\t TIME:323.7s\n",
      "\t\t\t\tDisc: 0.012283\t\tSym: 0.000000\t\tSpars: 0.001528\n",
      "\t TVw: 1.021707 | TVb: 2.017116 | GSw: -0.691908 | GSb: -0.403126 | TSUw: -0.379542 | TSUb: -0.001040\n",
      "Validating epoch 5091...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013466660695804232\n",
      "Average validation loss: 0.013950550589903798\n",
      "Training epoch 5092...\n",
      "\n",
      "Train Epoch: 5092 [0/8000 (0%)]\tBatch Loss: 0.013766\tLearning Rate (w_theta): 0.001000\t TIME:325.8s\n",
      "\t\t\t\tDisc: 0.012422\t\tSym: 0.000000\t\tSpars: 0.001344\n",
      "\t TVw: 1.020841 | TVb: 2.017941 | GSw: -0.691825 | GSb: -0.403013 | TSUw: -0.379515 | TSUb: -0.001133\n",
      "\n",
      "Train Epoch: 5092 [4000/8000 (50%)]\tBatch Loss: 0.014082\tLearning Rate (w_theta): 0.001000\t TIME:327.1s\n",
      "\t\t\t\tDisc: 0.012935\t\tSym: 0.000000\t\tSpars: 0.001147\n",
      "\t TVw: 1.020334 | TVb: 2.018822 | GSw: -0.691753 | GSb: -0.402909 | TSUw: -0.379661 | TSUb: -0.001320\n",
      "Validating epoch 5092...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013462465841582717\n",
      "Average validation loss: 0.013946216153519708\n",
      "Training epoch 5093...\n",
      "\n",
      "Train Epoch: 5093 [0/8000 (0%)]\tBatch Loss: 0.013159\tLearning Rate (w_theta): 0.001000\t TIME:329.4s\n",
      "\t\t\t\tDisc: 0.012128\t\tSym: 0.000000\t\tSpars: 0.001030\n",
      "\t TVw: 1.019600 | TVb: 2.019658 | GSw: -0.691672 | GSb: -0.402797 | TSUw: -0.379673 | TSUb: -0.001434\n",
      "\n",
      "Train Epoch: 5093 [4000/8000 (50%)]\tBatch Loss: 0.013471\tLearning Rate (w_theta): 0.001000\t TIME:330.6s\n",
      "\t\t\t\tDisc: 0.012494\t\tSym: 0.000000\t\tSpars: 0.000978\n",
      "\t TVw: 1.019077 | TVb: 2.020527 | GSw: -0.691593 | GSb: -0.402687 | TSUw: -0.379731 | TSUb: -0.001572\n",
      "Validating epoch 5093...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013457765142054982\n",
      "Average validation loss: 0.013941989807073469\n",
      "Training epoch 5094...\n",
      "\n",
      "Train Epoch: 5094 [0/8000 (0%)]\tBatch Loss: 0.013180\tLearning Rate (w_theta): 0.001000\t TIME:332.8s\n",
      "\t\t\t\tDisc: 0.012038\t\tSym: 0.000000\t\tSpars: 0.001143\n",
      "\t TVw: 1.018189 | TVb: 2.021337 | GSw: -0.691503 | GSb: -0.402565 | TSUw: -0.379602 | TSUb: -0.001610\n",
      "\n",
      "Train Epoch: 5094 [4000/8000 (50%)]\tBatch Loss: 0.013689\tLearning Rate (w_theta): 0.001000\t TIME:334.1s\n",
      "\t\t\t\tDisc: 0.012290\t\tSym: 0.000000\t\tSpars: 0.001398\n",
      "\t TVw: 1.017396 | TVb: 2.022151 | GSw: -0.691409 | GSb: -0.402440 | TSUw: -0.379421 | TSUb: -0.001620\n",
      "Validating epoch 5094...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013453690833846565\n",
      "Average validation loss: 0.013937823692653652\n",
      "Training epoch 5095...\n",
      "\n",
      "Train Epoch: 5095 [0/8000 (0%)]\tBatch Loss: 0.012531\tLearning Rate (w_theta): 0.001000\t TIME:336.3s\n",
      "\t\t\t\tDisc: 0.011653\t\tSym: 0.000000\t\tSpars: 0.000878\n",
      "\t TVw: 1.016568 | TVb: 2.022968 | GSw: -0.691326 | GSb: -0.402326 | TSUw: -0.379409 | TSUb: -0.001719\n",
      "\n",
      "Train Epoch: 5095 [4000/8000 (50%)]\tBatch Loss: 0.013824\tLearning Rate (w_theta): 0.001000\t TIME:337.6s\n",
      "\t\t\t\tDisc: 0.012455\t\tSym: 0.000000\t\tSpars: 0.001369\n",
      "\t TVw: 1.015432 | TVb: 2.023754 | GSw: -0.691247 | GSb: -0.402215 | TSUw: -0.379414 | TSUb: -0.001828\n",
      "Validating epoch 5095...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013449775103607559\n",
      "Average validation loss: 0.013934290942276217\n",
      "Training epoch 5096...\n",
      "\n",
      "Train Epoch: 5096 [0/8000 (0%)]\tBatch Loss: 0.013207\tLearning Rate (w_theta): 0.001000\t TIME:339.8s\n",
      "\t\t\t\tDisc: 0.012121\t\tSym: 0.000000\t\tSpars: 0.001086\n",
      "\t TVw: 1.014682 | TVb: 2.024582 | GSw: -0.691166 | GSb: -0.402102 | TSUw: -0.379440 | TSUb: -0.001948\n",
      "\n",
      "Train Epoch: 5096 [4000/8000 (50%)]\tBatch Loss: 0.013344\tLearning Rate (w_theta): 0.001000\t TIME:341.1s\n",
      "\t\t\t\tDisc: 0.012120\t\tSym: 0.000000\t\tSpars: 0.001224\n",
      "\t TVw: 1.014071 | TVb: 2.025429 | GSw: -0.691099 | GSb: -0.402005 | TSUw: -0.379680 | TSUb: -0.002183\n",
      "Validating epoch 5096...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013445785517862347\n",
      "Average validation loss: 0.01393022485079906\n",
      "Training epoch 5097...\n",
      "\n",
      "Train Epoch: 5097 [0/8000 (0%)]\tBatch Loss: 0.013368\tLearning Rate (w_theta): 0.001000\t TIME:343.4s\n",
      "\t\t\t\tDisc: 0.012201\t\tSym: 0.000000\t\tSpars: 0.001167\n",
      "\t TVw: 1.013461 | TVb: 2.026262 | GSw: -0.691012 | GSb: -0.401886 | TSUw: -0.379633 | TSUb: -0.002264\n",
      "\n",
      "Train Epoch: 5097 [4000/8000 (50%)]\tBatch Loss: 0.013806\tLearning Rate (w_theta): 0.001000\t TIME:344.7s\n",
      "\t\t\t\tDisc: 0.012771\t\tSym: 0.000000\t\tSpars: 0.001035\n",
      "\t TVw: 1.012844 | TVb: 2.027079 | GSw: -0.690918 | GSb: -0.401759 | TSUw: -0.379498 | TSUb: -0.002297\n",
      "Validating epoch 5097...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013441152133063149\n",
      "Average validation loss: 0.013925928981564934\n",
      "Training epoch 5098...\n",
      "\n",
      "Train Epoch: 5098 [0/8000 (0%)]\tBatch Loss: 0.013327\tLearning Rate (w_theta): 0.001000\t TIME:346.9s\n",
      "\t\t\t\tDisc: 0.012206\t\tSym: 0.000000\t\tSpars: 0.001122\n",
      "\t TVw: 1.012162 | TVb: 2.027909 | GSw: -0.690832 | GSb: -0.401642 | TSUw: -0.379462 | TSUb: -0.002383\n",
      "\n",
      "Train Epoch: 5098 [4000/8000 (50%)]\tBatch Loss: 0.012835\tLearning Rate (w_theta): 0.001000\t TIME:348.2s\n",
      "\t\t\t\tDisc: 0.011983\t\tSym: 0.000000\t\tSpars: 0.000852\n",
      "\t TVw: 1.011394 | TVb: 2.028727 | GSw: -0.690746 | GSb: -0.401524 | TSUw: -0.379394 | TSUb: -0.002452\n",
      "Validating epoch 5098...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013436919176254796\n",
      "Average validation loss: 0.013921851306741761\n",
      "Training epoch 5099...\n",
      "\n",
      "Train Epoch: 5099 [0/8000 (0%)]\tBatch Loss: 0.013615\tLearning Rate (w_theta): 0.001000\t TIME:350.4s\n",
      "\t\t\t\tDisc: 0.012309\t\tSym: 0.000000\t\tSpars: 0.001305\n",
      "\t TVw: 1.010633 | TVb: 2.029546 | GSw: -0.690659 | GSb: -0.401404 | TSUw: -0.379340 | TSUb: -0.002528\n",
      "\n",
      "Train Epoch: 5099 [4000/8000 (50%)]\tBatch Loss: 0.012982\tLearning Rate (w_theta): 0.001000\t TIME:351.7s\n",
      "\t\t\t\tDisc: 0.011899\t\tSym: 0.000000\t\tSpars: 0.001083\n",
      "\t TVw: 1.009955 | TVb: 2.030379 | GSw: -0.690574 | GSb: -0.401287 | TSUw: -0.379353 | TSUb: -0.002640\n",
      "Validating epoch 5099...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013432824212274352\n",
      "Average validation loss: 0.013917746697202821\n",
      "Training epoch 5100...\n",
      "\n",
      "Train Epoch: 5100 [0/8000 (0%)]\tBatch Loss: 0.013579\tLearning Rate (w_theta): 0.001000\t TIME:353.9s\n",
      "\t\t\t\tDisc: 0.012336\t\tSym: 0.000000\t\tSpars: 0.001243\n",
      "\t TVw: 1.009200 | TVb: 2.031194 | GSw: -0.690488 | GSb: -0.401168 | TSUw: -0.379317 | TSUb: -0.002725\n",
      "\n",
      "Train Epoch: 5100 [4000/8000 (50%)]\tBatch Loss: 0.013652\tLearning Rate (w_theta): 0.001000\t TIME:355.2s\n",
      "\t\t\t\tDisc: 0.012423\t\tSym: 0.000000\t\tSpars: 0.001230\n",
      "\t TVw: 1.008384 | TVb: 2.031986 | GSw: -0.690396 | GSb: -0.401043 | TSUw: -0.379210 | TSUb: -0.002772\n",
      "Validating epoch 5100...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013428716395202876\n",
      "Average validation loss: 0.013913726534766893\n",
      "Training epoch 5101...\n",
      "\n",
      "Train Epoch: 5101 [0/8000 (0%)]\tBatch Loss: 0.013232\tLearning Rate (w_theta): 0.001000\t TIME:358.1s\n",
      "\t\t\t\tDisc: 0.011866\t\tSym: 0.000000\t\tSpars: 0.001366\n",
      "\t TVw: 1.007787 | TVb: 2.032826 | GSw: -0.690315 | GSb: -0.400930 | TSUw: -0.379260 | TSUb: -0.002903\n",
      "\n",
      "Train Epoch: 5101 [4000/8000 (50%)]\tBatch Loss: 0.013467\tLearning Rate (w_theta): 0.001000\t TIME:359.4s\n",
      "\t\t\t\tDisc: 0.012269\t\tSym: 0.000000\t\tSpars: 0.001198\n",
      "\t TVw: 1.007314 | TVb: 2.033679 | GSw: -0.690241 | GSb: -0.400824 | TSUw: -0.379408 | TSUb: -0.003088\n",
      "Validating epoch 5101...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013424252122960358\n",
      "Average validation loss: 0.013909701289151337\n",
      "Training epoch 5102...\n",
      "\n",
      "Train Epoch: 5102 [0/8000 (0%)]\tBatch Loss: 0.012906\tLearning Rate (w_theta): 0.001000\t TIME:361.6s\n",
      "\t\t\t\tDisc: 0.011846\t\tSym: 0.000000\t\tSpars: 0.001060\n",
      "\t TVw: 1.006556 | TVb: 2.034491 | GSw: -0.690163 | GSb: -0.400714 | TSUw: -0.379481 | TSUb: -0.003231\n",
      "\n",
      "Train Epoch: 5102 [4000/8000 (50%)]\tBatch Loss: 0.013118\tLearning Rate (w_theta): 0.001000\t TIME:362.9s\n",
      "\t\t\t\tDisc: 0.011937\t\tSym: 0.000000\t\tSpars: 0.001181\n",
      "\t TVw: 1.005784 | TVb: 2.035317 | GSw: -0.690079 | GSb: -0.400597 | TSUw: -0.379460 | TSUb: -0.003323\n",
      "Validating epoch 5102...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013419916631011587\n",
      "Average validation loss: 0.013905774507809625\n",
      "Training epoch 5103...\n",
      "\n",
      "Train Epoch: 5103 [0/8000 (0%)]\tBatch Loss: 0.013326\tLearning Rate (w_theta): 0.001000\t TIME:365.1s\n",
      "\t\t\t\tDisc: 0.012166\t\tSym: 0.000000\t\tSpars: 0.001160\n",
      "\t TVw: 1.005032 | TVb: 2.036127 | GSw: -0.689995 | GSb: -0.400480 | TSUw: -0.379442 | TSUb: -0.003417\n",
      "\n",
      "Train Epoch: 5103 [4000/8000 (50%)]\tBatch Loss: 0.013708\tLearning Rate (w_theta): 0.001000\t TIME:366.4s\n",
      "\t\t\t\tDisc: 0.012523\t\tSym: 0.000000\t\tSpars: 0.001185\n",
      "\t TVw: 1.004189 | TVb: 2.036906 | GSw: -0.689904 | GSb: -0.400357 | TSUw: -0.379340 | TSUb: -0.003465\n",
      "Validating epoch 5103...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01341601651159206\n",
      "Average validation loss: 0.013901917924048428\n",
      "Training epoch 5104...\n",
      "\n",
      "Train Epoch: 5104 [0/8000 (0%)]\tBatch Loss: 0.013306\tLearning Rate (w_theta): 0.001000\t TIME:368.6s\n",
      "\t\t\t\tDisc: 0.012326\t\tSym: 0.000000\t\tSpars: 0.000980\n",
      "\t TVw: 1.003456 | TVb: 2.037703 | GSw: -0.689816 | GSb: -0.400236 | TSUw: -0.379290 | TSUb: -0.003540\n",
      "\n",
      "Train Epoch: 5104 [4000/8000 (50%)]\tBatch Loss: 0.013799\tLearning Rate (w_theta): 0.001000\t TIME:369.9s\n",
      "\t\t\t\tDisc: 0.012317\t\tSym: 0.000000\t\tSpars: 0.001482\n",
      "\t TVw: 1.002826 | TVb: 2.038530 | GSw: -0.689738 | GSb: -0.400125 | TSUw: -0.379391 | TSUb: -0.003698\n",
      "Validating epoch 5104...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01341194671656385\n",
      "Average validation loss: 0.013897984393554762\n",
      "Training epoch 5105...\n",
      "\n",
      "Train Epoch: 5105 [0/8000 (0%)]\tBatch Loss: 0.012851\tLearning Rate (w_theta): 0.001000\t TIME:372.1s\n",
      "\t\t\t\tDisc: 0.011890\t\tSym: 0.000000\t\tSpars: 0.000961\n",
      "\t TVw: 1.002107 | TVb: 2.039339 | GSw: -0.689653 | GSb: -0.400008 | TSUw: -0.379393 | TSUb: -0.003801\n",
      "\n",
      "Train Epoch: 5105 [4000/8000 (50%)]\tBatch Loss: 0.013273\tLearning Rate (w_theta): 0.001000\t TIME:373.4s\n",
      "\t\t\t\tDisc: 0.012159\t\tSym: 0.000000\t\tSpars: 0.001114\n",
      "\t TVw: 1.001546 | TVb: 2.040168 | GSw: -0.689579 | GSb: -0.399902 | TSUw: -0.379565 | TSUb: -0.003996\n",
      "Validating epoch 5105...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01340773434120228\n",
      "Average validation loss: 0.013894096736558581\n",
      "Training epoch 5106...\n",
      "\n",
      "Train Epoch: 5106 [0/8000 (0%)]\tBatch Loss: 0.014816\tLearning Rate (w_theta): 0.001000\t TIME:375.7s\n",
      "\t\t\t\tDisc: 0.013132\t\tSym: 0.000000\t\tSpars: 0.001684\n",
      "\t TVw: 1.000884 | TVb: 2.040989 | GSw: -0.689495 | GSb: -0.399785 | TSUw: -0.379591 | TSUb: -0.004112\n",
      "\n",
      "Train Epoch: 5106 [4000/8000 (50%)]\tBatch Loss: 0.013535\tLearning Rate (w_theta): 0.001000\t TIME:377.0s\n",
      "\t\t\t\tDisc: 0.012469\t\tSym: 0.000000\t\tSpars: 0.001066\n",
      "\t TVw: 1.000475 | TVb: 2.041832 | GSw: -0.689418 | GSb: -0.399674 | TSUw: -0.379753 | TSUb: -0.004302\n",
      "Validating epoch 5106...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01340332032852667\n",
      "Average validation loss: 0.013889991990212491\n",
      "Training epoch 5107...\n",
      "\n",
      "Train Epoch: 5107 [0/8000 (0%)]\tBatch Loss: 0.012944\tLearning Rate (w_theta): 0.001000\t TIME:379.1s\n",
      "\t\t\t\tDisc: 0.012016\t\tSym: 0.000000\t\tSpars: 0.000928\n",
      "\t TVw: 0.999692 | TVb: 2.042623 | GSw: -0.689328 | GSb: -0.399551 | TSUw: -0.379657 | TSUb: -0.004351\n",
      "\n",
      "Train Epoch: 5107 [4000/8000 (50%)]\tBatch Loss: 0.013469\tLearning Rate (w_theta): 0.001000\t TIME:380.4s\n",
      "\t\t\t\tDisc: 0.012437\t\tSym: 0.000000\t\tSpars: 0.001031\n",
      "\t TVw: 0.998894 | TVb: 2.043417 | GSw: -0.689238 | GSb: -0.399428 | TSUw: -0.379598 | TSUb: -0.004420\n",
      "Validating epoch 5107...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013399041956371996\n",
      "Average validation loss: 0.013886154188031203\n",
      "Training epoch 5108...\n",
      "\n",
      "Train Epoch: 5108 [0/8000 (0%)]\tBatch Loss: 0.013292\tLearning Rate (w_theta): 0.001000\t TIME:382.7s\n",
      "\t\t\t\tDisc: 0.012189\t\tSym: 0.000000\t\tSpars: 0.001103\n",
      "\t TVw: 0.998115 | TVb: 2.044211 | GSw: -0.689147 | GSb: -0.399303 | TSUw: -0.379493 | TSUb: -0.004464\n",
      "\n",
      "Train Epoch: 5108 [4000/8000 (50%)]\tBatch Loss: 0.013874\tLearning Rate (w_theta): 0.001000\t TIME:383.9s\n",
      "\t\t\t\tDisc: 0.012569\t\tSym: 0.000000\t\tSpars: 0.001304\n",
      "\t TVw: 0.997494 | TVb: 2.045000 | GSw: -0.689045 | GSb: -0.399167 | TSUw: -0.379264 | TSUb: -0.004442\n",
      "Validating epoch 5108...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013395372855300321\n",
      "Average validation loss: 0.013881957638940682\n",
      "Training epoch 5109...\n",
      "\n",
      "Train Epoch: 5109 [0/8000 (0%)]\tBatch Loss: 0.013465\tLearning Rate (w_theta): 0.001000\t TIME:386.1s\n",
      "\t\t\t\tDisc: 0.012309\t\tSym: 0.000000\t\tSpars: 0.001156\n",
      "\t TVw: 0.996783 | TVb: 2.045804 | GSw: -0.688962 | GSb: -0.399051 | TSUw: -0.379295 | TSUb: -0.004559\n",
      "\n",
      "Train Epoch: 5109 [4000/8000 (50%)]\tBatch Loss: 0.013819\tLearning Rate (w_theta): 0.001000\t TIME:387.4s\n",
      "\t\t\t\tDisc: 0.012639\t\tSym: 0.000000\t\tSpars: 0.001181\n",
      "\t TVw: 0.996352 | TVb: 2.046654 | GSw: -0.688892 | GSb: -0.398949 | TSUw: -0.379540 | TSUb: -0.004792\n",
      "Validating epoch 5109...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013391184125911814\n",
      "Average validation loss: 0.013878117928447429\n",
      "Training epoch 5110...\n",
      "\n",
      "Train Epoch: 5110 [0/8000 (0%)]\tBatch Loss: 0.013447\tLearning Rate (w_theta): 0.001000\t TIME:389.7s\n",
      "\t\t\t\tDisc: 0.012356\t\tSym: 0.000000\t\tSpars: 0.001090\n",
      "\t TVw: 0.995534 | TVb: 2.047452 | GSw: -0.688806 | GSb: -0.398830 | TSUw: -0.379523 | TSUb: -0.004882\n",
      "\n",
      "Train Epoch: 5110 [4000/8000 (50%)]\tBatch Loss: 0.012934\tLearning Rate (w_theta): 0.001000\t TIME:391.0s\n",
      "\t\t\t\tDisc: 0.011918\t\tSym: 0.000000\t\tSpars: 0.001015\n",
      "\t TVw: 0.994644 | TVb: 2.048216 | GSw: -0.688713 | GSb: -0.398703 | TSUw: -0.379397 | TSUb: -0.004913\n",
      "Validating epoch 5110...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013387064181674029\n",
      "Average validation loss: 0.013874458871072028\n",
      "Training epoch 5111...\n",
      "\n",
      "Train Epoch: 5111 [0/8000 (0%)]\tBatch Loss: 0.013605\tLearning Rate (w_theta): 0.001000\t TIME:393.9s\n",
      "\t\t\t\tDisc: 0.012211\t\tSym: 0.000000\t\tSpars: 0.001394\n",
      "\t TVw: 0.993860 | TVb: 2.049001 | GSw: -0.688622 | GSb: -0.398578 | TSUw: -0.379316 | TSUb: -0.004969\n",
      "\n",
      "Train Epoch: 5111 [4000/8000 (50%)]\tBatch Loss: 0.013306\tLearning Rate (w_theta): 0.001000\t TIME:395.1s\n",
      "\t\t\t\tDisc: 0.012354\t\tSym: 0.000000\t\tSpars: 0.000953\n",
      "\t TVw: 0.993219 | TVb: 2.049813 | GSw: -0.688540 | GSb: -0.398461 | TSUw: -0.379393 | TSUb: -0.005110\n",
      "Validating epoch 5111...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013383270229743931\n",
      "Average validation loss: 0.013870653619845288\n",
      "Training epoch 5112...\n",
      "\n",
      "Train Epoch: 5112 [0/8000 (0%)]\tBatch Loss: 0.013315\tLearning Rate (w_theta): 0.001000\t TIME:397.3s\n",
      "\t\t\t\tDisc: 0.012488\t\tSym: 0.000000\t\tSpars: 0.000827\n",
      "\t TVw: 0.992379 | TVb: 2.050598 | GSw: -0.688451 | GSb: -0.398339 | TSUw: -0.379351 | TSUb: -0.005187\n",
      "\n",
      "Train Epoch: 5112 [4000/8000 (50%)]\tBatch Loss: 0.013871\tLearning Rate (w_theta): 0.001000\t TIME:398.6s\n",
      "\t\t\t\tDisc: 0.012456\t\tSym: 0.000000\t\tSpars: 0.001415\n",
      "\t TVw: 0.991529 | TVb: 2.051365 | GSw: -0.688364 | GSb: -0.398219 | TSUw: -0.379340 | TSUb: -0.005279\n",
      "Validating epoch 5112...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013379593245308952\n",
      "Average validation loss: 0.013867002057633419\n",
      "Training epoch 5113...\n",
      "\n",
      "Train Epoch: 5113 [0/8000 (0%)]\tBatch Loss: 0.013346\tLearning Rate (w_theta): 0.001000\t TIME:400.8s\n",
      "\t\t\t\tDisc: 0.012086\t\tSym: 0.000000\t\tSpars: 0.001260\n",
      "\t TVw: 0.990974 | TVb: 2.052187 | GSw: -0.688287 | GSb: -0.398109 | TSUw: -0.379479 | TSUb: -0.005453\n",
      "\n",
      "Train Epoch: 5113 [4000/8000 (50%)]\tBatch Loss: 0.012615\tLearning Rate (w_theta): 0.001000\t TIME:402.1s\n",
      "\t\t\t\tDisc: 0.011724\t\tSym: 0.000000\t\tSpars: 0.000891\n",
      "\t TVw: 0.990455 | TVb: 2.053014 | GSw: -0.688201 | GSb: -0.397989 | TSUw: -0.379502 | TSUb: -0.005564\n",
      "Validating epoch 5113...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013375287046699718\n",
      "Average validation loss: 0.013863114935428125\n",
      "Training epoch 5114...\n",
      "\n",
      "Train Epoch: 5114 [0/8000 (0%)]\tBatch Loss: 0.013161\tLearning Rate (w_theta): 0.001000\t TIME:404.3s\n",
      "\t\t\t\tDisc: 0.011964\t\tSym: 0.000000\t\tSpars: 0.001197\n",
      "\t TVw: 0.989638 | TVb: 2.053791 | GSw: -0.688112 | GSb: -0.397866 | TSUw: -0.379449 | TSUb: -0.005633\n",
      "\n",
      "Train Epoch: 5114 [4000/8000 (50%)]\tBatch Loss: 0.013522\tLearning Rate (w_theta): 0.001000\t TIME:405.6s\n",
      "\t\t\t\tDisc: 0.012497\t\tSym: 0.000000\t\tSpars: 0.001024\n",
      "\t TVw: 0.989063 | TVb: 2.054611 | GSw: -0.688023 | GSb: -0.397742 | TSUw: -0.379424 | TSUb: -0.005718\n",
      "Validating epoch 5114...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013371301358852833\n",
      "Average validation loss: 0.013859287807247513\n",
      "Training epoch 5115...\n",
      "\n",
      "Train Epoch: 5115 [0/8000 (0%)]\tBatch Loss: 0.013099\tLearning Rate (w_theta): 0.001000\t TIME:407.9s\n",
      "\t\t\t\tDisc: 0.011810\t\tSym: 0.000000\t\tSpars: 0.001288\n",
      "\t TVw: 0.988265 | TVb: 2.055377 | GSw: -0.687937 | GSb: -0.397622 | TSUw: -0.379440 | TSUb: -0.005824\n",
      "\n",
      "Train Epoch: 5115 [4000/8000 (50%)]\tBatch Loss: 0.012880\tLearning Rate (w_theta): 0.001000\t TIME:409.2s\n",
      "\t\t\t\tDisc: 0.011948\t\tSym: 0.000000\t\tSpars: 0.000932\n",
      "\t TVw: 0.987522 | TVb: 2.056134 | GSw: -0.687845 | GSb: -0.397496 | TSUw: -0.379382 | TSUb: -0.005890\n",
      "Validating epoch 5115...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01336749949246783\n",
      "Average validation loss: 0.013855663519109905\n",
      "Training epoch 5116...\n",
      "\n",
      "Train Epoch: 5116 [0/8000 (0%)]\tBatch Loss: 0.014015\tLearning Rate (w_theta): 0.001000\t TIME:411.4s\n",
      "\t\t\t\tDisc: 0.012708\t\tSym: 0.000000\t\tSpars: 0.001307\n",
      "\t TVw: 0.986794 | TVb: 2.056913 | GSw: -0.687757 | GSb: -0.397374 | TSUw: -0.379368 | TSUb: -0.005980\n",
      "\n",
      "Train Epoch: 5116 [4000/8000 (50%)]\tBatch Loss: 0.013554\tLearning Rate (w_theta): 0.001000\t TIME:412.7s\n",
      "\t\t\t\tDisc: 0.012554\t\tSym: 0.000000\t\tSpars: 0.000999\n",
      "\t TVw: 0.986034 | TVb: 2.057716 | GSw: -0.687674 | GSb: -0.397257 | TSUw: -0.379431 | TSUb: -0.006110\n",
      "Validating epoch 5116...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01336380558653712\n",
      "Average validation loss: 0.013851963293316307\n",
      "Training epoch 5117...\n",
      "\n",
      "Train Epoch: 5117 [0/8000 (0%)]\tBatch Loss: 0.013218\tLearning Rate (w_theta): 0.001000\t TIME:414.9s\n",
      "\t\t\t\tDisc: 0.012124\t\tSym: 0.000000\t\tSpars: 0.001094\n",
      "\t TVw: 0.985330 | TVb: 2.058494 | GSw: -0.687586 | GSb: -0.397135 | TSUw: -0.379417 | TSUb: -0.006200\n",
      "\n",
      "Train Epoch: 5117 [4000/8000 (50%)]\tBatch Loss: 0.013695\tLearning Rate (w_theta): 0.001000\t TIME:416.2s\n",
      "\t\t\t\tDisc: 0.012470\t\tSym: 0.000000\t\tSpars: 0.001225\n",
      "\t TVw: 0.984670 | TVb: 2.059267 | GSw: -0.687502 | GSb: -0.397018 | TSUw: -0.379440 | TSUb: -0.006309\n",
      "Validating epoch 5117...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01335994307974904\n",
      "Average validation loss: 0.013848346808856653\n",
      "Training epoch 5118...\n",
      "\n",
      "Train Epoch: 5118 [0/8000 (0%)]\tBatch Loss: 0.013579\tLearning Rate (w_theta): 0.001000\t TIME:418.3s\n",
      "\t\t\t\tDisc: 0.012323\t\tSym: 0.000000\t\tSpars: 0.001257\n",
      "\t TVw: 0.983894 | TVb: 2.060034 | GSw: -0.687411 | GSb: -0.396892 | TSUw: -0.379367 | TSUb: -0.006365\n",
      "\n",
      "Train Epoch: 5118 [4000/8000 (50%)]\tBatch Loss: 0.012843\tLearning Rate (w_theta): 0.001000\t TIME:419.6s\n",
      "\t\t\t\tDisc: 0.011667\t\tSym: 0.000000\t\tSpars: 0.001176\n",
      "\t TVw: 0.983258 | TVb: 2.060801 | GSw: -0.687320 | GSb: -0.396767 | TSUw: -0.379351 | TSUb: -0.006453\n",
      "Validating epoch 5118...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013356220642634269\n",
      "Average validation loss: 0.013844664122280899\n",
      "Training epoch 5119...\n",
      "\n",
      "Train Epoch: 5119 [0/8000 (0%)]\tBatch Loss: 0.013616\tLearning Rate (w_theta): 0.001000\t TIME:421.9s\n",
      "\t\t\t\tDisc: 0.012047\t\tSym: 0.000000\t\tSpars: 0.001569\n",
      "\t TVw: 0.982576 | TVb: 2.061581 | GSw: -0.687232 | GSb: -0.396643 | TSUw: -0.379349 | TSUb: -0.006547\n",
      "\n",
      "Train Epoch: 5119 [4000/8000 (50%)]\tBatch Loss: 0.013766\tLearning Rate (w_theta): 0.001000\t TIME:423.2s\n",
      "\t\t\t\tDisc: 0.012496\t\tSym: 0.000000\t\tSpars: 0.001270\n",
      "\t TVw: 0.982098 | TVb: 2.062393 | GSw: -0.687153 | GSb: -0.396531 | TSUw: -0.379494 | TSUb: -0.006721\n",
      "Validating epoch 5119...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01335236837470494\n",
      "Average validation loss: 0.013840874733178455\n",
      "Training epoch 5120...\n",
      "\n",
      "Train Epoch: 5120 [0/8000 (0%)]\tBatch Loss: 0.013832\tLearning Rate (w_theta): 0.001000\t TIME:425.5s\n",
      "\t\t\t\tDisc: 0.012600\t\tSym: 0.000000\t\tSpars: 0.001233\n",
      "\t TVw: 0.981432 | TVb: 2.063171 | GSw: -0.687071 | GSb: -0.396413 | TSUw: -0.379566 | TSUb: -0.006855\n",
      "\n",
      "Train Epoch: 5120 [4000/8000 (50%)]\tBatch Loss: 0.013572\tLearning Rate (w_theta): 0.001000\t TIME:426.8s\n",
      "\t\t\t\tDisc: 0.012553\t\tSym: 0.000000\t\tSpars: 0.001019\n",
      "\t TVw: 0.980450 | TVb: 2.063893 | GSw: -0.686974 | GSb: -0.396281 | TSUw: -0.379416 | TSUb: -0.006869\n",
      "Validating epoch 5120...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013348461914427283\n",
      "Average validation loss: 0.013837321622853439\n",
      "Training epoch 5121...\n",
      "\n",
      "Train Epoch: 5121 [0/8000 (0%)]\tBatch Loss: 0.013048\tLearning Rate (w_theta): 0.001000\t TIME:429.6s\n",
      "\t\t\t\tDisc: 0.012016\t\tSym: 0.000000\t\tSpars: 0.001032\n",
      "\t TVw: 0.979813 | TVb: 2.064673 | GSw: -0.686884 | GSb: -0.396157 | TSUw: -0.379403 | TSUb: -0.006957\n",
      "\n",
      "Train Epoch: 5121 [4000/8000 (50%)]\tBatch Loss: 0.013466\tLearning Rate (w_theta): 0.001000\t TIME:430.8s\n",
      "\t\t\t\tDisc: 0.012560\t\tSym: 0.000000\t\tSpars: 0.000906\n",
      "\t TVw: 0.978903 | TVb: 2.065432 | GSw: -0.686784 | GSb: -0.396021 | TSUw: -0.379207 | TSUb: -0.006945\n",
      "Validating epoch 5121...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013345207788636659\n",
      "Average validation loss: 0.01383371154302216\n",
      "Training epoch 5122...\n",
      "\n",
      "Train Epoch: 5122 [0/8000 (0%)]\tBatch Loss: 0.013549\tLearning Rate (w_theta): 0.001000\t TIME:433.1s\n",
      "\t\t\t\tDisc: 0.012292\t\tSym: 0.000000\t\tSpars: 0.001257\n",
      "\t TVw: 0.978260 | TVb: 2.066223 | GSw: -0.686697 | GSb: -0.395899 | TSUw: -0.379221 | TSUb: -0.007046\n",
      "\n",
      "Train Epoch: 5122 [4000/8000 (50%)]\tBatch Loss: 0.013907\tLearning Rate (w_theta): 0.001000\t TIME:434.3s\n",
      "\t\t\t\tDisc: 0.012755\t\tSym: 0.000000\t\tSpars: 0.001152\n",
      "\t TVw: 0.978013 | TVb: 2.067041 | GSw: -0.686618 | GSb: -0.395786 | TSUw: -0.379413 | TSUb: -0.007245\n",
      "Validating epoch 5122...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013341098565184084\n",
      "Average validation loss: 0.013829769909649745\n",
      "Training epoch 5123...\n",
      "\n",
      "Train Epoch: 5123 [0/8000 (0%)]\tBatch Loss: 0.012878\tLearning Rate (w_theta): 0.001000\t TIME:436.5s\n",
      "\t\t\t\tDisc: 0.011849\t\tSym: 0.000000\t\tSpars: 0.001030\n",
      "\t TVw: 0.977331 | TVb: 2.067821 | GSw: -0.686536 | GSb: -0.395669 | TSUw: -0.379501 | TSUb: -0.007387\n",
      "\n",
      "Train Epoch: 5123 [4000/8000 (50%)]\tBatch Loss: 0.012982\tLearning Rate (w_theta): 0.001000\t TIME:437.8s\n",
      "\t\t\t\tDisc: 0.012128\t\tSym: 0.000000\t\tSpars: 0.000854\n",
      "\t TVw: 0.976573 | TVb: 2.068593 | GSw: -0.686454 | GSb: -0.395553 | TSUw: -0.379588 | TSUb: -0.007527\n",
      "Validating epoch 5123...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013336859055692027\n",
      "Average validation loss: 0.01382645367183912\n",
      "Training epoch 5124...\n",
      "\n",
      "Train Epoch: 5124 [0/8000 (0%)]\tBatch Loss: 0.013220\tLearning Rate (w_theta): 0.001000\t TIME:440.1s\n",
      "\t\t\t\tDisc: 0.012115\t\tSym: 0.000000\t\tSpars: 0.001105\n",
      "\t TVw: 0.975858 | TVb: 2.069345 | GSw: -0.686367 | GSb: -0.395431 | TSUw: -0.379617 | TSUb: -0.007636\n",
      "\n",
      "Train Epoch: 5124 [4000/8000 (50%)]\tBatch Loss: 0.012760\tLearning Rate (w_theta): 0.001000\t TIME:441.4s\n",
      "\t\t\t\tDisc: 0.011637\t\tSym: 0.000000\t\tSpars: 0.001123\n",
      "\t TVw: 0.975079 | TVb: 2.070089 | GSw: -0.686277 | GSb: -0.395305 | TSUw: -0.379618 | TSUb: -0.007730\n",
      "Validating epoch 5124...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013333251863138546\n",
      "Average validation loss: 0.013823065173976546\n",
      "Training epoch 5125...\n",
      "\n",
      "Train Epoch: 5125 [0/8000 (0%)]\tBatch Loss: 0.013371\tLearning Rate (w_theta): 0.001000\t TIME:443.6s\n",
      "\t\t\t\tDisc: 0.012181\t\tSym: 0.000000\t\tSpars: 0.001190\n",
      "\t TVw: 0.974394 | TVb: 2.070858 | GSw: -0.686188 | GSb: -0.395180 | TSUw: -0.379609 | TSUb: -0.007817\n",
      "\n",
      "Train Epoch: 5125 [4000/8000 (50%)]\tBatch Loss: 0.012956\tLearning Rate (w_theta): 0.001000\t TIME:444.9s\n",
      "\t\t\t\tDisc: 0.011926\t\tSym: 0.000000\t\tSpars: 0.001030\n",
      "\t TVw: 0.973456 | TVb: 2.071591 | GSw: -0.686091 | GSb: -0.395048 | TSUw: -0.379446 | TSUb: -0.007821\n",
      "Validating epoch 5125...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0133299426423782\n",
      "Average validation loss: 0.01381953832412358\n",
      "Training epoch 5126...\n",
      "\n",
      "Train Epoch: 5126 [0/8000 (0%)]\tBatch Loss: 0.013087\tLearning Rate (w_theta): 0.001000\t TIME:447.1s\n",
      "\t\t\t\tDisc: 0.012349\t\tSym: 0.000000\t\tSpars: 0.000738\n",
      "\t TVw: 0.972647 | TVb: 2.072348 | GSw: -0.685997 | GSb: -0.394919 | TSUw: -0.379352 | TSUb: -0.007862\n",
      "\n",
      "Train Epoch: 5126 [4000/8000 (50%)]\tBatch Loss: 0.013648\tLearning Rate (w_theta): 0.001000\t TIME:448.3s\n",
      "\t\t\t\tDisc: 0.012291\t\tSym: 0.000000\t\tSpars: 0.001356\n",
      "\t TVw: 0.971834 | TVb: 2.073086 | GSw: -0.685903 | GSb: -0.394791 | TSUw: -0.379316 | TSUb: -0.007934\n",
      "Validating epoch 5126...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013326620397530152\n",
      "Average validation loss: 0.013816034955105373\n",
      "Training epoch 5127...\n",
      "\n",
      "Train Epoch: 5127 [0/8000 (0%)]\tBatch Loss: 0.012887\tLearning Rate (w_theta): 0.001000\t TIME:450.5s\n",
      "\t\t\t\tDisc: 0.012061\t\tSym: 0.000000\t\tSpars: 0.000826\n",
      "\t TVw: 0.971297 | TVb: 2.073875 | GSw: -0.685816 | GSb: -0.394669 | TSUw: -0.379369 | TSUb: -0.008054\n",
      "\n",
      "Train Epoch: 5127 [4000/8000 (50%)]\tBatch Loss: 0.013484\tLearning Rate (w_theta): 0.001000\t TIME:451.8s\n",
      "\t\t\t\tDisc: 0.012276\t\tSym: 0.000000\t\tSpars: 0.001208\n",
      "\t TVw: 0.970761 | TVb: 2.074642 | GSw: -0.685723 | GSb: -0.394541 | TSUw: -0.379292 | TSUb: -0.008105\n",
      "Validating epoch 5127...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013322682010103296\n",
      "Average validation loss: 0.013812201586140875\n",
      "Training epoch 5128...\n",
      "\n",
      "Train Epoch: 5128 [0/8000 (0%)]\tBatch Loss: 0.013791\tLearning Rate (w_theta): 0.001000\t TIME:454.0s\n",
      "\t\t\t\tDisc: 0.012815\t\tSym: 0.000000\t\tSpars: 0.000976\n",
      "\t TVw: 0.970255 | TVb: 2.075446 | GSw: -0.685637 | GSb: -0.394419 | TSUw: -0.379370 | TSUb: -0.008238\n",
      "\n",
      "Train Epoch: 5128 [4000/8000 (50%)]\tBatch Loss: 0.012699\tLearning Rate (w_theta): 0.001000\t TIME:455.3s\n",
      "\t\t\t\tDisc: 0.011950\t\tSym: 0.000000\t\tSpars: 0.000750\n",
      "\t TVw: 0.969632 | TVb: 2.076228 | GSw: -0.685545 | GSb: -0.394290 | TSUw: -0.379330 | TSUb: -0.008308\n",
      "Validating epoch 5128...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01331867078735974\n",
      "Average validation loss: 0.0138085652538925\n",
      "Training epoch 5129...\n",
      "\n",
      "Train Epoch: 5129 [0/8000 (0%)]\tBatch Loss: 0.013177\tLearning Rate (w_theta): 0.001000\t TIME:457.5s\n",
      "\t\t\t\tDisc: 0.012235\t\tSym: 0.000000\t\tSpars: 0.000942\n",
      "\t TVw: 0.968956 | TVb: 2.077001 | GSw: -0.685461 | GSb: -0.394171 | TSUw: -0.379417 | TSUb: -0.008446\n",
      "\n",
      "Train Epoch: 5129 [4000/8000 (50%)]\tBatch Loss: 0.013194\tLearning Rate (w_theta): 0.001000\t TIME:458.8s\n",
      "\t\t\t\tDisc: 0.011963\t\tSym: 0.000000\t\tSpars: 0.001231\n",
      "\t TVw: 0.968214 | TVb: 2.077756 | GSw: -0.685380 | GSb: -0.394055 | TSUw: -0.379541 | TSUb: -0.008604\n",
      "Validating epoch 5129...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013314822668448367\n",
      "Average validation loss: 0.013805261437076234\n",
      "Training epoch 5130...\n",
      "\n",
      "Train Epoch: 5130 [0/8000 (0%)]\tBatch Loss: 0.013232\tLearning Rate (w_theta): 0.001000\t TIME:461.0s\n",
      "\t\t\t\tDisc: 0.012003\t\tSym: 0.000000\t\tSpars: 0.001229\n",
      "\t TVw: 0.967686 | TVb: 2.078540 | GSw: -0.685296 | GSb: -0.393935 | TSUw: -0.379639 | TSUb: -0.008747\n",
      "\n",
      "Train Epoch: 5130 [4000/8000 (50%)]\tBatch Loss: 0.013280\tLearning Rate (w_theta): 0.001000\t TIME:462.3s\n",
      "\t\t\t\tDisc: 0.012194\t\tSym: 0.000000\t\tSpars: 0.001086\n",
      "\t TVw: 0.967248 | TVb: 2.079319 | GSw: -0.685216 | GSb: -0.393820 | TSUw: -0.379815 | TSUb: -0.008933\n",
      "Validating epoch 5130...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013310881686647895\n",
      "Average validation loss: 0.013801755653633781\n",
      "Training epoch 5131...\n",
      "\n",
      "Train Epoch: 5131 [0/8000 (0%)]\tBatch Loss: 0.013470\tLearning Rate (w_theta): 0.001000\t TIME:465.0s\n",
      "\t\t\t\tDisc: 0.012545\t\tSym: 0.000000\t\tSpars: 0.000925\n",
      "\t TVw: 0.966467 | TVb: 2.080061 | GSw: -0.685122 | GSb: -0.393690 | TSUw: -0.379757 | TSUb: -0.008991\n",
      "\n",
      "Train Epoch: 5131 [4000/8000 (50%)]\tBatch Loss: 0.013779\tLearning Rate (w_theta): 0.001000\t TIME:466.2s\n",
      "\t\t\t\tDisc: 0.012454\t\tSym: 0.000000\t\tSpars: 0.001325\n",
      "\t TVw: 0.965353 | TVb: 2.080775 | GSw: -0.685033 | GSb: -0.393565 | TSUw: -0.379717 | TSUb: -0.009057\n",
      "Validating epoch 5131...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013307546726296481\n",
      "Average validation loss: 0.013798710985777358\n",
      "Training epoch 5132...\n",
      "\n",
      "Train Epoch: 5132 [0/8000 (0%)]\tBatch Loss: 0.013694\tLearning Rate (w_theta): 0.001000\t TIME:468.5s\n",
      "\t\t\t\tDisc: 0.012609\t\tSym: 0.000000\t\tSpars: 0.001085\n",
      "\t TVw: 0.964655 | TVb: 2.081529 | GSw: -0.684938 | GSb: -0.393434 | TSUw: -0.379660 | TSUb: -0.009115\n",
      "\n",
      "Train Epoch: 5132 [4000/8000 (50%)]\tBatch Loss: 0.012713\tLearning Rate (w_theta): 0.001000\t TIME:469.7s\n",
      "\t\t\t\tDisc: 0.011672\t\tSym: 0.000000\t\tSpars: 0.001041\n",
      "\t TVw: 0.964158 | TVb: 2.082304 | GSw: -0.684849 | GSb: -0.393309 | TSUw: -0.379697 | TSUb: -0.009225\n",
      "Validating epoch 5132...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013304069426459793\n",
      "Average validation loss: 0.01379497896860897\n",
      "Training epoch 5133...\n",
      "\n",
      "Train Epoch: 5133 [0/8000 (0%)]\tBatch Loss: 0.013511\tLearning Rate (w_theta): 0.001000\t TIME:472.0s\n",
      "\t\t\t\tDisc: 0.012653\t\tSym: 0.000000\t\tSpars: 0.000859\n",
      "\t TVw: 0.963613 | TVb: 2.083063 | GSw: -0.684756 | GSb: -0.393181 | TSUw: -0.379690 | TSUb: -0.009309\n",
      "\n",
      "Train Epoch: 5133 [4000/8000 (50%)]\tBatch Loss: 0.013602\tLearning Rate (w_theta): 0.001000\t TIME:473.3s\n",
      "\t\t\t\tDisc: 0.012171\t\tSym: 0.000000\t\tSpars: 0.001431\n",
      "\t TVw: 0.963077 | TVb: 2.083818 | GSw: -0.684665 | GSb: -0.393053 | TSUw: -0.379690 | TSUb: -0.009398\n",
      "Validating epoch 5133...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013300167450014291\n",
      "Average validation loss: 0.013791282593416245\n",
      "Training epoch 5134...\n",
      "\n",
      "Train Epoch: 5134 [0/8000 (0%)]\tBatch Loss: 0.013232\tLearning Rate (w_theta): 0.001000\t TIME:475.6s\n",
      "\t\t\t\tDisc: 0.012141\t\tSym: 0.000000\t\tSpars: 0.001091\n",
      "\t TVw: 0.962626 | TVb: 2.084583 | GSw: -0.684575 | GSb: -0.392927 | TSUw: -0.379746 | TSUb: -0.009516\n",
      "\n",
      "Train Epoch: 5134 [4000/8000 (50%)]\tBatch Loss: 0.013304\tLearning Rate (w_theta): 0.001000\t TIME:476.9s\n",
      "\t\t\t\tDisc: 0.012072\t\tSym: 0.000000\t\tSpars: 0.001231\n",
      "\t TVw: 0.961838 | TVb: 2.085317 | GSw: -0.684486 | GSb: -0.392803 | TSUw: -0.379793 | TSUb: -0.009629\n",
      "Validating epoch 5134...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013296288046107234\n",
      "Average validation loss: 0.013788044423232263\n",
      "Training epoch 5135...\n",
      "\n",
      "Train Epoch: 5135 [0/8000 (0%)]\tBatch Loss: 0.013605\tLearning Rate (w_theta): 0.001000\t TIME:479.1s\n",
      "\t\t\t\tDisc: 0.012390\t\tSym: 0.000000\t\tSpars: 0.001215\n",
      "\t TVw: 0.961317 | TVb: 2.086066 | GSw: -0.684398 | GSb: -0.392678 | TSUw: -0.379851 | TSUb: -0.009748\n",
      "\n",
      "Train Epoch: 5135 [4000/8000 (50%)]\tBatch Loss: 0.013163\tLearning Rate (w_theta): 0.001000\t TIME:480.4s\n",
      "\t\t\t\tDisc: 0.011953\t\tSym: 0.000000\t\tSpars: 0.001210\n",
      "\t TVw: 0.960709 | TVb: 2.086820 | GSw: -0.684309 | GSb: -0.392553 | TSUw: -0.379898 | TSUb: -0.009860\n",
      "Validating epoch 5135...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013292627916421515\n",
      "Average validation loss: 0.013784495894721084\n",
      "Training epoch 5136...\n",
      "\n",
      "Train Epoch: 5136 [0/8000 (0%)]\tBatch Loss: 0.013304\tLearning Rate (w_theta): 0.001000\t TIME:482.6s\n",
      "\t\t\t\tDisc: 0.012150\t\tSym: 0.000000\t\tSpars: 0.001155\n",
      "\t TVw: 0.960264 | TVb: 2.087572 | GSw: -0.684217 | GSb: -0.392424 | TSUw: -0.379901 | TSUb: -0.009949\n",
      "\n",
      "Train Epoch: 5136 [4000/8000 (50%)]\tBatch Loss: 0.013304\tLearning Rate (w_theta): 0.001000\t TIME:483.9s\n",
      "\t\t\t\tDisc: 0.012342\t\tSym: 0.000000\t\tSpars: 0.000962\n",
      "\t TVw: 0.959783 | TVb: 2.088333 | GSw: -0.684117 | GSb: -0.392288 | TSUw: -0.379809 | TSUb: -0.009986\n",
      "Validating epoch 5136...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013288802151417563\n",
      "Average validation loss: 0.013780771612861321\n",
      "Training epoch 5137...\n",
      "\n",
      "Train Epoch: 5137 [0/8000 (0%)]\tBatch Loss: 0.013459\tLearning Rate (w_theta): 0.001000\t TIME:486.0s\n",
      "\t\t\t\tDisc: 0.012352\t\tSym: 0.000000\t\tSpars: 0.001108\n",
      "\t TVw: 0.959140 | TVb: 2.089055 | GSw: -0.684025 | GSb: -0.392159 | TSUw: -0.379779 | TSUb: -0.010056\n",
      "\n",
      "Train Epoch: 5137 [4000/8000 (50%)]\tBatch Loss: 0.013333\tLearning Rate (w_theta): 0.001000\t TIME:487.3s\n",
      "\t\t\t\tDisc: 0.012311\t\tSym: 0.000000\t\tSpars: 0.001022\n",
      "\t TVw: 0.958560 | TVb: 2.089786 | GSw: -0.683935 | GSb: -0.392032 | TSUw: -0.379798 | TSUb: -0.010152\n",
      "Validating epoch 5137...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013285175203025702\n",
      "Average validation loss: 0.013777367692305139\n",
      "Training epoch 5138...\n",
      "\n",
      "Train Epoch: 5138 [0/8000 (0%)]\tBatch Loss: 0.012978\tLearning Rate (w_theta): 0.001000\t TIME:489.6s\n",
      "\t\t\t\tDisc: 0.011917\t\tSym: 0.000000\t\tSpars: 0.001061\n",
      "\t TVw: 0.957917 | TVb: 2.090513 | GSw: -0.683842 | GSb: -0.391902 | TSUw: -0.379783 | TSUb: -0.010230\n",
      "\n",
      "Train Epoch: 5138 [4000/8000 (50%)]\tBatch Loss: 0.013138\tLearning Rate (w_theta): 0.001000\t TIME:490.9s\n",
      "\t\t\t\tDisc: 0.012293\t\tSym: 0.000000\t\tSpars: 0.000845\n",
      "\t TVw: 0.957075 | TVb: 2.091205 | GSw: -0.683746 | GSb: -0.391769 | TSUw: -0.379708 | TSUb: -0.010274\n",
      "Validating epoch 5138...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013281914662598903\n",
      "Average validation loss: 0.0137743530472175\n",
      "Training epoch 5139...\n",
      "\n",
      "Train Epoch: 5139 [0/8000 (0%)]\tBatch Loss: 0.013784\tLearning Rate (w_theta): 0.001000\t TIME:493.1s\n",
      "\t\t\t\tDisc: 0.012674\t\tSym: 0.000000\t\tSpars: 0.001110\n",
      "\t TVw: 0.956394 | TVb: 2.091927 | GSw: -0.683656 | GSb: -0.391642 | TSUw: -0.379735 | TSUb: -0.010374\n",
      "\n",
      "Train Epoch: 5139 [4000/8000 (50%)]\tBatch Loss: 0.013677\tLearning Rate (w_theta): 0.001000\t TIME:494.4s\n",
      "\t\t\t\tDisc: 0.012453\t\tSym: 0.000000\t\tSpars: 0.001224\n",
      "\t TVw: 0.955830 | TVb: 2.092650 | GSw: -0.683560 | GSb: -0.391510 | TSUw: -0.379718 | TSUb: -0.010450\n",
      "Validating epoch 5139...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013278642099243442\n",
      "Average validation loss: 0.013770870853462739\n",
      "Training epoch 5140...\n",
      "\n",
      "Train Epoch: 5140 [0/8000 (0%)]\tBatch Loss: 0.013117\tLearning Rate (w_theta): 0.001000\t TIME:496.6s\n",
      "\t\t\t\tDisc: 0.011901\t\tSym: 0.000000\t\tSpars: 0.001217\n",
      "\t TVw: 0.955388 | TVb: 2.093398 | GSw: -0.683474 | GSb: -0.391387 | TSUw: -0.379826 | TSUb: -0.010593\n",
      "\n",
      "Train Epoch: 5140 [4000/8000 (50%)]\tBatch Loss: 0.013467\tLearning Rate (w_theta): 0.001000\t TIME:497.9s\n",
      "\t\t\t\tDisc: 0.012364\t\tSym: 0.000000\t\tSpars: 0.001103\n",
      "\t TVw: 0.954931 | TVb: 2.094131 | GSw: -0.683383 | GSb: -0.391259 | TSUw: -0.379860 | TSUb: -0.010697\n",
      "Validating epoch 5140...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013274793100983546\n",
      "Average validation loss: 0.01376742971166744\n",
      "Training epoch 5141...\n",
      "\n",
      "Train Epoch: 5141 [0/8000 (0%)]\tBatch Loss: 0.013525\tLearning Rate (w_theta): 0.001000\t TIME:500.7s\n",
      "\t\t\t\tDisc: 0.012276\t\tSym: 0.000000\t\tSpars: 0.001249\n",
      "\t TVw: 0.954416 | TVb: 2.094867 | GSw: -0.683296 | GSb: -0.391136 | TSUw: -0.379950 | TSUb: -0.010830\n",
      "\n",
      "Train Epoch: 5141 [4000/8000 (50%)]\tBatch Loss: 0.012865\tLearning Rate (w_theta): 0.001000\t TIME:502.0s\n",
      "\t\t\t\tDisc: 0.012117\t\tSym: 0.000000\t\tSpars: 0.000747\n",
      "\t TVw: 0.954044 | TVb: 2.095606 | GSw: -0.683210 | GSb: -0.391013 | TSUw: -0.380070 | TSUb: -0.010979\n",
      "Validating epoch 5141...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0132711252135468\n",
      "Average validation loss: 0.013764125422012845\n",
      "Training epoch 5142...\n",
      "\n",
      "Train Epoch: 5142 [0/8000 (0%)]\tBatch Loss: 0.013514\tLearning Rate (w_theta): 0.001000\t TIME:504.2s\n",
      "\t\t\t\tDisc: 0.012505\t\tSym: 0.000000\t\tSpars: 0.001009\n",
      "\t TVw: 0.953174 | TVb: 2.096289 | GSw: -0.683109 | GSb: -0.390874 | TSUw: -0.379925 | TSUb: -0.010984\n",
      "\n",
      "Train Epoch: 5142 [4000/8000 (50%)]\tBatch Loss: 0.013911\tLearning Rate (w_theta): 0.001000\t TIME:505.5s\n",
      "\t\t\t\tDisc: 0.012320\t\tSym: 0.000000\t\tSpars: 0.001590\n",
      "\t TVw: 0.952417 | TVb: 2.097013 | GSw: -0.683021 | GSb: -0.390749 | TSUw: -0.379995 | TSUb: -0.011105\n",
      "Validating epoch 5142...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0132679307041723\n",
      "Average validation loss: 0.01376092348483997\n",
      "Training epoch 5143...\n",
      "\n",
      "Train Epoch: 5143 [0/8000 (0%)]\tBatch Loss: 0.013581\tLearning Rate (w_theta): 0.001000\t TIME:507.8s\n",
      "\t\t\t\tDisc: 0.012548\t\tSym: 0.000000\t\tSpars: 0.001033\n",
      "\t TVw: 0.951892 | TVb: 2.097735 | GSw: -0.682928 | GSb: -0.390618 | TSUw: -0.380006 | TSUb: -0.011194\n",
      "\n",
      "Train Epoch: 5143 [4000/8000 (50%)]\tBatch Loss: 0.012697\tLearning Rate (w_theta): 0.001000\t TIME:509.0s\n",
      "\t\t\t\tDisc: 0.011652\t\tSym: 0.000000\t\tSpars: 0.001044\n",
      "\t TVw: 0.951315 | TVb: 2.098449 | GSw: -0.682834 | GSb: -0.390487 | TSUw: -0.379996 | TSUb: -0.011271\n",
      "Validating epoch 5143...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01326445976984477\n",
      "Average validation loss: 0.01375756093204313\n",
      "Training epoch 5144...\n",
      "\n",
      "Train Epoch: 5144 [0/8000 (0%)]\tBatch Loss: 0.013070\tLearning Rate (w_theta): 0.001000\t TIME:511.2s\n",
      "\t\t\t\tDisc: 0.012082\t\tSym: 0.000000\t\tSpars: 0.000987\n",
      "\t TVw: 0.950735 | TVb: 2.099148 | GSw: -0.682740 | GSb: -0.390355 | TSUw: -0.379986 | TSUb: -0.011348\n",
      "\n",
      "Train Epoch: 5144 [4000/8000 (50%)]\tBatch Loss: 0.013623\tLearning Rate (w_theta): 0.001000\t TIME:512.5s\n",
      "\t\t\t\tDisc: 0.012432\t\tSym: 0.000000\t\tSpars: 0.001191\n",
      "\t TVw: 0.949994 | TVb: 2.099830 | GSw: -0.682643 | GSb: -0.390221 | TSUw: -0.379894 | TSUb: -0.011380\n",
      "Validating epoch 5144...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013261244743563721\n",
      "Average validation loss: 0.013754332368978633\n",
      "Training epoch 5145...\n",
      "\n",
      "Train Epoch: 5145 [0/8000 (0%)]\tBatch Loss: 0.012843\tLearning Rate (w_theta): 0.001000\t TIME:514.8s\n",
      "\t\t\t\tDisc: 0.012009\t\tSym: 0.000000\t\tSpars: 0.000834\n",
      "\t TVw: 0.949455 | TVb: 2.100533 | GSw: -0.682550 | GSb: -0.390090 | TSUw: -0.379902 | TSUb: -0.011467\n",
      "\n",
      "Train Epoch: 5145 [4000/8000 (50%)]\tBatch Loss: 0.013047\tLearning Rate (w_theta): 0.001000\t TIME:516.0s\n",
      "\t\t\t\tDisc: 0.012338\t\tSym: 0.000000\t\tSpars: 0.000709\n",
      "\t TVw: 0.948978 | TVb: 2.101246 | GSw: -0.682463 | GSb: -0.389966 | TSUw: -0.380040 | TSUb: -0.011624\n",
      "Validating epoch 5145...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01325791128178865\n",
      "Average validation loss: 0.013751140515949776\n",
      "Training epoch 5146...\n",
      "\n",
      "Train Epoch: 5146 [0/8000 (0%)]\tBatch Loss: 0.013613\tLearning Rate (w_theta): 0.001000\t TIME:518.2s\n",
      "\t\t\t\tDisc: 0.012420\t\tSym: 0.000000\t\tSpars: 0.001193\n",
      "\t TVw: 0.948433 | TVb: 2.101955 | GSw: -0.682372 | GSb: -0.389837 | TSUw: -0.380091 | TSUb: -0.011733\n",
      "\n",
      "Train Epoch: 5146 [4000/8000 (50%)]\tBatch Loss: 0.013307\tLearning Rate (w_theta): 0.001000\t TIME:519.5s\n",
      "\t\t\t\tDisc: 0.011931\t\tSym: 0.000000\t\tSpars: 0.001376\n",
      "\t TVw: 0.948037 | TVb: 2.102682 | GSw: -0.682289 | GSb: -0.389717 | TSUw: -0.380263 | TSUb: -0.011908\n",
      "Validating epoch 5146...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01325435785923208\n",
      "Average validation loss: 0.013747809830977212\n",
      "Training epoch 5147...\n",
      "\n",
      "Train Epoch: 5147 [0/8000 (0%)]\tBatch Loss: 0.013796\tLearning Rate (w_theta): 0.001000\t TIME:521.7s\n",
      "\t\t\t\tDisc: 0.012652\t\tSym: 0.000000\t\tSpars: 0.001144\n",
      "\t TVw: 0.947530 | TVb: 2.103388 | GSw: -0.682191 | GSb: -0.389581 | TSUw: -0.380230 | TSUb: -0.011971\n",
      "\n",
      "Train Epoch: 5147 [4000/8000 (50%)]\tBatch Loss: 0.013163\tLearning Rate (w_theta): 0.001000\t TIME:523.0s\n",
      "\t\t\t\tDisc: 0.012131\t\tSym: 0.000000\t\tSpars: 0.001032\n",
      "\t TVw: 0.947161 | TVb: 2.104114 | GSw: -0.682085 | GSb: -0.389437 | TSUw: -0.380067 | TSUb: -0.011963\n",
      "Validating epoch 5147...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013250730624272802\n",
      "Average validation loss: 0.013744202827941062\n",
      "Training epoch 5148...\n",
      "\n",
      "Train Epoch: 5148 [0/8000 (0%)]\tBatch Loss: 0.012713\tLearning Rate (w_theta): 0.001000\t TIME:525.3s\n",
      "\t\t\t\tDisc: 0.011665\t\tSym: 0.000000\t\tSpars: 0.001047\n",
      "\t TVw: 0.946476 | TVb: 2.104797 | GSw: -0.681991 | GSb: -0.389305 | TSUw: -0.380067 | TSUb: -0.012043\n",
      "\n",
      "Train Epoch: 5148 [4000/8000 (50%)]\tBatch Loss: 0.013403\tLearning Rate (w_theta): 0.001000\t TIME:526.6s\n",
      "\t\t\t\tDisc: 0.012338\t\tSym: 0.000000\t\tSpars: 0.001065\n",
      "\t TVw: 0.945520 | TVb: 2.105444 | GSw: -0.681897 | GSb: -0.389173 | TSUw: -0.380020 | TSUb: -0.012097\n",
      "Validating epoch 5148...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013247752999400932\n",
      "Average validation loss: 0.013741565743638183\n",
      "Training epoch 5149...\n",
      "\n",
      "Train Epoch: 5149 [0/8000 (0%)]\tBatch Loss: 0.013901\tLearning Rate (w_theta): 0.001000\t TIME:528.8s\n",
      "\t\t\t\tDisc: 0.012617\t\tSym: 0.000000\t\tSpars: 0.001285\n",
      "\t TVw: 0.944748 | TVb: 2.106125 | GSw: -0.681805 | GSb: -0.389044 | TSUw: -0.380048 | TSUb: -0.012191\n",
      "\n",
      "Train Epoch: 5149 [4000/8000 (50%)]\tBatch Loss: 0.013388\tLearning Rate (w_theta): 0.001000\t TIME:530.1s\n",
      "\t\t\t\tDisc: 0.012313\t\tSym: 0.000000\t\tSpars: 0.001075\n",
      "\t TVw: 0.944040 | TVb: 2.106803 | GSw: -0.681710 | GSb: -0.388910 | TSUw: -0.380055 | TSUb: -0.012275\n",
      "Validating epoch 5149...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013244954579957512\n",
      "Average validation loss: 0.013738478506987215\n",
      "Training epoch 5150...\n",
      "\n",
      "Train Epoch: 5150 [0/8000 (0%)]\tBatch Loss: 0.012888\tLearning Rate (w_theta): 0.001000\t TIME:532.3s\n",
      "\t\t\t\tDisc: 0.011628\t\tSym: 0.000000\t\tSpars: 0.001260\n",
      "\t TVw: 0.943589 | TVb: 2.107504 | GSw: -0.681620 | GSb: -0.388781 | TSUw: -0.380124 | TSUb: -0.012391\n",
      "\n",
      "Train Epoch: 5150 [4000/8000 (50%)]\tBatch Loss: 0.012970\tLearning Rate (w_theta): 0.001000\t TIME:533.6s\n",
      "\t\t\t\tDisc: 0.012155\t\tSym: 0.000000\t\tSpars: 0.000815\n",
      "\t TVw: 0.943186 | TVb: 2.108200 | GSw: -0.681516 | GSb: -0.388638 | TSUw: -0.380001 | TSUb: -0.012405\n",
      "Validating epoch 5150...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013241618707380953\n",
      "Average validation loss: 0.013735040751468443\n",
      "Training epoch 5151...\n",
      "\n",
      "Train Epoch: 5151 [0/8000 (0%)]\tBatch Loss: 0.013495\tLearning Rate (w_theta): 0.001000\t TIME:536.5s\n",
      "\t\t\t\tDisc: 0.012428\t\tSym: 0.000000\t\tSpars: 0.001067\n",
      "\t TVw: 0.942574 | TVb: 2.108891 | GSw: -0.681428 | GSb: -0.388512 | TSUw: -0.380099 | TSUb: -0.012537\n",
      "\n",
      "Train Epoch: 5151 [4000/8000 (50%)]\tBatch Loss: 0.013760\tLearning Rate (w_theta): 0.001000\t TIME:537.8s\n",
      "\t\t\t\tDisc: 0.012516\t\tSym: 0.000000\t\tSpars: 0.001244\n",
      "\t TVw: 0.941806 | TVb: 2.109544 | GSw: -0.681339 | GSb: -0.388384 | TSUw: -0.380154 | TSUb: -0.012644\n",
      "Validating epoch 5151...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013238395050668206\n",
      "Average validation loss: 0.013732131982600789\n",
      "Training epoch 5152...\n",
      "\n",
      "Train Epoch: 5152 [0/8000 (0%)]\tBatch Loss: 0.012514\tLearning Rate (w_theta): 0.001000\t TIME:540.0s\n",
      "\t\t\t\tDisc: 0.011876\t\tSym: 0.000000\t\tSpars: 0.000638\n",
      "\t TVw: 0.941176 | TVb: 2.110231 | GSw: -0.681244 | GSb: -0.388251 | TSUw: -0.380154 | TSUb: -0.012722\n",
      "\n",
      "Train Epoch: 5152 [4000/8000 (50%)]\tBatch Loss: 0.013027\tLearning Rate (w_theta): 0.001000\t TIME:541.3s\n",
      "\t\t\t\tDisc: 0.012107\t\tSym: 0.000000\t\tSpars: 0.000920\n",
      "\t TVw: 0.940359 | TVb: 2.110900 | GSw: -0.681148 | GSb: -0.388116 | TSUw: -0.380135 | TSUb: -0.012790\n",
      "Validating epoch 5152...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0132355059057959\n",
      "Average validation loss: 0.013729273483591448\n",
      "Training epoch 5153...\n",
      "\n",
      "Train Epoch: 5153 [0/8000 (0%)]\tBatch Loss: 0.012852\tLearning Rate (w_theta): 0.001000\t TIME:543.5s\n",
      "\t\t\t\tDisc: 0.011952\t\tSym: 0.000000\t\tSpars: 0.000900\n",
      "\t TVw: 0.939856 | TVb: 2.111600 | GSw: -0.681058 | GSb: -0.387988 | TSUw: -0.380229 | TSUb: -0.012919\n",
      "\n",
      "Train Epoch: 5153 [4000/8000 (50%)]\tBatch Loss: 0.013225\tLearning Rate (w_theta): 0.001000\t TIME:544.7s\n",
      "\t\t\t\tDisc: 0.011927\t\tSym: 0.000000\t\tSpars: 0.001298\n",
      "\t TVw: 0.939381 | TVb: 2.112295 | GSw: -0.680967 | GSb: -0.387859 | TSUw: -0.380307 | TSUb: -0.013038\n",
      "Validating epoch 5153...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013232207127613482\n",
      "Average validation loss: 0.013726004783881772\n",
      "Training epoch 5154...\n",
      "\n",
      "Train Epoch: 5154 [0/8000 (0%)]\tBatch Loss: 0.013180\tLearning Rate (w_theta): 0.001000\t TIME:547.0s\n",
      "\t\t\t\tDisc: 0.012091\t\tSym: 0.000000\t\tSpars: 0.001089\n",
      "\t TVw: 0.939006 | TVb: 2.112997 | GSw: -0.680877 | GSb: -0.387729 | TSUw: -0.380406 | TSUb: -0.013169\n",
      "\n",
      "Train Epoch: 5154 [4000/8000 (50%)]\tBatch Loss: 0.012968\tLearning Rate (w_theta): 0.001000\t TIME:548.3s\n",
      "\t\t\t\tDisc: 0.011801\t\tSym: 0.000000\t\tSpars: 0.001167\n",
      "\t TVw: 0.938628 | TVb: 2.113694 | GSw: -0.680772 | GSb: -0.387586 | TSUw: -0.380306 | TSUb: -0.013192\n",
      "Validating epoch 5154...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013228737627626401\n",
      "Average validation loss: 0.013722552982357923\n",
      "Training epoch 5155...\n",
      "\n",
      "Train Epoch: 5155 [0/8000 (0%)]\tBatch Loss: 0.013291\tLearning Rate (w_theta): 0.001000\t TIME:550.5s\n",
      "\t\t\t\tDisc: 0.012492\t\tSym: 0.000000\t\tSpars: 0.000799\n",
      "\t TVw: 0.938172 | TVb: 2.114387 | GSw: -0.680685 | GSb: -0.387460 | TSUw: -0.380439 | TSUb: -0.013341\n",
      "\n",
      "Train Epoch: 5155 [4000/8000 (50%)]\tBatch Loss: 0.012878\tLearning Rate (w_theta): 0.001000\t TIME:551.8s\n",
      "\t\t\t\tDisc: 0.011745\t\tSym: 0.000000\t\tSpars: 0.001132\n",
      "\t TVw: 0.937125 | TVb: 2.114951 | GSw: -0.680578 | GSb: -0.387312 | TSUw: -0.380287 | TSUb: -0.013334\n",
      "Validating epoch 5155...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01322576462111704\n",
      "Average validation loss: 0.013720010375929431\n",
      "Training epoch 5156...\n",
      "\n",
      "Train Epoch: 5156 [0/8000 (0%)]\tBatch Loss: 0.012918\tLearning Rate (w_theta): 0.001000\t TIME:554.0s\n",
      "\t\t\t\tDisc: 0.012068\t\tSym: 0.000000\t\tSpars: 0.000850\n",
      "\t TVw: 0.936540 | TVb: 2.115624 | GSw: -0.680486 | GSb: -0.387181 | TSUw: -0.380337 | TSUb: -0.013437\n",
      "\n",
      "Train Epoch: 5156 [4000/8000 (50%)]\tBatch Loss: 0.012899\tLearning Rate (w_theta): 0.001000\t TIME:555.2s\n",
      "\t\t\t\tDisc: 0.011778\t\tSym: 0.000000\t\tSpars: 0.001122\n",
      "\t TVw: 0.935843 | TVb: 2.116295 | GSw: -0.680394 | GSb: -0.387051 | TSUw: -0.380358 | TSUb: -0.013523\n",
      "Validating epoch 5156...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013222926535354024\n",
      "Average validation loss: 0.013716937970899745\n",
      "Training epoch 5157...\n",
      "\n",
      "Train Epoch: 5157 [0/8000 (0%)]\tBatch Loss: 0.013185\tLearning Rate (w_theta): 0.001000\t TIME:557.4s\n",
      "\t\t\t\tDisc: 0.012174\t\tSym: 0.000000\t\tSpars: 0.001010\n",
      "\t TVw: 0.935529 | TVb: 2.117013 | GSw: -0.680309 | GSb: -0.386928 | TSUw: -0.380546 | TSUb: -0.013701\n",
      "\n",
      "Train Epoch: 5157 [4000/8000 (50%)]\tBatch Loss: 0.013426\tLearning Rate (w_theta): 0.001000\t TIME:558.7s\n",
      "\t\t\t\tDisc: 0.012324\t\tSym: 0.000000\t\tSpars: 0.001102\n",
      "\t TVw: 0.934962 | TVb: 2.117680 | GSw: -0.680223 | GSb: -0.386803 | TSUw: -0.380695 | TSUb: -0.013857\n",
      "Validating epoch 5157...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013219502583856672\n",
      "Average validation loss: 0.013714051886645526\n",
      "Training epoch 5158...\n",
      "\n",
      "Train Epoch: 5158 [0/8000 (0%)]\tBatch Loss: 0.013268\tLearning Rate (w_theta): 0.001000\t TIME:561.0s\n",
      "\t\t\t\tDisc: 0.012343\t\tSym: 0.000000\t\tSpars: 0.000925\n",
      "\t TVw: 0.934432 | TVb: 2.118364 | GSw: -0.680129 | GSb: -0.386670 | TSUw: -0.380730 | TSUb: -0.013950\n",
      "\n",
      "Train Epoch: 5158 [4000/8000 (50%)]\tBatch Loss: 0.013026\tLearning Rate (w_theta): 0.001000\t TIME:562.2s\n",
      "\t\t\t\tDisc: 0.011967\t\tSym: 0.000000\t\tSpars: 0.001058\n",
      "\t TVw: 0.933982 | TVb: 2.119044 | GSw: -0.680036 | GSb: -0.386537 | TSUw: -0.380811 | TSUb: -0.014069\n",
      "Validating epoch 5158...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013216246853917825\n",
      "Average validation loss: 0.013710877731884901\n",
      "Training epoch 5159...\n",
      "\n",
      "Train Epoch: 5159 [0/8000 (0%)]\tBatch Loss: 0.012667\tLearning Rate (w_theta): 0.001000\t TIME:564.4s\n",
      "\t\t\t\tDisc: 0.011586\t\tSym: 0.000000\t\tSpars: 0.001082\n",
      "\t TVw: 0.933562 | TVb: 2.119733 | GSw: -0.679943 | GSb: -0.386406 | TSUw: -0.380882 | TSUb: -0.014181\n",
      "\n",
      "Train Epoch: 5159 [4000/8000 (50%)]\tBatch Loss: 0.013785\tLearning Rate (w_theta): 0.001000\t TIME:565.7s\n",
      "\t\t\t\tDisc: 0.012783\t\tSym: 0.000000\t\tSpars: 0.001002\n",
      "\t TVw: 0.933002 | TVb: 2.120406 | GSw: -0.679850 | GSb: -0.386275 | TSUw: -0.380905 | TSUb: -0.014267\n",
      "Validating epoch 5159...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013212956818942388\n",
      "Average validation loss: 0.013707692118313646\n",
      "Training epoch 5160...\n",
      "\n",
      "Train Epoch: 5160 [0/8000 (0%)]\tBatch Loss: 0.012726\tLearning Rate (w_theta): 0.001000\t TIME:568.0s\n",
      "\t\t\t\tDisc: 0.011839\t\tSym: 0.000000\t\tSpars: 0.000887\n",
      "\t TVw: 0.932387 | TVb: 2.121057 | GSw: -0.679743 | GSb: -0.386128 | TSUw: -0.380758 | TSUb: -0.014260\n",
      "\n",
      "Train Epoch: 5160 [4000/8000 (50%)]\tBatch Loss: 0.013672\tLearning Rate (w_theta): 0.001000\t TIME:569.2s\n",
      "\t\t\t\tDisc: 0.012833\t\tSym: 0.000000\t\tSpars: 0.000839\n",
      "\t TVw: 0.932000 | TVb: 2.121733 | GSw: -0.679645 | GSb: -0.385989 | TSUw: -0.380741 | TSUb: -0.014324\n",
      "Validating epoch 5160...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013209944426488766\n",
      "Average validation loss: 0.013704437200163865\n",
      "Training epoch 5161...\n",
      "\n",
      "Train Epoch: 5161 [0/8000 (0%)]\tBatch Loss: 0.012887\tLearning Rate (w_theta): 0.001000\t TIME:572.0s\n",
      "\t\t\t\tDisc: 0.011799\t\tSym: 0.000000\t\tSpars: 0.001088\n",
      "\t TVw: 0.931409 | TVb: 2.122385 | GSw: -0.679544 | GSb: -0.385850 | TSUw: -0.380699 | TSUb: -0.014374\n",
      "\n",
      "Train Epoch: 5161 [4000/8000 (50%)]\tBatch Loss: 0.013652\tLearning Rate (w_theta): 0.001000\t TIME:573.3s\n",
      "\t\t\t\tDisc: 0.012621\t\tSym: 0.000000\t\tSpars: 0.001032\n",
      "\t TVw: 0.931171 | TVb: 2.123092 | GSw: -0.679445 | GSb: -0.385710 | TSUw: -0.380733 | TSUb: -0.014465\n",
      "Validating epoch 5161...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013206713499890534\n",
      "Average validation loss: 0.013701205284212417\n",
      "Training epoch 5162...\n",
      "\n",
      "Train Epoch: 5162 [0/8000 (0%)]\tBatch Loss: 0.012887\tLearning Rate (w_theta): 0.001000\t TIME:575.5s\n",
      "\t\t\t\tDisc: 0.012036\t\tSym: 0.000000\t\tSpars: 0.000851\n",
      "\t TVw: 0.930409 | TVb: 2.123718 | GSw: -0.679345 | GSb: -0.385570 | TSUw: -0.380692 | TSUb: -0.014515\n",
      "\n",
      "Train Epoch: 5162 [4000/8000 (50%)]\tBatch Loss: 0.012966\tLearning Rate (w_theta): 0.001000\t TIME:576.8s\n",
      "\t\t\t\tDisc: 0.012053\t\tSym: 0.000000\t\tSpars: 0.000913\n",
      "\t TVw: 0.929670 | TVb: 2.124365 | GSw: -0.679253 | GSb: -0.385441 | TSUw: -0.380773 | TSUb: -0.014630\n",
      "Validating epoch 5162...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013203926808445695\n",
      "Average validation loss: 0.013698654522951964\n",
      "Training epoch 5163...\n",
      "\n",
      "Train Epoch: 5163 [0/8000 (0%)]\tBatch Loss: 0.013013\tLearning Rate (w_theta): 0.001000\t TIME:579.0s\n",
      "\t\t\t\tDisc: 0.012142\t\tSym: 0.000000\t\tSpars: 0.000871\n",
      "\t TVw: 0.928856 | TVb: 2.124982 | GSw: -0.679150 | GSb: -0.385297 | TSUw: -0.380675 | TSUb: -0.014648\n",
      "\n",
      "Train Epoch: 5163 [4000/8000 (50%)]\tBatch Loss: 0.013349\tLearning Rate (w_theta): 0.001000\t TIME:580.3s\n",
      "\t\t\t\tDisc: 0.011978\t\tSym: 0.000000\t\tSpars: 0.001371\n",
      "\t TVw: 0.928225 | TVb: 2.125629 | GSw: -0.679054 | GSb: -0.385159 | TSUw: -0.380703 | TSUb: -0.014734\n",
      "Validating epoch 5163...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013201438905154773\n",
      "Average validation loss: 0.013695789648740433\n",
      "Training epoch 5164...\n",
      "\n",
      "Train Epoch: 5164 [0/8000 (0%)]\tBatch Loss: 0.012914\tLearning Rate (w_theta): 0.001000\t TIME:582.6s\n",
      "\t\t\t\tDisc: 0.012019\t\tSym: 0.000000\t\tSpars: 0.000896\n",
      "\t TVw: 0.927728 | TVb: 2.126290 | GSw: -0.678963 | GSb: -0.385029 | TSUw: -0.380811 | TSUb: -0.014865\n",
      "\n",
      "Train Epoch: 5164 [4000/8000 (50%)]\tBatch Loss: 0.013179\tLearning Rate (w_theta): 0.001000\t TIME:583.9s\n",
      "\t\t\t\tDisc: 0.011967\t\tSym: 0.000000\t\tSpars: 0.001212\n",
      "\t TVw: 0.926920 | TVb: 2.126893 | GSw: -0.678858 | GSb: -0.384882 | TSUw: -0.380703 | TSUb: -0.014877\n",
      "Validating epoch 5164...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013198633807537831\n",
      "Average validation loss: 0.013692930751095924\n",
      "Training epoch 5165...\n",
      "\n",
      "Train Epoch: 5165 [0/8000 (0%)]\tBatch Loss: 0.013074\tLearning Rate (w_theta): 0.001000\t TIME:586.1s\n",
      "\t\t\t\tDisc: 0.012112\t\tSym: 0.000000\t\tSpars: 0.000962\n",
      "\t TVw: 0.926475 | TVb: 2.127552 | GSw: -0.678761 | GSb: -0.384745 | TSUw: -0.380733 | TSUb: -0.014964\n",
      "\n",
      "Train Epoch: 5165 [4000/8000 (50%)]\tBatch Loss: 0.013582\tLearning Rate (w_theta): 0.001000\t TIME:587.4s\n",
      "\t\t\t\tDisc: 0.012476\t\tSym: 0.000000\t\tSpars: 0.001106\n",
      "\t TVw: 0.925887 | TVb: 2.128192 | GSw: -0.678670 | GSb: -0.384616 | TSUw: -0.380825 | TSUb: -0.015084\n",
      "Validating epoch 5165...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013195697054010743\n",
      "Average validation loss: 0.013690205655206098\n",
      "Training epoch 5166...\n",
      "\n",
      "Train Epoch: 5166 [0/8000 (0%)]\tBatch Loss: 0.013348\tLearning Rate (w_theta): 0.001000\t TIME:589.5s\n",
      "\t\t\t\tDisc: 0.012192\t\tSym: 0.000000\t\tSpars: 0.001156\n",
      "\t TVw: 0.925265 | TVb: 2.128828 | GSw: -0.678577 | GSb: -0.384483 | TSUw: -0.380913 | TSUb: -0.015202\n",
      "\n",
      "Train Epoch: 5166 [4000/8000 (50%)]\tBatch Loss: 0.014015\tLearning Rate (w_theta): 0.001000\t TIME:590.8s\n",
      "\t\t\t\tDisc: 0.013010\t\tSym: 0.000000\t\tSpars: 0.001005\n",
      "\t TVw: 0.924864 | TVb: 2.129491 | GSw: -0.678491 | GSb: -0.384356 | TSUw: -0.381130 | TSUb: -0.015390\n",
      "Validating epoch 5166...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013192875124620017\n",
      "Average validation loss: 0.013687541619727484\n",
      "Training epoch 5167...\n",
      "\n",
      "Train Epoch: 5167 [0/8000 (0%)]\tBatch Loss: 0.013026\tLearning Rate (w_theta): 0.001000\t TIME:593.0s\n",
      "\t\t\t\tDisc: 0.012245\t\tSym: 0.000000\t\tSpars: 0.000781\n",
      "\t TVw: 0.924267 | TVb: 2.130111 | GSw: -0.678398 | GSb: -0.384224 | TSUw: -0.381214 | TSUb: -0.015504\n",
      "\n",
      "Train Epoch: 5167 [4000/8000 (50%)]\tBatch Loss: 0.013670\tLearning Rate (w_theta): 0.001000\t TIME:594.3s\n",
      "\t\t\t\tDisc: 0.012724\t\tSym: 0.000000\t\tSpars: 0.000946\n",
      "\t TVw: 0.923392 | TVb: 2.130692 | GSw: -0.678304 | GSb: -0.384090 | TSUw: -0.381271 | TSUb: -0.015604\n",
      "Validating epoch 5167...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013190083864998738\n",
      "Average validation loss: 0.013685198984750645\n",
      "Training epoch 5168...\n",
      "\n",
      "Train Epoch: 5168 [0/8000 (0%)]\tBatch Loss: 0.013171\tLearning Rate (w_theta): 0.001000\t TIME:596.5s\n",
      "\t\t\t\tDisc: 0.012132\t\tSym: 0.000000\t\tSpars: 0.001039\n",
      "\t TVw: 0.922802 | TVb: 2.131308 | GSw: -0.678206 | GSb: -0.383952 | TSUw: -0.381282 | TSUb: -0.015678\n",
      "\n",
      "Train Epoch: 5168 [4000/8000 (50%)]\tBatch Loss: 0.013715\tLearning Rate (w_theta): 0.001000\t TIME:597.8s\n",
      "\t\t\t\tDisc: 0.012721\t\tSym: 0.000000\t\tSpars: 0.000994\n",
      "\t TVw: 0.922507 | TVb: 2.131966 | GSw: -0.678116 | GSb: -0.383821 | TSUw: -0.381401 | TSUb: -0.015811\n",
      "Validating epoch 5168...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013187470749377098\n",
      "Average validation loss: 0.013682261020965947\n",
      "Training epoch 5169...\n",
      "\n",
      "Train Epoch: 5169 [0/8000 (0%)]\tBatch Loss: 0.013594\tLearning Rate (w_theta): 0.001000\t TIME:600.1s\n",
      "\t\t\t\tDisc: 0.012162\t\tSym: 0.000000\t\tSpars: 0.001432\n",
      "\t TVw: 0.922009 | TVb: 2.132595 | GSw: -0.678018 | GSb: -0.383682 | TSUw: -0.381434 | TSUb: -0.015897\n",
      "\n",
      "Train Epoch: 5169 [4000/8000 (50%)]\tBatch Loss: 0.013188\tLearning Rate (w_theta): 0.001000\t TIME:601.4s\n",
      "\t\t\t\tDisc: 0.012027\t\tSym: 0.000000\t\tSpars: 0.001161\n",
      "\t TVw: 0.921465 | TVb: 2.133197 | GSw: -0.677914 | GSb: -0.383536 | TSUw: -0.381382 | TSUb: -0.015936\n",
      "Validating epoch 5169...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013184436044750055\n",
      "Average validation loss: 0.013679495973826953\n",
      "Training epoch 5170...\n",
      "\n",
      "Train Epoch: 5170 [0/8000 (0%)]\tBatch Loss: 0.012704\tLearning Rate (w_theta): 0.001000\t TIME:603.5s\n",
      "\t\t\t\tDisc: 0.011750\t\tSym: 0.000000\t\tSpars: 0.000954\n",
      "\t TVw: 0.920775 | TVb: 2.133788 | GSw: -0.677810 | GSb: -0.383391 | TSUw: -0.381322 | TSUb: -0.015971\n",
      "\n",
      "Train Epoch: 5170 [4000/8000 (50%)]\tBatch Loss: 0.013099\tLearning Rate (w_theta): 0.001000\t TIME:604.8s\n",
      "\t\t\t\tDisc: 0.012301\t\tSym: 0.000000\t\tSpars: 0.000798\n",
      "\t TVw: 0.920150 | TVb: 2.134408 | GSw: -0.677717 | GSb: -0.383257 | TSUw: -0.381425 | TSUb: -0.016093\n",
      "Validating epoch 5170...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013182018588750812\n",
      "Average validation loss: 0.013676891113827491\n",
      "Training epoch 5171...\n",
      "\n",
      "Train Epoch: 5171 [0/8000 (0%)]\tBatch Loss: 0.013783\tLearning Rate (w_theta): 0.001000\t TIME:607.6s\n",
      "\t\t\t\tDisc: 0.012694\t\tSym: 0.000000\t\tSpars: 0.001089\n",
      "\t TVw: 0.919639 | TVb: 2.135043 | GSw: -0.677617 | GSb: -0.383117 | TSUw: -0.381408 | TSUb: -0.016150\n",
      "\n",
      "Train Epoch: 5171 [4000/8000 (50%)]\tBatch Loss: 0.012953\tLearning Rate (w_theta): 0.001000\t TIME:608.9s\n",
      "\t\t\t\tDisc: 0.012003\t\tSym: 0.000000\t\tSpars: 0.000950\n",
      "\t TVw: 0.918958 | TVb: 2.135652 | GSw: -0.677502 | GSb: -0.382960 | TSUw: -0.381160 | TSUb: -0.016081\n",
      "Validating epoch 5171...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01317952295763655\n",
      "Average validation loss: 0.01367387385334763\n",
      "Training epoch 5172...\n",
      "\n",
      "Train Epoch: 5172 [0/8000 (0%)]\tBatch Loss: 0.012411\tLearning Rate (w_theta): 0.001000\t TIME:611.2s\n",
      "\t\t\t\tDisc: 0.011460\t\tSym: 0.000000\t\tSpars: 0.000952\n",
      "\t TVw: 0.918396 | TVb: 2.136254 | GSw: -0.677403 | GSb: -0.382821 | TSUw: -0.381174 | TSUb: -0.016154\n",
      "\n",
      "Train Epoch: 5172 [4000/8000 (50%)]\tBatch Loss: 0.012984\tLearning Rate (w_theta): 0.001000\t TIME:612.4s\n",
      "\t\t\t\tDisc: 0.012127\t\tSym: 0.000000\t\tSpars: 0.000856\n",
      "\t TVw: 0.917656 | TVb: 2.136841 | GSw: -0.677297 | GSb: -0.382672 | TSUw: -0.381055 | TSUb: -0.016156\n",
      "Validating epoch 5172...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013177112403583251\n",
      "Average validation loss: 0.01367142590162569\n",
      "Training epoch 5173...\n",
      "\n",
      "Train Epoch: 5173 [0/8000 (0%)]\tBatch Loss: 0.013102\tLearning Rate (w_theta): 0.001000\t TIME:614.7s\n",
      "\t\t\t\tDisc: 0.012036\t\tSym: 0.000000\t\tSpars: 0.001066\n",
      "\t TVw: 0.917015 | TVb: 2.137445 | GSw: -0.677203 | GSb: -0.382537 | TSUw: -0.381137 | TSUb: -0.016265\n",
      "\n",
      "Train Epoch: 5173 [4000/8000 (50%)]\tBatch Loss: 0.013182\tLearning Rate (w_theta): 0.001000\t TIME:616.0s\n",
      "\t\t\t\tDisc: 0.012034\t\tSym: 0.000000\t\tSpars: 0.001148\n",
      "\t TVw: 0.916491 | TVb: 2.138050 | GSw: -0.677104 | GSb: -0.382398 | TSUw: -0.381168 | TSUb: -0.016348\n",
      "Validating epoch 5173...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013174526293701347\n",
      "Average validation loss: 0.013668879166553417\n",
      "Training epoch 5174...\n",
      "\n",
      "Train Epoch: 5174 [0/8000 (0%)]\tBatch Loss: 0.012799\tLearning Rate (w_theta): 0.001000\t TIME:618.2s\n",
      "\t\t\t\tDisc: 0.011870\t\tSym: 0.000000\t\tSpars: 0.000928\n",
      "\t TVw: 0.915872 | TVb: 2.138646 | GSw: -0.677010 | GSb: -0.382263 | TSUw: -0.381251 | TSUb: -0.016459\n",
      "\n",
      "Train Epoch: 5174 [4000/8000 (50%)]\tBatch Loss: 0.012988\tLearning Rate (w_theta): 0.001000\t TIME:619.5s\n",
      "\t\t\t\tDisc: 0.011764\t\tSym: 0.000000\t\tSpars: 0.001224\n",
      "\t TVw: 0.915391 | TVb: 2.139273 | GSw: -0.676921 | GSb: -0.382133 | TSUw: -0.381414 | TSUb: -0.016613\n",
      "Validating epoch 5174...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013171875528201343\n",
      "Average validation loss: 0.013666399601211129\n",
      "Training epoch 5175...\n",
      "\n",
      "Train Epoch: 5175 [0/8000 (0%)]\tBatch Loss: 0.013307\tLearning Rate (w_theta): 0.001000\t TIME:621.6s\n",
      "\t\t\t\tDisc: 0.012037\t\tSym: 0.000000\t\tSpars: 0.001271\n",
      "\t TVw: 0.914883 | TVb: 2.139881 | GSw: -0.676823 | GSb: -0.381994 | TSUw: -0.381466 | TSUb: -0.016706\n",
      "\n",
      "Train Epoch: 5175 [4000/8000 (50%)]\tBatch Loss: 0.013259\tLearning Rate (w_theta): 0.001000\t TIME:622.9s\n",
      "\t\t\t\tDisc: 0.012231\t\tSym: 0.000000\t\tSpars: 0.001027\n",
      "\t TVw: 0.914412 | TVb: 2.140490 | GSw: -0.676721 | GSb: -0.381851 | TSUw: -0.381467 | TSUb: -0.016771\n",
      "Validating epoch 5175...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013169071378860095\n",
      "Average validation loss: 0.013663683913873358\n",
      "Training epoch 5176...\n",
      "\n",
      "Train Epoch: 5176 [0/8000 (0%)]\tBatch Loss: 0.012714\tLearning Rate (w_theta): 0.001000\t TIME:625.1s\n",
      "\t\t\t\tDisc: 0.011965\t\tSym: 0.000000\t\tSpars: 0.000750\n",
      "\t TVw: 0.913759 | TVb: 2.141074 | GSw: -0.676622 | GSb: -0.381710 | TSUw: -0.381483 | TSUb: -0.016843\n",
      "\n",
      "Train Epoch: 5176 [4000/8000 (50%)]\tBatch Loss: 0.013061\tLearning Rate (w_theta): 0.001000\t TIME:626.4s\n",
      "\t\t\t\tDisc: 0.011868\t\tSym: 0.000000\t\tSpars: 0.001193\n",
      "\t TVw: 0.912979 | TVb: 2.141633 | GSw: -0.676525 | GSb: -0.381572 | TSUw: -0.381530 | TSUb: -0.016932\n",
      "Validating epoch 5176...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013166777221501308\n",
      "Average validation loss: 0.013661515343188695\n",
      "Training epoch 5177...\n",
      "\n",
      "Train Epoch: 5177 [0/8000 (0%)]\tBatch Loss: 0.012842\tLearning Rate (w_theta): 0.001000\t TIME:628.6s\n",
      "\t\t\t\tDisc: 0.011972\t\tSym: 0.000000\t\tSpars: 0.000870\n",
      "\t TVw: 0.912444 | TVb: 2.142247 | GSw: -0.676435 | GSb: -0.381440 | TSUw: -0.381686 | TSUb: -0.017081\n",
      "\n",
      "Train Epoch: 5177 [4000/8000 (50%)]\tBatch Loss: 0.013171\tLearning Rate (w_theta): 0.001000\t TIME:629.8s\n",
      "\t\t\t\tDisc: 0.012224\t\tSym: 0.000000\t\tSpars: 0.000947\n",
      "\t TVw: 0.912024 | TVb: 2.142860 | GSw: -0.676351 | GSb: -0.381316 | TSUw: -0.381970 | TSUb: -0.017299\n",
      "Validating epoch 5177...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013164194901108444\n",
      "Average validation loss: 0.013659052235033291\n",
      "Training epoch 5178...\n",
      "\n",
      "Train Epoch: 5178 [0/8000 (0%)]\tBatch Loss: 0.013376\tLearning Rate (w_theta): 0.001000\t TIME:632.2s\n",
      "\t\t\t\tDisc: 0.012507\t\tSym: 0.000000\t\tSpars: 0.000869\n",
      "\t TVw: 0.911411 | TVb: 2.143456 | GSw: -0.676244 | GSb: -0.381166 | TSUw: -0.381875 | TSUb: -0.017309\n",
      "\n",
      "Train Epoch: 5178 [4000/8000 (50%)]\tBatch Loss: 0.013617\tLearning Rate (w_theta): 0.001000\t TIME:633.5s\n",
      "\t\t\t\tDisc: 0.012552\t\tSym: 0.000000\t\tSpars: 0.001065\n",
      "\t TVw: 0.910971 | TVb: 2.144061 | GSw: -0.676138 | GSb: -0.381017 | TSUw: -0.381817 | TSUb: -0.017340\n",
      "Validating epoch 5178...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013161499267475354\n",
      "Average validation loss: 0.01365627755759411\n",
      "Training epoch 5179...\n",
      "\n",
      "Train Epoch: 5179 [0/8000 (0%)]\tBatch Loss: 0.013333\tLearning Rate (w_theta): 0.001000\t TIME:635.7s\n",
      "\t\t\t\tDisc: 0.012322\t\tSym: 0.000000\t\tSpars: 0.001011\n",
      "\t TVw: 0.910348 | TVb: 2.144642 | GSw: -0.676034 | GSb: -0.380870 | TSUw: -0.381761 | TSUb: -0.017371\n",
      "\n",
      "Train Epoch: 5179 [4000/8000 (50%)]\tBatch Loss: 0.012526\tLearning Rate (w_theta): 0.001000\t TIME:636.9s\n",
      "\t\t\t\tDisc: 0.011623\t\tSym: 0.000000\t\tSpars: 0.000903\n",
      "\t TVw: 0.909832 | TVb: 2.145231 | GSw: -0.675932 | GSb: -0.380728 | TSUw: -0.381751 | TSUb: -0.017427\n",
      "Validating epoch 5179...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013158937423653146\n",
      "Average validation loss: 0.013653768155914644\n",
      "Training epoch 5180...\n",
      "\n",
      "Train Epoch: 5180 [0/8000 (0%)]\tBatch Loss: 0.012806\tLearning Rate (w_theta): 0.001000\t TIME:639.1s\n",
      "\t\t\t\tDisc: 0.011922\t\tSym: 0.000000\t\tSpars: 0.000884\n",
      "\t TVw: 0.909151 | TVb: 2.145813 | GSw: -0.675832 | GSb: -0.380587 | TSUw: -0.381763 | TSUb: -0.017494\n",
      "\n",
      "Train Epoch: 5180 [4000/8000 (50%)]\tBatch Loss: 0.013757\tLearning Rate (w_theta): 0.001000\t TIME:640.4s\n",
      "\t\t\t\tDisc: 0.012504\t\tSym: 0.000000\t\tSpars: 0.001253\n",
      "\t TVw: 0.908467 | TVb: 2.146392 | GSw: -0.675739 | GSb: -0.380453 | TSUw: -0.381893 | TSUb: -0.017626\n",
      "Validating epoch 5180...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013156661525407495\n",
      "Average validation loss: 0.013651546684078251\n",
      "Training epoch 5181...\n",
      "\n",
      "Train Epoch: 5181 [0/8000 (0%)]\tBatch Loss: 0.013395\tLearning Rate (w_theta): 0.001000\t TIME:643.2s\n",
      "\t\t\t\tDisc: 0.012338\t\tSym: 0.000000\t\tSpars: 0.001057\n",
      "\t TVw: 0.907955 | TVb: 2.146978 | GSw: -0.675638 | GSb: -0.380310 | TSUw: -0.381904 | TSUb: -0.017693\n",
      "\n",
      "Train Epoch: 5181 [4000/8000 (50%)]\tBatch Loss: 0.013643\tLearning Rate (w_theta): 0.001000\t TIME:644.5s\n",
      "\t\t\t\tDisc: 0.012639\t\tSym: 0.000000\t\tSpars: 0.001004\n",
      "\t TVw: 0.907321 | TVb: 2.147525 | GSw: -0.675523 | GSb: -0.380153 | TSUw: -0.381721 | TSUb: -0.017653\n",
      "Validating epoch 5181...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013154481097828635\n",
      "Average validation loss: 0.01364889386417123\n",
      "Training epoch 5182...\n",
      "\n",
      "Train Epoch: 5182 [0/8000 (0%)]\tBatch Loss: 0.012913\tLearning Rate (w_theta): 0.001000\t TIME:646.8s\n",
      "\t\t\t\tDisc: 0.012128\t\tSym: 0.000000\t\tSpars: 0.000785\n",
      "\t TVw: 0.906669 | TVb: 2.148086 | GSw: -0.675416 | GSb: -0.380003 | TSUw: -0.381644 | TSUb: -0.017671\n",
      "\n",
      "Train Epoch: 5182 [4000/8000 (50%)]\tBatch Loss: 0.013294\tLearning Rate (w_theta): 0.001000\t TIME:648.1s\n",
      "\t\t\t\tDisc: 0.012113\t\tSym: 0.000000\t\tSpars: 0.001181\n",
      "\t TVw: 0.905776 | TVb: 2.148651 | GSw: -0.675305 | GSb: -0.379848 | TSUw: -0.381467 | TSUb: -0.017634\n",
      "Validating epoch 5182...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013152730715355531\n",
      "Average validation loss: 0.013646600590911715\n",
      "Training epoch 5183...\n",
      "\n",
      "Train Epoch: 5183 [0/8000 (0%)]\tBatch Loss: 0.013088\tLearning Rate (w_theta): 0.001000\t TIME:650.3s\n",
      "\t\t\t\tDisc: 0.011964\t\tSym: 0.000000\t\tSpars: 0.001124\n",
      "\t TVw: 0.905293 | TVb: 2.149240 | GSw: -0.675215 | GSb: -0.379717 | TSUw: -0.381677 | TSUb: -0.017809\n",
      "\n",
      "Train Epoch: 5183 [4000/8000 (50%)]\tBatch Loss: 0.012762\tLearning Rate (w_theta): 0.001000\t TIME:651.6s\n",
      "\t\t\t\tDisc: 0.011846\t\tSym: 0.000000\t\tSpars: 0.000916\n",
      "\t TVw: 0.904944 | TVb: 2.149845 | GSw: -0.675135 | GSb: -0.379595 | TSUw: -0.382013 | TSUb: -0.018052\n",
      "Validating epoch 5183...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013149913181716774\n",
      "Average validation loss: 0.013644474506222115\n",
      "Training epoch 5184...\n",
      "\n",
      "Train Epoch: 5184 [0/8000 (0%)]\tBatch Loss: 0.012568\tLearning Rate (w_theta): 0.001000\t TIME:653.8s\n",
      "\t\t\t\tDisc: 0.011777\t\tSym: 0.000000\t\tSpars: 0.000791\n",
      "\t TVw: 0.904278 | TVb: 2.150400 | GSw: -0.675041 | GSb: -0.379459 | TSUw: -0.382141 | TSUb: -0.018181\n",
      "\n",
      "Train Epoch: 5184 [4000/8000 (50%)]\tBatch Loss: 0.014022\tLearning Rate (w_theta): 0.001000\t TIME:655.0s\n",
      "\t\t\t\tDisc: 0.012769\t\tSym: 0.000000\t\tSpars: 0.001253\n",
      "\t TVw: 0.903488 | TVb: 2.150939 | GSw: -0.674932 | GSb: -0.379309 | TSUw: -0.382027 | TSUb: -0.018177\n",
      "Validating epoch 5184...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013147662382199814\n",
      "Average validation loss: 0.013642210367365834\n",
      "Training epoch 5185...\n",
      "\n",
      "Train Epoch: 5185 [0/8000 (0%)]\tBatch Loss: 0.012938\tLearning Rate (w_theta): 0.001000\t TIME:657.2s\n",
      "\t\t\t\tDisc: 0.011872\t\tSym: 0.000000\t\tSpars: 0.001066\n",
      "\t TVw: 0.902994 | TVb: 2.151508 | GSw: -0.674834 | GSb: -0.379168 | TSUw: -0.382124 | TSUb: -0.018289\n",
      "\n",
      "Train Epoch: 5185 [4000/8000 (50%)]\tBatch Loss: 0.012795\tLearning Rate (w_theta): 0.001000\t TIME:658.5s\n",
      "\t\t\t\tDisc: 0.011947\t\tSym: 0.000000\t\tSpars: 0.000848\n",
      "\t TVw: 0.902845 | TVb: 2.152137 | GSw: -0.674752 | GSb: -0.379043 | TSUw: -0.382466 | TSUb: -0.018535\n",
      "Validating epoch 5185...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013145129295755918\n",
      "Average validation loss: 0.013639851740399405\n",
      "Training epoch 5186...\n",
      "\n",
      "Train Epoch: 5186 [0/8000 (0%)]\tBatch Loss: 0.013471\tLearning Rate (w_theta): 0.001000\t TIME:660.7s\n",
      "\t\t\t\tDisc: 0.012080\t\tSym: 0.000000\t\tSpars: 0.001391\n",
      "\t TVw: 0.902430 | TVb: 2.152721 | GSw: -0.674658 | GSb: -0.378907 | TSUw: -0.382620 | TSUb: -0.018678\n",
      "\n",
      "Train Epoch: 5186 [4000/8000 (50%)]\tBatch Loss: 0.013480\tLearning Rate (w_theta): 0.001000\t TIME:661.9s\n",
      "\t\t\t\tDisc: 0.012585\t\tSym: 0.000000\t\tSpars: 0.000894\n",
      "\t TVw: 0.902174 | TVb: 2.153321 | GSw: -0.674574 | GSb: -0.378781 | TSUw: -0.382969 | TSUb: -0.018927\n",
      "Validating epoch 5186...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013142275999108593\n",
      "Average validation loss: 0.013637671275760823\n",
      "Training epoch 5187...\n",
      "\n",
      "Train Epoch: 5187 [0/8000 (0%)]\tBatch Loss: 0.013692\tLearning Rate (w_theta): 0.001000\t TIME:664.3s\n",
      "\t\t\t\tDisc: 0.012441\t\tSym: 0.000000\t\tSpars: 0.001251\n",
      "\t TVw: 0.901595 | TVb: 2.153871 | GSw: -0.674465 | GSb: -0.378629 | TSUw: -0.382855 | TSUb: -0.018920\n",
      "\n",
      "Train Epoch: 5187 [4000/8000 (50%)]\tBatch Loss: 0.013137\tLearning Rate (w_theta): 0.001000\t TIME:665.6s\n",
      "\t\t\t\tDisc: 0.012230\t\tSym: 0.000000\t\tSpars: 0.000908\n",
      "\t TVw: 0.901292 | TVb: 2.154456 | GSw: -0.674357 | GSb: -0.378478 | TSUw: -0.382793 | TSUb: -0.018942\n",
      "Validating epoch 5187...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013139259183990828\n",
      "Average validation loss: 0.01363469634974831\n",
      "Training epoch 5188...\n",
      "\n",
      "Train Epoch: 5188 [0/8000 (0%)]\tBatch Loss: 0.013056\tLearning Rate (w_theta): 0.001000\t TIME:667.8s\n",
      "\t\t\t\tDisc: 0.012155\t\tSym: 0.000000\t\tSpars: 0.000901\n",
      "\t TVw: 0.900637 | TVb: 2.154991 | GSw: -0.674241 | GSb: -0.378319 | TSUw: -0.382599 | TSUb: -0.018891\n",
      "\n",
      "Train Epoch: 5188 [4000/8000 (50%)]\tBatch Loss: 0.012532\tLearning Rate (w_theta): 0.001000\t TIME:669.1s\n",
      "\t\t\t\tDisc: 0.011833\t\tSym: 0.000000\t\tSpars: 0.000698\n",
      "\t TVw: 0.899851 | TVb: 2.155492 | GSw: -0.674124 | GSb: -0.378158 | TSUw: -0.382384 | TSUb: -0.018828\n",
      "Validating epoch 5188...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013137378279695845\n",
      "Average validation loss: 0.01363240953690075\n",
      "Training epoch 5189...\n",
      "\n",
      "Train Epoch: 5189 [0/8000 (0%)]\tBatch Loss: 0.012514\tLearning Rate (w_theta): 0.001000\t TIME:671.3s\n",
      "\t\t\t\tDisc: 0.011671\t\tSym: 0.000000\t\tSpars: 0.000842\n",
      "\t TVw: 0.899131 | TVb: 2.156004 | GSw: -0.674013 | GSb: -0.378004 | TSUw: -0.382267 | TSUb: -0.018818\n",
      "\n",
      "Train Epoch: 5189 [4000/8000 (50%)]\tBatch Loss: 0.013105\tLearning Rate (w_theta): 0.001000\t TIME:672.6s\n",
      "\t\t\t\tDisc: 0.012212\t\tSym: 0.000000\t\tSpars: 0.000893\n",
      "\t TVw: 0.898458 | TVb: 2.156504 | GSw: -0.673916 | GSb: -0.377865 | TSUw: -0.382379 | TSUb: -0.018935\n",
      "Validating epoch 5189...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013135723851895719\n",
      "Average validation loss: 0.013630525174727685\n",
      "Training epoch 5190...\n",
      "\n",
      "Train Epoch: 5190 [0/8000 (0%)]\tBatch Loss: 0.013104\tLearning Rate (w_theta): 0.001000\t TIME:674.7s\n",
      "\t\t\t\tDisc: 0.012003\t\tSym: 0.000000\t\tSpars: 0.001101\n",
      "\t TVw: 0.897890 | TVb: 2.157055 | GSw: -0.673818 | GSb: -0.377725 | TSUw: -0.382463 | TSUb: -0.019036\n",
      "\n",
      "Train Epoch: 5190 [4000/8000 (50%)]\tBatch Loss: 0.013737\tLearning Rate (w_theta): 0.001000\t TIME:676.0s\n",
      "\t\t\t\tDisc: 0.012527\t\tSym: 0.000000\t\tSpars: 0.001210\n",
      "\t TVw: 0.897167 | TVb: 2.157590 | GSw: -0.673715 | GSb: -0.377576 | TSUw: -0.382433 | TSUb: -0.019074\n",
      "Validating epoch 5190...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013133693600523699\n",
      "Average validation loss: 0.013628228835255442\n",
      "Training epoch 5191...\n",
      "\n",
      "Train Epoch: 5191 [0/8000 (0%)]\tBatch Loss: 0.013208\tLearning Rate (w_theta): 0.001000\t TIME:678.8s\n",
      "\t\t\t\tDisc: 0.012363\t\tSym: 0.000000\t\tSpars: 0.000845\n",
      "\t TVw: 0.896659 | TVb: 2.158141 | GSw: -0.673608 | GSb: -0.377426 | TSUw: -0.382383 | TSUb: -0.019101\n",
      "\n",
      "Train Epoch: 5191 [4000/8000 (50%)]\tBatch Loss: 0.013756\tLearning Rate (w_theta): 0.001000\t TIME:680.1s\n",
      "\t\t\t\tDisc: 0.012458\t\tSym: 0.000000\t\tSpars: 0.001298\n",
      "\t TVw: 0.896205 | TVb: 2.158674 | GSw: -0.673509 | GSb: -0.377284 | TSUw: -0.382493 | TSUb: -0.019216\n",
      "Validating epoch 5191...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013131595240167881\n",
      "Average validation loss: 0.013625952512142006\n",
      "Training epoch 5192...\n",
      "\n",
      "Train Epoch: 5192 [0/8000 (0%)]\tBatch Loss: 0.013333\tLearning Rate (w_theta): 0.001000\t TIME:682.4s\n",
      "\t\t\t\tDisc: 0.012069\t\tSym: 0.000000\t\tSpars: 0.001264\n",
      "\t TVw: 0.895840 | TVb: 2.159245 | GSw: -0.673408 | GSb: -0.377141 | TSUw: -0.382578 | TSUb: -0.019317\n",
      "\n",
      "Train Epoch: 5192 [4000/8000 (50%)]\tBatch Loss: 0.012890\tLearning Rate (w_theta): 0.001000\t TIME:683.7s\n",
      "\t\t\t\tDisc: 0.011956\t\tSym: 0.000000\t\tSpars: 0.000934\n",
      "\t TVw: 0.895552 | TVb: 2.159796 | GSw: -0.673312 | GSb: -0.377003 | TSUw: -0.382746 | TSUb: -0.019464\n",
      "Validating epoch 5192...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013128909208982673\n",
      "Average validation loss: 0.013623682909740194\n",
      "Training epoch 5193...\n",
      "\n",
      "Train Epoch: 5193 [0/8000 (0%)]\tBatch Loss: 0.012787\tLearning Rate (w_theta): 0.001000\t TIME:685.9s\n",
      "\t\t\t\tDisc: 0.011888\t\tSym: 0.000000\t\tSpars: 0.000899\n",
      "\t TVw: 0.894896 | TVb: 2.160323 | GSw: -0.673206 | GSb: -0.376853 | TSUw: -0.382696 | TSUb: -0.019490\n",
      "\n",
      "Train Epoch: 5193 [4000/8000 (50%)]\tBatch Loss: 0.012982\tLearning Rate (w_theta): 0.001000\t TIME:687.2s\n",
      "\t\t\t\tDisc: 0.011874\t\tSym: 0.000000\t\tSpars: 0.001107\n",
      "\t TVw: 0.894124 | TVb: 2.160834 | GSw: -0.673104 | GSb: -0.376706 | TSUw: -0.382697 | TSUb: -0.019543\n",
      "Validating epoch 5193...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013127040516419356\n",
      "Average validation loss: 0.013621707441629652\n",
      "Training epoch 5194...\n",
      "\n",
      "Train Epoch: 5194 [0/8000 (0%)]\tBatch Loss: 0.012883\tLearning Rate (w_theta): 0.001000\t TIME:689.4s\n",
      "\t\t\t\tDisc: 0.012187\t\tSym: 0.000000\t\tSpars: 0.000697\n",
      "\t TVw: 0.893237 | TVb: 2.161324 | GSw: -0.672991 | GSb: -0.376549 | TSUw: -0.382546 | TSUb: -0.019513\n",
      "\n",
      "Train Epoch: 5194 [4000/8000 (50%)]\tBatch Loss: 0.012679\tLearning Rate (w_theta): 0.001000\t TIME:690.6s\n",
      "\t\t\t\tDisc: 0.011782\t\tSym: 0.000000\t\tSpars: 0.000896\n",
      "\t TVw: 0.892733 | TVb: 2.161862 | GSw: -0.672885 | GSb: -0.376400 | TSUw: -0.382544 | TSUb: -0.019564\n",
      "Validating epoch 5194...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01312534339288931\n",
      "Average validation loss: 0.013619555813707945\n",
      "Training epoch 5195...\n",
      "\n",
      "Train Epoch: 5195 [0/8000 (0%)]\tBatch Loss: 0.013071\tLearning Rate (w_theta): 0.001000\t TIME:692.8s\n",
      "\t\t\t\tDisc: 0.011974\t\tSym: 0.000000\t\tSpars: 0.001097\n",
      "\t TVw: 0.892282 | TVb: 2.162414 | GSw: -0.672787 | GSb: -0.376260 | TSUw: -0.382679 | TSUb: -0.019691\n",
      "\n",
      "Train Epoch: 5195 [4000/8000 (50%)]\tBatch Loss: 0.013406\tLearning Rate (w_theta): 0.001000\t TIME:694.1s\n",
      "\t\t\t\tDisc: 0.012477\t\tSym: 0.000000\t\tSpars: 0.000929\n",
      "\t TVw: 0.891949 | TVb: 2.162983 | GSw: -0.672689 | GSb: -0.376118 | TSUw: -0.382805 | TSUb: -0.019813\n",
      "Validating epoch 5195...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013122897073669402\n",
      "Average validation loss: 0.013617242355006364\n",
      "Training epoch 5196...\n",
      "\n",
      "Train Epoch: 5196 [0/8000 (0%)]\tBatch Loss: 0.013206\tLearning Rate (w_theta): 0.001000\t TIME:696.3s\n",
      "\t\t\t\tDisc: 0.012294\t\tSym: 0.000000\t\tSpars: 0.000912\n",
      "\t TVw: 0.891419 | TVb: 2.163519 | GSw: -0.672589 | GSb: -0.375974 | TSUw: -0.382875 | TSUb: -0.019903\n",
      "\n",
      "Train Epoch: 5196 [4000/8000 (50%)]\tBatch Loss: 0.013141\tLearning Rate (w_theta): 0.001000\t TIME:697.6s\n",
      "\t\t\t\tDisc: 0.012365\t\tSym: 0.000000\t\tSpars: 0.000776\n",
      "\t TVw: 0.890711 | TVb: 2.164016 | GSw: -0.672486 | GSb: -0.375828 | TSUw: -0.382911 | TSUb: -0.019974\n",
      "Validating epoch 5196...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013120695518356418\n",
      "Average validation loss: 0.013615486327664874\n",
      "Training epoch 5197...\n",
      "\n",
      "Train Epoch: 5197 [0/8000 (0%)]\tBatch Loss: 0.012221\tLearning Rate (w_theta): 0.001000\t TIME:699.8s\n",
      "\t\t\t\tDisc: 0.011554\t\tSym: 0.000000\t\tSpars: 0.000666\n",
      "\t TVw: 0.889973 | TVb: 2.164521 | GSw: -0.672385 | GSb: -0.375683 | TSUw: -0.382955 | TSUb: -0.020049\n",
      "\n",
      "Train Epoch: 5197 [4000/8000 (50%)]\tBatch Loss: 0.013701\tLearning Rate (w_theta): 0.001000\t TIME:701.1s\n",
      "\t\t\t\tDisc: 0.012682\t\tSym: 0.000000\t\tSpars: 0.001019\n",
      "\t TVw: 0.889213 | TVb: 2.165001 | GSw: -0.672283 | GSb: -0.375537 | TSUw: -0.382975 | TSUb: -0.020110\n",
      "Validating epoch 5197...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01311901102857308\n",
      "Average validation loss: 0.013613622197226137\n",
      "Training epoch 5198...\n",
      "\n",
      "Train Epoch: 5198 [0/8000 (0%)]\tBatch Loss: 0.012622\tLearning Rate (w_theta): 0.001000\t TIME:703.4s\n",
      "\t\t\t\tDisc: 0.011979\t\tSym: 0.000000\t\tSpars: 0.000643\n",
      "\t TVw: 0.888763 | TVb: 2.165540 | GSw: -0.672181 | GSb: -0.375391 | TSUw: -0.383036 | TSUb: -0.020194\n",
      "\n",
      "Train Epoch: 5198 [4000/8000 (50%)]\tBatch Loss: 0.012847\tLearning Rate (w_theta): 0.001000\t TIME:704.7s\n",
      "\t\t\t\tDisc: 0.011815\t\tSym: 0.000000\t\tSpars: 0.001032\n",
      "\t TVw: 0.888650 | TVb: 2.166129 | GSw: -0.672088 | GSb: -0.375255 | TSUw: -0.383302 | TSUb: -0.020392\n",
      "Validating epoch 5198...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01311675987773532\n",
      "Average validation loss: 0.013611439493069675\n",
      "Training epoch 5199...\n",
      "\n",
      "Train Epoch: 5199 [0/8000 (0%)]\tBatch Loss: 0.013377\tLearning Rate (w_theta): 0.001000\t TIME:706.9s\n",
      "\t\t\t\tDisc: 0.012350\t\tSym: 0.000000\t\tSpars: 0.001027\n",
      "\t TVw: 0.888215 | TVb: 2.166670 | GSw: -0.671990 | GSb: -0.375112 | TSUw: -0.383431 | TSUb: -0.020512\n",
      "\n",
      "Train Epoch: 5199 [4000/8000 (50%)]\tBatch Loss: 0.012824\tLearning Rate (w_theta): 0.001000\t TIME:708.1s\n",
      "\t\t\t\tDisc: 0.012058\t\tSym: 0.000000\t\tSpars: 0.000766\n",
      "\t TVw: 0.888001 | TVb: 2.167225 | GSw: -0.671897 | GSb: -0.374976 | TSUw: -0.383643 | TSUb: -0.020679\n",
      "Validating epoch 5199...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01311394819238849\n",
      "Average validation loss: 0.013609261088312856\n",
      "Training epoch 5200...\n",
      "\n",
      "Train Epoch: 5200 [0/8000 (0%)]\tBatch Loss: 0.013289\tLearning Rate (w_theta): 0.001000\t TIME:710.4s\n",
      "\t\t\t\tDisc: 0.012333\t\tSym: 0.000000\t\tSpars: 0.000956\n",
      "\t TVw: 0.887504 | TVb: 2.167745 | GSw: -0.671792 | GSb: -0.374827 | TSUw: -0.383659 | TSUb: -0.020737\n",
      "\n",
      "Train Epoch: 5200 [4000/8000 (50%)]\tBatch Loss: 0.012916\tLearning Rate (w_theta): 0.001000\t TIME:711.7s\n",
      "\t\t\t\tDisc: 0.011884\t\tSym: 0.000000\t\tSpars: 0.001032\n",
      "\t TVw: 0.886518 | TVb: 2.168198 | GSw: -0.671676 | GSb: -0.374668 | TSUw: -0.383491 | TSUb: -0.020691\n",
      "Validating epoch 5200...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01311203333695341\n",
      "Average validation loss: 0.013607396473198639\n",
      "Training epoch 5201...\n",
      "\n",
      "Train Epoch: 5201 [0/8000 (0%)]\tBatch Loss: 0.013580\tLearning Rate (w_theta): 0.001000\t TIME:714.5s\n",
      "\t\t\t\tDisc: 0.012251\t\tSym: 0.000000\t\tSpars: 0.001329\n",
      "\t TVw: 0.886026 | TVb: 2.168697 | GSw: -0.671566 | GSb: -0.374513 | TSUw: -0.383472 | TSUb: -0.020728\n",
      "\n",
      "Train Epoch: 5201 [4000/8000 (50%)]\tBatch Loss: 0.013267\tLearning Rate (w_theta): 0.001000\t TIME:715.8s\n",
      "\t\t\t\tDisc: 0.012306\t\tSym: 0.000000\t\tSpars: 0.000961\n",
      "\t TVw: 0.885663 | TVb: 2.169255 | GSw: -0.671468 | GSb: -0.374371 | TSUw: -0.383594 | TSUb: -0.020844\n",
      "Validating epoch 5201...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01311010989846403\n",
      "Average validation loss: 0.013605014693645204\n",
      "Training epoch 5202...\n",
      "\n",
      "Train Epoch: 5202 [0/8000 (0%)]\tBatch Loss: 0.012696\tLearning Rate (w_theta): 0.001000\t TIME:718.0s\n",
      "\t\t\t\tDisc: 0.011803\t\tSym: 0.000000\t\tSpars: 0.000893\n",
      "\t TVw: 0.885291 | TVb: 2.169783 | GSw: -0.671361 | GSb: -0.374221 | TSUw: -0.383611 | TSUb: -0.020901\n",
      "\n",
      "Train Epoch: 5202 [4000/8000 (50%)]\tBatch Loss: 0.013505\tLearning Rate (w_theta): 0.001000\t TIME:719.3s\n",
      "\t\t\t\tDisc: 0.012472\t\tSym: 0.000000\t\tSpars: 0.001033\n",
      "\t TVw: 0.884730 | TVb: 2.170272 | GSw: -0.671264 | GSb: -0.374082 | TSUw: -0.383767 | TSUb: -0.021034\n",
      "Validating epoch 5202...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013107785388922343\n",
      "Average validation loss: 0.013603063590381702\n",
      "Training epoch 5203...\n",
      "\n",
      "Train Epoch: 5203 [0/8000 (0%)]\tBatch Loss: 0.013444\tLearning Rate (w_theta): 0.001000\t TIME:721.6s\n",
      "\t\t\t\tDisc: 0.012270\t\tSym: 0.000000\t\tSpars: 0.001174\n",
      "\t TVw: 0.884367 | TVb: 2.170800 | GSw: -0.671152 | GSb: -0.373924 | TSUw: -0.383688 | TSUb: -0.021037\n",
      "\n",
      "Train Epoch: 5203 [4000/8000 (50%)]\tBatch Loss: 0.013377\tLearning Rate (w_theta): 0.001000\t TIME:722.9s\n",
      "\t\t\t\tDisc: 0.012313\t\tSym: 0.000000\t\tSpars: 0.001065\n",
      "\t TVw: 0.883904 | TVb: 2.171331 | GSw: -0.671037 | GSb: -0.373765 | TSUw: -0.383599 | TSUb: -0.021035\n",
      "Validating epoch 5203...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013105659009070417\n",
      "Average validation loss: 0.01360053583270662\n",
      "Training epoch 5204...\n",
      "\n",
      "Train Epoch: 5204 [0/8000 (0%)]\tBatch Loss: 0.013400\tLearning Rate (w_theta): 0.001000\t TIME:725.0s\n",
      "\t\t\t\tDisc: 0.012291\t\tSym: 0.000000\t\tSpars: 0.001109\n",
      "\t TVw: 0.883408 | TVb: 2.171845 | GSw: -0.670924 | GSb: -0.373606 | TSUw: -0.383506 | TSUb: -0.021029\n",
      "\n",
      "Train Epoch: 5204 [4000/8000 (50%)]\tBatch Loss: 0.013712\tLearning Rate (w_theta): 0.001000\t TIME:726.3s\n",
      "\t\t\t\tDisc: 0.012819\t\tSym: 0.000000\t\tSpars: 0.000893\n",
      "\t TVw: 0.882913 | TVb: 2.172352 | GSw: -0.670816 | GSb: -0.373453 | TSUw: -0.383519 | TSUb: -0.021083\n",
      "Validating epoch 5204...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013103588798973222\n",
      "Average validation loss: 0.013598553890085402\n",
      "Training epoch 5205...\n",
      "\n",
      "Train Epoch: 5205 [0/8000 (0%)]\tBatch Loss: 0.013121\tLearning Rate (w_theta): 0.001000\t TIME:728.6s\n",
      "\t\t\t\tDisc: 0.012240\t\tSym: 0.000000\t\tSpars: 0.000881\n",
      "\t TVw: 0.882184 | TVb: 2.172832 | GSw: -0.670713 | GSb: -0.373306 | TSUw: -0.383569 | TSUb: -0.021156\n",
      "\n",
      "Train Epoch: 5205 [4000/8000 (50%)]\tBatch Loss: 0.013024\tLearning Rate (w_theta): 0.001000\t TIME:729.8s\n",
      "\t\t\t\tDisc: 0.011986\t\tSym: 0.000000\t\tSpars: 0.001038\n",
      "\t TVw: 0.881623 | TVb: 2.173321 | GSw: -0.670617 | GSb: -0.373164 | TSUw: -0.383743 | TSUb: -0.021298\n",
      "Validating epoch 5205...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013101912541445371\n",
      "Average validation loss: 0.013596861504328003\n",
      "Training epoch 5206...\n",
      "\n",
      "Train Epoch: 5206 [0/8000 (0%)]\tBatch Loss: 0.013050\tLearning Rate (w_theta): 0.001000\t TIME:732.0s\n",
      "\t\t\t\tDisc: 0.012277\t\tSym: 0.000000\t\tSpars: 0.000773\n",
      "\t TVw: 0.881136 | TVb: 2.173828 | GSw: -0.670512 | GSb: -0.373015 | TSUw: -0.383784 | TSUb: -0.021366\n",
      "\n",
      "Train Epoch: 5206 [4000/8000 (50%)]\tBatch Loss: 0.013354\tLearning Rate (w_theta): 0.001000\t TIME:733.3s\n",
      "\t\t\t\tDisc: 0.012288\t\tSym: 0.000000\t\tSpars: 0.001066\n",
      "\t TVw: 0.880239 | TVb: 2.174278 | GSw: -0.670396 | GSb: -0.372856 | TSUw: -0.383645 | TSUb: -0.021333\n",
      "Validating epoch 5206...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013100159171403268\n",
      "Average validation loss: 0.013594921997304697\n",
      "Training epoch 5207...\n",
      "\n",
      "Train Epoch: 5207 [0/8000 (0%)]\tBatch Loss: 0.013305\tLearning Rate (w_theta): 0.001000\t TIME:735.5s\n",
      "\t\t\t\tDisc: 0.011943\t\tSym: 0.000000\t\tSpars: 0.001362\n",
      "\t TVw: 0.880032 | TVb: 2.174834 | GSw: -0.670299 | GSb: -0.372715 | TSUw: -0.383831 | TSUb: -0.021481\n",
      "\n",
      "Train Epoch: 5207 [4000/8000 (50%)]\tBatch Loss: 0.013066\tLearning Rate (w_theta): 0.001000\t TIME:736.8s\n",
      "\t\t\t\tDisc: 0.012410\t\tSym: 0.000000\t\tSpars: 0.000657\n",
      "\t TVw: 0.879917 | TVb: 2.175407 | GSw: -0.670195 | GSb: -0.372567 | TSUw: -0.383890 | TSUb: -0.021559\n",
      "Validating epoch 5207...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0130976535141804\n",
      "Average validation loss: 0.013592336152780306\n",
      "Training epoch 5208...\n",
      "\n",
      "Train Epoch: 5208 [0/8000 (0%)]\tBatch Loss: 0.012703\tLearning Rate (w_theta): 0.001000\t TIME:739.0s\n",
      "\t\t\t\tDisc: 0.011945\t\tSym: 0.000000\t\tSpars: 0.000758\n",
      "\t TVw: 0.879394 | TVb: 2.175908 | GSw: -0.670084 | GSb: -0.372411 | TSUw: -0.383844 | TSUb: -0.021577\n",
      "\n",
      "Train Epoch: 5208 [4000/8000 (50%)]\tBatch Loss: 0.013298\tLearning Rate (w_theta): 0.001000\t TIME:740.3s\n",
      "\t\t\t\tDisc: 0.012330\t\tSym: 0.000000\t\tSpars: 0.000968\n",
      "\t TVw: 0.878787 | TVb: 2.176389 | GSw: -0.669977 | GSb: -0.372260 | TSUw: -0.383850 | TSUb: -0.021624\n",
      "Validating epoch 5208...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013095567737204402\n",
      "Average validation loss: 0.013590442139240055\n",
      "Training epoch 5209...\n",
      "\n",
      "Train Epoch: 5209 [0/8000 (0%)]\tBatch Loss: 0.012936\tLearning Rate (w_theta): 0.001000\t TIME:742.6s\n",
      "\t\t\t\tDisc: 0.012112\t\tSym: 0.000000\t\tSpars: 0.000824\n",
      "\t TVw: 0.878177 | TVb: 2.176878 | GSw: -0.669868 | GSb: -0.372106 | TSUw: -0.383834 | TSUb: -0.021659\n",
      "\n",
      "Train Epoch: 5209 [4000/8000 (50%)]\tBatch Loss: 0.013080\tLearning Rate (w_theta): 0.001000\t TIME:743.8s\n",
      "\t\t\t\tDisc: 0.012053\t\tSym: 0.000000\t\tSpars: 0.001027\n",
      "\t TVw: 0.877546 | TVb: 2.177344 | GSw: -0.669757 | GSb: -0.371949 | TSUw: -0.383793 | TSUb: -0.021680\n",
      "Validating epoch 5209...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013093924607374623\n",
      "Average validation loss: 0.013588600201779842\n",
      "Training epoch 5210...\n",
      "\n",
      "Train Epoch: 5210 [0/8000 (0%)]\tBatch Loss: 0.013658\tLearning Rate (w_theta): 0.001000\t TIME:746.0s\n",
      "\t\t\t\tDisc: 0.012521\t\tSym: 0.000000\t\tSpars: 0.001137\n",
      "\t TVw: 0.877109 | TVb: 2.177855 | GSw: -0.669656 | GSb: -0.371803 | TSUw: -0.383917 | TSUb: -0.021792\n",
      "\n",
      "Train Epoch: 5210 [4000/8000 (50%)]\tBatch Loss: 0.013068\tLearning Rate (w_theta): 0.001000\t TIME:747.3s\n",
      "\t\t\t\tDisc: 0.012155\t\tSym: 0.000000\t\tSpars: 0.000913\n",
      "\t TVw: 0.876897 | TVb: 2.178406 | GSw: -0.669569 | GSb: -0.371673 | TSUw: -0.384294 | TSUb: -0.022044\n",
      "Validating epoch 5210...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013091747820925287\n",
      "Average validation loss: 0.013586859878271412\n",
      "Training epoch 5211...\n",
      "\n",
      "Train Epoch: 5211 [0/8000 (0%)]\tBatch Loss: 0.012997\tLearning Rate (w_theta): 0.001000\t TIME:750.2s\n",
      "\t\t\t\tDisc: 0.012073\t\tSym: 0.000000\t\tSpars: 0.000924\n",
      "\t TVw: 0.876525 | TVb: 2.178915 | GSw: -0.669466 | GSb: -0.371525 | TSUw: -0.384395 | TSUb: -0.022142\n",
      "\n",
      "Train Epoch: 5211 [4000/8000 (50%)]\tBatch Loss: 0.013053\tLearning Rate (w_theta): 0.001000\t TIME:751.5s\n",
      "\t\t\t\tDisc: 0.012087\t\tSym: 0.000000\t\tSpars: 0.000966\n",
      "\t TVw: 0.876072 | TVb: 2.179415 | GSw: -0.669351 | GSb: -0.371363 | TSUw: -0.384290 | TSUb: -0.022126\n",
      "Validating epoch 5211...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01308923261365675\n",
      "Average validation loss: 0.013584664197437564\n",
      "Training epoch 5212...\n",
      "\n",
      "Train Epoch: 5212 [0/8000 (0%)]\tBatch Loss: 0.012983\tLearning Rate (w_theta): 0.001000\t TIME:753.7s\n",
      "\t\t\t\tDisc: 0.012043\t\tSym: 0.000000\t\tSpars: 0.000940\n",
      "\t TVw: 0.875537 | TVb: 2.179897 | GSw: -0.669245 | GSb: -0.371212 | TSUw: -0.384345 | TSUb: -0.022198\n",
      "\n",
      "Train Epoch: 5212 [4000/8000 (50%)]\tBatch Loss: 0.012758\tLearning Rate (w_theta): 0.001000\t TIME:755.0s\n",
      "\t\t\t\tDisc: 0.012088\t\tSym: 0.000000\t\tSpars: 0.000670\n",
      "\t TVw: 0.874887 | TVb: 2.180360 | GSw: -0.669147 | GSb: -0.371070 | TSUw: -0.384505 | TSUb: -0.022328\n",
      "Validating epoch 5212...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013087399588639621\n",
      "Average validation loss: 0.013583143937351999\n",
      "Training epoch 5213...\n",
      "\n",
      "Train Epoch: 5213 [0/8000 (0%)]\tBatch Loss: 0.012673\tLearning Rate (w_theta): 0.001000\t TIME:757.2s\n",
      "\t\t\t\tDisc: 0.011811\t\tSym: 0.000000\t\tSpars: 0.000862\n",
      "\t TVw: 0.874421 | TVb: 2.180850 | GSw: -0.669041 | GSb: -0.370919 | TSUw: -0.384549 | TSUb: -0.022393\n",
      "\n",
      "Train Epoch: 5213 [4000/8000 (50%)]\tBatch Loss: 0.013257\tLearning Rate (w_theta): 0.001000\t TIME:758.5s\n",
      "\t\t\t\tDisc: 0.012239\t\tSym: 0.000000\t\tSpars: 0.001018\n",
      "\t TVw: 0.874082 | TVb: 2.181356 | GSw: -0.668932 | GSb: -0.370764 | TSUw: -0.384600 | TSUb: -0.022462\n",
      "Validating epoch 5213...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01308537255136358\n",
      "Average validation loss: 0.013581083960340582\n",
      "Training epoch 5214...\n",
      "\n",
      "Train Epoch: 5214 [0/8000 (0%)]\tBatch Loss: 0.013235\tLearning Rate (w_theta): 0.001000\t TIME:760.7s\n",
      "\t\t\t\tDisc: 0.012361\t\tSym: 0.000000\t\tSpars: 0.000874\n",
      "\t TVw: 0.873561 | TVb: 2.181843 | GSw: -0.668821 | GSb: -0.370609 | TSUw: -0.384579 | TSUb: -0.022490\n",
      "\n",
      "Train Epoch: 5214 [4000/8000 (50%)]\tBatch Loss: 0.013603\tLearning Rate (w_theta): 0.001000\t TIME:762.0s\n",
      "\t\t\t\tDisc: 0.012466\t\tSym: 0.000000\t\tSpars: 0.001137\n",
      "\t TVw: 0.872987 | TVb: 2.182301 | GSw: -0.668705 | GSb: -0.370448 | TSUw: -0.384452 | TSUb: -0.022459\n",
      "Validating epoch 5214...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01308358161614806\n",
      "Average validation loss: 0.013579013186851768\n",
      "Training epoch 5215...\n",
      "\n",
      "Train Epoch: 5215 [0/8000 (0%)]\tBatch Loss: 0.013214\tLearning Rate (w_theta): 0.001000\t TIME:764.1s\n",
      "\t\t\t\tDisc: 0.012187\t\tSym: 0.000000\t\tSpars: 0.001026\n",
      "\t TVw: 0.872630 | TVb: 2.182792 | GSw: -0.668596 | GSb: -0.370293 | TSUw: -0.384490 | TSUb: -0.022520\n",
      "\n",
      "Train Epoch: 5215 [4000/8000 (50%)]\tBatch Loss: 0.013595\tLearning Rate (w_theta): 0.001000\t TIME:765.4s\n",
      "\t\t\t\tDisc: 0.012519\t\tSym: 0.000000\t\tSpars: 0.001076\n",
      "\t TVw: 0.872261 | TVb: 2.183302 | GSw: -0.668507 | GSb: -0.370160 | TSUw: -0.384812 | TSUb: -0.022738\n",
      "Validating epoch 5215...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013081672841388134\n",
      "Average validation loss: 0.013577580559082333\n",
      "Training epoch 5216...\n",
      "\n",
      "Train Epoch: 5216 [0/8000 (0%)]\tBatch Loss: 0.012868\tLearning Rate (w_theta): 0.001000\t TIME:767.6s\n",
      "\t\t\t\tDisc: 0.011988\t\tSym: 0.000000\t\tSpars: 0.000881\n",
      "\t TVw: 0.871620 | TVb: 2.183761 | GSw: -0.668399 | GSb: -0.370006 | TSUw: -0.384830 | TSUb: -0.022787\n",
      "\n",
      "Train Epoch: 5216 [4000/8000 (50%)]\tBatch Loss: 0.012349\tLearning Rate (w_theta): 0.001000\t TIME:768.9s\n",
      "\t\t\t\tDisc: 0.011583\t\tSym: 0.000000\t\tSpars: 0.000766\n",
      "\t TVw: 0.871265 | TVb: 2.184255 | GSw: -0.668293 | GSb: -0.369856 | TSUw: -0.384932 | TSUb: -0.022882\n",
      "Validating epoch 5216...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013079568950864944\n",
      "Average validation loss: 0.013575562689564469\n",
      "Training epoch 5217...\n",
      "\n",
      "Train Epoch: 5217 [0/8000 (0%)]\tBatch Loss: 0.012953\tLearning Rate (w_theta): 0.001000\t TIME:771.1s\n",
      "\t\t\t\tDisc: 0.012190\t\tSym: 0.000000\t\tSpars: 0.000763\n",
      "\t TVw: 0.870824 | TVb: 2.184737 | GSw: -0.668183 | GSb: -0.369700 | TSUw: -0.384943 | TSUb: -0.022927\n",
      "\n",
      "Train Epoch: 5217 [4000/8000 (50%)]\tBatch Loss: 0.012514\tLearning Rate (w_theta): 0.001000\t TIME:772.4s\n",
      "\t\t\t\tDisc: 0.011811\t\tSym: 0.000000\t\tSpars: 0.000703\n",
      "\t TVw: 0.870145 | TVb: 2.185176 | GSw: -0.668063 | GSb: -0.369533 | TSUw: -0.384758 | TSUb: -0.022862\n",
      "Validating epoch 5217...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013077982667068276\n",
      "Average validation loss: 0.013573586055937824\n",
      "Training epoch 5218...\n",
      "\n",
      "Train Epoch: 5218 [0/8000 (0%)]\tBatch Loss: 0.012956\tLearning Rate (w_theta): 0.001000\t TIME:774.7s\n",
      "\t\t\t\tDisc: 0.012213\t\tSym: 0.000000\t\tSpars: 0.000743\n",
      "\t TVw: 0.869530 | TVb: 2.185624 | GSw: -0.667940 | GSb: -0.369364 | TSUw: -0.384562 | TSUb: -0.022790\n",
      "\n",
      "Train Epoch: 5218 [4000/8000 (50%)]\tBatch Loss: 0.013065\tLearning Rate (w_theta): 0.001000\t TIME:776.0s\n",
      "\t\t\t\tDisc: 0.012112\t\tSym: 0.000000\t\tSpars: 0.000953\n",
      "\t TVw: 0.868941 | TVb: 2.186061 | GSw: -0.667825 | GSb: -0.369204 | TSUw: -0.384483 | TSUb: -0.022784\n",
      "Validating epoch 5218...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013076557508444997\n",
      "Average validation loss: 0.013571767418867963\n",
      "Training epoch 5219...\n",
      "\n",
      "Train Epoch: 5219 [0/8000 (0%)]\tBatch Loss: 0.013792\tLearning Rate (w_theta): 0.001000\t TIME:778.1s\n",
      "\t\t\t\tDisc: 0.012649\t\tSym: 0.000000\t\tSpars: 0.001143\n",
      "\t TVw: 0.868676 | TVb: 2.186558 | GSw: -0.667717 | GSb: -0.369049 | TSUw: -0.384539 | TSUb: -0.022853\n",
      "\n",
      "Train Epoch: 5219 [4000/8000 (50%)]\tBatch Loss: 0.013395\tLearning Rate (w_theta): 0.001000\t TIME:779.4s\n",
      "\t\t\t\tDisc: 0.012428\t\tSym: 0.000000\t\tSpars: 0.000967\n",
      "\t TVw: 0.868370 | TVb: 2.187049 | GSw: -0.667604 | GSb: -0.368889 | TSUw: -0.384535 | TSUb: -0.022889\n",
      "Validating epoch 5219...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013074406546713569\n",
      "Average validation loss: 0.013569806055114257\n",
      "Training epoch 5220...\n",
      "\n",
      "Train Epoch: 5220 [0/8000 (0%)]\tBatch Loss: 0.012731\tLearning Rate (w_theta): 0.001000\t TIME:781.6s\n",
      "\t\t\t\tDisc: 0.011847\t\tSym: 0.000000\t\tSpars: 0.000884\n",
      "\t TVw: 0.867927 | TVb: 2.187535 | GSw: -0.667511 | GSb: -0.368751 | TSUw: -0.384805 | TSUb: -0.023076\n",
      "\n",
      "Train Epoch: 5220 [4000/8000 (50%)]\tBatch Loss: 0.013461\tLearning Rate (w_theta): 0.001000\t TIME:782.9s\n",
      "\t\t\t\tDisc: 0.012616\t\tSym: 0.000000\t\tSpars: 0.000846\n",
      "\t TVw: 0.867127 | TVb: 2.187961 | GSw: -0.667403 | GSb: -0.368598 | TSUw: -0.384841 | TSUb: -0.023133\n",
      "Validating epoch 5220...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013072495396615971\n",
      "Average validation loss: 0.013568395032783901\n",
      "Training epoch 5221...\n",
      "\n",
      "Train Epoch: 5221 [0/8000 (0%)]\tBatch Loss: 0.013668\tLearning Rate (w_theta): 0.001000\t TIME:785.8s\n",
      "\t\t\t\tDisc: 0.012634\t\tSym: 0.000000\t\tSpars: 0.001034\n",
      "\t TVw: 0.866896 | TVb: 2.188480 | GSw: -0.667305 | GSb: -0.368456 | TSUw: -0.385070 | TSUb: -0.023297\n",
      "\n",
      "Train Epoch: 5221 [4000/8000 (50%)]\tBatch Loss: 0.013024\tLearning Rate (w_theta): 0.001000\t TIME:787.0s\n",
      "\t\t\t\tDisc: 0.012098\t\tSym: 0.000000\t\tSpars: 0.000926\n",
      "\t TVw: 0.866754 | TVb: 2.189007 | GSw: -0.667222 | GSb: -0.368327 | TSUw: -0.385542 | TSUb: -0.023596\n",
      "Validating epoch 5221...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013070352821615774\n",
      "Average validation loss: 0.013566774334519478\n",
      "Training epoch 5222...\n",
      "\n",
      "Train Epoch: 5222 [0/8000 (0%)]\tBatch Loss: 0.013142\tLearning Rate (w_theta): 0.001000\t TIME:789.2s\n",
      "\t\t\t\tDisc: 0.012163\t\tSym: 0.000000\t\tSpars: 0.000979\n",
      "\t TVw: 0.866420 | TVb: 2.189486 | GSw: -0.667113 | GSb: -0.368172 | TSUw: -0.385588 | TSUb: -0.023657\n",
      "\n",
      "Train Epoch: 5222 [4000/8000 (50%)]\tBatch Loss: 0.013252\tLearning Rate (w_theta): 0.001000\t TIME:790.5s\n",
      "\t\t\t\tDisc: 0.012110\t\tSym: 0.000000\t\tSpars: 0.001142\n",
      "\t TVw: 0.865878 | TVb: 2.189942 | GSw: -0.667012 | GSb: -0.368027 | TSUw: -0.385752 | TSUb: -0.023783\n",
      "Validating epoch 5222...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013067929340115204\n",
      "Average validation loss: 0.013565087997155886\n",
      "Training epoch 5223...\n",
      "\n",
      "Train Epoch: 5223 [0/8000 (0%)]\tBatch Loss: 0.013242\tLearning Rate (w_theta): 0.001000\t TIME:792.8s\n",
      "\t\t\t\tDisc: 0.011956\t\tSym: 0.000000\t\tSpars: 0.001286\n",
      "\t TVw: 0.865597 | TVb: 2.190427 | GSw: -0.666899 | GSb: -0.367868 | TSUw: -0.385746 | TSUb: -0.023814\n",
      "\n",
      "Train Epoch: 5223 [4000/8000 (50%)]\tBatch Loss: 0.012338\tLearning Rate (w_theta): 0.001000\t TIME:794.0s\n",
      "\t\t\t\tDisc: 0.011737\t\tSym: 0.000000\t\tSpars: 0.000602\n",
      "\t TVw: 0.865457 | TVb: 2.190928 | GSw: -0.666776 | GSb: -0.367698 | TSUw: -0.385618 | TSUb: -0.023778\n",
      "Validating epoch 5223...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013066015014238385\n",
      "Average validation loss: 0.01356248303903895\n",
      "Training epoch 5224...\n",
      "\n",
      "Train Epoch: 5224 [0/8000 (0%)]\tBatch Loss: 0.012982\tLearning Rate (w_theta): 0.001000\t TIME:796.2s\n",
      "\t\t\t\tDisc: 0.012012\t\tSym: 0.000000\t\tSpars: 0.000970\n",
      "\t TVw: 0.864906 | TVb: 2.191370 | GSw: -0.666652 | GSb: -0.367527 | TSUw: -0.385413 | TSUb: -0.023696\n",
      "\n",
      "Train Epoch: 5224 [4000/8000 (50%)]\tBatch Loss: 0.013404\tLearning Rate (w_theta): 0.001000\t TIME:797.5s\n",
      "\t\t\t\tDisc: 0.012453\t\tSym: 0.000000\t\tSpars: 0.000951\n",
      "\t TVw: 0.864467 | TVb: 2.191858 | GSw: -0.666544 | GSb: -0.367374 | TSUw: -0.385483 | TSUb: -0.023769\n",
      "Validating epoch 5224...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013063911945702474\n",
      "Average validation loss: 0.013560670155211065\n",
      "Training epoch 5225...\n",
      "\n",
      "Train Epoch: 5225 [0/8000 (0%)]\tBatch Loss: 0.013009\tLearning Rate (w_theta): 0.001000\t TIME:799.7s\n",
      "\t\t\t\tDisc: 0.011879\t\tSym: 0.000000\t\tSpars: 0.001130\n",
      "\t TVw: 0.864099 | TVb: 2.192336 | GSw: -0.666432 | GSb: -0.367216 | TSUw: -0.385490 | TSUb: -0.023806\n",
      "\n",
      "Train Epoch: 5225 [4000/8000 (50%)]\tBatch Loss: 0.013140\tLearning Rate (w_theta): 0.001000\t TIME:800.9s\n",
      "\t\t\t\tDisc: 0.012340\t\tSym: 0.000000\t\tSpars: 0.000800\n",
      "\t TVw: 0.863581 | TVb: 2.192800 | GSw: -0.666319 | GSb: -0.367058 | TSUw: -0.385422 | TSUb: -0.023801\n",
      "Validating epoch 5225...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013062082697946087\n",
      "Average validation loss: 0.013558755664632332\n",
      "Training epoch 5226...\n",
      "\n",
      "Train Epoch: 5226 [0/8000 (0%)]\tBatch Loss: 0.013148\tLearning Rate (w_theta): 0.001000\t TIME:803.2s\n",
      "\t\t\t\tDisc: 0.012192\t\tSym: 0.000000\t\tSpars: 0.000956\n",
      "\t TVw: 0.863035 | TVb: 2.193242 | GSw: -0.666202 | GSb: -0.366895 | TSUw: -0.385343 | TSUb: -0.023790\n",
      "\n",
      "Train Epoch: 5226 [4000/8000 (50%)]\tBatch Loss: 0.013604\tLearning Rate (w_theta): 0.001000\t TIME:804.4s\n",
      "\t\t\t\tDisc: 0.012569\t\tSym: 0.000000\t\tSpars: 0.001035\n",
      "\t TVw: 0.862613 | TVb: 2.193704 | GSw: -0.666095 | GSb: -0.366741 | TSUw: -0.385407 | TSUb: -0.023859\n",
      "Validating epoch 5226...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013060449835581986\n",
      "Average validation loss: 0.013556937244386497\n",
      "Training epoch 5227...\n",
      "\n",
      "Train Epoch: 5227 [0/8000 (0%)]\tBatch Loss: 0.012885\tLearning Rate (w_theta): 0.001000\t TIME:806.8s\n",
      "\t\t\t\tDisc: 0.011990\t\tSym: 0.000000\t\tSpars: 0.000895\n",
      "\t TVw: 0.862253 | TVb: 2.194178 | GSw: -0.665986 | GSb: -0.366586 | TSUw: -0.385486 | TSUb: -0.023936\n",
      "\n",
      "Train Epoch: 5227 [4000/8000 (50%)]\tBatch Loss: 0.013146\tLearning Rate (w_theta): 0.001000\t TIME:808.1s\n",
      "\t\t\t\tDisc: 0.012413\t\tSym: 0.000000\t\tSpars: 0.000733\n",
      "\t TVw: 0.861593 | TVb: 2.194555 | GSw: -0.665867 | GSb: -0.366418 | TSUw: -0.385367 | TSUb: -0.023902\n",
      "Validating epoch 5227...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013058686449621564\n",
      "Average validation loss: 0.013555323872860509\n",
      "Training epoch 5228...\n",
      "\n",
      "Train Epoch: 5228 [0/8000 (0%)]\tBatch Loss: 0.012917\tLearning Rate (w_theta): 0.001000\t TIME:810.2s\n",
      "\t\t\t\tDisc: 0.012161\t\tSym: 0.000000\t\tSpars: 0.000756\n",
      "\t TVw: 0.861256 | TVb: 2.195006 | GSw: -0.665763 | GSb: -0.366268 | TSUw: -0.385561 | TSUb: -0.024043\n",
      "\n",
      "Train Epoch: 5228 [4000/8000 (50%)]\tBatch Loss: 0.013581\tLearning Rate (w_theta): 0.001000\t TIME:811.5s\n",
      "\t\t\t\tDisc: 0.012607\t\tSym: 0.000000\t\tSpars: 0.000975\n",
      "\t TVw: 0.860608 | TVb: 2.195446 | GSw: -0.665654 | GSb: -0.366112 | TSUw: -0.385647 | TSUb: -0.024123\n",
      "Validating epoch 5228...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013057039782051394\n",
      "Average validation loss: 0.013553915210508874\n",
      "Training epoch 5229...\n",
      "\n",
      "Train Epoch: 5229 [0/8000 (0%)]\tBatch Loss: 0.012880\tLearning Rate (w_theta): 0.001000\t TIME:813.7s\n",
      "\t\t\t\tDisc: 0.012181\t\tSym: 0.000000\t\tSpars: 0.000699\n",
      "\t TVw: 0.860358 | TVb: 2.195936 | GSw: -0.665548 | GSb: -0.365960 | TSUw: -0.385772 | TSUb: -0.024225\n",
      "\n",
      "Train Epoch: 5229 [4000/8000 (50%)]\tBatch Loss: 0.013018\tLearning Rate (w_theta): 0.001000\t TIME:815.0s\n",
      "\t\t\t\tDisc: 0.012093\t\tSym: 0.000000\t\tSpars: 0.000925\n",
      "\t TVw: 0.859921 | TVb: 2.196390 | GSw: -0.665436 | GSb: -0.365802 | TSUw: -0.385740 | TSUb: -0.024238\n",
      "Validating epoch 5229...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013055188910828758\n",
      "Average validation loss: 0.013552134314514686\n",
      "Training epoch 5230...\n",
      "\n",
      "Train Epoch: 5230 [0/8000 (0%)]\tBatch Loss: 0.012922\tLearning Rate (w_theta): 0.001000\t TIME:817.1s\n",
      "\t\t\t\tDisc: 0.011940\t\tSym: 0.000000\t\tSpars: 0.000981\n",
      "\t TVw: 0.859609 | TVb: 2.196869 | GSw: -0.665340 | GSb: -0.365660 | TSUw: -0.386021 | TSUb: -0.024427\n",
      "\n",
      "Train Epoch: 5230 [4000/8000 (50%)]\tBatch Loss: 0.013399\tLearning Rate (w_theta): 0.001000\t TIME:818.4s\n",
      "\t\t\t\tDisc: 0.012249\t\tSym: 0.000000\t\tSpars: 0.001149\n",
      "\t TVw: 0.859443 | TVb: 2.197360 | GSw: -0.665237 | GSb: -0.365512 | TSUw: -0.386213 | TSUb: -0.024565\n",
      "Validating epoch 5230...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013052823595821344\n",
      "Average validation loss: 0.01355026597721058\n",
      "Training epoch 5231...\n",
      "\n",
      "Train Epoch: 5231 [0/8000 (0%)]\tBatch Loss: 0.013007\tLearning Rate (w_theta): 0.001000\t TIME:821.3s\n",
      "\t\t\t\tDisc: 0.012145\t\tSym: 0.000000\t\tSpars: 0.000862\n",
      "\t TVw: 0.859141 | TVb: 2.197811 | GSw: -0.665123 | GSb: -0.365351 | TSUw: -0.386244 | TSUb: -0.024613\n",
      "\n",
      "Train Epoch: 5231 [4000/8000 (50%)]\tBatch Loss: 0.012635\tLearning Rate (w_theta): 0.001000\t TIME:822.6s\n",
      "\t\t\t\tDisc: 0.011828\t\tSym: 0.000000\t\tSpars: 0.000807\n",
      "\t TVw: 0.858796 | TVb: 2.198240 | GSw: -0.665008 | GSb: -0.365188 | TSUw: -0.386229 | TSUb: -0.024635\n",
      "Validating epoch 5231...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01305070667423678\n",
      "Average validation loss: 0.013548448483554208\n",
      "Training epoch 5232...\n",
      "\n",
      "Train Epoch: 5232 [0/8000 (0%)]\tBatch Loss: 0.013017\tLearning Rate (w_theta): 0.001000\t TIME:824.9s\n",
      "\t\t\t\tDisc: 0.012190\t\tSym: 0.000000\t\tSpars: 0.000827\n",
      "\t TVw: 0.858331 | TVb: 2.198672 | GSw: -0.664891 | GSb: -0.365024 | TSUw: -0.386201 | TSUb: -0.024648\n",
      "\n",
      "Train Epoch: 5232 [4000/8000 (50%)]\tBatch Loss: 0.012663\tLearning Rate (w_theta): 0.001000\t TIME:826.2s\n",
      "\t\t\t\tDisc: 0.011647\t\tSym: 0.000000\t\tSpars: 0.001016\n",
      "\t TVw: 0.857604 | TVb: 2.199088 | GSw: -0.664781 | GSb: -0.364867 | TSUw: -0.386243 | TSUb: -0.024700\n",
      "Validating epoch 5232...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013049298611631406\n",
      "Average validation loss: 0.013547198806766731\n",
      "Training epoch 5233...\n",
      "\n",
      "Train Epoch: 5233 [0/8000 (0%)]\tBatch Loss: 0.012718\tLearning Rate (w_theta): 0.001000\t TIME:828.4s\n",
      "\t\t\t\tDisc: 0.011804\t\tSym: 0.000000\t\tSpars: 0.000914\n",
      "\t TVw: 0.857126 | TVb: 2.199514 | GSw: -0.664671 | GSb: -0.364711 | TSUw: -0.386321 | TSUb: -0.024772\n",
      "\n",
      "Train Epoch: 5233 [4000/8000 (50%)]\tBatch Loss: 0.013267\tLearning Rate (w_theta): 0.001000\t TIME:829.6s\n",
      "\t\t\t\tDisc: 0.012372\t\tSym: 0.000000\t\tSpars: 0.000896\n",
      "\t TVw: 0.857046 | TVb: 2.200001 | GSw: -0.664561 | GSb: -0.364555 | TSUw: -0.386443 | TSUb: -0.024869\n",
      "Validating epoch 5233...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013047511585424318\n",
      "Average validation loss: 0.013545190397899283\n",
      "Training epoch 5234...\n",
      "\n",
      "Train Epoch: 5234 [0/8000 (0%)]\tBatch Loss: 0.013768\tLearning Rate (w_theta): 0.001000\t TIME:831.9s\n",
      "\t\t\t\tDisc: 0.012593\t\tSym: 0.000000\t\tSpars: 0.001174\n",
      "\t TVw: 0.856734 | TVb: 2.200440 | GSw: -0.664445 | GSb: -0.364392 | TSUw: -0.386435 | TSUb: -0.024894\n",
      "\n",
      "Train Epoch: 5234 [4000/8000 (50%)]\tBatch Loss: 0.013193\tLearning Rate (w_theta): 0.001000\t TIME:833.1s\n",
      "\t\t\t\tDisc: 0.012059\t\tSym: 0.000000\t\tSpars: 0.001134\n",
      "\t TVw: 0.856845 | TVb: 2.200945 | GSw: -0.664336 | GSb: -0.364235 | TSUw: -0.386554 | TSUb: -0.024989\n",
      "Validating epoch 5234...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013045189527102737\n",
      "Average validation loss: 0.013542991934266247\n",
      "Training epoch 5235...\n",
      "\n",
      "Train Epoch: 5235 [0/8000 (0%)]\tBatch Loss: 0.013299\tLearning Rate (w_theta): 0.001000\t TIME:835.3s\n",
      "\t\t\t\tDisc: 0.012392\t\tSym: 0.000000\t\tSpars: 0.000907\n",
      "\t TVw: 0.856366 | TVb: 2.201370 | GSw: -0.664219 | GSb: -0.364071 | TSUw: -0.386504 | TSUb: -0.024989\n",
      "\n",
      "Train Epoch: 5235 [4000/8000 (50%)]\tBatch Loss: 0.012585\tLearning Rate (w_theta): 0.001000\t TIME:836.6s\n",
      "\t\t\t\tDisc: 0.011735\t\tSym: 0.000000\t\tSpars: 0.000850\n",
      "\t TVw: 0.856104 | TVb: 2.201844 | GSw: -0.664107 | GSb: -0.363912 | TSUw: -0.386562 | TSUb: -0.025049\n",
      "Validating epoch 5235...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013043132431605268\n",
      "Average validation loss: 0.013541133463623435\n",
      "Training epoch 5236...\n",
      "\n",
      "Train Epoch: 5236 [0/8000 (0%)]\tBatch Loss: 0.012603\tLearning Rate (w_theta): 0.001000\t TIME:838.9s\n",
      "\t\t\t\tDisc: 0.011785\t\tSym: 0.000000\t\tSpars: 0.000818\n",
      "\t TVw: 0.855577 | TVb: 2.202251 | GSw: -0.663996 | GSb: -0.363754 | TSUw: -0.386611 | TSUb: -0.025103\n",
      "\n",
      "Train Epoch: 5236 [4000/8000 (50%)]\tBatch Loss: 0.013234\tLearning Rate (w_theta): 0.001000\t TIME:840.2s\n",
      "\t\t\t\tDisc: 0.012446\t\tSym: 0.000000\t\tSpars: 0.000788\n",
      "\t TVw: 0.855038 | TVb: 2.202671 | GSw: -0.663885 | GSb: -0.363596 | TSUw: -0.386656 | TSUb: -0.025154\n",
      "Validating epoch 5236...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013041552918746303\n",
      "Average validation loss: 0.013539677467145229\n",
      "Training epoch 5237...\n",
      "\n",
      "Train Epoch: 5237 [0/8000 (0%)]\tBatch Loss: 0.013864\tLearning Rate (w_theta): 0.001000\t TIME:842.4s\n",
      "\t\t\t\tDisc: 0.012372\t\tSym: 0.000000\t\tSpars: 0.001492\n",
      "\t TVw: 0.854721 | TVb: 2.203102 | GSw: -0.663771 | GSb: -0.363435 | TSUw: -0.386697 | TSUb: -0.025204\n",
      "\n",
      "Train Epoch: 5237 [4000/8000 (50%)]\tBatch Loss: 0.012654\tLearning Rate (w_theta): 0.001000\t TIME:843.7s\n",
      "\t\t\t\tDisc: 0.011861\t\tSym: 0.000000\t\tSpars: 0.000793\n",
      "\t TVw: 0.854446 | TVb: 2.203559 | GSw: -0.663670 | GSb: -0.363287 | TSUw: -0.386953 | TSUb: -0.025374\n",
      "Validating epoch 5237...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013039861799909779\n",
      "Average validation loss: 0.013538140937210008\n",
      "Training epoch 5238...\n",
      "\n",
      "Train Epoch: 5238 [0/8000 (0%)]\tBatch Loss: 0.012849\tLearning Rate (w_theta): 0.001000\t TIME:846.0s\n",
      "\t\t\t\tDisc: 0.012124\t\tSym: 0.000000\t\tSpars: 0.000725\n",
      "\t TVw: 0.853803 | TVb: 2.203938 | GSw: -0.663545 | GSb: -0.363114 | TSUw: -0.386777 | TSUb: -0.025301\n",
      "\n",
      "Train Epoch: 5238 [4000/8000 (50%)]\tBatch Loss: 0.013261\tLearning Rate (w_theta): 0.001000\t TIME:847.3s\n",
      "\t\t\t\tDisc: 0.012248\t\tSym: 0.000000\t\tSpars: 0.001012\n",
      "\t TVw: 0.853114 | TVb: 2.204326 | GSw: -0.663426 | GSb: -0.362947 | TSUw: -0.386661 | TSUb: -0.025260\n",
      "Validating epoch 5238...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013038585078590074\n",
      "Average validation loss: 0.01353655118857601\n",
      "Training epoch 5239...\n",
      "\n",
      "Train Epoch: 5239 [0/8000 (0%)]\tBatch Loss: 0.012711\tLearning Rate (w_theta): 0.001000\t TIME:849.4s\n",
      "\t\t\t\tDisc: 0.011841\t\tSym: 0.000000\t\tSpars: 0.000869\n",
      "\t TVw: 0.852683 | TVb: 2.204723 | GSw: -0.663310 | GSb: -0.362783 | TSUw: -0.386669 | TSUb: -0.025290\n",
      "\n",
      "Train Epoch: 5239 [4000/8000 (50%)]\tBatch Loss: 0.012701\tLearning Rate (w_theta): 0.001000\t TIME:850.7s\n",
      "\t\t\t\tDisc: 0.012013\t\tSym: 0.000000\t\tSpars: 0.000687\n",
      "\t TVw: 0.852334 | TVb: 2.205126 | GSw: -0.663207 | GSb: -0.362634 | TSUw: -0.386904 | TSUb: -0.025447\n",
      "Validating epoch 5239...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013037235185986418\n",
      "Average validation loss: 0.013535273381416687\n",
      "Training epoch 5240...\n",
      "\n",
      "Train Epoch: 5240 [0/8000 (0%)]\tBatch Loss: 0.013176\tLearning Rate (w_theta): 0.001000\t TIME:853.0s\n",
      "\t\t\t\tDisc: 0.012567\t\tSym: 0.000000\t\tSpars: 0.000609\n",
      "\t TVw: 0.851812 | TVb: 2.205531 | GSw: -0.663089 | GSb: -0.362470 | TSUw: -0.386870 | TSUb: -0.025453\n",
      "\n",
      "Train Epoch: 5240 [4000/8000 (50%)]\tBatch Loss: 0.012991\tLearning Rate (w_theta): 0.001000\t TIME:854.3s\n",
      "\t\t\t\tDisc: 0.012304\t\tSym: 0.000000\t\tSpars: 0.000687\n",
      "\t TVw: 0.851230 | TVb: 2.205934 | GSw: -0.662975 | GSb: -0.362306 | TSUw: -0.386856 | TSUb: -0.025469\n",
      "Validating epoch 5240...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013035735064954694\n",
      "Average validation loss: 0.013533729470761114\n",
      "Training epoch 5241...\n",
      "\n",
      "Train Epoch: 5241 [0/8000 (0%)]\tBatch Loss: 0.012836\tLearning Rate (w_theta): 0.001000\t TIME:857.3s\n",
      "\t\t\t\tDisc: 0.012030\t\tSym: 0.000000\t\tSpars: 0.000806\n",
      "\t TVw: 0.850847 | TVb: 2.206365 | GSw: -0.662870 | GSb: -0.362155 | TSUw: -0.387040 | TSUb: -0.025597\n",
      "\n",
      "Train Epoch: 5241 [4000/8000 (50%)]\tBatch Loss: 0.013495\tLearning Rate (w_theta): 0.001000\t TIME:858.6s\n",
      "\t\t\t\tDisc: 0.012520\t\tSym: 0.000000\t\tSpars: 0.000974\n",
      "\t TVw: 0.850352 | TVb: 2.206741 | GSw: -0.662747 | GSb: -0.361985 | TSUw: -0.386931 | TSUb: -0.025560\n",
      "Validating epoch 5241...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013034222732876556\n",
      "Average validation loss: 0.013532144446519363\n",
      "Training epoch 5242...\n",
      "\n",
      "Train Epoch: 5242 [0/8000 (0%)]\tBatch Loss: 0.013299\tLearning Rate (w_theta): 0.001000\t TIME:860.9s\n",
      "\t\t\t\tDisc: 0.012365\t\tSym: 0.000000\t\tSpars: 0.000935\n",
      "\t TVw: 0.850005 | TVb: 2.207156 | GSw: -0.662629 | GSb: -0.361820 | TSUw: -0.386912 | TSUb: -0.025574\n",
      "\n",
      "Train Epoch: 5242 [4000/8000 (50%)]\tBatch Loss: 0.012931\tLearning Rate (w_theta): 0.001000\t TIME:862.2s\n",
      "\t\t\t\tDisc: 0.012011\t\tSym: 0.000000\t\tSpars: 0.000920\n",
      "\t TVw: 0.849257 | TVb: 2.207546 | GSw: -0.662513 | GSb: -0.361656 | TSUw: -0.386860 | TSUb: -0.025567\n",
      "Validating epoch 5242...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013033013425956138\n",
      "Average validation loss: 0.013530600020106661\n",
      "Training epoch 5243...\n",
      "\n",
      "Train Epoch: 5243 [0/8000 (0%)]\tBatch Loss: 0.012793\tLearning Rate (w_theta): 0.001000\t TIME:864.4s\n",
      "\t\t\t\tDisc: 0.012036\t\tSym: 0.000000\t\tSpars: 0.000757\n",
      "\t TVw: 0.848861 | TVb: 2.207961 | GSw: -0.662395 | GSb: -0.361489 | TSUw: -0.386851 | TSUb: -0.025586\n",
      "\n",
      "Train Epoch: 5243 [4000/8000 (50%)]\tBatch Loss: 0.013209\tLearning Rate (w_theta): 0.001000\t TIME:865.7s\n",
      "\t\t\t\tDisc: 0.012451\t\tSym: 0.000000\t\tSpars: 0.000758\n",
      "\t TVw: 0.848534 | TVb: 2.208349 | GSw: -0.662281 | GSb: -0.361329 | TSUw: -0.386941 | TSUb: -0.025661\n",
      "Validating epoch 5243...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013031452941585326\n",
      "Average validation loss: 0.013529145733435595\n",
      "Training epoch 5244...\n",
      "\n",
      "Train Epoch: 5244 [0/8000 (0%)]\tBatch Loss: 0.012648\tLearning Rate (w_theta): 0.001000\t TIME:867.9s\n",
      "\t\t\t\tDisc: 0.011924\t\tSym: 0.000000\t\tSpars: 0.000724\n",
      "\t TVw: 0.848261 | TVb: 2.208783 | GSw: -0.662184 | GSb: -0.361184 | TSUw: -0.387267 | TSUb: -0.025868\n",
      "\n",
      "Train Epoch: 5244 [4000/8000 (50%)]\tBatch Loss: 0.013165\tLearning Rate (w_theta): 0.001000\t TIME:869.2s\n",
      "\t\t\t\tDisc: 0.012039\t\tSym: 0.000000\t\tSpars: 0.001126\n",
      "\t TVw: 0.848076 | TVb: 2.209214 | GSw: -0.662079 | GSb: -0.361031 | TSUw: -0.387490 | TSUb: -0.026017\n",
      "Validating epoch 5244...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01302932899850522\n",
      "Average validation loss: 0.013527872562210578\n",
      "Training epoch 5245...\n",
      "\n",
      "Train Epoch: 5245 [0/8000 (0%)]\tBatch Loss: 0.013164\tLearning Rate (w_theta): 0.001000\t TIME:871.6s\n",
      "\t\t\t\tDisc: 0.012359\t\tSym: 0.000000\t\tSpars: 0.000805\n",
      "\t TVw: 0.847765 | TVb: 2.209639 | GSw: -0.661975 | GSb: -0.360879 | TSUw: -0.387702 | TSUb: -0.026159\n",
      "\n",
      "Train Epoch: 5245 [4000/8000 (50%)]\tBatch Loss: 0.012681\tLearning Rate (w_theta): 0.001000\t TIME:872.8s\n",
      "\t\t\t\tDisc: 0.011859\t\tSym: 0.000000\t\tSpars: 0.000822\n",
      "\t TVw: 0.847310 | TVb: 2.210035 | GSw: -0.661863 | GSb: -0.360720 | TSUw: -0.387780 | TSUb: -0.026224\n",
      "Validating epoch 5245...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013027488181410737\n",
      "Average validation loss: 0.01352643041715467\n",
      "Training epoch 5246...\n",
      "\n",
      "Train Epoch: 5246 [0/8000 (0%)]\tBatch Loss: 0.013502\tLearning Rate (w_theta): 0.001000\t TIME:875.0s\n",
      "\t\t\t\tDisc: 0.012642\t\tSym: 0.000000\t\tSpars: 0.000860\n",
      "\t TVw: 0.846956 | TVb: 2.210450 | GSw: -0.661746 | GSb: -0.360555 | TSUw: -0.387784 | TSUb: -0.026248\n",
      "\n",
      "Train Epoch: 5246 [4000/8000 (50%)]\tBatch Loss: 0.013508\tLearning Rate (w_theta): 0.001000\t TIME:876.3s\n",
      "\t\t\t\tDisc: 0.012438\t\tSym: 0.000000\t\tSpars: 0.001070\n",
      "\t TVw: 0.846582 | TVb: 2.210872 | GSw: -0.661634 | GSb: -0.360393 | TSUw: -0.387866 | TSUb: -0.026315\n",
      "Validating epoch 5246...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01302583937512203\n",
      "Average validation loss: 0.013524685300618997\n",
      "Training epoch 5247...\n",
      "\n",
      "Train Epoch: 5247 [0/8000 (0%)]\tBatch Loss: 0.013173\tLearning Rate (w_theta): 0.001000\t TIME:878.6s\n",
      "\t\t\t\tDisc: 0.012270\t\tSym: 0.000000\t\tSpars: 0.000903\n",
      "\t TVw: 0.846365 | TVb: 2.211298 | GSw: -0.661513 | GSb: -0.360225 | TSUw: -0.387847 | TSUb: -0.026325\n",
      "\n",
      "Train Epoch: 5247 [4000/8000 (50%)]\tBatch Loss: 0.013304\tLearning Rate (w_theta): 0.001000\t TIME:879.9s\n",
      "\t\t\t\tDisc: 0.012319\t\tSym: 0.000000\t\tSpars: 0.000985\n",
      "\t TVw: 0.845905 | TVb: 2.211686 | GSw: -0.661381 | GSb: -0.360045 | TSUw: -0.387598 | TSUb: -0.026204\n",
      "Validating epoch 5247...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013024330956372423\n",
      "Average validation loss: 0.013522607386734428\n",
      "Training epoch 5248...\n",
      "\n",
      "Train Epoch: 5248 [0/8000 (0%)]\tBatch Loss: 0.012319\tLearning Rate (w_theta): 0.001000\t TIME:882.1s\n",
      "\t\t\t\tDisc: 0.011782\t\tSym: 0.000000\t\tSpars: 0.000537\n",
      "\t TVw: 0.845549 | TVb: 2.212078 | GSw: -0.661259 | GSb: -0.359874 | TSUw: -0.387538 | TSUb: -0.026190\n",
      "\n",
      "Train Epoch: 5248 [4000/8000 (50%)]\tBatch Loss: 0.012859\tLearning Rate (w_theta): 0.001000\t TIME:883.4s\n",
      "\t\t\t\tDisc: 0.012118\t\tSym: 0.000000\t\tSpars: 0.000740\n",
      "\t TVw: 0.845417 | TVb: 2.212483 | GSw: -0.661142 | GSb: -0.359709 | TSUw: -0.387597 | TSUb: -0.026244\n",
      "Validating epoch 5248...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013022646062059962\n",
      "Average validation loss: 0.013520854161060048\n",
      "Training epoch 5249...\n",
      "\n",
      "Train Epoch: 5249 [0/8000 (0%)]\tBatch Loss: 0.012697\tLearning Rate (w_theta): 0.001000\t TIME:885.6s\n",
      "\t\t\t\tDisc: 0.011756\t\tSym: 0.000000\t\tSpars: 0.000941\n",
      "\t TVw: 0.845224 | TVb: 2.212914 | GSw: -0.661033 | GSb: -0.359552 | TSUw: -0.387751 | TSUb: -0.026352\n",
      "\n",
      "Train Epoch: 5249 [4000/8000 (50%)]\tBatch Loss: 0.013517\tLearning Rate (w_theta): 0.001000\t TIME:886.9s\n",
      "\t\t\t\tDisc: 0.012241\t\tSym: 0.000000\t\tSpars: 0.001276\n",
      "\t TVw: 0.845252 | TVb: 2.213364 | GSw: -0.660927 | GSb: -0.359399 | TSUw: -0.388007 | TSUb: -0.026517\n",
      "Validating epoch 5249...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013020452672989772\n",
      "Average validation loss: 0.013519345547546486\n",
      "Training epoch 5250...\n",
      "\n",
      "Train Epoch: 5250 [0/8000 (0%)]\tBatch Loss: 0.012912\tLearning Rate (w_theta): 0.001000\t TIME:889.2s\n",
      "\t\t\t\tDisc: 0.012138\t\tSym: 0.000000\t\tSpars: 0.000775\n",
      "\t TVw: 0.844800 | TVb: 2.213757 | GSw: -0.660815 | GSb: -0.359239 | TSUw: -0.388105 | TSUb: -0.026591\n",
      "\n",
      "Train Epoch: 5250 [4000/8000 (50%)]\tBatch Loss: 0.013340\tLearning Rate (w_theta): 0.001000\t TIME:890.4s\n",
      "\t\t\t\tDisc: 0.012369\t\tSym: 0.000000\t\tSpars: 0.000971\n",
      "\t TVw: 0.844389 | TVb: 2.214122 | GSw: -0.660698 | GSb: -0.359073 | TSUw: -0.388161 | TSUb: -0.026642\n",
      "Validating epoch 5250...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013018716833439773\n",
      "Average validation loss: 0.013518063406721927\n",
      "Training epoch 5251...\n",
      "\n",
      "Train Epoch: 5251 [0/8000 (0%)]\tBatch Loss: 0.013337\tLearning Rate (w_theta): 0.001000\t TIME:893.3s\n",
      "\t\t\t\tDisc: 0.012292\t\tSym: 0.000000\t\tSpars: 0.001045\n",
      "\t TVw: 0.843932 | TVb: 2.214517 | GSw: -0.660584 | GSb: -0.358910 | TSUw: -0.388208 | TSUb: -0.026687\n",
      "\n",
      "Train Epoch: 5251 [4000/8000 (50%)]\tBatch Loss: 0.013157\tLearning Rate (w_theta): 0.001000\t TIME:894.5s\n",
      "\t\t\t\tDisc: 0.012475\t\tSym: 0.000000\t\tSpars: 0.000683\n",
      "\t TVw: 0.843579 | TVb: 2.214920 | GSw: -0.660463 | GSb: -0.358739 | TSUw: -0.388155 | TSUb: -0.026676\n",
      "Validating epoch 5251...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013017317356514591\n",
      "Average validation loss: 0.013516399588423548\n",
      "Training epoch 5252...\n",
      "\n",
      "Train Epoch: 5252 [0/8000 (0%)]\tBatch Loss: 0.012838\tLearning Rate (w_theta): 0.001000\t TIME:896.7s\n",
      "\t\t\t\tDisc: 0.012122\t\tSym: 0.000000\t\tSpars: 0.000715\n",
      "\t TVw: 0.843130 | TVb: 2.215283 | GSw: -0.660340 | GSb: -0.358568 | TSUw: -0.388076 | TSUb: -0.026649\n",
      "\n",
      "Train Epoch: 5252 [4000/8000 (50%)]\tBatch Loss: 0.013680\tLearning Rate (w_theta): 0.001000\t TIME:898.0s\n",
      "\t\t\t\tDisc: 0.012758\t\tSym: 0.000000\t\tSpars: 0.000923\n",
      "\t TVw: 0.842575 | TVb: 2.215632 | GSw: -0.660206 | GSb: -0.358385 | TSUw: -0.387799 | TSUb: -0.026509\n",
      "Validating epoch 5252...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013016453726924171\n",
      "Average validation loss: 0.013514652648094918\n",
      "Training epoch 5253...\n",
      "\n",
      "Train Epoch: 5253 [0/8000 (0%)]\tBatch Loss: 0.012847\tLearning Rate (w_theta): 0.001000\t TIME:900.2s\n",
      "\t\t\t\tDisc: 0.011966\t\tSym: 0.000000\t\tSpars: 0.000882\n",
      "\t TVw: 0.842323 | TVb: 2.216039 | GSw: -0.660098 | GSb: -0.358229 | TSUw: -0.387963 | TSUb: -0.026620\n",
      "\n",
      "Train Epoch: 5253 [4000/8000 (50%)]\tBatch Loss: 0.013672\tLearning Rate (w_theta): 0.001000\t TIME:901.4s\n",
      "\t\t\t\tDisc: 0.012689\t\tSym: 0.000000\t\tSpars: 0.000983\n",
      "\t TVw: 0.842014 | TVb: 2.216416 | GSw: -0.659983 | GSb: -0.358065 | TSUw: -0.388008 | TSUb: -0.026664\n",
      "Validating epoch 5253...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013014529088883075\n",
      "Average validation loss: 0.013513293688535937\n",
      "Training epoch 5254...\n",
      "\n",
      "Train Epoch: 5254 [0/8000 (0%)]\tBatch Loss: 0.013394\tLearning Rate (w_theta): 0.001000\t TIME:903.7s\n",
      "\t\t\t\tDisc: 0.012491\t\tSym: 0.000000\t\tSpars: 0.000903\n",
      "\t TVw: 0.841802 | TVb: 2.216849 | GSw: -0.659888 | GSb: -0.357923 | TSUw: -0.388439 | TSUb: -0.026926\n",
      "\n",
      "Train Epoch: 5254 [4000/8000 (50%)]\tBatch Loss: 0.013126\tLearning Rate (w_theta): 0.001000\t TIME:905.0s\n",
      "\t\t\t\tDisc: 0.012149\t\tSym: 0.000000\t\tSpars: 0.000978\n",
      "\t TVw: 0.841488 | TVb: 2.217251 | GSw: -0.659793 | GSb: -0.357780 | TSUw: -0.388877 | TSUb: -0.027192\n",
      "Validating epoch 5254...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013012819100591601\n",
      "Average validation loss: 0.013512619270039094\n",
      "Training epoch 5255...\n",
      "\n",
      "Train Epoch: 5255 [0/8000 (0%)]\tBatch Loss: 0.013183\tLearning Rate (w_theta): 0.001000\t TIME:907.1s\n",
      "\t\t\t\tDisc: 0.012305\t\tSym: 0.000000\t\tSpars: 0.000878\n",
      "\t TVw: 0.841099 | TVb: 2.217654 | GSw: -0.659678 | GSb: -0.357615 | TSUw: -0.388934 | TSUb: -0.027241\n",
      "\n",
      "Train Epoch: 5255 [4000/8000 (50%)]\tBatch Loss: 0.013161\tLearning Rate (w_theta): 0.001000\t TIME:908.4s\n",
      "\t\t\t\tDisc: 0.012235\t\tSym: 0.000000\t\tSpars: 0.000927\n",
      "\t TVw: 0.840521 | TVb: 2.218025 | GSw: -0.659553 | GSb: -0.357441 | TSUw: -0.388803 | TSUb: -0.027181\n",
      "Validating epoch 5255...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013011106221459153\n",
      "Average validation loss: 0.01351102925613417\n",
      "Training epoch 5256...\n",
      "\n",
      "Train Epoch: 5256 [0/8000 (0%)]\tBatch Loss: 0.013108\tLearning Rate (w_theta): 0.001000\t TIME:910.6s\n",
      "\t\t\t\tDisc: 0.012370\t\tSym: 0.000000\t\tSpars: 0.000738\n",
      "\t TVw: 0.840122 | TVb: 2.218399 | GSw: -0.659430 | GSb: -0.357270 | TSUw: -0.388740 | TSUb: -0.027160\n",
      "\n",
      "Train Epoch: 5256 [4000/8000 (50%)]\tBatch Loss: 0.012722\tLearning Rate (w_theta): 0.001000\t TIME:911.9s\n",
      "\t\t\t\tDisc: 0.012019\t\tSym: 0.000000\t\tSpars: 0.000703\n",
      "\t TVw: 0.839622 | TVb: 2.218756 | GSw: -0.659298 | GSb: -0.357087 | TSUw: -0.388545 | TSUb: -0.027064\n",
      "Validating epoch 5256...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013010054052769268\n",
      "Average validation loss: 0.013509193015860935\n",
      "Training epoch 5257...\n",
      "\n",
      "Train Epoch: 5257 [0/8000 (0%)]\tBatch Loss: 0.013385\tLearning Rate (w_theta): 0.001000\t TIME:914.0s\n",
      "\t\t\t\tDisc: 0.012398\t\tSym: 0.000000\t\tSpars: 0.000987\n",
      "\t TVw: 0.839444 | TVb: 2.219159 | GSw: -0.659181 | GSb: -0.356922 | TSUw: -0.388630 | TSUb: -0.027128\n",
      "\n",
      "Train Epoch: 5257 [4000/8000 (50%)]\tBatch Loss: 0.013506\tLearning Rate (w_theta): 0.001000\t TIME:915.3s\n",
      "\t\t\t\tDisc: 0.012287\t\tSym: 0.000000\t\tSpars: 0.001219\n",
      "\t TVw: 0.839231 | TVb: 2.219572 | GSw: -0.659053 | GSb: -0.356746 | TSUw: -0.388532 | TSUb: -0.027087\n",
      "Validating epoch 5257...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013008414978091331\n",
      "Average validation loss: 0.013507320609737793\n",
      "Training epoch 5258...\n",
      "\n",
      "Train Epoch: 5258 [0/8000 (0%)]\tBatch Loss: 0.012462\tLearning Rate (w_theta): 0.001000\t TIME:917.5s\n",
      "\t\t\t\tDisc: 0.011531\t\tSym: 0.000000\t\tSpars: 0.000931\n",
      "\t TVw: 0.838932 | TVb: 2.219948 | GSw: -0.658941 | GSb: -0.356586 | TSUw: -0.388677 | TSUb: -0.027185\n",
      "\n",
      "Train Epoch: 5258 [4000/8000 (50%)]\tBatch Loss: 0.012669\tLearning Rate (w_theta): 0.001000\t TIME:918.8s\n",
      "\t\t\t\tDisc: 0.011748\t\tSym: 0.000000\t\tSpars: 0.000921\n",
      "\t TVw: 0.838747 | TVb: 2.220353 | GSw: -0.658838 | GSb: -0.356436 | TSUw: -0.388971 | TSUb: -0.027368\n",
      "Validating epoch 5258...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013006481454402205\n",
      "Average validation loss: 0.013506174391634925\n",
      "Training epoch 5259...\n",
      "\n",
      "Train Epoch: 5259 [0/8000 (0%)]\tBatch Loss: 0.014113\tLearning Rate (w_theta): 0.001000\t TIME:921.0s\n",
      "\t\t\t\tDisc: 0.012822\t\tSym: 0.000000\t\tSpars: 0.001292\n",
      "\t TVw: 0.838588 | TVb: 2.220754 | GSw: -0.658724 | GSb: -0.356274 | TSUw: -0.389102 | TSUb: -0.027457\n",
      "\n",
      "Train Epoch: 5259 [4000/8000 (50%)]\tBatch Loss: 0.012706\tLearning Rate (w_theta): 0.001000\t TIME:922.2s\n",
      "\t\t\t\tDisc: 0.011892\t\tSym: 0.000000\t\tSpars: 0.000814\n",
      "\t TVw: 0.838790 | TVb: 2.221208 | GSw: -0.658624 | GSb: -0.356124 | TSUw: -0.389444 | TSUb: -0.027667\n",
      "Validating epoch 5259...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013004466400305476\n",
      "Average validation loss: 0.01350439524247358\n",
      "Training epoch 5260...\n",
      "\n",
      "Train Epoch: 5260 [0/8000 (0%)]\tBatch Loss: 0.012743\tLearning Rate (w_theta): 0.001000\t TIME:924.4s\n",
      "\t\t\t\tDisc: 0.011939\t\tSym: 0.000000\t\tSpars: 0.000804\n",
      "\t TVw: 0.838351 | TVb: 2.221555 | GSw: -0.658491 | GSb: -0.355942 | TSUw: -0.389230 | TSUb: -0.027558\n",
      "\n",
      "Train Epoch: 5260 [4000/8000 (50%)]\tBatch Loss: 0.013546\tLearning Rate (w_theta): 0.001000\t TIME:925.7s\n",
      "\t\t\t\tDisc: 0.012521\t\tSym: 0.000000\t\tSpars: 0.001025\n",
      "\t TVw: 0.837939 | TVb: 2.221903 | GSw: -0.658352 | GSb: -0.355751 | TSUw: -0.388925 | TSUb: -0.027397\n",
      "Validating epoch 5260...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01300289353084491\n",
      "Average validation loss: 0.013502447274521264\n",
      "Training epoch 5261...\n",
      "\n",
      "Train Epoch: 5261 [0/8000 (0%)]\tBatch Loss: 0.012636\tLearning Rate (w_theta): 0.001000\t TIME:928.5s\n",
      "\t\t\t\tDisc: 0.012086\t\tSym: 0.000000\t\tSpars: 0.000550\n",
      "\t TVw: 0.837531 | TVb: 2.222268 | GSw: -0.658228 | GSb: -0.355578 | TSUw: -0.388890 | TSUb: -0.027390\n",
      "\n",
      "Train Epoch: 5261 [4000/8000 (50%)]\tBatch Loss: 0.013218\tLearning Rate (w_theta): 0.001000\t TIME:929.8s\n",
      "\t\t\t\tDisc: 0.012063\t\tSym: 0.000000\t\tSpars: 0.001156\n",
      "\t TVw: 0.836867 | TVb: 2.222596 | GSw: -0.658102 | GSb: -0.355403 | TSUw: -0.388758 | TSUb: -0.027326\n",
      "Validating epoch 5261...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013002011340190906\n",
      "Average validation loss: 0.013501201664998613\n",
      "Training epoch 5262...\n",
      "\n",
      "Train Epoch: 5262 [0/8000 (0%)]\tBatch Loss: 0.013552\tLearning Rate (w_theta): 0.001000\t TIME:932.0s\n",
      "\t\t\t\tDisc: 0.012546\t\tSym: 0.000000\t\tSpars: 0.001007\n",
      "\t TVw: 0.836726 | TVb: 2.222995 | GSw: -0.657992 | GSb: -0.355244 | TSUw: -0.388956 | TSUb: -0.027453\n",
      "\n",
      "Train Epoch: 5262 [4000/8000 (50%)]\tBatch Loss: 0.012677\tLearning Rate (w_theta): 0.001000\t TIME:933.2s\n",
      "\t\t\t\tDisc: 0.011885\t\tSym: 0.000000\t\tSpars: 0.000792\n",
      "\t TVw: 0.836991 | TVb: 2.223463 | GSw: -0.657902 | GSb: -0.355108 | TSUw: -0.389535 | TSUb: -0.027798\n",
      "Validating epoch 5262...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.013000074978478616\n",
      "Average validation loss: 0.013500070691908785\n",
      "Training epoch 5263...\n",
      "\n",
      "Train Epoch: 5263 [0/8000 (0%)]\tBatch Loss: 0.012595\tLearning Rate (w_theta): 0.001000\t TIME:935.5s\n",
      "\t\t\t\tDisc: 0.011835\t\tSym: 0.000000\t\tSpars: 0.000760\n",
      "\t TVw: 0.836588 | TVb: 2.223824 | GSw: -0.657791 | GSb: -0.354949 | TSUw: -0.389703 | TSUb: -0.027906\n",
      "\n",
      "Train Epoch: 5263 [4000/8000 (50%)]\tBatch Loss: 0.013906\tLearning Rate (w_theta): 0.001000\t TIME:936.8s\n",
      "\t\t\t\tDisc: 0.012769\t\tSym: 0.000000\t\tSpars: 0.001137\n",
      "\t TVw: 0.835990 | TVb: 2.224143 | GSw: -0.657658 | GSb: -0.354767 | TSUw: -0.389488 | TSUb: -0.027794\n",
      "Validating epoch 5263...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012998222806162257\n",
      "Average validation loss: 0.013498424714467869\n",
      "Training epoch 5264...\n",
      "\n",
      "Train Epoch: 5264 [0/8000 (0%)]\tBatch Loss: 0.012774\tLearning Rate (w_theta): 0.001000\t TIME:938.9s\n",
      "\t\t\t\tDisc: 0.012040\t\tSym: 0.000000\t\tSpars: 0.000734\n",
      "\t TVw: 0.835592 | TVb: 2.224513 | GSw: -0.657532 | GSb: -0.354590 | TSUw: -0.389388 | TSUb: -0.027748\n",
      "\n",
      "Train Epoch: 5264 [4000/8000 (50%)]\tBatch Loss: 0.012759\tLearning Rate (w_theta): 0.001000\t TIME:940.2s\n",
      "\t\t\t\tDisc: 0.012149\t\tSym: 0.000000\t\tSpars: 0.000610\n",
      "\t TVw: 0.835614 | TVb: 2.224942 | GSw: -0.657441 | GSb: -0.354453 | TSUw: -0.389988 | TSUb: -0.028103\n",
      "Validating epoch 5264...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012997113541739167\n",
      "Average validation loss: 0.013497331498095896\n",
      "Training epoch 5265...\n",
      "\n",
      "Train Epoch: 5265 [0/8000 (0%)]\tBatch Loss: 0.014095\tLearning Rate (w_theta): 0.001000\t TIME:942.4s\n",
      "\t\t\t\tDisc: 0.012859\t\tSym: 0.000000\t\tSpars: 0.001237\n",
      "\t TVw: 0.835309 | TVb: 2.225298 | GSw: -0.657310 | GSb: -0.354270 | TSUw: -0.389832 | TSUb: -0.028024\n",
      "\n",
      "Train Epoch: 5265 [4000/8000 (50%)]\tBatch Loss: 0.012924\tLearning Rate (w_theta): 0.001000\t TIME:943.6s\n",
      "\t\t\t\tDisc: 0.012209\t\tSym: 0.000000\t\tSpars: 0.000715\n",
      "\t TVw: 0.835332 | TVb: 2.225731 | GSw: -0.657203 | GSb: -0.354113 | TSUw: -0.390100 | TSUb: -0.028189\n",
      "Validating epoch 5265...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012994781798103606\n",
      "Average validation loss: 0.013495643030532046\n",
      "Training epoch 5266...\n",
      "\n",
      "Train Epoch: 5266 [0/8000 (0%)]\tBatch Loss: 0.012440\tLearning Rate (w_theta): 0.001000\t TIME:945.8s\n",
      "\t\t\t\tDisc: 0.011635\t\tSym: 0.000000\t\tSpars: 0.000805\n",
      "\t TVw: 0.834741 | TVb: 2.226053 | GSw: -0.657069 | GSb: -0.353930 | TSUw: -0.389878 | TSUb: -0.028070\n",
      "\n",
      "Train Epoch: 5266 [4000/8000 (50%)]\tBatch Loss: 0.013319\tLearning Rate (w_theta): 0.001000\t TIME:947.1s\n",
      "\t\t\t\tDisc: 0.012510\t\tSym: 0.000000\t\tSpars: 0.000808\n",
      "\t TVw: 0.834001 | TVb: 2.226342 | GSw: -0.656933 | GSb: -0.353745 | TSUw: -0.389622 | TSUb: -0.027932\n",
      "Validating epoch 5266...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012993756754400523\n",
      "Average validation loss: 0.01349412066252597\n",
      "Training epoch 5267...\n",
      "\n",
      "Train Epoch: 5267 [0/8000 (0%)]\tBatch Loss: 0.012606\tLearning Rate (w_theta): 0.001000\t TIME:949.3s\n",
      "\t\t\t\tDisc: 0.011866\t\tSym: 0.000000\t\tSpars: 0.000740\n",
      "\t TVw: 0.833734 | TVb: 2.226703 | GSw: -0.656806 | GSb: -0.353568 | TSUw: -0.389543 | TSUb: -0.027896\n",
      "\n",
      "Train Epoch: 5267 [4000/8000 (50%)]\tBatch Loss: 0.012442\tLearning Rate (w_theta): 0.001000\t TIME:950.6s\n",
      "\t\t\t\tDisc: 0.011642\t\tSym: 0.000000\t\tSpars: 0.000799\n",
      "\t TVw: 0.833520 | TVb: 2.227048 | GSw: -0.656697 | GSb: -0.353411 | TSUw: -0.389770 | TSUb: -0.028037\n",
      "Validating epoch 5267...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012992588782994599\n",
      "Average validation loss: 0.013492788928048201\n",
      "Training epoch 5268...\n",
      "\n",
      "Train Epoch: 5268 [0/8000 (0%)]\tBatch Loss: 0.013362\tLearning Rate (w_theta): 0.001000\t TIME:952.8s\n",
      "\t\t\t\tDisc: 0.012562\t\tSym: 0.000000\t\tSpars: 0.000800\n",
      "\t TVw: 0.833145 | TVb: 2.227400 | GSw: -0.656569 | GSb: -0.353231 | TSUw: -0.389660 | TSUb: -0.027983\n",
      "\n",
      "Train Epoch: 5268 [4000/8000 (50%)]\tBatch Loss: 0.013370\tLearning Rate (w_theta): 0.001000\t TIME:954.0s\n",
      "\t\t\t\tDisc: 0.012661\t\tSym: 0.000000\t\tSpars: 0.000709\n",
      "\t TVw: 0.833122 | TVb: 2.227773 | GSw: -0.656451 | GSb: -0.353063 | TSUw: -0.389784 | TSUb: -0.028065\n",
      "Validating epoch 5268...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012990981413450084\n",
      "Average validation loss: 0.013491167716547884\n",
      "Training epoch 5269...\n",
      "\n",
      "Train Epoch: 5269 [0/8000 (0%)]\tBatch Loss: 0.012645\tLearning Rate (w_theta): 0.001000\t TIME:956.3s\n",
      "\t\t\t\tDisc: 0.012163\t\tSym: 0.000000\t\tSpars: 0.000482\n",
      "\t TVw: 0.832654 | TVb: 2.228127 | GSw: -0.656325 | GSb: -0.352887 | TSUw: -0.389709 | TSUb: -0.028031\n",
      "\n",
      "Train Epoch: 5269 [4000/8000 (50%)]\tBatch Loss: 0.013491\tLearning Rate (w_theta): 0.001000\t TIME:957.5s\n",
      "\t\t\t\tDisc: 0.012410\t\tSym: 0.000000\t\tSpars: 0.001081\n",
      "\t TVw: 0.831903 | TVb: 2.228425 | GSw: -0.656184 | GSb: -0.352694 | TSUw: -0.389351 | TSUb: -0.027833\n",
      "Validating epoch 5269...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012990423730405999\n",
      "Average validation loss: 0.013489685900423045\n",
      "Training epoch 5270...\n",
      "\n",
      "Train Epoch: 5270 [0/8000 (0%)]\tBatch Loss: 0.013867\tLearning Rate (w_theta): 0.001000\t TIME:959.7s\n",
      "\t\t\t\tDisc: 0.012820\t\tSym: 0.000000\t\tSpars: 0.001047\n",
      "\t TVw: 0.831848 | TVb: 2.228828 | GSw: -0.656075 | GSb: -0.352536 | TSUw: -0.389626 | TSUb: -0.028001\n",
      "\n",
      "Train Epoch: 5270 [4000/8000 (50%)]\tBatch Loss: 0.012919\tLearning Rate (w_theta): 0.001000\t TIME:960.9s\n",
      "\t\t\t\tDisc: 0.012106\t\tSym: 0.000000\t\tSpars: 0.000813\n",
      "\t TVw: 0.831708 | TVb: 2.229256 | GSw: -0.655980 | GSb: -0.352394 | TSUw: -0.390113 | TSUb: -0.028292\n",
      "Validating epoch 5270...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012988294443471651\n",
      "Average validation loss: 0.013488792712279212\n",
      "Training epoch 5271...\n",
      "\n",
      "Train Epoch: 5271 [0/8000 (0%)]\tBatch Loss: 0.012766\tLearning Rate (w_theta): 0.001000\t TIME:963.7s\n",
      "\t\t\t\tDisc: 0.011901\t\tSym: 0.000000\t\tSpars: 0.000865\n",
      "\t TVw: 0.831633 | TVb: 2.229640 | GSw: -0.655871 | GSb: -0.352235 | TSUw: -0.390363 | TSUb: -0.028446\n",
      "\n",
      "Train Epoch: 5271 [4000/8000 (50%)]\tBatch Loss: 0.012591\tLearning Rate (w_theta): 0.001000\t TIME:965.0s\n",
      "\t\t\t\tDisc: 0.011745\t\tSym: 0.000000\t\tSpars: 0.000845\n",
      "\t TVw: 0.831417 | TVb: 2.230007 | GSw: -0.655752 | GSb: -0.352066 | TSUw: -0.390463 | TSUb: -0.028512\n",
      "Validating epoch 5271...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012986080052482177\n",
      "Average validation loss: 0.013487356512402\n",
      "Training epoch 5272...\n",
      "\n",
      "Train Epoch: 5272 [0/8000 (0%)]\tBatch Loss: 0.013144\tLearning Rate (w_theta): 0.001000\t TIME:967.3s\n",
      "\t\t\t\tDisc: 0.012528\t\tSym: 0.000000\t\tSpars: 0.000615\n",
      "\t TVw: 0.831008 | TVb: 2.230325 | GSw: -0.655624 | GSb: -0.351887 | TSUw: -0.390396 | TSUb: -0.028481\n",
      "\n",
      "Train Epoch: 5272 [4000/8000 (50%)]\tBatch Loss: 0.012960\tLearning Rate (w_theta): 0.001000\t TIME:968.6s\n",
      "\t\t\t\tDisc: 0.012021\t\tSym: 0.000000\t\tSpars: 0.000939\n",
      "\t TVw: 0.830562 | TVb: 2.230636 | GSw: -0.655497 | GSb: -0.351708 | TSUw: -0.390324 | TSUb: -0.028447\n",
      "Validating epoch 5272...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012985101374192579\n",
      "Average validation loss: 0.013486194618585565\n",
      "Training epoch 5273...\n",
      "\n",
      "Train Epoch: 5273 [0/8000 (0%)]\tBatch Loss: 0.013094\tLearning Rate (w_theta): 0.001000\t TIME:970.7s\n",
      "\t\t\t\tDisc: 0.012264\t\tSym: 0.000000\t\tSpars: 0.000830\n",
      "\t TVw: 0.830253 | TVb: 2.230980 | GSw: -0.655384 | GSb: -0.351546 | TSUw: -0.390526 | TSUb: -0.028571\n",
      "\n",
      "Train Epoch: 5273 [4000/8000 (50%)]\tBatch Loss: 0.012824\tLearning Rate (w_theta): 0.001000\t TIME:972.0s\n",
      "\t\t\t\tDisc: 0.011946\t\tSym: 0.000000\t\tSpars: 0.000878\n",
      "\t TVw: 0.829382 | TVb: 2.231244 | GSw: -0.655259 | GSb: -0.351369 | TSUw: -0.390472 | TSUb: -0.028545\n",
      "Validating epoch 5273...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012984168313390493\n",
      "Average validation loss: 0.013485488805272181\n",
      "Training epoch 5274...\n",
      "\n",
      "Train Epoch: 5274 [0/8000 (0%)]\tBatch Loss: 0.013658\tLearning Rate (w_theta): 0.001000\t TIME:974.2s\n",
      "\t\t\t\tDisc: 0.012665\t\tSym: 0.000000\t\tSpars: 0.000993\n",
      "\t TVw: 0.829035 | TVb: 2.231577 | GSw: -0.655138 | GSb: -0.351197 | TSUw: -0.390533 | TSUb: -0.028587\n",
      "\n",
      "Train Epoch: 5274 [4000/8000 (50%)]\tBatch Loss: 0.013078\tLearning Rate (w_theta): 0.001000\t TIME:975.5s\n",
      "\t\t\t\tDisc: 0.012076\t\tSym: 0.000000\t\tSpars: 0.001001\n",
      "\t TVw: 0.828824 | TVb: 2.231950 | GSw: -0.655021 | GSb: -0.351031 | TSUw: -0.390665 | TSUb: -0.028670\n",
      "Validating epoch 5274...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012982996840303115\n",
      "Average validation loss: 0.013484379511765093\n",
      "Training epoch 5275...\n",
      "\n",
      "Train Epoch: 5275 [0/8000 (0%)]\tBatch Loss: 0.012990\tLearning Rate (w_theta): 0.001000\t TIME:977.6s\n",
      "\t\t\t\tDisc: 0.012319\t\tSym: 0.000000\t\tSpars: 0.000671\n",
      "\t TVw: 0.828459 | TVb: 2.232275 | GSw: -0.654900 | GSb: -0.350860 | TSUw: -0.390721 | TSUb: -0.028708\n",
      "\n",
      "Train Epoch: 5275 [4000/8000 (50%)]\tBatch Loss: 0.013291\tLearning Rate (w_theta): 0.001000\t TIME:978.9s\n",
      "\t\t\t\tDisc: 0.012329\t\tSym: 0.000000\t\tSpars: 0.000963\n",
      "\t TVw: 0.828195 | TVb: 2.232601 | GSw: -0.654778 | GSb: -0.350687 | TSUw: -0.390762 | TSUb: -0.028738\n",
      "Validating epoch 5275...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012981827130795013\n",
      "Average validation loss: 0.013482831953610188\n",
      "Training epoch 5276...\n",
      "\n",
      "Train Epoch: 5276 [0/8000 (0%)]\tBatch Loss: 0.012114\tLearning Rate (w_theta): 0.001000\t TIME:981.1s\n",
      "\t\t\t\tDisc: 0.011431\t\tSym: 0.000000\t\tSpars: 0.000683\n",
      "\t TVw: 0.827770 | TVb: 2.232919 | GSw: -0.654651 | GSb: -0.350509 | TSUw: -0.390695 | TSUb: -0.028705\n",
      "\n",
      "Train Epoch: 5276 [4000/8000 (50%)]\tBatch Loss: 0.013318\tLearning Rate (w_theta): 0.001000\t TIME:982.4s\n",
      "\t\t\t\tDisc: 0.012462\t\tSym: 0.000000\t\tSpars: 0.000856\n",
      "\t TVw: 0.827654 | TVb: 2.233271 | GSw: -0.654548 | GSb: -0.350356 | TSUw: -0.391052 | TSUb: -0.028918\n",
      "Validating epoch 5276...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012980378192629658\n",
      "Average validation loss: 0.013481964742324415\n",
      "Training epoch 5277...\n",
      "\n",
      "Train Epoch: 5277 [0/8000 (0%)]\tBatch Loss: 0.012522\tLearning Rate (w_theta): 0.001000\t TIME:984.6s\n",
      "\t\t\t\tDisc: 0.011564\t\tSym: 0.000000\t\tSpars: 0.000958\n",
      "\t TVw: 0.827455 | TVb: 2.233623 | GSw: -0.654421 | GSb: -0.350179 | TSUw: -0.391045 | TSUb: -0.028918\n",
      "\n",
      "Train Epoch: 5277 [4000/8000 (50%)]\tBatch Loss: 0.013123\tLearning Rate (w_theta): 0.001000\t TIME:985.8s\n",
      "\t\t\t\tDisc: 0.012426\t\tSym: 0.000000\t\tSpars: 0.000696\n",
      "\t TVw: 0.827411 | TVb: 2.233981 | GSw: -0.654281 | GSb: -0.349988 | TSUw: -0.390831 | TSUb: -0.028800\n",
      "Validating epoch 5277...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012978894491356448\n",
      "Average validation loss: 0.0134798261264832\n",
      "Training epoch 5278...\n",
      "\n",
      "Train Epoch: 5278 [0/8000 (0%)]\tBatch Loss: 0.011892\tLearning Rate (w_theta): 0.001000\t TIME:988.0s\n",
      "\t\t\t\tDisc: 0.011468\t\tSym: 0.000000\t\tSpars: 0.000424\n",
      "\t TVw: 0.826891 | TVb: 2.234261 | GSw: -0.654149 | GSb: -0.349804 | TSUw: -0.390710 | TSUb: -0.028734\n",
      "\n",
      "Train Epoch: 5278 [4000/8000 (50%)]\tBatch Loss: 0.012964\tLearning Rate (w_theta): 0.001000\t TIME:989.3s\n",
      "\t\t\t\tDisc: 0.012185\t\tSym: 0.000000\t\tSpars: 0.000778\n",
      "\t TVw: 0.826449 | TVb: 2.234540 | GSw: -0.654040 | GSb: -0.349645 | TSUw: -0.391007 | TSUb: -0.028911\n",
      "Validating epoch 5278...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012977819107854572\n",
      "Average validation loss: 0.013479424626964238\n",
      "Training epoch 5279...\n",
      "\n",
      "Train Epoch: 5279 [0/8000 (0%)]\tBatch Loss: 0.012475\tLearning Rate (w_theta): 0.001000\t TIME:991.4s\n",
      "\t\t\t\tDisc: 0.011979\t\tSym: 0.000000\t\tSpars: 0.000496\n",
      "\t TVw: 0.825973 | TVb: 2.234863 | GSw: -0.653921 | GSb: -0.349477 | TSUw: -0.391112 | TSUb: -0.028976\n",
      "\n",
      "Train Epoch: 5279 [4000/8000 (50%)]\tBatch Loss: 0.012597\tLearning Rate (w_theta): 0.001000\t TIME:992.7s\n",
      "\t\t\t\tDisc: 0.011814\t\tSym: 0.000000\t\tSpars: 0.000783\n",
      "\t TVw: 0.825779 | TVb: 2.235211 | GSw: -0.653802 | GSb: -0.349308 | TSUw: -0.391243 | TSUb: -0.029056\n",
      "Validating epoch 5279...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012976546087059702\n",
      "Average validation loss: 0.01347820721900263\n",
      "Training epoch 5280...\n",
      "\n",
      "Train Epoch: 5280 [0/8000 (0%)]\tBatch Loss: 0.013019\tLearning Rate (w_theta): 0.001000\t TIME:994.9s\n",
      "\t\t\t\tDisc: 0.012034\t\tSym: 0.000000\t\tSpars: 0.000985\n",
      "\t TVw: 0.825645 | TVb: 2.235555 | GSw: -0.653680 | GSb: -0.349135 | TSUw: -0.391309 | TSUb: -0.029099\n",
      "\n",
      "Train Epoch: 5280 [4000/8000 (50%)]\tBatch Loss: 0.012971\tLearning Rate (w_theta): 0.001000\t TIME:996.2s\n",
      "\t\t\t\tDisc: 0.012092\t\tSym: 0.000000\t\tSpars: 0.000878\n",
      "\t TVw: 0.824963 | TVb: 2.235810 | GSw: -0.653538 | GSb: -0.348941 | TSUw: -0.390978 | TSUb: -0.028909\n",
      "Validating epoch 5280...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012975638191541062\n",
      "Average validation loss: 0.013477009945158169\n",
      "Training epoch 5281...\n",
      "\n",
      "Train Epoch: 5281 [0/8000 (0%)]\tBatch Loss: 0.013079\tLearning Rate (w_theta): 0.001000\t TIME:999.0s\n",
      "\t\t\t\tDisc: 0.012141\t\tSym: 0.000000\t\tSpars: 0.000937\n",
      "\t TVw: 0.824699 | TVb: 2.236146 | GSw: -0.653426 | GSb: -0.348779 | TSUw: -0.391230 | TSUb: -0.029059\n",
      "\n",
      "Train Epoch: 5281 [4000/8000 (50%)]\tBatch Loss: 0.013107\tLearning Rate (w_theta): 0.001000\t TIME:1000.3s\n",
      "\t\t\t\tDisc: 0.012272\t\tSym: 0.000000\t\tSpars: 0.000835\n",
      "\t TVw: 0.824439 | TVb: 2.236457 | GSw: -0.653303 | GSb: -0.348604 | TSUw: -0.391255 | TSUb: -0.029077\n",
      "Validating epoch 5281...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012974261827531492\n",
      "Average validation loss: 0.013475973876290041\n",
      "Training epoch 5282...\n",
      "\n",
      "Train Epoch: 5282 [0/8000 (0%)]\tBatch Loss: 0.012761\tLearning Rate (w_theta): 0.001000\t TIME:1002.5s\n",
      "\t\t\t\tDisc: 0.011966\t\tSym: 0.000000\t\tSpars: 0.000795\n",
      "\t TVw: 0.824173 | TVb: 2.236780 | GSw: -0.653191 | GSb: -0.348444 | TSUw: -0.391547 | TSUb: -0.029251\n",
      "\n",
      "Train Epoch: 5282 [4000/8000 (50%)]\tBatch Loss: 0.012524\tLearning Rate (w_theta): 0.001000\t TIME:1003.7s\n",
      "\t\t\t\tDisc: 0.011789\t\tSym: 0.000000\t\tSpars: 0.000735\n",
      "\t TVw: 0.824108 | TVb: 2.237123 | GSw: -0.653074 | GSb: -0.348276 | TSUw: -0.391754 | TSUb: -0.029374\n",
      "Validating epoch 5282...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012972779955328534\n",
      "Average validation loss: 0.013475044518341812\n",
      "Training epoch 5283...\n",
      "\n",
      "Train Epoch: 5283 [0/8000 (0%)]\tBatch Loss: 0.012828\tLearning Rate (w_theta): 0.001000\t TIME:1006.0s\n",
      "\t\t\t\tDisc: 0.011963\t\tSym: 0.000000\t\tSpars: 0.000864\n",
      "\t TVw: 0.823706 | TVb: 2.237432 | GSw: -0.652951 | GSb: -0.348102 | TSUw: -0.391818 | TSUb: -0.029413\n",
      "\n",
      "Train Epoch: 5283 [4000/8000 (50%)]\tBatch Loss: 0.013389\tLearning Rate (w_theta): 0.001000\t TIME:1007.2s\n",
      "\t\t\t\tDisc: 0.012578\t\tSym: 0.000000\t\tSpars: 0.000811\n",
      "\t TVw: 0.823158 | TVb: 2.237715 | GSw: -0.652831 | GSb: -0.347933 | TSUw: -0.391883 | TSUb: -0.029452\n",
      "Validating epoch 5283...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012971718198411739\n",
      "Average validation loss: 0.013474165216099766\n",
      "Training epoch 5284...\n",
      "\n",
      "Train Epoch: 5284 [0/8000 (0%)]\tBatch Loss: 0.012846\tLearning Rate (w_theta): 0.001000\t TIME:1009.4s\n",
      "\t\t\t\tDisc: 0.011835\t\tSym: 0.000000\t\tSpars: 0.001011\n",
      "\t TVw: 0.822704 | TVb: 2.237990 | GSw: -0.652700 | GSb: -0.347750 | TSUw: -0.391798 | TSUb: -0.029404\n",
      "\n",
      "Train Epoch: 5284 [4000/8000 (50%)]\tBatch Loss: 0.012821\tLearning Rate (w_theta): 0.001000\t TIME:1010.6s\n",
      "\t\t\t\tDisc: 0.012065\t\tSym: 0.000000\t\tSpars: 0.000756\n",
      "\t TVw: 0.823142 | TVb: 2.238414 | GSw: -0.652587 | GSb: -0.347587 | TSUw: -0.392119 | TSUb: -0.029593\n",
      "Validating epoch 5284...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012970569660520681\n",
      "Average validation loss: 0.013472582266318518\n",
      "Training epoch 5285...\n",
      "\n",
      "Train Epoch: 5285 [0/8000 (0%)]\tBatch Loss: 0.012853\tLearning Rate (w_theta): 0.001000\t TIME:1012.8s\n",
      "\t\t\t\tDisc: 0.012112\t\tSym: 0.000000\t\tSpars: 0.000741\n",
      "\t TVw: 0.822594 | TVb: 2.238672 | GSw: -0.652449 | GSb: -0.347397 | TSUw: -0.391922 | TSUb: -0.029479\n",
      "\n",
      "Train Epoch: 5285 [4000/8000 (50%)]\tBatch Loss: 0.012930\tLearning Rate (w_theta): 0.001000\t TIME:1014.1s\n",
      "\t\t\t\tDisc: 0.012234\t\tSym: 0.000000\t\tSpars: 0.000696\n",
      "\t TVw: 0.821355 | TVb: 2.238813 | GSw: -0.652300 | GSb: -0.347195 | TSUw: -0.391473 | TSUb: -0.029216\n",
      "Validating epoch 5285...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012970315044561462\n",
      "Average validation loss: 0.013471741403308821\n",
      "Training epoch 5286...\n",
      "\n",
      "Train Epoch: 5286 [0/8000 (0%)]\tBatch Loss: 0.013346\tLearning Rate (w_theta): 0.001000\t TIME:1016.3s\n",
      "\t\t\t\tDisc: 0.012393\t\tSym: 0.000000\t\tSpars: 0.000953\n",
      "\t TVw: 0.820975 | TVb: 2.239101 | GSw: -0.652174 | GSb: -0.347016 | TSUw: -0.391480 | TSUb: -0.029221\n",
      "\n",
      "Train Epoch: 5286 [4000/8000 (50%)]\tBatch Loss: 0.013630\tLearning Rate (w_theta): 0.001000\t TIME:1017.6s\n",
      "\t\t\t\tDisc: 0.012763\t\tSym: 0.000000\t\tSpars: 0.000867\n",
      "\t TVw: 0.821255 | TVb: 2.239513 | GSw: -0.652059 | GSb: -0.346849 | TSUw: -0.391741 | TSUb: -0.029376\n",
      "Validating epoch 5286...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012969127292337145\n",
      "Average validation loss: 0.013470459519864466\n",
      "Training epoch 5287...\n",
      "\n",
      "Train Epoch: 5287 [0/8000 (0%)]\tBatch Loss: 0.013083\tLearning Rate (w_theta): 0.001000\t TIME:1019.8s\n",
      "\t\t\t\tDisc: 0.012221\t\tSym: 0.000000\t\tSpars: 0.000862\n",
      "\t TVw: 0.821006 | TVb: 2.239813 | GSw: -0.651946 | GSb: -0.346684 | TSUw: -0.391995 | TSUb: -0.029525\n",
      "\n",
      "Train Epoch: 5287 [4000/8000 (50%)]\tBatch Loss: 0.013440\tLearning Rate (w_theta): 0.001000\t TIME:1021.0s\n",
      "\t\t\t\tDisc: 0.011959\t\tSym: 0.000000\t\tSpars: 0.001481\n",
      "\t TVw: 0.820471 | TVb: 2.240068 | GSw: -0.651812 | GSb: -0.346499 | TSUw: -0.391895 | TSUb: -0.029467\n",
      "Validating epoch 5287...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012967897108176772\n",
      "Average validation loss: 0.013469921708891025\n",
      "Training epoch 5288...\n",
      "\n",
      "Train Epoch: 5288 [0/8000 (0%)]\tBatch Loss: 0.012756\tLearning Rate (w_theta): 0.001000\t TIME:1023.2s\n",
      "\t\t\t\tDisc: 0.012071\t\tSym: 0.000000\t\tSpars: 0.000685\n",
      "\t TVw: 0.820083 | TVb: 2.240336 | GSw: -0.651699 | GSb: -0.346335 | TSUw: -0.392153 | TSUb: -0.029618\n",
      "\n",
      "Train Epoch: 5288 [4000/8000 (50%)]\tBatch Loss: 0.013543\tLearning Rate (w_theta): 0.001000\t TIME:1024.5s\n",
      "\t\t\t\tDisc: 0.012683\t\tSym: 0.000000\t\tSpars: 0.000860\n",
      "\t TVw: 0.819596 | TVb: 2.240580 | GSw: -0.651561 | GSb: -0.346145 | TSUw: -0.391949 | TSUb: -0.029499\n",
      "Validating epoch 5288...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012967119279979416\n",
      "Average validation loss: 0.013468840820736013\n",
      "Training epoch 5289...\n",
      "\n",
      "Train Epoch: 5289 [0/8000 (0%)]\tBatch Loss: 0.012438\tLearning Rate (w_theta): 0.001000\t TIME:1026.7s\n",
      "\t\t\t\tDisc: 0.011739\t\tSym: 0.000000\t\tSpars: 0.000699\n",
      "\t TVw: 0.819265 | TVb: 2.240856 | GSw: -0.651435 | GSb: -0.345967 | TSUw: -0.391981 | TSUb: -0.029518\n",
      "\n",
      "Train Epoch: 5289 [4000/8000 (50%)]\tBatch Loss: 0.012739\tLearning Rate (w_theta): 0.001000\t TIME:1027.9s\n",
      "\t\t\t\tDisc: 0.012064\t\tSym: 0.000000\t\tSpars: 0.000675\n",
      "\t TVw: 0.818761 | TVb: 2.241143 | GSw: -0.651316 | GSb: -0.345798 | TSUw: -0.392129 | TSUb: -0.029604\n",
      "Validating epoch 5289...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012966084555591735\n",
      "Average validation loss: 0.013468100475521428\n",
      "Training epoch 5290...\n",
      "\n",
      "Train Epoch: 5290 [0/8000 (0%)]\tBatch Loss: 0.012837\tLearning Rate (w_theta): 0.001000\t TIME:1030.1s\n",
      "\t\t\t\tDisc: 0.012048\t\tSym: 0.000000\t\tSpars: 0.000789\n",
      "\t TVw: 0.818561 | TVb: 2.241457 | GSw: -0.651201 | GSb: -0.345632 | TSUw: -0.392358 | TSUb: -0.029738\n",
      "\n",
      "Train Epoch: 5290 [4000/8000 (50%)]\tBatch Loss: 0.013418\tLearning Rate (w_theta): 0.001000\t TIME:1031.4s\n",
      "\t\t\t\tDisc: 0.012599\t\tSym: 0.000000\t\tSpars: 0.000819\n",
      "\t TVw: 0.818236 | TVb: 2.241712 | GSw: -0.651090 | GSb: -0.345469 | TSUw: -0.392636 | TSUb: -0.029901\n",
      "Validating epoch 5290...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012964946909193299\n",
      "Average validation loss: 0.013467490277359002\n",
      "Training epoch 5291...\n",
      "\n",
      "Train Epoch: 5291 [0/8000 (0%)]\tBatch Loss: 0.012861\tLearning Rate (w_theta): 0.001000\t TIME:1034.2s\n",
      "\t\t\t\tDisc: 0.012035\t\tSym: 0.000000\t\tSpars: 0.000826\n",
      "\t TVw: 0.817982 | TVb: 2.242011 | GSw: -0.650962 | GSb: -0.345291 | TSUw: -0.392659 | TSUb: -0.029913\n",
      "\n",
      "Train Epoch: 5291 [4000/8000 (50%)]\tBatch Loss: 0.012959\tLearning Rate (w_theta): 0.001000\t TIME:1035.5s\n",
      "\t\t\t\tDisc: 0.012266\t\tSym: 0.000000\t\tSpars: 0.000693\n",
      "\t TVw: 0.817890 | TVb: 2.242382 | GSw: -0.650853 | GSb: -0.345131 | TSUw: -0.393064 | TSUb: -0.030149\n",
      "Validating epoch 5291...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012963781188096277\n",
      "Average validation loss: 0.01346660080896736\n",
      "Training epoch 5292...\n",
      "\n",
      "Train Epoch: 5292 [0/8000 (0%)]\tBatch Loss: 0.012839\tLearning Rate (w_theta): 0.001000\t TIME:1037.7s\n",
      "\t\t\t\tDisc: 0.012151\t\tSym: 0.000000\t\tSpars: 0.000688\n",
      "\t TVw: 0.817701 | TVb: 2.242676 | GSw: -0.650721 | GSb: -0.344947 | TSUw: -0.393026 | TSUb: -0.030125\n",
      "\n",
      "Train Epoch: 5292 [4000/8000 (50%)]\tBatch Loss: 0.012737\tLearning Rate (w_theta): 0.001000\t TIME:1039.0s\n",
      "\t\t\t\tDisc: 0.011820\t\tSym: 0.000000\t\tSpars: 0.000918\n",
      "\t TVw: 0.817474 | TVb: 2.242940 | GSw: -0.650588 | GSb: -0.344765 | TSUw: -0.392950 | TSUb: -0.030077\n",
      "Validating epoch 5292...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012962141355566854\n",
      "Average validation loss: 0.013465114018880231\n",
      "Training epoch 5293...\n",
      "\n",
      "Train Epoch: 5293 [0/8000 (0%)]\tBatch Loss: 0.012747\tLearning Rate (w_theta): 0.001000\t TIME:1041.1s\n",
      "\t\t\t\tDisc: 0.011901\t\tSym: 0.000000\t\tSpars: 0.000846\n",
      "\t TVw: 0.817255 | TVb: 2.243229 | GSw: -0.650450 | GSb: -0.344575 | TSUw: -0.392800 | TSUb: -0.029986\n",
      "\n",
      "Train Epoch: 5293 [4000/8000 (50%)]\tBatch Loss: 0.012680\tLearning Rate (w_theta): 0.001000\t TIME:1042.4s\n",
      "\t\t\t\tDisc: 0.012079\t\tSym: 0.000000\t\tSpars: 0.000601\n",
      "\t TVw: 0.816838 | TVb: 2.243500 | GSw: -0.650312 | GSb: -0.344385 | TSUw: -0.392624 | TSUb: -0.029879\n",
      "Validating epoch 5293...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012961288937899348\n",
      "Average validation loss: 0.013463476693529701\n",
      "Training epoch 5294...\n",
      "\n",
      "Train Epoch: 5294 [0/8000 (0%)]\tBatch Loss: 0.013353\tLearning Rate (w_theta): 0.001000\t TIME:1044.6s\n",
      "\t\t\t\tDisc: 0.012172\t\tSym: 0.000000\t\tSpars: 0.001181\n",
      "\t TVw: 0.816857 | TVb: 2.243814 | GSw: -0.650186 | GSb: -0.344206 | TSUw: -0.392713 | TSUb: -0.029930\n",
      "\n",
      "Train Epoch: 5294 [4000/8000 (50%)]\tBatch Loss: 0.012650\tLearning Rate (w_theta): 0.001000\t TIME:1045.9s\n",
      "\t\t\t\tDisc: 0.012079\t\tSym: 0.000000\t\tSpars: 0.000571\n",
      "\t TVw: 0.816929 | TVb: 2.244159 | GSw: -0.650066 | GSb: -0.344035 | TSUw: -0.392934 | TSUb: -0.030057\n",
      "Validating epoch 5294...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012959765495597571\n",
      "Average validation loss: 0.01346225151276808\n",
      "Training epoch 5295...\n",
      "\n",
      "Train Epoch: 5295 [0/8000 (0%)]\tBatch Loss: 0.012454\tLearning Rate (w_theta): 0.001000\t TIME:1048.1s\n",
      "\t\t\t\tDisc: 0.011613\t\tSym: 0.000000\t\tSpars: 0.000841\n",
      "\t TVw: 0.816717 | TVb: 2.244445 | GSw: -0.649938 | GSb: -0.343854 | TSUw: -0.392985 | TSUb: -0.030085\n",
      "\n",
      "Train Epoch: 5295 [4000/8000 (50%)]\tBatch Loss: 0.012862\tLearning Rate (w_theta): 0.001000\t TIME:1049.4s\n",
      "\t\t\t\tDisc: 0.012021\t\tSym: 0.000000\t\tSpars: 0.000841\n",
      "\t TVw: 0.815937 | TVb: 2.244642 | GSw: -0.649794 | GSb: -0.343655 | TSUw: -0.392674 | TSUb: -0.029896\n",
      "Validating epoch 5295...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012958982500536129\n",
      "Average validation loss: 0.013461282054398917\n",
      "Training epoch 5296...\n",
      "\n",
      "Train Epoch: 5296 [0/8000 (0%)]\tBatch Loss: 0.012886\tLearning Rate (w_theta): 0.001000\t TIME:1051.6s\n",
      "\t\t\t\tDisc: 0.012224\t\tSym: 0.000000\t\tSpars: 0.000662\n",
      "\t TVw: 0.815546 | TVb: 2.244908 | GSw: -0.649667 | GSb: -0.343477 | TSUw: -0.392714 | TSUb: -0.029917\n",
      "\n",
      "Train Epoch: 5296 [4000/8000 (50%)]\tBatch Loss: 0.012599\tLearning Rate (w_theta): 0.001000\t TIME:1052.9s\n",
      "\t\t\t\tDisc: 0.011567\t\tSym: 0.000000\t\tSpars: 0.001032\n",
      "\t TVw: 0.815015 | TVb: 2.245137 | GSw: -0.649540 | GSb: -0.343299 | TSUw: -0.392718 | TSUb: -0.029916\n",
      "Validating epoch 5296...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012958400216833536\n",
      "Average validation loss: 0.013460775110884539\n",
      "Training epoch 5297...\n",
      "\n",
      "Train Epoch: 5297 [0/8000 (0%)]\tBatch Loss: 0.012724\tLearning Rate (w_theta): 0.001000\t TIME:1055.1s\n",
      "\t\t\t\tDisc: 0.011794\t\tSym: 0.000000\t\tSpars: 0.000930\n",
      "\t TVw: 0.814857 | TVb: 2.245425 | GSw: -0.649429 | GSb: -0.343136 | TSUw: -0.393051 | TSUb: -0.030109\n",
      "\n",
      "Train Epoch: 5297 [4000/8000 (50%)]\tBatch Loss: 0.013689\tLearning Rate (w_theta): 0.001000\t TIME:1056.3s\n",
      "\t\t\t\tDisc: 0.012696\t\tSym: 0.000000\t\tSpars: 0.000993\n",
      "\t TVw: 0.814913 | TVb: 2.245760 | GSw: -0.649298 | GSb: -0.342953 | TSUw: -0.393029 | TSUb: -0.030094\n",
      "Validating epoch 5297...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01295712833237727\n",
      "Average validation loss: 0.013459392026711904\n",
      "Training epoch 5298...\n",
      "\n",
      "Train Epoch: 5298 [0/8000 (0%)]\tBatch Loss: 0.013368\tLearning Rate (w_theta): 0.001000\t TIME:1058.5s\n",
      "\t\t\t\tDisc: 0.012516\t\tSym: 0.000000\t\tSpars: 0.000853\n",
      "\t TVw: 0.814790 | TVb: 2.246072 | GSw: -0.649182 | GSb: -0.342785 | TSUw: -0.393302 | TSUb: -0.030252\n",
      "\n",
      "Train Epoch: 5298 [4000/8000 (50%)]\tBatch Loss: 0.012657\tLearning Rate (w_theta): 0.001000\t TIME:1059.8s\n",
      "\t\t\t\tDisc: 0.011702\t\tSym: 0.000000\t\tSpars: 0.000954\n",
      "\t TVw: 0.814547 | TVb: 2.246361 | GSw: -0.649067 | GSb: -0.342618 | TSUw: -0.393603 | TSUb: -0.030426\n",
      "Validating epoch 5298...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012955488078838567\n",
      "Average validation loss: 0.013459154007842977\n",
      "Training epoch 5299...\n",
      "\n",
      "Train Epoch: 5299 [0/8000 (0%)]\tBatch Loss: 0.013463\tLearning Rate (w_theta): 0.001000\t TIME:1061.9s\n",
      "\t\t\t\tDisc: 0.012527\t\tSym: 0.000000\t\tSpars: 0.000936\n",
      "\t TVw: 0.814257 | TVb: 2.246620 | GSw: -0.648946 | GSb: -0.342445 | TSUw: -0.393791 | TSUb: -0.030533\n",
      "\n",
      "Train Epoch: 5299 [4000/8000 (50%)]\tBatch Loss: 0.012450\tLearning Rate (w_theta): 0.001000\t TIME:1063.2s\n",
      "\t\t\t\tDisc: 0.011652\t\tSym: 0.000000\t\tSpars: 0.000798\n",
      "\t TVw: 0.814148 | TVb: 2.246856 | GSw: -0.648815 | GSb: -0.342260 | TSUw: -0.393836 | TSUb: -0.030555\n",
      "Validating epoch 5299...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012954487978682584\n",
      "Average validation loss: 0.013457962083410244\n",
      "Training epoch 5300...\n",
      "\n",
      "Train Epoch: 5300 [0/8000 (0%)]\tBatch Loss: 0.013022\tLearning Rate (w_theta): 0.001000\t TIME:1065.5s\n",
      "\t\t\t\tDisc: 0.012256\t\tSym: 0.000000\t\tSpars: 0.000766\n",
      "\t TVw: 0.813808 | TVb: 2.247082 | GSw: -0.648671 | GSb: -0.342064 | TSUw: -0.393617 | TSUb: -0.030419\n",
      "\n",
      "Train Epoch: 5300 [4000/8000 (50%)]\tBatch Loss: 0.012639\tLearning Rate (w_theta): 0.001000\t TIME:1066.7s\n",
      "\t\t\t\tDisc: 0.011784\t\tSym: 0.000000\t\tSpars: 0.000855\n",
      "\t TVw: 0.813562 | TVb: 2.247323 | GSw: -0.648534 | GSb: -0.341876 | TSUw: -0.393513 | TSUb: -0.030351\n",
      "Validating epoch 5300...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012953685034601446\n",
      "Average validation loss: 0.013456977594329724\n",
      "Training epoch 5301...\n",
      "\n",
      "Train Epoch: 5301 [0/8000 (0%)]\tBatch Loss: 0.013136\tLearning Rate (w_theta): 0.001000\t TIME:1069.5s\n",
      "\t\t\t\tDisc: 0.012145\t\tSym: 0.000000\t\tSpars: 0.000991\n",
      "\t TVw: 0.813483 | TVb: 2.247611 | GSw: -0.648421 | GSb: -0.341711 | TSUw: -0.393827 | TSUb: -0.030532\n",
      "\n",
      "Train Epoch: 5301 [4000/8000 (50%)]\tBatch Loss: 0.013057\tLearning Rate (w_theta): 0.001000\t TIME:1070.8s\n",
      "\t\t\t\tDisc: 0.012348\t\tSym: 0.000000\t\tSpars: 0.000709\n",
      "\t TVw: 0.813667 | TVb: 2.247951 | GSw: -0.648309 | GSb: -0.341547 | TSUw: -0.394180 | TSUb: -0.030736\n",
      "Validating epoch 5301...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012952221242282016\n",
      "Average validation loss: 0.013455955001628984\n",
      "Training epoch 5302...\n",
      "\n",
      "Train Epoch: 5302 [0/8000 (0%)]\tBatch Loss: 0.013005\tLearning Rate (w_theta): 0.001000\t TIME:1073.0s\n",
      "\t\t\t\tDisc: 0.012281\t\tSym: 0.000000\t\tSpars: 0.000724\n",
      "\t TVw: 0.813212 | TVb: 2.248176 | GSw: -0.648167 | GSb: -0.341350 | TSUw: -0.393973 | TSUb: -0.030606\n",
      "\n",
      "Train Epoch: 5302 [4000/8000 (50%)]\tBatch Loss: 0.012623\tLearning Rate (w_theta): 0.001000\t TIME:1074.2s\n",
      "\t\t\t\tDisc: 0.012114\t\tSym: 0.000000\t\tSpars: 0.000509\n",
      "\t TVw: 0.812947 | TVb: 2.248374 | GSw: -0.648012 | GSb: -0.341138 | TSUw: -0.393589 | TSUb: -0.030372\n",
      "Validating epoch 5302...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012951546576924669\n",
      "Average validation loss: 0.013454309749801167\n",
      "Training epoch 5303...\n",
      "\n",
      "Train Epoch: 5303 [0/8000 (0%)]\tBatch Loss: 0.013807\tLearning Rate (w_theta): 0.001000\t TIME:1076.5s\n",
      "\t\t\t\tDisc: 0.012760\t\tSym: 0.000000\t\tSpars: 0.001047\n",
      "\t TVw: 0.812581 | TVb: 2.248586 | GSw: -0.647864 | GSb: -0.340935 | TSUw: -0.393302 | TSUb: -0.030194\n",
      "\n",
      "Train Epoch: 5303 [4000/8000 (50%)]\tBatch Loss: 0.012534\tLearning Rate (w_theta): 0.001000\t TIME:1077.7s\n",
      "\t\t\t\tDisc: 0.011890\t\tSym: 0.000000\t\tSpars: 0.000644\n",
      "\t TVw: 0.812296 | TVb: 2.248860 | GSw: -0.647731 | GSb: -0.340749 | TSUw: -0.393284 | TSUb: -0.030177\n",
      "Validating epoch 5303...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012951125826748636\n",
      "Average validation loss: 0.013453373398892254\n",
      "Training epoch 5304...\n",
      "\n",
      "Train Epoch: 5304 [0/8000 (0%)]\tBatch Loss: 0.012571\tLearning Rate (w_theta): 0.001000\t TIME:1080.0s\n",
      "\t\t\t\tDisc: 0.011796\t\tSym: 0.000000\t\tSpars: 0.000775\n",
      "\t TVw: 0.811892 | TVb: 2.249084 | GSw: -0.647611 | GSb: -0.340578 | TSUw: -0.393485 | TSUb: -0.030290\n",
      "\n",
      "Train Epoch: 5304 [4000/8000 (50%)]\tBatch Loss: 0.012969\tLearning Rate (w_theta): 0.001000\t TIME:1081.2s\n",
      "\t\t\t\tDisc: 0.012352\t\tSym: 0.000000\t\tSpars: 0.000617\n",
      "\t TVw: 0.812131 | TVb: 2.249416 | GSw: -0.647493 | GSb: -0.340407 | TSUw: -0.393777 | TSUb: -0.030460\n",
      "Validating epoch 5304...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01294954545665073\n",
      "Average validation loss: 0.01345280027713215\n",
      "Training epoch 5305...\n",
      "\n",
      "Train Epoch: 5305 [0/8000 (0%)]\tBatch Loss: 0.012850\tLearning Rate (w_theta): 0.001000\t TIME:1083.4s\n",
      "\t\t\t\tDisc: 0.012114\t\tSym: 0.000000\t\tSpars: 0.000735\n",
      "\t TVw: 0.811733 | TVb: 2.249655 | GSw: -0.647379 | GSb: -0.340242 | TSUw: -0.394093 | TSUb: -0.030642\n",
      "\n",
      "Train Epoch: 5305 [4000/8000 (50%)]\tBatch Loss: 0.012974\tLearning Rate (w_theta): 0.001000\t TIME:1084.7s\n",
      "\t\t\t\tDisc: 0.012069\t\tSym: 0.000000\t\tSpars: 0.000905\n",
      "\t TVw: 0.810711 | TVb: 2.249770 | GSw: -0.647233 | GSb: -0.340041 | TSUw: -0.393761 | TSUb: -0.030436\n",
      "Validating epoch 5305...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01294952610426623\n",
      "Average validation loss: 0.013452501037884744\n",
      "Training epoch 5306...\n",
      "\n",
      "Train Epoch: 5306 [0/8000 (0%)]\tBatch Loss: 0.013572\tLearning Rate (w_theta): 0.001000\t TIME:1086.8s\n",
      "\t\t\t\tDisc: 0.012535\t\tSym: 0.000000\t\tSpars: 0.001036\n",
      "\t TVw: 0.810526 | TVb: 2.250023 | GSw: -0.647123 | GSb: -0.339880 | TSUw: -0.394168 | TSUb: -0.030672\n",
      "\n",
      "Train Epoch: 5306 [4000/8000 (50%)]\tBatch Loss: 0.012516\tLearning Rate (w_theta): 0.001000\t TIME:1088.1s\n",
      "\t\t\t\tDisc: 0.012043\t\tSym: 0.000000\t\tSpars: 0.000473\n",
      "\t TVw: 0.810441 | TVb: 2.250307 | GSw: -0.647025 | GSb: -0.339733 | TSUw: -0.394808 | TSUb: -0.031048\n",
      "Validating epoch 5306...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012948381266567425\n",
      "Average validation loss: 0.013452850813508407\n",
      "Training epoch 5307...\n",
      "\n",
      "Train Epoch: 5307 [0/8000 (0%)]\tBatch Loss: 0.012809\tLearning Rate (w_theta): 0.001000\t TIME:1090.3s\n",
      "\t\t\t\tDisc: 0.012263\t\tSym: 0.000000\t\tSpars: 0.000546\n",
      "\t TVw: 0.810071 | TVb: 2.250511 | GSw: -0.646898 | GSb: -0.339552 | TSUw: -0.394884 | TSUb: -0.031084\n",
      "\n",
      "Train Epoch: 5307 [4000/8000 (50%)]\tBatch Loss: 0.013510\tLearning Rate (w_theta): 0.001000\t TIME:1091.6s\n",
      "\t\t\t\tDisc: 0.012413\t\tSym: 0.000000\t\tSpars: 0.001097\n",
      "\t TVw: 0.810044 | TVb: 2.250745 | GSw: -0.646755 | GSb: -0.339355 | TSUw: -0.394736 | TSUb: -0.030987\n",
      "Validating epoch 5307...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012947223233001228\n",
      "Average validation loss: 0.013451423097320801\n",
      "Training epoch 5308...\n",
      "\n",
      "Train Epoch: 5308 [0/8000 (0%)]\tBatch Loss: 0.012480\tLearning Rate (w_theta): 0.001000\t TIME:1093.7s\n",
      "\t\t\t\tDisc: 0.011716\t\tSym: 0.000000\t\tSpars: 0.000764\n",
      "\t TVw: 0.809896 | TVb: 2.250990 | GSw: -0.646625 | GSb: -0.339173 | TSUw: -0.394797 | TSUb: -0.031014\n",
      "\n",
      "Train Epoch: 5308 [4000/8000 (50%)]\tBatch Loss: 0.012303\tLearning Rate (w_theta): 0.001000\t TIME:1095.0s\n",
      "\t\t\t\tDisc: 0.011688\t\tSym: 0.000000\t\tSpars: 0.000615\n",
      "\t TVw: 0.809638 | TVb: 2.251206 | GSw: -0.646489 | GSb: -0.338984 | TSUw: -0.394727 | TSUb: -0.030962\n",
      "Validating epoch 5308...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012946254765412921\n",
      "Average validation loss: 0.013450203982737684\n",
      "Training epoch 5309...\n",
      "\n",
      "Train Epoch: 5309 [0/8000 (0%)]\tBatch Loss: 0.013089\tLearning Rate (w_theta): 0.001000\t TIME:1097.2s\n",
      "\t\t\t\tDisc: 0.012210\t\tSym: 0.000000\t\tSpars: 0.000879\n",
      "\t TVw: 0.809264 | TVb: 2.251438 | GSw: -0.646349 | GSb: -0.338790 | TSUw: -0.394581 | TSUb: -0.030865\n",
      "\n",
      "Train Epoch: 5309 [4000/8000 (50%)]\tBatch Loss: 0.013355\tLearning Rate (w_theta): 0.001000\t TIME:1098.5s\n",
      "\t\t\t\tDisc: 0.012501\t\tSym: 0.000000\t\tSpars: 0.000854\n",
      "\t TVw: 0.809184 | TVb: 2.251703 | GSw: -0.646228 | GSb: -0.338616 | TSUw: -0.394843 | TSUb: -0.031014\n",
      "Validating epoch 5309...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01294537653023137\n",
      "Average validation loss: 0.013449416564502133\n",
      "Training epoch 5310...\n",
      "\n",
      "Train Epoch: 5310 [0/8000 (0%)]\tBatch Loss: 0.012517\tLearning Rate (w_theta): 0.001000\t TIME:1100.7s\n",
      "\t\t\t\tDisc: 0.011677\t\tSym: 0.000000\t\tSpars: 0.000840\n",
      "\t TVw: 0.808943 | TVb: 2.251949 | GSw: -0.646097 | GSb: -0.338432 | TSUw: -0.394897 | TSUb: -0.031036\n",
      "\n",
      "Train Epoch: 5310 [4000/8000 (50%)]\tBatch Loss: 0.013326\tLearning Rate (w_theta): 0.001000\t TIME:1101.9s\n",
      "\t\t\t\tDisc: 0.012470\t\tSym: 0.000000\t\tSpars: 0.000856\n",
      "\t TVw: 0.808503 | TVb: 2.252151 | GSw: -0.645965 | GSb: -0.338248 | TSUw: -0.394930 | TSUb: -0.031046\n",
      "Validating epoch 5310...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012944473970537381\n",
      "Average validation loss: 0.013448711420736696\n",
      "Training epoch 5311...\n",
      "\n",
      "Train Epoch: 5311 [0/8000 (0%)]\tBatch Loss: 0.012913\tLearning Rate (w_theta): 0.001000\t TIME:1104.7s\n",
      "\t\t\t\tDisc: 0.012145\t\tSym: 0.000000\t\tSpars: 0.000768\n",
      "\t TVw: 0.808104 | TVb: 2.252359 | GSw: -0.645824 | GSb: -0.338051 | TSUw: -0.394776 | TSUb: -0.030943\n",
      "\n",
      "Train Epoch: 5311 [4000/8000 (50%)]\tBatch Loss: 0.013351\tLearning Rate (w_theta): 0.001000\t TIME:1106.0s\n",
      "\t\t\t\tDisc: 0.012561\t\tSym: 0.000000\t\tSpars: 0.000790\n",
      "\t TVw: 0.807596 | TVb: 2.252576 | GSw: -0.645692 | GSb: -0.337867 | TSUw: -0.394801 | TSUb: -0.030946\n",
      "Validating epoch 5311...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012944228741287046\n",
      "Average validation loss: 0.01344772057729129\n",
      "Training epoch 5312...\n",
      "\n",
      "Train Epoch: 5312 [0/8000 (0%)]\tBatch Loss: 0.012488\tLearning Rate (w_theta): 0.001000\t TIME:1108.2s\n",
      "\t\t\t\tDisc: 0.011614\t\tSym: 0.000000\t\tSpars: 0.000874\n",
      "\t TVw: 0.807406 | TVb: 2.252821 | GSw: -0.645559 | GSb: -0.337680 | TSUw: -0.394802 | TSUb: -0.030937\n",
      "\n",
      "Train Epoch: 5312 [4000/8000 (50%)]\tBatch Loss: 0.013066\tLearning Rate (w_theta): 0.001000\t TIME:1109.4s\n",
      "\t\t\t\tDisc: 0.012160\t\tSym: 0.000000\t\tSpars: 0.000906\n",
      "\t TVw: 0.807151 | TVb: 2.253020 | GSw: -0.645440 | GSb: -0.337511 | TSUw: -0.395045 | TSUb: -0.031074\n",
      "Validating epoch 5312...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012943417472696383\n",
      "Average validation loss: 0.013447080711937249\n",
      "Training epoch 5313...\n",
      "\n",
      "Train Epoch: 5313 [0/8000 (0%)]\tBatch Loss: 0.013184\tLearning Rate (w_theta): 0.001000\t TIME:1111.7s\n",
      "\t\t\t\tDisc: 0.012357\t\tSym: 0.000000\t\tSpars: 0.000827\n",
      "\t TVw: 0.806970 | TVb: 2.253245 | GSw: -0.645300 | GSb: -0.337317 | TSUw: -0.394945 | TSUb: -0.031004\n",
      "\n",
      "Train Epoch: 5313 [4000/8000 (50%)]\tBatch Loss: 0.012339\tLearning Rate (w_theta): 0.001000\t TIME:1112.9s\n",
      "\t\t\t\tDisc: 0.011658\t\tSym: 0.000000\t\tSpars: 0.000681\n",
      "\t TVw: 0.807006 | TVb: 2.253489 | GSw: -0.645161 | GSb: -0.337123 | TSUw: -0.394874 | TSUb: -0.030951\n",
      "Validating epoch 5313...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012942453114025946\n",
      "Average validation loss: 0.013445844474863014\n",
      "Training epoch 5314...\n",
      "\n",
      "Train Epoch: 5314 [0/8000 (0%)]\tBatch Loss: 0.012996\tLearning Rate (w_theta): 0.001000\t TIME:1115.2s\n",
      "\t\t\t\tDisc: 0.012209\t\tSym: 0.000000\t\tSpars: 0.000788\n",
      "\t TVw: 0.806692 | TVb: 2.253700 | GSw: -0.645028 | GSb: -0.336936 | TSUw: -0.394897 | TSUb: -0.030955\n",
      "\n",
      "Train Epoch: 5314 [4000/8000 (50%)]\tBatch Loss: 0.012721\tLearning Rate (w_theta): 0.001000\t TIME:1116.4s\n",
      "\t\t\t\tDisc: 0.011969\t\tSym: 0.000000\t\tSpars: 0.000752\n",
      "\t TVw: 0.806473 | TVb: 2.253918 | GSw: -0.644904 | GSb: -0.336758 | TSUw: -0.395149 | TSUb: -0.031096\n",
      "Validating epoch 5314...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012941504756303297\n",
      "Average validation loss: 0.013445485795785951\n",
      "Training epoch 5315...\n",
      "\n",
      "Train Epoch: 5315 [0/8000 (0%)]\tBatch Loss: 0.012700\tLearning Rate (w_theta): 0.001000\t TIME:1118.6s\n",
      "\t\t\t\tDisc: 0.012064\t\tSym: 0.000000\t\tSpars: 0.000636\n",
      "\t TVw: 0.806215 | TVb: 2.254155 | GSw: -0.644774 | GSb: -0.336576 | TSUw: -0.395246 | TSUb: -0.031144\n",
      "\n",
      "Train Epoch: 5315 [4000/8000 (50%)]\tBatch Loss: 0.013248\tLearning Rate (w_theta): 0.001000\t TIME:1119.9s\n",
      "\t\t\t\tDisc: 0.012248\t\tSym: 0.000000\t\tSpars: 0.001000\n",
      "\t TVw: 0.806092 | TVb: 2.254395 | GSw: -0.644640 | GSb: -0.336385 | TSUw: -0.395281 | TSUb: -0.031155\n",
      "Validating epoch 5315...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012940633296017835\n",
      "Average validation loss: 0.013444607512688897\n",
      "Training epoch 5316...\n",
      "\n",
      "Train Epoch: 5316 [0/8000 (0%)]\tBatch Loss: 0.012529\tLearning Rate (w_theta): 0.001000\t TIME:1122.1s\n",
      "\t\t\t\tDisc: 0.011578\t\tSym: 0.000000\t\tSpars: 0.000952\n",
      "\t TVw: 0.805935 | TVb: 2.254630 | GSw: -0.644512 | GSb: -0.336204 | TSUw: -0.395405 | TSUb: -0.031220\n",
      "\n",
      "Train Epoch: 5316 [4000/8000 (50%)]\tBatch Loss: 0.013003\tLearning Rate (w_theta): 0.001000\t TIME:1123.3s\n",
      "\t\t\t\tDisc: 0.012334\t\tSym: 0.000000\t\tSpars: 0.000669\n",
      "\t TVw: 0.805441 | TVb: 2.254783 | GSw: -0.644357 | GSb: -0.335993 | TSUw: -0.395002 | TSUb: -0.030966\n",
      "Validating epoch 5316...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012940444697367508\n",
      "Average validation loss: 0.013443490530498614\n",
      "Training epoch 5317...\n",
      "\n",
      "Train Epoch: 5317 [0/8000 (0%)]\tBatch Loss: 0.012763\tLearning Rate (w_theta): 0.001000\t TIME:1125.5s\n",
      "\t\t\t\tDisc: 0.011892\t\tSym: 0.000000\t\tSpars: 0.000871\n",
      "\t TVw: 0.805404 | TVb: 2.255028 | GSw: -0.644237 | GSb: -0.335821 | TSUw: -0.395312 | TSUb: -0.031143\n",
      "\n",
      "Train Epoch: 5317 [4000/8000 (50%)]\tBatch Loss: 0.012470\tLearning Rate (w_theta): 0.001000\t TIME:1126.8s\n",
      "\t\t\t\tDisc: 0.011948\t\tSym: 0.000000\t\tSpars: 0.000522\n",
      "\t TVw: 0.805041 | TVb: 2.255224 | GSw: -0.644099 | GSb: -0.335629 | TSUw: -0.395219 | TSUb: -0.031074\n",
      "Validating epoch 5317...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012939333490797466\n",
      "Average validation loss: 0.013443070829001357\n",
      "Training epoch 5318...\n",
      "\n",
      "Train Epoch: 5318 [0/8000 (0%)]\tBatch Loss: 0.013091\tLearning Rate (w_theta): 0.001000\t TIME:1129.1s\n",
      "\t\t\t\tDisc: 0.012077\t\tSym: 0.000000\t\tSpars: 0.001014\n",
      "\t TVw: 0.805078 | TVb: 2.255508 | GSw: -0.643991 | GSb: -0.335469 | TSUw: -0.395765 | TSUb: -0.031394\n",
      "\n",
      "Train Epoch: 5318 [4000/8000 (50%)]\tBatch Loss: 0.012922\tLearning Rate (w_theta): 0.001000\t TIME:1130.3s\n",
      "\t\t\t\tDisc: 0.012091\t\tSym: 0.000000\t\tSpars: 0.000831\n",
      "\t TVw: 0.805373 | TVb: 2.255782 | GSw: -0.643881 | GSb: -0.335307 | TSUw: -0.396340 | TSUb: -0.031733\n",
      "Validating epoch 5318...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012937688589871746\n",
      "Average validation loss: 0.01344302406246858\n",
      "Training epoch 5319...\n",
      "\n",
      "Train Epoch: 5319 [0/8000 (0%)]\tBatch Loss: 0.013713\tLearning Rate (w_theta): 0.001000\t TIME:1132.5s\n",
      "\t\t\t\tDisc: 0.012634\t\tSym: 0.000000\t\tSpars: 0.001079\n",
      "\t TVw: 0.805407 | TVb: 2.256036 | GSw: -0.643757 | GSb: -0.335129 | TSUw: -0.396564 | TSUb: -0.031856\n",
      "\n",
      "Train Epoch: 5319 [4000/8000 (50%)]\tBatch Loss: 0.012744\tLearning Rate (w_theta): 0.001000\t TIME:1133.7s\n",
      "\t\t\t\tDisc: 0.012102\t\tSym: 0.000000\t\tSpars: 0.000642\n",
      "\t TVw: 0.805001 | TVb: 2.256236 | GSw: -0.643586 | GSb: -0.334901 | TSUw: -0.395862 | TSUb: -0.031415\n",
      "Validating epoch 5319...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012937118779881381\n",
      "Average validation loss: 0.01344088834278645\n",
      "Training epoch 5320...\n",
      "\n",
      "Train Epoch: 5320 [0/8000 (0%)]\tBatch Loss: 0.012713\tLearning Rate (w_theta): 0.001000\t TIME:1136.0s\n",
      "\t\t\t\tDisc: 0.012087\t\tSym: 0.000000\t\tSpars: 0.000627\n",
      "\t TVw: 0.804478 | TVb: 2.256387 | GSw: -0.643448 | GSb: -0.334709 | TSUw: -0.395784 | TSUb: -0.031352\n",
      "\n",
      "Train Epoch: 5320 [4000/8000 (50%)]\tBatch Loss: 0.012929\tLearning Rate (w_theta): 0.001000\t TIME:1137.2s\n",
      "\t\t\t\tDisc: 0.012329\t\tSym: 0.000000\t\tSpars: 0.000600\n",
      "\t TVw: 0.803967 | TVb: 2.256501 | GSw: -0.643319 | GSb: -0.334526 | TSUw: -0.395902 | TSUb: -0.031410\n",
      "Validating epoch 5320...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01293628157754642\n",
      "Average validation loss: 0.013440942597947206\n",
      "Training epoch 5321...\n",
      "\n",
      "Train Epoch: 5321 [0/8000 (0%)]\tBatch Loss: 0.012487\tLearning Rate (w_theta): 0.001000\t TIME:1140.1s\n",
      "\t\t\t\tDisc: 0.011856\t\tSym: 0.000000\t\tSpars: 0.000630\n",
      "\t TVw: 0.803600 | TVb: 2.256682 | GSw: -0.643188 | GSb: -0.334342 | TSUw: -0.395990 | TSUb: -0.031450\n",
      "\n",
      "Train Epoch: 5321 [4000/8000 (50%)]\tBatch Loss: 0.012982\tLearning Rate (w_theta): 0.001000\t TIME:1141.3s\n",
      "\t\t\t\tDisc: 0.012228\t\tSym: 0.000000\t\tSpars: 0.000754\n",
      "\t TVw: 0.803129 | TVb: 2.256848 | GSw: -0.643061 | GSb: -0.334161 | TSUw: -0.396129 | TSUb: -0.031520\n",
      "Validating epoch 5321...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012936020616832614\n",
      "Average validation loss: 0.013440607025556653\n",
      "Training epoch 5322...\n",
      "\n",
      "Train Epoch: 5322 [0/8000 (0%)]\tBatch Loss: 0.013532\tLearning Rate (w_theta): 0.001000\t TIME:1143.6s\n",
      "\t\t\t\tDisc: 0.012610\t\tSym: 0.000000\t\tSpars: 0.000922\n",
      "\t TVw: 0.803063 | TVb: 2.257086 | GSw: -0.642927 | GSb: -0.333974 | TSUw: -0.396211 | TSUb: -0.031557\n",
      "\n",
      "Train Epoch: 5322 [4000/8000 (50%)]\tBatch Loss: 0.012735\tLearning Rate (w_theta): 0.001000\t TIME:1144.9s\n",
      "\t\t\t\tDisc: 0.012035\t\tSym: 0.000000\t\tSpars: 0.000700\n",
      "\t TVw: 0.803069 | TVb: 2.257316 | GSw: -0.642795 | GSb: -0.333788 | TSUw: -0.396356 | TSUb: -0.031632\n",
      "Validating epoch 5322...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01293494829404499\n",
      "Average validation loss: 0.013439706583451297\n",
      "Training epoch 5323...\n",
      "\n",
      "Train Epoch: 5323 [0/8000 (0%)]\tBatch Loss: 0.012489\tLearning Rate (w_theta): 0.001000\t TIME:1147.1s\n",
      "\t\t\t\tDisc: 0.011825\t\tSym: 0.000000\t\tSpars: 0.000664\n",
      "\t TVw: 0.803024 | TVb: 2.257541 | GSw: -0.642663 | GSb: -0.333603 | TSUw: -0.396474 | TSUb: -0.031691\n",
      "\n",
      "Train Epoch: 5323 [4000/8000 (50%)]\tBatch Loss: 0.012862\tLearning Rate (w_theta): 0.001000\t TIME:1148.3s\n",
      "\t\t\t\tDisc: 0.011960\t\tSym: 0.000000\t\tSpars: 0.000902\n",
      "\t TVw: 0.802991 | TVb: 2.257768 | GSw: -0.642523 | GSb: -0.333412 | TSUw: -0.396408 | TSUb: -0.031636\n",
      "Validating epoch 5323...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012933818386683317\n",
      "Average validation loss: 0.01343873085964104\n",
      "Training epoch 5324...\n",
      "\n",
      "Train Epoch: 5324 [0/8000 (0%)]\tBatch Loss: 0.012650\tLearning Rate (w_theta): 0.001000\t TIME:1150.5s\n",
      "\t\t\t\tDisc: 0.012090\t\tSym: 0.000000\t\tSpars: 0.000560\n",
      "\t TVw: 0.802722 | TVb: 2.257954 | GSw: -0.642392 | GSb: -0.333227 | TSUw: -0.396511 | TSUb: -0.031684\n",
      "\n",
      "Train Epoch: 5324 [4000/8000 (50%)]\tBatch Loss: 0.013208\tLearning Rate (w_theta): 0.001000\t TIME:1151.8s\n",
      "\t\t\t\tDisc: 0.012139\t\tSym: 0.000000\t\tSpars: 0.001069\n",
      "\t TVw: 0.802030 | TVb: 2.258047 | GSw: -0.642255 | GSb: -0.333034 | TSUw: -0.396459 | TSUb: -0.031637\n",
      "Validating epoch 5324...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012933671532633778\n",
      "Average validation loss: 0.013438354125125767\n",
      "Training epoch 5325...\n",
      "\n",
      "Train Epoch: 5325 [0/8000 (0%)]\tBatch Loss: 0.012498\tLearning Rate (w_theta): 0.001000\t TIME:1154.0s\n",
      "\t\t\t\tDisc: 0.011881\t\tSym: 0.000000\t\tSpars: 0.000617\n",
      "\t TVw: 0.801872 | TVb: 2.258247 | GSw: -0.642118 | GSb: -0.332841 | TSUw: -0.396471 | TSUb: -0.031630\n",
      "\n",
      "Train Epoch: 5325 [4000/8000 (50%)]\tBatch Loss: 0.012970\tLearning Rate (w_theta): 0.001000\t TIME:1155.2s\n",
      "\t\t\t\tDisc: 0.012051\t\tSym: 0.000000\t\tSpars: 0.000919\n",
      "\t TVw: 0.801666 | TVb: 2.258404 | GSw: -0.641977 | GSb: -0.332645 | TSUw: -0.396435 | TSUb: -0.031593\n",
      "Validating epoch 5325...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012933068771729955\n",
      "Average validation loss: 0.013437486067720298\n",
      "Training epoch 5326...\n",
      "\n",
      "Train Epoch: 5326 [0/8000 (0%)]\tBatch Loss: 0.013436\tLearning Rate (w_theta): 0.001000\t TIME:1157.4s\n",
      "\t\t\t\tDisc: 0.012453\t\tSym: 0.000000\t\tSpars: 0.000982\n",
      "\t TVw: 0.801790 | TVb: 2.258635 | GSw: -0.641845 | GSb: -0.332458 | TSUw: -0.396588 | TSUb: -0.031673\n",
      "\n",
      "Train Epoch: 5326 [4000/8000 (50%)]\tBatch Loss: 0.012704\tLearning Rate (w_theta): 0.001000\t TIME:1158.7s\n",
      "\t\t\t\tDisc: 0.012033\t\tSym: 0.000000\t\tSpars: 0.000670\n",
      "\t TVw: 0.802014 | TVb: 2.258913 | GSw: -0.641701 | GSb: -0.332257 | TSUw: -0.396564 | TSUb: -0.031646\n",
      "Validating epoch 5326...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012931764258813518\n",
      "Average validation loss: 0.013436182487494435\n",
      "Training epoch 5327...\n",
      "\n",
      "Train Epoch: 5327 [0/8000 (0%)]\tBatch Loss: 0.013202\tLearning Rate (w_theta): 0.001000\t TIME:1160.9s\n",
      "\t\t\t\tDisc: 0.012257\t\tSym: 0.000000\t\tSpars: 0.000945\n",
      "\t TVw: 0.801978 | TVb: 2.259132 | GSw: -0.641575 | GSb: -0.332075 | TSUw: -0.396773 | TSUb: -0.031759\n",
      "\n",
      "Train Epoch: 5327 [4000/8000 (50%)]\tBatch Loss: 0.012935\tLearning Rate (w_theta): 0.001000\t TIME:1162.2s\n",
      "\t\t\t\tDisc: 0.011915\t\tSym: 0.000000\t\tSpars: 0.001020\n",
      "\t TVw: 0.801704 | TVb: 2.259333 | GSw: -0.641453 | GSb: -0.331902 | TSUw: -0.397117 | TSUb: -0.031954\n",
      "Validating epoch 5327...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012930609653527738\n",
      "Average validation loss: 0.013436191176900232\n",
      "Training epoch 5328...\n",
      "\n",
      "Train Epoch: 5328 [0/8000 (0%)]\tBatch Loss: 0.012885\tLearning Rate (w_theta): 0.001000\t TIME:1164.4s\n",
      "\t\t\t\tDisc: 0.012045\t\tSym: 0.000000\t\tSpars: 0.000840\n",
      "\t TVw: 0.801443 | TVb: 2.259507 | GSw: -0.641319 | GSb: -0.331712 | TSUw: -0.397178 | TSUb: -0.031975\n",
      "\n",
      "Train Epoch: 5328 [4000/8000 (50%)]\tBatch Loss: 0.012698\tLearning Rate (w_theta): 0.001000\t TIME:1165.6s\n",
      "\t\t\t\tDisc: 0.012046\t\tSym: 0.000000\t\tSpars: 0.000651\n",
      "\t TVw: 0.801404 | TVb: 2.259680 | GSw: -0.641168 | GSb: -0.331503 | TSUw: -0.396937 | TSUb: -0.031812\n",
      "Validating epoch 5328...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012930122797250618\n",
      "Average validation loss: 0.013434678966558209\n",
      "Training epoch 5329...\n",
      "\n",
      "Train Epoch: 5329 [0/8000 (0%)]\tBatch Loss: 0.013254\tLearning Rate (w_theta): 0.001000\t TIME:1167.8s\n",
      "\t\t\t\tDisc: 0.012084\t\tSym: 0.000000\t\tSpars: 0.001169\n",
      "\t TVw: 0.801217 | TVb: 2.259858 | GSw: -0.641029 | GSb: -0.331309 | TSUw: -0.396913 | TSUb: -0.031782\n",
      "\n",
      "Train Epoch: 5329 [4000/8000 (50%)]\tBatch Loss: 0.012895\tLearning Rate (w_theta): 0.001000\t TIME:1169.1s\n",
      "\t\t\t\tDisc: 0.011882\t\tSym: 0.000000\t\tSpars: 0.001014\n",
      "\t TVw: 0.801019 | TVb: 2.260036 | GSw: -0.640895 | GSb: -0.331121 | TSUw: -0.397019 | TSUb: -0.031831\n",
      "Validating epoch 5329...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0129294468979517\n",
      "Average validation loss: 0.013434290876781321\n",
      "Training epoch 5330...\n",
      "\n",
      "Train Epoch: 5330 [0/8000 (0%)]\tBatch Loss: 0.012609\tLearning Rate (w_theta): 0.001000\t TIME:1171.3s\n",
      "\t\t\t\tDisc: 0.011973\t\tSym: 0.000000\t\tSpars: 0.000636\n",
      "\t TVw: 0.800580 | TVb: 2.260171 | GSw: -0.640755 | GSb: -0.330926 | TSUw: -0.396988 | TSUb: -0.031795\n",
      "\n",
      "Train Epoch: 5330 [4000/8000 (50%)]\tBatch Loss: 0.012731\tLearning Rate (w_theta): 0.001000\t TIME:1172.5s\n",
      "\t\t\t\tDisc: 0.012234\t\tSym: 0.000000\t\tSpars: 0.000497\n",
      "\t TVw: 0.800431 | TVb: 2.260368 | GSw: -0.640628 | GSb: -0.330745 | TSUw: -0.397169 | TSUb: -0.031891\n",
      "Validating epoch 5330...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012928871459821701\n",
      "Average validation loss: 0.013433929017317551\n",
      "Training epoch 5331...\n",
      "\n",
      "Train Epoch: 5331 [0/8000 (0%)]\tBatch Loss: 0.013035\tLearning Rate (w_theta): 0.001000\t TIME:1175.5s\n",
      "\t\t\t\tDisc: 0.012194\t\tSym: 0.000000\t\tSpars: 0.000841\n",
      "\t TVw: 0.800189 | TVb: 2.260560 | GSw: -0.640497 | GSb: -0.330560 | TSUw: -0.397299 | TSUb: -0.031954\n",
      "\n",
      "Train Epoch: 5331 [4000/8000 (50%)]\tBatch Loss: 0.013132\tLearning Rate (w_theta): 0.001000\t TIME:1176.7s\n",
      "\t\t\t\tDisc: 0.012292\t\tSym: 0.000000\t\tSpars: 0.000840\n",
      "\t TVw: 0.800038 | TVb: 2.260747 | GSw: -0.640374 | GSb: -0.330383 | TSUw: -0.397608 | TSUb: -0.032128\n",
      "Validating epoch 5331...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012928203022871145\n",
      "Average validation loss: 0.013433745367445377\n",
      "Training epoch 5332...\n",
      "\n",
      "Train Epoch: 5332 [0/8000 (0%)]\tBatch Loss: 0.012593\tLearning Rate (w_theta): 0.001000\t TIME:1179.0s\n",
      "\t\t\t\tDisc: 0.011747\t\tSym: 0.000000\t\tSpars: 0.000847\n",
      "\t TVw: 0.799831 | TVb: 2.260912 | GSw: -0.640234 | GSb: -0.330189 | TSUw: -0.397611 | TSUb: -0.032113\n",
      "\n",
      "Train Epoch: 5332 [4000/8000 (50%)]\tBatch Loss: 0.012888\tLearning Rate (w_theta): 0.001000\t TIME:1180.2s\n",
      "\t\t\t\tDisc: 0.011931\t\tSym: 0.000000\t\tSpars: 0.000956\n",
      "\t TVw: 0.799856 | TVb: 2.261138 | GSw: -0.640103 | GSb: -0.330002 | TSUw: -0.397798 | TSUb: -0.032212\n",
      "Validating epoch 5332...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012927229585113595\n",
      "Average validation loss: 0.013432731878253137\n",
      "Training epoch 5333...\n",
      "\n",
      "Train Epoch: 5333 [0/8000 (0%)]\tBatch Loss: 0.013171\tLearning Rate (w_theta): 0.001000\t TIME:1182.4s\n",
      "\t\t\t\tDisc: 0.012058\t\tSym: 0.000000\t\tSpars: 0.001113\n",
      "\t TVw: 0.799618 | TVb: 2.261293 | GSw: -0.639958 | GSb: -0.329801 | TSUw: -0.397695 | TSUb: -0.032130\n",
      "\n",
      "Train Epoch: 5333 [4000/8000 (50%)]\tBatch Loss: 0.012734\tLearning Rate (w_theta): 0.001000\t TIME:1183.6s\n",
      "\t\t\t\tDisc: 0.011903\t\tSym: 0.000000\t\tSpars: 0.000831\n",
      "\t TVw: 0.799234 | TVb: 2.261414 | GSw: -0.639808 | GSb: -0.329593 | TSUw: -0.397496 | TSUb: -0.031989\n",
      "Validating epoch 5333...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012926729054359768\n",
      "Average validation loss: 0.013431612663180006\n",
      "Training epoch 5334...\n",
      "\n",
      "Train Epoch: 5334 [0/8000 (0%)]\tBatch Loss: 0.012963\tLearning Rate (w_theta): 0.001000\t TIME:1185.9s\n",
      "\t\t\t\tDisc: 0.012080\t\tSym: 0.000000\t\tSpars: 0.000882\n",
      "\t TVw: 0.799033 | TVb: 2.261580 | GSw: -0.639662 | GSb: -0.329391 | TSUw: -0.397367 | TSUb: -0.031892\n",
      "\n",
      "Train Epoch: 5334 [4000/8000 (50%)]\tBatch Loss: 0.013289\tLearning Rate (w_theta): 0.001000\t TIME:1187.1s\n",
      "\t\t\t\tDisc: 0.012368\t\tSym: 0.000000\t\tSpars: 0.000920\n",
      "\t TVw: 0.798737 | TVb: 2.261730 | GSw: -0.639531 | GSb: -0.329206 | TSUw: -0.397491 | TSUb: -0.031950\n",
      "Validating epoch 5334...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012926616593796887\n",
      "Average validation loss: 0.013431106029389345\n",
      "Training epoch 5335...\n",
      "\n",
      "Train Epoch: 5335 [0/8000 (0%)]\tBatch Loss: 0.012444\tLearning Rate (w_theta): 0.001000\t TIME:1189.3s\n",
      "\t\t\t\tDisc: 0.011782\t\tSym: 0.000000\t\tSpars: 0.000662\n",
      "\t TVw: 0.798371 | TVb: 2.261861 | GSw: -0.639380 | GSb: -0.329000 | TSUw: -0.397300 | TSUb: -0.031814\n",
      "\n",
      "Train Epoch: 5335 [4000/8000 (50%)]\tBatch Loss: 0.013002\tLearning Rate (w_theta): 0.001000\t TIME:1190.6s\n",
      "\t\t\t\tDisc: 0.012010\t\tSym: 0.000000\t\tSpars: 0.000992\n",
      "\t TVw: 0.797574 | TVb: 2.262003 | GSw: -0.639219 | GSb: -0.328782 | TSUw: -0.396842 | TSUb: -0.031512\n",
      "Validating epoch 5335...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012927353513280093\n",
      "Average validation loss: 0.013430389870887634\n",
      "Training epoch 5336...\n",
      "\n",
      "Train Epoch: 5336 [0/8000 (0%)]\tBatch Loss: 0.013053\tLearning Rate (w_theta): 0.001000\t TIME:1192.8s\n",
      "\t\t\t\tDisc: 0.012032\t\tSym: 0.000000\t\tSpars: 0.001022\n",
      "\t TVw: 0.797622 | TVb: 2.262225 | GSw: -0.639100 | GSb: -0.328609 | TSUw: -0.397263 | TSUb: -0.031757\n",
      "\n",
      "Train Epoch: 5336 [4000/8000 (50%)]\tBatch Loss: 0.012629\tLearning Rate (w_theta): 0.001000\t TIME:1194.1s\n",
      "\t\t\t\tDisc: 0.011913\t\tSym: 0.000000\t\tSpars: 0.000717\n",
      "\t TVw: 0.797993 | TVb: 2.262483 | GSw: -0.639006 | GSb: -0.328463 | TSUw: -0.398225 | TSUb: -0.032339\n",
      "Validating epoch 5336...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012926045741149483\n",
      "Average validation loss: 0.01343132485442186\n",
      "Training epoch 5337...\n",
      "\n",
      "Train Epoch: 5337 [0/8000 (0%)]\tBatch Loss: 0.012918\tLearning Rate (w_theta): 0.001000\t TIME:1196.3s\n",
      "\t\t\t\tDisc: 0.012215\t\tSym: 0.000000\t\tSpars: 0.000704\n",
      "\t TVw: 0.797779 | TVb: 2.262635 | GSw: -0.638884 | GSb: -0.328288 | TSUw: -0.398562 | TSUb: -0.032531\n",
      "\n",
      "Train Epoch: 5337 [4000/8000 (50%)]\tBatch Loss: 0.012914\tLearning Rate (w_theta): 0.001000\t TIME:1197.5s\n",
      "\t\t\t\tDisc: 0.012007\t\tSym: 0.000000\t\tSpars: 0.000906\n",
      "\t TVw: 0.797003 | TVb: 2.262671 | GSw: -0.638752 | GSb: -0.328102 | TSUw: -0.398683 | TSUb: -0.032585\n",
      "Validating epoch 5337...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012924697955483315\n",
      "Average validation loss: 0.013431284109447888\n",
      "Training epoch 5338...\n",
      "\n",
      "Train Epoch: 5338 [0/8000 (0%)]\tBatch Loss: 0.013573\tLearning Rate (w_theta): 0.001000\t TIME:1199.7s\n",
      "\t\t\t\tDisc: 0.012846\t\tSym: 0.000000\t\tSpars: 0.000727\n",
      "\t TVw: 0.797014 | TVb: 2.262845 | GSw: -0.638601 | GSb: -0.327894 | TSUw: -0.398489 | TSUb: -0.032445\n",
      "\n",
      "Train Epoch: 5338 [4000/8000 (50%)]\tBatch Loss: 0.013169\tLearning Rate (w_theta): 0.001000\t TIME:1201.0s\n",
      "\t\t\t\tDisc: 0.012225\t\tSym: 0.000000\t\tSpars: 0.000944\n",
      "\t TVw: 0.796479 | TVb: 2.262948 | GSw: -0.638429 | GSb: -0.327664 | TSUw: -0.397840 | TSUb: -0.032020\n",
      "Validating epoch 5338...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012925049932500097\n",
      "Average validation loss: 0.013429346861628205\n",
      "Training epoch 5339...\n",
      "\n",
      "Train Epoch: 5339 [0/8000 (0%)]\tBatch Loss: 0.012526\tLearning Rate (w_theta): 0.001000\t TIME:1203.2s\n",
      "\t\t\t\tDisc: 0.011806\t\tSym: 0.000000\t\tSpars: 0.000720\n",
      "\t TVw: 0.796566 | TVb: 2.263143 | GSw: -0.638290 | GSb: -0.327470 | TSUw: -0.397918 | TSUb: -0.032050\n",
      "\n",
      "Train Epoch: 5339 [4000/8000 (50%)]\tBatch Loss: 0.013016\tLearning Rate (w_theta): 0.001000\t TIME:1204.4s\n",
      "\t\t\t\tDisc: 0.012158\t\tSym: 0.000000\t\tSpars: 0.000858\n",
      "\t TVw: 0.796566 | TVb: 2.263349 | GSw: -0.638169 | GSb: -0.327295 | TSUw: -0.398290 | TSUb: -0.032264\n",
      "Validating epoch 5339...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012923856376377291\n",
      "Average validation loss: 0.013428754639550292\n",
      "Training epoch 5340...\n",
      "\n",
      "Train Epoch: 5340 [0/8000 (0%)]\tBatch Loss: 0.013484\tLearning Rate (w_theta): 0.001000\t TIME:1206.7s\n",
      "\t\t\t\tDisc: 0.012477\t\tSym: 0.000000\t\tSpars: 0.001007\n",
      "\t TVw: 0.796803 | TVb: 2.263578 | GSw: -0.638030 | GSb: -0.327102 | TSUw: -0.398371 | TSUb: -0.032296\n",
      "\n",
      "Train Epoch: 5340 [4000/8000 (50%)]\tBatch Loss: 0.012305\tLearning Rate (w_theta): 0.001000\t TIME:1208.0s\n",
      "\t\t\t\tDisc: 0.011516\t\tSym: 0.000000\t\tSpars: 0.000789\n",
      "\t TVw: 0.797078 | TVb: 2.263803 | GSw: -0.637908 | GSb: -0.326925 | TSUw: -0.398767 | TSUb: -0.032525\n",
      "Validating epoch 5340...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012922569509855819\n",
      "Average validation loss: 0.013427949204669946\n",
      "Training epoch 5341...\n",
      "\n",
      "Train Epoch: 5341 [0/8000 (0%)]\tBatch Loss: 0.013027\tLearning Rate (w_theta): 0.001000\t TIME:1210.8s\n",
      "\t\t\t\tDisc: 0.012287\t\tSym: 0.000000\t\tSpars: 0.000740\n",
      "\t TVw: 0.796876 | TVb: 2.263959 | GSw: -0.637755 | GSb: -0.326714 | TSUw: -0.398532 | TSUb: -0.032359\n",
      "\n",
      "Train Epoch: 5341 [4000/8000 (50%)]\tBatch Loss: 0.012936\tLearning Rate (w_theta): 0.001000\t TIME:1212.0s\n",
      "\t\t\t\tDisc: 0.012091\t\tSym: 0.000000\t\tSpars: 0.000846\n",
      "\t TVw: 0.796703 | TVb: 2.264138 | GSw: -0.637604 | GSb: -0.326504 | TSUw: -0.398342 | TSUb: -0.032221\n",
      "Validating epoch 5341...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012921649500791787\n",
      "Average validation loss: 0.013426638406247495\n",
      "Training epoch 5342...\n",
      "\n",
      "Train Epoch: 5342 [0/8000 (0%)]\tBatch Loss: 0.013415\tLearning Rate (w_theta): 0.001000\t TIME:1214.2s\n",
      "\t\t\t\tDisc: 0.012570\t\tSym: 0.000000\t\tSpars: 0.000845\n",
      "\t TVw: 0.796383 | TVb: 2.264267 | GSw: -0.637454 | GSb: -0.326299 | TSUw: -0.398201 | TSUb: -0.032112\n",
      "\n",
      "Train Epoch: 5342 [4000/8000 (50%)]\tBatch Loss: 0.012685\tLearning Rate (w_theta): 0.001000\t TIME:1215.5s\n",
      "\t\t\t\tDisc: 0.011989\t\tSym: 0.000000\t\tSpars: 0.000696\n",
      "\t TVw: 0.796545 | TVb: 2.264499 | GSw: -0.637327 | GSb: -0.326117 | TSUw: -0.398553 | TSUb: -0.032314\n",
      "Validating epoch 5342...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0129212757752591\n",
      "Average validation loss: 0.01342687168138129\n",
      "Training epoch 5343...\n",
      "\n",
      "Train Epoch: 5343 [0/8000 (0%)]\tBatch Loss: 0.013066\tLearning Rate (w_theta): 0.001000\t TIME:1217.7s\n",
      "\t\t\t\tDisc: 0.012263\t\tSym: 0.000000\t\tSpars: 0.000803\n",
      "\t TVw: 0.796165 | TVb: 2.264632 | GSw: -0.637203 | GSb: -0.325940 | TSUw: -0.398902 | TSUb: -0.032511\n",
      "\n",
      "Train Epoch: 5343 [4000/8000 (50%)]\tBatch Loss: 0.012995\tLearning Rate (w_theta): 0.001000\t TIME:1219.0s\n",
      "\t\t\t\tDisc: 0.012170\t\tSym: 0.000000\t\tSpars: 0.000825\n",
      "\t TVw: 0.795920 | TVb: 2.264778 | GSw: -0.637028 | GSb: -0.325706 | TSUw: -0.398285 | TSUb: -0.032104\n",
      "Validating epoch 5343...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01292123731077974\n",
      "Average validation loss: 0.013425216093637572\n",
      "Training epoch 5344...\n",
      "\n",
      "Train Epoch: 5344 [0/8000 (0%)]\tBatch Loss: 0.012815\tLearning Rate (w_theta): 0.001000\t TIME:1221.1s\n",
      "\t\t\t\tDisc: 0.012018\t\tSym: 0.000000\t\tSpars: 0.000796\n",
      "\t TVw: 0.795664 | TVb: 2.264900 | GSw: -0.636891 | GSb: -0.325513 | TSUw: -0.398364 | TSUb: -0.032134\n",
      "\n",
      "Train Epoch: 5344 [4000/8000 (50%)]\tBatch Loss: 0.012739\tLearning Rate (w_theta): 0.001000\t TIME:1222.4s\n",
      "\t\t\t\tDisc: 0.011754\t\tSym: 0.000000\t\tSpars: 0.000985\n",
      "\t TVw: 0.795854 | TVb: 2.265114 | GSw: -0.636785 | GSb: -0.325355 | TSUw: -0.399113 | TSUb: -0.032586\n",
      "Validating epoch 5344...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012920036945686188\n",
      "Average validation loss: 0.013425898098739812\n",
      "Training epoch 5345...\n",
      "\n",
      "Train Epoch: 5345 [0/8000 (0%)]\tBatch Loss: 0.013306\tLearning Rate (w_theta): 0.001000\t TIME:1224.7s\n",
      "\t\t\t\tDisc: 0.012481\t\tSym: 0.000000\t\tSpars: 0.000825\n",
      "\t TVw: 0.795615 | TVb: 2.265254 | GSw: -0.636660 | GSb: -0.325175 | TSUw: -0.399407 | TSUb: -0.032751\n",
      "\n",
      "Train Epoch: 5345 [4000/8000 (50%)]\tBatch Loss: 0.013381\tLearning Rate (w_theta): 0.001000\t TIME:1225.9s\n",
      "\t\t\t\tDisc: 0.012451\t\tSym: 0.000000\t\tSpars: 0.000930\n",
      "\t TVw: 0.795283 | TVb: 2.265373 | GSw: -0.636514 | GSb: -0.324973 | TSUw: -0.399330 | TSUb: -0.032680\n",
      "Validating epoch 5345...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012919015607474209\n",
      "Average validation loss: 0.013425313188005692\n",
      "Training epoch 5346...\n",
      "\n",
      "Train Epoch: 5346 [0/8000 (0%)]\tBatch Loss: 0.013272\tLearning Rate (w_theta): 0.001000\t TIME:1228.1s\n",
      "\t\t\t\tDisc: 0.012139\t\tSym: 0.000000\t\tSpars: 0.001133\n",
      "\t TVw: 0.795217 | TVb: 2.265514 | GSw: -0.636366 | GSb: -0.324769 | TSUw: -0.399254 | TSUb: -0.032611\n",
      "\n",
      "Train Epoch: 5346 [4000/8000 (50%)]\tBatch Loss: 0.012902\tLearning Rate (w_theta): 0.001000\t TIME:1229.4s\n",
      "\t\t\t\tDisc: 0.012066\t\tSym: 0.000000\t\tSpars: 0.000836\n",
      "\t TVw: 0.794856 | TVb: 2.265593 | GSw: -0.636213 | GSb: -0.324560 | TSUw: -0.399088 | TSUb: -0.032485\n",
      "Validating epoch 5346...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012918656793148079\n",
      "Average validation loss: 0.013424513411953427\n",
      "Training epoch 5347...\n",
      "\n",
      "Train Epoch: 5347 [0/8000 (0%)]\tBatch Loss: 0.013152\tLearning Rate (w_theta): 0.001000\t TIME:1231.6s\n",
      "\t\t\t\tDisc: 0.012278\t\tSym: 0.000000\t\tSpars: 0.000874\n",
      "\t TVw: 0.794700 | TVb: 2.265745 | GSw: -0.636070 | GSb: -0.324360 | TSUw: -0.399074 | TSUb: -0.032455\n",
      "\n",
      "Train Epoch: 5347 [4000/8000 (50%)]\tBatch Loss: 0.012697\tLearning Rate (w_theta): 0.001000\t TIME:1232.9s\n",
      "\t\t\t\tDisc: 0.011855\t\tSym: 0.000000\t\tSpars: 0.000842\n",
      "\t TVw: 0.794545 | TVb: 2.265913 | GSw: -0.635906 | GSb: -0.324136 | TSUw: -0.398643 | TSUb: -0.032162\n",
      "Validating epoch 5347...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012918784147194032\n",
      "Average validation loss: 0.013423416093828413\n",
      "Training epoch 5348...\n",
      "\n",
      "Train Epoch: 5348 [0/8000 (0%)]\tBatch Loss: 0.013102\tLearning Rate (w_theta): 0.001000\t TIME:1235.0s\n",
      "\t\t\t\tDisc: 0.012241\t\tSym: 0.000000\t\tSpars: 0.000862\n",
      "\t TVw: 0.794386 | TVb: 2.266077 | GSw: -0.635785 | GSb: -0.323961 | TSUw: -0.399055 | TSUb: -0.032402\n",
      "\n",
      "Train Epoch: 5348 [4000/8000 (50%)]\tBatch Loss: 0.012704\tLearning Rate (w_theta): 0.001000\t TIME:1236.3s\n",
      "\t\t\t\tDisc: 0.012074\t\tSym: 0.000000\t\tSpars: 0.000630\n",
      "\t TVw: 0.794538 | TVb: 2.266306 | GSw: -0.635677 | GSb: -0.323797 | TSUw: -0.399759 | TSUb: -0.032827\n",
      "Validating epoch 5348...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012917885414955638\n",
      "Average validation loss: 0.013423894438230888\n",
      "Training epoch 5349...\n",
      "\n",
      "Train Epoch: 5349 [0/8000 (0%)]\tBatch Loss: 0.012817\tLearning Rate (w_theta): 0.001000\t TIME:1238.5s\n",
      "\t\t\t\tDisc: 0.011899\t\tSym: 0.000000\t\tSpars: 0.000917\n",
      "\t TVw: 0.794259 | TVb: 2.266426 | GSw: -0.635537 | GSb: -0.323601 | TSUw: -0.399823 | TSUb: -0.032845\n",
      "\n",
      "Train Epoch: 5349 [4000/8000 (50%)]\tBatch Loss: 0.013130\tLearning Rate (w_theta): 0.001000\t TIME:1239.9s\n",
      "\t\t\t\tDisc: 0.012248\t\tSym: 0.000000\t\tSpars: 0.000883\n",
      "\t TVw: 0.793696 | TVb: 2.266512 | GSw: -0.635395 | GSb: -0.323405 | TSUw: -0.399811 | TSUb: -0.032813\n",
      "Validating epoch 5349...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012917038897036616\n",
      "Average validation loss: 0.013423519533105341\n",
      "Training epoch 5350...\n",
      "\n",
      "Train Epoch: 5350 [0/8000 (0%)]\tBatch Loss: 0.012887\tLearning Rate (w_theta): 0.001000\t TIME:1242.0s\n",
      "\t\t\t\tDisc: 0.012285\t\tSym: 0.000000\t\tSpars: 0.000602\n",
      "\t TVw: 0.793509 | TVb: 2.266625 | GSw: -0.635237 | GSb: -0.323189 | TSUw: -0.399561 | TSUb: -0.032632\n",
      "\n",
      "Train Epoch: 5350 [4000/8000 (50%)]\tBatch Loss: 0.012786\tLearning Rate (w_theta): 0.001000\t TIME:1243.3s\n",
      "\t\t\t\tDisc: 0.012189\t\tSym: 0.000000\t\tSpars: 0.000597\n",
      "\t TVw: 0.793617 | TVb: 2.266753 | GSw: -0.635073 | GSb: -0.322966 | TSUw: -0.399177 | TSUb: -0.032367\n",
      "Validating epoch 5350...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012917013497706742\n",
      "Average validation loss: 0.013422104372844712\n",
      "Training epoch 5351...\n",
      "\n",
      "Train Epoch: 5351 [0/8000 (0%)]\tBatch Loss: 0.012883\tLearning Rate (w_theta): 0.001000\t TIME:1246.1s\n",
      "\t\t\t\tDisc: 0.012049\t\tSym: 0.000000\t\tSpars: 0.000834\n",
      "\t TVw: 0.793204 | TVb: 2.266846 | GSw: -0.634939 | GSb: -0.322777 | TSUw: -0.399347 | TSUb: -0.032452\n",
      "\n",
      "Train Epoch: 5351 [4000/8000 (50%)]\tBatch Loss: 0.013013\tLearning Rate (w_theta): 0.001000\t TIME:1247.3s\n",
      "\t\t\t\tDisc: 0.012098\t\tSym: 0.000000\t\tSpars: 0.000915\n",
      "\t TVw: 0.793023 | TVb: 2.266957 | GSw: -0.634795 | GSb: -0.322576 | TSUw: -0.399381 | TSUb: -0.032452\n",
      "Validating epoch 5351...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012916673444750483\n",
      "Average validation loss: 0.01342203845628304\n",
      "Training epoch 5352...\n",
      "\n",
      "Train Epoch: 5352 [0/8000 (0%)]\tBatch Loss: 0.012920\tLearning Rate (w_theta): 0.001000\t TIME:1249.6s\n",
      "\t\t\t\tDisc: 0.011905\t\tSym: 0.000000\t\tSpars: 0.001015\n",
      "\t TVw: 0.792947 | TVb: 2.267120 | GSw: -0.634667 | GSb: -0.322392 | TSUw: -0.399737 | TSUb: -0.032658\n",
      "\n",
      "Train Epoch: 5352 [4000/8000 (50%)]\tBatch Loss: 0.013316\tLearning Rate (w_theta): 0.001000\t TIME:1250.8s\n",
      "\t\t\t\tDisc: 0.012374\t\tSym: 0.000000\t\tSpars: 0.000942\n",
      "\t TVw: 0.792946 | TVb: 2.267324 | GSw: -0.634548 | GSb: -0.322221 | TSUw: -0.400254 | TSUb: -0.032966\n",
      "Validating epoch 5352...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012916032566083426\n",
      "Average validation loss: 0.01342219352652059\n",
      "Training epoch 5353...\n",
      "\n",
      "Train Epoch: 5353 [0/8000 (0%)]\tBatch Loss: 0.012430\tLearning Rate (w_theta): 0.001000\t TIME:1253.0s\n",
      "\t\t\t\tDisc: 0.011747\t\tSym: 0.000000\t\tSpars: 0.000683\n",
      "\t TVw: 0.792690 | TVb: 2.267445 | GSw: -0.634397 | GSb: -0.322014 | TSUw: -0.400131 | TSUb: -0.032864\n",
      "\n",
      "Train Epoch: 5353 [4000/8000 (50%)]\tBatch Loss: 0.012942\tLearning Rate (w_theta): 0.001000\t TIME:1254.2s\n",
      "\t\t\t\tDisc: 0.012204\t\tSym: 0.000000\t\tSpars: 0.000738\n",
      "\t TVw: 0.792289 | TVb: 2.267528 | GSw: -0.634220 | GSb: -0.321779 | TSUw: -0.399470 | TSUb: -0.032420\n",
      "Validating epoch 5353...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012916132774389175\n",
      "Average validation loss: 0.0134206717495923\n",
      "Training epoch 5354...\n",
      "\n",
      "Train Epoch: 5354 [0/8000 (0%)]\tBatch Loss: 0.013244\tLearning Rate (w_theta): 0.001000\t TIME:1256.5s\n",
      "\t\t\t\tDisc: 0.012376\t\tSym: 0.000000\t\tSpars: 0.000868\n",
      "\t TVw: 0.792242 | TVb: 2.267680 | GSw: -0.634084 | GSb: -0.321586 | TSUw: -0.399651 | TSUb: -0.032513\n",
      "\n",
      "Train Epoch: 5354 [4000/8000 (50%)]\tBatch Loss: 0.013469\tLearning Rate (w_theta): 0.001000\t TIME:1257.8s\n",
      "\t\t\t\tDisc: 0.012433\t\tSym: 0.000000\t\tSpars: 0.001036\n",
      "\t TVw: 0.792330 | TVb: 2.267915 | GSw: -0.633964 | GSb: -0.321408 | TSUw: -0.400149 | TSUb: -0.032810\n",
      "Validating epoch 5354...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01291485990902602\n",
      "Average validation loss: 0.013420952821092277\n",
      "Training epoch 5355...\n",
      "\n",
      "Train Epoch: 5355 [0/8000 (0%)]\tBatch Loss: 0.013208\tLearning Rate (w_theta): 0.001000\t TIME:1259.9s\n",
      "\t\t\t\tDisc: 0.012047\t\tSym: 0.000000\t\tSpars: 0.001162\n",
      "\t TVw: 0.792313 | TVb: 2.268076 | GSw: -0.633841 | GSb: -0.321230 | TSUw: -0.400598 | TSUb: -0.033075\n",
      "\n",
      "Train Epoch: 5355 [4000/8000 (50%)]\tBatch Loss: 0.013302\tLearning Rate (w_theta): 0.001000\t TIME:1261.2s\n",
      "\t\t\t\tDisc: 0.012547\t\tSym: 0.000000\t\tSpars: 0.000755\n",
      "\t TVw: 0.792224 | TVb: 2.268206 | GSw: -0.633706 | GSb: -0.321038 | TSUw: -0.400785 | TSUb: -0.033171\n",
      "Validating epoch 5355...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012914254124664497\n",
      "Average validation loss: 0.013420555488633981\n",
      "Training epoch 5356...\n",
      "\n",
      "Train Epoch: 5356 [0/8000 (0%)]\tBatch Loss: 0.012585\tLearning Rate (w_theta): 0.001000\t TIME:1263.4s\n",
      "\t\t\t\tDisc: 0.011670\t\tSym: 0.000000\t\tSpars: 0.000915\n",
      "\t TVw: 0.791986 | TVb: 2.268302 | GSw: -0.633547 | GSb: -0.320822 | TSUw: -0.400513 | TSUb: -0.032972\n",
      "\n",
      "Train Epoch: 5356 [4000/8000 (50%)]\tBatch Loss: 0.012884\tLearning Rate (w_theta): 0.001000\t TIME:1264.7s\n",
      "\t\t\t\tDisc: 0.011911\t\tSym: 0.000000\t\tSpars: 0.000973\n",
      "\t TVw: 0.791717 | TVb: 2.268398 | GSw: -0.633387 | GSb: -0.320606 | TSUw: -0.400248 | TSUb: -0.032777\n",
      "Validating epoch 5356...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012913537523987204\n",
      "Average validation loss: 0.013419795420613414\n",
      "Training epoch 5357...\n",
      "\n",
      "Train Epoch: 5357 [0/8000 (0%)]\tBatch Loss: 0.013294\tLearning Rate (w_theta): 0.001000\t TIME:1266.9s\n",
      "\t\t\t\tDisc: 0.012472\t\tSym: 0.000000\t\tSpars: 0.000822\n",
      "\t TVw: 0.791254 | TVb: 2.268468 | GSw: -0.633237 | GSb: -0.320398 | TSUw: -0.400151 | TSUb: -0.032690\n",
      "\n",
      "Train Epoch: 5357 [4000/8000 (50%)]\tBatch Loss: 0.012483\tLearning Rate (w_theta): 0.001000\t TIME:1268.1s\n",
      "\t\t\t\tDisc: 0.011805\t\tSym: 0.000000\t\tSpars: 0.000678\n",
      "\t TVw: 0.791344 | TVb: 2.268642 | GSw: -0.633102 | GSb: -0.320207 | TSUw: -0.400388 | TSUb: -0.032819\n",
      "Validating epoch 5357...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012913406070360369\n",
      "Average validation loss: 0.013419227114748739\n",
      "Training epoch 5358...\n",
      "\n",
      "Train Epoch: 5358 [0/8000 (0%)]\tBatch Loss: 0.013473\tLearning Rate (w_theta): 0.001000\t TIME:1270.3s\n",
      "\t\t\t\tDisc: 0.012556\t\tSym: 0.000000\t\tSpars: 0.000917\n",
      "\t TVw: 0.791267 | TVb: 2.268803 | GSw: -0.632955 | GSb: -0.320004 | TSUw: -0.400370 | TSUb: -0.032784\n",
      "\n",
      "Train Epoch: 5358 [4000/8000 (50%)]\tBatch Loss: 0.012995\tLearning Rate (w_theta): 0.001000\t TIME:1271.6s\n",
      "\t\t\t\tDisc: 0.012083\t\tSym: 0.000000\t\tSpars: 0.000912\n",
      "\t TVw: 0.791024 | TVb: 2.268909 | GSw: -0.632778 | GSb: -0.319766 | TSUw: -0.399760 | TSUb: -0.032369\n",
      "Validating epoch 5358...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012913892920850906\n",
      "Average validation loss: 0.013417879148522337\n",
      "Training epoch 5359...\n",
      "\n",
      "Train Epoch: 5359 [0/8000 (0%)]\tBatch Loss: 0.013365\tLearning Rate (w_theta): 0.001000\t TIME:1273.8s\n",
      "\t\t\t\tDisc: 0.012422\t\tSym: 0.000000\t\tSpars: 0.000943\n",
      "\t TVw: 0.790881 | TVb: 2.269056 | GSw: -0.632644 | GSb: -0.319577 | TSUw: -0.399992 | TSUb: -0.032496\n",
      "\n",
      "Train Epoch: 5359 [4000/8000 (50%)]\tBatch Loss: 0.012162\tLearning Rate (w_theta): 0.001000\t TIME:1275.1s\n",
      "\t\t\t\tDisc: 0.011470\t\tSym: 0.000000\t\tSpars: 0.000692\n",
      "\t TVw: 0.791280 | TVb: 2.269306 | GSw: -0.632542 | GSb: -0.319423 | TSUw: -0.400838 | TSUb: -0.033020\n",
      "Validating epoch 5359...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012912072333107375\n",
      "Average validation loss: 0.013418573032155143\n",
      "Training epoch 5360...\n",
      "\n",
      "Train Epoch: 5360 [0/8000 (0%)]\tBatch Loss: 0.012722\tLearning Rate (w_theta): 0.001000\t TIME:1277.3s\n",
      "\t\t\t\tDisc: 0.012210\t\tSym: 0.000000\t\tSpars: 0.000512\n",
      "\t TVw: 0.791028 | TVb: 2.269403 | GSw: -0.632406 | GSb: -0.319232 | TSUw: -0.401032 | TSUb: -0.033121\n",
      "\n",
      "Train Epoch: 5360 [4000/8000 (50%)]\tBatch Loss: 0.013009\tLearning Rate (w_theta): 0.001000\t TIME:1278.6s\n",
      "\t\t\t\tDisc: 0.012214\t\tSym: 0.000000\t\tSpars: 0.000794\n",
      "\t TVw: 0.790795 | TVb: 2.269521 | GSw: -0.632256 | GSb: -0.319027 | TSUw: -0.400947 | TSUb: -0.033041\n",
      "Validating epoch 5360...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012911289215713245\n",
      "Average validation loss: 0.013418163364908888\n",
      "Training epoch 5361...\n",
      "\n",
      "Train Epoch: 5361 [0/8000 (0%)]\tBatch Loss: 0.013211\tLearning Rate (w_theta): 0.001000\t TIME:1281.4s\n",
      "\t\t\t\tDisc: 0.012474\t\tSym: 0.000000\t\tSpars: 0.000737\n",
      "\t TVw: 0.790656 | TVb: 2.269649 | GSw: -0.632120 | GSb: -0.318834 | TSUw: -0.401197 | TSUb: -0.033178\n",
      "\n",
      "Train Epoch: 5361 [4000/8000 (50%)]\tBatch Loss: 0.012186\tLearning Rate (w_theta): 0.001000\t TIME:1282.6s\n",
      "\t\t\t\tDisc: 0.011499\t\tSym: 0.000000\t\tSpars: 0.000687\n",
      "\t TVw: 0.790215 | TVb: 2.269697 | GSw: -0.631958 | GSb: -0.318614 | TSUw: -0.400923 | TSUb: -0.032976\n",
      "Validating epoch 5361...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012911295440969063\n",
      "Average validation loss: 0.01341742187380076\n",
      "Training epoch 5362...\n",
      "\n",
      "Train Epoch: 5362 [0/8000 (0%)]\tBatch Loss: 0.013137\tLearning Rate (w_theta): 0.001000\t TIME:1284.8s\n",
      "\t\t\t\tDisc: 0.012250\t\tSym: 0.000000\t\tSpars: 0.000887\n",
      "\t TVw: 0.790036 | TVb: 2.269811 | GSw: -0.631810 | GSb: -0.318409 | TSUw: -0.400916 | TSUb: -0.032947\n",
      "\n",
      "Train Epoch: 5362 [4000/8000 (50%)]\tBatch Loss: 0.012382\tLearning Rate (w_theta): 0.001000\t TIME:1286.1s\n",
      "\t\t\t\tDisc: 0.011774\t\tSym: 0.000000\t\tSpars: 0.000608\n",
      "\t TVw: 0.790115 | TVb: 2.269963 | GSw: -0.631694 | GSb: -0.318242 | TSUw: -0.401535 | TSUb: -0.033323\n",
      "Validating epoch 5362...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01291087693130589\n",
      "Average validation loss: 0.01341774139502322\n",
      "Training epoch 5363...\n",
      "\n",
      "Train Epoch: 5363 [0/8000 (0%)]\tBatch Loss: 0.013113\tLearning Rate (w_theta): 0.001000\t TIME:1288.4s\n",
      "\t\t\t\tDisc: 0.012239\t\tSym: 0.000000\t\tSpars: 0.000874\n",
      "\t TVw: 0.790134 | TVb: 2.270082 | GSw: -0.631541 | GSb: -0.318030 | TSUw: -0.401431 | TSUb: -0.033231\n",
      "\n",
      "Train Epoch: 5363 [4000/8000 (50%)]\tBatch Loss: 0.012994\tLearning Rate (w_theta): 0.001000\t TIME:1289.6s\n",
      "\t\t\t\tDisc: 0.012032\t\tSym: 0.000000\t\tSpars: 0.000962\n",
      "\t TVw: 0.789984 | TVb: 2.270155 | GSw: -0.631362 | GSb: -0.317792 | TSUw: -0.400852 | TSUb: -0.032830\n",
      "Validating epoch 5363...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012910539574590783\n",
      "Average validation loss: 0.013415825130687937\n",
      "Training epoch 5364...\n",
      "\n",
      "Train Epoch: 5364 [0/8000 (0%)]\tBatch Loss: 0.012598\tLearning Rate (w_theta): 0.001000\t TIME:1291.8s\n",
      "\t\t\t\tDisc: 0.011881\t\tSym: 0.000000\t\tSpars: 0.000717\n",
      "\t TVw: 0.789930 | TVb: 2.270276 | GSw: -0.631210 | GSb: -0.317581 | TSUw: -0.400772 | TSUb: -0.032752\n",
      "\n",
      "Train Epoch: 5364 [4000/8000 (50%)]\tBatch Loss: 0.012929\tLearning Rate (w_theta): 0.001000\t TIME:1293.1s\n",
      "\t\t\t\tDisc: 0.012124\t\tSym: 0.000000\t\tSpars: 0.000805\n",
      "\t TVw: 0.790042 | TVb: 2.270450 | GSw: -0.631075 | GSb: -0.317390 | TSUw: -0.401040 | TSUb: -0.032903\n",
      "Validating epoch 5364...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012909486828058859\n",
      "Average validation loss: 0.013415879340352125\n",
      "Training epoch 5365...\n",
      "\n",
      "Train Epoch: 5365 [0/8000 (0%)]\tBatch Loss: 0.012472\tLearning Rate (w_theta): 0.001000\t TIME:1295.3s\n",
      "\t\t\t\tDisc: 0.011763\t\tSym: 0.000000\t\tSpars: 0.000709\n",
      "\t TVw: 0.789765 | TVb: 2.270557 | GSw: -0.630943 | GSb: -0.317202 | TSUw: -0.401338 | TSUb: -0.033072\n",
      "\n",
      "Train Epoch: 5365 [4000/8000 (50%)]\tBatch Loss: 0.013107\tLearning Rate (w_theta): 0.001000\t TIME:1296.5s\n",
      "\t\t\t\tDisc: 0.012430\t\tSym: 0.000000\t\tSpars: 0.000677\n",
      "\t TVw: 0.789706 | TVb: 2.270736 | GSw: -0.630807 | GSb: -0.317008 | TSUw: -0.401521 | TSUb: -0.033166\n",
      "Validating epoch 5365...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012908721262482471\n",
      "Average validation loss: 0.013415708149402858\n",
      "Training epoch 5366...\n",
      "\n",
      "Train Epoch: 5366 [0/8000 (0%)]\tBatch Loss: 0.012920\tLearning Rate (w_theta): 0.001000\t TIME:1298.7s\n",
      "\t\t\t\tDisc: 0.012316\t\tSym: 0.000000\t\tSpars: 0.000604\n",
      "\t TVw: 0.789514 | TVb: 2.270854 | GSw: -0.630665 | GSb: -0.316810 | TSUw: -0.401652 | TSUb: -0.033226\n",
      "\n",
      "Train Epoch: 5366 [4000/8000 (50%)]\tBatch Loss: 0.012782\tLearning Rate (w_theta): 0.001000\t TIME:1300.0s\n",
      "\t\t\t\tDisc: 0.012046\t\tSym: 0.000000\t\tSpars: 0.000736\n",
      "\t TVw: 0.788980 | TVb: 2.270902 | GSw: -0.630505 | GSb: -0.316592 | TSUw: -0.401434 | TSUb: -0.033057\n",
      "Validating epoch 5366...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012908856052856956\n",
      "Average validation loss: 0.013415097119003393\n",
      "Training epoch 5367...\n",
      "\n",
      "Train Epoch: 5367 [0/8000 (0%)]\tBatch Loss: 0.012888\tLearning Rate (w_theta): 0.001000\t TIME:1302.2s\n",
      "\t\t\t\tDisc: 0.012224\t\tSym: 0.000000\t\tSpars: 0.000663\n",
      "\t TVw: 0.788748 | TVb: 2.270984 | GSw: -0.630355 | GSb: -0.316385 | TSUw: -0.401397 | TSUb: -0.033008\n",
      "\n",
      "Train Epoch: 5367 [4000/8000 (50%)]\tBatch Loss: 0.013171\tLearning Rate (w_theta): 0.001000\t TIME:1303.5s\n",
      "\t\t\t\tDisc: 0.012451\t\tSym: 0.000000\t\tSpars: 0.000721\n",
      "\t TVw: 0.788501 | TVb: 2.271077 | GSw: -0.630208 | GSb: -0.316180 | TSUw: -0.401409 | TSUb: -0.032990\n",
      "Validating epoch 5367...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012908630327495776\n",
      "Average validation loss: 0.01341502667577656\n",
      "Training epoch 5368...\n",
      "\n",
      "Train Epoch: 5368 [0/8000 (0%)]\tBatch Loss: 0.012939\tLearning Rate (w_theta): 0.001000\t TIME:1305.7s\n",
      "\t\t\t\tDisc: 0.012043\t\tSym: 0.000000\t\tSpars: 0.000897\n",
      "\t TVw: 0.788566 | TVb: 2.271203 | GSw: -0.630072 | GSb: -0.315986 | TSUw: -0.401693 | TSUb: -0.033151\n",
      "\n",
      "Train Epoch: 5368 [4000/8000 (50%)]\tBatch Loss: 0.012621\tLearning Rate (w_theta): 0.001000\t TIME:1306.9s\n",
      "\t\t\t\tDisc: 0.011880\t\tSym: 0.000000\t\tSpars: 0.000741\n",
      "\t TVw: 0.788412 | TVb: 2.271297 | GSw: -0.629912 | GSb: -0.315766 | TSUw: -0.401524 | TSUb: -0.033016\n",
      "Validating epoch 5368...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01290821097512194\n",
      "Average validation loss: 0.013414792230076009\n",
      "Training epoch 5369...\n",
      "\n",
      "Train Epoch: 5369 [0/8000 (0%)]\tBatch Loss: 0.012905\tLearning Rate (w_theta): 0.001000\t TIME:1309.2s\n",
      "\t\t\t\tDisc: 0.011859\t\tSym: 0.000000\t\tSpars: 0.001046\n",
      "\t TVw: 0.788396 | TVb: 2.271424 | GSw: -0.629789 | GSb: -0.315588 | TSUw: -0.402053 | TSUb: -0.033337\n",
      "\n",
      "Train Epoch: 5369 [4000/8000 (50%)]\tBatch Loss: 0.012790\tLearning Rate (w_theta): 0.001000\t TIME:1310.4s\n",
      "\t\t\t\tDisc: 0.012173\t\tSym: 0.000000\t\tSpars: 0.000617\n",
      "\t TVw: 0.788669 | TVb: 2.271650 | GSw: -0.629665 | GSb: -0.315407 | TSUw: -0.402592 | TSUb: -0.033665\n",
      "Validating epoch 5369...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012907491660985395\n",
      "Average validation loss: 0.01341513867321754\n",
      "Training epoch 5370...\n",
      "\n",
      "Train Epoch: 5370 [0/8000 (0%)]\tBatch Loss: 0.012943\tLearning Rate (w_theta): 0.001000\t TIME:1312.6s\n",
      "\t\t\t\tDisc: 0.012134\t\tSym: 0.000000\t\tSpars: 0.000809\n",
      "\t TVw: 0.788632 | TVb: 2.271743 | GSw: -0.629505 | GSb: -0.315188 | TSUw: -0.402374 | TSUb: -0.033495\n",
      "\n",
      "Train Epoch: 5370 [4000/8000 (50%)]\tBatch Loss: 0.013175\tLearning Rate (w_theta): 0.001000\t TIME:1313.9s\n",
      "\t\t\t\tDisc: 0.012323\t\tSym: 0.000000\t\tSpars: 0.000851\n",
      "\t TVw: 0.788228 | TVb: 2.271743 | GSw: -0.629299 | GSb: -0.314921 | TSUw: -0.401241 | TSUb: -0.032724\n",
      "Validating epoch 5370...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01290908454450416\n",
      "Average validation loss: 0.013412586469676089\n",
      "Training epoch 5371...\n",
      "\n",
      "Train Epoch: 5371 [0/8000 (0%)]\tBatch Loss: 0.013117\tLearning Rate (w_theta): 0.001000\t TIME:1316.7s\n",
      "\t\t\t\tDisc: 0.012299\t\tSym: 0.000000\t\tSpars: 0.000818\n",
      "\t TVw: 0.788132 | TVb: 2.271838 | GSw: -0.629158 | GSb: -0.314724 | TSUw: -0.401361 | TSUb: -0.032777\n",
      "\n",
      "Train Epoch: 5371 [4000/8000 (50%)]\tBatch Loss: 0.012780\tLearning Rate (w_theta): 0.001000\t TIME:1318.0s\n",
      "\t\t\t\tDisc: 0.011881\t\tSym: 0.000000\t\tSpars: 0.000899\n",
      "\t TVw: 0.788458 | TVb: 2.272037 | GSw: -0.629054 | GSb: -0.314565 | TSUw: -0.402233 | TSUb: -0.033325\n",
      "Validating epoch 5371...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01290684594458251\n",
      "Average validation loss: 0.013413305389107583\n",
      "Training epoch 5372...\n",
      "\n",
      "Train Epoch: 5372 [0/8000 (0%)]\tBatch Loss: 0.012894\tLearning Rate (w_theta): 0.001000\t TIME:1320.3s\n",
      "\t\t\t\tDisc: 0.012085\t\tSym: 0.000000\t\tSpars: 0.000808\n",
      "\t TVw: 0.788453 | TVb: 2.272181 | GSw: -0.628918 | GSb: -0.314373 | TSUw: -0.402479 | TSUb: -0.033461\n",
      "\n",
      "Train Epoch: 5372 [4000/8000 (50%)]\tBatch Loss: 0.013068\tLearning Rate (w_theta): 0.001000\t TIME:1321.5s\n",
      "\t\t\t\tDisc: 0.012165\t\tSym: 0.000000\t\tSpars: 0.000903\n",
      "\t TVw: 0.788803 | TVb: 2.272411 | GSw: -0.628804 | GSb: -0.314204 | TSUw: -0.403148 | TSUb: -0.033877\n",
      "Validating epoch 5372...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012905540785815342\n",
      "Average validation loss: 0.013413652033803817\n",
      "Training epoch 5373...\n",
      "\n",
      "Train Epoch: 5373 [0/8000 (0%)]\tBatch Loss: 0.013011\tLearning Rate (w_theta): 0.001000\t TIME:1323.7s\n",
      "\t\t\t\tDisc: 0.012329\t\tSym: 0.000000\t\tSpars: 0.000682\n",
      "\t TVw: 0.788345 | TVb: 2.272458 | GSw: -0.628639 | GSb: -0.313980 | TSUw: -0.402804 | TSUb: -0.033620\n",
      "\n",
      "Train Epoch: 5373 [4000/8000 (50%)]\tBatch Loss: 0.012765\tLearning Rate (w_theta): 0.001000\t TIME:1325.0s\n",
      "\t\t\t\tDisc: 0.012067\t\tSym: 0.000000\t\tSpars: 0.000698\n",
      "\t TVw: 0.787865 | TVb: 2.272484 | GSw: -0.628462 | GSb: -0.313744 | TSUw: -0.402208 | TSUb: -0.033197\n",
      "Validating epoch 5373...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012905189260895867\n",
      "Average validation loss: 0.013411740832164041\n",
      "Training epoch 5374...\n",
      "\n",
      "Train Epoch: 5374 [0/8000 (0%)]\tBatch Loss: 0.013226\tLearning Rate (w_theta): 0.001000\t TIME:1327.2s\n",
      "\t\t\t\tDisc: 0.012361\t\tSym: 0.000000\t\tSpars: 0.000865\n",
      "\t TVw: 0.787541 | TVb: 2.272565 | GSw: -0.628300 | GSb: -0.313524 | TSUw: -0.401957 | TSUb: -0.033002\n",
      "\n",
      "Train Epoch: 5374 [4000/8000 (50%)]\tBatch Loss: 0.012650\tLearning Rate (w_theta): 0.001000\t TIME:1328.5s\n",
      "\t\t\t\tDisc: 0.012000\t\tSym: 0.000000\t\tSpars: 0.000650\n",
      "\t TVw: 0.787326 | TVb: 2.272628 | GSw: -0.628158 | GSb: -0.313324 | TSUw: -0.402102 | TSUb: -0.033071\n",
      "Validating epoch 5374...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012905416197572508\n",
      "Average validation loss: 0.013411824340351063\n",
      "Training epoch 5375...\n",
      "\n",
      "Train Epoch: 5375 [0/8000 (0%)]\tBatch Loss: 0.012358\tLearning Rate (w_theta): 0.001000\t TIME:1330.6s\n",
      "\t\t\t\tDisc: 0.011504\t\tSym: 0.000000\t\tSpars: 0.000855\n",
      "\t TVw: 0.787035 | TVb: 2.272717 | GSw: -0.628021 | GSb: -0.313131 | TSUw: -0.402349 | TSUb: -0.033208\n",
      "\n",
      "Train Epoch: 5375 [4000/8000 (50%)]\tBatch Loss: 0.012701\tLearning Rate (w_theta): 0.001000\t TIME:1331.9s\n",
      "\t\t\t\tDisc: 0.012123\t\tSym: 0.000000\t\tSpars: 0.000578\n",
      "\t TVw: 0.787157 | TVb: 2.272885 | GSw: -0.627886 | GSb: -0.312940 | TSUw: -0.402716 | TSUb: -0.033426\n",
      "Validating epoch 5375...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01290507340032121\n",
      "Average validation loss: 0.013411769076419767\n",
      "Training epoch 5376...\n",
      "\n",
      "Train Epoch: 5376 [0/8000 (0%)]\tBatch Loss: 0.012468\tLearning Rate (w_theta): 0.001000\t TIME:1334.1s\n",
      "\t\t\t\tDisc: 0.011701\t\tSym: 0.000000\t\tSpars: 0.000768\n",
      "\t TVw: 0.786746 | TVb: 2.272961 | GSw: -0.627737 | GSb: -0.312734 | TSUw: -0.402683 | TSUb: -0.033376\n",
      "\n",
      "Train Epoch: 5376 [4000/8000 (50%)]\tBatch Loss: 0.012998\tLearning Rate (w_theta): 0.001000\t TIME:1335.4s\n",
      "\t\t\t\tDisc: 0.012174\t\tSym: 0.000000\t\tSpars: 0.000824\n",
      "\t TVw: 0.786421 | TVb: 2.273067 | GSw: -0.627578 | GSb: -0.312518 | TSUw: -0.402468 | TSUb: -0.033206\n",
      "Validating epoch 5376...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012904677248864942\n",
      "Average validation loss: 0.013411243613332733\n",
      "Training epoch 5377...\n",
      "\n",
      "Train Epoch: 5377 [0/8000 (0%)]\tBatch Loss: 0.013072\tLearning Rate (w_theta): 0.001000\t TIME:1337.6s\n",
      "\t\t\t\tDisc: 0.012244\t\tSym: 0.000000\t\tSpars: 0.000828\n",
      "\t TVw: 0.786213 | TVb: 2.273158 | GSw: -0.627428 | GSb: -0.312310 | TSUw: -0.402476 | TSUb: -0.033185\n",
      "\n",
      "Train Epoch: 5377 [4000/8000 (50%)]\tBatch Loss: 0.013147\tLearning Rate (w_theta): 0.001000\t TIME:1338.9s\n",
      "\t\t\t\tDisc: 0.012231\t\tSym: 0.000000\t\tSpars: 0.000916\n",
      "\t TVw: 0.785764 | TVb: 2.273150 | GSw: -0.627251 | GSb: -0.312069 | TSUw: -0.402007 | TSUb: -0.032847\n",
      "Validating epoch 5377...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012905703617102141\n",
      "Average validation loss: 0.013410989448602395\n",
      "Training epoch 5378...\n",
      "\n",
      "Train Epoch: 5378 [0/8000 (0%)]\tBatch Loss: 0.012866\tLearning Rate (w_theta): 0.001000\t TIME:1341.1s\n",
      "\t\t\t\tDisc: 0.012008\t\tSym: 0.000000\t\tSpars: 0.000858\n",
      "\t TVw: 0.785701 | TVb: 2.273282 | GSw: -0.627132 | GSb: -0.311894 | TSUw: -0.402626 | TSUb: -0.033234\n",
      "\n",
      "Train Epoch: 5378 [4000/8000 (50%)]\tBatch Loss: 0.012901\tLearning Rate (w_theta): 0.001000\t TIME:1342.3s\n",
      "\t\t\t\tDisc: 0.012197\t\tSym: 0.000000\t\tSpars: 0.000704\n",
      "\t TVw: 0.785801 | TVb: 2.273434 | GSw: -0.627000 | GSb: -0.311710 | TSUw: -0.403020 | TSUb: -0.033472\n",
      "Validating epoch 5378...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012904078993202114\n",
      "Average validation loss: 0.013412065795000842\n",
      "Training epoch 5379...\n",
      "\n",
      "Train Epoch: 5379 [0/8000 (0%)]\tBatch Loss: 0.012976\tLearning Rate (w_theta): 0.001000\t TIME:1344.5s\n",
      "\t\t\t\tDisc: 0.012250\t\tSym: 0.000000\t\tSpars: 0.000727\n",
      "\t TVw: 0.785751 | TVb: 2.273565 | GSw: -0.626873 | GSb: -0.311528 | TSUw: -0.403464 | TSUb: -0.033742\n",
      "\n",
      "Train Epoch: 5379 [4000/8000 (50%)]\tBatch Loss: 0.012279\tLearning Rate (w_theta): 0.001000\t TIME:1345.8s\n",
      "\t\t\t\tDisc: 0.011637\t\tSym: 0.000000\t\tSpars: 0.000642\n",
      "\t TVw: 0.785718 | TVb: 2.273683 | GSw: -0.626721 | GSb: -0.311318 | TSUw: -0.403442 | TSUb: -0.033699\n",
      "Validating epoch 5379...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012903467655514474\n",
      "Average validation loss: 0.013411503584481496\n",
      "Training epoch 5380...\n",
      "\n",
      "Train Epoch: 5380 [0/8000 (0%)]\tBatch Loss: 0.013178\tLearning Rate (w_theta): 0.001000\t TIME:1348.0s\n",
      "\t\t\t\tDisc: 0.012316\t\tSym: 0.000000\t\tSpars: 0.000862\n",
      "\t TVw: 0.785671 | TVb: 2.273783 | GSw: -0.626574 | GSb: -0.311114 | TSUw: -0.403529 | TSUb: -0.033729\n",
      "\n",
      "Train Epoch: 5380 [4000/8000 (50%)]\tBatch Loss: 0.012298\tLearning Rate (w_theta): 0.001000\t TIME:1349.3s\n",
      "\t\t\t\tDisc: 0.011624\t\tSym: 0.000000\t\tSpars: 0.000675\n",
      "\t TVw: 0.785414 | TVb: 2.273859 | GSw: -0.626413 | GSb: -0.310898 | TSUw: -0.403298 | TSUb: -0.033545\n",
      "Validating epoch 5380...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012903196307687787\n",
      "Average validation loss: 0.013410691272224723\n",
      "Training epoch 5381...\n",
      "\n",
      "Train Epoch: 5381 [0/8000 (0%)]\tBatch Loss: 0.012474\tLearning Rate (w_theta): 0.001000\t TIME:1352.2s\n",
      "\t\t\t\tDisc: 0.011606\t\tSym: 0.000000\t\tSpars: 0.000867\n",
      "\t TVw: 0.785085 | TVb: 2.273922 | GSw: -0.626269 | GSb: -0.310697 | TSUw: -0.403442 | TSUb: -0.033612\n",
      "\n",
      "Train Epoch: 5381 [4000/8000 (50%)]\tBatch Loss: 0.012688\tLearning Rate (w_theta): 0.001000\t TIME:1353.5s\n",
      "\t\t\t\tDisc: 0.011815\t\tSym: 0.000000\t\tSpars: 0.000873\n",
      "\t TVw: 0.784768 | TVb: 2.274002 | GSw: -0.626114 | GSb: -0.310483 | TSUw: -0.403372 | TSUb: -0.033536\n",
      "Validating epoch 5381...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012903258652633792\n",
      "Average validation loss: 0.013410366252548506\n",
      "Training epoch 5382...\n",
      "\n",
      "Train Epoch: 5382 [0/8000 (0%)]\tBatch Loss: 0.012926\tLearning Rate (w_theta): 0.001000\t TIME:1355.7s\n",
      "\t\t\t\tDisc: 0.012285\t\tSym: 0.000000\t\tSpars: 0.000641\n",
      "\t TVw: 0.784563 | TVb: 2.274059 | GSw: -0.625956 | GSb: -0.310266 | TSUw: -0.403247 | TSUb: -0.033424\n",
      "\n",
      "Train Epoch: 5382 [4000/8000 (50%)]\tBatch Loss: 0.013540\tLearning Rate (w_theta): 0.001000\t TIME:1356.9s\n",
      "\t\t\t\tDisc: 0.012607\t\tSym: 0.000000\t\tSpars: 0.000933\n",
      "\t TVw: 0.784634 | TVb: 2.274173 | GSw: -0.625794 | GSb: -0.310047 | TSUw: -0.403071 | TSUb: -0.033278\n",
      "Validating epoch 5382...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012903384743175166\n",
      "Average validation loss: 0.013409315079484872\n",
      "Training epoch 5383...\n",
      "\n",
      "Train Epoch: 5383 [0/8000 (0%)]\tBatch Loss: 0.012477\tLearning Rate (w_theta): 0.001000\t TIME:1359.2s\n",
      "\t\t\t\tDisc: 0.011885\t\tSym: 0.000000\t\tSpars: 0.000592\n",
      "\t TVw: 0.784319 | TVb: 2.274218 | GSw: -0.625641 | GSb: -0.309836 | TSUw: -0.403024 | TSUb: -0.033219\n",
      "\n",
      "Train Epoch: 5383 [4000/8000 (50%)]\tBatch Loss: 0.012382\tLearning Rate (w_theta): 0.001000\t TIME:1360.4s\n",
      "\t\t\t\tDisc: 0.011680\t\tSym: 0.000000\t\tSpars: 0.000702\n",
      "\t TVw: 0.784543 | TVb: 2.274330 | GSw: -0.625503 | GSb: -0.309642 | TSUw: -0.403306 | TSUb: -0.033384\n",
      "Validating epoch 5383...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012902788629926769\n",
      "Average validation loss: 0.013409470867333718\n",
      "Training epoch 5384...\n",
      "\n",
      "Train Epoch: 5384 [0/8000 (0%)]\tBatch Loss: 0.013410\tLearning Rate (w_theta): 0.001000\t TIME:1362.6s\n",
      "\t\t\t\tDisc: 0.012442\t\tSym: 0.000000\t\tSpars: 0.000968\n",
      "\t TVw: 0.784371 | TVb: 2.274441 | GSw: -0.625362 | GSb: -0.309441 | TSUw: -0.403525 | TSUb: -0.033505\n",
      "\n",
      "Train Epoch: 5384 [4000/8000 (50%)]\tBatch Loss: 0.012898\tLearning Rate (w_theta): 0.001000\t TIME:1363.8s\n",
      "\t\t\t\tDisc: 0.012104\t\tSym: 0.000000\t\tSpars: 0.000794\n",
      "\t TVw: 0.783908 | TVb: 2.274456 | GSw: -0.625228 | GSb: -0.309248 | TSUw: -0.403905 | TSUb: -0.033732\n",
      "Validating epoch 5384...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0129023417648892\n",
      "Average validation loss: 0.013410627280166678\n",
      "Training epoch 5385...\n",
      "\n",
      "Train Epoch: 5385 [0/8000 (0%)]\tBatch Loss: 0.013461\tLearning Rate (w_theta): 0.001000\t TIME:1366.1s\n",
      "\t\t\t\tDisc: 0.012512\t\tSym: 0.000000\t\tSpars: 0.000949\n",
      "\t TVw: 0.783748 | TVb: 2.274546 | GSw: -0.625084 | GSb: -0.309047 | TSUw: -0.404102 | TSUb: -0.033837\n",
      "\n",
      "Train Epoch: 5385 [4000/8000 (50%)]\tBatch Loss: 0.013233\tLearning Rate (w_theta): 0.001000\t TIME:1367.3s\n",
      "\t\t\t\tDisc: 0.012343\t\tSym: 0.000000\t\tSpars: 0.000890\n",
      "\t TVw: 0.784045 | TVb: 2.274734 | GSw: -0.624922 | GSb: -0.308823 | TSUw: -0.403933 | TSUb: -0.033696\n",
      "Validating epoch 5385...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012901882884008108\n",
      "Average validation loss: 0.013408989445772394\n",
      "Training epoch 5386...\n",
      "\n",
      "Train Epoch: 5386 [0/8000 (0%)]\tBatch Loss: 0.013251\tLearning Rate (w_theta): 0.001000\t TIME:1369.5s\n",
      "\t\t\t\tDisc: 0.012316\t\tSym: 0.000000\t\tSpars: 0.000935\n",
      "\t TVw: 0.783912 | TVb: 2.274827 | GSw: -0.624767 | GSb: -0.308610 | TSUw: -0.403888 | TSUb: -0.033637\n",
      "\n",
      "Train Epoch: 5386 [4000/8000 (50%)]\tBatch Loss: 0.012989\tLearning Rate (w_theta): 0.001000\t TIME:1370.8s\n",
      "\t\t\t\tDisc: 0.012189\t\tSym: 0.000000\t\tSpars: 0.000800\n",
      "\t TVw: 0.783888 | TVb: 2.274935 | GSw: -0.624645 | GSb: -0.308433 | TSUw: -0.404548 | TSUb: -0.034054\n",
      "Validating epoch 5386...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01290221721307456\n",
      "Average validation loss: 0.013409517155737469\n",
      "Training epoch 5387...\n",
      "\n",
      "Train Epoch: 5387 [0/8000 (0%)]\tBatch Loss: 0.012863\tLearning Rate (w_theta): 0.001000\t TIME:1373.0s\n",
      "\t\t\t\tDisc: 0.011929\t\tSym: 0.000000\t\tSpars: 0.000934\n",
      "\t TVw: 0.783685 | TVb: 2.274986 | GSw: -0.624471 | GSb: -0.308200 | TSUw: -0.404121 | TSUb: -0.033734\n",
      "\n",
      "Train Epoch: 5387 [4000/8000 (50%)]\tBatch Loss: 0.013286\tLearning Rate (w_theta): 0.001000\t TIME:1374.3s\n",
      "\t\t\t\tDisc: 0.012376\t\tSym: 0.000000\t\tSpars: 0.000910\n",
      "\t TVw: 0.783262 | TVb: 2.274996 | GSw: -0.624314 | GSb: -0.307985 | TSUw: -0.403995 | TSUb: -0.033618\n",
      "Validating epoch 5387...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012901509425605865\n",
      "Average validation loss: 0.013408295883001867\n",
      "Training epoch 5388...\n",
      "\n",
      "Train Epoch: 5388 [0/8000 (0%)]\tBatch Loss: 0.013156\tLearning Rate (w_theta): 0.001000\t TIME:1376.5s\n",
      "\t\t\t\tDisc: 0.012256\t\tSym: 0.000000\t\tSpars: 0.000900\n",
      "\t TVw: 0.783037 | TVb: 2.275079 | GSw: -0.624144 | GSb: -0.307757 | TSUw: -0.403646 | TSUb: -0.033351\n",
      "\n",
      "Train Epoch: 5388 [4000/8000 (50%)]\tBatch Loss: 0.013297\tLearning Rate (w_theta): 0.001000\t TIME:1377.7s\n",
      "\t\t\t\tDisc: 0.012402\t\tSym: 0.000000\t\tSpars: 0.000895\n",
      "\t TVw: 0.783230 | TVb: 2.275298 | GSw: -0.623994 | GSb: -0.307547 | TSUw: -0.403699 | TSUb: -0.033359\n",
      "Validating epoch 5388...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012901306210526632\n",
      "Average validation loss: 0.013407458091738746\n",
      "Training epoch 5389...\n",
      "\n",
      "Train Epoch: 5389 [0/8000 (0%)]\tBatch Loss: 0.012888\tLearning Rate (w_theta): 0.001000\t TIME:1380.0s\n",
      "\t\t\t\tDisc: 0.012069\t\tSym: 0.000000\t\tSpars: 0.000818\n",
      "\t TVw: 0.783106 | TVb: 2.275376 | GSw: -0.623852 | GSb: -0.307347 | TSUw: -0.403933 | TSUb: -0.033490\n",
      "\n",
      "Train Epoch: 5389 [4000/8000 (50%)]\tBatch Loss: 0.013245\tLearning Rate (w_theta): 0.001000\t TIME:1381.2s\n",
      "\t\t\t\tDisc: 0.012467\t\tSym: 0.000000\t\tSpars: 0.000777\n",
      "\t TVw: 0.782800 | TVb: 2.275436 | GSw: -0.623729 | GSb: -0.307166 | TSUw: -0.404507 | TSUb: -0.033852\n",
      "Validating epoch 5389...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012901279947237328\n",
      "Average validation loss: 0.013408313265703537\n",
      "Training epoch 5390...\n",
      "\n",
      "Train Epoch: 5390 [0/8000 (0%)]\tBatch Loss: 0.012781\tLearning Rate (w_theta): 0.001000\t TIME:1383.4s\n",
      "\t\t\t\tDisc: 0.012046\t\tSym: 0.000000\t\tSpars: 0.000735\n",
      "\t TVw: 0.782684 | TVb: 2.275496 | GSw: -0.623564 | GSb: -0.306943 | TSUw: -0.404313 | TSUb: -0.033692\n",
      "\n",
      "Train Epoch: 5390 [4000/8000 (50%)]\tBatch Loss: 0.012737\tLearning Rate (w_theta): 0.001000\t TIME:1384.7s\n",
      "\t\t\t\tDisc: 0.011993\t\tSym: 0.000000\t\tSpars: 0.000745\n",
      "\t TVw: 0.781938 | TVb: 2.275452 | GSw: -0.623412 | GSb: -0.306731 | TSUw: -0.404290 | TSUb: -0.033645\n",
      "Validating epoch 5390...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012900891298140095\n",
      "Average validation loss: 0.013408194158127948\n",
      "Training epoch 5391...\n",
      "\n",
      "Train Epoch: 5391 [0/8000 (0%)]\tBatch Loss: 0.012932\tLearning Rate (w_theta): 0.001000\t TIME:1387.5s\n",
      "\t\t\t\tDisc: 0.011972\t\tSym: 0.000000\t\tSpars: 0.000960\n",
      "\t TVw: 0.781901 | TVb: 2.275544 | GSw: -0.623255 | GSb: -0.306517 | TSUw: -0.404230 | TSUb: -0.033576\n",
      "\n",
      "Train Epoch: 5391 [4000/8000 (50%)]\tBatch Loss: 0.012036\tLearning Rate (w_theta): 0.001000\t TIME:1388.8s\n",
      "\t\t\t\tDisc: 0.011576\t\tSym: 0.000000\t\tSpars: 0.000460\n",
      "\t TVw: 0.782088 | TVb: 2.275669 | GSw: -0.623120 | GSb: -0.306326 | TSUw: -0.404657 | TSUb: -0.033839\n",
      "Validating epoch 5391...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01290148488969957\n",
      "Average validation loss: 0.013407585309467054\n",
      "Training epoch 5392...\n",
      "\n",
      "Train Epoch: 5392 [0/8000 (0%)]\tBatch Loss: 0.012923\tLearning Rate (w_theta): 0.001000\t TIME:1391.0s\n",
      "\t\t\t\tDisc: 0.012346\t\tSym: 0.000000\t\tSpars: 0.000577\n",
      "\t TVw: 0.781871 | TVb: 2.275708 | GSw: -0.622940 | GSb: -0.306086 | TSUw: -0.404127 | TSUb: -0.033445\n",
      "\n",
      "Train Epoch: 5392 [4000/8000 (50%)]\tBatch Loss: 0.013405\tLearning Rate (w_theta): 0.001000\t TIME:1392.3s\n",
      "\t\t\t\tDisc: 0.012653\t\tSym: 0.000000\t\tSpars: 0.000751\n",
      "\t TVw: 0.781781 | TVb: 2.275758 | GSw: -0.622763 | GSb: -0.305851 | TSUw: -0.403683 | TSUb: -0.033112\n",
      "Validating epoch 5392...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012901645617624717\n",
      "Average validation loss: 0.013406557899056998\n",
      "Training epoch 5393...\n",
      "\n",
      "Train Epoch: 5393 [0/8000 (0%)]\tBatch Loss: 0.012853\tLearning Rate (w_theta): 0.001000\t TIME:1394.4s\n",
      "\t\t\t\tDisc: 0.011874\t\tSym: 0.000000\t\tSpars: 0.000980\n",
      "\t TVw: 0.781841 | TVb: 2.275882 | GSw: -0.622635 | GSb: -0.305666 | TSUw: -0.404195 | TSUb: -0.033438\n",
      "\n",
      "Train Epoch: 5393 [4000/8000 (50%)]\tBatch Loss: 0.013049\tLearning Rate (w_theta): 0.001000\t TIME:1395.7s\n",
      "\t\t\t\tDisc: 0.012065\t\tSym: 0.000000\t\tSpars: 0.000983\n",
      "\t TVw: 0.782153 | TVb: 2.276027 | GSw: -0.622500 | GSb: -0.305471 | TSUw: -0.404588 | TSUb: -0.033683\n",
      "Validating epoch 5393...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01289989947086489\n",
      "Average validation loss: 0.013407270933163129\n",
      "Training epoch 5394...\n",
      "\n",
      "Train Epoch: 5394 [0/8000 (0%)]\tBatch Loss: 0.012423\tLearning Rate (w_theta): 0.001000\t TIME:1397.9s\n",
      "\t\t\t\tDisc: 0.011651\t\tSym: 0.000000\t\tSpars: 0.000772\n",
      "\t TVw: 0.781991 | TVb: 2.276085 | GSw: -0.622371 | GSb: -0.305288 | TSUw: -0.405078 | TSUb: -0.033994\n",
      "\n",
      "Train Epoch: 5394 [4000/8000 (50%)]\tBatch Loss: 0.013426\tLearning Rate (w_theta): 0.001000\t TIME:1399.3s\n",
      "\t\t\t\tDisc: 0.012420\t\tSym: 0.000000\t\tSpars: 0.001005\n",
      "\t TVw: 0.782006 | TVb: 2.276218 | GSw: -0.622237 | GSb: -0.305102 | TSUw: -0.405467 | TSUb: -0.034233\n",
      "Validating epoch 5394...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012899139650814843\n",
      "Average validation loss: 0.013407829903937518\n",
      "Training epoch 5395...\n",
      "\n",
      "Train Epoch: 5395 [0/8000 (0%)]\tBatch Loss: 0.012467\tLearning Rate (w_theta): 0.001000\t TIME:1401.5s\n",
      "\t\t\t\tDisc: 0.011838\t\tSym: 0.000000\t\tSpars: 0.000628\n",
      "\t TVw: 0.781723 | TVb: 2.276265 | GSw: -0.622074 | GSb: -0.304879 | TSUw: -0.405282 | TSUb: -0.034075\n",
      "\n",
      "Train Epoch: 5395 [4000/8000 (50%)]\tBatch Loss: 0.012959\tLearning Rate (w_theta): 0.001000\t TIME:1402.7s\n",
      "\t\t\t\tDisc: 0.012143\t\tSym: 0.000000\t\tSpars: 0.000816\n",
      "\t TVw: 0.781529 | TVb: 2.276330 | GSw: -0.621910 | GSb: -0.304659 | TSUw: -0.405156 | TSUb: -0.033956\n",
      "Validating epoch 5395...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012898982780236691\n",
      "Average validation loss: 0.013406963810022977\n",
      "Training epoch 5396...\n",
      "\n",
      "Train Epoch: 5396 [0/8000 (0%)]\tBatch Loss: 0.012726\tLearning Rate (w_theta): 0.001000\t TIME:1405.1s\n",
      "\t\t\t\tDisc: 0.011763\t\tSym: 0.000000\t\tSpars: 0.000963\n",
      "\t TVw: 0.781625 | TVb: 2.276434 | GSw: -0.621763 | GSb: -0.304453 | TSUw: -0.405332 | TSUb: -0.034048\n",
      "\n",
      "Train Epoch: 5396 [4000/8000 (50%)]\tBatch Loss: 0.012639\tLearning Rate (w_theta): 0.001000\t TIME:1406.3s\n",
      "\t\t\t\tDisc: 0.011957\t\tSym: 0.000000\t\tSpars: 0.000682\n",
      "\t TVw: 0.781482 | TVb: 2.276472 | GSw: -0.621591 | GSb: -0.304220 | TSUw: -0.405005 | TSUb: -0.033790\n",
      "Validating epoch 5396...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012898669330316711\n",
      "Average validation loss: 0.013405771177569378\n",
      "Training epoch 5397...\n",
      "\n",
      "Train Epoch: 5397 [0/8000 (0%)]\tBatch Loss: 0.012818\tLearning Rate (w_theta): 0.001000\t TIME:1408.6s\n",
      "\t\t\t\tDisc: 0.011837\t\tSym: 0.000000\t\tSpars: 0.000982\n",
      "\t TVw: 0.781383 | TVb: 2.276510 | GSw: -0.621414 | GSb: -0.303984 | TSUw: -0.404607 | TSUb: -0.033483\n",
      "\n",
      "Train Epoch: 5397 [4000/8000 (50%)]\tBatch Loss: 0.013087\tLearning Rate (w_theta): 0.001000\t TIME:1409.8s\n",
      "\t\t\t\tDisc: 0.012339\t\tSym: 0.000000\t\tSpars: 0.000748\n",
      "\t TVw: 0.781599 | TVb: 2.276626 | GSw: -0.621273 | GSb: -0.303786 | TSUw: -0.404898 | TSUb: -0.033657\n",
      "Validating epoch 5397...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012898815149619875\n",
      "Average validation loss: 0.01340554991270012\n",
      "Training epoch 5398...\n",
      "\n",
      "Train Epoch: 5398 [0/8000 (0%)]\tBatch Loss: 0.012891\tLearning Rate (w_theta): 0.001000\t TIME:1412.0s\n",
      "\t\t\t\tDisc: 0.012082\t\tSym: 0.000000\t\tSpars: 0.000809\n",
      "\t TVw: 0.781483 | TVb: 2.276710 | GSw: -0.621133 | GSb: -0.303590 | TSUw: -0.405208 | TSUb: -0.033843\n",
      "\n",
      "Train Epoch: 5398 [4000/8000 (50%)]\tBatch Loss: 0.013024\tLearning Rate (w_theta): 0.001000\t TIME:1413.3s\n",
      "\t\t\t\tDisc: 0.012191\t\tSym: 0.000000\t\tSpars: 0.000832\n",
      "\t TVw: 0.781087 | TVb: 2.276806 | GSw: -0.620983 | GSb: -0.303382 | TSUw: -0.405286 | TSUb: -0.033867\n",
      "Validating epoch 5398...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012898159176849956\n",
      "Average validation loss: 0.013405694364375168\n",
      "Training epoch 5399...\n",
      "\n",
      "Train Epoch: 5399 [0/8000 (0%)]\tBatch Loss: 0.013333\tLearning Rate (w_theta): 0.001000\t TIME:1415.5s\n",
      "\t\t\t\tDisc: 0.012306\t\tSym: 0.000000\t\tSpars: 0.001027\n",
      "\t TVw: 0.781120 | TVb: 2.276870 | GSw: -0.620823 | GSb: -0.303162 | TSUw: -0.405240 | TSUb: -0.033805\n",
      "\n",
      "Train Epoch: 5399 [4000/8000 (50%)]\tBatch Loss: 0.013003\tLearning Rate (w_theta): 0.001000\t TIME:1416.8s\n",
      "\t\t\t\tDisc: 0.012224\t\tSym: 0.000000\t\tSpars: 0.000780\n",
      "\t TVw: 0.781258 | TVb: 2.276950 | GSw: -0.620664 | GSb: -0.302942 | TSUw: -0.405241 | TSUb: -0.033778\n",
      "Validating epoch 5399...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012897703499519129\n",
      "Average validation loss: 0.01340509893750346\n",
      "Training epoch 5400...\n",
      "\n",
      "Train Epoch: 5400 [0/8000 (0%)]\tBatch Loss: 0.012882\tLearning Rate (w_theta): 0.001000\t TIME:1419.1s\n",
      "\t\t\t\tDisc: 0.012264\t\tSym: 0.000000\t\tSpars: 0.000618\n",
      "\t TVw: 0.781222 | TVb: 2.277013 | GSw: -0.620515 | GSb: -0.302735 | TSUw: -0.405366 | TSUb: -0.033836\n",
      "\n",
      "Train Epoch: 5400 [4000/8000 (50%)]\tBatch Loss: 0.012668\tLearning Rate (w_theta): 0.001000\t TIME:1420.4s\n",
      "\t\t\t\tDisc: 0.011950\t\tSym: 0.000000\t\tSpars: 0.000718\n",
      "\t TVw: 0.780496 | TVb: 2.276992 | GSw: -0.620335 | GSb: -0.302498 | TSUw: -0.404873 | TSUb: -0.033461\n",
      "Validating epoch 5400...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012898332988543117\n",
      "Average validation loss: 0.013404730684157427\n",
      "Training epoch 5401...\n",
      "\n",
      "Train Epoch: 5401 [0/8000 (0%)]\tBatch Loss: 0.013467\tLearning Rate (w_theta): 0.001000\t TIME:1423.2s\n",
      "\t\t\t\tDisc: 0.012695\t\tSym: 0.000000\t\tSpars: 0.000772\n",
      "\t TVw: 0.780492 | TVb: 2.277086 | GSw: -0.620191 | GSb: -0.302297 | TSUw: -0.405137 | TSUb: -0.033616\n",
      "\n",
      "Train Epoch: 5401 [4000/8000 (50%)]\tBatch Loss: 0.013127\tLearning Rate (w_theta): 0.001000\t TIME:1424.5s\n",
      "\t\t\t\tDisc: 0.012134\t\tSym: 0.000000\t\tSpars: 0.000993\n",
      "\t TVw: 0.780460 | TVb: 2.277169 | GSw: -0.620030 | GSb: -0.302075 | TSUw: -0.405048 | TSUb: -0.033526\n",
      "Validating epoch 5401...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012898196067611778\n",
      "Average validation loss: 0.013404897228097295\n",
      "Training epoch 5402...\n",
      "\n",
      "Train Epoch: 5402 [0/8000 (0%)]\tBatch Loss: 0.013183\tLearning Rate (w_theta): 0.001000\t TIME:1426.7s\n",
      "\t\t\t\tDisc: 0.012420\t\tSym: 0.000000\t\tSpars: 0.000763\n",
      "\t TVw: 0.780688 | TVb: 2.277295 | GSw: -0.619912 | GSb: -0.301900 | TSUw: -0.405815 | TSUb: -0.034037\n",
      "\n",
      "Train Epoch: 5402 [4000/8000 (50%)]\tBatch Loss: 0.012229\tLearning Rate (w_theta): 0.001000\t TIME:1428.0s\n",
      "\t\t\t\tDisc: 0.011609\t\tSym: 0.000000\t\tSpars: 0.000620\n",
      "\t TVw: 0.780524 | TVb: 2.277357 | GSw: -0.619768 | GSb: -0.301699 | TSUw: -0.406078 | TSUb: -0.034192\n",
      "Validating epoch 5402...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012897213232367161\n",
      "Average validation loss: 0.013405159059442031\n",
      "Training epoch 5403...\n",
      "\n",
      "Train Epoch: 5403 [0/8000 (0%)]\tBatch Loss: 0.013850\tLearning Rate (w_theta): 0.001000\t TIME:1430.2s\n",
      "\t\t\t\tDisc: 0.012853\t\tSym: 0.000000\t\tSpars: 0.000997\n",
      "\t TVw: 0.780324 | TVb: 2.277390 | GSw: -0.619603 | GSb: -0.301476 | TSUw: -0.405903 | TSUb: -0.034038\n",
      "\n",
      "Train Epoch: 5403 [4000/8000 (50%)]\tBatch Loss: 0.012327\tLearning Rate (w_theta): 0.001000\t TIME:1431.5s\n",
      "\t\t\t\tDisc: 0.011751\t\tSym: 0.000000\t\tSpars: 0.000576\n",
      "\t TVw: 0.780155 | TVb: 2.277435 | GSw: -0.619445 | GSb: -0.301258 | TSUw: -0.405870 | TSUb: -0.033984\n",
      "Validating epoch 5403...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012896926875213766\n",
      "Average validation loss: 0.013404649096956014\n",
      "Training epoch 5404...\n",
      "\n",
      "Train Epoch: 5404 [0/8000 (0%)]\tBatch Loss: 0.012809\tLearning Rate (w_theta): 0.001000\t TIME:1433.7s\n",
      "\t\t\t\tDisc: 0.011981\t\tSym: 0.000000\t\tSpars: 0.000827\n",
      "\t TVw: 0.780146 | TVb: 2.277523 | GSw: -0.619299 | GSb: -0.301055 | TSUw: -0.406082 | TSUb: -0.034103\n",
      "\n",
      "Train Epoch: 5404 [4000/8000 (50%)]\tBatch Loss: 0.013343\tLearning Rate (w_theta): 0.001000\t TIME:1435.0s\n",
      "\t\t\t\tDisc: 0.012344\t\tSym: 0.000000\t\tSpars: 0.000999\n",
      "\t TVw: 0.779918 | TVb: 2.277573 | GSw: -0.619141 | GSb: -0.300838 | TSUw: -0.406075 | TSUb: -0.034067\n",
      "Validating epoch 5404...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012896557398382486\n",
      "Average validation loss: 0.013404785904614776\n",
      "Training epoch 5405...\n",
      "\n",
      "Train Epoch: 5405 [0/8000 (0%)]\tBatch Loss: 0.013080\tLearning Rate (w_theta): 0.001000\t TIME:1437.3s\n",
      "\t\t\t\tDisc: 0.012183\t\tSym: 0.000000\t\tSpars: 0.000897\n",
      "\t TVw: 0.780130 | TVb: 2.277668 | GSw: -0.618990 | GSb: -0.300630 | TSUw: -0.406242 | TSUb: -0.034155\n",
      "\n",
      "Train Epoch: 5405 [4000/8000 (50%)]\tBatch Loss: 0.013401\tLearning Rate (w_theta): 0.001000\t TIME:1438.6s\n",
      "\t\t\t\tDisc: 0.012584\t\tSym: 0.000000\t\tSpars: 0.000817\n",
      "\t TVw: 0.780353 | TVb: 2.277733 | GSw: -0.618833 | GSb: -0.300417 | TSUw: -0.406318 | TSUb: -0.034178\n",
      "Validating epoch 5405...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012895853806361006\n",
      "Average validation loss: 0.013403970126823692\n",
      "Training epoch 5406...\n",
      "\n",
      "Train Epoch: 5406 [0/8000 (0%)]\tBatch Loss: 0.012599\tLearning Rate (w_theta): 0.001000\t TIME:1440.8s\n",
      "\t\t\t\tDisc: 0.011778\t\tSym: 0.000000\t\tSpars: 0.000821\n",
      "\t TVw: 0.780220 | TVb: 2.277799 | GSw: -0.618675 | GSb: -0.300201 | TSUw: -0.406326 | TSUb: -0.034153\n",
      "\n",
      "Train Epoch: 5406 [4000/8000 (50%)]\tBatch Loss: 0.012918\tLearning Rate (w_theta): 0.001000\t TIME:1442.0s\n",
      "\t\t\t\tDisc: 0.012124\t\tSym: 0.000000\t\tSpars: 0.000794\n",
      "\t TVw: 0.780404 | TVb: 2.277924 | GSw: -0.618541 | GSb: -0.300010 | TSUw: -0.406839 | TSUb: -0.034485\n",
      "Validating epoch 5406...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012896133474944173\n",
      "Average validation loss: 0.013403435865637997\n",
      "Training epoch 5407...\n",
      "\n",
      "Train Epoch: 5407 [0/8000 (0%)]\tBatch Loss: 0.013067\tLearning Rate (w_theta): 0.001000\t TIME:1444.3s\n",
      "\t\t\t\tDisc: 0.012158\t\tSym: 0.000000\t\tSpars: 0.000909\n",
      "\t TVw: 0.780214 | TVb: 2.277934 | GSw: -0.618352 | GSb: -0.299759 | TSUw: -0.406202 | TSUb: -0.034000\n",
      "\n",
      "Train Epoch: 5407 [4000/8000 (50%)]\tBatch Loss: 0.012175\tLearning Rate (w_theta): 0.001000\t TIME:1445.6s\n",
      "\t\t\t\tDisc: 0.011476\t\tSym: 0.000000\t\tSpars: 0.000699\n",
      "\t TVw: 0.779930 | TVb: 2.277898 | GSw: -0.618187 | GSb: -0.299533 | TSUw: -0.406065 | TSUb: -0.033870\n",
      "Validating epoch 5407...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012895408464311255\n",
      "Average validation loss: 0.013402918986800362\n",
      "Training epoch 5408...\n",
      "\n",
      "Train Epoch: 5408 [0/8000 (0%)]\tBatch Loss: 0.012646\tLearning Rate (w_theta): 0.001000\t TIME:1448.0s\n",
      "\t\t\t\tDisc: 0.011786\t\tSym: 0.000000\t\tSpars: 0.000859\n",
      "\t TVw: 0.779793 | TVb: 2.277951 | GSw: -0.618022 | GSb: -0.299311 | TSUw: -0.405953 | TSUb: -0.033759\n",
      "\n",
      "Train Epoch: 5408 [4000/8000 (50%)]\tBatch Loss: 0.012664\tLearning Rate (w_theta): 0.001000\t TIME:1449.3s\n",
      "\t\t\t\tDisc: 0.011926\t\tSym: 0.000000\t\tSpars: 0.000738\n",
      "\t TVw: 0.779755 | TVb: 2.278048 | GSw: -0.617900 | GSb: -0.299135 | TSUw: -0.406651 | TSUb: -0.034226\n",
      "Validating epoch 5408...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012896434660281522\n",
      "Average validation loss: 0.013403847252928487\n",
      "Training epoch 5409...\n",
      "\n",
      "Train Epoch: 5409 [0/8000 (0%)]\tBatch Loss: 0.012671\tLearning Rate (w_theta): 0.001000\t TIME:1451.6s\n",
      "\t\t\t\tDisc: 0.011996\t\tSym: 0.000000\t\tSpars: 0.000676\n",
      "\t TVw: 0.779627 | TVb: 2.278105 | GSw: -0.617730 | GSb: -0.298905 | TSUw: -0.406412 | TSUb: -0.034023\n",
      "\n",
      "Train Epoch: 5409 [4000/8000 (50%)]\tBatch Loss: 0.012806\tLearning Rate (w_theta): 0.001000\t TIME:1452.9s\n",
      "\t\t\t\tDisc: 0.012017\t\tSym: 0.000000\t\tSpars: 0.000789\n",
      "\t TVw: 0.779305 | TVb: 2.278163 | GSw: -0.617535 | GSb: -0.298649 | TSUw: -0.405619 | TSUb: -0.033425\n",
      "Validating epoch 5409...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012896548952599174\n",
      "Average validation loss: 0.01340213885622116\n",
      "Training epoch 5410...\n",
      "\n",
      "Train Epoch: 5410 [0/8000 (0%)]\tBatch Loss: 0.012620\tLearning Rate (w_theta): 0.001000\t TIME:1455.1s\n",
      "\t\t\t\tDisc: 0.011893\t\tSym: 0.000000\t\tSpars: 0.000728\n",
      "\t TVw: 0.779219 | TVb: 2.278244 | GSw: -0.617401 | GSb: -0.298459 | TSUw: -0.406056 | TSUb: -0.033708\n",
      "\n",
      "Train Epoch: 5410 [4000/8000 (50%)]\tBatch Loss: 0.012485\tLearning Rate (w_theta): 0.001000\t TIME:1456.4s\n",
      "\t\t\t\tDisc: 0.011889\t\tSym: 0.000000\t\tSpars: 0.000596\n",
      "\t TVw: 0.779215 | TVb: 2.278370 | GSw: -0.617283 | GSb: -0.298284 | TSUw: -0.406800 | TSUb: -0.034211\n",
      "Validating epoch 5410...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012895532239550192\n",
      "Average validation loss: 0.013403214098016656\n",
      "Training epoch 5411...\n",
      "\n",
      "Train Epoch: 5411 [0/8000 (0%)]\tBatch Loss: 0.012986\tLearning Rate (w_theta): 0.001000\t TIME:1459.4s\n",
      "\t\t\t\tDisc: 0.012323\t\tSym: 0.000000\t\tSpars: 0.000663\n",
      "\t TVw: 0.779089 | TVb: 2.278457 | GSw: -0.617132 | GSb: -0.298075 | TSUw: -0.406921 | TSUb: -0.034267\n",
      "\n",
      "Train Epoch: 5411 [4000/8000 (50%)]\tBatch Loss: 0.012680\tLearning Rate (w_theta): 0.001000\t TIME:1460.7s\n",
      "\t\t\t\tDisc: 0.011762\t\tSym: 0.000000\t\tSpars: 0.000918\n",
      "\t TVw: 0.779243 | TVb: 2.278583 | GSw: -0.616983 | GSb: -0.297869 | TSUw: -0.407134 | TSUb: -0.034390\n",
      "Validating epoch 5411...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012894383946810027\n",
      "Average validation loss: 0.013402865179878955\n",
      "Training epoch 5412...\n",
      "\n",
      "Train Epoch: 5412 [0/8000 (0%)]\tBatch Loss: 0.012623\tLearning Rate (w_theta): 0.001000\t TIME:1463.2s\n",
      "\t\t\t\tDisc: 0.011861\t\tSym: 0.000000\t\tSpars: 0.000762\n",
      "\t TVw: 0.779121 | TVb: 2.278627 | GSw: -0.616810 | GSb: -0.297637 | TSUw: -0.406867 | TSUb: -0.034167\n",
      "\n",
      "Train Epoch: 5412 [4000/8000 (50%)]\tBatch Loss: 0.013452\tLearning Rate (w_theta): 0.001000\t TIME:1464.5s\n",
      "\t\t\t\tDisc: 0.012536\t\tSym: 0.000000\t\tSpars: 0.000915\n",
      "\t TVw: 0.779340 | TVb: 2.278766 | GSw: -0.616626 | GSb: -0.297394 | TSUw: -0.406387 | TSUb: -0.033791\n",
      "Validating epoch 5412...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012894196057311673\n",
      "Average validation loss: 0.013400991588812314\n",
      "Training epoch 5413...\n",
      "\n",
      "Train Epoch: 5413 [0/8000 (0%)]\tBatch Loss: 0.012689\tLearning Rate (w_theta): 0.001000\t TIME:1466.8s\n",
      "\t\t\t\tDisc: 0.012059\t\tSym: 0.000000\t\tSpars: 0.000630\n",
      "\t TVw: 0.778987 | TVb: 2.278776 | GSw: -0.616469 | GSb: -0.297178 | TSUw: -0.406402 | TSUb: -0.033771\n",
      "\n",
      "Train Epoch: 5413 [4000/8000 (50%)]\tBatch Loss: 0.012512\tLearning Rate (w_theta): 0.001000\t TIME:1468.0s\n",
      "\t\t\t\tDisc: 0.011910\t\tSym: 0.000000\t\tSpars: 0.000602\n",
      "\t TVw: 0.778574 | TVb: 2.278782 | GSw: -0.616295 | GSb: -0.296946 | TSUw: -0.406141 | TSUb: -0.033553\n",
      "Validating epoch 5413...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012894830011881462\n",
      "Average validation loss: 0.013401664001251328\n",
      "Training epoch 5414...\n",
      "\n",
      "Train Epoch: 5414 [0/8000 (0%)]\tBatch Loss: 0.013992\tLearning Rate (w_theta): 0.001000\t TIME:1470.3s\n",
      "\t\t\t\tDisc: 0.012895\t\tSym: 0.000000\t\tSpars: 0.001098\n",
      "\t TVw: 0.778462 | TVb: 2.278828 | GSw: -0.616175 | GSb: -0.296767 | TSUw: -0.406887 | TSUb: -0.034060\n",
      "\n",
      "Train Epoch: 5414 [4000/8000 (50%)]\tBatch Loss: 0.012585\tLearning Rate (w_theta): 0.001000\t TIME:1471.5s\n",
      "\t\t\t\tDisc: 0.011887\t\tSym: 0.000000\t\tSpars: 0.000698\n",
      "\t TVw: 0.779259 | TVb: 2.279058 | GSw: -0.616064 | GSb: -0.296600 | TSUw: -0.407922 | TSUb: -0.034779\n",
      "Validating epoch 5414...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012894477434204613\n",
      "Average validation loss: 0.013404207124087226\n",
      "Training epoch 5415...\n",
      "\n",
      "Train Epoch: 5415 [0/8000 (0%)]\tBatch Loss: 0.013453\tLearning Rate (w_theta): 0.001000\t TIME:1473.7s\n",
      "\t\t\t\tDisc: 0.012412\t\tSym: 0.000000\t\tSpars: 0.001041\n",
      "\t TVw: 0.779257 | TVb: 2.279125 | GSw: -0.615914 | GSb: -0.296391 | TSUw: -0.408084 | TSUb: -0.034863\n",
      "\n",
      "Train Epoch: 5415 [4000/8000 (50%)]\tBatch Loss: 0.012433\tLearning Rate (w_theta): 0.001000\t TIME:1475.0s\n",
      "\t\t\t\tDisc: 0.011749\t\tSym: 0.000000\t\tSpars: 0.000685\n",
      "\t TVw: 0.779185 | TVb: 2.279157 | GSw: -0.615745 | GSb: -0.296159 | TSUw: -0.407858 | TSUb: -0.034665\n",
      "Validating epoch 5415...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01289246360099682\n",
      "Average validation loss: 0.013401620784224797\n",
      "Training epoch 5416...\n",
      "\n",
      "Train Epoch: 5416 [0/8000 (0%)]\tBatch Loss: 0.012529\tLearning Rate (w_theta): 0.001000\t TIME:1477.3s\n",
      "\t\t\t\tDisc: 0.011652\t\tSym: 0.000000\t\tSpars: 0.000876\n",
      "\t TVw: 0.778674 | TVb: 2.279103 | GSw: -0.615550 | GSb: -0.295903 | TSUw: -0.407138 | TSUb: -0.034110\n",
      "\n",
      "Train Epoch: 5416 [4000/8000 (50%)]\tBatch Loss: 0.013002\tLearning Rate (w_theta): 0.001000\t TIME:1478.5s\n",
      "\t\t\t\tDisc: 0.012110\t\tSym: 0.000000\t\tSpars: 0.000893\n",
      "\t TVw: 0.778179 | TVb: 2.279055 | GSw: -0.615368 | GSb: -0.295663 | TSUw: -0.406732 | TSUb: -0.033782\n",
      "Validating epoch 5416...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0128934766026351\n",
      "Average validation loss: 0.01340069816978385\n",
      "Training epoch 5417...\n",
      "\n",
      "Train Epoch: 5417 [0/8000 (0%)]\tBatch Loss: 0.013127\tLearning Rate (w_theta): 0.001000\t TIME:1480.9s\n",
      "\t\t\t\tDisc: 0.012355\t\tSym: 0.000000\t\tSpars: 0.000772\n",
      "\t TVw: 0.777873 | TVb: 2.279076 | GSw: -0.615198 | GSb: -0.295433 | TSUw: -0.406518 | TSUb: -0.033595\n",
      "\n",
      "Train Epoch: 5417 [4000/8000 (50%)]\tBatch Loss: 0.013447\tLearning Rate (w_theta): 0.001000\t TIME:1482.2s\n",
      "\t\t\t\tDisc: 0.012344\t\tSym: 0.000000\t\tSpars: 0.001103\n",
      "\t TVw: 0.777507 | TVb: 2.279094 | GSw: -0.615040 | GSb: -0.295218 | TSUw: -0.406519 | TSUb: -0.033565\n",
      "Validating epoch 5417...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012895349727704224\n",
      "Average validation loss: 0.013401279408850412\n",
      "Training epoch 5418...\n",
      "\n",
      "Train Epoch: 5418 [0/8000 (0%)]\tBatch Loss: 0.012915\tLearning Rate (w_theta): 0.001000\t TIME:1484.4s\n",
      "\t\t\t\tDisc: 0.012040\t\tSym: 0.000000\t\tSpars: 0.000875\n",
      "\t TVw: 0.777657 | TVb: 2.279226 | GSw: -0.614920 | GSb: -0.295043 | TSUw: -0.407257 | TSUb: -0.034072\n",
      "\n",
      "Train Epoch: 5418 [4000/8000 (50%)]\tBatch Loss: 0.012744\tLearning Rate (w_theta): 0.001000\t TIME:1485.7s\n",
      "\t\t\t\tDisc: 0.012072\t\tSym: 0.000000\t\tSpars: 0.000671\n",
      "\t TVw: 0.777208 | TVb: 2.279185 | GSw: -0.614777 | GSb: -0.294844 | TSUw: -0.407542 | TSUb: -0.034249\n",
      "Validating epoch 5418...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012893700533335346\n",
      "Average validation loss: 0.01340272353600506\n",
      "Training epoch 5419...\n",
      "\n",
      "Train Epoch: 5419 [0/8000 (0%)]\tBatch Loss: 0.013530\tLearning Rate (w_theta): 0.001000\t TIME:1487.9s\n",
      "\t\t\t\tDisc: 0.012765\t\tSym: 0.000000\t\tSpars: 0.000765\n",
      "\t TVw: 0.777303 | TVb: 2.279290 | GSw: -0.614629 | GSb: -0.294639 | TSUw: -0.407791 | TSUb: -0.034400\n",
      "\n",
      "Train Epoch: 5419 [4000/8000 (50%)]\tBatch Loss: 0.013238\tLearning Rate (w_theta): 0.001000\t TIME:1489.2s\n",
      "\t\t\t\tDisc: 0.012311\t\tSym: 0.000000\t\tSpars: 0.000926\n",
      "\t TVw: 0.776459 | TVb: 2.279202 | GSw: -0.614431 | GSb: -0.294379 | TSUw: -0.406989 | TSUb: -0.033782\n",
      "Validating epoch 5419...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012895888627729345\n",
      "Average validation loss: 0.013401586018740672\n",
      "Training epoch 5420...\n",
      "\n",
      "Train Epoch: 5420 [0/8000 (0%)]\tBatch Loss: 0.013141\tLearning Rate (w_theta): 0.001000\t TIME:1491.4s\n",
      "\t\t\t\tDisc: 0.012350\t\tSym: 0.000000\t\tSpars: 0.000791\n",
      "\t TVw: 0.776524 | TVb: 2.279316 | GSw: -0.614308 | GSb: -0.294200 | TSUw: -0.407691 | TSUb: -0.034263\n",
      "\n",
      "Train Epoch: 5420 [4000/8000 (50%)]\tBatch Loss: 0.012456\tLearning Rate (w_theta): 0.001000\t TIME:1492.7s\n",
      "\t\t\t\tDisc: 0.011843\t\tSym: 0.000000\t\tSpars: 0.000613\n",
      "\t TVw: 0.776530 | TVb: 2.279399 | GSw: -0.614192 | GSb: -0.294028 | TSUw: -0.408547 | TSUb: -0.034857\n",
      "Validating epoch 5420...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012894396182853832\n",
      "Average validation loss: 0.013404063820450483\n",
      "Training epoch 5421...\n",
      "\n",
      "Train Epoch: 5421 [0/8000 (0%)]\tBatch Loss: 0.013418\tLearning Rate (w_theta): 0.001000\t TIME:1495.8s\n",
      "\t\t\t\tDisc: 0.012342\t\tSym: 0.000000\t\tSpars: 0.001076\n",
      "\t TVw: 0.776636 | TVb: 2.279482 | GSw: -0.614035 | GSb: -0.293814 | TSUw: -0.408611 | TSUb: -0.034871\n",
      "\n",
      "Train Epoch: 5421 [4000/8000 (50%)]\tBatch Loss: 0.013158\tLearning Rate (w_theta): 0.001000\t TIME:1497.1s\n",
      "\t\t\t\tDisc: 0.012112\t\tSym: 0.000000\t\tSpars: 0.001046\n",
      "\t TVw: 0.777333 | TVb: 2.279689 | GSw: -0.613872 | GSb: -0.293590 | TSUw: -0.408590 | TSUb: -0.034824\n",
      "Validating epoch 5421...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012892943185103757\n",
      "Average validation loss: 0.01340093000227498\n",
      "Training epoch 5422...\n",
      "\n",
      "Train Epoch: 5422 [0/8000 (0%)]\tBatch Loss: 0.013208\tLearning Rate (w_theta): 0.001000\t TIME:1499.3s\n",
      "\t\t\t\tDisc: 0.012543\t\tSym: 0.000000\t\tSpars: 0.000665\n",
      "\t TVw: 0.777366 | TVb: 2.279722 | GSw: -0.613671 | GSb: -0.293329 | TSUw: -0.407807 | TSUb: -0.034216\n",
      "\n",
      "Train Epoch: 5422 [4000/8000 (50%)]\tBatch Loss: 0.013490\tLearning Rate (w_theta): 0.001000\t TIME:1500.6s\n",
      "\t\t\t\tDisc: 0.012475\t\tSym: 0.000000\t\tSpars: 0.001015\n",
      "\t TVw: 0.777452 | TVb: 2.279824 | GSw: -0.613511 | GSb: -0.293116 | TSUw: -0.407818 | TSUb: -0.034189\n",
      "Validating epoch 5422...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012892294145997334\n",
      "Average validation loss: 0.013399706671635042\n",
      "Training epoch 5423...\n",
      "\n",
      "Train Epoch: 5423 [0/8000 (0%)]\tBatch Loss: 0.012186\tLearning Rate (w_theta): 0.001000\t TIME:1502.9s\n",
      "\t\t\t\tDisc: 0.011808\t\tSym: 0.000000\t\tSpars: 0.000378\n",
      "\t TVw: 0.777245 | TVb: 2.279830 | GSw: -0.613326 | GSb: -0.292871 | TSUw: -0.407347 | TSUb: -0.033811\n",
      "\n",
      "Train Epoch: 5423 [4000/8000 (50%)]\tBatch Loss: 0.013030\tLearning Rate (w_theta): 0.001000\t TIME:1504.2s\n",
      "\t\t\t\tDisc: 0.012268\t\tSym: 0.000000\t\tSpars: 0.000762\n",
      "\t TVw: 0.776359 | TVb: 2.279750 | GSw: -0.613104 | GSb: -0.292586 | TSUw: -0.406121 | TSUb: -0.032879\n",
      "Validating epoch 5423...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012897140771259013\n",
      "Average validation loss: 0.013399379573070865\n",
      "Training epoch 5424...\n",
      "\n",
      "Train Epoch: 5424 [0/8000 (0%)]\tBatch Loss: 0.012623\tLearning Rate (w_theta): 0.001000\t TIME:1506.4s\n",
      "\t\t\t\tDisc: 0.011882\t\tSym: 0.000000\t\tSpars: 0.000741\n",
      "\t TVw: 0.776421 | TVb: 2.279820 | GSw: -0.613002 | GSb: -0.292431 | TSUw: -0.407194 | TSUb: -0.033638\n",
      "\n",
      "Train Epoch: 5424 [4000/8000 (50%)]\tBatch Loss: 0.013007\tLearning Rate (w_theta): 0.001000\t TIME:1507.7s\n",
      "\t\t\t\tDisc: 0.011974\t\tSym: 0.000000\t\tSpars: 0.001033\n",
      "\t TVw: 0.776641 | TVb: 2.279926 | GSw: -0.612892 | GSb: -0.292266 | TSUw: -0.408119 | TSUb: -0.034291\n",
      "Validating epoch 5424...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012892158693180878\n",
      "Average validation loss: 0.013402741286332544\n",
      "Training epoch 5425...\n",
      "\n",
      "Train Epoch: 5425 [0/8000 (0%)]\tBatch Loss: 0.012193\tLearning Rate (w_theta): 0.001000\t TIME:1510.0s\n",
      "\t\t\t\tDisc: 0.011617\t\tSym: 0.000000\t\tSpars: 0.000576\n",
      "\t TVw: 0.776969 | TVb: 2.280061 | GSw: -0.612791 | GSb: -0.292110 | TSUw: -0.409280 | TSUb: -0.035118\n",
      "\n",
      "Train Epoch: 5425 [4000/8000 (50%)]\tBatch Loss: 0.012412\tLearning Rate (w_theta): 0.001000\t TIME:1511.3s\n",
      "\t\t\t\tDisc: 0.011690\t\tSym: 0.000000\t\tSpars: 0.000722\n",
      "\t TVw: 0.777237 | TVb: 2.280162 | GSw: -0.612664 | GSb: -0.291927 | TSUw: -0.409977 | TSUb: -0.035601\n",
      "Validating epoch 5425...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012893199384882833\n",
      "Average validation loss: 0.013404518333458015\n",
      "Training epoch 5426...\n",
      "\n",
      "Train Epoch: 5426 [0/8000 (0%)]\tBatch Loss: 0.012817\tLearning Rate (w_theta): 0.001000\t TIME:1513.5s\n",
      "\t\t\t\tDisc: 0.012086\t\tSym: 0.000000\t\tSpars: 0.000732\n",
      "\t TVw: 0.777458 | TVb: 2.280256 | GSw: -0.612478 | GSb: -0.291681 | TSUw: -0.409482 | TSUb: -0.035195\n",
      "\n",
      "Train Epoch: 5426 [4000/8000 (50%)]\tBatch Loss: 0.012730\tLearning Rate (w_theta): 0.001000\t TIME:1514.8s\n",
      "\t\t\t\tDisc: 0.011891\t\tSym: 0.000000\t\tSpars: 0.000840\n",
      "\t TVw: 0.777666 | TVb: 2.280284 | GSw: -0.612260 | GSb: -0.291400 | TSUw: -0.408352 | TSUb: -0.034319\n",
      "Validating epoch 5426...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012890247029484951\n",
      "Average validation loss: 0.013397998224549467\n",
      "Training epoch 5427...\n",
      "\n",
      "Train Epoch: 5427 [0/8000 (0%)]\tBatch Loss: 0.012228\tLearning Rate (w_theta): 0.001000\t TIME:1517.1s\n",
      "\t\t\t\tDisc: 0.011530\t\tSym: 0.000000\t\tSpars: 0.000698\n",
      "\t TVw: 0.777416 | TVb: 2.280266 | GSw: -0.612056 | GSb: -0.291134 | TSUw: -0.407498 | TSUb: -0.033648\n",
      "\n",
      "Train Epoch: 5427 [4000/8000 (50%)]\tBatch Loss: 0.013125\tLearning Rate (w_theta): 0.001000\t TIME:1518.3s\n",
      "\t\t\t\tDisc: 0.012471\t\tSym: 0.000000\t\tSpars: 0.000654\n",
      "\t TVw: 0.777446 | TVb: 2.280305 | GSw: -0.611887 | GSb: -0.290907 | TSUw: -0.407341 | TSUb: -0.033498\n",
      "Validating epoch 5427...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012891862334833333\n",
      "Average validation loss: 0.01339795424527347\n",
      "Training epoch 5428...\n",
      "\n",
      "Train Epoch: 5428 [0/8000 (0%)]\tBatch Loss: 0.013357\tLearning Rate (w_theta): 0.001000\t TIME:1520.6s\n",
      "\t\t\t\tDisc: 0.012411\t\tSym: 0.000000\t\tSpars: 0.000946\n",
      "\t TVw: 0.777116 | TVb: 2.280317 | GSw: -0.611740 | GSb: -0.290702 | TSUw: -0.407569 | TSUb: -0.033637\n",
      "\n",
      "Train Epoch: 5428 [4000/8000 (50%)]\tBatch Loss: 0.012388\tLearning Rate (w_theta): 0.001000\t TIME:1521.8s\n",
      "\t\t\t\tDisc: 0.011695\t\tSym: 0.000000\t\tSpars: 0.000693\n",
      "\t TVw: 0.777421 | TVb: 2.280443 | GSw: -0.611600 | GSb: -0.290502 | TSUw: -0.408017 | TSUb: -0.033942\n",
      "Validating epoch 5428...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012890700325534793\n",
      "Average validation loss: 0.01339871242360517\n",
      "Training epoch 5429...\n",
      "\n",
      "Train Epoch: 5429 [0/8000 (0%)]\tBatch Loss: 0.012374\tLearning Rate (w_theta): 0.001000\t TIME:1524.1s\n",
      "\t\t\t\tDisc: 0.011781\t\tSym: 0.000000\t\tSpars: 0.000593\n",
      "\t TVw: 0.777217 | TVb: 2.280505 | GSw: -0.611484 | GSb: -0.290331 | TSUw: -0.408864 | TSUb: -0.034544\n",
      "\n",
      "Train Epoch: 5429 [4000/8000 (50%)]\tBatch Loss: 0.013605\tLearning Rate (w_theta): 0.001000\t TIME:1525.4s\n",
      "\t\t\t\tDisc: 0.012563\t\tSym: 0.000000\t\tSpars: 0.001042\n",
      "\t TVw: 0.776661 | TVb: 2.280427 | GSw: -0.611336 | GSb: -0.290128 | TSUw: -0.409108 | TSUb: -0.034693\n",
      "Validating epoch 5429...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012890780584931535\n",
      "Average validation loss: 0.013401585414753647\n",
      "Training epoch 5430...\n",
      "\n",
      "Train Epoch: 5430 [0/8000 (0%)]\tBatch Loss: 0.012442\tLearning Rate (w_theta): 0.001000\t TIME:1527.7s\n",
      "\t\t\t\tDisc: 0.011741\t\tSym: 0.000000\t\tSpars: 0.000701\n",
      "\t TVw: 0.776641 | TVb: 2.280479 | GSw: -0.611180 | GSb: -0.289915 | TSUw: -0.409251 | TSUb: -0.034767\n",
      "\n",
      "Train Epoch: 5430 [4000/8000 (50%)]\tBatch Loss: 0.013097\tLearning Rate (w_theta): 0.001000\t TIME:1529.0s\n",
      "\t\t\t\tDisc: 0.012147\t\tSym: 0.000000\t\tSpars: 0.000950\n",
      "\t TVw: 0.776043 | TVb: 2.280351 | GSw: -0.610964 | GSb: -0.289636 | TSUw: -0.408186 | TSUb: -0.033934\n",
      "Validating epoch 5430...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012893464891462623\n",
      "Average validation loss: 0.013398865900860592\n",
      "Training epoch 5431...\n",
      "\n",
      "Train Epoch: 5431 [0/8000 (0%)]\tBatch Loss: 0.012716\tLearning Rate (w_theta): 0.001000\t TIME:1531.9s\n",
      "\t\t\t\tDisc: 0.011926\t\tSym: 0.000000\t\tSpars: 0.000789\n",
      "\t TVw: 0.776186 | TVb: 2.280472 | GSw: -0.610824 | GSb: -0.289439 | TSUw: -0.408614 | TSUb: -0.034224\n",
      "\n",
      "Train Epoch: 5431 [4000/8000 (50%)]\tBatch Loss: 0.013487\tLearning Rate (w_theta): 0.001000\t TIME:1533.2s\n",
      "\t\t\t\tDisc: 0.012422\t\tSym: 0.000000\t\tSpars: 0.001064\n",
      "\t TVw: 0.776380 | TVb: 2.280565 | GSw: -0.610671 | GSb: -0.289228 | TSUw: -0.408806 | TSUb: -0.034336\n",
      "Validating epoch 5431...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012890653662081928\n",
      "Average validation loss: 0.013399221123012435\n",
      "Training epoch 5432...\n",
      "\n",
      "Train Epoch: 5432 [0/8000 (0%)]\tBatch Loss: 0.013479\tLearning Rate (w_theta): 0.001000\t TIME:1535.4s\n",
      "\t\t\t\tDisc: 0.012620\t\tSym: 0.000000\t\tSpars: 0.000859\n",
      "\t TVw: 0.776444 | TVb: 2.280667 | GSw: -0.610524 | GSb: -0.289023 | TSUw: -0.409128 | TSUb: -0.034547\n",
      "\n",
      "Train Epoch: 5432 [4000/8000 (50%)]\tBatch Loss: 0.012412\tLearning Rate (w_theta): 0.001000\t TIME:1536.7s\n",
      "\t\t\t\tDisc: 0.011761\t\tSym: 0.000000\t\tSpars: 0.000651\n",
      "\t TVw: 0.775890 | TVb: 2.280635 | GSw: -0.610349 | GSb: -0.288785 | TSUw: -0.408878 | TSUb: -0.034327\n",
      "Validating epoch 5432...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012890997668327001\n",
      "Average validation loss: 0.013399068151051042\n",
      "Training epoch 5433...\n",
      "\n",
      "Train Epoch: 5433 [0/8000 (0%)]\tBatch Loss: 0.012671\tLearning Rate (w_theta): 0.001000\t TIME:1538.9s\n",
      "\t\t\t\tDisc: 0.011777\t\tSym: 0.000000\t\tSpars: 0.000895\n",
      "\t TVw: 0.775810 | TVb: 2.280689 | GSw: -0.610202 | GSb: -0.288581 | TSUw: -0.409198 | TSUb: -0.034536\n",
      "\n",
      "Train Epoch: 5433 [4000/8000 (50%)]\tBatch Loss: 0.012859\tLearning Rate (w_theta): 0.001000\t TIME:1540.2s\n",
      "\t\t\t\tDisc: 0.012278\t\tSym: 0.000000\t\tSpars: 0.000581\n",
      "\t TVw: 0.775779 | TVb: 2.280782 | GSw: -0.610057 | GSb: -0.288384 | TSUw: -0.409613 | TSUb: -0.034816\n",
      "Validating epoch 5433...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012890983194151514\n",
      "Average validation loss: 0.013399375033613287\n",
      "Training epoch 5434...\n",
      "\n",
      "Train Epoch: 5434 [0/8000 (0%)]\tBatch Loss: 0.013268\tLearning Rate (w_theta): 0.001000\t TIME:1542.5s\n",
      "\t\t\t\tDisc: 0.012344\t\tSym: 0.000000\t\tSpars: 0.000924\n",
      "\t TVw: 0.775716 | TVb: 2.280824 | GSw: -0.609877 | GSb: -0.288144 | TSUw: -0.409313 | TSUb: -0.034556\n",
      "\n",
      "Train Epoch: 5434 [4000/8000 (50%)]\tBatch Loss: 0.012083\tLearning Rate (w_theta): 0.001000\t TIME:1543.8s\n",
      "\t\t\t\tDisc: 0.011487\t\tSym: 0.000000\t\tSpars: 0.000596\n",
      "\t TVw: 0.775877 | TVb: 2.280870 | GSw: -0.609692 | GSb: -0.287897 | TSUw: -0.408953 | TSUb: -0.034252\n",
      "Validating epoch 5434...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012890289216087777\n",
      "Average validation loss: 0.013398170673913006\n",
      "Training epoch 5435...\n",
      "\n",
      "Train Epoch: 5435 [0/8000 (0%)]\tBatch Loss: 0.012822\tLearning Rate (w_theta): 0.001000\t TIME:1546.2s\n",
      "\t\t\t\tDisc: 0.012008\t\tSym: 0.000000\t\tSpars: 0.000814\n",
      "\t TVw: 0.775930 | TVb: 2.280919 | GSw: -0.609537 | GSb: -0.287685 | TSUw: -0.409146 | TSUb: -0.034366\n",
      "\n",
      "Train Epoch: 5435 [4000/8000 (50%)]\tBatch Loss: 0.013227\tLearning Rate (w_theta): 0.001000\t TIME:1547.5s\n",
      "\t\t\t\tDisc: 0.012472\t\tSym: 0.000000\t\tSpars: 0.000756\n",
      "\t TVw: 0.775519 | TVb: 2.280919 | GSw: -0.609341 | GSb: -0.287428 | TSUw: -0.408529 | TSUb: -0.033867\n",
      "Validating epoch 5435...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0128916558424025\n",
      "Average validation loss: 0.013397447043849932\n",
      "Training epoch 5436...\n",
      "\n",
      "Train Epoch: 5436 [0/8000 (0%)]\tBatch Loss: 0.012594\tLearning Rate (w_theta): 0.001000\t TIME:1549.9s\n",
      "\t\t\t\tDisc: 0.011593\t\tSym: 0.000000\t\tSpars: 0.001001\n",
      "\t TVw: 0.775667 | TVb: 2.281011 | GSw: -0.609207 | GSb: -0.287238 | TSUw: -0.409107 | TSUb: -0.034276\n",
      "\n",
      "Train Epoch: 5436 [4000/8000 (50%)]\tBatch Loss: 0.012996\tLearning Rate (w_theta): 0.001000\t TIME:1551.2s\n",
      "\t\t\t\tDisc: 0.012244\t\tSym: 0.000000\t\tSpars: 0.000751\n",
      "\t TVw: 0.776492 | TVb: 2.281173 | GSw: -0.609108 | GSb: -0.287086 | TSUw: -0.410395 | TSUb: -0.035226\n",
      "Validating epoch 5436...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012890172388482722\n",
      "Average validation loss: 0.013400338381928743\n",
      "Training epoch 5437...\n",
      "\n",
      "Train Epoch: 5437 [0/8000 (0%)]\tBatch Loss: 0.013060\tLearning Rate (w_theta): 0.001000\t TIME:1553.4s\n",
      "\t\t\t\tDisc: 0.012389\t\tSym: 0.000000\t\tSpars: 0.000671\n",
      "\t TVw: 0.776516 | TVb: 2.281233 | GSw: -0.608946 | GSb: -0.286867 | TSUw: -0.410411 | TSUb: -0.035205\n",
      "\n",
      "Train Epoch: 5437 [4000/8000 (50%)]\tBatch Loss: 0.012495\tLearning Rate (w_theta): 0.001000\t TIME:1554.7s\n",
      "\t\t\t\tDisc: 0.011891\t\tSym: 0.000000\t\tSpars: 0.000604\n",
      "\t TVw: 0.776386 | TVb: 2.281273 | GSw: -0.608753 | GSb: -0.286612 | TSUw: -0.409825 | TSUb: -0.034723\n",
      "Validating epoch 5437...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012888650913313761\n",
      "Average validation loss: 0.01339749677100408\n",
      "Training epoch 5438...\n",
      "\n",
      "Train Epoch: 5438 [0/8000 (0%)]\tBatch Loss: 0.012103\tLearning Rate (w_theta): 0.001000\t TIME:1557.1s\n",
      "\t\t\t\tDisc: 0.011591\t\tSym: 0.000000\t\tSpars: 0.000512\n",
      "\t TVw: 0.776187 | TVb: 2.281273 | GSw: -0.608568 | GSb: -0.286368 | TSUw: -0.409432 | TSUb: -0.034387\n",
      "\n",
      "Train Epoch: 5438 [4000/8000 (50%)]\tBatch Loss: 0.013274\tLearning Rate (w_theta): 0.001000\t TIME:1558.4s\n",
      "\t\t\t\tDisc: 0.012371\t\tSym: 0.000000\t\tSpars: 0.000903\n",
      "\t TVw: 0.775791 | TVb: 2.281265 | GSw: -0.608373 | GSb: -0.286111 | TSUw: -0.408837 | TSUb: -0.033899\n",
      "Validating epoch 5438...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012890285356452202\n",
      "Average validation loss: 0.013396512069005153\n",
      "Training epoch 5439...\n",
      "\n",
      "Train Epoch: 5439 [0/8000 (0%)]\tBatch Loss: 0.013129\tLearning Rate (w_theta): 0.001000\t TIME:1560.6s\n",
      "\t\t\t\tDisc: 0.012378\t\tSym: 0.000000\t\tSpars: 0.000751\n",
      "\t TVw: 0.775666 | TVb: 2.281284 | GSw: -0.608229 | GSb: -0.285909 | TSUw: -0.409236 | TSUb: -0.034172\n",
      "\n",
      "Train Epoch: 5439 [4000/8000 (50%)]\tBatch Loss: 0.013000\tLearning Rate (w_theta): 0.001000\t TIME:1561.9s\n",
      "\t\t\t\tDisc: 0.012187\t\tSym: 0.000000\t\tSpars: 0.000814\n",
      "\t TVw: 0.775588 | TVb: 2.281340 | GSw: -0.608118 | GSb: -0.285741 | TSUw: -0.410232 | TSUb: -0.034904\n",
      "Validating epoch 5439...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012889883371925877\n",
      "Average validation loss: 0.013399100251175309\n",
      "Training epoch 5440...\n",
      "\n",
      "Train Epoch: 5440 [0/8000 (0%)]\tBatch Loss: 0.013064\tLearning Rate (w_theta): 0.001000\t TIME:1564.2s\n",
      "\t\t\t\tDisc: 0.012447\t\tSym: 0.000000\t\tSpars: 0.000618\n",
      "\t TVw: 0.775613 | TVb: 2.281372 | GSw: -0.607952 | GSb: -0.285516 | TSUw: -0.410194 | TSUb: -0.034843\n",
      "\n",
      "Train Epoch: 5440 [4000/8000 (50%)]\tBatch Loss: 0.012565\tLearning Rate (w_theta): 0.001000\t TIME:1565.4s\n",
      "\t\t\t\tDisc: 0.012100\t\tSym: 0.000000\t\tSpars: 0.000465\n",
      "\t TVw: 0.775456 | TVb: 2.281397 | GSw: -0.607783 | GSb: -0.285290 | TSUw: -0.410138 | TSUb: -0.034766\n",
      "Validating epoch 5440...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012888891685629945\n",
      "Average validation loss: 0.013397339814415888\n",
      "Training epoch 5441...\n",
      "\n",
      "Train Epoch: 5441 [0/8000 (0%)]\tBatch Loss: 0.012774\tLearning Rate (w_theta): 0.001000\t TIME:1568.4s\n",
      "\t\t\t\tDisc: 0.012201\t\tSym: 0.000000\t\tSpars: 0.000573\n",
      "\t TVw: 0.775517 | TVb: 2.281433 | GSw: -0.607591 | GSb: -0.285038 | TSUw: -0.409646 | TSUb: -0.034354\n",
      "\n",
      "Train Epoch: 5441 [4000/8000 (50%)]\tBatch Loss: 0.012752\tLearning Rate (w_theta): 0.001000\t TIME:1569.7s\n",
      "\t\t\t\tDisc: 0.012162\t\tSym: 0.000000\t\tSpars: 0.000591\n",
      "\t TVw: 0.775609 | TVb: 2.281400 | GSw: -0.607394 | GSb: -0.284779 | TSUw: -0.409130 | TSUb: -0.033926\n",
      "Validating epoch 5441...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012889827900338728\n",
      "Average validation loss: 0.013396127783759747\n",
      "Training epoch 5442...\n",
      "\n",
      "Train Epoch: 5442 [0/8000 (0%)]\tBatch Loss: 0.012534\tLearning Rate (w_theta): 0.001000\t TIME:1571.8s\n",
      "\t\t\t\tDisc: 0.011910\t\tSym: 0.000000\t\tSpars: 0.000624\n",
      "\t TVw: 0.775628 | TVb: 2.281452 | GSw: -0.607253 | GSb: -0.284584 | TSUw: -0.409586 | TSUb: -0.034247\n",
      "\n",
      "Train Epoch: 5442 [4000/8000 (50%)]\tBatch Loss: 0.013025\tLearning Rate (w_theta): 0.001000\t TIME:1573.1s\n",
      "\t\t\t\tDisc: 0.012012\t\tSym: 0.000000\t\tSpars: 0.001013\n",
      "\t TVw: 0.775757 | TVb: 2.281534 | GSw: -0.607131 | GSb: -0.284409 | TSUw: -0.410423 | TSUb: -0.034861\n",
      "Validating epoch 5442...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01288834961546722\n",
      "Average validation loss: 0.013398514616770987\n",
      "Training epoch 5443...\n",
      "\n",
      "Train Epoch: 5443 [0/8000 (0%)]\tBatch Loss: 0.012820\tLearning Rate (w_theta): 0.001000\t TIME:1575.5s\n",
      "\t\t\t\tDisc: 0.012025\t\tSym: 0.000000\t\tSpars: 0.000795\n",
      "\t TVw: 0.775964 | TVb: 2.281646 | GSw: -0.606981 | GSb: -0.284201 | TSUw: -0.410764 | TSUb: -0.035093\n",
      "\n",
      "Train Epoch: 5443 [4000/8000 (50%)]\tBatch Loss: 0.012486\tLearning Rate (w_theta): 0.001000\t TIME:1576.8s\n",
      "\t\t\t\tDisc: 0.011782\t\tSym: 0.000000\t\tSpars: 0.000703\n",
      "\t TVw: 0.775694 | TVb: 2.281642 | GSw: -0.606788 | GSb: -0.283945 | TSUw: -0.410233 | TSUb: -0.034649\n",
      "Validating epoch 5443...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012888464977263673\n",
      "Average validation loss: 0.013396443814905581\n",
      "Training epoch 5444...\n",
      "\n",
      "Train Epoch: 5444 [0/8000 (0%)]\tBatch Loss: 0.012986\tLearning Rate (w_theta): 0.001000\t TIME:1579.0s\n",
      "\t\t\t\tDisc: 0.012166\t\tSym: 0.000000\t\tSpars: 0.000820\n",
      "\t TVw: 0.775443 | TVb: 2.281636 | GSw: -0.606596 | GSb: -0.283693 | TSUw: -0.409747 | TSUb: -0.034239\n",
      "\n",
      "Train Epoch: 5444 [4000/8000 (50%)]\tBatch Loss: 0.013320\tLearning Rate (w_theta): 0.001000\t TIME:1580.2s\n",
      "\t\t\t\tDisc: 0.012416\t\tSym: 0.000000\t\tSpars: 0.000905\n",
      "\t TVw: 0.775287 | TVb: 2.281669 | GSw: -0.606427 | GSb: -0.283465 | TSUw: -0.409719 | TSUb: -0.034185\n",
      "Validating epoch 5444...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012888521936952745\n",
      "Average validation loss: 0.013396297758840336\n",
      "Training epoch 5445...\n",
      "\n",
      "Train Epoch: 5445 [0/8000 (0%)]\tBatch Loss: 0.013331\tLearning Rate (w_theta): 0.001000\t TIME:1582.5s\n",
      "\t\t\t\tDisc: 0.012467\t\tSym: 0.000000\t\tSpars: 0.000863\n",
      "\t TVw: 0.775428 | TVb: 2.281736 | GSw: -0.606285 | GSb: -0.283267 | TSUw: -0.410191 | TSUb: -0.034520\n",
      "\n",
      "Train Epoch: 5445 [4000/8000 (50%)]\tBatch Loss: 0.012536\tLearning Rate (w_theta): 0.001000\t TIME:1583.7s\n",
      "\t\t\t\tDisc: 0.011612\t\tSym: 0.000000\t\tSpars: 0.000924\n",
      "\t TVw: 0.775202 | TVb: 2.281780 | GSw: -0.606153 | GSb: -0.283082 | TSUw: -0.410873 | TSUb: -0.035017\n",
      "Validating epoch 5445...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012887952866143288\n",
      "Average validation loss: 0.013398457224675087\n",
      "Training epoch 5446...\n",
      "\n",
      "Train Epoch: 5446 [0/8000 (0%)]\tBatch Loss: 0.012759\tLearning Rate (w_theta): 0.001000\t TIME:1585.9s\n",
      "\t\t\t\tDisc: 0.011951\t\tSym: 0.000000\t\tSpars: 0.000808\n",
      "\t TVw: 0.775262 | TVb: 2.281837 | GSw: -0.605990 | GSb: -0.282860 | TSUw: -0.410984 | TSUb: -0.035071\n",
      "\n",
      "Train Epoch: 5446 [4000/8000 (50%)]\tBatch Loss: 0.012442\tLearning Rate (w_theta): 0.001000\t TIME:1587.2s\n",
      "\t\t\t\tDisc: 0.011804\t\tSym: 0.000000\t\tSpars: 0.000639\n",
      "\t TVw: 0.775297 | TVb: 2.281877 | GSw: -0.605819 | GSb: -0.282633 | TSUw: -0.410922 | TSUb: -0.034988\n",
      "Validating epoch 5446...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012887468813100666\n",
      "Average validation loss: 0.013396378193862385\n",
      "Training epoch 5447...\n",
      "\n",
      "Train Epoch: 5447 [0/8000 (0%)]\tBatch Loss: 0.012687\tLearning Rate (w_theta): 0.001000\t TIME:1589.6s\n",
      "\t\t\t\tDisc: 0.012038\t\tSym: 0.000000\t\tSpars: 0.000649\n",
      "\t TVw: 0.775207 | TVb: 2.281855 | GSw: -0.605614 | GSb: -0.282365 | TSUw: -0.410217 | TSUb: -0.034407\n",
      "\n",
      "Train Epoch: 5447 [4000/8000 (50%)]\tBatch Loss: 0.012597\tLearning Rate (w_theta): 0.001000\t TIME:1590.9s\n",
      "\t\t\t\tDisc: 0.011890\t\tSym: 0.000000\t\tSpars: 0.000707\n",
      "\t TVw: 0.774772 | TVb: 2.281841 | GSw: -0.605420 | GSb: -0.282108 | TSUw: -0.409773 | TSUb: -0.034028\n",
      "Validating epoch 5447...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012889032313371218\n",
      "Average validation loss: 0.013395760706675523\n",
      "Training epoch 5448...\n",
      "\n",
      "Train Epoch: 5448 [0/8000 (0%)]\tBatch Loss: 0.013386\tLearning Rate (w_theta): 0.001000\t TIME:1593.1s\n",
      "\t\t\t\tDisc: 0.012310\t\tSym: 0.000000\t\tSpars: 0.001076\n",
      "\t TVw: 0.774775 | TVb: 2.281891 | GSw: -0.605279 | GSb: -0.281910 | TSUw: -0.410263 | TSUb: -0.034378\n",
      "\n",
      "Train Epoch: 5448 [4000/8000 (50%)]\tBatch Loss: 0.012684\tLearning Rate (w_theta): 0.001000\t TIME:1594.4s\n",
      "\t\t\t\tDisc: 0.011775\t\tSym: 0.000000\t\tSpars: 0.000909\n",
      "\t TVw: 0.775077 | TVb: 2.282023 | GSw: -0.605137 | GSb: -0.281712 | TSUw: -0.410760 | TSUb: -0.034736\n",
      "Validating epoch 5448...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012887673273885243\n",
      "Average validation loss: 0.013397300868972077\n",
      "Training epoch 5449...\n",
      "\n",
      "Train Epoch: 5449 [0/8000 (0%)]\tBatch Loss: 0.013211\tLearning Rate (w_theta): 0.001000\t TIME:1596.7s\n",
      "\t\t\t\tDisc: 0.012394\t\tSym: 0.000000\t\tSpars: 0.000816\n",
      "\t TVw: 0.774965 | TVb: 2.282028 | GSw: -0.604986 | GSb: -0.281506 | TSUw: -0.411110 | TSUb: -0.034977\n",
      "\n",
      "Train Epoch: 5449 [4000/8000 (50%)]\tBatch Loss: 0.012898\tLearning Rate (w_theta): 0.001000\t TIME:1598.0s\n",
      "\t\t\t\tDisc: 0.012029\t\tSym: 0.000000\t\tSpars: 0.000869\n",
      "\t TVw: 0.774608 | TVb: 2.281976 | GSw: -0.604782 | GSb: -0.281240 | TSUw: -0.410418 | TSUb: -0.034404\n",
      "Validating epoch 5449...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012888593064340027\n",
      "Average validation loss: 0.013396132655084709\n",
      "Training epoch 5450...\n",
      "\n",
      "Train Epoch: 5450 [0/8000 (0%)]\tBatch Loss: 0.013025\tLearning Rate (w_theta): 0.001000\t TIME:1600.2s\n",
      "\t\t\t\tDisc: 0.012133\t\tSym: 0.000000\t\tSpars: 0.000892\n",
      "\t TVw: 0.774456 | TVb: 2.281951 | GSw: -0.604623 | GSb: -0.281023 | TSUw: -0.410567 | TSUb: -0.034488\n",
      "\n",
      "Train Epoch: 5450 [4000/8000 (50%)]\tBatch Loss: 0.012744\tLearning Rate (w_theta): 0.001000\t TIME:1601.5s\n",
      "\t\t\t\tDisc: 0.011905\t\tSym: 0.000000\t\tSpars: 0.000840\n",
      "\t TVw: 0.774625 | TVb: 2.282001 | GSw: -0.604476 | GSb: -0.280821 | TSUw: -0.410980 | TSUb: -0.034780\n",
      "Validating epoch 5450...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012887454004556195\n",
      "Average validation loss: 0.013396899422500897\n",
      "Training epoch 5451...\n",
      "\n",
      "Train Epoch: 5451 [0/8000 (0%)]\tBatch Loss: 0.012703\tLearning Rate (w_theta): 0.001000\t TIME:1604.6s\n",
      "\t\t\t\tDisc: 0.011999\t\tSym: 0.000000\t\tSpars: 0.000704\n",
      "\t TVw: 0.774717 | TVb: 2.282072 | GSw: -0.604323 | GSb: -0.280612 | TSUw: -0.411305 | TSUb: -0.035002\n",
      "\n",
      "Train Epoch: 5451 [4000/8000 (50%)]\tBatch Loss: 0.012634\tLearning Rate (w_theta): 0.001000\t TIME:1605.8s\n",
      "\t\t\t\tDisc: 0.011817\t\tSym: 0.000000\t\tSpars: 0.000817\n",
      "\t TVw: 0.775419 | TVb: 2.282194 | GSw: -0.604166 | GSb: -0.280395 | TSUw: -0.411576 | TSUb: -0.035184\n",
      "Validating epoch 5451...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012887012063168658\n",
      "Average validation loss: 0.013397117876660068\n",
      "Training epoch 5452...\n",
      "\n",
      "Train Epoch: 5452 [0/8000 (0%)]\tBatch Loss: 0.013121\tLearning Rate (w_theta): 0.001000\t TIME:1608.2s\n",
      "\t\t\t\tDisc: 0.012015\t\tSym: 0.000000\t\tSpars: 0.001105\n",
      "\t TVw: 0.775536 | TVb: 2.282256 | GSw: -0.603996 | GSb: -0.280166 | TSUw: -0.411588 | TSUb: -0.035159\n",
      "\n",
      "Train Epoch: 5452 [4000/8000 (50%)]\tBatch Loss: 0.013027\tLearning Rate (w_theta): 0.001000\t TIME:1609.4s\n",
      "\t\t\t\tDisc: 0.011922\t\tSym: 0.000000\t\tSpars: 0.001105\n",
      "\t TVw: 0.775847 | TVb: 2.282347 | GSw: -0.603812 | GSb: -0.279926 | TSUw: -0.411394 | TSUb: -0.034971\n",
      "Validating epoch 5452...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01288552996003672\n",
      "Average validation loss: 0.013394379048893817\n",
      "Training epoch 5453...\n",
      "\n",
      "Train Epoch: 5453 [0/8000 (0%)]\tBatch Loss: 0.013306\tLearning Rate (w_theta): 0.001000\t TIME:1611.6s\n",
      "\t\t\t\tDisc: 0.012273\t\tSym: 0.000000\t\tSpars: 0.001033\n",
      "\t TVw: 0.775732 | TVb: 2.282367 | GSw: -0.603601 | GSb: -0.279651 | TSUw: -0.410618 | TSUb: -0.034326\n",
      "\n",
      "Train Epoch: 5453 [4000/8000 (50%)]\tBatch Loss: 0.012092\tLearning Rate (w_theta): 0.001000\t TIME:1612.8s\n",
      "\t\t\t\tDisc: 0.011669\t\tSym: 0.000000\t\tSpars: 0.000422\n",
      "\t TVw: 0.774862 | TVb: 2.282204 | GSw: -0.603398 | GSb: -0.279384 | TSUw: -0.409967 | TSUb: -0.033780\n",
      "Validating epoch 5453...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012887685807463087\n",
      "Average validation loss: 0.013394567545208744\n",
      "Training epoch 5454...\n",
      "\n",
      "Train Epoch: 5454 [0/8000 (0%)]\tBatch Loss: 0.012885\tLearning Rate (w_theta): 0.001000\t TIME:1615.0s\n",
      "\t\t\t\tDisc: 0.012112\t\tSym: 0.000000\t\tSpars: 0.000773\n",
      "\t TVw: 0.774436 | TVb: 2.282209 | GSw: -0.603257 | GSb: -0.279188 | TSUw: -0.410455 | TSUb: -0.034131\n",
      "\n",
      "Train Epoch: 5454 [4000/8000 (50%)]\tBatch Loss: 0.012762\tLearning Rate (w_theta): 0.001000\t TIME:1616.4s\n",
      "\t\t\t\tDisc: 0.011983\t\tSym: 0.000000\t\tSpars: 0.000780\n",
      "\t TVw: 0.774200 | TVb: 2.282217 | GSw: -0.603145 | GSb: -0.279026 | TSUw: -0.411490 | TSUb: -0.034917\n",
      "Validating epoch 5454...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012887551675343263\n",
      "Average validation loss: 0.013397824061533272\n",
      "Training epoch 5455...\n",
      "\n",
      "Train Epoch: 5455 [0/8000 (0%)]\tBatch Loss: 0.013156\tLearning Rate (w_theta): 0.001000\t TIME:1618.7s\n",
      "\t\t\t\tDisc: 0.012097\t\tSym: 0.000000\t\tSpars: 0.001059\n",
      "\t TVw: 0.774242 | TVb: 2.282289 | GSw: -0.603004 | GSb: -0.278830 | TSUw: -0.412033 | TSUb: -0.035314\n",
      "\n",
      "Train Epoch: 5455 [4000/8000 (50%)]\tBatch Loss: 0.012790\tLearning Rate (w_theta): 0.001000\t TIME:1619.9s\n",
      "\t\t\t\tDisc: 0.011948\t\tSym: 0.000000\t\tSpars: 0.000842\n",
      "\t TVw: 0.774838 | TVb: 2.282452 | GSw: -0.602838 | GSb: -0.278608 | TSUw: -0.412144 | TSUb: -0.035370\n",
      "Validating epoch 5455...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012887185870976215\n",
      "Average validation loss: 0.013395598346521494\n",
      "Training epoch 5456...\n",
      "\n",
      "Train Epoch: 5456 [0/8000 (0%)]\tBatch Loss: 0.013265\tLearning Rate (w_theta): 0.001000\t TIME:1622.1s\n",
      "\t\t\t\tDisc: 0.012465\t\tSym: 0.000000\t\tSpars: 0.000800\n",
      "\t TVw: 0.774633 | TVb: 2.282426 | GSw: -0.602618 | GSb: -0.278324 | TSUw: -0.411183 | TSUb: -0.034574\n",
      "\n",
      "Train Epoch: 5456 [4000/8000 (50%)]\tBatch Loss: 0.012505\tLearning Rate (w_theta): 0.001000\t TIME:1623.5s\n",
      "\t\t\t\tDisc: 0.011895\t\tSym: 0.000000\t\tSpars: 0.000609\n",
      "\t TVw: 0.774542 | TVb: 2.282431 | GSw: -0.602386 | GSb: -0.278024 | TSUw: -0.410007 | TSUb: -0.033610\n",
      "Validating epoch 5456...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012889312348452881\n",
      "Average validation loss: 0.013393947531021275\n",
      "Training epoch 5457...\n",
      "\n",
      "Train Epoch: 5457 [0/8000 (0%)]\tBatch Loss: 0.012231\tLearning Rate (w_theta): 0.001000\t TIME:1625.7s\n",
      "\t\t\t\tDisc: 0.011647\t\tSym: 0.000000\t\tSpars: 0.000583\n",
      "\t TVw: 0.774243 | TVb: 2.282449 | GSw: -0.602262 | GSb: -0.277846 | TSUw: -0.410766 | TSUb: -0.034179\n",
      "\n",
      "Train Epoch: 5457 [4000/8000 (50%)]\tBatch Loss: 0.012964\tLearning Rate (w_theta): 0.001000\t TIME:1627.0s\n",
      "\t\t\t\tDisc: 0.012039\t\tSym: 0.000000\t\tSpars: 0.000925\n",
      "\t TVw: 0.774075 | TVb: 2.282503 | GSw: -0.602194 | GSb: -0.277732 | TSUw: -0.412611 | TSUb: -0.035611\n",
      "Validating epoch 5457...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012888734031856985\n",
      "Average validation loss: 0.013399469509945335\n",
      "Training epoch 5458...\n",
      "\n",
      "Train Epoch: 5458 [0/8000 (0%)]\tBatch Loss: 0.013346\tLearning Rate (w_theta): 0.001000\t TIME:1629.2s\n",
      "\t\t\t\tDisc: 0.012204\t\tSym: 0.000000\t\tSpars: 0.001141\n",
      "\t TVw: 0.774252 | TVb: 2.282573 | GSw: -0.602036 | GSb: -0.277518 | TSUw: -0.412762 | TSUb: -0.035696\n",
      "\n",
      "Train Epoch: 5458 [4000/8000 (50%)]\tBatch Loss: 0.012863\tLearning Rate (w_theta): 0.001000\t TIME:1630.5s\n",
      "\t\t\t\tDisc: 0.012236\t\tSym: 0.000000\t\tSpars: 0.000626\n",
      "\t TVw: 0.775096 | TVb: 2.282749 | GSw: -0.601850 | GSb: -0.277271 | TSUw: -0.412480 | TSUb: -0.035437\n",
      "Validating epoch 5458...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012885775399242412\n",
      "Average validation loss: 0.01339432411361994\n",
      "Training epoch 5459...\n",
      "\n",
      "Train Epoch: 5459 [0/8000 (0%)]\tBatch Loss: 0.013179\tLearning Rate (w_theta): 0.001000\t TIME:1632.6s\n",
      "\t\t\t\tDisc: 0.012024\t\tSym: 0.000000\t\tSpars: 0.001155\n",
      "\t TVw: 0.775001 | TVb: 2.282732 | GSw: -0.601631 | GSb: -0.276993 | TSUw: -0.411520 | TSUb: -0.034634\n",
      "\n",
      "Train Epoch: 5459 [4000/8000 (50%)]\tBatch Loss: 0.013418\tLearning Rate (w_theta): 0.001000\t TIME:1633.9s\n",
      "\t\t\t\tDisc: 0.012476\t\tSym: 0.000000\t\tSpars: 0.000942\n",
      "\t TVw: 0.774986 | TVb: 2.282746 | GSw: -0.601482 | GSb: -0.276789 | TSUw: -0.411889 | TSUb: -0.034893\n",
      "Validating epoch 5459...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01288574941898494\n",
      "Average validation loss: 0.013393920415594075\n",
      "Training epoch 5460...\n",
      "\n",
      "Train Epoch: 5460 [0/8000 (0%)]\tBatch Loss: 0.012836\tLearning Rate (w_theta): 0.001000\t TIME:1636.1s\n",
      "\t\t\t\tDisc: 0.012160\t\tSym: 0.000000\t\tSpars: 0.000676\n",
      "\t TVw: 0.774580 | TVb: 2.282640 | GSw: -0.601273 | GSb: -0.276519 | TSUw: -0.411150 | TSUb: -0.034267\n",
      "\n",
      "Train Epoch: 5460 [4000/8000 (50%)]\tBatch Loss: 0.013157\tLearning Rate (w_theta): 0.001000\t TIME:1637.4s\n",
      "\t\t\t\tDisc: 0.012049\t\tSym: 0.000000\t\tSpars: 0.001108\n",
      "\t TVw: 0.774338 | TVb: 2.282612 | GSw: -0.601093 | GSb: -0.276279 | TSUw: -0.410899 | TSUb: -0.034033\n",
      "Validating epoch 5460...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012887515293955229\n",
      "Average validation loss: 0.013394078806362739\n",
      "Training epoch 5461...\n",
      "\n",
      "Train Epoch: 5461 [0/8000 (0%)]\tBatch Loss: 0.013266\tLearning Rate (w_theta): 0.001000\t TIME:1640.4s\n",
      "\t\t\t\tDisc: 0.012556\t\tSym: 0.000000\t\tSpars: 0.000710\n",
      "\t TVw: 0.774243 | TVb: 2.282633 | GSw: -0.600956 | GSb: -0.276087 | TSUw: -0.411503 | TSUb: -0.034486\n",
      "\n",
      "Train Epoch: 5461 [4000/8000 (50%)]\tBatch Loss: 0.013206\tLearning Rate (w_theta): 0.001000\t TIME:1641.7s\n",
      "\t\t\t\tDisc: 0.012444\t\tSym: 0.000000\t\tSpars: 0.000762\n",
      "\t TVw: 0.774188 | TVb: 2.282735 | GSw: -0.600820 | GSb: -0.275897 | TSUw: -0.412128 | TSUb: -0.034956\n",
      "Validating epoch 5461...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012885816548365833\n",
      "Average validation loss: 0.01339621361479858\n",
      "Training epoch 5462...\n",
      "\n",
      "Train Epoch: 5462 [0/8000 (0%)]\tBatch Loss: 0.012712\tLearning Rate (w_theta): 0.001000\t TIME:1643.9s\n",
      "\t\t\t\tDisc: 0.012057\t\tSym: 0.000000\t\tSpars: 0.000655\n",
      "\t TVw: 0.773907 | TVb: 2.282706 | GSw: -0.600666 | GSb: -0.275687 | TSUw: -0.412452 | TSUb: -0.035183\n",
      "\n",
      "Train Epoch: 5462 [4000/8000 (50%)]\tBatch Loss: 0.013090\tLearning Rate (w_theta): 0.001000\t TIME:1645.2s\n",
      "\t\t\t\tDisc: 0.012020\t\tSym: 0.000000\t\tSpars: 0.001070\n",
      "\t TVw: 0.773559 | TVb: 2.282640 | GSw: -0.600460 | GSb: -0.275421 | TSUw: -0.411761 | TSUb: -0.034596\n",
      "Validating epoch 5462...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012886884122748401\n",
      "Average validation loss: 0.013395203436245466\n",
      "Training epoch 5463...\n",
      "\n",
      "Train Epoch: 5463 [0/8000 (0%)]\tBatch Loss: 0.013292\tLearning Rate (w_theta): 0.001000\t TIME:1647.4s\n",
      "\t\t\t\tDisc: 0.012289\t\tSym: 0.000000\t\tSpars: 0.001002\n",
      "\t TVw: 0.773774 | TVb: 2.282713 | GSw: -0.600312 | GSb: -0.275220 | TSUw: -0.412234 | TSUb: -0.034944\n",
      "\n",
      "Train Epoch: 5463 [4000/8000 (50%)]\tBatch Loss: 0.012956\tLearning Rate (w_theta): 0.001000\t TIME:1648.7s\n",
      "\t\t\t\tDisc: 0.012250\t\tSym: 0.000000\t\tSpars: 0.000706\n",
      "\t TVw: 0.773865 | TVb: 2.282754 | GSw: -0.600140 | GSb: -0.274990 | TSUw: -0.412289 | TSUb: -0.034955\n",
      "Validating epoch 5463...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012886640641631971\n",
      "Average validation loss: 0.013394671139385776\n",
      "Training epoch 5464...\n",
      "\n",
      "Train Epoch: 5464 [0/8000 (0%)]\tBatch Loss: 0.012766\tLearning Rate (w_theta): 0.001000\t TIME:1650.9s\n",
      "\t\t\t\tDisc: 0.012061\t\tSym: 0.000000\t\tSpars: 0.000705\n",
      "\t TVw: 0.773661 | TVb: 2.282743 | GSw: -0.599951 | GSb: -0.274740 | TSUw: -0.411975 | TSUb: -0.034669\n",
      "\n",
      "Train Epoch: 5464 [4000/8000 (50%)]\tBatch Loss: 0.012227\tLearning Rate (w_theta): 0.001000\t TIME:1652.2s\n",
      "\t\t\t\tDisc: 0.011513\t\tSym: 0.000000\t\tSpars: 0.000715\n",
      "\t TVw: 0.773567 | TVb: 2.282778 | GSw: -0.599795 | GSb: -0.274528 | TSUw: -0.412270 | TSUb: -0.034874\n",
      "Validating epoch 5464...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012886332262905437\n",
      "Average validation loss: 0.01339492533852956\n",
      "Training epoch 5465...\n",
      "\n",
      "Train Epoch: 5465 [0/8000 (0%)]\tBatch Loss: 0.012500\tLearning Rate (w_theta): 0.001000\t TIME:1654.4s\n",
      "\t\t\t\tDisc: 0.011770\t\tSym: 0.000000\t\tSpars: 0.000730\n",
      "\t TVw: 0.773391 | TVb: 2.282785 | GSw: -0.599621 | GSb: -0.274294 | TSUw: -0.412226 | TSUb: -0.034805\n",
      "\n",
      "Train Epoch: 5465 [4000/8000 (50%)]\tBatch Loss: 0.012812\tLearning Rate (w_theta): 0.001000\t TIME:1655.7s\n",
      "\t\t\t\tDisc: 0.012130\t\tSym: 0.000000\t\tSpars: 0.000682\n",
      "\t TVw: 0.773585 | TVb: 2.282862 | GSw: -0.599496 | GSb: -0.274114 | TSUw: -0.413140 | TSUb: -0.035512\n",
      "Validating epoch 5465...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012887069555473692\n",
      "Average validation loss: 0.013396174813837773\n",
      "Training epoch 5466...\n",
      "\n",
      "Train Epoch: 5466 [0/8000 (0%)]\tBatch Loss: 0.012928\tLearning Rate (w_theta): 0.001000\t TIME:1657.9s\n",
      "\t\t\t\tDisc: 0.012323\t\tSym: 0.000000\t\tSpars: 0.000605\n",
      "\t TVw: 0.773321 | TVb: 2.282787 | GSw: -0.599298 | GSb: -0.273857 | TSUw: -0.412654 | TSUb: -0.035083\n",
      "\n",
      "Train Epoch: 5466 [4000/8000 (50%)]\tBatch Loss: 0.013014\tLearning Rate (w_theta): 0.001000\t TIME:1659.2s\n",
      "\t\t\t\tDisc: 0.011973\t\tSym: 0.000000\t\tSpars: 0.001041\n",
      "\t TVw: 0.772918 | TVb: 2.282738 | GSw: -0.599117 | GSb: -0.273619 | TSUw: -0.412497 | TSUb: -0.034920\n",
      "Validating epoch 5466...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012885969120265132\n",
      "Average validation loss: 0.013394874284504388\n",
      "Training epoch 5467...\n",
      "\n",
      "Train Epoch: 5467 [0/8000 (0%)]\tBatch Loss: 0.012276\tLearning Rate (w_theta): 0.001000\t TIME:1661.4s\n",
      "\t\t\t\tDisc: 0.011696\t\tSym: 0.000000\t\tSpars: 0.000580\n",
      "\t TVw: 0.773215 | TVb: 2.282801 | GSw: -0.598927 | GSb: -0.273369 | TSUw: -0.412224 | TSUb: -0.034666\n",
      "\n",
      "Train Epoch: 5467 [4000/8000 (50%)]\tBatch Loss: 0.013303\tLearning Rate (w_theta): 0.001000\t TIME:1662.7s\n",
      "\t\t\t\tDisc: 0.012190\t\tSym: 0.000000\t\tSpars: 0.001112\n",
      "\t TVw: 0.773275 | TVb: 2.282863 | GSw: -0.598747 | GSb: -0.273131 | TSUw: -0.412128 | TSUb: -0.034556\n",
      "Validating epoch 5467...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01288670844986094\n",
      "Average validation loss: 0.01339443152213735\n",
      "Training epoch 5468...\n",
      "\n",
      "Train Epoch: 5468 [0/8000 (0%)]\tBatch Loss: 0.012676\tLearning Rate (w_theta): 0.001000\t TIME:1665.0s\n",
      "\t\t\t\tDisc: 0.011878\t\tSym: 0.000000\t\tSpars: 0.000798\n",
      "\t TVw: 0.773538 | TVb: 2.282945 | GSw: -0.598591 | GSb: -0.272921 | TSUw: -0.412440 | TSUb: -0.034779\n",
      "\n",
      "Train Epoch: 5468 [4000/8000 (50%)]\tBatch Loss: 0.012611\tLearning Rate (w_theta): 0.001000\t TIME:1666.2s\n",
      "\t\t\t\tDisc: 0.011753\t\tSym: 0.000000\t\tSpars: 0.000858\n",
      "\t TVw: 0.773074 | TVb: 2.282840 | GSw: -0.598404 | GSb: -0.272678 | TSUw: -0.412169 | TSUb: -0.034525\n",
      "Validating epoch 5468...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012886654565879355\n",
      "Average validation loss: 0.013394785144891383\n",
      "Training epoch 5469...\n",
      "\n",
      "Train Epoch: 5469 [0/8000 (0%)]\tBatch Loss: 0.013055\tLearning Rate (w_theta): 0.001000\t TIME:1668.4s\n",
      "\t\t\t\tDisc: 0.012224\t\tSym: 0.000000\t\tSpars: 0.000831\n",
      "\t TVw: 0.773259 | TVb: 2.282889 | GSw: -0.598261 | GSb: -0.272479 | TSUw: -0.412734 | TSUb: -0.034955\n",
      "\n",
      "Train Epoch: 5469 [4000/8000 (50%)]\tBatch Loss: 0.012886\tLearning Rate (w_theta): 0.001000\t TIME:1669.7s\n",
      "\t\t\t\tDisc: 0.011888\t\tSym: 0.000000\t\tSpars: 0.000997\n",
      "\t TVw: 0.773447 | TVb: 2.282892 | GSw: -0.598117 | GSb: -0.272283 | TSUw: -0.413280 | TSUb: -0.035369\n",
      "Validating epoch 5469...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012885840199411358\n",
      "Average validation loss: 0.013396719531268812\n",
      "Training epoch 5470...\n",
      "\n",
      "Train Epoch: 5470 [0/8000 (0%)]\tBatch Loss: 0.012396\tLearning Rate (w_theta): 0.001000\t TIME:1671.9s\n",
      "\t\t\t\tDisc: 0.011745\t\tSym: 0.000000\t\tSpars: 0.000651\n",
      "\t TVw: 0.773408 | TVb: 2.282915 | GSw: -0.597942 | GSb: -0.272050 | TSUw: -0.413242 | TSUb: -0.035304\n",
      "\n",
      "Train Epoch: 5470 [4000/8000 (50%)]\tBatch Loss: 0.013199\tLearning Rate (w_theta): 0.001000\t TIME:1673.2s\n",
      "\t\t\t\tDisc: 0.012031\t\tSym: 0.000000\t\tSpars: 0.001168\n",
      "\t TVw: 0.773446 | TVb: 2.282982 | GSw: -0.597783 | GSb: -0.271836 | TSUw: -0.413536 | TSUb: -0.035510\n",
      "Validating epoch 5470...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012885893379785877\n",
      "Average validation loss: 0.013395334828536607\n",
      "Training epoch 5471...\n",
      "\n",
      "Train Epoch: 5471 [0/8000 (0%)]\tBatch Loss: 0.013100\tLearning Rate (w_theta): 0.001000\t TIME:1676.0s\n",
      "\t\t\t\tDisc: 0.012387\t\tSym: 0.000000\t\tSpars: 0.000713\n",
      "\t TVw: 0.773434 | TVb: 2.283002 | GSw: -0.597570 | GSb: -0.271562 | TSUw: -0.412837 | TSUb: -0.034902\n",
      "\n",
      "Train Epoch: 5471 [4000/8000 (50%)]\tBatch Loss: 0.012952\tLearning Rate (w_theta): 0.001000\t TIME:1677.3s\n",
      "\t\t\t\tDisc: 0.012052\t\tSym: 0.000000\t\tSpars: 0.000901\n",
      "\t TVw: 0.773343 | TVb: 2.283010 | GSw: -0.597374 | GSb: -0.271307 | TSUw: -0.412374 | TSUb: -0.034488\n",
      "Validating epoch 5471...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012885926681903751\n",
      "Average validation loss: 0.013393464689005109\n",
      "Training epoch 5472...\n",
      "\n",
      "Train Epoch: 5472 [0/8000 (0%)]\tBatch Loss: 0.012565\tLearning Rate (w_theta): 0.001000\t TIME:1679.5s\n",
      "\t\t\t\tDisc: 0.011758\t\tSym: 0.000000\t\tSpars: 0.000807\n",
      "\t TVw: 0.773269 | TVb: 2.283005 | GSw: -0.597192 | GSb: -0.271064 | TSUw: -0.412196 | TSUb: -0.034310\n",
      "\n",
      "Train Epoch: 5472 [4000/8000 (50%)]\tBatch Loss: 0.012999\tLearning Rate (w_theta): 0.001000\t TIME:1680.8s\n",
      "\t\t\t\tDisc: 0.012341\t\tSym: 0.000000\t\tSpars: 0.000658\n",
      "\t TVw: 0.773073 | TVb: 2.283019 | GSw: -0.597075 | GSb: -0.270889 | TSUw: -0.413178 | TSUb: -0.035087\n",
      "Validating epoch 5472...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012886758966320052\n",
      "Average validation loss: 0.013395479189443718\n",
      "Training epoch 5473...\n",
      "\n",
      "Train Epoch: 5473 [0/8000 (0%)]\tBatch Loss: 0.012611\tLearning Rate (w_theta): 0.001000\t TIME:1683.0s\n",
      "\t\t\t\tDisc: 0.011908\t\tSym: 0.000000\t\tSpars: 0.000703\n",
      "\t TVw: 0.772910 | TVb: 2.283042 | GSw: -0.596901 | GSb: -0.270658 | TSUw: -0.413143 | TSUb: -0.035026\n",
      "\n",
      "Train Epoch: 5473 [4000/8000 (50%)]\tBatch Loss: 0.013056\tLearning Rate (w_theta): 0.001000\t TIME:1684.2s\n",
      "\t\t\t\tDisc: 0.012196\t\tSym: 0.000000\t\tSpars: 0.000860\n",
      "\t TVw: 0.772516 | TVb: 2.282979 | GSw: -0.596705 | GSb: -0.270405 | TSUw: -0.412715 | TSUb: -0.034641\n",
      "Validating epoch 5473...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012886491068424889\n",
      "Average validation loss: 0.013394565505810791\n",
      "Training epoch 5474...\n",
      "\n",
      "Train Epoch: 5474 [0/8000 (0%)]\tBatch Loss: 0.012896\tLearning Rate (w_theta): 0.001000\t TIME:1686.5s\n",
      "\t\t\t\tDisc: 0.012063\t\tSym: 0.000000\t\tSpars: 0.000833\n",
      "\t TVw: 0.772548 | TVb: 2.283041 | GSw: -0.596547 | GSb: -0.270192 | TSUw: -0.413034 | TSUb: -0.034875\n",
      "\n",
      "Train Epoch: 5474 [4000/8000 (50%)]\tBatch Loss: 0.012775\tLearning Rate (w_theta): 0.001000\t TIME:1687.8s\n",
      "\t\t\t\tDisc: 0.012018\t\tSym: 0.000000\t\tSpars: 0.000757\n",
      "\t TVw: 0.772879 | TVb: 2.283224 | GSw: -0.596429 | GSb: -0.270027 | TSUw: -0.414071 | TSUb: -0.035701\n",
      "Validating epoch 5474...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01288660190042191\n",
      "Average validation loss: 0.01339622317539147\n",
      "Training epoch 5475...\n",
      "\n",
      "Train Epoch: 5475 [0/8000 (0%)]\tBatch Loss: 0.012511\tLearning Rate (w_theta): 0.001000\t TIME:1690.0s\n",
      "\t\t\t\tDisc: 0.011855\t\tSym: 0.000000\t\tSpars: 0.000656\n",
      "\t TVw: 0.772708 | TVb: 2.283184 | GSw: -0.596235 | GSb: -0.269773 | TSUw: -0.413678 | TSUb: -0.035342\n",
      "\n",
      "Train Epoch: 5475 [4000/8000 (50%)]\tBatch Loss: 0.012942\tLearning Rate (w_theta): 0.001000\t TIME:1691.3s\n",
      "\t\t\t\tDisc: 0.012138\t\tSym: 0.000000\t\tSpars: 0.000803\n",
      "\t TVw: 0.772455 | TVb: 2.283070 | GSw: -0.596029 | GSb: -0.269509 | TSUw: -0.413145 | TSUb: -0.034865\n",
      "Validating epoch 5475...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012885289833122633\n",
      "Average validation loss: 0.013394094592483207\n",
      "Training epoch 5476...\n",
      "\n",
      "Train Epoch: 5476 [0/8000 (0%)]\tBatch Loss: 0.012810\tLearning Rate (w_theta): 0.001000\t TIME:1693.5s\n",
      "\t\t\t\tDisc: 0.012005\t\tSym: 0.000000\t\tSpars: 0.000805\n",
      "\t TVw: 0.772435 | TVb: 2.283074 | GSw: -0.595839 | GSb: -0.269259 | TSUw: -0.412878 | TSUb: -0.034611\n",
      "\n",
      "Train Epoch: 5476 [4000/8000 (50%)]\tBatch Loss: 0.012520\tLearning Rate (w_theta): 0.001000\t TIME:1694.8s\n",
      "\t\t\t\tDisc: 0.011790\t\tSym: 0.000000\t\tSpars: 0.000730\n",
      "\t TVw: 0.772857 | TVb: 2.283184 | GSw: -0.595690 | GSb: -0.269055 | TSUw: -0.413402 | TSUb: -0.035015\n",
      "Validating epoch 5476...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012885750283145406\n",
      "Average validation loss: 0.01339446679642136\n",
      "Training epoch 5477...\n",
      "\n",
      "Train Epoch: 5477 [0/8000 (0%)]\tBatch Loss: 0.012478\tLearning Rate (w_theta): 0.001000\t TIME:1697.0s\n",
      "\t\t\t\tDisc: 0.011795\t\tSym: 0.000000\t\tSpars: 0.000684\n",
      "\t TVw: 0.772764 | TVb: 2.283227 | GSw: -0.595514 | GSb: -0.268819 | TSUw: -0.413386 | TSUb: -0.034970\n",
      "\n",
      "Train Epoch: 5477 [4000/8000 (50%)]\tBatch Loss: 0.012794\tLearning Rate (w_theta): 0.001000\t TIME:1698.3s\n",
      "\t\t\t\tDisc: 0.012068\t\tSym: 0.000000\t\tSpars: 0.000725\n",
      "\t TVw: 0.772408 | TVb: 2.283170 | GSw: -0.595325 | GSb: -0.268570 | TSUw: -0.413105 | TSUb: -0.034704\n",
      "Validating epoch 5477...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012885604780214003\n",
      "Average validation loss: 0.013394389789691565\n",
      "Training epoch 5478...\n",
      "\n",
      "Train Epoch: 5478 [0/8000 (0%)]\tBatch Loss: 0.012963\tLearning Rate (w_theta): 0.001000\t TIME:1700.5s\n",
      "\t\t\t\tDisc: 0.012233\t\tSym: 0.000000\t\tSpars: 0.000730\n",
      "\t TVw: 0.772175 | TVb: 2.283164 | GSw: -0.595154 | GSb: -0.268342 | TSUw: -0.413195 | TSUb: -0.034747\n",
      "\n",
      "Train Epoch: 5478 [4000/8000 (50%)]\tBatch Loss: 0.012927\tLearning Rate (w_theta): 0.001000\t TIME:1701.8s\n",
      "\t\t\t\tDisc: 0.011943\t\tSym: 0.000000\t\tSpars: 0.000984\n",
      "\t TVw: 0.771648 | TVb: 2.283081 | GSw: -0.594945 | GSb: -0.268069 | TSUw: -0.412638 | TSUb: -0.034253\n",
      "Validating epoch 5478...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012888318102393962\n",
      "Average validation loss: 0.013394685743339466\n",
      "Training epoch 5479...\n",
      "\n",
      "Train Epoch: 5479 [0/8000 (0%)]\tBatch Loss: 0.012937\tLearning Rate (w_theta): 0.001000\t TIME:1704.1s\n",
      "\t\t\t\tDisc: 0.012216\t\tSym: 0.000000\t\tSpars: 0.000721\n",
      "\t TVw: 0.771827 | TVb: 2.283179 | GSw: -0.594842 | GSb: -0.267914 | TSUw: -0.413875 | TSUb: -0.035258\n",
      "\n",
      "Train Epoch: 5479 [4000/8000 (50%)]\tBatch Loss: 0.013136\tLearning Rate (w_theta): 0.001000\t TIME:1705.4s\n",
      "\t\t\t\tDisc: 0.012455\t\tSym: 0.000000\t\tSpars: 0.000681\n",
      "\t TVw: 0.772135 | TVb: 2.283294 | GSw: -0.594730 | GSb: -0.267752 | TSUw: -0.414961 | TSUb: -0.036135\n",
      "Validating epoch 5479...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01288625888276881\n",
      "Average validation loss: 0.013399354081634035\n",
      "Training epoch 5480...\n",
      "\n",
      "Train Epoch: 5480 [0/8000 (0%)]\tBatch Loss: 0.012910\tLearning Rate (w_theta): 0.001000\t TIME:1707.6s\n",
      "\t\t\t\tDisc: 0.011996\t\tSym: 0.000000\t\tSpars: 0.000914\n",
      "\t TVw: 0.772182 | TVb: 2.283297 | GSw: -0.594544 | GSb: -0.267506 | TSUw: -0.414732 | TSUb: -0.035908\n",
      "\n",
      "Train Epoch: 5480 [4000/8000 (50%)]\tBatch Loss: 0.013138\tLearning Rate (w_theta): 0.001000\t TIME:1708.9s\n",
      "\t\t\t\tDisc: 0.012298\t\tSym: 0.000000\t\tSpars: 0.000841\n",
      "\t TVw: 0.772325 | TVb: 2.283223 | GSw: -0.594312 | GSb: -0.267215 | TSUw: -0.413719 | TSUb: -0.035023\n",
      "Validating epoch 5480...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012886277566754901\n",
      "Average validation loss: 0.013393680338162415\n",
      "Training epoch 5481...\n",
      "\n",
      "Train Epoch: 5481 [0/8000 (0%)]\tBatch Loss: 0.012293\tLearning Rate (w_theta): 0.001000\t TIME:1711.8s\n",
      "\t\t\t\tDisc: 0.011431\t\tSym: 0.000000\t\tSpars: 0.000862\n",
      "\t TVw: 0.772201 | TVb: 2.283209 | GSw: -0.594116 | GSb: -0.266961 | TSUw: -0.413318 | TSUb: -0.034653\n",
      "\n",
      "Train Epoch: 5481 [4000/8000 (50%)]\tBatch Loss: 0.012715\tLearning Rate (w_theta): 0.001000\t TIME:1713.0s\n",
      "\t\t\t\tDisc: 0.011908\t\tSym: 0.000000\t\tSpars: 0.000807\n",
      "\t TVw: 0.772153 | TVb: 2.283212 | GSw: -0.593962 | GSb: -0.266757 | TSUw: -0.413693 | TSUb: -0.034933\n",
      "Validating epoch 5481...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012885837161705115\n",
      "Average validation loss: 0.013395205626424853\n",
      "Training epoch 5482...\n",
      "\n",
      "Train Epoch: 5482 [0/8000 (0%)]\tBatch Loss: 0.012955\tLearning Rate (w_theta): 0.001000\t TIME:1715.3s\n",
      "\t\t\t\tDisc: 0.012154\t\tSym: 0.000000\t\tSpars: 0.000801\n",
      "\t TVw: 0.772025 | TVb: 2.283271 | GSw: -0.593804 | GSb: -0.266546 | TSUw: -0.413998 | TSUb: -0.035156\n",
      "\n",
      "Train Epoch: 5482 [4000/8000 (50%)]\tBatch Loss: 0.012675\tLearning Rate (w_theta): 0.001000\t TIME:1716.5s\n",
      "\t\t\t\tDisc: 0.011953\t\tSym: 0.000000\t\tSpars: 0.000722\n",
      "\t TVw: 0.771918 | TVb: 2.283330 | GSw: -0.593619 | GSb: -0.266303 | TSUw: -0.413837 | TSUb: -0.034989\n",
      "Validating epoch 5482...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012885594947026471\n",
      "Average validation loss: 0.013394490998957396\n",
      "Training epoch 5483...\n",
      "\n",
      "Train Epoch: 5483 [0/8000 (0%)]\tBatch Loss: 0.012760\tLearning Rate (w_theta): 0.001000\t TIME:1718.8s\n",
      "\t\t\t\tDisc: 0.011984\t\tSym: 0.000000\t\tSpars: 0.000776\n",
      "\t TVw: 0.771582 | TVb: 2.283296 | GSw: -0.593434 | GSb: -0.266059 | TSUw: -0.413696 | TSUb: -0.034839\n",
      "\n",
      "Train Epoch: 5483 [4000/8000 (50%)]\tBatch Loss: 0.012764\tLearning Rate (w_theta): 0.001000\t TIME:1720.1s\n",
      "\t\t\t\tDisc: 0.012003\t\tSym: 0.000000\t\tSpars: 0.000761\n",
      "\t TVw: 0.771542 | TVb: 2.283358 | GSw: -0.593268 | GSb: -0.265834 | TSUw: -0.413887 | TSUb: -0.034969\n",
      "Validating epoch 5483...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012885725677264957\n",
      "Average validation loss: 0.013395829579022191\n",
      "Training epoch 5484...\n",
      "\n",
      "Train Epoch: 5484 [0/8000 (0%)]\tBatch Loss: 0.012699\tLearning Rate (w_theta): 0.001000\t TIME:1722.4s\n",
      "\t\t\t\tDisc: 0.012064\t\tSym: 0.000000\t\tSpars: 0.000635\n",
      "\t TVw: 0.771307 | TVb: 2.283363 | GSw: -0.593124 | GSb: -0.265635 | TSUw: -0.414470 | TSUb: -0.035428\n",
      "\n",
      "Train Epoch: 5484 [4000/8000 (50%)]\tBatch Loss: 0.012901\tLearning Rate (w_theta): 0.001000\t TIME:1723.6s\n",
      "\t\t\t\tDisc: 0.012311\t\tSym: 0.000000\t\tSpars: 0.000590\n",
      "\t TVw: 0.771061 | TVb: 2.283367 | GSw: -0.592948 | GSb: -0.265398 | TSUw: -0.414519 | TSUb: -0.035437\n",
      "Validating epoch 5484...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012885843751877561\n",
      "Average validation loss: 0.01339621431462333\n",
      "Training epoch 5485...\n",
      "\n",
      "Train Epoch: 5485 [0/8000 (0%)]\tBatch Loss: 0.013010\tLearning Rate (w_theta): 0.001000\t TIME:1725.9s\n",
      "\t\t\t\tDisc: 0.012122\t\tSym: 0.000000\t\tSpars: 0.000888\n",
      "\t TVw: 0.770992 | TVb: 2.283326 | GSw: -0.592761 | GSb: -0.265153 | TSUw: -0.414350 | TSUb: -0.035261\n",
      "\n",
      "Train Epoch: 5485 [4000/8000 (50%)]\tBatch Loss: 0.013013\tLearning Rate (w_theta): 0.001000\t TIME:1727.2s\n",
      "\t\t\t\tDisc: 0.012187\t\tSym: 0.000000\t\tSpars: 0.000826\n",
      "\t TVw: 0.771517 | TVb: 2.283391 | GSw: -0.592571 | GSb: -0.264909 | TSUw: -0.414177 | TSUb: -0.035084\n",
      "Validating epoch 5485...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012885650292164796\n",
      "Average validation loss: 0.013394975542444315\n",
      "Training epoch 5486...\n",
      "\n",
      "Train Epoch: 5486 [0/8000 (0%)]\tBatch Loss: 0.013254\tLearning Rate (w_theta): 0.001000\t TIME:1729.4s\n",
      "\t\t\t\tDisc: 0.012223\t\tSym: 0.000000\t\tSpars: 0.001031\n",
      "\t TVw: 0.771623 | TVb: 2.283440 | GSw: -0.592410 | GSb: -0.264694 | TSUw: -0.414457 | TSUb: -0.035289\n",
      "\n",
      "Train Epoch: 5486 [4000/8000 (50%)]\tBatch Loss: 0.012648\tLearning Rate (w_theta): 0.001000\t TIME:1730.7s\n",
      "\t\t\t\tDisc: 0.012035\t\tSym: 0.000000\t\tSpars: 0.000613\n",
      "\t TVw: 0.771437 | TVb: 2.283453 | GSw: -0.592225 | GSb: -0.264452 | TSUw: -0.414309 | TSUb: -0.035131\n",
      "Validating epoch 5486...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012885568961008488\n",
      "Average validation loss: 0.013394278058905236\n",
      "Training epoch 5487...\n",
      "\n",
      "Train Epoch: 5487 [0/8000 (0%)]\tBatch Loss: 0.012920\tLearning Rate (w_theta): 0.001000\t TIME:1733.0s\n",
      "\t\t\t\tDisc: 0.012249\t\tSym: 0.000000\t\tSpars: 0.000671\n",
      "\t TVw: 0.770915 | TVb: 2.283361 | GSw: -0.592020 | GSb: -0.264188 | TSUw: -0.413834 | TSUb: -0.034696\n",
      "\n",
      "Train Epoch: 5487 [4000/8000 (50%)]\tBatch Loss: 0.012993\tLearning Rate (w_theta): 0.001000\t TIME:1734.2s\n",
      "\t\t\t\tDisc: 0.012093\t\tSym: 0.000000\t\tSpars: 0.000900\n",
      "\t TVw: 0.770866 | TVb: 2.283369 | GSw: -0.591829 | GSb: -0.263939 | TSUw: -0.413617 | TSUb: -0.034482\n",
      "Validating epoch 5487...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012887267013652058\n",
      "Average validation loss: 0.0133950151967093\n",
      "Training epoch 5488...\n",
      "\n",
      "Train Epoch: 5488 [0/8000 (0%)]\tBatch Loss: 0.013376\tLearning Rate (w_theta): 0.001000\t TIME:1736.5s\n",
      "\t\t\t\tDisc: 0.012539\t\tSym: 0.000000\t\tSpars: 0.000836\n",
      "\t TVw: 0.770839 | TVb: 2.283425 | GSw: -0.591716 | GSb: -0.263775 | TSUw: -0.414725 | TSUb: -0.035390\n",
      "\n",
      "Train Epoch: 5488 [4000/8000 (50%)]\tBatch Loss: 0.013048\tLearning Rate (w_theta): 0.001000\t TIME:1737.8s\n",
      "\t\t\t\tDisc: 0.012184\t\tSym: 0.000000\t\tSpars: 0.000864\n",
      "\t TVw: 0.770647 | TVb: 2.283429 | GSw: -0.591566 | GSb: -0.263569 | TSUw: -0.415164 | TSUb: -0.035730\n",
      "Validating epoch 5488...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012885830194525036\n",
      "Average validation loss: 0.013397923363450435\n",
      "Training epoch 5489...\n",
      "\n",
      "Train Epoch: 5489 [0/8000 (0%)]\tBatch Loss: 0.012301\tLearning Rate (w_theta): 0.001000\t TIME:1740.0s\n",
      "\t\t\t\tDisc: 0.011512\t\tSym: 0.000000\t\tSpars: 0.000788\n",
      "\t TVw: 0.770606 | TVb: 2.283425 | GSw: -0.591398 | GSb: -0.263346 | TSUw: -0.415327 | TSUb: -0.035835\n",
      "\n",
      "Train Epoch: 5489 [4000/8000 (50%)]\tBatch Loss: 0.012727\tLearning Rate (w_theta): 0.001000\t TIME:1741.2s\n",
      "\t\t\t\tDisc: 0.011974\t\tSym: 0.000000\t\tSpars: 0.000753\n",
      "\t TVw: 0.770958 | TVb: 2.283438 | GSw: -0.591196 | GSb: -0.263086 | TSUw: -0.414925 | TSUb: -0.035460\n",
      "Validating epoch 5489...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012885822946179935\n",
      "Average validation loss: 0.013394987356522012\n",
      "Training epoch 5490...\n",
      "\n",
      "Train Epoch: 5490 [0/8000 (0%)]\tBatch Loss: 0.012697\tLearning Rate (w_theta): 0.001000\t TIME:1743.5s\n",
      "\t\t\t\tDisc: 0.011914\t\tSym: 0.000000\t\tSpars: 0.000783\n",
      "\t TVw: 0.770798 | TVb: 2.283441 | GSw: -0.590989 | GSb: -0.262821 | TSUw: -0.414414 | TSUb: -0.034990\n",
      "\n",
      "Train Epoch: 5490 [4000/8000 (50%)]\tBatch Loss: 0.013392\tLearning Rate (w_theta): 0.001000\t TIME:1744.8s\n",
      "\t\t\t\tDisc: 0.012625\t\tSym: 0.000000\t\tSpars: 0.000767\n",
      "\t TVw: 0.770308 | TVb: 2.283372 | GSw: -0.590787 | GSb: -0.262560 | TSUw: -0.414030 | TSUb: -0.034629\n",
      "Validating epoch 5490...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012886842278469923\n",
      "Average validation loss: 0.0133948393293413\n",
      "Training epoch 5491...\n",
      "\n",
      "Train Epoch: 5491 [0/8000 (0%)]\tBatch Loss: 0.012265\tLearning Rate (w_theta): 0.001000\t TIME:1747.7s\n",
      "\t\t\t\tDisc: 0.011631\t\tSym: 0.000000\t\tSpars: 0.000634\n",
      "\t TVw: 0.770136 | TVb: 2.283378 | GSw: -0.590643 | GSb: -0.262363 | TSUw: -0.414606 | TSUb: -0.035088\n",
      "\n",
      "Train Epoch: 5491 [4000/8000 (50%)]\tBatch Loss: 0.013048\tLearning Rate (w_theta): 0.001000\t TIME:1749.0s\n",
      "\t\t\t\tDisc: 0.011986\t\tSym: 0.000000\t\tSpars: 0.001063\n",
      "\t TVw: 0.770169 | TVb: 2.283400 | GSw: -0.590481 | GSb: -0.262148 | TSUw: -0.414884 | TSUb: -0.035295\n",
      "Validating epoch 5491...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012886781238203523\n",
      "Average validation loss: 0.013397555529444835\n",
      "Training epoch 5492...\n",
      "\n",
      "Train Epoch: 5492 [0/8000 (0%)]\tBatch Loss: 0.013464\tLearning Rate (w_theta): 0.001000\t TIME:1751.2s\n",
      "\t\t\t\tDisc: 0.012384\t\tSym: 0.000000\t\tSpars: 0.001080\n",
      "\t TVw: 0.770296 | TVb: 2.283483 | GSw: -0.590339 | GSb: -0.261954 | TSUw: -0.415527 | TSUb: -0.035813\n",
      "\n",
      "Train Epoch: 5492 [4000/8000 (50%)]\tBatch Loss: 0.012681\tLearning Rate (w_theta): 0.001000\t TIME:1752.6s\n",
      "\t\t\t\tDisc: 0.012078\t\tSym: 0.000000\t\tSpars: 0.000603\n",
      "\t TVw: 0.770300 | TVb: 2.283488 | GSw: -0.590133 | GSb: -0.261687 | TSUw: -0.415034 | TSUb: -0.035358\n",
      "Validating epoch 5492...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012887964478435836\n",
      "Average validation loss: 0.013394280638887196\n",
      "Training epoch 5493...\n",
      "\n",
      "Train Epoch: 5493 [0/8000 (0%)]\tBatch Loss: 0.012903\tLearning Rate (w_theta): 0.001000\t TIME:1754.8s\n",
      "\t\t\t\tDisc: 0.012221\t\tSym: 0.000000\t\tSpars: 0.000682\n",
      "\t TVw: 0.770122 | TVb: 2.283432 | GSw: -0.589906 | GSb: -0.261399 | TSUw: -0.414161 | TSUb: -0.034576\n",
      "\n",
      "Train Epoch: 5493 [4000/8000 (50%)]\tBatch Loss: 0.013106\tLearning Rate (w_theta): 0.001000\t TIME:1756.1s\n",
      "\t\t\t\tDisc: 0.012255\t\tSym: 0.000000\t\tSpars: 0.000851\n",
      "\t TVw: 0.769507 | TVb: 2.283255 | GSw: -0.589747 | GSb: -0.261186 | TSUw: -0.414424 | TSUb: -0.034769\n",
      "Validating epoch 5493...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01288820572284966\n",
      "Average validation loss: 0.01339702219586566\n",
      "Training epoch 5494...\n",
      "\n",
      "Train Epoch: 5494 [0/8000 (0%)]\tBatch Loss: 0.012979\tLearning Rate (w_theta): 0.001000\t TIME:1758.3s\n",
      "\t\t\t\tDisc: 0.012251\t\tSym: 0.000000\t\tSpars: 0.000729\n",
      "\t TVw: 0.769477 | TVb: 2.283320 | GSw: -0.589635 | GSb: -0.261027 | TSUw: -0.415532 | TSUb: -0.035690\n",
      "\n",
      "Train Epoch: 5494 [4000/8000 (50%)]\tBatch Loss: 0.013222\tLearning Rate (w_theta): 0.001000\t TIME:1759.6s\n",
      "\t\t\t\tDisc: 0.012293\t\tSym: 0.000000\t\tSpars: 0.000929\n",
      "\t TVw: 0.768959 | TVb: 2.283245 | GSw: -0.589473 | GSb: -0.260810 | TSUw: -0.415792 | TSUb: -0.035879\n",
      "Validating epoch 5494...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012887561229545322\n",
      "Average validation loss: 0.013397883411232141\n",
      "Training epoch 5495...\n",
      "\n",
      "Train Epoch: 5495 [0/8000 (0%)]\tBatch Loss: 0.012779\tLearning Rate (w_theta): 0.001000\t TIME:1761.9s\n",
      "\t\t\t\tDisc: 0.011954\t\tSym: 0.000000\t\tSpars: 0.000826\n",
      "\t TVw: 0.769258 | TVb: 2.283316 | GSw: -0.589269 | GSb: -0.260547 | TSUw: -0.415362 | TSUb: -0.035476\n",
      "\n",
      "Train Epoch: 5495 [4000/8000 (50%)]\tBatch Loss: 0.013037\tLearning Rate (w_theta): 0.001000\t TIME:1763.1s\n",
      "\t\t\t\tDisc: 0.011998\t\tSym: 0.000000\t\tSpars: 0.001040\n",
      "\t TVw: 0.769500 | TVb: 2.283406 | GSw: -0.589086 | GSb: -0.260303 | TSUw: -0.415311 | TSUb: -0.035399\n",
      "Validating epoch 5495...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012886770078124842\n",
      "Average validation loss: 0.013395983772974145\n",
      "Training epoch 5496...\n",
      "\n",
      "Train Epoch: 5496 [0/8000 (0%)]\tBatch Loss: 0.012871\tLearning Rate (w_theta): 0.001000\t TIME:1765.3s\n",
      "\t\t\t\tDisc: 0.012331\t\tSym: 0.000000\t\tSpars: 0.000540\n",
      "\t TVw: 0.769459 | TVb: 2.283426 | GSw: -0.588888 | GSb: -0.260050 | TSUw: -0.415002 | TSUb: -0.035100\n",
      "\n",
      "Train Epoch: 5496 [4000/8000 (50%)]\tBatch Loss: 0.013203\tLearning Rate (w_theta): 0.001000\t TIME:1766.6s\n",
      "\t\t\t\tDisc: 0.012220\t\tSym: 0.000000\t\tSpars: 0.000984\n",
      "\t TVw: 0.769234 | TVb: 2.283368 | GSw: -0.588680 | GSb: -0.259786 | TSUw: -0.414545 | TSUb: -0.034674\n",
      "Validating epoch 5496...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012887722353411145\n",
      "Average validation loss: 0.013395390055363509\n",
      "Training epoch 5497...\n",
      "\n",
      "Train Epoch: 5497 [0/8000 (0%)]\tBatch Loss: 0.012538\tLearning Rate (w_theta): 0.001000\t TIME:1768.9s\n",
      "\t\t\t\tDisc: 0.011874\t\tSym: 0.000000\t\tSpars: 0.000664\n",
      "\t TVw: 0.769333 | TVb: 2.283435 | GSw: -0.588533 | GSb: -0.259587 | TSUw: -0.415091 | TSUb: -0.035113\n",
      "\n",
      "Train Epoch: 5497 [4000/8000 (50%)]\tBatch Loss: 0.012439\tLearning Rate (w_theta): 0.001000\t TIME:1770.2s\n",
      "\t\t\t\tDisc: 0.011719\t\tSym: 0.000000\t\tSpars: 0.000721\n",
      "\t TVw: 0.769380 | TVb: 2.283457 | GSw: -0.588369 | GSb: -0.259369 | TSUw: -0.415379 | TSUb: -0.035332\n",
      "Validating epoch 5497...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012886560394615328\n",
      "Average validation loss: 0.01339670290672854\n",
      "Training epoch 5498...\n",
      "\n",
      "Train Epoch: 5498 [0/8000 (0%)]\tBatch Loss: 0.013536\tLearning Rate (w_theta): 0.001000\t TIME:1772.4s\n",
      "\t\t\t\tDisc: 0.012413\t\tSym: 0.000000\t\tSpars: 0.001123\n",
      "\t TVw: 0.769665 | TVb: 2.283544 | GSw: -0.588215 | GSb: -0.259162 | TSUw: -0.415855 | TSUb: -0.035712\n",
      "\n",
      "Train Epoch: 5498 [4000/8000 (50%)]\tBatch Loss: 0.012371\tLearning Rate (w_theta): 0.001000\t TIME:1773.6s\n",
      "\t\t\t\tDisc: 0.011782\t\tSym: 0.000000\t\tSpars: 0.000589\n",
      "\t TVw: 0.770055 | TVb: 2.283667 | GSw: -0.588074 | GSb: -0.258971 | TSUw: -0.416591 | TSUb: -0.036317\n",
      "Validating epoch 5498...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012888170969000547\n",
      "Average validation loss: 0.013395970799247746\n",
      "Training epoch 5499...\n",
      "\n",
      "Train Epoch: 5499 [0/8000 (0%)]\tBatch Loss: 0.013386\tLearning Rate (w_theta): 0.001000\t TIME:1775.9s\n",
      "\t\t\t\tDisc: 0.012642\t\tSym: 0.000000\t\tSpars: 0.000744\n",
      "\t TVw: 0.769708 | TVb: 2.283532 | GSw: -0.587826 | GSb: -0.258662 | TSUw: -0.415359 | TSUb: -0.035213\n",
      "\n",
      "Train Epoch: 5499 [4000/8000 (50%)]\tBatch Loss: 0.012694\tLearning Rate (w_theta): 0.001000\t TIME:1777.2s\n",
      "\t\t\t\tDisc: 0.012114\t\tSym: 0.000000\t\tSpars: 0.000581\n",
      "\t TVw: 0.769897 | TVb: 2.283535 | GSw: -0.587602 | GSb: -0.258379 | TSUw: -0.414567 | TSUb: -0.034494\n",
      "Validating epoch 5499...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01288702864264453\n",
      "Average validation loss: 0.013393996770689271\n",
      "Training epoch 5500...\n",
      "\n",
      "Train Epoch: 5500 [0/8000 (0%)]\tBatch Loss: 0.012844\tLearning Rate (w_theta): 0.001000\t TIME:1779.4s\n",
      "\t\t\t\tDisc: 0.012153\t\tSym: 0.000000\t\tSpars: 0.000691\n",
      "\t TVw: 0.769914 | TVb: 2.283538 | GSw: -0.587431 | GSb: -0.258154 | TSUw: -0.414687 | TSUb: -0.034567\n",
      "\n",
      "Train Epoch: 5500 [4000/8000 (50%)]\tBatch Loss: 0.012075\tLearning Rate (w_theta): 0.001000\t TIME:1780.7s\n",
      "\t\t\t\tDisc: 0.011502\t\tSym: 0.000000\t\tSpars: 0.000572\n",
      "\t TVw: 0.769967 | TVb: 2.283568 | GSw: -0.587277 | GSb: -0.257948 | TSUw: -0.415104 | TSUb: -0.034899\n",
      "Validating epoch 5500...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01288603486130228\n",
      "Average validation loss: 0.013396596011933137\n",
      "Training epoch 5501...\n",
      "\n",
      "Train Epoch: 5501 [0/8000 (0%)]\tBatch Loss: 0.012923\tLearning Rate (w_theta): 0.001000\t TIME:1783.5s\n",
      "\t\t\t\tDisc: 0.011939\t\tSym: 0.000000\t\tSpars: 0.000984\n",
      "\t TVw: 0.769961 | TVb: 2.283627 | GSw: -0.587170 | GSb: -0.257794 | TSUw: -0.416326 | TSUb: -0.035931\n",
      "\n",
      "Train Epoch: 5501 [4000/8000 (50%)]\tBatch Loss: 0.012852\tLearning Rate (w_theta): 0.001000\t TIME:1784.8s\n",
      "\t\t\t\tDisc: 0.012139\t\tSym: 0.000000\t\tSpars: 0.000713\n",
      "\t TVw: 0.770594 | TVb: 2.283866 | GSw: -0.587058 | GSb: -0.257633 | TSUw: -0.417506 | TSUb: -0.036925\n",
      "Validating epoch 5501...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012888289408458247\n",
      "Average validation loss: 0.013399808563724872\n",
      "Training epoch 5502...\n",
      "\n",
      "Train Epoch: 5502 [0/8000 (0%)]\tBatch Loss: 0.012541\tLearning Rate (w_theta): 0.001000\t TIME:1787.1s\n",
      "\t\t\t\tDisc: 0.011595\t\tSym: 0.000000\t\tSpars: 0.000946\n",
      "\t TVw: 0.770323 | TVb: 2.283786 | GSw: -0.586826 | GSb: -0.257343 | TSUw: -0.416480 | TSUb: -0.035993\n",
      "\n",
      "Train Epoch: 5502 [4000/8000 (50%)]\tBatch Loss: 0.012744\tLearning Rate (w_theta): 0.001000\t TIME:1788.3s\n",
      "\t\t\t\tDisc: 0.012032\t\tSym: 0.000000\t\tSpars: 0.000712\n",
      "\t TVw: 0.770436 | TVb: 2.283808 | GSw: -0.586580 | GSb: -0.257031 | TSUw: -0.415262 | TSUb: -0.034896\n",
      "Validating epoch 5502...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012884789286739662\n",
      "Average validation loss: 0.013393691191559478\n",
      "Training epoch 5503...\n",
      "\n",
      "Train Epoch: 5503 [0/8000 (0%)]\tBatch Loss: 0.013254\tLearning Rate (w_theta): 0.001000\t TIME:1790.5s\n",
      "\t\t\t\tDisc: 0.012270\t\tSym: 0.000000\t\tSpars: 0.000984\n",
      "\t TVw: 0.770035 | TVb: 2.283684 | GSw: -0.586340 | GSb: -0.256730 | TSUw: -0.414159 | TSUb: -0.033899\n",
      "\n",
      "Train Epoch: 5503 [4000/8000 (50%)]\tBatch Loss: 0.013457\tLearning Rate (w_theta): 0.001000\t TIME:1791.8s\n",
      "\t\t\t\tDisc: 0.012147\t\tSym: 0.000000\t\tSpars: 0.001309\n",
      "\t TVw: 0.769459 | TVb: 2.283546 | GSw: -0.586175 | GSb: -0.256511 | TSUw: -0.414276 | TSUb: -0.033971\n",
      "Validating epoch 5503...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012890638099542117\n",
      "Average validation loss: 0.013396014584966604\n",
      "Training epoch 5504...\n",
      "\n",
      "Train Epoch: 5504 [0/8000 (0%)]\tBatch Loss: 0.013198\tLearning Rate (w_theta): 0.001000\t TIME:1794.1s\n",
      "\t\t\t\tDisc: 0.012370\t\tSym: 0.000000\t\tSpars: 0.000828\n",
      "\t TVw: 0.769416 | TVb: 2.283654 | GSw: -0.586136 | GSb: -0.256431 | TSUw: -0.416397 | TSUb: -0.035795\n",
      "\n",
      "Train Epoch: 5504 [4000/8000 (50%)]\tBatch Loss: 0.012553\tLearning Rate (w_theta): 0.001000\t TIME:1795.3s\n",
      "\t\t\t\tDisc: 0.011736\t\tSym: 0.000000\t\tSpars: 0.000818\n",
      "\t TVw: 0.768853 | TVb: 2.283631 | GSw: -0.585975 | GSb: -0.256216 | TSUw: -0.416533 | TSUb: -0.035881\n",
      "Validating epoch 5504...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012885951498150711\n",
      "Average validation loss: 0.01340025146126605\n",
      "Training epoch 5505...\n",
      "\n",
      "Train Epoch: 5505 [0/8000 (0%)]\tBatch Loss: 0.012832\tLearning Rate (w_theta): 0.001000\t TIME:1797.5s\n",
      "\t\t\t\tDisc: 0.012108\t\tSym: 0.000000\t\tSpars: 0.000724\n",
      "\t TVw: 0.768908 | TVb: 2.283657 | GSw: -0.585826 | GSb: -0.256021 | TSUw: -0.416946 | TSUb: -0.036210\n",
      "\n",
      "Train Epoch: 5505 [4000/8000 (50%)]\tBatch Loss: 0.012327\tLearning Rate (w_theta): 0.001000\t TIME:1798.8s\n",
      "\t\t\t\tDisc: 0.011471\t\tSym: 0.000000\t\tSpars: 0.000856\n",
      "\t TVw: 0.768823 | TVb: 2.283669 | GSw: -0.585588 | GSb: -0.255729 | TSUw: -0.415834 | TSUb: -0.035200\n",
      "Validating epoch 5505...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012888716498945688\n",
      "Average validation loss: 0.013395164855018155\n",
      "Training epoch 5506...\n",
      "\n",
      "Train Epoch: 5506 [0/8000 (0%)]\tBatch Loss: 0.012678\tLearning Rate (w_theta): 0.001000\t TIME:1801.1s\n",
      "\t\t\t\tDisc: 0.012040\t\tSym: 0.000000\t\tSpars: 0.000638\n",
      "\t TVw: 0.768649 | TVb: 2.283643 | GSw: -0.585413 | GSb: -0.255501 | TSUw: -0.415853 | TSUb: -0.035184\n",
      "\n",
      "Train Epoch: 5506 [4000/8000 (50%)]\tBatch Loss: 0.012507\tLearning Rate (w_theta): 0.001000\t TIME:1802.4s\n",
      "\t\t\t\tDisc: 0.011764\t\tSym: 0.000000\t\tSpars: 0.000743\n",
      "\t TVw: 0.768784 | TVb: 2.283651 | GSw: -0.585257 | GSb: -0.255295 | TSUw: -0.416221 | TSUb: -0.035476\n",
      "Validating epoch 5506...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01288658331952602\n",
      "Average validation loss: 0.013397346119907127\n",
      "Training epoch 5507...\n",
      "\n",
      "Train Epoch: 5507 [0/8000 (0%)]\tBatch Loss: 0.012436\tLearning Rate (w_theta): 0.001000\t TIME:1804.5s\n",
      "\t\t\t\tDisc: 0.011733\t\tSym: 0.000000\t\tSpars: 0.000703\n",
      "\t TVw: 0.768705 | TVb: 2.283634 | GSw: -0.585093 | GSb: -0.255079 | TSUw: -0.416477 | TSUb: -0.035669\n",
      "\n",
      "Train Epoch: 5507 [4000/8000 (50%)]\tBatch Loss: 0.013527\tLearning Rate (w_theta): 0.001000\t TIME:1805.8s\n",
      "\t\t\t\tDisc: 0.012350\t\tSym: 0.000000\t\tSpars: 0.001176\n",
      "\t TVw: 0.768746 | TVb: 2.283683 | GSw: -0.584928 | GSb: -0.254865 | TSUw: -0.416725 | TSUb: -0.035855\n",
      "Validating epoch 5507...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012886546461784849\n",
      "Average validation loss: 0.01339697655055843\n",
      "Training epoch 5508...\n",
      "\n",
      "Train Epoch: 5508 [0/8000 (0%)]\tBatch Loss: 0.013653\tLearning Rate (w_theta): 0.001000\t TIME:1808.0s\n",
      "\t\t\t\tDisc: 0.012674\t\tSym: 0.000000\t\tSpars: 0.000978\n",
      "\t TVw: 0.768738 | TVb: 2.283666 | GSw: -0.584727 | GSb: -0.254607 | TSUw: -0.416387 | TSUb: -0.035524\n",
      "\n",
      "Train Epoch: 5508 [4000/8000 (50%)]\tBatch Loss: 0.012818\tLearning Rate (w_theta): 0.001000\t TIME:1809.3s\n",
      "\t\t\t\tDisc: 0.012059\t\tSym: 0.000000\t\tSpars: 0.000759\n",
      "\t TVw: 0.768805 | TVb: 2.283659 | GSw: -0.584485 | GSb: -0.254303 | TSUw: -0.415385 | TSUb: -0.034611\n",
      "Validating epoch 5508...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012888143519834925\n",
      "Average validation loss: 0.013394797955218021\n",
      "Training epoch 5509...\n",
      "\n",
      "Train Epoch: 5509 [0/8000 (0%)]\tBatch Loss: 0.012112\tLearning Rate (w_theta): 0.001000\t TIME:1811.5s\n",
      "\t\t\t\tDisc: 0.011644\t\tSym: 0.000000\t\tSpars: 0.000468\n",
      "\t TVw: 0.768532 | TVb: 2.283598 | GSw: -0.584331 | GSb: -0.254097 | TSUw: -0.415796 | TSUb: -0.034942\n",
      "\n",
      "Train Epoch: 5509 [4000/8000 (50%)]\tBatch Loss: 0.012918\tLearning Rate (w_theta): 0.001000\t TIME:1812.8s\n",
      "\t\t\t\tDisc: 0.011982\t\tSym: 0.000000\t\tSpars: 0.000936\n",
      "\t TVw: 0.767213 | TVb: 2.283281 | GSw: -0.584152 | GSb: -0.253867 | TSUw: -0.415767 | TSUb: -0.034884\n",
      "Validating epoch 5509...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012888477127954632\n",
      "Average validation loss: 0.01339900509832399\n",
      "Training epoch 5510...\n",
      "\n",
      "Train Epoch: 5510 [0/8000 (0%)]\tBatch Loss: 0.013289\tLearning Rate (w_theta): 0.001000\t TIME:1815.1s\n",
      "\t\t\t\tDisc: 0.012289\t\tSym: 0.000000\t\tSpars: 0.001000\n",
      "\t TVw: 0.767644 | TVb: 2.283450 | GSw: -0.584067 | GSb: -0.253736 | TSUw: -0.417377 | TSUb: -0.036276\n",
      "\n",
      "Train Epoch: 5510 [4000/8000 (50%)]\tBatch Loss: 0.013711\tLearning Rate (w_theta): 0.001000\t TIME:1816.4s\n",
      "\t\t\t\tDisc: 0.012712\t\tSym: 0.000000\t\tSpars: 0.000999\n",
      "\t TVw: 0.768146 | TVb: 2.283583 | GSw: -0.583929 | GSb: -0.253548 | TSUw: -0.418035 | TSUb: -0.036826\n",
      "Validating epoch 5510...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012890531024481535\n",
      "Average validation loss: 0.013398670734973014\n",
      "Training epoch 5511...\n",
      "\n",
      "Train Epoch: 5511 [0/8000 (0%)]\tBatch Loss: 0.013290\tLearning Rate (w_theta): 0.001000\t TIME:1819.3s\n",
      "\t\t\t\tDisc: 0.012442\t\tSym: 0.000000\t\tSpars: 0.000848\n",
      "\t TVw: 0.768449 | TVb: 2.283609 | GSw: -0.583668 | GSb: -0.253225 | TSUw: -0.416595 | TSUb: -0.035516\n",
      "\n",
      "Train Epoch: 5511 [4000/8000 (50%)]\tBatch Loss: 0.013015\tLearning Rate (w_theta): 0.001000\t TIME:1820.5s\n",
      "\t\t\t\tDisc: 0.011921\t\tSym: 0.000000\t\tSpars: 0.001094\n",
      "\t TVw: 0.768168 | TVb: 2.283457 | GSw: -0.583395 | GSb: -0.252890 | TSUw: -0.414948 | TSUb: -0.034023\n",
      "Validating epoch 5511...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012892551148332439\n",
      "Average validation loss: 0.013395113134484918\n",
      "Training epoch 5512...\n",
      "\n",
      "Train Epoch: 5512 [0/8000 (0%)]\tBatch Loss: 0.012899\tLearning Rate (w_theta): 0.001000\t TIME:1822.7s\n",
      "\t\t\t\tDisc: 0.012050\t\tSym: 0.000000\t\tSpars: 0.000849\n",
      "\t TVw: 0.768367 | TVb: 2.283548 | GSw: -0.583291 | GSb: -0.252740 | TSUw: -0.416005 | TSUb: -0.034928\n",
      "\n",
      "Train Epoch: 5512 [4000/8000 (50%)]\tBatch Loss: 0.012879\tLearning Rate (w_theta): 0.001000\t TIME:1824.0s\n",
      "\t\t\t\tDisc: 0.012098\t\tSym: 0.000000\t\tSpars: 0.000782\n",
      "\t TVw: 0.768146 | TVb: 2.283594 | GSw: -0.583251 | GSb: -0.252659 | TSUw: -0.418043 | TSUb: -0.036705\n",
      "Validating epoch 5512...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012893186780153441\n",
      "Average validation loss: 0.013401104769520602\n",
      "Training epoch 5513...\n",
      "\n",
      "Train Epoch: 5513 [0/8000 (0%)]\tBatch Loss: 0.013149\tLearning Rate (w_theta): 0.001000\t TIME:1826.3s\n",
      "\t\t\t\tDisc: 0.012110\t\tSym: 0.000000\t\tSpars: 0.001039\n",
      "\t TVw: 0.768433 | TVb: 2.283664 | GSw: -0.583059 | GSb: -0.252413 | TSUw: -0.417593 | TSUb: -0.036268\n",
      "\n",
      "Train Epoch: 5513 [4000/8000 (50%)]\tBatch Loss: 0.013256\tLearning Rate (w_theta): 0.001000\t TIME:1827.6s\n",
      "\t\t\t\tDisc: 0.012213\t\tSym: 0.000000\t\tSpars: 0.001043\n",
      "\t TVw: 0.768737 | TVb: 2.283750 | GSw: -0.582830 | GSb: -0.252124 | TSUw: -0.416657 | TSUb: -0.035398\n",
      "Validating epoch 5513...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0128858060027319\n",
      "Average validation loss: 0.013394335411882558\n",
      "Training epoch 5514...\n",
      "\n",
      "Train Epoch: 5514 [0/8000 (0%)]\tBatch Loss: 0.012962\tLearning Rate (w_theta): 0.001000\t TIME:1829.8s\n",
      "\t\t\t\tDisc: 0.012246\t\tSym: 0.000000\t\tSpars: 0.000717\n",
      "\t TVw: 0.768812 | TVb: 2.283750 | GSw: -0.582610 | GSb: -0.251849 | TSUw: -0.415911 | TSUb: -0.034699\n",
      "\n",
      "Train Epoch: 5514 [4000/8000 (50%)]\tBatch Loss: 0.012502\tLearning Rate (w_theta): 0.001000\t TIME:1831.1s\n",
      "\t\t\t\tDisc: 0.011828\t\tSym: 0.000000\t\tSpars: 0.000674\n",
      "\t TVw: 0.769045 | TVb: 2.283867 | GSw: -0.582484 | GSb: -0.251678 | TSUw: -0.416718 | TSUb: -0.035387\n",
      "Validating epoch 5514...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012887841343604848\n",
      "Average validation loss: 0.013395456141178092\n",
      "Training epoch 5515...\n",
      "\n",
      "Train Epoch: 5515 [0/8000 (0%)]\tBatch Loss: 0.013104\tLearning Rate (w_theta): 0.001000\t TIME:1833.4s\n",
      "\t\t\t\tDisc: 0.012064\t\tSym: 0.000000\t\tSpars: 0.001040\n",
      "\t TVw: 0.769014 | TVb: 2.283882 | GSw: -0.582308 | GSb: -0.251449 | TSUw: -0.416742 | TSUb: -0.035378\n",
      "\n",
      "Train Epoch: 5515 [4000/8000 (50%)]\tBatch Loss: 0.012620\tLearning Rate (w_theta): 0.001000\t TIME:1834.7s\n",
      "\t\t\t\tDisc: 0.011892\t\tSym: 0.000000\t\tSpars: 0.000728\n",
      "\t TVw: 0.768854 | TVb: 2.283819 | GSw: -0.582112 | GSb: -0.251197 | TSUw: -0.416497 | TSUb: -0.035130\n",
      "Validating epoch 5515...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012886126569102284\n",
      "Average validation loss: 0.013395130536806184\n",
      "Training epoch 5516...\n",
      "\n",
      "Train Epoch: 5516 [0/8000 (0%)]\tBatch Loss: 0.012617\tLearning Rate (w_theta): 0.001000\t TIME:1836.9s\n",
      "\t\t\t\tDisc: 0.011769\t\tSym: 0.000000\t\tSpars: 0.000848\n",
      "\t TVw: 0.768718 | TVb: 2.283803 | GSw: -0.581943 | GSb: -0.250976 | TSUw: -0.416670 | TSUb: -0.035256\n",
      "\n",
      "Train Epoch: 5516 [4000/8000 (50%)]\tBatch Loss: 0.012746\tLearning Rate (w_theta): 0.001000\t TIME:1838.1s\n",
      "\t\t\t\tDisc: 0.012029\t\tSym: 0.000000\t\tSpars: 0.000717\n",
      "\t TVw: 0.768058 | TVb: 2.283669 | GSw: -0.581773 | GSb: -0.250760 | TSUw: -0.416820 | TSUb: -0.035358\n",
      "Validating epoch 5516...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012886770471871542\n",
      "Average validation loss: 0.013397121083653422\n",
      "Training epoch 5517...\n",
      "\n",
      "Train Epoch: 5517 [0/8000 (0%)]\tBatch Loss: 0.012683\tLearning Rate (w_theta): 0.001000\t TIME:1840.4s\n",
      "\t\t\t\tDisc: 0.011976\t\tSym: 0.000000\t\tSpars: 0.000707\n",
      "\t TVw: 0.767799 | TVb: 2.283647 | GSw: -0.581613 | GSb: -0.250550 | TSUw: -0.417164 | TSUb: -0.035637\n",
      "\n",
      "Train Epoch: 5517 [4000/8000 (50%)]\tBatch Loss: 0.012588\tLearning Rate (w_theta): 0.001000\t TIME:1841.6s\n",
      "\t\t\t\tDisc: 0.011783\t\tSym: 0.000000\t\tSpars: 0.000806\n",
      "\t TVw: 0.767962 | TVb: 2.283717 | GSw: -0.581409 | GSb: -0.250289 | TSUw: -0.416839 | TSUb: -0.035319\n",
      "Validating epoch 5517...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012887322676341182\n",
      "Average validation loss: 0.0133960367216231\n",
      "Training epoch 5518...\n",
      "\n",
      "Train Epoch: 5518 [0/8000 (0%)]\tBatch Loss: 0.012835\tLearning Rate (w_theta): 0.001000\t TIME:1843.8s\n",
      "\t\t\t\tDisc: 0.012286\t\tSym: 0.000000\t\tSpars: 0.000549\n",
      "\t TVw: 0.767708 | TVb: 2.283709 | GSw: -0.581229 | GSb: -0.250057 | TSUw: -0.416872 | TSUb: -0.035320\n",
      "\n",
      "Train Epoch: 5518 [4000/8000 (50%)]\tBatch Loss: 0.013084\tLearning Rate (w_theta): 0.001000\t TIME:1845.1s\n",
      "\t\t\t\tDisc: 0.012116\t\tSym: 0.000000\t\tSpars: 0.000968\n",
      "\t TVw: 0.767466 | TVb: 2.283718 | GSw: -0.581068 | GSb: -0.249845 | TSUw: -0.417217 | TSUb: -0.035599\n",
      "Validating epoch 5518...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012887246592017051\n",
      "Average validation loss: 0.013398310862689288\n",
      "Training epoch 5519...\n",
      "\n",
      "Train Epoch: 5519 [0/8000 (0%)]\tBatch Loss: 0.012715\tLearning Rate (w_theta): 0.001000\t TIME:1847.5s\n",
      "\t\t\t\tDisc: 0.012161\t\tSym: 0.000000\t\tSpars: 0.000553\n",
      "\t TVw: 0.767376 | TVb: 2.283722 | GSw: -0.580897 | GSb: -0.249623 | TSUw: -0.417404 | TSUb: -0.035737\n",
      "\n",
      "Train Epoch: 5519 [4000/8000 (50%)]\tBatch Loss: 0.013526\tLearning Rate (w_theta): 0.001000\t TIME:1848.7s\n",
      "\t\t\t\tDisc: 0.012310\t\tSym: 0.000000\t\tSpars: 0.001216\n",
      "\t TVw: 0.767566 | TVb: 2.283748 | GSw: -0.580699 | GSb: -0.249371 | TSUw: -0.417176 | TSUb: -0.035505\n",
      "Validating epoch 5519...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012888097461383075\n",
      "Average validation loss: 0.013397317480662833\n",
      "Training epoch 5520...\n",
      "\n",
      "Train Epoch: 5520 [0/8000 (0%)]\tBatch Loss: 0.012683\tLearning Rate (w_theta): 0.001000\t TIME:1850.9s\n",
      "\t\t\t\tDisc: 0.011724\t\tSym: 0.000000\t\tSpars: 0.000958\n",
      "\t TVw: 0.767735 | TVb: 2.283799 | GSw: -0.580530 | GSb: -0.249150 | TSUw: -0.417414 | TSUb: -0.035689\n",
      "\n",
      "Train Epoch: 5520 [4000/8000 (50%)]\tBatch Loss: 0.012470\tLearning Rate (w_theta): 0.001000\t TIME:1852.2s\n",
      "\t\t\t\tDisc: 0.011766\t\tSym: 0.000000\t\tSpars: 0.000704\n",
      "\t TVw: 0.767537 | TVb: 2.283749 | GSw: -0.580307 | GSb: -0.248873 | TSUw: -0.416766 | TSUb: -0.035078\n",
      "Validating epoch 5520...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012887982537714096\n",
      "Average validation loss: 0.013396387744344233\n",
      "Training epoch 5521...\n",
      "\n",
      "Train Epoch: 5521 [0/8000 (0%)]\tBatch Loss: 0.013462\tLearning Rate (w_theta): 0.001000\t TIME:1855.1s\n",
      "\t\t\t\tDisc: 0.012790\t\tSym: 0.000000\t\tSpars: 0.000672\n",
      "\t TVw: 0.767263 | TVb: 2.283756 | GSw: -0.580153 | GSb: -0.248667 | TSUw: -0.417204 | TSUb: -0.035441\n",
      "\n",
      "Train Epoch: 5521 [4000/8000 (50%)]\tBatch Loss: 0.012708\tLearning Rate (w_theta): 0.001000\t TIME:1856.4s\n",
      "\t\t\t\tDisc: 0.011971\t\tSym: 0.000000\t\tSpars: 0.000737\n",
      "\t TVw: 0.767321 | TVb: 2.283762 | GSw: -0.580005 | GSb: -0.248463 | TSUw: -0.417736 | TSUb: -0.035890\n",
      "Validating epoch 5521...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012887379321858313\n",
      "Average validation loss: 0.01339758332025166\n",
      "Training epoch 5522...\n",
      "\n",
      "Train Epoch: 5522 [0/8000 (0%)]\tBatch Loss: 0.012466\tLearning Rate (w_theta): 0.001000\t TIME:1858.7s\n",
      "\t\t\t\tDisc: 0.011874\t\tSym: 0.000000\t\tSpars: 0.000591\n",
      "\t TVw: 0.767121 | TVb: 2.283733 | GSw: -0.579810 | GSb: -0.248215 | TSUw: -0.417536 | TSUb: -0.035680\n",
      "\n",
      "Train Epoch: 5522 [4000/8000 (50%)]\tBatch Loss: 0.012885\tLearning Rate (w_theta): 0.001000\t TIME:1860.0s\n",
      "\t\t\t\tDisc: 0.012009\t\tSym: 0.000000\t\tSpars: 0.000875\n",
      "\t TVw: 0.766702 | TVb: 2.283641 | GSw: -0.579640 | GSb: -0.247997 | TSUw: -0.417765 | TSUb: -0.035855\n",
      "Validating epoch 5522...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01288802066512694\n",
      "Average validation loss: 0.01339851978116177\n",
      "Training epoch 5523...\n",
      "\n",
      "Train Epoch: 5523 [0/8000 (0%)]\tBatch Loss: 0.012564\tLearning Rate (w_theta): 0.001000\t TIME:1862.2s\n",
      "\t\t\t\tDisc: 0.011922\t\tSym: 0.000000\t\tSpars: 0.000642\n",
      "\t TVw: 0.766612 | TVb: 2.283641 | GSw: -0.579449 | GSb: -0.247755 | TSUw: -0.417666 | TSUb: -0.035734\n",
      "\n",
      "Train Epoch: 5523 [4000/8000 (50%)]\tBatch Loss: 0.012827\tLearning Rate (w_theta): 0.001000\t TIME:1863.5s\n",
      "\t\t\t\tDisc: 0.012257\t\tSym: 0.000000\t\tSpars: 0.000570\n",
      "\t TVw: 0.766432 | TVb: 2.283643 | GSw: -0.579202 | GSb: -0.247452 | TSUw: -0.416634 | TSUb: -0.034775\n",
      "Validating epoch 5523...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01289085150751645\n",
      "Average validation loss: 0.013396113160449787\n",
      "Training epoch 5524...\n",
      "\n",
      "Train Epoch: 5524 [0/8000 (0%)]\tBatch Loss: 0.012559\tLearning Rate (w_theta): 0.001000\t TIME:1865.8s\n",
      "\t\t\t\tDisc: 0.011717\t\tSym: 0.000000\t\tSpars: 0.000842\n",
      "\t TVw: 0.766532 | TVb: 2.283669 | GSw: -0.579045 | GSb: -0.247246 | TSUw: -0.417030 | TSUb: -0.035104\n",
      "\n",
      "Train Epoch: 5524 [4000/8000 (50%)]\tBatch Loss: 0.013197\tLearning Rate (w_theta): 0.001000\t TIME:1867.1s\n",
      "\t\t\t\tDisc: 0.012560\t\tSym: 0.000000\t\tSpars: 0.000636\n",
      "\t TVw: 0.766749 | TVb: 2.283724 | GSw: -0.578920 | GSb: -0.247077 | TSUw: -0.417887 | TSUb: -0.035848\n",
      "Validating epoch 5524...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012888526789203847\n",
      "Average validation loss: 0.013398650196871736\n",
      "Training epoch 5525...\n",
      "\n",
      "Train Epoch: 5525 [0/8000 (0%)]\tBatch Loss: 0.012714\tLearning Rate (w_theta): 0.001000\t TIME:1869.3s\n",
      "\t\t\t\tDisc: 0.011807\t\tSym: 0.000000\t\tSpars: 0.000908\n",
      "\t TVw: 0.766769 | TVb: 2.283736 | GSw: -0.578762 | GSb: -0.246868 | TSUw: -0.418246 | TSUb: -0.036144\n",
      "\n",
      "Train Epoch: 5525 [4000/8000 (50%)]\tBatch Loss: 0.012936\tLearning Rate (w_theta): 0.001000\t TIME:1870.6s\n",
      "\t\t\t\tDisc: 0.012101\t\tSym: 0.000000\t\tSpars: 0.000834\n",
      "\t TVw: 0.766829 | TVb: 2.283717 | GSw: -0.578608 | GSb: -0.246661 | TSUw: -0.418744 | TSUb: -0.036564\n",
      "Validating epoch 5525...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012888860080896694\n",
      "Average validation loss: 0.01339981189519294\n",
      "Training epoch 5526...\n",
      "\n",
      "Train Epoch: 5526 [0/8000 (0%)]\tBatch Loss: 0.013308\tLearning Rate (w_theta): 0.001000\t TIME:1872.8s\n",
      "\t\t\t\tDisc: 0.012742\t\tSym: 0.000000\t\tSpars: 0.000566\n",
      "\t TVw: 0.766589 | TVb: 2.283668 | GSw: -0.578360 | GSb: -0.246354 | TSUw: -0.417674 | TSUb: -0.035561\n",
      "\n",
      "Train Epoch: 5526 [4000/8000 (50%)]\tBatch Loss: 0.012562\tLearning Rate (w_theta): 0.001000\t TIME:1874.1s\n",
      "\t\t\t\tDisc: 0.011783\t\tSym: 0.000000\t\tSpars: 0.000779\n",
      "\t TVw: 0.766376 | TVb: 2.283616 | GSw: -0.578084 | GSb: -0.246019 | TSUw: -0.416132 | TSUb: -0.034132\n",
      "Validating epoch 5526...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012894649521859864\n",
      "Average validation loss: 0.013396134628075554\n",
      "Training epoch 5527...\n",
      "\n",
      "Train Epoch: 5527 [0/8000 (0%)]\tBatch Loss: 0.012957\tLearning Rate (w_theta): 0.001000\t TIME:1876.3s\n",
      "\t\t\t\tDisc: 0.012167\t\tSym: 0.000000\t\tSpars: 0.000790\n",
      "\t TVw: 0.766504 | TVb: 2.283742 | GSw: -0.577999 | GSb: -0.245891 | TSUw: -0.417467 | TSUb: -0.035313\n",
      "\n",
      "Train Epoch: 5527 [4000/8000 (50%)]\tBatch Loss: 0.013120\tLearning Rate (w_theta): 0.001000\t TIME:1877.6s\n",
      "\t\t\t\tDisc: 0.012313\t\tSym: 0.000000\t\tSpars: 0.000806\n",
      "\t TVw: 0.766593 | TVb: 2.283806 | GSw: -0.577916 | GSb: -0.245768 | TSUw: -0.418910 | TSUb: -0.036593\n",
      "Validating epoch 5527...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012889294208118535\n",
      "Average validation loss: 0.013402710189242151\n",
      "Training epoch 5528...\n",
      "\n",
      "Train Epoch: 5528 [0/8000 (0%)]\tBatch Loss: 0.013413\tLearning Rate (w_theta): 0.001000\t TIME:1880.0s\n",
      "\t\t\t\tDisc: 0.012470\t\tSym: 0.000000\t\tSpars: 0.000943\n",
      "\t TVw: 0.766781 | TVb: 2.283857 | GSw: -0.577725 | GSb: -0.245526 | TSUw: -0.418645 | TSUb: -0.036320\n",
      "\n",
      "Train Epoch: 5528 [4000/8000 (50%)]\tBatch Loss: 0.012935\tLearning Rate (w_theta): 0.001000\t TIME:1881.3s\n",
      "\t\t\t\tDisc: 0.012095\t\tSym: 0.000000\t\tSpars: 0.000840\n",
      "\t TVw: 0.767124 | TVb: 2.283936 | GSw: -0.577451 | GSb: -0.245192 | TSUw: -0.417104 | TSUb: -0.034885\n",
      "Validating epoch 5528...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01289067341255078\n",
      "Average validation loss: 0.01339532581703325\n",
      "Training epoch 5529...\n",
      "\n",
      "Train Epoch: 5529 [0/8000 (0%)]\tBatch Loss: 0.012954\tLearning Rate (w_theta): 0.001000\t TIME:1883.5s\n",
      "\t\t\t\tDisc: 0.012077\t\tSym: 0.000000\t\tSpars: 0.000877\n",
      "\t TVw: 0.766923 | TVb: 2.283920 | GSw: -0.577291 | GSb: -0.244984 | TSUw: -0.417338 | TSUb: -0.035067\n",
      "\n",
      "Train Epoch: 5529 [4000/8000 (50%)]\tBatch Loss: 0.012781\tLearning Rate (w_theta): 0.001000\t TIME:1884.8s\n",
      "\t\t\t\tDisc: 0.012125\t\tSym: 0.000000\t\tSpars: 0.000655\n",
      "\t TVw: 0.766366 | TVb: 2.283832 | GSw: -0.577154 | GSb: -0.244799 | TSUw: -0.417944 | TSUb: -0.035587\n",
      "Validating epoch 5529...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012887873756956015\n",
      "Average validation loss: 0.013398924866777358\n",
      "Training epoch 5530...\n",
      "\n",
      "Train Epoch: 5530 [0/8000 (0%)]\tBatch Loss: 0.012901\tLearning Rate (w_theta): 0.001000\t TIME:1887.1s\n",
      "\t\t\t\tDisc: 0.012149\t\tSym: 0.000000\t\tSpars: 0.000753\n",
      "\t TVw: 0.766027 | TVb: 2.283758 | GSw: -0.577001 | GSb: -0.244596 | TSUw: -0.418360 | TSUb: -0.035937\n",
      "\n",
      "Train Epoch: 5530 [4000/8000 (50%)]\tBatch Loss: 0.013527\tLearning Rate (w_theta): 0.001000\t TIME:1888.3s\n",
      "\t\t\t\tDisc: 0.012508\t\tSym: 0.000000\t\tSpars: 0.001019\n",
      "\t TVw: 0.765269 | TVb: 2.283478 | GSw: -0.576802 | GSb: -0.244346 | TSUw: -0.418103 | TSUb: -0.035671\n",
      "Validating epoch 5530...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012889569522322121\n",
      "Average validation loss: 0.01339902078243289\n",
      "Training epoch 5531...\n",
      "\n",
      "Train Epoch: 5531 [0/8000 (0%)]\tBatch Loss: 0.012637\tLearning Rate (w_theta): 0.001000\t TIME:1891.2s\n",
      "\t\t\t\tDisc: 0.011961\t\tSym: 0.000000\t\tSpars: 0.000676\n",
      "\t TVw: 0.765203 | TVb: 2.283434 | GSw: -0.576625 | GSb: -0.244120 | TSUw: -0.418214 | TSUb: -0.035743\n",
      "\n",
      "Train Epoch: 5531 [4000/8000 (50%)]\tBatch Loss: 0.012641\tLearning Rate (w_theta): 0.001000\t TIME:1892.5s\n",
      "\t\t\t\tDisc: 0.012051\t\tSym: 0.000000\t\tSpars: 0.000590\n",
      "\t TVw: 0.765743 | TVb: 2.283628 | GSw: -0.576483 | GSb: -0.243931 | TSUw: -0.418892 | TSUb: -0.036335\n",
      "Validating epoch 5531...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01289058395359206\n",
      "Average validation loss: 0.013400745099080902\n",
      "Training epoch 5532...\n",
      "\n",
      "Train Epoch: 5532 [0/8000 (0%)]\tBatch Loss: 0.012874\tLearning Rate (w_theta): 0.001000\t TIME:1894.7s\n",
      "\t\t\t\tDisc: 0.012172\t\tSym: 0.000000\t\tSpars: 0.000701\n",
      "\t TVw: 0.765724 | TVb: 2.283626 | GSw: -0.576270 | GSb: -0.243664 | TSUw: -0.418428 | TSUb: -0.035879\n",
      "\n",
      "Train Epoch: 5532 [4000/8000 (50%)]\tBatch Loss: 0.012304\tLearning Rate (w_theta): 0.001000\t TIME:1896.0s\n",
      "\t\t\t\tDisc: 0.011499\t\tSym: 0.000000\t\tSpars: 0.000806\n",
      "\t TVw: 0.765448 | TVb: 2.283583 | GSw: -0.576038 | GSb: -0.243379 | TSUw: -0.417668 | TSUb: -0.035152\n",
      "Validating epoch 5532...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012889809143843425\n",
      "Average validation loss: 0.013397432510091352\n",
      "Training epoch 5533...\n",
      "\n",
      "Train Epoch: 5533 [0/8000 (0%)]\tBatch Loss: 0.012249\tLearning Rate (w_theta): 0.001000\t TIME:1898.2s\n",
      "\t\t\t\tDisc: 0.011659\t\tSym: 0.000000\t\tSpars: 0.000590\n",
      "\t TVw: 0.765175 | TVb: 2.283518 | GSw: -0.575861 | GSb: -0.243152 | TSUw: -0.417771 | TSUb: -0.035216\n",
      "\n",
      "Train Epoch: 5533 [4000/8000 (50%)]\tBatch Loss: 0.013261\tLearning Rate (w_theta): 0.001000\t TIME:1899.5s\n",
      "\t\t\t\tDisc: 0.012395\t\tSym: 0.000000\t\tSpars: 0.000866\n",
      "\t TVw: 0.764490 | TVb: 2.283371 | GSw: -0.575694 | GSb: -0.242940 | TSUw: -0.418039 | TSUb: -0.035432\n",
      "Validating epoch 5533...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012890830732052097\n",
      "Average validation loss: 0.01340018464981888\n",
      "Training epoch 5534...\n",
      "\n",
      "Train Epoch: 5534 [0/8000 (0%)]\tBatch Loss: 0.012812\tLearning Rate (w_theta): 0.001000\t TIME:1901.7s\n",
      "\t\t\t\tDisc: 0.012022\t\tSym: 0.000000\t\tSpars: 0.000790\n",
      "\t TVw: 0.764474 | TVb: 2.283416 | GSw: -0.575552 | GSb: -0.242749 | TSUw: -0.418702 | TSUb: -0.036012\n",
      "\n",
      "Train Epoch: 5534 [4000/8000 (50%)]\tBatch Loss: 0.013282\tLearning Rate (w_theta): 0.001000\t TIME:1903.0s\n",
      "\t\t\t\tDisc: 0.012238\t\tSym: 0.000000\t\tSpars: 0.001044\n",
      "\t TVw: 0.764709 | TVb: 2.283385 | GSw: -0.575397 | GSb: -0.242548 | TSUw: -0.419180 | TSUb: -0.036421\n",
      "Validating epoch 5534...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012891094205669433\n",
      "Average validation loss: 0.013400555306845422\n",
      "Training epoch 5535...\n",
      "\n",
      "Train Epoch: 5535 [0/8000 (0%)]\tBatch Loss: 0.012478\tLearning Rate (w_theta): 0.001000\t TIME:1905.2s\n",
      "\t\t\t\tDisc: 0.011807\t\tSym: 0.000000\t\tSpars: 0.000671\n",
      "\t TVw: 0.764852 | TVb: 2.283389 | GSw: -0.575169 | GSb: -0.242263 | TSUw: -0.418507 | TSUb: -0.035775\n",
      "\n",
      "Train Epoch: 5535 [4000/8000 (50%)]\tBatch Loss: 0.012519\tLearning Rate (w_theta): 0.001000\t TIME:1906.5s\n",
      "\t\t\t\tDisc: 0.011840\t\tSym: 0.000000\t\tSpars: 0.000680\n",
      "\t TVw: 0.764481 | TVb: 2.283232 | GSw: -0.574911 | GSb: -0.241944 | TSUw: -0.417405 | TSUb: -0.034733\n",
      "Validating epoch 5535...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01289341520237229\n",
      "Average validation loss: 0.013398406397623509\n",
      "Training epoch 5536...\n",
      "\n",
      "Train Epoch: 5536 [0/8000 (0%)]\tBatch Loss: 0.012546\tLearning Rate (w_theta): 0.001000\t TIME:1908.7s\n",
      "\t\t\t\tDisc: 0.011821\t\tSym: 0.000000\t\tSpars: 0.000726\n",
      "\t TVw: 0.764615 | TVb: 2.283273 | GSw: -0.574764 | GSb: -0.241747 | TSUw: -0.417922 | TSUb: -0.035179\n",
      "\n",
      "Train Epoch: 5536 [4000/8000 (50%)]\tBatch Loss: 0.013100\tLearning Rate (w_theta): 0.001000\t TIME:1910.0s\n",
      "\t\t\t\tDisc: 0.012173\t\tSym: 0.000000\t\tSpars: 0.000927\n",
      "\t TVw: 0.764820 | TVb: 2.283457 | GSw: -0.574671 | GSb: -0.241613 | TSUw: -0.419258 | TSUb: -0.036378\n",
      "Validating epoch 5536...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012891888224259065\n",
      "Average validation loss: 0.013403028717920982\n",
      "Training epoch 5537...\n",
      "\n",
      "Train Epoch: 5537 [0/8000 (0%)]\tBatch Loss: 0.012835\tLearning Rate (w_theta): 0.001000\t TIME:1912.2s\n",
      "\t\t\t\tDisc: 0.012098\t\tSym: 0.000000\t\tSpars: 0.000737\n",
      "\t TVw: 0.764995 | TVb: 2.283489 | GSw: -0.574482 | GSb: -0.241375 | TSUw: -0.419138 | TSUb: -0.036238\n",
      "\n",
      "Train Epoch: 5537 [4000/8000 (50%)]\tBatch Loss: 0.013256\tLearning Rate (w_theta): 0.001000\t TIME:1913.5s\n",
      "\t\t\t\tDisc: 0.012436\t\tSym: 0.000000\t\tSpars: 0.000820\n",
      "\t TVw: 0.765594 | TVb: 2.283661 | GSw: -0.574278 | GSb: -0.241120 | TSUw: -0.418821 | TSUb: -0.035917\n",
      "Validating epoch 5537...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012889738296751552\n",
      "Average validation loss: 0.013397474258236095\n",
      "Training epoch 5538...\n",
      "\n",
      "Train Epoch: 5538 [0/8000 (0%)]\tBatch Loss: 0.013030\tLearning Rate (w_theta): 0.001000\t TIME:1915.7s\n",
      "\t\t\t\tDisc: 0.012262\t\tSym: 0.000000\t\tSpars: 0.000768\n",
      "\t TVw: 0.765705 | TVb: 2.283653 | GSw: -0.574057 | GSb: -0.240845 | TSUw: -0.418278 | TSUb: -0.035389\n",
      "\n",
      "Train Epoch: 5538 [4000/8000 (50%)]\tBatch Loss: 0.012758\tLearning Rate (w_theta): 0.001000\t TIME:1917.0s\n",
      "\t\t\t\tDisc: 0.012055\t\tSym: 0.000000\t\tSpars: 0.000703\n",
      "\t TVw: 0.765501 | TVb: 2.283549 | GSw: -0.573884 | GSb: -0.240627 | TSUw: -0.418457 | TSUb: -0.035524\n",
      "Validating epoch 5538...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012889516180290791\n",
      "Average validation loss: 0.013398902116195023\n",
      "Training epoch 5539...\n",
      "\n",
      "Train Epoch: 5539 [0/8000 (0%)]\tBatch Loss: 0.012793\tLearning Rate (w_theta): 0.001000\t TIME:1919.3s\n",
      "\t\t\t\tDisc: 0.012154\t\tSym: 0.000000\t\tSpars: 0.000639\n",
      "\t TVw: 0.765314 | TVb: 2.283498 | GSw: -0.573727 | GSb: -0.240424 | TSUw: -0.418912 | TSUb: -0.035914\n",
      "\n",
      "Train Epoch: 5539 [4000/8000 (50%)]\tBatch Loss: 0.013458\tLearning Rate (w_theta): 0.001000\t TIME:1920.6s\n",
      "\t\t\t\tDisc: 0.012460\t\tSym: 0.000000\t\tSpars: 0.000997\n",
      "\t TVw: 0.765199 | TVb: 2.283518 | GSw: -0.573525 | GSb: -0.240167 | TSUw: -0.418657 | TSUb: -0.035650\n",
      "Validating epoch 5539...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012890519823683534\n",
      "Average validation loss: 0.013398175184208178\n",
      "Training epoch 5540...\n",
      "\n",
      "Train Epoch: 5540 [0/8000 (0%)]\tBatch Loss: 0.012844\tLearning Rate (w_theta): 0.001000\t TIME:1922.8s\n",
      "\t\t\t\tDisc: 0.012052\t\tSym: 0.000000\t\tSpars: 0.000792\n",
      "\t TVw: 0.765137 | TVb: 2.283514 | GSw: -0.573335 | GSb: -0.239925 | TSUw: -0.418611 | TSUb: -0.035579\n",
      "\n",
      "Train Epoch: 5540 [4000/8000 (50%)]\tBatch Loss: 0.012814\tLearning Rate (w_theta): 0.001000\t TIME:1924.1s\n",
      "\t\t\t\tDisc: 0.012411\t\tSym: 0.000000\t\tSpars: 0.000403\n",
      "\t TVw: 0.764744 | TVb: 2.283430 | GSw: -0.573166 | GSb: -0.239712 | TSUw: -0.418885 | TSUb: -0.035803\n",
      "Validating epoch 5540...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012890562977137726\n",
      "Average validation loss: 0.013399988384000305\n",
      "Training epoch 5541...\n",
      "\n",
      "Train Epoch: 5541 [0/8000 (0%)]\tBatch Loss: 0.013171\tLearning Rate (w_theta): 0.001000\t TIME:1927.0s\n",
      "\t\t\t\tDisc: 0.012226\t\tSym: 0.000000\t\tSpars: 0.000946\n",
      "\t TVw: 0.764537 | TVb: 2.283398 | GSw: -0.572975 | GSb: -0.239470 | TSUw: -0.418821 | TSUb: -0.035715\n",
      "\n",
      "Train Epoch: 5541 [4000/8000 (50%)]\tBatch Loss: 0.013014\tLearning Rate (w_theta): 0.001000\t TIME:1928.3s\n",
      "\t\t\t\tDisc: 0.012058\t\tSym: 0.000000\t\tSpars: 0.000956\n",
      "\t TVw: 0.765102 | TVb: 2.283580 | GSw: -0.572784 | GSb: -0.239225 | TSUw: -0.418796 | TSUb: -0.035667\n",
      "Validating epoch 5541...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012890232770740844\n",
      "Average validation loss: 0.013399240850699634\n",
      "Training epoch 5542...\n",
      "\n",
      "Train Epoch: 5542 [0/8000 (0%)]\tBatch Loss: 0.013259\tLearning Rate (w_theta): 0.001000\t TIME:1930.5s\n",
      "\t\t\t\tDisc: 0.012324\t\tSym: 0.000000\t\tSpars: 0.000935\n",
      "\t TVw: 0.765255 | TVb: 2.283622 | GSw: -0.572626 | GSb: -0.239020 | TSUw: -0.419244 | TSUb: -0.036053\n",
      "\n",
      "Train Epoch: 5542 [4000/8000 (50%)]\tBatch Loss: 0.013163\tLearning Rate (w_theta): 0.001000\t TIME:1931.8s\n",
      "\t\t\t\tDisc: 0.012241\t\tSym: 0.000000\t\tSpars: 0.000922\n",
      "\t TVw: 0.765239 | TVb: 2.283643 | GSw: -0.572441 | GSb: -0.238786 | TSUw: -0.419300 | TSUb: -0.036076\n",
      "Validating epoch 5542...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012889696337770724\n",
      "Average validation loss: 0.013398910869069037\n",
      "Training epoch 5543...\n",
      "\n",
      "Train Epoch: 5543 [0/8000 (0%)]\tBatch Loss: 0.013240\tLearning Rate (w_theta): 0.001000\t TIME:1934.0s\n",
      "\t\t\t\tDisc: 0.012246\t\tSym: 0.000000\t\tSpars: 0.000994\n",
      "\t TVw: 0.765234 | TVb: 2.283588 | GSw: -0.572238 | GSb: -0.238532 | TSUw: -0.419104 | TSUb: -0.035866\n",
      "\n",
      "Train Epoch: 5543 [4000/8000 (50%)]\tBatch Loss: 0.012704\tLearning Rate (w_theta): 0.001000\t TIME:1935.3s\n",
      "\t\t\t\tDisc: 0.011913\t\tSym: 0.000000\t\tSpars: 0.000790\n",
      "\t TVw: 0.765620 | TVb: 2.283653 | GSw: -0.572054 | GSb: -0.238299 | TSUw: -0.419188 | TSUb: -0.035915\n",
      "Validating epoch 5543...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012889432351196438\n",
      "Average validation loss: 0.013398188869845565\n",
      "Training epoch 5544...\n",
      "\n",
      "Train Epoch: 5544 [0/8000 (0%)]\tBatch Loss: 0.013176\tLearning Rate (w_theta): 0.001000\t TIME:1937.5s\n",
      "\t\t\t\tDisc: 0.012221\t\tSym: 0.000000\t\tSpars: 0.000956\n",
      "\t TVw: 0.765448 | TVb: 2.283578 | GSw: -0.571837 | GSb: -0.238029 | TSUw: -0.418777 | TSUb: -0.035505\n",
      "\n",
      "Train Epoch: 5544 [4000/8000 (50%)]\tBatch Loss: 0.012592\tLearning Rate (w_theta): 0.001000\t TIME:1938.8s\n",
      "\t\t\t\tDisc: 0.011893\t\tSym: 0.000000\t\tSpars: 0.000699\n",
      "\t TVw: 0.765399 | TVb: 2.283522 | GSw: -0.571644 | GSb: -0.237787 | TSUw: -0.418718 | TSUb: -0.035423\n",
      "Validating epoch 5544...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01289086882034257\n",
      "Average validation loss: 0.013399848956257957\n",
      "Training epoch 5545...\n",
      "\n",
      "Train Epoch: 5545 [0/8000 (0%)]\tBatch Loss: 0.013823\tLearning Rate (w_theta): 0.001000\t TIME:1941.0s\n",
      "\t\t\t\tDisc: 0.012852\t\tSym: 0.000000\t\tSpars: 0.000971\n",
      "\t TVw: 0.765388 | TVb: 2.283564 | GSw: -0.571504 | GSb: -0.237603 | TSUw: -0.419447 | TSUb: -0.036069\n",
      "\n",
      "Train Epoch: 5545 [4000/8000 (50%)]\tBatch Loss: 0.012236\tLearning Rate (w_theta): 0.001000\t TIME:1942.3s\n",
      "\t\t\t\tDisc: 0.011413\t\tSym: 0.000000\t\tSpars: 0.000822\n",
      "\t TVw: 0.765163 | TVb: 2.283498 | GSw: -0.571310 | GSb: -0.237360 | TSUw: -0.419324 | TSUb: -0.035928\n",
      "Validating epoch 5545...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012889724309529461\n",
      "Average validation loss: 0.013399677926318788\n",
      "Training epoch 5546...\n",
      "\n",
      "Train Epoch: 5546 [0/8000 (0%)]\tBatch Loss: 0.012514\tLearning Rate (w_theta): 0.001000\t TIME:1944.6s\n",
      "\t\t\t\tDisc: 0.011991\t\tSym: 0.000000\t\tSpars: 0.000523\n",
      "\t TVw: 0.764766 | TVb: 2.283385 | GSw: -0.571100 | GSb: -0.237099 | TSUw: -0.419022 | TSUb: -0.035619\n",
      "\n",
      "Train Epoch: 5546 [4000/8000 (50%)]\tBatch Loss: 0.013184\tLearning Rate (w_theta): 0.001000\t TIME:1945.9s\n",
      "\t\t\t\tDisc: 0.012434\t\tSym: 0.000000\t\tSpars: 0.000750\n",
      "\t TVw: 0.764078 | TVb: 2.283164 | GSw: -0.570893 | GSb: -0.236840 | TSUw: -0.418771 | TSUb: -0.035357\n",
      "Validating epoch 5546...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012892794989558675\n",
      "Average validation loss: 0.013401561577847377\n",
      "Training epoch 5547...\n",
      "\n",
      "Train Epoch: 5547 [0/8000 (0%)]\tBatch Loss: 0.012779\tLearning Rate (w_theta): 0.001000\t TIME:1948.2s\n",
      "\t\t\t\tDisc: 0.012042\t\tSym: 0.000000\t\tSpars: 0.000738\n",
      "\t TVw: 0.764298 | TVb: 2.283291 | GSw: -0.570774 | GSb: -0.236680 | TSUw: -0.419766 | TSUb: -0.036253\n",
      "\n",
      "Train Epoch: 5547 [4000/8000 (50%)]\tBatch Loss: 0.012589\tLearning Rate (w_theta): 0.001000\t TIME:1949.4s\n",
      "\t\t\t\tDisc: 0.011776\t\tSym: 0.000000\t\tSpars: 0.000813\n",
      "\t TVw: 0.764294 | TVb: 2.283251 | GSw: -0.570564 | GSb: -0.236415 | TSUw: -0.419415 | TSUb: -0.035898\n",
      "Validating epoch 5547...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012891426891878006\n",
      "Average validation loss: 0.013400727268966848\n",
      "Training epoch 5548...\n",
      "\n",
      "Train Epoch: 5548 [0/8000 (0%)]\tBatch Loss: 0.013012\tLearning Rate (w_theta): 0.001000\t TIME:1951.6s\n",
      "\t\t\t\tDisc: 0.012208\t\tSym: 0.000000\t\tSpars: 0.000804\n",
      "\t TVw: 0.764424 | TVb: 2.283271 | GSw: -0.570377 | GSb: -0.236182 | TSUw: -0.419441 | TSUb: -0.035894\n",
      "\n",
      "Train Epoch: 5548 [4000/8000 (50%)]\tBatch Loss: 0.012390\tLearning Rate (w_theta): 0.001000\t TIME:1952.9s\n",
      "\t\t\t\tDisc: 0.011959\t\tSym: 0.000000\t\tSpars: 0.000431\n",
      "\t TVw: 0.764600 | TVb: 2.283364 | GSw: -0.570143 | GSb: -0.235896 | TSUw: -0.418793 | TSUb: -0.035263\n",
      "Validating epoch 5548...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012892329639741207\n",
      "Average validation loss: 0.013398935961434252\n",
      "Training epoch 5549...\n",
      "\n",
      "Train Epoch: 5549 [0/8000 (0%)]\tBatch Loss: 0.012565\tLearning Rate (w_theta): 0.001000\t TIME:1955.2s\n",
      "\t\t\t\tDisc: 0.012026\t\tSym: 0.000000\t\tSpars: 0.000539\n",
      "\t TVw: 0.764389 | TVb: 2.283335 | GSw: -0.569993 | GSb: -0.235701 | TSUw: -0.419353 | TSUb: -0.035757\n",
      "\n",
      "Train Epoch: 5549 [4000/8000 (50%)]\tBatch Loss: 0.012553\tLearning Rate (w_theta): 0.001000\t TIME:1956.5s\n",
      "\t\t\t\tDisc: 0.011995\t\tSym: 0.000000\t\tSpars: 0.000558\n",
      "\t TVw: 0.764436 | TVb: 2.283429 | GSw: -0.569888 | GSb: -0.235554 | TSUw: -0.420564 | TSUb: -0.036857\n",
      "Validating epoch 5549...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012892990824514648\n",
      "Average validation loss: 0.013402556028711932\n",
      "Training epoch 5550...\n",
      "\n",
      "Train Epoch: 5550 [0/8000 (0%)]\tBatch Loss: 0.012920\tLearning Rate (w_theta): 0.001000\t TIME:1958.7s\n",
      "\t\t\t\tDisc: 0.012005\t\tSym: 0.000000\t\tSpars: 0.000914\n",
      "\t TVw: 0.764272 | TVb: 2.283349 | GSw: -0.569667 | GSb: -0.235282 | TSUw: -0.420000 | TSUb: -0.036300\n",
      "\n",
      "Train Epoch: 5550 [4000/8000 (50%)]\tBatch Loss: 0.012785\tLearning Rate (w_theta): 0.001000\t TIME:1960.0s\n",
      "\t\t\t\tDisc: 0.012190\t\tSym: 0.000000\t\tSpars: 0.000595\n",
      "\t TVw: 0.764837 | TVb: 2.283533 | GSw: -0.569481 | GSb: -0.235053 | TSUw: -0.419996 | TSUb: -0.036265\n",
      "Validating epoch 5550...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012890484121792946\n",
      "Average validation loss: 0.01339824952167635\n",
      "Training epoch 5551...\n",
      "\n",
      "Train Epoch: 5551 [0/8000 (0%)]\tBatch Loss: 0.012569\tLearning Rate (w_theta): 0.001000\t TIME:1963.0s\n",
      "\t\t\t\tDisc: 0.011903\t\tSym: 0.000000\t\tSpars: 0.000666\n",
      "\t TVw: 0.764850 | TVb: 2.283455 | GSw: -0.569214 | GSb: -0.234732 | TSUw: -0.418835 | TSUb: -0.035152\n",
      "\n",
      "Train Epoch: 5551 [4000/8000 (50%)]\tBatch Loss: 0.012941\tLearning Rate (w_theta): 0.001000\t TIME:1964.3s\n",
      "\t\t\t\tDisc: 0.012157\t\tSym: 0.000000\t\tSpars: 0.000784\n",
      "\t TVw: 0.765071 | TVb: 2.283508 | GSw: -0.569044 | GSb: -0.234513 | TSUw: -0.419069 | TSUb: -0.035342\n",
      "Validating epoch 5551...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012891491035717018\n",
      "Average validation loss: 0.01339938534425803\n",
      "Training epoch 5552...\n",
      "\n",
      "Train Epoch: 5552 [0/8000 (0%)]\tBatch Loss: 0.013099\tLearning Rate (w_theta): 0.001000\t TIME:1966.6s\n",
      "\t\t\t\tDisc: 0.012286\t\tSym: 0.000000\t\tSpars: 0.000812\n",
      "\t TVw: 0.764900 | TVb: 2.283490 | GSw: -0.568905 | GSb: -0.234332 | TSUw: -0.419769 | TSUb: -0.035968\n",
      "\n",
      "Train Epoch: 5552 [4000/8000 (50%)]\tBatch Loss: 0.013086\tLearning Rate (w_theta): 0.001000\t TIME:1967.9s\n",
      "\t\t\t\tDisc: 0.012342\t\tSym: 0.000000\t\tSpars: 0.000744\n",
      "\t TVw: 0.764779 | TVb: 2.283465 | GSw: -0.568720 | GSb: -0.234102 | TSUw: -0.419819 | TSUb: -0.035986\n",
      "Validating epoch 5552...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012890569877130002\n",
      "Average validation loss: 0.013399884580323419\n",
      "Training epoch 5553...\n",
      "\n",
      "Train Epoch: 5553 [0/8000 (0%)]\tBatch Loss: 0.012692\tLearning Rate (w_theta): 0.001000\t TIME:1970.0s\n",
      "\t\t\t\tDisc: 0.012007\t\tSym: 0.000000\t\tSpars: 0.000685\n",
      "\t TVw: 0.764513 | TVb: 2.283357 | GSw: -0.568526 | GSb: -0.233861 | TSUw: -0.419758 | TSUb: -0.035902\n",
      "\n",
      "Train Epoch: 5553 [4000/8000 (50%)]\tBatch Loss: 0.013021\tLearning Rate (w_theta): 0.001000\t TIME:1971.3s\n",
      "\t\t\t\tDisc: 0.012346\t\tSym: 0.000000\t\tSpars: 0.000675\n",
      "\t TVw: 0.764216 | TVb: 2.283316 | GSw: -0.568316 | GSb: -0.233602 | TSUw: -0.419475 | TSUb: -0.035609\n",
      "Validating epoch 5553...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012891525851679454\n",
      "Average validation loss: 0.013400970038952026\n",
      "Training epoch 5554...\n",
      "\n",
      "Train Epoch: 5554 [0/8000 (0%)]\tBatch Loss: 0.013065\tLearning Rate (w_theta): 0.001000\t TIME:1973.6s\n",
      "\t\t\t\tDisc: 0.012205\t\tSym: 0.000000\t\tSpars: 0.000860\n",
      "\t TVw: 0.764260 | TVb: 2.283283 | GSw: -0.568178 | GSb: -0.233420 | TSUw: -0.420259 | TSUb: -0.036315\n",
      "\n",
      "Train Epoch: 5554 [4000/8000 (50%)]\tBatch Loss: 0.012961\tLearning Rate (w_theta): 0.001000\t TIME:1974.9s\n",
      "\t\t\t\tDisc: 0.011933\t\tSym: 0.000000\t\tSpars: 0.001028\n",
      "\t TVw: 0.765074 | TVb: 2.283471 | GSw: -0.568020 | GSb: -0.233220 | TSUw: -0.420728 | TSUb: -0.036727\n",
      "Validating epoch 5554...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012891760270965719\n",
      "Average validation loss: 0.013400834902110245\n",
      "Training epoch 5555...\n",
      "\n",
      "Train Epoch: 5555 [0/8000 (0%)]\tBatch Loss: 0.013080\tLearning Rate (w_theta): 0.001000\t TIME:1977.2s\n",
      "\t\t\t\tDisc: 0.012131\t\tSym: 0.000000\t\tSpars: 0.000949\n",
      "\t TVw: 0.764854 | TVb: 2.283344 | GSw: -0.567783 | GSb: -0.232929 | TSUw: -0.420020 | TSUb: -0.036034\n",
      "\n",
      "Train Epoch: 5555 [4000/8000 (50%)]\tBatch Loss: 0.012034\tLearning Rate (w_theta): 0.001000\t TIME:1978.4s\n",
      "\t\t\t\tDisc: 0.011222\t\tSym: 0.000000\t\tSpars: 0.000812\n",
      "\t TVw: 0.764394 | TVb: 2.283177 | GSw: -0.567581 | GSb: -0.232680 | TSUw: -0.419863 | TSUb: -0.035855\n",
      "Validating epoch 5555...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012890596885737102\n",
      "Average validation loss: 0.013399577149918625\n",
      "Training epoch 5556...\n",
      "\n",
      "Train Epoch: 5556 [0/8000 (0%)]\tBatch Loss: 0.013035\tLearning Rate (w_theta): 0.001000\t TIME:1980.7s\n",
      "\t\t\t\tDisc: 0.011920\t\tSym: 0.000000\t\tSpars: 0.001115\n",
      "\t TVw: 0.764499 | TVb: 2.283150 | GSw: -0.567353 | GSb: -0.232401 | TSUw: -0.419324 | TSUb: -0.035323\n",
      "\n",
      "Train Epoch: 5556 [4000/8000 (50%)]\tBatch Loss: 0.012679\tLearning Rate (w_theta): 0.001000\t TIME:1982.0s\n",
      "\t\t\t\tDisc: 0.012096\t\tSym: 0.000000\t\tSpars: 0.000583\n",
      "\t TVw: 0.765113 | TVb: 2.283345 | GSw: -0.567202 | GSb: -0.232206 | TSUw: -0.419929 | TSUb: -0.035864\n",
      "Validating epoch 5556...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012892233127789567\n",
      "Average validation loss: 0.013400363906688095\n",
      "Training epoch 5557...\n",
      "\n",
      "Train Epoch: 5557 [0/8000 (0%)]\tBatch Loss: 0.012590\tLearning Rate (w_theta): 0.001000\t TIME:1984.2s\n",
      "\t\t\t\tDisc: 0.012148\t\tSym: 0.000000\t\tSpars: 0.000442\n",
      "\t TVw: 0.764824 | TVb: 2.283240 | GSw: -0.567025 | GSb: -0.231985 | TSUw: -0.420121 | TSUb: -0.036016\n",
      "\n",
      "Train Epoch: 5557 [4000/8000 (50%)]\tBatch Loss: 0.012468\tLearning Rate (w_theta): 0.001000\t TIME:1985.5s\n",
      "\t\t\t\tDisc: 0.011666\t\tSym: 0.000000\t\tSpars: 0.000802\n",
      "\t TVw: 0.764664 | TVb: 2.283160 | GSw: -0.566836 | GSb: -0.231753 | TSUw: -0.420130 | TSUb: -0.035997\n",
      "Validating epoch 5557...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012891279159085643\n",
      "Average validation loss: 0.013401083225836614\n",
      "Training epoch 5558...\n",
      "\n",
      "Train Epoch: 5558 [0/8000 (0%)]\tBatch Loss: 0.012605\tLearning Rate (w_theta): 0.001000\t TIME:1987.7s\n",
      "\t\t\t\tDisc: 0.011789\t\tSym: 0.000000\t\tSpars: 0.000817\n",
      "\t TVw: 0.764588 | TVb: 2.283130 | GSw: -0.566648 | GSb: -0.231518 | TSUw: -0.420182 | TSUb: -0.036018\n",
      "\n",
      "Train Epoch: 5558 [4000/8000 (50%)]\tBatch Loss: 0.013121\tLearning Rate (w_theta): 0.001000\t TIME:1989.0s\n",
      "\t\t\t\tDisc: 0.012262\t\tSym: 0.000000\t\tSpars: 0.000859\n",
      "\t TVw: 0.764441 | TVb: 2.283053 | GSw: -0.566404 | GSb: -0.231222 | TSUw: -0.419443 | TSUb: -0.035297\n",
      "Validating epoch 5558...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012893395377885235\n",
      "Average validation loss: 0.013400799671275523\n",
      "Training epoch 5559...\n",
      "\n",
      "Train Epoch: 5559 [0/8000 (0%)]\tBatch Loss: 0.012432\tLearning Rate (w_theta): 0.001000\t TIME:1991.2s\n",
      "\t\t\t\tDisc: 0.011801\t\tSym: 0.000000\t\tSpars: 0.000630\n",
      "\t TVw: 0.764398 | TVb: 2.283077 | GSw: -0.566275 | GSb: -0.231047 | TSUw: -0.420296 | TSUb: -0.036071\n",
      "\n",
      "Train Epoch: 5559 [4000/8000 (50%)]\tBatch Loss: 0.012691\tLearning Rate (w_theta): 0.001000\t TIME:1992.5s\n",
      "\t\t\t\tDisc: 0.011895\t\tSym: 0.000000\t\tSpars: 0.000796\n",
      "\t TVw: 0.764122 | TVb: 2.282963 | GSw: -0.566098 | GSb: -0.230821 | TSUw: -0.420460 | TSUb: -0.036198\n",
      "Validating epoch 5559...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012891527548629694\n",
      "Average validation loss: 0.013403044189082109\n",
      "Training epoch 5560...\n",
      "\n",
      "Train Epoch: 5560 [0/8000 (0%)]\tBatch Loss: 0.012932\tLearning Rate (w_theta): 0.001000\t TIME:1994.8s\n",
      "\t\t\t\tDisc: 0.012255\t\tSym: 0.000000\t\tSpars: 0.000676\n",
      "\t TVw: 0.764111 | TVb: 2.282957 | GSw: -0.565910 | GSb: -0.230587 | TSUw: -0.420519 | TSUb: -0.036226\n",
      "\n",
      "Train Epoch: 5560 [4000/8000 (50%)]\tBatch Loss: 0.012605\tLearning Rate (w_theta): 0.001000\t TIME:1996.1s\n",
      "\t\t\t\tDisc: 0.011476\t\tSym: 0.000000\t\tSpars: 0.001129\n",
      "\t TVw: 0.763973 | TVb: 2.282987 | GSw: -0.565696 | GSb: -0.230326 | TSUw: -0.420209 | TSUb: -0.035905\n",
      "Validating epoch 5560...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012893056148286342\n",
      "Average validation loss: 0.013401759108813858\n",
      "Training epoch 5561...\n",
      "\n",
      "Train Epoch: 5561 [0/8000 (0%)]\tBatch Loss: 0.013263\tLearning Rate (w_theta): 0.001000\t TIME:1998.9s\n",
      "\t\t\t\tDisc: 0.012333\t\tSym: 0.000000\t\tSpars: 0.000930\n",
      "\t TVw: 0.764492 | TVb: 2.283156 | GSw: -0.565535 | GSb: -0.230123 | TSUw: -0.420674 | TSUb: -0.036317\n",
      "\n",
      "Train Epoch: 5561 [4000/8000 (50%)]\tBatch Loss: 0.013017\tLearning Rate (w_theta): 0.001000\t TIME:2000.3s\n",
      "\t\t\t\tDisc: 0.012028\t\tSym: 0.000000\t\tSpars: 0.000989\n",
      "\t TVw: 0.764587 | TVb: 2.283182 | GSw: -0.565376 | GSb: -0.229922 | TSUw: -0.421175 | TSUb: -0.036761\n",
      "Validating epoch 5561...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012892222295404184\n",
      "Average validation loss: 0.013401117659694286\n",
      "Training epoch 5562...\n",
      "\n",
      "Train Epoch: 5562 [0/8000 (0%)]\tBatch Loss: 0.012289\tLearning Rate (w_theta): 0.001000\t TIME:2002.5s\n",
      "\t\t\t\tDisc: 0.011683\t\tSym: 0.000000\t\tSpars: 0.000606\n",
      "\t TVw: 0.764704 | TVb: 2.283157 | GSw: -0.565125 | GSb: -0.229617 | TSUw: -0.420319 | TSUb: -0.035926\n",
      "\n",
      "Train Epoch: 5562 [4000/8000 (50%)]\tBatch Loss: 0.012346\tLearning Rate (w_theta): 0.001000\t TIME:2003.7s\n",
      "\t\t\t\tDisc: 0.011645\t\tSym: 0.000000\t\tSpars: 0.000701\n",
      "\t TVw: 0.763649 | TVb: 2.282778 | GSw: -0.564843 | GSb: -0.229277 | TSUw: -0.419024 | TSUb: -0.034674\n",
      "Validating epoch 5562...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01289755460186409\n",
      "Average validation loss: 0.013400842189713371\n",
      "Training epoch 5563...\n",
      "\n",
      "Train Epoch: 5563 [0/8000 (0%)]\tBatch Loss: 0.012869\tLearning Rate (w_theta): 0.001000\t TIME:2005.9s\n",
      "\t\t\t\tDisc: 0.012129\t\tSym: 0.000000\t\tSpars: 0.000740\n",
      "\t TVw: 0.763773 | TVb: 2.282848 | GSw: -0.564767 | GSb: -0.229168 | TSUw: -0.420487 | TSUb: -0.036027\n",
      "\n",
      "Train Epoch: 5563 [4000/8000 (50%)]\tBatch Loss: 0.012979\tLearning Rate (w_theta): 0.001000\t TIME:2007.2s\n",
      "\t\t\t\tDisc: 0.012033\t\tSym: 0.000000\t\tSpars: 0.000947\n",
      "\t TVw: 0.764560 | TVb: 2.283197 | GSw: -0.564699 | GSb: -0.229063 | TSUw: -0.422098 | TSUb: -0.037521\n",
      "Validating epoch 5563...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01289627301513745\n",
      "Average validation loss: 0.013408411366745593\n",
      "Training epoch 5564...\n",
      "\n",
      "Train Epoch: 5564 [0/8000 (0%)]\tBatch Loss: 0.013436\tLearning Rate (w_theta): 0.001000\t TIME:2009.5s\n",
      "\t\t\t\tDisc: 0.012782\t\tSym: 0.000000\t\tSpars: 0.000654\n",
      "\t TVw: 0.764774 | TVb: 2.283198 | GSw: -0.564478 | GSb: -0.228795 | TSUw: -0.421457 | TSUb: -0.036883\n",
      "\n",
      "Train Epoch: 5564 [4000/8000 (50%)]\tBatch Loss: 0.012319\tLearning Rate (w_theta): 0.001000\t TIME:2010.7s\n",
      "\t\t\t\tDisc: 0.011458\t\tSym: 0.000000\t\tSpars: 0.000861\n",
      "\t TVw: 0.765017 | TVb: 2.283110 | GSw: -0.564198 | GSb: -0.228467 | TSUw: -0.420006 | TSUb: -0.035480\n",
      "Validating epoch 5564...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012891245826083279\n",
      "Average validation loss: 0.013399224199570667\n",
      "Training epoch 5565...\n",
      "\n",
      "Train Epoch: 5565 [0/8000 (0%)]\tBatch Loss: 0.012851\tLearning Rate (w_theta): 0.001000\t TIME:2012.9s\n",
      "\t\t\t\tDisc: 0.012319\t\tSym: 0.000000\t\tSpars: 0.000532\n",
      "\t TVw: 0.764945 | TVb: 2.283043 | GSw: -0.563983 | GSb: -0.228203 | TSUw: -0.419541 | TSUb: -0.035010\n",
      "\n",
      "Train Epoch: 5565 [4000/8000 (50%)]\tBatch Loss: 0.012449\tLearning Rate (w_theta): 0.001000\t TIME:2014.2s\n",
      "\t\t\t\tDisc: 0.011729\t\tSym: 0.000000\t\tSpars: 0.000719\n",
      "\t TVw: 0.764245 | TVb: 2.282922 | GSw: -0.563843 | GSb: -0.228030 | TSUw: -0.420104 | TSUb: -0.035513\n",
      "Validating epoch 5565...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012895251110257522\n",
      "Average validation loss: 0.013404294587860776\n",
      "Training epoch 5566...\n",
      "\n",
      "Train Epoch: 5566 [0/8000 (0%)]\tBatch Loss: 0.013121\tLearning Rate (w_theta): 0.001000\t TIME:2016.5s\n",
      "\t\t\t\tDisc: 0.012243\t\tSym: 0.000000\t\tSpars: 0.000878\n",
      "\t TVw: 0.764415 | TVb: 2.283011 | GSw: -0.563763 | GSb: -0.227915 | TSUw: -0.421530 | TSUb: -0.036835\n",
      "\n",
      "Train Epoch: 5566 [4000/8000 (50%)]\tBatch Loss: 0.012903\tLearning Rate (w_theta): 0.001000\t TIME:2017.8s\n",
      "\t\t\t\tDisc: 0.012101\t\tSym: 0.000000\t\tSpars: 0.000802\n",
      "\t TVw: 0.764866 | TVb: 2.283158 | GSw: -0.563584 | GSb: -0.227691 | TSUw: -0.421578 | TSUb: -0.036853\n",
      "Validating epoch 5566...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012892524384262092\n",
      "Average validation loss: 0.01340149581752885\n",
      "Training epoch 5567...\n",
      "\n",
      "Train Epoch: 5567 [0/8000 (0%)]\tBatch Loss: 0.013578\tLearning Rate (w_theta): 0.001000\t TIME:2020.0s\n",
      "\t\t\t\tDisc: 0.012773\t\tSym: 0.000000\t\tSpars: 0.000805\n",
      "\t TVw: 0.765154 | TVb: 2.283190 | GSw: -0.563314 | GSb: -0.227367 | TSUw: -0.420406 | TSUb: -0.035713\n",
      "\n",
      "Train Epoch: 5567 [4000/8000 (50%)]\tBatch Loss: 0.012206\tLearning Rate (w_theta): 0.001000\t TIME:2021.2s\n",
      "\t\t\t\tDisc: 0.011458\t\tSym: 0.000000\t\tSpars: 0.000748\n",
      "\t TVw: 0.765230 | TVb: 2.283198 | GSw: -0.563090 | GSb: -0.227094 | TSUw: -0.419837 | TSUb: -0.035146\n",
      "Validating epoch 5567...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012894460998275653\n",
      "Average validation loss: 0.013400125773173224\n",
      "Training epoch 5568...\n",
      "\n",
      "Train Epoch: 5568 [0/8000 (0%)]\tBatch Loss: 0.013129\tLearning Rate (w_theta): 0.001000\t TIME:2023.5s\n",
      "\t\t\t\tDisc: 0.012298\t\tSym: 0.000000\t\tSpars: 0.000831\n",
      "\t TVw: 0.765123 | TVb: 2.283173 | GSw: -0.562977 | GSb: -0.226945 | TSUw: -0.420811 | TSUb: -0.036041\n",
      "\n",
      "Train Epoch: 5568 [4000/8000 (50%)]\tBatch Loss: 0.013134\tLearning Rate (w_theta): 0.001000\t TIME:2024.8s\n",
      "\t\t\t\tDisc: 0.012060\t\tSym: 0.000000\t\tSpars: 0.001073\n",
      "\t TVw: 0.765130 | TVb: 2.283217 | GSw: -0.562838 | GSb: -0.226767 | TSUw: -0.421467 | TSUb: -0.036636\n",
      "Validating epoch 5568...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012891693071668126\n",
      "Average validation loss: 0.013402056788075812\n",
      "Training epoch 5569...\n",
      "\n",
      "Train Epoch: 5569 [0/8000 (0%)]\tBatch Loss: 0.013407\tLearning Rate (w_theta): 0.001000\t TIME:2027.0s\n",
      "\t\t\t\tDisc: 0.012242\t\tSym: 0.000000\t\tSpars: 0.001166\n",
      "\t TVw: 0.765117 | TVb: 2.283150 | GSw: -0.562634 | GSb: -0.226514 | TSUw: -0.421253 | TSUb: -0.036405\n",
      "\n",
      "Train Epoch: 5569 [4000/8000 (50%)]\tBatch Loss: 0.012661\tLearning Rate (w_theta): 0.001000\t TIME:2028.3s\n",
      "\t\t\t\tDisc: 0.012010\t\tSym: 0.000000\t\tSpars: 0.000650\n",
      "\t TVw: 0.765297 | TVb: 2.283100 | GSw: -0.562445 | GSb: -0.226282 | TSUw: -0.421306 | TSUb: -0.036427\n",
      "Validating epoch 5569...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012891236668130437\n",
      "Average validation loss: 0.013400434429239981\n",
      "Training epoch 5570...\n",
      "\n",
      "Train Epoch: 5570 [0/8000 (0%)]\tBatch Loss: 0.013062\tLearning Rate (w_theta): 0.001000\t TIME:2030.5s\n",
      "\t\t\t\tDisc: 0.012168\t\tSym: 0.000000\t\tSpars: 0.000895\n",
      "\t TVw: 0.765323 | TVb: 2.283021 | GSw: -0.562202 | GSb: -0.225989 | TSUw: -0.420616 | TSUb: -0.035745\n",
      "\n",
      "Train Epoch: 5570 [4000/8000 (50%)]\tBatch Loss: 0.012688\tLearning Rate (w_theta): 0.001000\t TIME:2031.8s\n",
      "\t\t\t\tDisc: 0.011867\t\tSym: 0.000000\t\tSpars: 0.000821\n",
      "\t TVw: 0.765393 | TVb: 2.282925 | GSw: -0.561972 | GSb: -0.225706 | TSUw: -0.420110 | TSUb: -0.035239\n",
      "Validating epoch 5570...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012893504245621745\n",
      "Average validation loss: 0.013400613997901475\n",
      "Training epoch 5571...\n",
      "\n",
      "Train Epoch: 5571 [0/8000 (0%)]\tBatch Loss: 0.012780\tLearning Rate (w_theta): 0.001000\t TIME:2034.7s\n",
      "\t\t\t\tDisc: 0.012075\t\tSym: 0.000000\t\tSpars: 0.000705\n",
      "\t TVw: 0.765409 | TVb: 2.283006 | GSw: -0.561859 | GSb: -0.225556 | TSUw: -0.421144 | TSUb: -0.036195\n",
      "\n",
      "Train Epoch: 5571 [4000/8000 (50%)]\tBatch Loss: 0.013085\tLearning Rate (w_theta): 0.001000\t TIME:2036.0s\n",
      "\t\t\t\tDisc: 0.012122\t\tSym: 0.000000\t\tSpars: 0.000963\n",
      "\t TVw: 0.765571 | TVb: 2.283149 | GSw: -0.561766 | GSb: -0.225429 | TSUw: -0.422513 | TSUb: -0.037469\n",
      "Validating epoch 5571...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01289545577504498\n",
      "Average validation loss: 0.013405508598217455\n",
      "Training epoch 5572...\n",
      "\n",
      "Train Epoch: 5572 [0/8000 (0%)]\tBatch Loss: 0.012535\tLearning Rate (w_theta): 0.001000\t TIME:2038.1s\n",
      "\t\t\t\tDisc: 0.011671\t\tSym: 0.000000\t\tSpars: 0.000864\n",
      "\t TVw: 0.765496 | TVb: 2.283039 | GSw: -0.561507 | GSb: -0.225123 | TSUw: -0.421456 | TSUb: -0.036432\n",
      "\n",
      "Train Epoch: 5572 [4000/8000 (50%)]\tBatch Loss: 0.012603\tLearning Rate (w_theta): 0.001000\t TIME:2039.4s\n",
      "\t\t\t\tDisc: 0.012049\t\tSym: 0.000000\t\tSpars: 0.000553\n",
      "\t TVw: 0.765001 | TVb: 2.282705 | GSw: -0.561231 | GSb: -0.224794 | TSUw: -0.420171 | TSUb: -0.035179\n",
      "Validating epoch 5572...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012893026020755507\n",
      "Average validation loss: 0.013401115572520765\n",
      "Training epoch 5573...\n",
      "\n",
      "Train Epoch: 5573 [0/8000 (0%)]\tBatch Loss: 0.013331\tLearning Rate (w_theta): 0.001000\t TIME:2041.7s\n",
      "\t\t\t\tDisc: 0.012329\t\tSym: 0.000000\t\tSpars: 0.001002\n",
      "\t TVw: 0.764924 | TVb: 2.282680 | GSw: -0.561052 | GSb: -0.224571 | TSUw: -0.420223 | TSUb: -0.035201\n",
      "\n",
      "Train Epoch: 5573 [4000/8000 (50%)]\tBatch Loss: 0.013503\tLearning Rate (w_theta): 0.001000\t TIME:2043.0s\n",
      "\t\t\t\tDisc: 0.012417\t\tSym: 0.000000\t\tSpars: 0.001086\n",
      "\t TVw: 0.765131 | TVb: 2.282866 | GSw: -0.560948 | GSb: -0.224432 | TSUw: -0.421346 | TSUb: -0.036244\n",
      "Validating epoch 5573...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012895203861899697\n",
      "Average validation loss: 0.013408014768317733\n",
      "Training epoch 5574...\n",
      "\n",
      "Train Epoch: 5574 [0/8000 (0%)]\tBatch Loss: 0.013208\tLearning Rate (w_theta): 0.001000\t TIME:2045.2s\n",
      "\t\t\t\tDisc: 0.012459\t\tSym: 0.000000\t\tSpars: 0.000749\n",
      "\t TVw: 0.765165 | TVb: 2.282935 | GSw: -0.560834 | GSb: -0.224282 | TSUw: -0.422275 | TSUb: -0.037101\n",
      "\n",
      "Train Epoch: 5574 [4000/8000 (50%)]\tBatch Loss: 0.013259\tLearning Rate (w_theta): 0.001000\t TIME:2046.4s\n",
      "\t\t\t\tDisc: 0.012333\t\tSym: 0.000000\t\tSpars: 0.000926\n",
      "\t TVw: 0.765312 | TVb: 2.282870 | GSw: -0.560611 | GSb: -0.224016 | TSUw: -0.421719 | TSUb: -0.036541\n",
      "Validating epoch 5574...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012892408044623587\n",
      "Average validation loss: 0.013400578196342173\n",
      "Training epoch 5575...\n",
      "\n",
      "Train Epoch: 5575 [0/8000 (0%)]\tBatch Loss: 0.012565\tLearning Rate (w_theta): 0.001000\t TIME:2048.7s\n",
      "\t\t\t\tDisc: 0.011903\t\tSym: 0.000000\t\tSpars: 0.000663\n",
      "\t TVw: 0.765325 | TVb: 2.282805 | GSw: -0.560346 | GSb: -0.223700 | TSUw: -0.420663 | TSUb: -0.035506\n",
      "\n",
      "Train Epoch: 5575 [4000/8000 (50%)]\tBatch Loss: 0.013470\tLearning Rate (w_theta): 0.001000\t TIME:2050.0s\n",
      "\t\t\t\tDisc: 0.012369\t\tSym: 0.000000\t\tSpars: 0.001101\n",
      "\t TVw: 0.764455 | TVb: 2.282485 | GSw: -0.560189 | GSb: -0.223504 | TSUw: -0.421057 | TSUb: -0.035853\n",
      "Validating epoch 5575...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012896033344731208\n",
      "Average validation loss: 0.013403749028805072\n",
      "Training epoch 5576...\n",
      "\n",
      "Train Epoch: 5576 [0/8000 (0%)]\tBatch Loss: 0.012938\tLearning Rate (w_theta): 0.001000\t TIME:2052.2s\n",
      "\t\t\t\tDisc: 0.012143\t\tSym: 0.000000\t\tSpars: 0.000794\n",
      "\t TVw: 0.764679 | TVb: 2.282540 | GSw: -0.560026 | GSb: -0.223301 | TSUw: -0.421373 | TSUb: -0.036128\n",
      "\n",
      "Train Epoch: 5576 [4000/8000 (50%)]\tBatch Loss: 0.012687\tLearning Rate (w_theta): 0.001000\t TIME:2053.4s\n",
      "\t\t\t\tDisc: 0.011885\t\tSym: 0.000000\t\tSpars: 0.000803\n",
      "\t TVw: 0.765153 | TVb: 2.282703 | GSw: -0.559849 | GSb: -0.223083 | TSUw: -0.421518 | TSUb: -0.036240\n",
      "Validating epoch 5576...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012893065861900298\n",
      "Average validation loss: 0.01340222247167867\n",
      "Training epoch 5577...\n",
      "\n",
      "Train Epoch: 5577 [0/8000 (0%)]\tBatch Loss: 0.013121\tLearning Rate (w_theta): 0.001000\t TIME:2055.7s\n",
      "\t\t\t\tDisc: 0.012013\t\tSym: 0.000000\t\tSpars: 0.001108\n",
      "\t TVw: 0.765337 | TVb: 2.282752 | GSw: -0.559661 | GSb: -0.222851 | TSUw: -0.421608 | TSUb: -0.036301\n",
      "\n",
      "Train Epoch: 5577 [4000/8000 (50%)]\tBatch Loss: 0.013167\tLearning Rate (w_theta): 0.001000\t TIME:2057.1s\n",
      "\t\t\t\tDisc: 0.012406\t\tSym: 0.000000\t\tSpars: 0.000760\n",
      "\t TVw: 0.765593 | TVb: 2.282843 | GSw: -0.559460 | GSb: -0.222606 | TSUw: -0.421540 | TSUb: -0.036211\n",
      "Validating epoch 5577...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012892386695385035\n",
      "Average validation loss: 0.013400956511159348\n",
      "Training epoch 5578...\n",
      "\n",
      "Train Epoch: 5578 [0/8000 (0%)]\tBatch Loss: 0.012452\tLearning Rate (w_theta): 0.001000\t TIME:2059.3s\n",
      "\t\t\t\tDisc: 0.011810\t\tSym: 0.000000\t\tSpars: 0.000642\n",
      "\t TVw: 0.765493 | TVb: 2.282809 | GSw: -0.559238 | GSb: -0.222340 | TSUw: -0.421173 | TSUb: -0.035834\n",
      "\n",
      "Train Epoch: 5578 [4000/8000 (50%)]\tBatch Loss: 0.012826\tLearning Rate (w_theta): 0.001000\t TIME:2060.5s\n",
      "\t\t\t\tDisc: 0.012044\t\tSym: 0.000000\t\tSpars: 0.000782\n",
      "\t TVw: 0.765317 | TVb: 2.282692 | GSw: -0.559092 | GSb: -0.222166 | TSUw: -0.421826 | TSUb: -0.036433\n",
      "Validating epoch 5578...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012893906032295581\n",
      "Average validation loss: 0.013403726742143043\n",
      "Training epoch 5579...\n",
      "\n",
      "Train Epoch: 5579 [0/8000 (0%)]\tBatch Loss: 0.012960\tLearning Rate (w_theta): 0.001000\t TIME:2062.8s\n",
      "\t\t\t\tDisc: 0.012221\t\tSym: 0.000000\t\tSpars: 0.000739\n",
      "\t TVw: 0.765220 | TVb: 2.282696 | GSw: -0.558888 | GSb: -0.221917 | TSUw: -0.421679 | TSUb: -0.036265\n",
      "\n",
      "Train Epoch: 5579 [4000/8000 (50%)]\tBatch Loss: 0.012275\tLearning Rate (w_theta): 0.001000\t TIME:2064.0s\n",
      "\t\t\t\tDisc: 0.011477\t\tSym: 0.000000\t\tSpars: 0.000797\n",
      "\t TVw: 0.764828 | TVb: 2.282568 | GSw: -0.558654 | GSb: -0.221638 | TSUw: -0.421141 | TSUb: -0.035724\n",
      "Validating epoch 5579...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012893926250476405\n",
      "Average validation loss: 0.013402252153270575\n",
      "Training epoch 5580...\n",
      "\n",
      "Train Epoch: 5580 [0/8000 (0%)]\tBatch Loss: 0.013229\tLearning Rate (w_theta): 0.001000\t TIME:2066.2s\n",
      "\t\t\t\tDisc: 0.012156\t\tSym: 0.000000\t\tSpars: 0.001073\n",
      "\t TVw: 0.764991 | TVb: 2.282655 | GSw: -0.558499 | GSb: -0.221438 | TSUw: -0.421654 | TSUb: -0.036191\n",
      "\n",
      "Train Epoch: 5580 [4000/8000 (50%)]\tBatch Loss: 0.013059\tLearning Rate (w_theta): 0.001000\t TIME:2067.5s\n",
      "\t\t\t\tDisc: 0.012240\t\tSym: 0.000000\t\tSpars: 0.000819\n",
      "\t TVw: 0.765223 | TVb: 2.282775 | GSw: -0.558346 | GSb: -0.221245 | TSUw: -0.422214 | TSUb: -0.036701\n",
      "Validating epoch 5580...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01289354154556479\n",
      "Average validation loss: 0.013402972150095767\n",
      "Training epoch 5581...\n",
      "\n",
      "Train Epoch: 5581 [0/8000 (0%)]\tBatch Loss: 0.012655\tLearning Rate (w_theta): 0.001000\t TIME:2070.4s\n",
      "\t\t\t\tDisc: 0.011862\t\tSym: 0.000000\t\tSpars: 0.000793\n",
      "\t TVw: 0.765111 | TVb: 2.282691 | GSw: -0.558111 | GSb: -0.220961 | TSUw: -0.421670 | TSUb: -0.036154\n",
      "\n",
      "Train Epoch: 5581 [4000/8000 (50%)]\tBatch Loss: 0.012638\tLearning Rate (w_theta): 0.001000\t TIME:2071.7s\n",
      "\t\t\t\tDisc: 0.011972\t\tSym: 0.000000\t\tSpars: 0.000666\n",
      "\t TVw: 0.765046 | TVb: 2.282607 | GSw: -0.557889 | GSb: -0.220693 | TSUw: -0.421333 | TSUb: -0.035805\n",
      "Validating epoch 5581...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012893611991758135\n",
      "Average validation loss: 0.013401461857376782\n",
      "Training epoch 5582...\n",
      "\n",
      "Train Epoch: 5582 [0/8000 (0%)]\tBatch Loss: 0.013579\tLearning Rate (w_theta): 0.001000\t TIME:2074.0s\n",
      "\t\t\t\tDisc: 0.012508\t\tSym: 0.000000\t\tSpars: 0.001072\n",
      "\t TVw: 0.765191 | TVb: 2.282613 | GSw: -0.557714 | GSb: -0.220480 | TSUw: -0.421615 | TSUb: -0.036051\n",
      "\n",
      "Train Epoch: 5582 [4000/8000 (50%)]\tBatch Loss: 0.013191\tLearning Rate (w_theta): 0.001000\t TIME:2075.3s\n",
      "\t\t\t\tDisc: 0.012402\t\tSym: 0.000000\t\tSpars: 0.000789\n",
      "\t TVw: 0.765422 | TVb: 2.282702 | GSw: -0.557591 | GSb: -0.220325 | TSUw: -0.422567 | TSUb: -0.036939\n",
      "Validating epoch 5582...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012894231899380161\n",
      "Average validation loss: 0.01340475378409538\n",
      "Training epoch 5583...\n",
      "\n",
      "Train Epoch: 5583 [0/8000 (0%)]\tBatch Loss: 0.012999\tLearning Rate (w_theta): 0.001000\t TIME:2077.4s\n",
      "\t\t\t\tDisc: 0.011984\t\tSym: 0.000000\t\tSpars: 0.001015\n",
      "\t TVw: 0.765331 | TVb: 2.282604 | GSw: -0.557369 | GSb: -0.220059 | TSUw: -0.422189 | TSUb: -0.036550\n",
      "\n",
      "Train Epoch: 5583 [4000/8000 (50%)]\tBatch Loss: 0.012525\tLearning Rate (w_theta): 0.001000\t TIME:2078.7s\n",
      "\t\t\t\tDisc: 0.011764\t\tSym: 0.000000\t\tSpars: 0.000761\n",
      "\t TVw: 0.765928 | TVb: 2.282720 | GSw: -0.557142 | GSb: -0.219786 | TSUw: -0.421785 | TSUb: -0.036137\n",
      "Validating epoch 5583...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012892426652302972\n",
      "Average validation loss: 0.013401132885103646\n",
      "Training epoch 5584...\n",
      "\n",
      "Train Epoch: 5584 [0/8000 (0%)]\tBatch Loss: 0.012970\tLearning Rate (w_theta): 0.001000\t TIME:2080.9s\n",
      "\t\t\t\tDisc: 0.012200\t\tSym: 0.000000\t\tSpars: 0.000769\n",
      "\t TVw: 0.765722 | TVb: 2.282649 | GSw: -0.556912 | GSb: -0.219514 | TSUw: -0.421342 | TSUb: -0.035685\n",
      "\n",
      "Train Epoch: 5584 [4000/8000 (50%)]\tBatch Loss: 0.012626\tLearning Rate (w_theta): 0.001000\t TIME:2082.2s\n",
      "\t\t\t\tDisc: 0.011958\t\tSym: 0.000000\t\tSpars: 0.000668\n",
      "\t TVw: 0.765164 | TVb: 2.282506 | GSw: -0.556745 | GSb: -0.219316 | TSUw: -0.421685 | TSUb: -0.035988\n",
      "Validating epoch 5584...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012894138156309874\n",
      "Average validation loss: 0.013404561176644283\n",
      "Training epoch 5585...\n",
      "\n",
      "Train Epoch: 5585 [0/8000 (0%)]\tBatch Loss: 0.012780\tLearning Rate (w_theta): 0.001000\t TIME:2084.4s\n",
      "\t\t\t\tDisc: 0.011984\t\tSym: 0.000000\t\tSpars: 0.000796\n",
      "\t TVw: 0.764793 | TVb: 2.282426 | GSw: -0.556601 | GSb: -0.219137 | TSUw: -0.422360 | TSUb: -0.036610\n",
      "\n",
      "Train Epoch: 5585 [4000/8000 (50%)]\tBatch Loss: 0.012865\tLearning Rate (w_theta): 0.001000\t TIME:2085.7s\n",
      "\t\t\t\tDisc: 0.012019\t\tSym: 0.000000\t\tSpars: 0.000846\n",
      "\t TVw: 0.764950 | TVb: 2.282485 | GSw: -0.556388 | GSb: -0.218882 | TSUw: -0.422136 | TSUb: -0.036370\n",
      "Validating epoch 5585...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012894176777204797\n",
      "Average validation loss: 0.013402443098090088\n",
      "Training epoch 5586...\n",
      "\n",
      "Train Epoch: 5586 [0/8000 (0%)]\tBatch Loss: 0.013379\tLearning Rate (w_theta): 0.001000\t TIME:2088.0s\n",
      "\t\t\t\tDisc: 0.012323\t\tSym: 0.000000\t\tSpars: 0.001056\n",
      "\t TVw: 0.765179 | TVb: 2.282494 | GSw: -0.556187 | GSb: -0.218632 | TSUw: -0.422064 | TSUb: -0.036276\n",
      "\n",
      "Train Epoch: 5586 [4000/8000 (50%)]\tBatch Loss: 0.012466\tLearning Rate (w_theta): 0.001000\t TIME:2089.2s\n",
      "\t\t\t\tDisc: 0.011700\t\tSym: 0.000000\t\tSpars: 0.000767\n",
      "\t TVw: 0.765827 | TVb: 2.282606 | GSw: -0.555977 | GSb: -0.218369 | TSUw: -0.421898 | TSUb: -0.036094\n",
      "Validating epoch 5586...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012893577549230305\n",
      "Average validation loss: 0.013401978572228461\n",
      "Training epoch 5587...\n",
      "\n",
      "Train Epoch: 5587 [0/8000 (0%)]\tBatch Loss: 0.013047\tLearning Rate (w_theta): 0.001000\t TIME:2091.5s\n",
      "\t\t\t\tDisc: 0.012264\t\tSym: 0.000000\t\tSpars: 0.000782\n",
      "\t TVw: 0.765772 | TVb: 2.282578 | GSw: -0.555793 | GSb: -0.218146 | TSUw: -0.422092 | TSUb: -0.036255\n",
      "\n",
      "Train Epoch: 5587 [4000/8000 (50%)]\tBatch Loss: 0.012472\tLearning Rate (w_theta): 0.001000\t TIME:2092.8s\n",
      "\t\t\t\tDisc: 0.011937\t\tSym: 0.000000\t\tSpars: 0.000535\n",
      "\t TVw: 0.766237 | TVb: 2.282765 | GSw: -0.555674 | GSb: -0.217997 | TSUw: -0.423152 | TSUb: -0.037248\n",
      "Validating epoch 5587...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01289583242608149\n",
      "Average validation loss: 0.013402346364383264\n",
      "Training epoch 5588...\n",
      "\n",
      "Train Epoch: 5588 [0/8000 (0%)]\tBatch Loss: 0.012652\tLearning Rate (w_theta): 0.001000\t TIME:2095.0s\n",
      "\t\t\t\tDisc: 0.011882\t\tSym: 0.000000\t\tSpars: 0.000770\n",
      "\t TVw: 0.765916 | TVb: 2.282622 | GSw: -0.555382 | GSb: -0.217655 | TSUw: -0.421800 | TSUb: -0.035920\n",
      "\n",
      "Train Epoch: 5588 [4000/8000 (50%)]\tBatch Loss: 0.012601\tLearning Rate (w_theta): 0.001000\t TIME:2096.3s\n",
      "\t\t\t\tDisc: 0.011985\t\tSym: 0.000000\t\tSpars: 0.000615\n",
      "\t TVw: 0.765700 | TVb: 2.282535 | GSw: -0.555133 | GSb: -0.217356 | TSUw: -0.421062 | TSUb: -0.035184\n",
      "Validating epoch 5588...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012896861969343261\n",
      "Average validation loss: 0.013402603686729004\n",
      "Training epoch 5589...\n",
      "\n",
      "Train Epoch: 5589 [0/8000 (0%)]\tBatch Loss: 0.012530\tLearning Rate (w_theta): 0.001000\t TIME:2098.5s\n",
      "\t\t\t\tDisc: 0.011919\t\tSym: 0.000000\t\tSpars: 0.000611\n",
      "\t TVw: 0.765429 | TVb: 2.282506 | GSw: -0.555063 | GSb: -0.217263 | TSUw: -0.422521 | TSUb: -0.036561\n",
      "\n",
      "Train Epoch: 5589 [4000/8000 (50%)]\tBatch Loss: 0.012759\tLearning Rate (w_theta): 0.001000\t TIME:2099.8s\n",
      "\t\t\t\tDisc: 0.011728\t\tSym: 0.000000\t\tSpars: 0.001031\n",
      "\t TVw: 0.764946 | TVb: 2.282345 | GSw: -0.554933 | GSb: -0.217107 | TSUw: -0.423266 | TSUb: -0.037251\n",
      "Validating epoch 5589...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012895201955820603\n",
      "Average validation loss: 0.013408110764675345\n",
      "Training epoch 5590...\n",
      "\n",
      "Train Epoch: 5590 [0/8000 (0%)]\tBatch Loss: 0.012693\tLearning Rate (w_theta): 0.001000\t TIME:2102.0s\n",
      "\t\t\t\tDisc: 0.011990\t\tSym: 0.000000\t\tSpars: 0.000703\n",
      "\t TVw: 0.764977 | TVb: 2.282330 | GSw: -0.554696 | GSb: -0.216827 | TSUw: -0.422604 | TSUb: -0.036587\n",
      "\n",
      "Train Epoch: 5590 [4000/8000 (50%)]\tBatch Loss: 0.013279\tLearning Rate (w_theta): 0.001000\t TIME:2103.2s\n",
      "\t\t\t\tDisc: 0.012395\t\tSym: 0.000000\t\tSpars: 0.000884\n",
      "\t TVw: 0.765014 | TVb: 2.282326 | GSw: -0.554435 | GSb: -0.216519 | TSUw: -0.421633 | TSUb: -0.035623\n",
      "Validating epoch 5590...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012897204274817064\n",
      "Average validation loss: 0.01340284592371859\n",
      "Training epoch 5591...\n",
      "\n",
      "Train Epoch: 5591 [0/8000 (0%)]\tBatch Loss: 0.013212\tLearning Rate (w_theta): 0.001000\t TIME:2106.2s\n",
      "\t\t\t\tDisc: 0.012558\t\tSym: 0.000000\t\tSpars: 0.000655\n",
      "\t TVw: 0.765189 | TVb: 2.282358 | GSw: -0.554278 | GSb: -0.216326 | TSUw: -0.422007 | TSUb: -0.035958\n",
      "\n",
      "Train Epoch: 5591 [4000/8000 (50%)]\tBatch Loss: 0.012552\tLearning Rate (w_theta): 0.001000\t TIME:2107.5s\n",
      "\t\t\t\tDisc: 0.011798\t\tSym: 0.000000\t\tSpars: 0.000753\n",
      "\t TVw: 0.764743 | TVb: 2.282229 | GSw: -0.554124 | GSb: -0.216141 | TSUw: -0.422469 | TSUb: -0.036377\n",
      "Validating epoch 5591...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01289495003673\n",
      "Average validation loss: 0.013406213362912119\n",
      "Training epoch 5592...\n",
      "\n",
      "Train Epoch: 5592 [0/8000 (0%)]\tBatch Loss: 0.012601\tLearning Rate (w_theta): 0.001000\t TIME:2109.7s\n",
      "\t\t\t\tDisc: 0.011886\t\tSym: 0.000000\t\tSpars: 0.000716\n",
      "\t TVw: 0.764681 | TVb: 2.282160 | GSw: -0.553952 | GSb: -0.215931 | TSUw: -0.422733 | TSUb: -0.036607\n",
      "\n",
      "Train Epoch: 5592 [4000/8000 (50%)]\tBatch Loss: 0.012866\tLearning Rate (w_theta): 0.001000\t TIME:2110.9s\n",
      "\t\t\t\tDisc: 0.012128\t\tSym: 0.000000\t\tSpars: 0.000738\n",
      "\t TVw: 0.764951 | TVb: 2.282268 | GSw: -0.553781 | GSb: -0.215729 | TSUw: -0.423065 | TSUb: -0.036903\n",
      "Validating epoch 5592...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012894955566725593\n",
      "Average validation loss: 0.013403973426818358\n",
      "Training epoch 5593...\n",
      "\n",
      "Train Epoch: 5593 [0/8000 (0%)]\tBatch Loss: 0.013117\tLearning Rate (w_theta): 0.001000\t TIME:2113.2s\n",
      "\t\t\t\tDisc: 0.012207\t\tSym: 0.000000\t\tSpars: 0.000910\n",
      "\t TVw: 0.765156 | TVb: 2.282263 | GSw: -0.553522 | GSb: -0.215425 | TSUw: -0.422277 | TSUb: -0.036117\n",
      "\n",
      "Train Epoch: 5593 [4000/8000 (50%)]\tBatch Loss: 0.012839\tLearning Rate (w_theta): 0.001000\t TIME:2114.4s\n",
      "\t\t\t\tDisc: 0.012074\t\tSym: 0.000000\t\tSpars: 0.000765\n",
      "\t TVw: 0.765612 | TVb: 2.282330 | GSw: -0.553267 | GSb: -0.215123 | TSUw: -0.421525 | TSUb: -0.035367\n",
      "Validating epoch 5593...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012897436993800998\n",
      "Average validation loss: 0.013402832838618981\n",
      "Training epoch 5594...\n",
      "\n",
      "Train Epoch: 5594 [0/8000 (0%)]\tBatch Loss: 0.013374\tLearning Rate (w_theta): 0.001000\t TIME:2116.7s\n",
      "\t\t\t\tDisc: 0.012386\t\tSym: 0.000000\t\tSpars: 0.000988\n",
      "\t TVw: 0.765429 | TVb: 2.282355 | GSw: -0.553169 | GSb: -0.214998 | TSUw: -0.422659 | TSUb: -0.036439\n",
      "\n",
      "Train Epoch: 5594 [4000/8000 (50%)]\tBatch Loss: 0.013046\tLearning Rate (w_theta): 0.001000\t TIME:2117.9s\n",
      "\t\t\t\tDisc: 0.012278\t\tSym: 0.000000\t\tSpars: 0.000768\n",
      "\t TVw: 0.765092 | TVb: 2.282324 | GSw: -0.552983 | GSb: -0.214773 | TSUw: -0.422697 | TSUb: -0.036450\n",
      "Validating epoch 5594...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012894540416792444\n",
      "Average validation loss: 0.013405739477578775\n",
      "Training epoch 5595...\n",
      "\n",
      "Train Epoch: 5595 [0/8000 (0%)]\tBatch Loss: 0.012919\tLearning Rate (w_theta): 0.001000\t TIME:2120.3s\n",
      "\t\t\t\tDisc: 0.012211\t\tSym: 0.000000\t\tSpars: 0.000709\n",
      "\t TVw: 0.764683 | TVb: 2.282221 | GSw: -0.552824 | GSb: -0.214580 | TSUw: -0.423143 | TSUb: -0.036856\n",
      "\n",
      "Train Epoch: 5595 [4000/8000 (50%)]\tBatch Loss: 0.013972\tLearning Rate (w_theta): 0.001000\t TIME:2121.6s\n",
      "\t\t\t\tDisc: 0.012972\t\tSym: 0.000000\t\tSpars: 0.001000\n",
      "\t TVw: 0.764072 | TVb: 2.281973 | GSw: -0.552609 | GSb: -0.214323 | TSUw: -0.422871 | TSUb: -0.036566\n",
      "Validating epoch 5595...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012896205884228582\n",
      "Average validation loss: 0.013404779234747225\n",
      "Training epoch 5596...\n",
      "\n",
      "Train Epoch: 5596 [0/8000 (0%)]\tBatch Loss: 0.013122\tLearning Rate (w_theta): 0.001000\t TIME:2123.8s\n",
      "\t\t\t\tDisc: 0.012077\t\tSym: 0.000000\t\tSpars: 0.001045\n",
      "\t TVw: 0.764499 | TVb: 2.282103 | GSw: -0.552394 | GSb: -0.214068 | TSUw: -0.422635 | TSUb: -0.036314\n",
      "\n",
      "Train Epoch: 5596 [4000/8000 (50%)]\tBatch Loss: 0.013011\tLearning Rate (w_theta): 0.001000\t TIME:2125.1s\n",
      "\t\t\t\tDisc: 0.012371\t\tSym: 0.000000\t\tSpars: 0.000639\n",
      "\t TVw: 0.765224 | TVb: 2.282259 | GSw: -0.552252 | GSb: -0.213893 | TSUw: -0.423351 | TSUb: -0.036982\n",
      "Validating epoch 5596...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012897116512284845\n",
      "Average validation loss: 0.01340353937998473\n",
      "Training epoch 5597...\n",
      "\n",
      "Train Epoch: 5597 [0/8000 (0%)]\tBatch Loss: 0.012761\tLearning Rate (w_theta): 0.001000\t TIME:2127.3s\n",
      "\t\t\t\tDisc: 0.011945\t\tSym: 0.000000\t\tSpars: 0.000816\n",
      "\t TVw: 0.765222 | TVb: 2.282168 | GSw: -0.551979 | GSb: -0.213573 | TSUw: -0.422362 | TSUb: -0.035998\n",
      "\n",
      "Train Epoch: 5597 [4000/8000 (50%)]\tBatch Loss: 0.012885\tLearning Rate (w_theta): 0.001000\t TIME:2128.6s\n",
      "\t\t\t\tDisc: 0.012104\t\tSym: 0.000000\t\tSpars: 0.000781\n",
      "\t TVw: 0.765590 | TVb: 2.282327 | GSw: -0.551814 | GSb: -0.213373 | TSUw: -0.422733 | TSUb: -0.036334\n",
      "Validating epoch 5597...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01289506189587682\n",
      "Average validation loss: 0.013402967172421587\n",
      "Training epoch 5598...\n",
      "\n",
      "Train Epoch: 5598 [0/8000 (0%)]\tBatch Loss: 0.012205\tLearning Rate (w_theta): 0.001000\t TIME:2130.8s\n",
      "\t\t\t\tDisc: 0.011761\t\tSym: 0.000000\t\tSpars: 0.000444\n",
      "\t TVw: 0.765332 | TVb: 2.282213 | GSw: -0.551589 | GSb: -0.213109 | TSUw: -0.422393 | TSUb: -0.035980\n",
      "\n",
      "Train Epoch: 5598 [4000/8000 (50%)]\tBatch Loss: 0.013369\tLearning Rate (w_theta): 0.001000\t TIME:2132.1s\n",
      "\t\t\t\tDisc: 0.012415\t\tSym: 0.000000\t\tSpars: 0.000955\n",
      "\t TVw: 0.764357 | TVb: 2.281910 | GSw: -0.551374 | GSb: -0.212850 | TSUw: -0.422188 | TSUb: -0.035756\n",
      "Validating epoch 5598...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012896747588086808\n",
      "Average validation loss: 0.013405014220654009\n",
      "Training epoch 5599...\n",
      "\n",
      "Train Epoch: 5599 [0/8000 (0%)]\tBatch Loss: 0.012577\tLearning Rate (w_theta): 0.001000\t TIME:2134.3s\n",
      "\t\t\t\tDisc: 0.011776\t\tSym: 0.000000\t\tSpars: 0.000802\n",
      "\t TVw: 0.764322 | TVb: 2.282036 | GSw: -0.551247 | GSb: -0.212691 | TSUw: -0.423046 | TSUb: -0.036564\n",
      "\n",
      "Train Epoch: 5599 [4000/8000 (50%)]\tBatch Loss: 0.012729\tLearning Rate (w_theta): 0.001000\t TIME:2135.6s\n",
      "\t\t\t\tDisc: 0.012033\t\tSym: 0.000000\t\tSpars: 0.000696\n",
      "\t TVw: 0.763863 | TVb: 2.281972 | GSw: -0.551069 | GSb: -0.212474 | TSUw: -0.423274 | TSUb: -0.036760\n",
      "Validating epoch 5599...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01289634849361444\n",
      "Average validation loss: 0.013406500422415181\n",
      "Training epoch 5600...\n",
      "\n",
      "Train Epoch: 5600 [0/8000 (0%)]\tBatch Loss: 0.012915\tLearning Rate (w_theta): 0.001000\t TIME:2138.0s\n",
      "\t\t\t\tDisc: 0.012251\t\tSym: 0.000000\t\tSpars: 0.000665\n",
      "\t TVw: 0.763767 | TVb: 2.281933 | GSw: -0.550856 | GSb: -0.212226 | TSUw: -0.423081 | TSUb: -0.036549\n",
      "\n",
      "Train Epoch: 5600 [4000/8000 (50%)]\tBatch Loss: 0.012185\tLearning Rate (w_theta): 0.001000\t TIME:2139.2s\n",
      "\t\t\t\tDisc: 0.011382\t\tSym: 0.000000\t\tSpars: 0.000803\n",
      "\t TVw: 0.764254 | TVb: 2.282101 | GSw: -0.550633 | GSb: -0.211961 | TSUw: -0.422790 | TSUb: -0.036244\n",
      "Validating epoch 5600...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012896121157741035\n",
      "Average validation loss: 0.013405005408324448\n",
      "Training epoch 5601...\n",
      "\n",
      "Train Epoch: 5601 [0/8000 (0%)]\tBatch Loss: 0.012470\tLearning Rate (w_theta): 0.001000\t TIME:2142.2s\n",
      "\t\t\t\tDisc: 0.011770\t\tSym: 0.000000\t\tSpars: 0.000701\n",
      "\t TVw: 0.764383 | TVb: 2.282117 | GSw: -0.550439 | GSb: -0.211732 | TSUw: -0.422869 | TSUb: -0.036297\n",
      "\n",
      "Train Epoch: 5601 [4000/8000 (50%)]\tBatch Loss: 0.012965\tLearning Rate (w_theta): 0.001000\t TIME:2143.5s\n",
      "\t\t\t\tDisc: 0.011963\t\tSym: 0.000000\t\tSpars: 0.001002\n",
      "\t TVw: 0.764271 | TVb: 2.282043 | GSw: -0.550200 | GSb: -0.211445 | TSUw: -0.422403 | TSUb: -0.035821\n",
      "Validating epoch 5601...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01289729366321919\n",
      "Average validation loss: 0.013405985561962697\n",
      "Training epoch 5602...\n",
      "\n",
      "Train Epoch: 5602 [0/8000 (0%)]\tBatch Loss: 0.012978\tLearning Rate (w_theta): 0.001000\t TIME:2145.7s\n",
      "\t\t\t\tDisc: 0.012147\t\tSym: 0.000000\t\tSpars: 0.000831\n",
      "\t TVw: 0.764389 | TVb: 2.282094 | GSw: -0.550087 | GSb: -0.211306 | TSUw: -0.423467 | TSUb: -0.036831\n",
      "\n",
      "Train Epoch: 5602 [4000/8000 (50%)]\tBatch Loss: 0.012199\tLearning Rate (w_theta): 0.001000\t TIME:2146.9s\n",
      "\t\t\t\tDisc: 0.011601\t\tSym: 0.000000\t\tSpars: 0.000597\n",
      "\t TVw: 0.764151 | TVb: 2.282091 | GSw: -0.549920 | GSb: -0.211111 | TSUw: -0.423831 | TSUb: -0.037158\n",
      "Validating epoch 5602...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012897192002064201\n",
      "Average validation loss: 0.013406853599377815\n",
      "Training epoch 5603...\n",
      "\n",
      "Train Epoch: 5603 [0/8000 (0%)]\tBatch Loss: 0.013121\tLearning Rate (w_theta): 0.001000\t TIME:2149.3s\n",
      "\t\t\t\tDisc: 0.012283\t\tSym: 0.000000\t\tSpars: 0.000838\n",
      "\t TVw: 0.764221 | TVb: 2.282070 | GSw: -0.549654 | GSb: -0.210805 | TSUw: -0.422963 | TSUb: -0.036290\n",
      "\n",
      "Train Epoch: 5603 [4000/8000 (50%)]\tBatch Loss: 0.013129\tLearning Rate (w_theta): 0.001000\t TIME:2150.5s\n",
      "\t\t\t\tDisc: 0.012123\t\tSym: 0.000000\t\tSpars: 0.001005\n",
      "\t TVw: 0.764721 | TVb: 2.282261 | GSw: -0.549424 | GSb: -0.210529 | TSUw: -0.422502 | TSUb: -0.035819\n",
      "Validating epoch 5603...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012897610089375885\n",
      "Average validation loss: 0.013403584377849853\n",
      "Training epoch 5604...\n",
      "\n",
      "Train Epoch: 5604 [0/8000 (0%)]\tBatch Loss: 0.012269\tLearning Rate (w_theta): 0.001000\t TIME:2152.7s\n",
      "\t\t\t\tDisc: 0.011520\t\tSym: 0.000000\t\tSpars: 0.000749\n",
      "\t TVw: 0.764881 | TVb: 2.282334 | GSw: -0.549277 | GSb: -0.210352 | TSUw: -0.423086 | TSUb: -0.036362\n",
      "\n",
      "Train Epoch: 5604 [4000/8000 (50%)]\tBatch Loss: 0.012554\tLearning Rate (w_theta): 0.001000\t TIME:2154.0s\n",
      "\t\t\t\tDisc: 0.011839\t\tSym: 0.000000\t\tSpars: 0.000715\n",
      "\t TVw: 0.764718 | TVb: 2.282259 | GSw: -0.549118 | GSb: -0.210161 | TSUw: -0.423555 | TSUb: -0.036794\n",
      "Validating epoch 5604...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012895664947319418\n",
      "Average validation loss: 0.013405842917457337\n",
      "Training epoch 5605...\n",
      "\n",
      "Train Epoch: 5605 [0/8000 (0%)]\tBatch Loss: 0.012918\tLearning Rate (w_theta): 0.001000\t TIME:2156.2s\n",
      "\t\t\t\tDisc: 0.012253\t\tSym: 0.000000\t\tSpars: 0.000665\n",
      "\t TVw: 0.764588 | TVb: 2.282150 | GSw: -0.548903 | GSb: -0.209910 | TSUw: -0.423334 | TSUb: -0.036555\n",
      "\n",
      "Train Epoch: 5605 [4000/8000 (50%)]\tBatch Loss: 0.012335\tLearning Rate (w_theta): 0.001000\t TIME:2157.5s\n",
      "\t\t\t\tDisc: 0.011645\t\tSym: 0.000000\t\tSpars: 0.000690\n",
      "\t TVw: 0.764411 | TVb: 2.282134 | GSw: -0.548675 | GSb: -0.209643 | TSUw: -0.422961 | TSUb: -0.036169\n",
      "Validating epoch 5605...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012896007092176455\n",
      "Average validation loss: 0.013404963530151899\n",
      "Training epoch 5606...\n",
      "\n",
      "Train Epoch: 5606 [0/8000 (0%)]\tBatch Loss: 0.013058\tLearning Rate (w_theta): 0.001000\t TIME:2159.7s\n",
      "\t\t\t\tDisc: 0.012183\t\tSym: 0.000000\t\tSpars: 0.000875\n",
      "\t TVw: 0.764439 | TVb: 2.282155 | GSw: -0.548516 | GSb: -0.209450 | TSUw: -0.423451 | TSUb: -0.036622\n",
      "\n",
      "Train Epoch: 5606 [4000/8000 (50%)]\tBatch Loss: 0.012757\tLearning Rate (w_theta): 0.001000\t TIME:2161.0s\n",
      "\t\t\t\tDisc: 0.011935\t\tSym: 0.000000\t\tSpars: 0.000822\n",
      "\t TVw: 0.764201 | TVb: 2.282113 | GSw: -0.548353 | GSb: -0.209248 | TSUw: -0.423914 | TSUb: -0.037048\n",
      "Validating epoch 5606...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012897115046463622\n",
      "Average validation loss: 0.013407691200675845\n",
      "Training epoch 5607...\n",
      "\n",
      "Train Epoch: 5607 [0/8000 (0%)]\tBatch Loss: 0.012503\tLearning Rate (w_theta): 0.001000\t TIME:2163.2s\n",
      "\t\t\t\tDisc: 0.012053\t\tSym: 0.000000\t\tSpars: 0.000450\n",
      "\t TVw: 0.764372 | TVb: 2.282079 | GSw: -0.548106 | GSb: -0.208962 | TSUw: -0.423325 | TSUb: -0.036451\n",
      "\n",
      "Train Epoch: 5607 [4000/8000 (50%)]\tBatch Loss: 0.012785\tLearning Rate (w_theta): 0.001000\t TIME:2164.5s\n",
      "\t\t\t\tDisc: 0.011784\t\tSym: 0.000000\t\tSpars: 0.001001\n",
      "\t TVw: 0.763779 | TVb: 2.281796 | GSw: -0.547817 | GSb: -0.208633 | TSUw: -0.422179 | TSUb: -0.035311\n",
      "Validating epoch 5607...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01290316087462916\n",
      "Average validation loss: 0.013406359634715617\n",
      "Training epoch 5608...\n",
      "\n",
      "Train Epoch: 5608 [0/8000 (0%)]\tBatch Loss: 0.012744\tLearning Rate (w_theta): 0.001000\t TIME:2166.7s\n",
      "\t\t\t\tDisc: 0.012059\t\tSym: 0.000000\t\tSpars: 0.000685\n",
      "\t TVw: 0.763941 | TVb: 2.281974 | GSw: -0.547767 | GSb: -0.208562 | TSUw: -0.423770 | TSUb: -0.036835\n",
      "\n",
      "Train Epoch: 5608 [4000/8000 (50%)]\tBatch Loss: 0.013403\tLearning Rate (w_theta): 0.001000\t TIME:2168.0s\n",
      "\t\t\t\tDisc: 0.012625\t\tSym: 0.000000\t\tSpars: 0.000778\n",
      "\t TVw: 0.763862 | TVb: 2.281995 | GSw: -0.547608 | GSb: -0.208372 | TSUw: -0.424129 | TSUb: -0.037160\n",
      "Validating epoch 5608...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012897296384564695\n",
      "Average validation loss: 0.013407829627763792\n",
      "Training epoch 5609...\n",
      "\n",
      "Train Epoch: 5609 [0/8000 (0%)]\tBatch Loss: 0.012827\tLearning Rate (w_theta): 0.001000\t TIME:2170.3s\n",
      "\t\t\t\tDisc: 0.012018\t\tSym: 0.000000\t\tSpars: 0.000809\n",
      "\t TVw: 0.764006 | TVb: 2.282004 | GSw: -0.547386 | GSb: -0.208115 | TSUw: -0.423745 | TSUb: -0.036761\n",
      "\n",
      "Train Epoch: 5609 [4000/8000 (50%)]\tBatch Loss: 0.012305\tLearning Rate (w_theta): 0.001000\t TIME:2171.6s\n",
      "\t\t\t\tDisc: 0.011676\t\tSym: 0.000000\t\tSpars: 0.000629\n",
      "\t TVw: 0.764526 | TVb: 2.282070 | GSw: -0.547197 | GSb: -0.207896 | TSUw: -0.423803 | TSUb: -0.036793\n",
      "Validating epoch 5609...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012896272494632658\n",
      "Average validation loss: 0.013405184247002431\n",
      "Training epoch 5610...\n",
      "\n",
      "Train Epoch: 5610 [0/8000 (0%)]\tBatch Loss: 0.012650\tLearning Rate (w_theta): 0.001000\t TIME:2173.8s\n",
      "\t\t\t\tDisc: 0.011683\t\tSym: 0.000000\t\tSpars: 0.000967\n",
      "\t TVw: 0.764714 | TVb: 2.282067 | GSw: -0.546955 | GSb: -0.207613 | TSUw: -0.423276 | TSUb: -0.036256\n",
      "\n",
      "Train Epoch: 5610 [4000/8000 (50%)]\tBatch Loss: 0.012627\tLearning Rate (w_theta): 0.001000\t TIME:2175.1s\n",
      "\t\t\t\tDisc: 0.011853\t\tSym: 0.000000\t\tSpars: 0.000774\n",
      "\t TVw: 0.764931 | TVb: 2.282135 | GSw: -0.546759 | GSb: -0.207377 | TSUw: -0.423310 | TSUb: -0.036267\n",
      "Validating epoch 5610...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01289608554448863\n",
      "Average validation loss: 0.013405119414649254\n",
      "Training epoch 5611...\n",
      "\n",
      "Train Epoch: 5611 [0/8000 (0%)]\tBatch Loss: 0.012852\tLearning Rate (w_theta): 0.001000\t TIME:2178.0s\n",
      "\t\t\t\tDisc: 0.012181\t\tSym: 0.000000\t\tSpars: 0.000671\n",
      "\t TVw: 0.764749 | TVb: 2.282071 | GSw: -0.546556 | GSb: -0.207140 | TSUw: -0.423281 | TSUb: -0.036215\n",
      "\n",
      "Train Epoch: 5611 [4000/8000 (50%)]\tBatch Loss: 0.012995\tLearning Rate (w_theta): 0.001000\t TIME:2179.3s\n",
      "\t\t\t\tDisc: 0.012266\t\tSym: 0.000000\t\tSpars: 0.000728\n",
      "\t TVw: 0.764351 | TVb: 2.281863 | GSw: -0.546343 | GSb: -0.206889 | TSUw: -0.423149 | TSUb: -0.036064\n",
      "Validating epoch 5611...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01289707904674501\n",
      "Average validation loss: 0.013407051310710492\n",
      "Training epoch 5612...\n",
      "\n",
      "Train Epoch: 5612 [0/8000 (0%)]\tBatch Loss: 0.013189\tLearning Rate (w_theta): 0.001000\t TIME:2181.6s\n",
      "\t\t\t\tDisc: 0.012366\t\tSym: 0.000000\t\tSpars: 0.000823\n",
      "\t TVw: 0.764414 | TVb: 2.281997 | GSw: -0.546217 | GSb: -0.206737 | TSUw: -0.424051 | TSUb: -0.036920\n",
      "\n",
      "Train Epoch: 5612 [4000/8000 (50%)]\tBatch Loss: 0.012361\tLearning Rate (w_theta): 0.001000\t TIME:2182.9s\n",
      "\t\t\t\tDisc: 0.011464\t\tSym: 0.000000\t\tSpars: 0.000897\n",
      "\t TVw: 0.764405 | TVb: 2.282133 | GSw: -0.546074 | GSb: -0.206567 | TSUw: -0.424707 | TSUb: -0.037536\n",
      "Validating epoch 5612...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012898530465615619\n",
      "Average validation loss: 0.013406245748623966\n",
      "Training epoch 5613...\n",
      "\n",
      "Train Epoch: 5613 [0/8000 (0%)]\tBatch Loss: 0.013147\tLearning Rate (w_theta): 0.001000\t TIME:2185.2s\n",
      "\t\t\t\tDisc: 0.012384\t\tSym: 0.000000\t\tSpars: 0.000764\n",
      "\t TVw: 0.764447 | TVb: 2.282081 | GSw: -0.545779 | GSb: -0.206231 | TSUw: -0.423480 | TSUb: -0.036313\n",
      "\n",
      "Train Epoch: 5613 [4000/8000 (50%)]\tBatch Loss: 0.013276\tLearning Rate (w_theta): 0.001000\t TIME:2186.5s\n",
      "\t\t\t\tDisc: 0.012530\t\tSym: 0.000000\t\tSpars: 0.000745\n",
      "\t TVw: 0.764487 | TVb: 2.282008 | GSw: -0.545514 | GSb: -0.205922 | TSUw: -0.422653 | TSUb: -0.035483\n",
      "Validating epoch 5613...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012899353331606389\n",
      "Average validation loss: 0.013405166245753051\n",
      "Training epoch 5614...\n",
      "\n",
      "Train Epoch: 5614 [0/8000 (0%)]\tBatch Loss: 0.012911\tLearning Rate (w_theta): 0.001000\t TIME:2188.8s\n",
      "\t\t\t\tDisc: 0.012233\t\tSym: 0.000000\t\tSpars: 0.000679\n",
      "\t TVw: 0.764370 | TVb: 2.282019 | GSw: -0.545393 | GSb: -0.205776 | TSUw: -0.423463 | TSUb: -0.036249\n",
      "\n",
      "Train Epoch: 5614 [4000/8000 (50%)]\tBatch Loss: 0.012601\tLearning Rate (w_theta): 0.001000\t TIME:2190.1s\n",
      "\t\t\t\tDisc: 0.011860\t\tSym: 0.000000\t\tSpars: 0.000740\n",
      "\t TVw: 0.764607 | TVb: 2.281995 | GSw: -0.545284 | GSb: -0.205648 | TSUw: -0.424487 | TSUb: -0.037227\n",
      "Validating epoch 5614...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012898458666163702\n",
      "Average validation loss: 0.013414001585783094\n",
      "Training epoch 5615...\n",
      "\n",
      "Train Epoch: 5615 [0/8000 (0%)]\tBatch Loss: 0.013062\tLearning Rate (w_theta): 0.001000\t TIME:2192.3s\n",
      "\t\t\t\tDisc: 0.012163\t\tSym: 0.000000\t\tSpars: 0.000899\n",
      "\t TVw: 0.764759 | TVb: 2.282065 | GSw: -0.545094 | GSb: -0.205430 | TSUw: -0.424489 | TSUb: -0.037205\n",
      "\n",
      "Train Epoch: 5615 [4000/8000 (50%)]\tBatch Loss: 0.012662\tLearning Rate (w_theta): 0.001000\t TIME:2193.6s\n",
      "\t\t\t\tDisc: 0.012001\t\tSym: 0.000000\t\tSpars: 0.000661\n",
      "\t TVw: 0.765201 | TVb: 2.282202 | GSw: -0.544836 | GSb: -0.205135 | TSUw: -0.423674 | TSUb: -0.036384\n",
      "Validating epoch 5615...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012896434633512094\n",
      "Average validation loss: 0.013404049907763468\n",
      "Training epoch 5616...\n",
      "\n",
      "Train Epoch: 5616 [0/8000 (0%)]\tBatch Loss: 0.012535\tLearning Rate (w_theta): 0.001000\t TIME:2195.9s\n",
      "\t\t\t\tDisc: 0.011699\t\tSym: 0.000000\t\tSpars: 0.000836\n",
      "\t TVw: 0.765221 | TVb: 2.282193 | GSw: -0.544625 | GSb: -0.204894 | TSUw: -0.423480 | TSUb: -0.036171\n",
      "\n",
      "Train Epoch: 5616 [4000/8000 (50%)]\tBatch Loss: 0.012583\tLearning Rate (w_theta): 0.001000\t TIME:2197.2s\n",
      "\t\t\t\tDisc: 0.011878\t\tSym: 0.000000\t\tSpars: 0.000705\n",
      "\t TVw: 0.764770 | TVb: 2.282022 | GSw: -0.544438 | GSb: -0.204672 | TSUw: -0.423585 | TSUb: -0.036250\n",
      "Validating epoch 5616...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012897032112871618\n",
      "Average validation loss: 0.013406502335486225\n",
      "Training epoch 5617...\n",
      "\n",
      "Train Epoch: 5617 [0/8000 (0%)]\tBatch Loss: 0.012678\tLearning Rate (w_theta): 0.001000\t TIME:2199.4s\n",
      "\t\t\t\tDisc: 0.012045\t\tSym: 0.000000\t\tSpars: 0.000634\n",
      "\t TVw: 0.764510 | TVb: 2.282005 | GSw: -0.544289 | GSb: -0.204497 | TSUw: -0.424149 | TSUb: -0.036779\n",
      "\n",
      "Train Epoch: 5617 [4000/8000 (50%)]\tBatch Loss: 0.012870\tLearning Rate (w_theta): 0.001000\t TIME:2200.8s\n",
      "\t\t\t\tDisc: 0.012055\t\tSym: 0.000000\t\tSpars: 0.000815\n",
      "\t TVw: 0.764017 | TVb: 2.281884 | GSw: -0.544103 | GSb: -0.204288 | TSUw: -0.424297 | TSUb: -0.036900\n",
      "Validating epoch 5617...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012897861562439867\n",
      "Average validation loss: 0.013406956331477371\n",
      "Training epoch 5618...\n",
      "\n",
      "Train Epoch: 5618 [0/8000 (0%)]\tBatch Loss: 0.013587\tLearning Rate (w_theta): 0.001000\t TIME:2203.0s\n",
      "\t\t\t\tDisc: 0.012215\t\tSym: 0.000000\t\tSpars: 0.001372\n",
      "\t TVw: 0.764051 | TVb: 2.281880 | GSw: -0.543885 | GSb: -0.204034 | TSUw: -0.424083 | TSUb: -0.036668\n",
      "\n",
      "Train Epoch: 5618 [4000/8000 (50%)]\tBatch Loss: 0.012821\tLearning Rate (w_theta): 0.001000\t TIME:2204.3s\n",
      "\t\t\t\tDisc: 0.012021\t\tSym: 0.000000\t\tSpars: 0.000800\n",
      "\t TVw: 0.764691 | TVb: 2.282039 | GSw: -0.543697 | GSb: -0.203812 | TSUw: -0.424221 | TSUb: -0.036783\n",
      "Validating epoch 5618...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0128978963191963\n",
      "Average validation loss: 0.013405526344512829\n",
      "Training epoch 5619...\n",
      "\n",
      "Train Epoch: 5619 [0/8000 (0%)]\tBatch Loss: 0.012584\tLearning Rate (w_theta): 0.001000\t TIME:2206.5s\n",
      "\t\t\t\tDisc: 0.011725\t\tSym: 0.000000\t\tSpars: 0.000859\n",
      "\t TVw: 0.764567 | TVb: 2.281987 | GSw: -0.543459 | GSb: -0.203536 | TSUw: -0.423809 | TSUb: -0.036357\n",
      "\n",
      "Train Epoch: 5619 [4000/8000 (50%)]\tBatch Loss: 0.012513\tLearning Rate (w_theta): 0.001000\t TIME:2207.8s\n",
      "\t\t\t\tDisc: 0.011998\t\tSym: 0.000000\t\tSpars: 0.000516\n",
      "\t TVw: 0.765453 | TVb: 2.282251 | GSw: -0.543302 | GSb: -0.203354 | TSUw: -0.424329 | TSUb: -0.036846\n",
      "Validating epoch 5619...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01289732032489675\n",
      "Average validation loss: 0.013405553066725358\n",
      "Training epoch 5620...\n",
      "\n",
      "Train Epoch: 5620 [0/8000 (0%)]\tBatch Loss: 0.013612\tLearning Rate (w_theta): 0.001000\t TIME:2210.1s\n",
      "\t\t\t\tDisc: 0.012857\t\tSym: 0.000000\t\tSpars: 0.000756\n",
      "\t TVw: 0.765213 | TVb: 2.282181 | GSw: -0.543049 | GSb: -0.203062 | TSUw: -0.423742 | TSUb: -0.036248\n",
      "\n",
      "Train Epoch: 5620 [4000/8000 (50%)]\tBatch Loss: 0.012634\tLearning Rate (w_theta): 0.001000\t TIME:2211.4s\n",
      "\t\t\t\tDisc: 0.011898\t\tSym: 0.000000\t\tSpars: 0.000736\n",
      "\t TVw: 0.765359 | TVb: 2.282305 | GSw: -0.542824 | GSb: -0.202804 | TSUw: -0.423462 | TSUb: -0.035953\n",
      "Validating epoch 5620...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012897397261106162\n",
      "Average validation loss: 0.013405133568913824\n",
      "Training epoch 5621...\n",
      "\n",
      "Train Epoch: 5621 [0/8000 (0%)]\tBatch Loss: 0.012823\tLearning Rate (w_theta): 0.001000\t TIME:2214.2s\n",
      "\t\t\t\tDisc: 0.012045\t\tSym: 0.000000\t\tSpars: 0.000777\n",
      "\t TVw: 0.764962 | TVb: 2.282244 | GSw: -0.542693 | GSb: -0.202646 | TSUw: -0.424239 | TSUb: -0.036693\n",
      "\n",
      "Train Epoch: 5621 [4000/8000 (50%)]\tBatch Loss: 0.013400\tLearning Rate (w_theta): 0.001000\t TIME:2215.6s\n",
      "\t\t\t\tDisc: 0.012285\t\tSym: 0.000000\t\tSpars: 0.001115\n",
      "\t TVw: 0.764866 | TVb: 2.282206 | GSw: -0.542573 | GSb: -0.202503 | TSUw: -0.425142 | TSUb: -0.037555\n",
      "Validating epoch 5621...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012898906873989991\n",
      "Average validation loss: 0.013408484817835922\n",
      "Training epoch 5622...\n",
      "\n",
      "Train Epoch: 5622 [0/8000 (0%)]\tBatch Loss: 0.012932\tLearning Rate (w_theta): 0.001000\t TIME:2217.8s\n",
      "\t\t\t\tDisc: 0.011978\t\tSym: 0.000000\t\tSpars: 0.000954\n",
      "\t TVw: 0.764873 | TVb: 2.282122 | GSw: -0.542292 | GSb: -0.202184 | TSUw: -0.424146 | TSUb: -0.036555\n",
      "\n",
      "Train Epoch: 5622 [4000/8000 (50%)]\tBatch Loss: 0.012937\tLearning Rate (w_theta): 0.001000\t TIME:2219.1s\n",
      "\t\t\t\tDisc: 0.012007\t\tSym: 0.000000\t\tSpars: 0.000930\n",
      "\t TVw: 0.764502 | TVb: 2.281968 | GSw: -0.542050 | GSb: -0.201914 | TSUw: -0.423579 | TSUb: -0.035974\n",
      "Validating epoch 5622...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01289936716712884\n",
      "Average validation loss: 0.013405747620626556\n",
      "Training epoch 5623...\n",
      "\n",
      "Train Epoch: 5623 [0/8000 (0%)]\tBatch Loss: 0.012939\tLearning Rate (w_theta): 0.001000\t TIME:2221.4s\n",
      "\t\t\t\tDisc: 0.012135\t\tSym: 0.000000\t\tSpars: 0.000804\n",
      "\t TVw: 0.764500 | TVb: 2.282031 | GSw: -0.541904 | GSb: -0.201737 | TSUw: -0.424082 | TSUb: -0.036444\n",
      "\n",
      "Train Epoch: 5623 [4000/8000 (50%)]\tBatch Loss: 0.012555\tLearning Rate (w_theta): 0.001000\t TIME:2222.7s\n",
      "\t\t\t\tDisc: 0.012085\t\tSym: 0.000000\t\tSpars: 0.000470\n",
      "\t TVw: 0.764246 | TVb: 2.281936 | GSw: -0.541790 | GSb: -0.201604 | TSUw: -0.424993 | TSUb: -0.037315\n",
      "Validating epoch 5623...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01289958073088105\n",
      "Average validation loss: 0.013411681674422448\n",
      "Training epoch 5624...\n",
      "\n",
      "Train Epoch: 5624 [0/8000 (0%)]\tBatch Loss: 0.013088\tLearning Rate (w_theta): 0.001000\t TIME:2225.0s\n",
      "\t\t\t\tDisc: 0.012278\t\tSym: 0.000000\t\tSpars: 0.000809\n",
      "\t TVw: 0.764112 | TVb: 2.281855 | GSw: -0.541547 | GSb: -0.201326 | TSUw: -0.424411 | TSUb: -0.036720\n",
      "\n",
      "Train Epoch: 5624 [4000/8000 (50%)]\tBatch Loss: 0.012068\tLearning Rate (w_theta): 0.001000\t TIME:2226.3s\n",
      "\t\t\t\tDisc: 0.011631\t\tSym: 0.000000\t\tSpars: 0.000436\n",
      "\t TVw: 0.764002 | TVb: 2.281828 | GSw: -0.541285 | GSb: -0.201031 | TSUw: -0.423616 | TSUb: -0.035916\n",
      "Validating epoch 5624...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012900707391838906\n",
      "Average validation loss: 0.013406443872138078\n",
      "Training epoch 5625...\n",
      "\n",
      "Train Epoch: 5625 [0/8000 (0%)]\tBatch Loss: 0.012758\tLearning Rate (w_theta): 0.001000\t TIME:2228.8s\n",
      "\t\t\t\tDisc: 0.012008\t\tSym: 0.000000\t\tSpars: 0.000750\n",
      "\t TVw: 0.763873 | TVb: 2.281790 | GSw: -0.541126 | GSb: -0.200850 | TSUw: -0.423968 | TSUb: -0.036240\n",
      "\n",
      "Train Epoch: 5625 [4000/8000 (50%)]\tBatch Loss: 0.012617\tLearning Rate (w_theta): 0.001000\t TIME:2230.1s\n",
      "\t\t\t\tDisc: 0.011882\t\tSym: 0.000000\t\tSpars: 0.000735\n",
      "\t TVw: 0.764456 | TVb: 2.282028 | GSw: -0.541061 | GSb: -0.200770 | TSUw: -0.425333 | TSUb: -0.037558\n",
      "Validating epoch 5625...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012900900044255925\n",
      "Average validation loss: 0.01341063997845382\n",
      "Training epoch 5626...\n",
      "\n",
      "Train Epoch: 5626 [0/8000 (0%)]\tBatch Loss: 0.012247\tLearning Rate (w_theta): 0.001000\t TIME:2232.6s\n",
      "\t\t\t\tDisc: 0.011748\t\tSym: 0.000000\t\tSpars: 0.000498\n",
      "\t TVw: 0.764524 | TVb: 2.281973 | GSw: -0.540809 | GSb: -0.200480 | TSUw: -0.424597 | TSUb: -0.036812\n",
      "\n",
      "Train Epoch: 5626 [4000/8000 (50%)]\tBatch Loss: 0.013396\tLearning Rate (w_theta): 0.001000\t TIME:2233.9s\n",
      "\t\t\t\tDisc: 0.012688\t\tSym: 0.000000\t\tSpars: 0.000708\n",
      "\t TVw: 0.764463 | TVb: 2.281940 | GSw: -0.540563 | GSb: -0.200201 | TSUw: -0.423988 | TSUb: -0.036190\n",
      "Validating epoch 5626...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012899010830484746\n",
      "Average validation loss: 0.013405901128738115\n",
      "Training epoch 5627...\n",
      "\n",
      "Train Epoch: 5627 [0/8000 (0%)]\tBatch Loss: 0.012561\tLearning Rate (w_theta): 0.001000\t TIME:2236.3s\n",
      "\t\t\t\tDisc: 0.011831\t\tSym: 0.000000\t\tSpars: 0.000730\n",
      "\t TVw: 0.764398 | TVb: 2.281914 | GSw: -0.540367 | GSb: -0.199971 | TSUw: -0.423947 | TSUb: -0.036127\n",
      "\n",
      "Train Epoch: 5627 [4000/8000 (50%)]\tBatch Loss: 0.012867\tLearning Rate (w_theta): 0.001000\t TIME:2237.6s\n",
      "\t\t\t\tDisc: 0.011998\t\tSym: 0.000000\t\tSpars: 0.000869\n",
      "\t TVw: 0.764428 | TVb: 2.281869 | GSw: -0.540216 | GSb: -0.199792 | TSUw: -0.424413 | TSUb: -0.036565\n",
      "Validating epoch 5627...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012898210174607603\n",
      "Average validation loss: 0.013411694845014635\n",
      "Training epoch 5628...\n",
      "\n",
      "Train Epoch: 5628 [0/8000 (0%)]\tBatch Loss: 0.013406\tLearning Rate (w_theta): 0.001000\t TIME:2239.9s\n",
      "\t\t\t\tDisc: 0.012594\t\tSym: 0.000000\t\tSpars: 0.000812\n",
      "\t TVw: 0.764643 | TVb: 2.281942 | GSw: -0.540083 | GSb: -0.199635 | TSUw: -0.425100 | TSUb: -0.037220\n",
      "\n",
      "Train Epoch: 5628 [4000/8000 (50%)]\tBatch Loss: 0.013733\tLearning Rate (w_theta): 0.001000\t TIME:2241.2s\n",
      "\t\t\t\tDisc: 0.012655\t\tSym: 0.000000\t\tSpars: 0.001077\n",
      "\t TVw: 0.764376 | TVb: 2.281823 | GSw: -0.539815 | GSb: -0.199331 | TSUw: -0.424302 | TSUb: -0.036413\n",
      "Validating epoch 5628...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012900185810756968\n",
      "Average validation loss: 0.013407297854229554\n",
      "Training epoch 5629...\n",
      "\n",
      "Train Epoch: 5629 [0/8000 (0%)]\tBatch Loss: 0.013110\tLearning Rate (w_theta): 0.001000\t TIME:2243.7s\n",
      "\t\t\t\tDisc: 0.012248\t\tSym: 0.000000\t\tSpars: 0.000862\n",
      "\t TVw: 0.764522 | TVb: 2.281880 | GSw: -0.539644 | GSb: -0.199137 | TSUw: -0.424564 | TSUb: -0.036649\n",
      "\n",
      "Train Epoch: 5629 [4000/8000 (50%)]\tBatch Loss: 0.012379\tLearning Rate (w_theta): 0.001000\t TIME:2245.0s\n",
      "\t\t\t\tDisc: 0.011774\t\tSym: 0.000000\t\tSpars: 0.000605\n",
      "\t TVw: 0.764284 | TVb: 2.281780 | GSw: -0.539414 | GSb: -0.198869 | TSUw: -0.424242 | TSUb: -0.036311\n",
      "Validating epoch 5629...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012898848274953112\n",
      "Average validation loss: 0.013407948011024007\n",
      "Training epoch 5630...\n",
      "\n",
      "Train Epoch: 5630 [0/8000 (0%)]\tBatch Loss: 0.012493\tLearning Rate (w_theta): 0.001000\t TIME:2247.4s\n",
      "\t\t\t\tDisc: 0.011705\t\tSym: 0.000000\t\tSpars: 0.000789\n",
      "\t TVw: 0.764343 | TVb: 2.281727 | GSw: -0.539264 | GSb: -0.198696 | TSUw: -0.424787 | TSUb: -0.036826\n",
      "\n",
      "Train Epoch: 5630 [4000/8000 (50%)]\tBatch Loss: 0.012746\tLearning Rate (w_theta): 0.001000\t TIME:2248.7s\n",
      "\t\t\t\tDisc: 0.012085\t\tSym: 0.000000\t\tSpars: 0.000661\n",
      "\t TVw: 0.764636 | TVb: 2.281869 | GSw: -0.539086 | GSb: -0.198499 | TSUw: -0.425017 | TSUb: -0.037032\n",
      "Validating epoch 5630...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012898826828832916\n",
      "Average validation loss: 0.013408048829206763\n",
      "Training epoch 5631...\n",
      "\n",
      "Train Epoch: 5631 [0/8000 (0%)]\tBatch Loss: 0.012573\tLearning Rate (w_theta): 0.001000\t TIME:2251.7s\n",
      "\t\t\t\tDisc: 0.011940\t\tSym: 0.000000\t\tSpars: 0.000633\n",
      "\t TVw: 0.764740 | TVb: 2.281790 | GSw: -0.538855 | GSb: -0.198236 | TSUw: -0.424679 | TSUb: -0.036678\n",
      "\n",
      "Train Epoch: 5631 [4000/8000 (50%)]\tBatch Loss: 0.013663\tLearning Rate (w_theta): 0.001000\t TIME:2253.0s\n",
      "\t\t\t\tDisc: 0.012606\t\tSym: 0.000000\t\tSpars: 0.001057\n",
      "\t TVw: 0.764944 | TVb: 2.281771 | GSw: -0.538663 | GSb: -0.198019 | TSUw: -0.424782 | TSUb: -0.036758\n",
      "Validating epoch 5631...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012898977587514501\n",
      "Average validation loss: 0.013409808080760796\n",
      "Training epoch 5632...\n",
      "\n",
      "Train Epoch: 5632 [0/8000 (0%)]\tBatch Loss: 0.012224\tLearning Rate (w_theta): 0.001000\t TIME:2255.3s\n",
      "\t\t\t\tDisc: 0.011680\t\tSym: 0.000000\t\tSpars: 0.000544\n",
      "\t TVw: 0.764982 | TVb: 2.281800 | GSw: -0.538469 | GSb: -0.197802 | TSUw: -0.424873 | TSUb: -0.036826\n",
      "\n",
      "Train Epoch: 5632 [4000/8000 (50%)]\tBatch Loss: 0.013293\tLearning Rate (w_theta): 0.001000\t TIME:2256.5s\n",
      "\t\t\t\tDisc: 0.012367\t\tSym: 0.000000\t\tSpars: 0.000926\n",
      "\t TVw: 0.764885 | TVb: 2.281775 | GSw: -0.538230 | GSb: -0.197529 | TSUw: -0.424451 | TSUb: -0.036390\n",
      "Validating epoch 5632...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012898818821780697\n",
      "Average validation loss: 0.013407009647983371\n",
      "Training epoch 5633...\n",
      "\n",
      "Train Epoch: 5633 [0/8000 (0%)]\tBatch Loss: 0.012834\tLearning Rate (w_theta): 0.001000\t TIME:2258.8s\n",
      "\t\t\t\tDisc: 0.012119\t\tSym: 0.000000\t\tSpars: 0.000714\n",
      "\t TVw: 0.764859 | TVb: 2.281820 | GSw: -0.538039 | GSb: -0.197315 | TSUw: -0.424576 | TSUb: -0.036493\n",
      "\n",
      "Train Epoch: 5633 [4000/8000 (50%)]\tBatch Loss: 0.012776\tLearning Rate (w_theta): 0.001000\t TIME:2260.1s\n",
      "\t\t\t\tDisc: 0.011786\t\tSym: 0.000000\t\tSpars: 0.000990\n",
      "\t TVw: 0.765126 | TVb: 2.281925 | GSw: -0.537875 | GSb: -0.197134 | TSUw: -0.424984 | TSUb: -0.036874\n",
      "Validating epoch 5633...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01289792962946647\n",
      "Average validation loss: 0.013410407436959088\n",
      "Training epoch 5634...\n",
      "\n",
      "Train Epoch: 5634 [0/8000 (0%)]\tBatch Loss: 0.012646\tLearning Rate (w_theta): 0.001000\t TIME:2262.4s\n",
      "\t\t\t\tDisc: 0.011977\t\tSym: 0.000000\t\tSpars: 0.000669\n",
      "\t TVw: 0.765399 | TVb: 2.281983 | GSw: -0.537699 | GSb: -0.196933 | TSUw: -0.425289 | TSUb: -0.037154\n",
      "\n",
      "Train Epoch: 5634 [4000/8000 (50%)]\tBatch Loss: 0.013355\tLearning Rate (w_theta): 0.001000\t TIME:2263.7s\n",
      "\t\t\t\tDisc: 0.012446\t\tSym: 0.000000\t\tSpars: 0.000910\n",
      "\t TVw: 0.765119 | TVb: 2.281821 | GSw: -0.537464 | GSb: -0.196669 | TSUw: -0.424951 | TSUb: -0.036799\n",
      "Validating epoch 5634...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012897462059426145\n",
      "Average validation loss: 0.0134066253342462\n",
      "Training epoch 5635...\n",
      "\n",
      "Train Epoch: 5635 [0/8000 (0%)]\tBatch Loss: 0.013235\tLearning Rate (w_theta): 0.001000\t TIME:2266.1s\n",
      "\t\t\t\tDisc: 0.012362\t\tSym: 0.000000\t\tSpars: 0.000873\n",
      "\t TVw: 0.765276 | TVb: 2.281792 | GSw: -0.537210 | GSb: -0.196376 | TSUw: -0.424420 | TSUb: -0.036256\n",
      "\n",
      "Train Epoch: 5635 [4000/8000 (50%)]\tBatch Loss: 0.012401\tLearning Rate (w_theta): 0.001000\t TIME:2267.4s\n",
      "\t\t\t\tDisc: 0.011667\t\tSym: 0.000000\t\tSpars: 0.000734\n",
      "\t TVw: 0.766298 | TVb: 2.282039 | GSw: -0.537033 | GSb: -0.196170 | TSUw: -0.424729 | TSUb: -0.036542\n",
      "Validating epoch 5635...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01289807696078623\n",
      "Average validation loss: 0.013408189479179001\n",
      "Training epoch 5636...\n",
      "\n",
      "Train Epoch: 5636 [0/8000 (0%)]\tBatch Loss: 0.013015\tLearning Rate (w_theta): 0.001000\t TIME:2269.7s\n",
      "\t\t\t\tDisc: 0.012126\t\tSym: 0.000000\t\tSpars: 0.000888\n",
      "\t TVw: 0.766221 | TVb: 2.282047 | GSw: -0.536870 | GSb: -0.195986 | TSUw: -0.425185 | TSUb: -0.036971\n",
      "\n",
      "Train Epoch: 5636 [4000/8000 (50%)]\tBatch Loss: 0.012561\tLearning Rate (w_theta): 0.001000\t TIME:2271.0s\n",
      "\t\t\t\tDisc: 0.011829\t\tSym: 0.000000\t\tSpars: 0.000732\n",
      "\t TVw: 0.765996 | TVb: 2.282063 | GSw: -0.536628 | GSb: -0.195707 | TSUw: -0.424742 | TSUb: -0.036514\n",
      "Validating epoch 5636...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012897556174882469\n",
      "Average validation loss: 0.01340730099003712\n",
      "Training epoch 5637...\n",
      "\n",
      "Train Epoch: 5637 [0/8000 (0%)]\tBatch Loss: 0.012413\tLearning Rate (w_theta): 0.001000\t TIME:2273.2s\n",
      "\t\t\t\tDisc: 0.011751\t\tSym: 0.000000\t\tSpars: 0.000662\n",
      "\t TVw: 0.765659 | TVb: 2.281984 | GSw: -0.536472 | GSb: -0.195534 | TSUw: -0.425255 | TSUb: -0.036997\n",
      "\n",
      "Train Epoch: 5637 [4000/8000 (50%)]\tBatch Loss: 0.013000\tLearning Rate (w_theta): 0.001000\t TIME:2274.4s\n",
      "\t\t\t\tDisc: 0.012131\t\tSym: 0.000000\t\tSpars: 0.000869\n",
      "\t TVw: 0.765452 | TVb: 2.281865 | GSw: -0.536296 | GSb: -0.195343 | TSUw: -0.425588 | TSUb: -0.037305\n",
      "Validating epoch 5637...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012898296131283148\n",
      "Average validation loss: 0.013408481629868626\n",
      "Training epoch 5638...\n",
      "\n",
      "Train Epoch: 5638 [0/8000 (0%)]\tBatch Loss: 0.012864\tLearning Rate (w_theta): 0.001000\t TIME:2276.7s\n",
      "\t\t\t\tDisc: 0.012069\t\tSym: 0.000000\t\tSpars: 0.000795\n",
      "\t TVw: 0.765411 | TVb: 2.281782 | GSw: -0.536038 | GSb: -0.195052 | TSUw: -0.424984 | TSUb: -0.036688\n",
      "\n",
      "Train Epoch: 5638 [4000/8000 (50%)]\tBatch Loss: 0.012679\tLearning Rate (w_theta): 0.001000\t TIME:2278.0s\n",
      "\t\t\t\tDisc: 0.011947\t\tSym: 0.000000\t\tSpars: 0.000732\n",
      "\t TVw: 0.765080 | TVb: 2.281610 | GSw: -0.535777 | GSb: -0.194755 | TSUw: -0.424330 | TSUb: -0.036022\n",
      "Validating epoch 5638...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012900437691036364\n",
      "Average validation loss: 0.01340765067419059\n",
      "Training epoch 5639...\n",
      "\n",
      "Train Epoch: 5639 [0/8000 (0%)]\tBatch Loss: 0.012494\tLearning Rate (w_theta): 0.001000\t TIME:2280.3s\n",
      "\t\t\t\tDisc: 0.011817\t\tSym: 0.000000\t\tSpars: 0.000677\n",
      "\t TVw: 0.764758 | TVb: 2.281528 | GSw: -0.535625 | GSb: -0.194582 | TSUw: -0.424815 | TSUb: -0.036479\n",
      "\n",
      "Train Epoch: 5639 [4000/8000 (50%)]\tBatch Loss: 0.013248\tLearning Rate (w_theta): 0.001000\t TIME:2281.6s\n",
      "\t\t\t\tDisc: 0.012191\t\tSym: 0.000000\t\tSpars: 0.001057\n",
      "\t TVw: 0.764984 | TVb: 2.281674 | GSw: -0.535527 | GSb: -0.194478 | TSUw: -0.425910 | TSUb: -0.037538\n",
      "Validating epoch 5639...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012901399043250855\n",
      "Average validation loss: 0.013415898984655963\n",
      "Training epoch 5640...\n",
      "\n",
      "Train Epoch: 5640 [0/8000 (0%)]\tBatch Loss: 0.013219\tLearning Rate (w_theta): 0.001000\t TIME:2283.9s\n",
      "\t\t\t\tDisc: 0.012177\t\tSym: 0.000000\t\tSpars: 0.001042\n",
      "\t TVw: 0.765256 | TVb: 2.281692 | GSw: -0.535328 | GSb: -0.194258 | TSUw: -0.425870 | TSUb: -0.037477\n",
      "\n",
      "Train Epoch: 5640 [4000/8000 (50%)]\tBatch Loss: 0.012984\tLearning Rate (w_theta): 0.001000\t TIME:2285.2s\n",
      "\t\t\t\tDisc: 0.012205\t\tSym: 0.000000\t\tSpars: 0.000779\n",
      "\t TVw: 0.765483 | TVb: 2.281631 | GSw: -0.535057 | GSb: -0.193957 | TSUw: -0.425063 | TSUb: -0.036659\n",
      "Validating epoch 5640...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012897119578342482\n",
      "Average validation loss: 0.013407115458817403\n",
      "Training epoch 5641...\n",
      "\n",
      "Train Epoch: 5641 [0/8000 (0%)]\tBatch Loss: 0.012657\tLearning Rate (w_theta): 0.001000\t TIME:2288.2s\n",
      "\t\t\t\tDisc: 0.011680\t\tSym: 0.000000\t\tSpars: 0.000977\n",
      "\t TVw: 0.765560 | TVb: 2.281680 | GSw: -0.534805 | GSb: -0.193674 | TSUw: -0.424486 | TSUb: -0.036069\n",
      "\n",
      "Train Epoch: 5641 [4000/8000 (50%)]\tBatch Loss: 0.013241\tLearning Rate (w_theta): 0.001000\t TIME:2289.4s\n",
      "\t\t\t\tDisc: 0.012336\t\tSym: 0.000000\t\tSpars: 0.000905\n",
      "\t TVw: 0.765656 | TVb: 2.281903 | GSw: -0.534651 | GSb: -0.193505 | TSUw: -0.424934 | TSUb: -0.036490\n",
      "Validating epoch 5641...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012900253489179565\n",
      "Average validation loss: 0.013410566161523139\n",
      "Training epoch 5642...\n",
      "\n",
      "Train Epoch: 5642 [0/8000 (0%)]\tBatch Loss: 0.013313\tLearning Rate (w_theta): 0.001000\t TIME:2291.6s\n",
      "\t\t\t\tDisc: 0.012306\t\tSym: 0.000000\t\tSpars: 0.001007\n",
      "\t TVw: 0.765817 | TVb: 2.281942 | GSw: -0.534536 | GSb: -0.193371 | TSUw: -0.425791 | TSUb: -0.037316\n",
      "\n",
      "Train Epoch: 5642 [4000/8000 (50%)]\tBatch Loss: 0.013402\tLearning Rate (w_theta): 0.001000\t TIME:2292.9s\n",
      "\t\t\t\tDisc: 0.012360\t\tSym: 0.000000\t\tSpars: 0.001041\n",
      "\t TVw: 0.765816 | TVb: 2.281768 | GSw: -0.534282 | GSb: -0.193076 | TSUw: -0.425193 | TSUb: -0.036706\n",
      "Validating epoch 5642...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012898693707839078\n",
      "Average validation loss: 0.01340753330641905\n",
      "Training epoch 5643...\n",
      "\n",
      "Train Epoch: 5643 [0/8000 (0%)]\tBatch Loss: 0.012723\tLearning Rate (w_theta): 0.001000\t TIME:2295.3s\n",
      "\t\t\t\tDisc: 0.011812\t\tSym: 0.000000\t\tSpars: 0.000911\n",
      "\t TVw: 0.765837 | TVb: 2.281718 | GSw: -0.534069 | GSb: -0.192840 | TSUw: -0.425062 | TSUb: -0.036557\n",
      "\n",
      "Train Epoch: 5643 [4000/8000 (50%)]\tBatch Loss: 0.012746\tLearning Rate (w_theta): 0.001000\t TIME:2296.6s\n",
      "\t\t\t\tDisc: 0.012041\t\tSym: 0.000000\t\tSpars: 0.000706\n",
      "\t TVw: 0.765872 | TVb: 2.281639 | GSw: -0.533872 | GSb: -0.192623 | TSUw: -0.425122 | TSUb: -0.036597\n",
      "Validating epoch 5643...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012898960482249103\n",
      "Average validation loss: 0.013411379651127863\n",
      "Training epoch 5644...\n",
      "\n",
      "Train Epoch: 5644 [0/8000 (0%)]\tBatch Loss: 0.013466\tLearning Rate (w_theta): 0.001000\t TIME:2298.8s\n",
      "\t\t\t\tDisc: 0.012225\t\tSym: 0.000000\t\tSpars: 0.001241\n",
      "\t TVw: 0.765881 | TVb: 2.281747 | GSw: -0.533766 | GSb: -0.192506 | TSUw: -0.426128 | TSUb: -0.037569\n",
      "\n",
      "Train Epoch: 5644 [4000/8000 (50%)]\tBatch Loss: 0.012931\tLearning Rate (w_theta): 0.001000\t TIME:2300.1s\n",
      "\t\t\t\tDisc: 0.012090\t\tSym: 0.000000\t\tSpars: 0.000840\n",
      "\t TVw: 0.766390 | TVb: 2.281970 | GSw: -0.533542 | GSb: -0.192258 | TSUw: -0.425825 | TSUb: -0.037249\n",
      "Validating epoch 5644...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012899931639910961\n",
      "Average validation loss: 0.013406027462239659\n",
      "Training epoch 5645...\n",
      "\n",
      "Train Epoch: 5645 [0/8000 (0%)]\tBatch Loss: 0.012531\tLearning Rate (w_theta): 0.001000\t TIME:2302.3s\n",
      "\t\t\t\tDisc: 0.011746\t\tSym: 0.000000\t\tSpars: 0.000785\n",
      "\t TVw: 0.766358 | TVb: 2.281863 | GSw: -0.533220 | GSb: -0.191899 | TSUw: -0.424486 | TSUb: -0.035905\n",
      "\n",
      "Train Epoch: 5645 [4000/8000 (50%)]\tBatch Loss: 0.013400\tLearning Rate (w_theta): 0.001000\t TIME:2303.6s\n",
      "\t\t\t\tDisc: 0.012417\t\tSym: 0.000000\t\tSpars: 0.000983\n",
      "\t TVw: 0.766167 | TVb: 2.281732 | GSw: -0.533003 | GSb: -0.191662 | TSUw: -0.424209 | TSUb: -0.035612\n",
      "Validating epoch 5645...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012903234287485382\n",
      "Average validation loss: 0.013410262360824184\n",
      "Training epoch 5646...\n",
      "\n",
      "Train Epoch: 5646 [0/8000 (0%)]\tBatch Loss: 0.013007\tLearning Rate (w_theta): 0.001000\t TIME:2305.9s\n",
      "\t\t\t\tDisc: 0.012122\t\tSym: 0.000000\t\tSpars: 0.000885\n",
      "\t TVw: 0.765912 | TVb: 2.281844 | GSw: -0.533057 | GSb: -0.191720 | TSUw: -0.426621 | TSUb: -0.037971\n",
      "\n",
      "Train Epoch: 5646 [4000/8000 (50%)]\tBatch Loss: 0.013682\tLearning Rate (w_theta): 0.001000\t TIME:2307.1s\n",
      "\t\t\t\tDisc: 0.012564\t\tSym: 0.000000\t\tSpars: 0.001117\n",
      "\t TVw: 0.765601 | TVb: 2.281878 | GSw: -0.532936 | GSb: -0.191583 | TSUw: -0.427002 | TSUb: -0.038322\n",
      "Validating epoch 5646...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01291054766983034\n",
      "Average validation loss: 0.013407741195691117\n",
      "Training epoch 5647...\n",
      "\n",
      "Train Epoch: 5647 [0/8000 (0%)]\tBatch Loss: 0.012297\tLearning Rate (w_theta): 0.001000\t TIME:2309.4s\n",
      "\t\t\t\tDisc: 0.011582\t\tSym: 0.000000\t\tSpars: 0.000715\n",
      "\t TVw: 0.765369 | TVb: 2.281641 | GSw: -0.532583 | GSb: -0.191190 | TSUw: -0.424832 | TSUb: -0.036150\n",
      "\n",
      "Train Epoch: 5647 [4000/8000 (50%)]\tBatch Loss: 0.012631\tLearning Rate (w_theta): 0.001000\t TIME:2310.7s\n",
      "\t\t\t\tDisc: 0.011615\t\tSym: 0.000000\t\tSpars: 0.001017\n",
      "\t TVw: 0.765334 | TVb: 2.281511 | GSw: -0.532428 | GSb: -0.191022 | TSUw: -0.424841 | TSUb: -0.036133\n",
      "Validating epoch 5647...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012901598232538818\n",
      "Average validation loss: 0.013408178230394417\n",
      "Training epoch 5648...\n",
      "\n",
      "Train Epoch: 5648 [0/8000 (0%)]\tBatch Loss: 0.012541\tLearning Rate (w_theta): 0.001000\t TIME:2312.9s\n",
      "\t\t\t\tDisc: 0.011853\t\tSym: 0.000000\t\tSpars: 0.000687\n",
      "\t TVw: 0.765410 | TVb: 2.281557 | GSw: -0.532322 | GSb: -0.190910 | TSUw: -0.425488 | TSUb: -0.036750\n",
      "\n",
      "Train Epoch: 5648 [4000/8000 (50%)]\tBatch Loss: 0.013240\tLearning Rate (w_theta): 0.001000\t TIME:2314.2s\n",
      "\t\t\t\tDisc: 0.012274\t\tSym: 0.000000\t\tSpars: 0.000967\n",
      "\t TVw: 0.765476 | TVb: 2.281680 | GSw: -0.532203 | GSb: -0.190784 | TSUw: -0.426134 | TSUb: -0.037367\n",
      "Validating epoch 5648...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012899824657237989\n",
      "Average validation loss: 0.013410544139940432\n",
      "Training epoch 5649...\n",
      "\n",
      "Train Epoch: 5649 [0/8000 (0%)]\tBatch Loss: 0.013143\tLearning Rate (w_theta): 0.001000\t TIME:2316.5s\n",
      "\t\t\t\tDisc: 0.012016\t\tSym: 0.000000\t\tSpars: 0.001128\n",
      "\t TVw: 0.765553 | TVb: 2.281732 | GSw: -0.531983 | GSb: -0.190543 | TSUw: -0.425806 | TSUb: -0.037022\n",
      "\n",
      "Train Epoch: 5649 [4000/8000 (50%)]\tBatch Loss: 0.013215\tLearning Rate (w_theta): 0.001000\t TIME:2317.8s\n",
      "\t\t\t\tDisc: 0.012569\t\tSym: 0.000000\t\tSpars: 0.000646\n",
      "\t TVw: 0.765622 | TVb: 2.281673 | GSw: -0.531713 | GSb: -0.190248 | TSUw: -0.425055 | TSUb: -0.036259\n",
      "Validating epoch 5649...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012900283359150413\n",
      "Average validation loss: 0.01340751600917496\n",
      "Training epoch 5650...\n",
      "\n",
      "Train Epoch: 5650 [0/8000 (0%)]\tBatch Loss: 0.013006\tLearning Rate (w_theta): 0.001000\t TIME:2320.0s\n",
      "\t\t\t\tDisc: 0.012251\t\tSym: 0.000000\t\tSpars: 0.000754\n",
      "\t TVw: 0.765552 | TVb: 2.281673 | GSw: -0.531526 | GSb: -0.190037 | TSUw: -0.425101 | TSUb: -0.036286\n",
      "\n",
      "Train Epoch: 5650 [4000/8000 (50%)]\tBatch Loss: 0.013189\tLearning Rate (w_theta): 0.001000\t TIME:2321.3s\n",
      "\t\t\t\tDisc: 0.012188\t\tSym: 0.000000\t\tSpars: 0.001001\n",
      "\t TVw: 0.765758 | TVb: 2.281786 | GSw: -0.531365 | GSb: -0.189857 | TSUw: -0.425426 | TSUb: -0.036588\n",
      "Validating epoch 5650...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012898580070559912\n",
      "Average validation loss: 0.013412605960763978\n",
      "Training epoch 5651...\n",
      "\n",
      "Train Epoch: 5651 [0/8000 (0%)]\tBatch Loss: 0.012943\tLearning Rate (w_theta): 0.001000\t TIME:2324.1s\n",
      "\t\t\t\tDisc: 0.012173\t\tSym: 0.000000\t\tSpars: 0.000769\n",
      "\t TVw: 0.765511 | TVb: 2.281753 | GSw: -0.531261 | GSb: -0.189744 | TSUw: -0.426405 | TSUb: -0.037537\n",
      "\n",
      "Train Epoch: 5651 [4000/8000 (50%)]\tBatch Loss: 0.012573\tLearning Rate (w_theta): 0.001000\t TIME:2325.4s\n",
      "\t\t\t\tDisc: 0.011652\t\tSym: 0.000000\t\tSpars: 0.000922\n",
      "\t TVw: 0.765578 | TVb: 2.281774 | GSw: -0.531060 | GSb: -0.189530 | TSUw: -0.426399 | TSUb: -0.037510\n",
      "Validating epoch 5651...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012900151620487283\n",
      "Average validation loss: 0.013408481408578237\n",
      "Training epoch 5652...\n",
      "\n",
      "Train Epoch: 5652 [0/8000 (0%)]\tBatch Loss: 0.012947\tLearning Rate (w_theta): 0.001000\t TIME:2327.7s\n",
      "\t\t\t\tDisc: 0.012388\t\tSym: 0.000000\t\tSpars: 0.000559\n",
      "\t TVw: 0.765381 | TVb: 2.281583 | GSw: -0.530753 | GSb: -0.189191 | TSUw: -0.425286 | TSUb: -0.036388\n",
      "\n",
      "Train Epoch: 5652 [4000/8000 (50%)]\tBatch Loss: 0.012749\tLearning Rate (w_theta): 0.001000\t TIME:2329.0s\n",
      "\t\t\t\tDisc: 0.011841\t\tSym: 0.000000\t\tSpars: 0.000908\n",
      "\t TVw: 0.764559 | TVb: 2.281173 | GSw: -0.530535 | GSb: -0.188947 | TSUw: -0.424995 | TSUb: -0.036080\n",
      "Validating epoch 5652...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012908023854406462\n",
      "Average validation loss: 0.013414511695080728\n",
      "Training epoch 5653...\n",
      "\n",
      "Train Epoch: 5653 [0/8000 (0%)]\tBatch Loss: 0.012991\tLearning Rate (w_theta): 0.001000\t TIME:2331.2s\n",
      "\t\t\t\tDisc: 0.012205\t\tSym: 0.000000\t\tSpars: 0.000786\n",
      "\t TVw: 0.764739 | TVb: 2.281382 | GSw: -0.530482 | GSb: -0.188892 | TSUw: -0.426203 | TSUb: -0.037254\n",
      "\n",
      "Train Epoch: 5653 [4000/8000 (50%)]\tBatch Loss: 0.013436\tLearning Rate (w_theta): 0.001000\t TIME:2332.4s\n",
      "\t\t\t\tDisc: 0.012563\t\tSym: 0.000000\t\tSpars: 0.000873\n",
      "\t TVw: 0.765213 | TVb: 2.281558 | GSw: -0.530257 | GSb: -0.188643 | TSUw: -0.425778 | TSUb: -0.036813\n",
      "Validating epoch 5653...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012901408771642177\n",
      "Average validation loss: 0.013410024304184358\n",
      "Training epoch 5654...\n",
      "\n",
      "Train Epoch: 5654 [0/8000 (0%)]\tBatch Loss: 0.013400\tLearning Rate (w_theta): 0.001000\t TIME:2334.7s\n",
      "\t\t\t\tDisc: 0.012296\t\tSym: 0.000000\t\tSpars: 0.001104\n",
      "\t TVw: 0.765479 | TVb: 2.281647 | GSw: -0.530076 | GSb: -0.188444 | TSUw: -0.425881 | TSUb: -0.036896\n",
      "\n",
      "Train Epoch: 5654 [4000/8000 (50%)]\tBatch Loss: 0.013093\tLearning Rate (w_theta): 0.001000\t TIME:2336.0s\n",
      "\t\t\t\tDisc: 0.012394\t\tSym: 0.000000\t\tSpars: 0.000700\n",
      "\t TVw: 0.766100 | TVb: 2.281756 | GSw: -0.529896 | GSb: -0.188241 | TSUw: -0.426048 | TSUb: -0.037043\n",
      "Validating epoch 5654...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012900587416996883\n",
      "Average validation loss: 0.013407926191689193\n",
      "Training epoch 5655...\n",
      "\n",
      "Train Epoch: 5655 [0/8000 (0%)]\tBatch Loss: 0.012821\tLearning Rate (w_theta): 0.001000\t TIME:2338.2s\n",
      "\t\t\t\tDisc: 0.012082\t\tSym: 0.000000\t\tSpars: 0.000738\n",
      "\t TVw: 0.766078 | TVb: 2.281759 | GSw: -0.529653 | GSb: -0.187976 | TSUw: -0.425582 | TSUb: -0.036562\n",
      "\n",
      "Train Epoch: 5655 [4000/8000 (50%)]\tBatch Loss: 0.012671\tLearning Rate (w_theta): 0.001000\t TIME:2339.5s\n",
      "\t\t\t\tDisc: 0.012062\t\tSym: 0.000000\t\tSpars: 0.000609\n",
      "\t TVw: 0.765892 | TVb: 2.281817 | GSw: -0.529470 | GSb: -0.187786 | TSUw: -0.425740 | TSUb: -0.036699\n",
      "Validating epoch 5655...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012898953092549813\n",
      "Average validation loss: 0.013409579651047776\n",
      "Training epoch 5656...\n",
      "\n",
      "Train Epoch: 5656 [0/8000 (0%)]\tBatch Loss: 0.012971\tLearning Rate (w_theta): 0.001000\t TIME:2341.8s\n",
      "\t\t\t\tDisc: 0.012134\t\tSym: 0.000000\t\tSpars: 0.000837\n",
      "\t TVw: 0.765720 | TVb: 2.281759 | GSw: -0.529314 | GSb: -0.187617 | TSUw: -0.426214 | TSUb: -0.037149\n",
      "\n",
      "Train Epoch: 5656 [4000/8000 (50%)]\tBatch Loss: 0.012330\tLearning Rate (w_theta): 0.001000\t TIME:2343.0s\n",
      "\t\t\t\tDisc: 0.011664\t\tSym: 0.000000\t\tSpars: 0.000666\n",
      "\t TVw: 0.765388 | TVb: 2.281640 | GSw: -0.529106 | GSb: -0.187390 | TSUw: -0.426162 | TSUb: -0.037079\n",
      "Validating epoch 5656...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012900110136003685\n",
      "Average validation loss: 0.013409498596692134\n",
      "Training epoch 5657...\n",
      "\n",
      "Train Epoch: 5657 [0/8000 (0%)]\tBatch Loss: 0.012235\tLearning Rate (w_theta): 0.001000\t TIME:2345.2s\n",
      "\t\t\t\tDisc: 0.011557\t\tSym: 0.000000\t\tSpars: 0.000679\n",
      "\t TVw: 0.765181 | TVb: 2.281466 | GSw: -0.528856 | GSb: -0.187114 | TSUw: -0.425716 | TSUb: -0.036619\n",
      "\n",
      "Train Epoch: 5657 [4000/8000 (50%)]\tBatch Loss: 0.013270\tLearning Rate (w_theta): 0.001000\t TIME:2346.5s\n",
      "\t\t\t\tDisc: 0.012126\t\tSym: 0.000000\t\tSpars: 0.001144\n",
      "\t TVw: 0.765884 | TVb: 2.281775 | GSw: -0.528678 | GSb: -0.186912 | TSUw: -0.425976 | TSUb: -0.036859\n",
      "Validating epoch 5657...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012900372839078402\n",
      "Average validation loss: 0.013408502747459253\n",
      "Training epoch 5658...\n",
      "\n",
      "Train Epoch: 5658 [0/8000 (0%)]\tBatch Loss: 0.013504\tLearning Rate (w_theta): 0.001000\t TIME:2348.8s\n",
      "\t\t\t\tDisc: 0.012479\t\tSym: 0.000000\t\tSpars: 0.001025\n",
      "\t TVw: 0.766168 | TVb: 2.281902 | GSw: -0.528466 | GSb: -0.186679 | TSUw: -0.425920 | TSUb: -0.036785\n",
      "\n",
      "Train Epoch: 5658 [4000/8000 (50%)]\tBatch Loss: 0.012718\tLearning Rate (w_theta): 0.001000\t TIME:2350.0s\n",
      "\t\t\t\tDisc: 0.011937\t\tSym: 0.000000\t\tSpars: 0.000782\n",
      "\t TVw: 0.766626 | TVb: 2.282134 | GSw: -0.528288 | GSb: -0.186484 | TSUw: -0.426199 | TSUb: -0.037045\n",
      "Validating epoch 5658...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01289940857567685\n",
      "Average validation loss: 0.013407821695222893\n",
      "Training epoch 5659...\n",
      "\n",
      "Train Epoch: 5659 [0/8000 (0%)]\tBatch Loss: 0.012680\tLearning Rate (w_theta): 0.001000\t TIME:2352.3s\n",
      "\t\t\t\tDisc: 0.012138\t\tSym: 0.000000\t\tSpars: 0.000542\n",
      "\t TVw: 0.766169 | TVb: 2.281960 | GSw: -0.528037 | GSb: -0.186209 | TSUw: -0.425741 | TSUb: -0.036572\n",
      "\n",
      "Train Epoch: 5659 [4000/8000 (50%)]\tBatch Loss: 0.012606\tLearning Rate (w_theta): 0.001000\t TIME:2353.6s\n",
      "\t\t\t\tDisc: 0.011758\t\tSym: 0.000000\t\tSpars: 0.000848\n",
      "\t TVw: 0.765577 | TVb: 2.281826 | GSw: -0.527815 | GSb: -0.185977 | TSUw: -0.425548 | TSUb: -0.036362\n",
      "Validating epoch 5659...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012900075120709814\n",
      "Average validation loss: 0.013411693640590765\n",
      "Training epoch 5660...\n",
      "\n",
      "Train Epoch: 5660 [0/8000 (0%)]\tBatch Loss: 0.013053\tLearning Rate (w_theta): 0.001000\t TIME:2355.8s\n",
      "\t\t\t\tDisc: 0.012182\t\tSym: 0.000000\t\tSpars: 0.000871\n",
      "\t TVw: 0.765529 | TVb: 2.281812 | GSw: -0.527710 | GSb: -0.185865 | TSUw: -0.426479 | TSUb: -0.037268\n",
      "\n",
      "Train Epoch: 5660 [4000/8000 (50%)]\tBatch Loss: 0.012995\tLearning Rate (w_theta): 0.001000\t TIME:2357.1s\n",
      "\t\t\t\tDisc: 0.012433\t\tSym: 0.000000\t\tSpars: 0.000562\n",
      "\t TVw: 0.765244 | TVb: 2.281553 | GSw: -0.527495 | GSb: -0.185628 | TSUw: -0.426358 | TSUb: -0.037129\n",
      "Validating epoch 5660...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0129006667876823\n",
      "Average validation loss: 0.013412771324169858\n",
      "Training epoch 5661...\n",
      "\n",
      "Train Epoch: 5661 [0/8000 (0%)]\tBatch Loss: 0.012884\tLearning Rate (w_theta): 0.001000\t TIME:2360.1s\n",
      "\t\t\t\tDisc: 0.011832\t\tSym: 0.000000\t\tSpars: 0.001052\n",
      "\t TVw: 0.765371 | TVb: 2.281525 | GSw: -0.527309 | GSb: -0.185427 | TSUw: -0.426541 | TSUb: -0.037293\n",
      "\n",
      "Train Epoch: 5661 [4000/8000 (50%)]\tBatch Loss: 0.012749\tLearning Rate (w_theta): 0.001000\t TIME:2361.4s\n",
      "\t\t\t\tDisc: 0.011990\t\tSym: 0.000000\t\tSpars: 0.000758\n",
      "\t TVw: 0.766053 | TVb: 2.281570 | GSw: -0.527088 | GSb: -0.185191 | TSUw: -0.426403 | TSUb: -0.037139\n",
      "Validating epoch 5661...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012899932063151934\n",
      "Average validation loss: 0.01340896599948955\n",
      "Training epoch 5662...\n",
      "\n",
      "Train Epoch: 5662 [0/8000 (0%)]\tBatch Loss: 0.012935\tLearning Rate (w_theta): 0.001000\t TIME:2363.5s\n",
      "\t\t\t\tDisc: 0.012006\t\tSym: 0.000000\t\tSpars: 0.000929\n",
      "\t TVw: 0.766386 | TVb: 2.281687 | GSw: -0.526848 | GSb: -0.184932 | TSUw: -0.426051 | TSUb: -0.036771\n",
      "\n",
      "Train Epoch: 5662 [4000/8000 (50%)]\tBatch Loss: 0.012578\tLearning Rate (w_theta): 0.001000\t TIME:2364.8s\n",
      "\t\t\t\tDisc: 0.011857\t\tSym: 0.000000\t\tSpars: 0.000721\n",
      "\t TVw: 0.766692 | TVb: 2.281842 | GSw: -0.526637 | GSb: -0.184708 | TSUw: -0.425989 | TSUb: -0.036691\n",
      "Validating epoch 5662...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012901333695213003\n",
      "Average validation loss: 0.013410455246185265\n",
      "Training epoch 5663...\n",
      "\n",
      "Train Epoch: 5663 [0/8000 (0%)]\tBatch Loss: 0.013167\tLearning Rate (w_theta): 0.001000\t TIME:2367.0s\n",
      "\t\t\t\tDisc: 0.012324\t\tSym: 0.000000\t\tSpars: 0.000843\n",
      "\t TVw: 0.766935 | TVb: 2.281969 | GSw: -0.526477 | GSb: -0.184536 | TSUw: -0.426381 | TSUb: -0.037062\n",
      "\n",
      "Train Epoch: 5663 [4000/8000 (50%)]\tBatch Loss: 0.013261\tLearning Rate (w_theta): 0.001000\t TIME:2368.3s\n",
      "\t\t\t\tDisc: 0.012374\t\tSym: 0.000000\t\tSpars: 0.000887\n",
      "\t TVw: 0.766928 | TVb: 2.281957 | GSw: -0.526259 | GSb: -0.184304 | TSUw: -0.426229 | TSUb: -0.036893\n",
      "Validating epoch 5663...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012898368438678184\n",
      "Average validation loss: 0.013407589562172138\n",
      "Training epoch 5664...\n",
      "\n",
      "Train Epoch: 5664 [0/8000 (0%)]\tBatch Loss: 0.013258\tLearning Rate (w_theta): 0.001000\t TIME:2370.5s\n",
      "\t\t\t\tDisc: 0.012390\t\tSym: 0.000000\t\tSpars: 0.000868\n",
      "\t TVw: 0.766929 | TVb: 2.281979 | GSw: -0.526032 | GSb: -0.184058 | TSUw: -0.426005 | TSUb: -0.036653\n",
      "\n",
      "Train Epoch: 5664 [4000/8000 (50%)]\tBatch Loss: 0.012791\tLearning Rate (w_theta): 0.001000\t TIME:2371.8s\n",
      "\t\t\t\tDisc: 0.011943\t\tSym: 0.000000\t\tSpars: 0.000848\n",
      "\t TVw: 0.766895 | TVb: 2.282058 | GSw: -0.525921 | GSb: -0.183948 | TSUw: -0.426889 | TSUb: -0.037511\n",
      "Validating epoch 5664...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012901080078296765\n",
      "Average validation loss: 0.013410683480750312\n",
      "Training epoch 5665...\n",
      "\n",
      "Train Epoch: 5665 [0/8000 (0%)]\tBatch Loss: 0.013516\tLearning Rate (w_theta): 0.001000\t TIME:2374.1s\n",
      "\t\t\t\tDisc: 0.012537\t\tSym: 0.000000\t\tSpars: 0.000979\n",
      "\t TVw: 0.766593 | TVb: 2.281920 | GSw: -0.525660 | GSb: -0.183662 | TSUw: -0.426283 | TSUb: -0.036891\n",
      "\n",
      "Train Epoch: 5665 [4000/8000 (50%)]\tBatch Loss: 0.012768\tLearning Rate (w_theta): 0.001000\t TIME:2375.4s\n",
      "\t\t\t\tDisc: 0.011928\t\tSym: 0.000000\t\tSpars: 0.000840\n",
      "\t TVw: 0.766128 | TVb: 2.281724 | GSw: -0.525374 | GSb: -0.183347 | TSUw: -0.425442 | TSUb: -0.036038\n",
      "Validating epoch 5665...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012902319647913899\n",
      "Average validation loss: 0.013409218183519422\n",
      "Training epoch 5666...\n",
      "\n",
      "Train Epoch: 5666 [0/8000 (0%)]\tBatch Loss: 0.012797\tLearning Rate (w_theta): 0.001000\t TIME:2377.6s\n",
      "\t\t\t\tDisc: 0.011888\t\tSym: 0.000000\t\tSpars: 0.000910\n",
      "\t TVw: 0.765984 | TVb: 2.281700 | GSw: -0.525304 | GSb: -0.183276 | TSUw: -0.426589 | TSUb: -0.037157\n",
      "\n",
      "Train Epoch: 5666 [4000/8000 (50%)]\tBatch Loss: 0.012998\tLearning Rate (w_theta): 0.001000\t TIME:2378.9s\n",
      "\t\t\t\tDisc: 0.012170\t\tSym: 0.000000\t\tSpars: 0.000828\n",
      "\t TVw: 0.765785 | TVb: 2.281727 | GSw: -0.525193 | GSb: -0.183169 | TSUw: -0.427346 | TSUb: -0.037888\n",
      "Validating epoch 5666...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012903943802467528\n",
      "Average validation loss: 0.013411605205585958\n",
      "Training epoch 5667...\n",
      "\n",
      "Train Epoch: 5667 [0/8000 (0%)]\tBatch Loss: 0.013074\tLearning Rate (w_theta): 0.001000\t TIME:2381.2s\n",
      "\t\t\t\tDisc: 0.012079\t\tSym: 0.000000\t\tSpars: 0.000995\n",
      "\t TVw: 0.765828 | TVb: 2.281608 | GSw: -0.524873 | GSb: -0.182825 | TSUw: -0.426038 | TSUb: -0.036570\n",
      "\n",
      "Train Epoch: 5667 [4000/8000 (50%)]\tBatch Loss: 0.012574\tLearning Rate (w_theta): 0.001000\t TIME:2382.5s\n",
      "\t\t\t\tDisc: 0.012017\t\tSym: 0.000000\t\tSpars: 0.000558\n",
      "\t TVw: 0.766189 | TVb: 2.281576 | GSw: -0.524655 | GSb: -0.182589 | TSUw: -0.425662 | TSUb: -0.036179\n",
      "Validating epoch 5667...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01290483636485276\n",
      "Average validation loss: 0.01341047170334504\n",
      "Training epoch 5668...\n",
      "\n",
      "Train Epoch: 5668 [0/8000 (0%)]\tBatch Loss: 0.012925\tLearning Rate (w_theta): 0.001000\t TIME:2384.7s\n",
      "\t\t\t\tDisc: 0.012229\t\tSym: 0.000000\t\tSpars: 0.000696\n",
      "\t TVw: 0.766087 | TVb: 2.281602 | GSw: -0.524577 | GSb: -0.182514 | TSUw: -0.426595 | TSUb: -0.037085\n",
      "\n",
      "Train Epoch: 5668 [4000/8000 (50%)]\tBatch Loss: 0.012847\tLearning Rate (w_theta): 0.001000\t TIME:2386.0s\n",
      "\t\t\t\tDisc: 0.012135\t\tSym: 0.000000\t\tSpars: 0.000712\n",
      "\t TVw: 0.765551 | TVb: 2.281403 | GSw: -0.524389 | GSb: -0.182317 | TSUw: -0.426566 | TSUb: -0.037036\n",
      "Validating epoch 5668...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012901132775700574\n",
      "Average validation loss: 0.01341125792950329\n",
      "Training epoch 5669...\n",
      "\n",
      "Train Epoch: 5669 [0/8000 (0%)]\tBatch Loss: 0.013123\tLearning Rate (w_theta): 0.001000\t TIME:2388.3s\n",
      "\t\t\t\tDisc: 0.012325\t\tSym: 0.000000\t\tSpars: 0.000797\n",
      "\t TVw: 0.765564 | TVb: 2.281460 | GSw: -0.524181 | GSb: -0.182094 | TSUw: -0.426429 | TSUb: -0.036882\n",
      "\n",
      "Train Epoch: 5669 [4000/8000 (50%)]\tBatch Loss: 0.012689\tLearning Rate (w_theta): 0.001000\t TIME:2389.6s\n",
      "\t\t\t\tDisc: 0.012104\t\tSym: 0.000000\t\tSpars: 0.000585\n",
      "\t TVw: 0.765043 | TVb: 2.281389 | GSw: -0.523926 | GSb: -0.181823 | TSUw: -0.425932 | TSUb: -0.036369\n",
      "Validating epoch 5669...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012903629552722992\n",
      "Average validation loss: 0.013412968257325367\n",
      "Training epoch 5670...\n",
      "\n",
      "Train Epoch: 5670 [0/8000 (0%)]\tBatch Loss: 0.012620\tLearning Rate (w_theta): 0.001000\t TIME:2391.9s\n",
      "\t\t\t\tDisc: 0.011956\t\tSym: 0.000000\t\tSpars: 0.000664\n",
      "\t TVw: 0.765165 | TVb: 2.281530 | GSw: -0.523864 | GSb: -0.181763 | TSUw: -0.427191 | TSUb: -0.037602\n",
      "\n",
      "Train Epoch: 5670 [4000/8000 (50%)]\tBatch Loss: 0.012959\tLearning Rate (w_theta): 0.001000\t TIME:2393.3s\n",
      "\t\t\t\tDisc: 0.012116\t\tSym: 0.000000\t\tSpars: 0.000843\n",
      "\t TVw: 0.765219 | TVb: 2.281527 | GSw: -0.523703 | GSb: -0.181598 | TSUw: -0.427494 | TSUb: -0.037883\n",
      "Validating epoch 5670...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012904895131688679\n",
      "Average validation loss: 0.013410397783631758\n",
      "Training epoch 5671...\n",
      "\n",
      "Train Epoch: 5671 [0/8000 (0%)]\tBatch Loss: 0.012588\tLearning Rate (w_theta): 0.001000\t TIME:2396.3s\n",
      "\t\t\t\tDisc: 0.011937\t\tSym: 0.000000\t\tSpars: 0.000651\n",
      "\t TVw: 0.765673 | TVb: 2.281516 | GSw: -0.523364 | GSb: -0.181231 | TSUw: -0.426013 | TSUb: -0.036393\n",
      "\n",
      "Train Epoch: 5671 [4000/8000 (50%)]\tBatch Loss: 0.012288\tLearning Rate (w_theta): 0.001000\t TIME:2397.6s\n",
      "\t\t\t\tDisc: 0.011757\t\tSym: 0.000000\t\tSpars: 0.000531\n",
      "\t TVw: 0.766157 | TVb: 2.281597 | GSw: -0.523236 | GSb: -0.181096 | TSUw: -0.426489 | TSUb: -0.036847\n",
      "Validating epoch 5671...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012904796567705256\n",
      "Average validation loss: 0.013411274792424209\n",
      "Training epoch 5672...\n",
      "\n",
      "Train Epoch: 5672 [0/8000 (0%)]\tBatch Loss: 0.013147\tLearning Rate (w_theta): 0.001000\t TIME:2399.9s\n",
      "\t\t\t\tDisc: 0.012293\t\tSym: 0.000000\t\tSpars: 0.000854\n",
      "\t TVw: 0.766427 | TVb: 2.281664 | GSw: -0.523062 | GSb: -0.180910 | TSUw: -0.426581 | TSUb: -0.036920\n",
      "\n",
      "Train Epoch: 5672 [4000/8000 (50%)]\tBatch Loss: 0.012508\tLearning Rate (w_theta): 0.001000\t TIME:2401.1s\n",
      "\t\t\t\tDisc: 0.011671\t\tSym: 0.000000\t\tSpars: 0.000838\n",
      "\t TVw: 0.766286 | TVb: 2.281592 | GSw: -0.522852 | GSb: -0.180682 | TSUw: -0.426385 | TSUb: -0.036707\n",
      "Validating epoch 5672...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012902251940408454\n",
      "Average validation loss: 0.013411493856306847\n",
      "Training epoch 5673...\n",
      "\n",
      "Train Epoch: 5673 [0/8000 (0%)]\tBatch Loss: 0.012857\tLearning Rate (w_theta): 0.001000\t TIME:2403.4s\n",
      "\t\t\t\tDisc: 0.012285\t\tSym: 0.000000\t\tSpars: 0.000572\n",
      "\t TVw: 0.766441 | TVb: 2.281641 | GSw: -0.522685 | GSb: -0.180507 | TSUw: -0.426608 | TSUb: -0.036912\n",
      "\n",
      "Train Epoch: 5673 [4000/8000 (50%)]\tBatch Loss: 0.013262\tLearning Rate (w_theta): 0.001000\t TIME:2404.7s\n",
      "\t\t\t\tDisc: 0.012355\t\tSym: 0.000000\t\tSpars: 0.000907\n",
      "\t TVw: 0.766106 | TVb: 2.281568 | GSw: -0.522495 | GSb: -0.180305 | TSUw: -0.426643 | TSUb: -0.036928\n",
      "Validating epoch 5673...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012901732176436982\n",
      "Average validation loss: 0.013413181801314468\n",
      "Training epoch 5674...\n",
      "\n",
      "Train Epoch: 5674 [0/8000 (0%)]\tBatch Loss: 0.012758\tLearning Rate (w_theta): 0.001000\t TIME:2407.1s\n",
      "\t\t\t\tDisc: 0.011906\t\tSym: 0.000000\t\tSpars: 0.000852\n",
      "\t TVw: 0.766121 | TVb: 2.281660 | GSw: -0.522340 | GSb: -0.180149 | TSUw: -0.427050 | TSUb: -0.037315\n",
      "\n",
      "Train Epoch: 5674 [4000/8000 (50%)]\tBatch Loss: 0.013076\tLearning Rate (w_theta): 0.001000\t TIME:2408.4s\n",
      "\t\t\t\tDisc: 0.012280\t\tSym: 0.000000\t\tSpars: 0.000796\n",
      "\t TVw: 0.765567 | TVb: 2.281616 | GSw: -0.522104 | GSb: -0.179907 | TSUw: -0.426725 | TSUb: -0.036973\n",
      "Validating epoch 5674...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012901846407265223\n",
      "Average validation loss: 0.013411599072084524\n",
      "Training epoch 5675...\n",
      "\n",
      "Train Epoch: 5675 [0/8000 (0%)]\tBatch Loss: 0.012907\tLearning Rate (w_theta): 0.001000\t TIME:2410.7s\n",
      "\t\t\t\tDisc: 0.012251\t\tSym: 0.000000\t\tSpars: 0.000656\n",
      "\t TVw: 0.766163 | TVb: 2.281723 | GSw: -0.521889 | GSb: -0.179680 | TSUw: -0.426595 | TSUb: -0.036828\n",
      "\n",
      "Train Epoch: 5675 [4000/8000 (50%)]\tBatch Loss: 0.012000\tLearning Rate (w_theta): 0.001000\t TIME:2412.0s\n",
      "\t\t\t\tDisc: 0.011420\t\tSym: 0.000000\t\tSpars: 0.000579\n",
      "\t TVw: 0.766458 | TVb: 2.281817 | GSw: -0.521650 | GSb: -0.179419 | TSUw: -0.426194 | TSUb: -0.036412\n",
      "Validating epoch 5675...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012903620605893907\n",
      "Average validation loss: 0.013411784563052169\n",
      "Training epoch 5676...\n",
      "\n",
      "Train Epoch: 5676 [0/8000 (0%)]\tBatch Loss: 0.012348\tLearning Rate (w_theta): 0.001000\t TIME:2414.2s\n",
      "\t\t\t\tDisc: 0.011627\t\tSym: 0.000000\t\tSpars: 0.000721\n",
      "\t TVw: 0.766321 | TVb: 2.281774 | GSw: -0.521578 | GSb: -0.179356 | TSUw: -0.427305 | TSUb: -0.037499\n",
      "\n",
      "Train Epoch: 5676 [4000/8000 (50%)]\tBatch Loss: 0.012648\tLearning Rate (w_theta): 0.001000\t TIME:2415.5s\n",
      "\t\t\t\tDisc: 0.011839\t\tSym: 0.000000\t\tSpars: 0.000809\n",
      "\t TVw: 0.766463 | TVb: 2.281904 | GSw: -0.521420 | GSb: -0.179195 | TSUw: -0.427639 | TSUb: -0.037814\n",
      "Validating epoch 5676...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012902323161734461\n",
      "Average validation loss: 0.013410482988724501\n",
      "Training epoch 5677...\n",
      "\n",
      "Train Epoch: 5677 [0/8000 (0%)]\tBatch Loss: 0.013391\tLearning Rate (w_theta): 0.001000\t TIME:2417.7s\n",
      "\t\t\t\tDisc: 0.012647\t\tSym: 0.000000\t\tSpars: 0.000744\n",
      "\t TVw: 0.766648 | TVb: 2.281852 | GSw: -0.521093 | GSb: -0.178843 | TSUw: -0.426374 | TSUb: -0.036538\n",
      "\n",
      "Train Epoch: 5677 [4000/8000 (50%)]\tBatch Loss: 0.012064\tLearning Rate (w_theta): 0.001000\t TIME:2419.0s\n",
      "\t\t\t\tDisc: 0.011358\t\tSym: 0.000000\t\tSpars: 0.000707\n",
      "\t TVw: 0.767355 | TVb: 2.281978 | GSw: -0.520903 | GSb: -0.178642 | TSUw: -0.426255 | TSUb: -0.036403\n",
      "Validating epoch 5677...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012905894871199704\n",
      "Average validation loss: 0.013412090950738082\n",
      "Training epoch 5678...\n",
      "\n",
      "Train Epoch: 5678 [0/8000 (0%)]\tBatch Loss: 0.012529\tLearning Rate (w_theta): 0.001000\t TIME:2421.4s\n",
      "\t\t\t\tDisc: 0.011774\t\tSym: 0.000000\t\tSpars: 0.000755\n",
      "\t TVw: 0.767551 | TVb: 2.282064 | GSw: -0.520850 | GSb: -0.178601 | TSUw: -0.427354 | TSUb: -0.037478\n",
      "\n",
      "Train Epoch: 5678 [4000/8000 (50%)]\tBatch Loss: 0.012589\tLearning Rate (w_theta): 0.001000\t TIME:2422.6s\n",
      "\t\t\t\tDisc: 0.011824\t\tSym: 0.000000\t\tSpars: 0.000766\n",
      "\t TVw: 0.767080 | TVb: 2.281904 | GSw: -0.520634 | GSb: -0.178374 | TSUw: -0.427069 | TSUb: -0.037176\n",
      "Validating epoch 5678...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012901047659285663\n",
      "Average validation loss: 0.013409813024119794\n",
      "Training epoch 5679...\n",
      "\n",
      "Train Epoch: 5679 [0/8000 (0%)]\tBatch Loss: 0.012743\tLearning Rate (w_theta): 0.001000\t TIME:2424.9s\n",
      "\t\t\t\tDisc: 0.012022\t\tSym: 0.000000\t\tSpars: 0.000720\n",
      "\t TVw: 0.766853 | TVb: 2.281852 | GSw: -0.520407 | GSb: -0.178136 | TSUw: -0.426723 | TSUb: -0.036814\n",
      "\n",
      "Train Epoch: 5679 [4000/8000 (50%)]\tBatch Loss: 0.012638\tLearning Rate (w_theta): 0.001000\t TIME:2426.1s\n",
      "\t\t\t\tDisc: 0.011955\t\tSym: 0.000000\t\tSpars: 0.000682\n",
      "\t TVw: 0.766804 | TVb: 2.281890 | GSw: -0.520193 | GSb: -0.177912 | TSUw: -0.426549 | TSUb: -0.036624\n",
      "Validating epoch 5679...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012900949447589204\n",
      "Average validation loss: 0.013411388337042762\n",
      "Training epoch 5680...\n",
      "\n",
      "Train Epoch: 5680 [0/8000 (0%)]\tBatch Loss: 0.013214\tLearning Rate (w_theta): 0.001000\t TIME:2428.4s\n",
      "\t\t\t\tDisc: 0.012092\t\tSym: 0.000000\t\tSpars: 0.001121\n",
      "\t TVw: 0.766792 | TVb: 2.281907 | GSw: -0.520099 | GSb: -0.177822 | TSUw: -0.427462 | TSUb: -0.037517\n",
      "\n",
      "Train Epoch: 5680 [4000/8000 (50%)]\tBatch Loss: 0.012532\tLearning Rate (w_theta): 0.001000\t TIME:2429.7s\n",
      "\t\t\t\tDisc: 0.012022\t\tSym: 0.000000\t\tSpars: 0.000510\n",
      "\t TVw: 0.767898 | TVb: 2.282400 | GSw: -0.520027 | GSb: -0.177756 | TSUw: -0.428512 | TSUb: -0.038544\n",
      "Validating epoch 5680...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012909516066585136\n",
      "Average validation loss: 0.013408106303357325\n",
      "Training epoch 5681...\n",
      "\n",
      "Train Epoch: 5681 [0/8000 (0%)]\tBatch Loss: 0.012987\tLearning Rate (w_theta): 0.001000\t TIME:2432.6s\n",
      "\t\t\t\tDisc: 0.012237\t\tSym: 0.000000\t\tSpars: 0.000750\n",
      "\t TVw: 0.767703 | TVb: 2.282083 | GSw: -0.519580 | GSb: -0.177275 | TSUw: -0.425894 | TSUb: -0.035919\n",
      "\n",
      "Train Epoch: 5681 [4000/8000 (50%)]\tBatch Loss: 0.012691\tLearning Rate (w_theta): 0.001000\t TIME:2433.9s\n",
      "\t\t\t\tDisc: 0.011908\t\tSym: 0.000000\t\tSpars: 0.000783\n",
      "\t TVw: 0.767758 | TVb: 2.282120 | GSw: -0.519425 | GSb: -0.177114 | TSUw: -0.425685 | TSUb: -0.035690\n",
      "Validating epoch 5681...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012909388667489344\n",
      "Average validation loss: 0.013410268744173816\n",
      "Training epoch 5682...\n",
      "\n",
      "Train Epoch: 5682 [0/8000 (0%)]\tBatch Loss: 0.012698\tLearning Rate (w_theta): 0.001000\t TIME:2436.1s\n",
      "\t\t\t\tDisc: 0.011988\t\tSym: 0.000000\t\tSpars: 0.000711\n",
      "\t TVw: 0.767521 | TVb: 2.282155 | GSw: -0.519512 | GSb: -0.177229 | TSUw: -0.427576 | TSUb: -0.037549\n",
      "\n",
      "Train Epoch: 5682 [4000/8000 (50%)]\tBatch Loss: 0.012976\tLearning Rate (w_theta): 0.001000\t TIME:2437.4s\n",
      "\t\t\t\tDisc: 0.012174\t\tSym: 0.000000\t\tSpars: 0.000802\n",
      "\t TVw: 0.767386 | TVb: 2.282190 | GSw: -0.519436 | GSb: -0.177163 | TSUw: -0.428199 | TSUb: -0.038148\n",
      "Validating epoch 5682...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012904090960285518\n",
      "Average validation loss: 0.013411238282772986\n",
      "Training epoch 5683...\n",
      "\n",
      "Train Epoch: 5683 [0/8000 (0%)]\tBatch Loss: 0.012676\tLearning Rate (w_theta): 0.001000\t TIME:2439.7s\n",
      "\t\t\t\tDisc: 0.011918\t\tSym: 0.000000\t\tSpars: 0.000758\n",
      "\t TVw: 0.767175 | TVb: 2.282005 | GSw: -0.519122 | GSb: -0.176836 | TSUw: -0.426762 | TSUb: -0.036697\n",
      "\n",
      "Train Epoch: 5683 [4000/8000 (50%)]\tBatch Loss: 0.013329\tLearning Rate (w_theta): 0.001000\t TIME:2441.0s\n",
      "\t\t\t\tDisc: 0.012224\t\tSym: 0.000000\t\tSpars: 0.001105\n",
      "\t TVw: 0.766612 | TVb: 2.281644 | GSw: -0.518865 | GSb: -0.176578 | TSUw: -0.425890 | TSUb: -0.035810\n",
      "Validating epoch 5683...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012907161034986223\n",
      "Average validation loss: 0.013410461065225306\n",
      "Training epoch 5684...\n",
      "\n",
      "Train Epoch: 5684 [0/8000 (0%)]\tBatch Loss: 0.013079\tLearning Rate (w_theta): 0.001000\t TIME:2443.4s\n",
      "\t\t\t\tDisc: 0.012090\t\tSym: 0.000000\t\tSpars: 0.000988\n",
      "\t TVw: 0.766625 | TVb: 2.281799 | GSw: -0.518892 | GSb: -0.176626 | TSUw: -0.427344 | TSUb: -0.037237\n",
      "\n",
      "Train Epoch: 5684 [4000/8000 (50%)]\tBatch Loss: 0.012693\tLearning Rate (w_theta): 0.001000\t TIME:2444.7s\n",
      "\t\t\t\tDisc: 0.012118\t\tSym: 0.000000\t\tSpars: 0.000575\n",
      "\t TVw: 0.766562 | TVb: 2.281848 | GSw: -0.518832 | GSb: -0.176581 | TSUw: -0.428135 | TSUb: -0.038005\n",
      "Validating epoch 5684...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01290850106188516\n",
      "Average validation loss: 0.013410136350599091\n",
      "Training epoch 5685...\n",
      "\n",
      "Train Epoch: 5685 [0/8000 (0%)]\tBatch Loss: 0.013594\tLearning Rate (w_theta): 0.001000\t TIME:2447.0s\n",
      "\t\t\t\tDisc: 0.012608\t\tSym: 0.000000\t\tSpars: 0.000986\n",
      "\t TVw: 0.766663 | TVb: 2.281884 | GSw: -0.518533 | GSb: -0.176265 | TSUw: -0.426823 | TSUb: -0.036680\n",
      "\n",
      "Train Epoch: 5685 [4000/8000 (50%)]\tBatch Loss: 0.012708\tLearning Rate (w_theta): 0.001000\t TIME:2448.3s\n",
      "\t\t\t\tDisc: 0.011900\t\tSym: 0.000000\t\tSpars: 0.000809\n",
      "\t TVw: 0.766858 | TVb: 2.282088 | GSw: -0.518449 | GSb: -0.176184 | TSUw: -0.427474 | TSUb: -0.037310\n",
      "Validating epoch 5685...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012902959677193036\n",
      "Average validation loss: 0.013409474644047428\n",
      "Training epoch 5686...\n",
      "\n",
      "Train Epoch: 5686 [0/8000 (0%)]\tBatch Loss: 0.012651\tLearning Rate (w_theta): 0.001000\t TIME:2450.5s\n",
      "\t\t\t\tDisc: 0.011964\t\tSym: 0.000000\t\tSpars: 0.000687\n",
      "\t TVw: 0.766819 | TVb: 2.281996 | GSw: -0.518155 | GSb: -0.175870 | TSUw: -0.426472 | TSUb: -0.036294\n",
      "\n",
      "Train Epoch: 5686 [4000/8000 (50%)]\tBatch Loss: 0.012661\tLearning Rate (w_theta): 0.001000\t TIME:2451.8s\n",
      "\t\t\t\tDisc: 0.011646\t\tSym: 0.000000\t\tSpars: 0.001016\n",
      "\t TVw: 0.766676 | TVb: 2.281968 | GSw: -0.517923 | GSb: -0.175623 | TSUw: -0.425964 | TSUb: -0.035773\n",
      "Validating epoch 5686...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012907779298560679\n",
      "Average validation loss: 0.01341376256542521\n",
      "Training epoch 5687...\n",
      "\n",
      "Train Epoch: 5687 [0/8000 (0%)]\tBatch Loss: 0.013457\tLearning Rate (w_theta): 0.001000\t TIME:2454.2s\n",
      "\t\t\t\tDisc: 0.012463\t\tSym: 0.000000\t\tSpars: 0.000993\n",
      "\t TVw: 0.766549 | TVb: 2.282084 | GSw: -0.518035 | GSb: -0.175759 | TSUw: -0.428176 | TSUb: -0.037957\n",
      "\n",
      "Train Epoch: 5687 [4000/8000 (50%)]\tBatch Loss: 0.012814\tLearning Rate (w_theta): 0.001000\t TIME:2455.4s\n",
      "\t\t\t\tDisc: 0.012118\t\tSym: 0.000000\t\tSpars: 0.000696\n",
      "\t TVw: 0.766537 | TVb: 2.282202 | GSw: -0.517921 | GSb: -0.175653 | TSUw: -0.428382 | TSUb: -0.038143\n",
      "Validating epoch 5687...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012911320957456885\n",
      "Average validation loss: 0.013409699873042002\n",
      "Training epoch 5688...\n",
      "\n",
      "Train Epoch: 5688 [0/8000 (0%)]\tBatch Loss: 0.013015\tLearning Rate (w_theta): 0.001000\t TIME:2457.7s\n",
      "\t\t\t\tDisc: 0.012128\t\tSym: 0.000000\t\tSpars: 0.000887\n",
      "\t TVw: 0.766527 | TVb: 2.282005 | GSw: -0.517544 | GSb: -0.175255 | TSUw: -0.426375 | TSUb: -0.036124\n",
      "\n",
      "Train Epoch: 5688 [4000/8000 (50%)]\tBatch Loss: 0.013157\tLearning Rate (w_theta): 0.001000\t TIME:2458.9s\n",
      "\t\t\t\tDisc: 0.012209\t\tSym: 0.000000\t\tSpars: 0.000948\n",
      "\t TVw: 0.766773 | TVb: 2.282009 | GSw: -0.517395 | GSb: -0.175107 | TSUw: -0.426188 | TSUb: -0.035919\n",
      "Validating epoch 5688...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012910428007412643\n",
      "Average validation loss: 0.013413493835116171\n",
      "Training epoch 5689...\n",
      "\n",
      "Train Epoch: 5689 [0/8000 (0%)]\tBatch Loss: 0.013301\tLearning Rate (w_theta): 0.001000\t TIME:2461.2s\n",
      "\t\t\t\tDisc: 0.012340\t\tSym: 0.000000\t\tSpars: 0.000961\n",
      "\t TVw: 0.766956 | TVb: 2.282201 | GSw: -0.517515 | GSb: -0.175256 | TSUw: -0.428192 | TSUb: -0.037896\n",
      "\n",
      "Train Epoch: 5689 [4000/8000 (50%)]\tBatch Loss: 0.012527\tLearning Rate (w_theta): 0.001000\t TIME:2462.5s\n",
      "\t\t\t\tDisc: 0.011856\t\tSym: 0.000000\t\tSpars: 0.000671\n",
      "\t TVw: 0.767256 | TVb: 2.282387 | GSw: -0.517422 | GSb: -0.175172 | TSUw: -0.428503 | TSUb: -0.038186\n",
      "Validating epoch 5689...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01290792158969822\n",
      "Average validation loss: 0.01340921549023983\n",
      "Training epoch 5690...\n",
      "\n",
      "Train Epoch: 5690 [0/8000 (0%)]\tBatch Loss: 0.013126\tLearning Rate (w_theta): 0.001000\t TIME:2464.7s\n",
      "\t\t\t\tDisc: 0.012162\t\tSym: 0.000000\t\tSpars: 0.000963\n",
      "\t TVw: 0.767348 | TVb: 2.282244 | GSw: -0.517045 | GSb: -0.174776 | TSUw: -0.426520 | TSUb: -0.036191\n",
      "\n",
      "Train Epoch: 5690 [4000/8000 (50%)]\tBatch Loss: 0.013017\tLearning Rate (w_theta): 0.001000\t TIME:2466.0s\n",
      "\t\t\t\tDisc: 0.012269\t\tSym: 0.000000\t\tSpars: 0.000748\n",
      "\t TVw: 0.767700 | TVb: 2.282334 | GSw: -0.516856 | GSb: -0.174583 | TSUw: -0.426082 | TSUb: -0.035736\n",
      "Validating epoch 5690...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012911837432501577\n",
      "Average validation loss: 0.013413266751801005\n",
      "Training epoch 5691...\n",
      "\n",
      "Train Epoch: 5691 [0/8000 (0%)]\tBatch Loss: 0.012912\tLearning Rate (w_theta): 0.001000\t TIME:2468.8s\n",
      "\t\t\t\tDisc: 0.011744\t\tSym: 0.000000\t\tSpars: 0.001168\n",
      "\t TVw: 0.767868 | TVb: 2.282557 | GSw: -0.516988 | GSb: -0.174750 | TSUw: -0.428005 | TSUb: -0.037634\n",
      "\n",
      "Train Epoch: 5691 [4000/8000 (50%)]\tBatch Loss: 0.012775\tLearning Rate (w_theta): 0.001000\t TIME:2470.1s\n",
      "\t\t\t\tDisc: 0.012171\t\tSym: 0.000000\t\tSpars: 0.000604\n",
      "\t TVw: 0.767455 | TVb: 2.282447 | GSw: -0.516819 | GSb: -0.174587 | TSUw: -0.427765 | TSUb: -0.037376\n",
      "Validating epoch 5691...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012901292545611677\n",
      "Average validation loss: 0.013410831919804368\n",
      "Training epoch 5692...\n",
      "\n",
      "Train Epoch: 5692 [0/8000 (0%)]\tBatch Loss: 0.012359\tLearning Rate (w_theta): 0.001000\t TIME:2472.4s\n",
      "\t\t\t\tDisc: 0.011605\t\tSym: 0.000000\t\tSpars: 0.000754\n",
      "\t TVw: 0.767056 | TVb: 2.282190 | GSw: -0.516565 | GSb: -0.174321 | TSUw: -0.427044 | TSUb: -0.036640\n",
      "\n",
      "Train Epoch: 5692 [4000/8000 (50%)]\tBatch Loss: 0.012776\tLearning Rate (w_theta): 0.001000\t TIME:2473.7s\n",
      "\t\t\t\tDisc: 0.012185\t\tSym: 0.000000\t\tSpars: 0.000591\n",
      "\t TVw: 0.766683 | TVb: 2.281938 | GSw: -0.516316 | GSb: -0.174076 | TSUw: -0.426445 | TSUb: -0.036027\n",
      "Validating epoch 5692...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012904033744920884\n",
      "Average validation loss: 0.013411027000866138\n",
      "Training epoch 5693...\n",
      "\n",
      "Train Epoch: 5693 [0/8000 (0%)]\tBatch Loss: 0.013221\tLearning Rate (w_theta): 0.001000\t TIME:2475.9s\n",
      "\t\t\t\tDisc: 0.012408\t\tSym: 0.000000\t\tSpars: 0.000813\n",
      "\t TVw: 0.766456 | TVb: 2.281857 | GSw: -0.516286 | GSb: -0.174061 | TSUw: -0.427533 | TSUb: -0.037096\n",
      "\n",
      "Train Epoch: 5693 [4000/8000 (50%)]\tBatch Loss: 0.013113\tLearning Rate (w_theta): 0.001000\t TIME:2477.2s\n",
      "\t\t\t\tDisc: 0.012273\t\tSym: 0.000000\t\tSpars: 0.000840\n",
      "\t TVw: 0.766524 | TVb: 2.281823 | GSw: -0.516145 | GSb: -0.173927 | TSUw: -0.427840 | TSUb: -0.037387\n",
      "Validating epoch 5693...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01290280914352225\n",
      "Average validation loss: 0.013413136418491196\n",
      "Training epoch 5694...\n",
      "\n",
      "Train Epoch: 5694 [0/8000 (0%)]\tBatch Loss: 0.012327\tLearning Rate (w_theta): 0.001000\t TIME:2479.4s\n",
      "\t\t\t\tDisc: 0.011736\t\tSym: 0.000000\t\tSpars: 0.000591\n",
      "\t TVw: 0.766374 | TVb: 2.281726 | GSw: -0.515905 | GSb: -0.173676 | TSUw: -0.427423 | TSUb: -0.036957\n",
      "\n",
      "Train Epoch: 5694 [4000/8000 (50%)]\tBatch Loss: 0.012950\tLearning Rate (w_theta): 0.001000\t TIME:2480.7s\n",
      "\t\t\t\tDisc: 0.011966\t\tSym: 0.000000\t\tSpars: 0.000984\n",
      "\t TVw: 0.766014 | TVb: 2.281497 | GSw: -0.515671 | GSb: -0.173433 | TSUw: -0.427121 | TSUb: -0.036641\n",
      "Validating epoch 5694...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0129029533112555\n",
      "Average validation loss: 0.013412115345333386\n",
      "Training epoch 5695...\n",
      "\n",
      "Train Epoch: 5695 [0/8000 (0%)]\tBatch Loss: 0.013068\tLearning Rate (w_theta): 0.001000\t TIME:2482.9s\n",
      "\t\t\t\tDisc: 0.012284\t\tSym: 0.000000\t\tSpars: 0.000784\n",
      "\t TVw: 0.766008 | TVb: 2.281547 | GSw: -0.515477 | GSb: -0.173233 | TSUw: -0.427149 | TSUb: -0.036655\n",
      "\n",
      "Train Epoch: 5695 [4000/8000 (50%)]\tBatch Loss: 0.012949\tLearning Rate (w_theta): 0.001000\t TIME:2484.1s\n",
      "\t\t\t\tDisc: 0.012122\t\tSym: 0.000000\t\tSpars: 0.000827\n",
      "\t TVw: 0.765755 | TVb: 2.281544 | GSw: -0.515253 | GSb: -0.173002 | TSUw: -0.426968 | TSUb: -0.036462\n",
      "Validating epoch 5695...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012904373464007322\n",
      "Average validation loss: 0.01341651819906712\n",
      "Training epoch 5696...\n",
      "\n",
      "Train Epoch: 5696 [0/8000 (0%)]\tBatch Loss: 0.013182\tLearning Rate (w_theta): 0.001000\t TIME:2486.4s\n",
      "\t\t\t\tDisc: 0.012410\t\tSym: 0.000000\t\tSpars: 0.000773\n",
      "\t TVw: 0.766077 | TVb: 2.281845 | GSw: -0.515225 | GSb: -0.172989 | TSUw: -0.428226 | TSUb: -0.037704\n",
      "\n",
      "Train Epoch: 5696 [4000/8000 (50%)]\tBatch Loss: 0.013409\tLearning Rate (w_theta): 0.001000\t TIME:2487.7s\n",
      "\t\t\t\tDisc: 0.012405\t\tSym: 0.000000\t\tSpars: 0.001004\n",
      "\t TVw: 0.766954 | TVb: 2.282224 | GSw: -0.515065 | GSb: -0.172831 | TSUw: -0.428418 | TSUb: -0.037882\n",
      "Validating epoch 5696...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01290446932210187\n",
      "Average validation loss: 0.013410954737948495\n",
      "Training epoch 5697...\n",
      "\n",
      "Train Epoch: 5697 [0/8000 (0%)]\tBatch Loss: 0.012689\tLearning Rate (w_theta): 0.001000\t TIME:2489.9s\n",
      "\t\t\t\tDisc: 0.011898\t\tSym: 0.000000\t\tSpars: 0.000791\n",
      "\t TVw: 0.767191 | TVb: 2.282217 | GSw: -0.514727 | GSb: -0.172477 | TSUw: -0.427249 | TSUb: -0.036701\n",
      "\n",
      "Train Epoch: 5697 [4000/8000 (50%)]\tBatch Loss: 0.012934\tLearning Rate (w_theta): 0.001000\t TIME:2491.2s\n",
      "\t\t\t\tDisc: 0.012181\t\tSym: 0.000000\t\tSpars: 0.000753\n",
      "\t TVw: 0.766413 | TVb: 2.281745 | GSw: -0.514430 | GSb: -0.172173 | TSUw: -0.426453 | TSUb: -0.035893\n",
      "Validating epoch 5697...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012905265228906813\n",
      "Average validation loss: 0.013411432656471461\n",
      "Training epoch 5698...\n",
      "\n",
      "Train Epoch: 5698 [0/8000 (0%)]\tBatch Loss: 0.012377\tLearning Rate (w_theta): 0.001000\t TIME:2493.5s\n",
      "\t\t\t\tDisc: 0.011943\t\tSym: 0.000000\t\tSpars: 0.000434\n",
      "\t TVw: 0.766225 | TVb: 2.281744 | GSw: -0.514412 | GSb: -0.172175 | TSUw: -0.427633 | TSUb: -0.037055\n",
      "\n",
      "Train Epoch: 5698 [4000/8000 (50%)]\tBatch Loss: 0.012253\tLearning Rate (w_theta): 0.001000\t TIME:2494.8s\n",
      "\t\t\t\tDisc: 0.011691\t\tSym: 0.000000\t\tSpars: 0.000561\n",
      "\t TVw: 0.766422 | TVb: 2.281812 | GSw: -0.514335 | GSb: -0.172117 | TSUw: -0.428455 | TSUb: -0.037860\n",
      "Validating epoch 5698...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012905237663223698\n",
      "Average validation loss: 0.013414714742735699\n",
      "Training epoch 5699...\n",
      "\n",
      "Train Epoch: 5699 [0/8000 (0%)]\tBatch Loss: 0.012905\tLearning Rate (w_theta): 0.001000\t TIME:2497.0s\n",
      "\t\t\t\tDisc: 0.012245\t\tSym: 0.000000\t\tSpars: 0.000660\n",
      "\t TVw: 0.766502 | TVb: 2.281804 | GSw: -0.514025 | GSb: -0.171796 | TSUw: -0.427450 | TSUb: -0.036843\n",
      "\n",
      "Train Epoch: 5699 [4000/8000 (50%)]\tBatch Loss: 0.012936\tLearning Rate (w_theta): 0.001000\t TIME:2498.3s\n",
      "\t\t\t\tDisc: 0.012147\t\tSym: 0.000000\t\tSpars: 0.000790\n",
      "\t TVw: 0.766526 | TVb: 2.281880 | GSw: -0.513822 | GSb: -0.171588 | TSUw: -0.427239 | TSUb: -0.036618\n",
      "Validating epoch 5699...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012905016144407838\n",
      "Average validation loss: 0.013411738745695758\n",
      "Training epoch 5700...\n",
      "\n",
      "Train Epoch: 5700 [0/8000 (0%)]\tBatch Loss: 0.013102\tLearning Rate (w_theta): 0.001000\t TIME:2500.6s\n",
      "\t\t\t\tDisc: 0.012338\t\tSym: 0.000000\t\tSpars: 0.000764\n",
      "\t TVw: 0.766539 | TVb: 2.281964 | GSw: -0.513689 | GSb: -0.171462 | TSUw: -0.427605 | TSUb: -0.036969\n",
      "\n",
      "Train Epoch: 5700 [4000/8000 (50%)]\tBatch Loss: 0.013221\tLearning Rate (w_theta): 0.001000\t TIME:2501.8s\n",
      "\t\t\t\tDisc: 0.012475\t\tSym: 0.000000\t\tSpars: 0.000746\n",
      "\t TVw: 0.766280 | TVb: 2.281845 | GSw: -0.513483 | GSb: -0.171261 | TSUw: -0.427503 | TSUb: -0.036853\n",
      "Validating epoch 5700...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012902679247604241\n",
      "Average validation loss: 0.013413458542149708\n",
      "Training epoch 5701...\n",
      "\n",
      "Train Epoch: 5701 [0/8000 (0%)]\tBatch Loss: 0.012810\tLearning Rate (w_theta): 0.001000\t TIME:2504.9s\n",
      "\t\t\t\tDisc: 0.011992\t\tSym: 0.000000\t\tSpars: 0.000817\n",
      "\t TVw: 0.766203 | TVb: 2.281838 | GSw: -0.513320 | GSb: -0.171103 | TSUw: -0.427749 | TSUb: -0.037085\n",
      "\n",
      "Train Epoch: 5701 [4000/8000 (50%)]\tBatch Loss: 0.012714\tLearning Rate (w_theta): 0.001000\t TIME:2506.2s\n",
      "\t\t\t\tDisc: 0.011902\t\tSym: 0.000000\t\tSpars: 0.000812\n",
      "\t TVw: 0.766076 | TVb: 2.281699 | GSw: -0.513143 | GSb: -0.170932 | TSUw: -0.427921 | TSUb: -0.037243\n",
      "Validating epoch 5701...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012903289200425312\n",
      "Average validation loss: 0.01341319055869744\n",
      "Training epoch 5702...\n",
      "\n",
      "Train Epoch: 5702 [0/8000 (0%)]\tBatch Loss: 0.012697\tLearning Rate (w_theta): 0.001000\t TIME:2508.5s\n",
      "\t\t\t\tDisc: 0.011899\t\tSym: 0.000000\t\tSpars: 0.000798\n",
      "\t TVw: 0.766260 | TVb: 2.281685 | GSw: -0.512902 | GSb: -0.170688 | TSUw: -0.427621 | TSUb: -0.036931\n",
      "\n",
      "Train Epoch: 5702 [4000/8000 (50%)]\tBatch Loss: 0.012507\tLearning Rate (w_theta): 0.001000\t TIME:2509.7s\n",
      "\t\t\t\tDisc: 0.011771\t\tSym: 0.000000\t\tSpars: 0.000736\n",
      "\t TVw: 0.766119 | TVb: 2.281593 | GSw: -0.512695 | GSb: -0.170484 | TSUw: -0.427598 | TSUb: -0.036896\n",
      "Validating epoch 5702...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01290350674433613\n",
      "Average validation loss: 0.013413733383549372\n",
      "Training epoch 5703...\n",
      "\n",
      "Train Epoch: 5703 [0/8000 (0%)]\tBatch Loss: 0.012567\tLearning Rate (w_theta): 0.001000\t TIME:2512.0s\n",
      "\t\t\t\tDisc: 0.011931\t\tSym: 0.000000\t\tSpars: 0.000636\n",
      "\t TVw: 0.766276 | TVb: 2.281623 | GSw: -0.512502 | GSb: -0.170287 | TSUw: -0.427685 | TSUb: -0.036970\n",
      "\n",
      "Train Epoch: 5703 [4000/8000 (50%)]\tBatch Loss: 0.012859\tLearning Rate (w_theta): 0.001000\t TIME:2513.3s\n",
      "\t\t\t\tDisc: 0.011947\t\tSym: 0.000000\t\tSpars: 0.000912\n",
      "\t TVw: 0.766401 | TVb: 2.281647 | GSw: -0.512281 | GSb: -0.170068 | TSUw: -0.427558 | TSUb: -0.036830\n",
      "Validating epoch 5703...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012903481871321685\n",
      "Average validation loss: 0.013413847281477204\n",
      "Training epoch 5704...\n",
      "\n",
      "Train Epoch: 5704 [0/8000 (0%)]\tBatch Loss: 0.012620\tLearning Rate (w_theta): 0.001000\t TIME:2515.5s\n",
      "\t\t\t\tDisc: 0.011754\t\tSym: 0.000000\t\tSpars: 0.000866\n",
      "\t TVw: 0.766551 | TVb: 2.281804 | GSw: -0.512133 | GSb: -0.169926 | TSUw: -0.427989 | TSUb: -0.037248\n",
      "\n",
      "Train Epoch: 5704 [4000/8000 (50%)]\tBatch Loss: 0.012799\tLearning Rate (w_theta): 0.001000\t TIME:2516.8s\n",
      "\t\t\t\tDisc: 0.012062\t\tSym: 0.000000\t\tSpars: 0.000738\n",
      "\t TVw: 0.766035 | TVb: 2.281653 | GSw: -0.511868 | GSb: -0.169655 | TSUw: -0.427520 | TSUb: -0.036767\n",
      "Validating epoch 5704...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012904972874693462\n",
      "Average validation loss: 0.013415423304215244\n",
      "Training epoch 5705...\n",
      "\n",
      "Train Epoch: 5705 [0/8000 (0%)]\tBatch Loss: 0.013120\tLearning Rate (w_theta): 0.001000\t TIME:2519.1s\n",
      "\t\t\t\tDisc: 0.012104\t\tSym: 0.000000\t\tSpars: 0.001016\n",
      "\t TVw: 0.766147 | TVb: 2.281698 | GSw: -0.511735 | GSb: -0.169526 | TSUw: -0.428046 | TSUb: -0.037278\n",
      "\n",
      "Train Epoch: 5705 [4000/8000 (50%)]\tBatch Loss: 0.012659\tLearning Rate (w_theta): 0.001000\t TIME:2520.5s\n",
      "\t\t\t\tDisc: 0.011733\t\tSym: 0.000000\t\tSpars: 0.000925\n",
      "\t TVw: 0.766477 | TVb: 2.281865 | GSw: -0.511534 | GSb: -0.169327 | TSUw: -0.428068 | TSUb: -0.037289\n",
      "Validating epoch 5705...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012903349432932707\n",
      "Average validation loss: 0.013413808981299326\n",
      "Training epoch 5706...\n",
      "\n",
      "Train Epoch: 5706 [0/8000 (0%)]\tBatch Loss: 0.012731\tLearning Rate (w_theta): 0.001000\t TIME:2522.7s\n",
      "\t\t\t\tDisc: 0.012125\t\tSym: 0.000000\t\tSpars: 0.000606\n",
      "\t TVw: 0.766796 | TVb: 2.281911 | GSw: -0.511284 | GSb: -0.169070 | TSUw: -0.427726 | TSUb: -0.036935\n",
      "\n",
      "Train Epoch: 5706 [4000/8000 (50%)]\tBatch Loss: 0.012803\tLearning Rate (w_theta): 0.001000\t TIME:2524.0s\n",
      "\t\t\t\tDisc: 0.012122\t\tSym: 0.000000\t\tSpars: 0.000681\n",
      "\t TVw: 0.766922 | TVb: 2.281869 | GSw: -0.511049 | GSb: -0.168837 | TSUw: -0.427516 | TSUb: -0.036712\n",
      "Validating epoch 5706...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012903445044562287\n",
      "Average validation loss: 0.013412616180749008\n",
      "Training epoch 5707...\n",
      "\n",
      "Train Epoch: 5707 [0/8000 (0%)]\tBatch Loss: 0.013060\tLearning Rate (w_theta): 0.001000\t TIME:2526.3s\n",
      "\t\t\t\tDisc: 0.012189\t\tSym: 0.000000\t\tSpars: 0.000871\n",
      "\t TVw: 0.767039 | TVb: 2.281995 | GSw: -0.510924 | GSb: -0.168725 | TSUw: -0.428086 | TSUb: -0.037268\n",
      "\n",
      "Train Epoch: 5707 [4000/8000 (50%)]\tBatch Loss: 0.012857\tLearning Rate (w_theta): 0.001000\t TIME:2527.6s\n",
      "\t\t\t\tDisc: 0.012023\t\tSym: 0.000000\t\tSpars: 0.000834\n",
      "\t TVw: 0.767071 | TVb: 2.282077 | GSw: -0.510715 | GSb: -0.168514 | TSUw: -0.427987 | TSUb: -0.037156\n",
      "Validating epoch 5707...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01290332234043866\n",
      "Average validation loss: 0.01341198228152271\n",
      "Training epoch 5708...\n",
      "\n",
      "Train Epoch: 5708 [0/8000 (0%)]\tBatch Loss: 0.012484\tLearning Rate (w_theta): 0.001000\t TIME:2529.8s\n",
      "\t\t\t\tDisc: 0.011820\t\tSym: 0.000000\t\tSpars: 0.000663\n",
      "\t TVw: 0.767003 | TVb: 2.281984 | GSw: -0.510492 | GSb: -0.168293 | TSUw: -0.427832 | TSUb: -0.036988\n",
      "\n",
      "Train Epoch: 5708 [4000/8000 (50%)]\tBatch Loss: 0.012986\tLearning Rate (w_theta): 0.001000\t TIME:2531.1s\n",
      "\t\t\t\tDisc: 0.012091\t\tSym: 0.000000\t\tSpars: 0.000895\n",
      "\t TVw: 0.766498 | TVb: 2.281651 | GSw: -0.510257 | GSb: -0.168061 | TSUw: -0.427631 | TSUb: -0.036774\n",
      "Validating epoch 5708...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012903829438528643\n",
      "Average validation loss: 0.01341395145182184\n",
      "Training epoch 5709...\n",
      "\n",
      "Train Epoch: 5709 [0/8000 (0%)]\tBatch Loss: 0.014067\tLearning Rate (w_theta): 0.001000\t TIME:2533.4s\n",
      "\t\t\t\tDisc: 0.013158\t\tSym: 0.000000\t\tSpars: 0.000908\n",
      "\t TVw: 0.766754 | TVb: 2.281781 | GSw: -0.510102 | GSb: -0.167913 | TSUw: -0.427982 | TSUb: -0.037112\n",
      "\n",
      "Train Epoch: 5709 [4000/8000 (50%)]\tBatch Loss: 0.012490\tLearning Rate (w_theta): 0.001000\t TIME:2534.6s\n",
      "\t\t\t\tDisc: 0.011650\t\tSym: 0.000000\t\tSpars: 0.000840\n",
      "\t TVw: 0.767109 | TVb: 2.281975 | GSw: -0.509956 | GSb: -0.167771 | TSUw: -0.428401 | TSUb: -0.037518\n",
      "Validating epoch 5709...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012904875843729544\n",
      "Average validation loss: 0.013418057323043072\n",
      "Training epoch 5710...\n",
      "\n",
      "Train Epoch: 5710 [0/8000 (0%)]\tBatch Loss: 0.012801\tLearning Rate (w_theta): 0.001000\t TIME:2536.9s\n",
      "\t\t\t\tDisc: 0.012160\t\tSym: 0.000000\t\tSpars: 0.000641\n",
      "\t TVw: 0.767277 | TVb: 2.281947 | GSw: -0.509735 | GSb: -0.167557 | TSUw: -0.428234 | TSUb: -0.037338\n",
      "\n",
      "Train Epoch: 5710 [4000/8000 (50%)]\tBatch Loss: 0.012553\tLearning Rate (w_theta): 0.001000\t TIME:2538.2s\n",
      "\t\t\t\tDisc: 0.011926\t\tSym: 0.000000\t\tSpars: 0.000627\n",
      "\t TVw: 0.766476 | TVb: 2.281470 | GSw: -0.509393 | GSb: -0.167204 | TSUw: -0.427128 | TSUb: -0.036219\n",
      "Validating epoch 5710...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012908550434484323\n",
      "Average validation loss: 0.013413196877289743\n",
      "Training epoch 5711...\n",
      "\n",
      "Train Epoch: 5711 [0/8000 (0%)]\tBatch Loss: 0.012598\tLearning Rate (w_theta): 0.001000\t TIME:2541.1s\n",
      "\t\t\t\tDisc: 0.011874\t\tSym: 0.000000\t\tSpars: 0.000723\n",
      "\t TVw: 0.766597 | TVb: 2.281621 | GSw: -0.509348 | GSb: -0.167186 | TSUw: -0.428082 | TSUb: -0.037156\n",
      "\n",
      "Train Epoch: 5711 [4000/8000 (50%)]\tBatch Loss: 0.012810\tLearning Rate (w_theta): 0.001000\t TIME:2542.3s\n",
      "\t\t\t\tDisc: 0.012169\t\tSym: 0.000000\t\tSpars: 0.000641\n",
      "\t TVw: 0.767006 | TVb: 2.281764 | GSw: -0.509228 | GSb: -0.167086 | TSUw: -0.428537 | TSUb: -0.037597\n",
      "Validating epoch 5711...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01290511742460448\n",
      "Average validation loss: 0.013413837645003451\n",
      "Training epoch 5712...\n",
      "\n",
      "Train Epoch: 5712 [0/8000 (0%)]\tBatch Loss: 0.012820\tLearning Rate (w_theta): 0.001000\t TIME:2544.6s\n",
      "\t\t\t\tDisc: 0.012018\t\tSym: 0.000000\t\tSpars: 0.000803\n",
      "\t TVw: 0.767113 | TVb: 2.281819 | GSw: -0.508976 | GSb: -0.166834 | TSUw: -0.428031 | TSUb: -0.037079\n",
      "\n",
      "Train Epoch: 5712 [4000/8000 (50%)]\tBatch Loss: 0.013320\tLearning Rate (w_theta): 0.001000\t TIME:2545.9s\n",
      "\t\t\t\tDisc: 0.012458\t\tSym: 0.000000\t\tSpars: 0.000862\n",
      "\t TVw: 0.767324 | TVb: 2.281997 | GSw: -0.508811 | GSb: -0.166682 | TSUw: -0.428232 | TSUb: -0.037265\n",
      "Validating epoch 5712...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012903304946663327\n",
      "Average validation loss: 0.013412142527470174\n",
      "Training epoch 5713...\n",
      "\n",
      "Train Epoch: 5713 [0/8000 (0%)]\tBatch Loss: 0.013368\tLearning Rate (w_theta): 0.001000\t TIME:2548.1s\n",
      "\t\t\t\tDisc: 0.012310\t\tSym: 0.000000\t\tSpars: 0.001058\n",
      "\t TVw: 0.767410 | TVb: 2.282047 | GSw: -0.508560 | GSb: -0.166426 | TSUw: -0.427820 | TSUb: -0.036841\n",
      "\n",
      "Train Epoch: 5713 [4000/8000 (50%)]\tBatch Loss: 0.013044\tLearning Rate (w_theta): 0.001000\t TIME:2549.3s\n",
      "\t\t\t\tDisc: 0.012438\t\tSym: 0.000000\t\tSpars: 0.000605\n",
      "\t TVw: 0.767018 | TVb: 2.281915 | GSw: -0.508326 | GSb: -0.166190 | TSUw: -0.427551 | TSUb: -0.036559\n",
      "Validating epoch 5713...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012904598478422607\n",
      "Average validation loss: 0.013414968121158744\n",
      "Training epoch 5714...\n",
      "\n",
      "Train Epoch: 5714 [0/8000 (0%)]\tBatch Loss: 0.012865\tLearning Rate (w_theta): 0.001000\t TIME:2551.7s\n",
      "\t\t\t\tDisc: 0.012113\t\tSym: 0.000000\t\tSpars: 0.000752\n",
      "\t TVw: 0.767130 | TVb: 2.282011 | GSw: -0.508264 | GSb: -0.166146 | TSUw: -0.428511 | TSUb: -0.037505\n",
      "\n",
      "Train Epoch: 5714 [4000/8000 (50%)]\tBatch Loss: 0.012461\tLearning Rate (w_theta): 0.001000\t TIME:2553.0s\n",
      "\t\t\t\tDisc: 0.011795\t\tSym: 0.000000\t\tSpars: 0.000666\n",
      "\t TVw: 0.767496 | TVb: 2.281943 | GSw: -0.508069 | GSb: -0.165949 | TSUw: -0.428516 | TSUb: -0.037496\n",
      "Validating epoch 5714...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012905583970449518\n",
      "Average validation loss: 0.013412202263263048\n",
      "Training epoch 5715...\n",
      "\n",
      "Train Epoch: 5715 [0/8000 (0%)]\tBatch Loss: 0.012995\tLearning Rate (w_theta): 0.001000\t TIME:2555.2s\n",
      "\t\t\t\tDisc: 0.011934\t\tSym: 0.000000\t\tSpars: 0.001061\n",
      "\t TVw: 0.767543 | TVb: 2.281901 | GSw: -0.507796 | GSb: -0.165674 | TSUw: -0.427898 | TSUb: -0.036866\n",
      "\n",
      "Train Epoch: 5715 [4000/8000 (50%)]\tBatch Loss: 0.014081\tLearning Rate (w_theta): 0.001000\t TIME:2556.5s\n",
      "\t\t\t\tDisc: 0.012812\t\tSym: 0.000000\t\tSpars: 0.001269\n",
      "\t TVw: 0.767058 | TVb: 2.281808 | GSw: -0.507650 | GSb: -0.165548 | TSUw: -0.428237 | TSUb: -0.037191\n",
      "Validating epoch 5715...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012904146771817658\n",
      "Average validation loss: 0.013415272444451128\n",
      "Training epoch 5716...\n",
      "\n",
      "Train Epoch: 5716 [0/8000 (0%)]\tBatch Loss: 0.012800\tLearning Rate (w_theta): 0.001000\t TIME:2558.8s\n",
      "\t\t\t\tDisc: 0.011974\t\tSym: 0.000000\t\tSpars: 0.000826\n",
      "\t TVw: 0.767573 | TVb: 2.282019 | GSw: -0.507469 | GSb: -0.165376 | TSUw: -0.428326 | TSUb: -0.037267\n",
      "\n",
      "Train Epoch: 5716 [4000/8000 (50%)]\tBatch Loss: 0.012445\tLearning Rate (w_theta): 0.001000\t TIME:2560.0s\n",
      "\t\t\t\tDisc: 0.011784\t\tSym: 0.000000\t\tSpars: 0.000661\n",
      "\t TVw: 0.767706 | TVb: 2.282005 | GSw: -0.507224 | GSb: -0.165129 | TSUw: -0.427982 | TSUb: -0.036911\n",
      "Validating epoch 5716...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012903796757702526\n",
      "Average validation loss: 0.013412079862268078\n",
      "Training epoch 5717...\n",
      "\n",
      "Train Epoch: 5717 [0/8000 (0%)]\tBatch Loss: 0.013002\tLearning Rate (w_theta): 0.001000\t TIME:2562.3s\n",
      "\t\t\t\tDisc: 0.012266\t\tSym: 0.000000\t\tSpars: 0.000736\n",
      "\t TVw: 0.767625 | TVb: 2.281982 | GSw: -0.507035 | GSb: -0.164945 | TSUw: -0.428052 | TSUb: -0.036968\n",
      "\n",
      "Train Epoch: 5717 [4000/8000 (50%)]\tBatch Loss: 0.012933\tLearning Rate (w_theta): 0.001000\t TIME:2563.5s\n",
      "\t\t\t\tDisc: 0.012243\t\tSym: 0.000000\t\tSpars: 0.000689\n",
      "\t TVw: 0.767790 | TVb: 2.282155 | GSw: -0.506906 | GSb: -0.164833 | TSUw: -0.428562 | TSUb: -0.037465\n",
      "Validating epoch 5717...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012902712459123536\n",
      "Average validation loss: 0.0134155084577785\n",
      "Training epoch 5718...\n",
      "\n",
      "Train Epoch: 5718 [0/8000 (0%)]\tBatch Loss: 0.012821\tLearning Rate (w_theta): 0.001000\t TIME:2565.8s\n",
      "\t\t\t\tDisc: 0.011841\t\tSym: 0.000000\t\tSpars: 0.000981\n",
      "\t TVw: 0.767771 | TVb: 2.282118 | GSw: -0.506711 | GSb: -0.164645 | TSUw: -0.428597 | TSUb: -0.037487\n",
      "\n",
      "Train Epoch: 5718 [4000/8000 (50%)]\tBatch Loss: 0.012733\tLearning Rate (w_theta): 0.001000\t TIME:2567.1s\n",
      "\t\t\t\tDisc: 0.011901\t\tSym: 0.000000\t\tSpars: 0.000832\n",
      "\t TVw: 0.767653 | TVb: 2.281909 | GSw: -0.506509 | GSb: -0.164455 | TSUw: -0.428624 | TSUb: -0.037500\n",
      "Validating epoch 5718...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012904400725089728\n",
      "Average validation loss: 0.013412604273856587\n",
      "Training epoch 5719...\n",
      "\n",
      "Train Epoch: 5719 [0/8000 (0%)]\tBatch Loss: 0.013273\tLearning Rate (w_theta): 0.001000\t TIME:2569.3s\n",
      "\t\t\t\tDisc: 0.011987\t\tSym: 0.000000\t\tSpars: 0.001286\n",
      "\t TVw: 0.767896 | TVb: 2.281953 | GSw: -0.506196 | GSb: -0.164141 | TSUw: -0.427749 | TSUb: -0.036613\n",
      "\n",
      "Train Epoch: 5719 [4000/8000 (50%)]\tBatch Loss: 0.012886\tLearning Rate (w_theta): 0.001000\t TIME:2570.6s\n",
      "\t\t\t\tDisc: 0.012278\t\tSym: 0.000000\t\tSpars: 0.000608\n",
      "\t TVw: 0.768531 | TVb: 2.282432 | GSw: -0.506132 | GSb: -0.164109 | TSUw: -0.428609 | TSUb: -0.037459\n",
      "Validating epoch 5719...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012906753736104446\n",
      "Average validation loss: 0.013411815883843737\n",
      "Training epoch 5720...\n",
      "\n",
      "Train Epoch: 5720 [0/8000 (0%)]\tBatch Loss: 0.012972\tLearning Rate (w_theta): 0.001000\t TIME:2572.9s\n",
      "\t\t\t\tDisc: 0.012172\t\tSym: 0.000000\t\tSpars: 0.000800\n",
      "\t TVw: 0.768355 | TVb: 2.282379 | GSw: -0.505884 | GSb: -0.163865 | TSUw: -0.428151 | TSUb: -0.036988\n",
      "\n",
      "Train Epoch: 5720 [4000/8000 (50%)]\tBatch Loss: 0.013467\tLearning Rate (w_theta): 0.001000\t TIME:2574.2s\n",
      "\t\t\t\tDisc: 0.012532\t\tSym: 0.000000\t\tSpars: 0.000935\n",
      "\t TVw: 0.767689 | TVb: 2.282201 | GSw: -0.505711 | GSb: -0.163713 | TSUw: -0.428290 | TSUb: -0.037112\n",
      "Validating epoch 5720...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012902638626415431\n",
      "Average validation loss: 0.013413153888885355\n",
      "Training epoch 5721...\n",
      "\n",
      "Train Epoch: 5721 [0/8000 (0%)]\tBatch Loss: 0.012481\tLearning Rate (w_theta): 0.001000\t TIME:2577.2s\n",
      "\t\t\t\tDisc: 0.011930\t\tSym: 0.000000\t\tSpars: 0.000551\n",
      "\t TVw: 0.767386 | TVb: 2.282015 | GSw: -0.505502 | GSb: -0.163505 | TSUw: -0.428197 | TSUb: -0.037006\n",
      "\n",
      "Train Epoch: 5721 [4000/8000 (50%)]\tBatch Loss: 0.012854\tLearning Rate (w_theta): 0.001000\t TIME:2578.4s\n",
      "\t\t\t\tDisc: 0.011967\t\tSym: 0.000000\t\tSpars: 0.000886\n",
      "\t TVw: 0.766616 | TVb: 2.281618 | GSw: -0.505240 | GSb: -0.163242 | TSUw: -0.427759 | TSUb: -0.036556\n",
      "Validating epoch 5721...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01290671056266792\n",
      "Average validation loss: 0.013417196321606224\n",
      "Training epoch 5722...\n",
      "\n",
      "Train Epoch: 5722 [0/8000 (0%)]\tBatch Loss: 0.012795\tLearning Rate (w_theta): 0.001000\t TIME:2580.7s\n",
      "\t\t\t\tDisc: 0.011934\t\tSym: 0.000000\t\tSpars: 0.000861\n",
      "\t TVw: 0.766947 | TVb: 2.281866 | GSw: -0.505235 | GSb: -0.163266 | TSUw: -0.429080 | TSUb: -0.037863\n",
      "\n",
      "Train Epoch: 5722 [4000/8000 (50%)]\tBatch Loss: 0.012891\tLearning Rate (w_theta): 0.001000\t TIME:2582.0s\n",
      "\t\t\t\tDisc: 0.012061\t\tSym: 0.000000\t\tSpars: 0.000829\n",
      "\t TVw: 0.766998 | TVb: 2.281807 | GSw: -0.505038 | GSb: -0.163086 | TSUw: -0.428972 | TSUb: -0.037740\n",
      "Validating epoch 5722...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012907348262734035\n",
      "Average validation loss: 0.01341403534993915\n",
      "Training epoch 5723...\n",
      "\n",
      "Train Epoch: 5723 [0/8000 (0%)]\tBatch Loss: 0.013537\tLearning Rate (w_theta): 0.001000\t TIME:2584.4s\n",
      "\t\t\t\tDisc: 0.012518\t\tSym: 0.000000\t\tSpars: 0.001019\n",
      "\t TVw: 0.767270 | TVb: 2.281814 | GSw: -0.504770 | GSb: -0.162817 | TSUw: -0.428328 | TSUb: -0.037083\n",
      "\n",
      "Train Epoch: 5723 [4000/8000 (50%)]\tBatch Loss: 0.012704\tLearning Rate (w_theta): 0.001000\t TIME:2585.7s\n",
      "\t\t\t\tDisc: 0.011876\t\tSym: 0.000000\t\tSpars: 0.000828\n",
      "\t TVw: 0.767460 | TVb: 2.281945 | GSw: -0.504598 | GSb: -0.162654 | TSUw: -0.428440 | TSUb: -0.037182\n",
      "Validating epoch 5723...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012904717921884655\n",
      "Average validation loss: 0.01341293160564061\n",
      "Training epoch 5724...\n",
      "\n",
      "Train Epoch: 5724 [0/8000 (0%)]\tBatch Loss: 0.013426\tLearning Rate (w_theta): 0.001000\t TIME:2588.0s\n",
      "\t\t\t\tDisc: 0.012536\t\tSym: 0.000000\t\tSpars: 0.000890\n",
      "\t TVw: 0.767605 | TVb: 2.282018 | GSw: -0.504371 | GSb: -0.162434 | TSUw: -0.428196 | TSUb: -0.036925\n",
      "\n",
      "Train Epoch: 5724 [4000/8000 (50%)]\tBatch Loss: 0.013008\tLearning Rate (w_theta): 0.001000\t TIME:2589.3s\n",
      "\t\t\t\tDisc: 0.012218\t\tSym: 0.000000\t\tSpars: 0.000790\n",
      "\t TVw: 0.767781 | TVb: 2.282149 | GSw: -0.504157 | GSb: -0.162224 | TSUw: -0.428019 | TSUb: -0.036736\n",
      "Validating epoch 5724...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012904473883436442\n",
      "Average validation loss: 0.013414141118516444\n",
      "Training epoch 5725...\n",
      "\n",
      "Train Epoch: 5725 [0/8000 (0%)]\tBatch Loss: 0.012672\tLearning Rate (w_theta): 0.001000\t TIME:2591.6s\n",
      "\t\t\t\tDisc: 0.011975\t\tSym: 0.000000\t\tSpars: 0.000697\n",
      "\t TVw: 0.767780 | TVb: 2.282156 | GSw: -0.504058 | GSb: -0.162150 | TSUw: -0.428691 | TSUb: -0.037396\n",
      "\n",
      "Train Epoch: 5725 [4000/8000 (50%)]\tBatch Loss: 0.013253\tLearning Rate (w_theta): 0.001000\t TIME:2592.9s\n",
      "\t\t\t\tDisc: 0.012299\t\tSym: 0.000000\t\tSpars: 0.000954\n",
      "\t TVw: 0.767792 | TVb: 2.282031 | GSw: -0.503955 | GSb: -0.162071 | TSUw: -0.429361 | TSUb: -0.038052\n",
      "Validating epoch 5725...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012906654847487825\n",
      "Average validation loss: 0.013415092186250538\n",
      "Training epoch 5726...\n",
      "\n",
      "Train Epoch: 5726 [0/8000 (0%)]\tBatch Loss: 0.012618\tLearning Rate (w_theta): 0.001000\t TIME:2595.1s\n",
      "\t\t\t\tDisc: 0.011912\t\tSym: 0.000000\t\tSpars: 0.000705\n",
      "\t TVw: 0.767876 | TVb: 2.281875 | GSw: -0.503620 | GSb: -0.161732 | TSUw: -0.428267 | TSUb: -0.036945\n",
      "\n",
      "Train Epoch: 5726 [4000/8000 (50%)]\tBatch Loss: 0.012535\tLearning Rate (w_theta): 0.001000\t TIME:2596.4s\n",
      "\t\t\t\tDisc: 0.011883\t\tSym: 0.000000\t\tSpars: 0.000652\n",
      "\t TVw: 0.767788 | TVb: 2.281772 | GSw: -0.503362 | GSb: -0.161489 | TSUw: -0.427678 | TSUb: -0.036343\n",
      "Validating epoch 5726...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012909351533374944\n",
      "Average validation loss: 0.013415542587665601\n",
      "Training epoch 5727...\n",
      "\n",
      "Train Epoch: 5727 [0/8000 (0%)]\tBatch Loss: 0.012811\tLearning Rate (w_theta): 0.001000\t TIME:2598.7s\n",
      "\t\t\t\tDisc: 0.012084\t\tSym: 0.000000\t\tSpars: 0.000727\n",
      "\t TVw: 0.767832 | TVb: 2.281904 | GSw: -0.503395 | GSb: -0.161566 | TSUw: -0.429083 | TSUb: -0.037733\n",
      "\n",
      "Train Epoch: 5727 [4000/8000 (50%)]\tBatch Loss: 0.012719\tLearning Rate (w_theta): 0.001000\t TIME:2600.0s\n",
      "\t\t\t\tDisc: 0.011860\t\tSym: 0.000000\t\tSpars: 0.000859\n",
      "\t TVw: 0.767680 | TVb: 2.281790 | GSw: -0.503176 | GSb: -0.161348 | TSUw: -0.428681 | TSUb: -0.037317\n",
      "Validating epoch 5727...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012907409701939522\n",
      "Average validation loss: 0.013414600393754358\n",
      "Training epoch 5728...\n",
      "\n",
      "Train Epoch: 5728 [0/8000 (0%)]\tBatch Loss: 0.013625\tLearning Rate (w_theta): 0.001000\t TIME:2602.2s\n",
      "\t\t\t\tDisc: 0.012782\t\tSym: 0.000000\t\tSpars: 0.000843\n",
      "\t TVw: 0.767877 | TVb: 2.281855 | GSw: -0.502964 | GSb: -0.161147 | TSUw: -0.428414 | TSUb: -0.037036\n",
      "\n",
      "Train Epoch: 5728 [4000/8000 (50%)]\tBatch Loss: 0.012907\tLearning Rate (w_theta): 0.001000\t TIME:2603.5s\n",
      "\t\t\t\tDisc: 0.012278\t\tSym: 0.000000\t\tSpars: 0.000629\n",
      "\t TVw: 0.767753 | TVb: 2.281956 | GSw: -0.502791 | GSb: -0.160995 | TSUw: -0.428486 | TSUb: -0.037095\n",
      "Validating epoch 5728...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012904707758540218\n",
      "Average validation loss: 0.013416452092719935\n",
      "Training epoch 5729...\n",
      "\n",
      "Train Epoch: 5729 [0/8000 (0%)]\tBatch Loss: 0.012951\tLearning Rate (w_theta): 0.001000\t TIME:2605.7s\n",
      "\t\t\t\tDisc: 0.012086\t\tSym: 0.000000\t\tSpars: 0.000865\n",
      "\t TVw: 0.768117 | TVb: 2.282124 | GSw: -0.502670 | GSb: -0.160898 | TSUw: -0.428964 | TSUb: -0.037560\n",
      "\n",
      "Train Epoch: 5729 [4000/8000 (50%)]\tBatch Loss: 0.013192\tLearning Rate (w_theta): 0.001000\t TIME:2607.0s\n",
      "\t\t\t\tDisc: 0.012289\t\tSym: 0.000000\t\tSpars: 0.000904\n",
      "\t TVw: 0.768193 | TVb: 2.281956 | GSw: -0.502370 | GSb: -0.160598 | TSUw: -0.428141 | TSUb: -0.036725\n",
      "Validating epoch 5729...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012907988784279073\n",
      "Average validation loss: 0.013415601427611291\n",
      "Training epoch 5730...\n",
      "\n",
      "Train Epoch: 5730 [0/8000 (0%)]\tBatch Loss: 0.012958\tLearning Rate (w_theta): 0.001000\t TIME:2609.2s\n",
      "\t\t\t\tDisc: 0.012045\t\tSym: 0.000000\t\tSpars: 0.000912\n",
      "\t TVw: 0.768195 | TVb: 2.282033 | GSw: -0.502299 | GSb: -0.160555 | TSUw: -0.428905 | TSUb: -0.037475\n",
      "\n",
      "Train Epoch: 5730 [4000/8000 (50%)]\tBatch Loss: 0.012908\tLearning Rate (w_theta): 0.001000\t TIME:2610.5s\n",
      "\t\t\t\tDisc: 0.012057\t\tSym: 0.000000\t\tSpars: 0.000851\n",
      "\t TVw: 0.768024 | TVb: 2.282131 | GSw: -0.502143 | GSb: -0.160423 | TSUw: -0.429147 | TSUb: -0.037703\n",
      "Validating epoch 5730...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01290652424153277\n",
      "Average validation loss: 0.013413526094470957\n",
      "Training epoch 5731...\n",
      "\n",
      "Train Epoch: 5731 [0/8000 (0%)]\tBatch Loss: 0.013128\tLearning Rate (w_theta): 0.001000\t TIME:2613.4s\n",
      "\t\t\t\tDisc: 0.012384\t\tSym: 0.000000\t\tSpars: 0.000744\n",
      "\t TVw: 0.767936 | TVb: 2.281959 | GSw: -0.501827 | GSb: -0.160107 | TSUw: -0.428213 | TSUb: -0.036757\n",
      "\n",
      "Train Epoch: 5731 [4000/8000 (50%)]\tBatch Loss: 0.012980\tLearning Rate (w_theta): 0.001000\t TIME:2614.7s\n",
      "\t\t\t\tDisc: 0.012170\t\tSym: 0.000000\t\tSpars: 0.000810\n",
      "\t TVw: 0.768164 | TVb: 2.282059 | GSw: -0.501694 | GSb: -0.159995 | TSUw: -0.428541 | TSUb: -0.037072\n",
      "Validating epoch 5731...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012904636454325932\n",
      "Average validation loss: 0.013416670823743317\n",
      "Training epoch 5732...\n",
      "\n",
      "Train Epoch: 5732 [0/8000 (0%)]\tBatch Loss: 0.013526\tLearning Rate (w_theta): 0.001000\t TIME:2617.0s\n",
      "\t\t\t\tDisc: 0.012610\t\tSym: 0.000000\t\tSpars: 0.000916\n",
      "\t TVw: 0.768443 | TVb: 2.282183 | GSw: -0.501583 | GSb: -0.159910 | TSUw: -0.429083 | TSUb: -0.037601\n",
      "\n",
      "Train Epoch: 5732 [4000/8000 (50%)]\tBatch Loss: 0.012762\tLearning Rate (w_theta): 0.001000\t TIME:2618.3s\n",
      "\t\t\t\tDisc: 0.012086\t\tSym: 0.000000\t\tSpars: 0.000676\n",
      "\t TVw: 0.769736 | TVb: 2.282654 | GSw: -0.501417 | GSb: -0.159771 | TSUw: -0.429273 | TSUb: -0.037780\n",
      "Validating epoch 5732...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012903506789289068\n",
      "Average validation loss: 0.01341215716674004\n",
      "Training epoch 5733...\n",
      "\n",
      "Train Epoch: 5733 [0/8000 (0%)]\tBatch Loss: 0.013179\tLearning Rate (w_theta): 0.001000\t TIME:2620.5s\n",
      "\t\t\t\tDisc: 0.012370\t\tSym: 0.000000\t\tSpars: 0.000808\n",
      "\t TVw: 0.769712 | TVb: 2.282513 | GSw: -0.501080 | GSb: -0.159431 | TSUw: -0.428248 | TSUb: -0.036744\n",
      "\n",
      "Train Epoch: 5733 [4000/8000 (50%)]\tBatch Loss: 0.013366\tLearning Rate (w_theta): 0.001000\t TIME:2621.8s\n",
      "\t\t\t\tDisc: 0.012538\t\tSym: 0.000000\t\tSpars: 0.000828\n",
      "\t TVw: 0.769154 | TVb: 2.282374 | GSw: -0.500914 | GSb: -0.159284 | TSUw: -0.428318 | TSUb: -0.036799\n",
      "Validating epoch 5733...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012906139083424731\n",
      "Average validation loss: 0.013416147761929027\n",
      "Training epoch 5734...\n",
      "\n",
      "Train Epoch: 5734 [0/8000 (0%)]\tBatch Loss: 0.012933\tLearning Rate (w_theta): 0.001000\t TIME:2624.1s\n",
      "\t\t\t\tDisc: 0.012069\t\tSym: 0.000000\t\tSpars: 0.000864\n",
      "\t TVw: 0.768742 | TVb: 2.282205 | GSw: -0.500840 | GSb: -0.159240 | TSUw: -0.429042 | TSUb: -0.037509\n",
      "\n",
      "Train Epoch: 5734 [4000/8000 (50%)]\tBatch Loss: 0.012723\tLearning Rate (w_theta): 0.001000\t TIME:2625.3s\n",
      "\t\t\t\tDisc: 0.011905\t\tSym: 0.000000\t\tSpars: 0.000818\n",
      "\t TVw: 0.768287 | TVb: 2.281874 | GSw: -0.500637 | GSb: -0.159044 | TSUw: -0.428912 | TSUb: -0.037367\n",
      "Validating epoch 5734...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012904722648378577\n",
      "Average validation loss: 0.013414314597188212\n",
      "Training epoch 5735...\n",
      "\n",
      "Train Epoch: 5735 [0/8000 (0%)]\tBatch Loss: 0.013021\tLearning Rate (w_theta): 0.001000\t TIME:2627.6s\n",
      "\t\t\t\tDisc: 0.012392\t\tSym: 0.000000\t\tSpars: 0.000629\n",
      "\t TVw: 0.768263 | TVb: 2.281793 | GSw: -0.500374 | GSb: -0.158789 | TSUw: -0.428423 | TSUb: -0.036865\n",
      "\n",
      "Train Epoch: 5735 [4000/8000 (50%)]\tBatch Loss: 0.012665\tLearning Rate (w_theta): 0.001000\t TIME:2628.9s\n",
      "\t\t\t\tDisc: 0.011832\t\tSym: 0.000000\t\tSpars: 0.000833\n",
      "\t TVw: 0.768072 | TVb: 2.281602 | GSw: -0.500232 | GSb: -0.158668 | TSUw: -0.428735 | TSUb: -0.037164\n",
      "Validating epoch 5735...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012907169803665132\n",
      "Average validation loss: 0.01342173179761409\n",
      "Training epoch 5736...\n",
      "\n",
      "Train Epoch: 5736 [0/8000 (0%)]\tBatch Loss: 0.012661\tLearning Rate (w_theta): 0.001000\t TIME:2631.2s\n",
      "\t\t\t\tDisc: 0.011714\t\tSym: 0.000000\t\tSpars: 0.000947\n",
      "\t TVw: 0.767984 | TVb: 2.281607 | GSw: -0.500155 | GSb: -0.158627 | TSUw: -0.429510 | TSUb: -0.037926\n",
      "\n",
      "Train Epoch: 5736 [4000/8000 (50%)]\tBatch Loss: 0.012945\tLearning Rate (w_theta): 0.001000\t TIME:2632.5s\n",
      "\t\t\t\tDisc: 0.012108\t\tSym: 0.000000\t\tSpars: 0.000837\n",
      "\t TVw: 0.768451 | TVb: 2.281715 | GSw: -0.499916 | GSb: -0.158397 | TSUw: -0.429154 | TSUb: -0.037558\n",
      "Validating epoch 5736...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012906479716736271\n",
      "Average validation loss: 0.013414776949023648\n",
      "Training epoch 5737...\n",
      "\n",
      "Train Epoch: 5737 [0/8000 (0%)]\tBatch Loss: 0.012716\tLearning Rate (w_theta): 0.001000\t TIME:2634.7s\n",
      "\t\t\t\tDisc: 0.012095\t\tSym: 0.000000\t\tSpars: 0.000621\n",
      "\t TVw: 0.768423 | TVb: 2.281616 | GSw: -0.499554 | GSb: -0.158034 | TSUw: -0.427944 | TSUb: -0.036336\n",
      "\n",
      "Train Epoch: 5737 [4000/8000 (50%)]\tBatch Loss: 0.012668\tLearning Rate (w_theta): 0.001000\t TIME:2635.9s\n",
      "\t\t\t\tDisc: 0.011887\t\tSym: 0.000000\t\tSpars: 0.000781\n",
      "\t TVw: 0.767751 | TVb: 2.281311 | GSw: -0.499391 | GSb: -0.157899 | TSUw: -0.428014 | TSUb: -0.036392\n",
      "Validating epoch 5737...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012912284848106997\n",
      "Average validation loss: 0.013429456936672223\n",
      "Training epoch 5738...\n",
      "\n",
      "Train Epoch: 5738 [0/8000 (0%)]\tBatch Loss: 0.012616\tLearning Rate (w_theta): 0.001000\t TIME:2638.3s\n",
      "\t\t\t\tDisc: 0.011792\t\tSym: 0.000000\t\tSpars: 0.000823\n",
      "\t TVw: 0.768067 | TVb: 2.281619 | GSw: -0.499557 | GSb: -0.158122 | TSUw: -0.430102 | TSUb: -0.038465\n",
      "\n",
      "Train Epoch: 5738 [4000/8000 (50%)]\tBatch Loss: 0.012972\tLearning Rate (w_theta): 0.001000\t TIME:2639.5s\n",
      "\t\t\t\tDisc: 0.012010\t\tSym: 0.000000\t\tSpars: 0.000962\n",
      "\t TVw: 0.767981 | TVb: 2.281550 | GSw: -0.499364 | GSb: -0.157953 | TSUw: -0.429610 | TSUb: -0.037958\n",
      "Validating epoch 5738...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01291359734341964\n",
      "Average validation loss: 0.013415153295749854\n",
      "Training epoch 5739...\n",
      "\n",
      "Train Epoch: 5739 [0/8000 (0%)]\tBatch Loss: 0.012694\tLearning Rate (w_theta): 0.001000\t TIME:2641.7s\n",
      "\t\t\t\tDisc: 0.011847\t\tSym: 0.000000\t\tSpars: 0.000847\n",
      "\t TVw: 0.768113 | TVb: 2.281500 | GSw: -0.499023 | GSb: -0.157615 | TSUw: -0.428192 | TSUb: -0.036525\n",
      "\n",
      "Train Epoch: 5739 [4000/8000 (50%)]\tBatch Loss: 0.012116\tLearning Rate (w_theta): 0.001000\t TIME:2643.0s\n",
      "\t\t\t\tDisc: 0.011474\t\tSym: 0.000000\t\tSpars: 0.000642\n",
      "\t TVw: 0.768072 | TVb: 2.281579 | GSw: -0.498852 | GSb: -0.157456 | TSUw: -0.428023 | TSUb: -0.036343\n",
      "Validating epoch 5739...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012911177938343114\n",
      "Average validation loss: 0.013419339026221217\n",
      "Training epoch 5740...\n",
      "\n",
      "Train Epoch: 5740 [0/8000 (0%)]\tBatch Loss: 0.012586\tLearning Rate (w_theta): 0.001000\t TIME:2645.2s\n",
      "\t\t\t\tDisc: 0.011806\t\tSym: 0.000000\t\tSpars: 0.000780\n",
      "\t TVw: 0.768124 | TVb: 2.281744 | GSw: -0.498982 | GSb: -0.157641 | TSUw: -0.429794 | TSUb: -0.038098\n",
      "\n",
      "Train Epoch: 5740 [4000/8000 (50%)]\tBatch Loss: 0.012759\tLearning Rate (w_theta): 0.001000\t TIME:2646.5s\n",
      "\t\t\t\tDisc: 0.011935\t\tSym: 0.000000\t\tSpars: 0.000824\n",
      "\t TVw: 0.767799 | TVb: 2.281674 | GSw: -0.498900 | GSb: -0.157596 | TSUw: -0.430089 | TSUb: -0.038377\n",
      "Validating epoch 5740...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012912062744979571\n",
      "Average validation loss: 0.013416134616125834\n",
      "Training epoch 5741...\n",
      "\n",
      "Train Epoch: 5741 [0/8000 (0%)]\tBatch Loss: 0.013888\tLearning Rate (w_theta): 0.001000\t TIME:2649.6s\n",
      "\t\t\t\tDisc: 0.012624\t\tSym: 0.000000\t\tSpars: 0.001264\n",
      "\t TVw: 0.768373 | TVb: 2.281693 | GSw: -0.498549 | GSb: -0.157249 | TSUw: -0.428531 | TSUb: -0.036805\n",
      "\n",
      "Train Epoch: 5741 [4000/8000 (50%)]\tBatch Loss: 0.012847\tLearning Rate (w_theta): 0.001000\t TIME:2650.9s\n",
      "\t\t\t\tDisc: 0.012004\t\tSym: 0.000000\t\tSpars: 0.000843\n",
      "\t TVw: 0.768779 | TVb: 2.281791 | GSw: -0.498318 | GSb: -0.157039 | TSUw: -0.427876 | TSUb: -0.036137\n",
      "Validating epoch 5741...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01291148336800153\n",
      "Average validation loss: 0.013415378270779562\n",
      "Training epoch 5742...\n",
      "\n",
      "Train Epoch: 5742 [0/8000 (0%)]\tBatch Loss: 0.012683\tLearning Rate (w_theta): 0.001000\t TIME:2653.0s\n",
      "\t\t\t\tDisc: 0.011949\t\tSym: 0.000000\t\tSpars: 0.000733\n",
      "\t TVw: 0.768740 | TVb: 2.281918 | GSw: -0.498421 | GSb: -0.157203 | TSUw: -0.429343 | TSUb: -0.037589\n",
      "\n",
      "Train Epoch: 5742 [4000/8000 (50%)]\tBatch Loss: 0.013138\tLearning Rate (w_theta): 0.001000\t TIME:2654.3s\n",
      "\t\t\t\tDisc: 0.012404\t\tSym: 0.000000\t\tSpars: 0.000734\n",
      "\t TVw: 0.768641 | TVb: 2.282029 | GSw: -0.498358 | GSb: -0.157183 | TSUw: -0.429821 | TSUb: -0.038052\n",
      "Validating epoch 5742...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01290845399808307\n",
      "Average validation loss: 0.013415048363057631\n",
      "Training epoch 5743...\n",
      "\n",
      "Train Epoch: 5743 [0/8000 (0%)]\tBatch Loss: 0.012772\tLearning Rate (w_theta): 0.001000\t TIME:2656.6s\n",
      "\t\t\t\tDisc: 0.011933\t\tSym: 0.000000\t\tSpars: 0.000839\n",
      "\t TVw: 0.768752 | TVb: 2.281974 | GSw: -0.498033 | GSb: -0.156861 | TSUw: -0.428594 | TSUb: -0.036811\n",
      "\n",
      "Train Epoch: 5743 [4000/8000 (50%)]\tBatch Loss: 0.013352\tLearning Rate (w_theta): 0.001000\t TIME:2657.8s\n",
      "\t\t\t\tDisc: 0.012287\t\tSym: 0.000000\t\tSpars: 0.001065\n",
      "\t TVw: 0.768794 | TVb: 2.281870 | GSw: -0.497878 | GSb: -0.156725 | TSUw: -0.428497 | TSUb: -0.036701\n",
      "Validating epoch 5743...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012911946810171706\n",
      "Average validation loss: 0.013420865702740686\n",
      "Training epoch 5744...\n",
      "\n",
      "Train Epoch: 5744 [0/8000 (0%)]\tBatch Loss: 0.012461\tLearning Rate (w_theta): 0.001000\t TIME:2660.0s\n",
      "\t\t\t\tDisc: 0.011828\t\tSym: 0.000000\t\tSpars: 0.000633\n",
      "\t TVw: 0.768853 | TVb: 2.281975 | GSw: -0.497874 | GSb: -0.156763 | TSUw: -0.429363 | TSUb: -0.037553\n",
      "\n",
      "Train Epoch: 5744 [4000/8000 (50%)]\tBatch Loss: 0.013169\tLearning Rate (w_theta): 0.001000\t TIME:2661.3s\n",
      "\t\t\t\tDisc: 0.012288\t\tSym: 0.000000\t\tSpars: 0.000881\n",
      "\t TVw: 0.768264 | TVb: 2.281729 | GSw: -0.497583 | GSb: -0.156481 | TSUw: -0.428473 | TSUb: -0.036649\n",
      "Validating epoch 5744...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012911258519404048\n",
      "Average validation loss: 0.01341618000147327\n",
      "Training epoch 5745...\n",
      "\n",
      "Train Epoch: 5745 [0/8000 (0%)]\tBatch Loss: 0.012731\tLearning Rate (w_theta): 0.001000\t TIME:2663.6s\n",
      "\t\t\t\tDisc: 0.011834\t\tSym: 0.000000\t\tSpars: 0.000896\n",
      "\t TVw: 0.768361 | TVb: 2.281879 | GSw: -0.497577 | GSb: -0.156520 | TSUw: -0.429425 | TSUb: -0.037588\n",
      "\n",
      "Train Epoch: 5745 [4000/8000 (50%)]\tBatch Loss: 0.012630\tLearning Rate (w_theta): 0.001000\t TIME:2664.9s\n",
      "\t\t\t\tDisc: 0.011947\t\tSym: 0.000000\t\tSpars: 0.000683\n",
      "\t TVw: 0.768260 | TVb: 2.281980 | GSw: -0.497514 | GSb: -0.156487 | TSUw: -0.430018 | TSUb: -0.038169\n",
      "Validating epoch 5745...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012910624995262595\n",
      "Average validation loss: 0.013415102363769854\n",
      "Training epoch 5746...\n",
      "\n",
      "Train Epoch: 5746 [0/8000 (0%)]\tBatch Loss: 0.012370\tLearning Rate (w_theta): 0.001000\t TIME:2667.2s\n",
      "\t\t\t\tDisc: 0.011764\t\tSym: 0.000000\t\tSpars: 0.000606\n",
      "\t TVw: 0.768322 | TVb: 2.281815 | GSw: -0.497154 | GSb: -0.156134 | TSUw: -0.428627 | TSUb: -0.036764\n",
      "\n",
      "Train Epoch: 5746 [4000/8000 (50%)]\tBatch Loss: 0.013046\tLearning Rate (w_theta): 0.001000\t TIME:2668.4s\n",
      "\t\t\t\tDisc: 0.012063\t\tSym: 0.000000\t\tSpars: 0.000983\n",
      "\t TVw: 0.768251 | TVb: 2.281703 | GSw: -0.496886 | GSb: -0.155871 | TSUw: -0.427922 | TSUb: -0.036046\n",
      "Validating epoch 5746...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01291198894257521\n",
      "Average validation loss: 0.013415158547943824\n",
      "Training epoch 5747...\n",
      "\n",
      "Train Epoch: 5747 [0/8000 (0%)]\tBatch Loss: 0.013318\tLearning Rate (w_theta): 0.001000\t TIME:2670.8s\n",
      "\t\t\t\tDisc: 0.012419\t\tSym: 0.000000\t\tSpars: 0.000899\n",
      "\t TVw: 0.768501 | TVb: 2.281907 | GSw: -0.497004 | GSb: -0.156050 | TSUw: -0.429491 | TSUb: -0.037602\n",
      "\n",
      "Train Epoch: 5747 [4000/8000 (50%)]\tBatch Loss: 0.013194\tLearning Rate (w_theta): 0.001000\t TIME:2672.0s\n",
      "\t\t\t\tDisc: 0.012316\t\tSym: 0.000000\t\tSpars: 0.000877\n",
      "\t TVw: 0.768452 | TVb: 2.281865 | GSw: -0.496940 | GSb: -0.156022 | TSUw: -0.429875 | TSUb: -0.037972\n",
      "Validating epoch 5747...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012909520692943701\n",
      "Average validation loss: 0.013419691183040709\n",
      "Training epoch 5748...\n",
      "\n",
      "Train Epoch: 5748 [0/8000 (0%)]\tBatch Loss: 0.012789\tLearning Rate (w_theta): 0.001000\t TIME:2674.2s\n",
      "\t\t\t\tDisc: 0.011984\t\tSym: 0.000000\t\tSpars: 0.000805\n",
      "\t TVw: 0.768824 | TVb: 2.281937 | GSw: -0.496690 | GSb: -0.155795 | TSUw: -0.429169 | TSUb: -0.037253\n",
      "\n",
      "Train Epoch: 5748 [4000/8000 (50%)]\tBatch Loss: 0.013100\tLearning Rate (w_theta): 0.001000\t TIME:2675.5s\n",
      "\t\t\t\tDisc: 0.012410\t\tSym: 0.000000\t\tSpars: 0.000690\n",
      "\t TVw: 0.769272 | TVb: 2.282106 | GSw: -0.496526 | GSb: -0.155669 | TSUw: -0.429091 | TSUb: -0.037162\n",
      "Validating epoch 5748...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0129061894389298\n",
      "Average validation loss: 0.013414215333266527\n",
      "Training epoch 5749...\n",
      "\n",
      "Train Epoch: 5749 [0/8000 (0%)]\tBatch Loss: 0.013364\tLearning Rate (w_theta): 0.001000\t TIME:2677.8s\n",
      "\t\t\t\tDisc: 0.012355\t\tSym: 0.000000\t\tSpars: 0.001009\n",
      "\t TVw: 0.769319 | TVb: 2.282042 | GSw: -0.496304 | GSb: -0.155467 | TSUw: -0.428743 | TSUb: -0.036803\n",
      "\n",
      "Train Epoch: 5749 [4000/8000 (50%)]\tBatch Loss: 0.012232\tLearning Rate (w_theta): 0.001000\t TIME:2679.1s\n",
      "\t\t\t\tDisc: 0.011675\t\tSym: 0.000000\t\tSpars: 0.000557\n",
      "\t TVw: 0.768988 | TVb: 2.281922 | GSw: -0.496106 | GSb: -0.155299 | TSUw: -0.428593 | TSUb: -0.036642\n",
      "Validating epoch 5749...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012907074652631079\n",
      "Average validation loss: 0.013420321082831456\n",
      "Training epoch 5750...\n",
      "\n",
      "Train Epoch: 5750 [0/8000 (0%)]\tBatch Loss: 0.012481\tLearning Rate (w_theta): 0.001000\t TIME:2681.3s\n",
      "\t\t\t\tDisc: 0.011771\t\tSym: 0.000000\t\tSpars: 0.000711\n",
      "\t TVw: 0.768868 | TVb: 2.281900 | GSw: -0.496136 | GSb: -0.155379 | TSUw: -0.429834 | TSUb: -0.037872\n",
      "\n",
      "Train Epoch: 5750 [4000/8000 (50%)]\tBatch Loss: 0.013400\tLearning Rate (w_theta): 0.001000\t TIME:2682.6s\n",
      "\t\t\t\tDisc: 0.012572\t\tSym: 0.000000\t\tSpars: 0.000827\n",
      "\t TVw: 0.769010 | TVb: 2.281975 | GSw: -0.495965 | GSb: -0.155236 | TSUw: -0.429752 | TSUb: -0.037779\n",
      "Validating epoch 5750...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012911393023140011\n",
      "Average validation loss: 0.013415096290728637\n",
      "Training epoch 5751...\n",
      "\n",
      "Train Epoch: 5751 [0/8000 (0%)]\tBatch Loss: 0.013460\tLearning Rate (w_theta): 0.001000\t TIME:2685.5s\n",
      "\t\t\t\tDisc: 0.012539\t\tSym: 0.000000\t\tSpars: 0.000921\n",
      "\t TVw: 0.769306 | TVb: 2.281940 | GSw: -0.495577 | GSb: -0.154848 | TSUw: -0.428275 | TSUb: -0.036289\n",
      "\n",
      "Train Epoch: 5751 [4000/8000 (50%)]\tBatch Loss: 0.012388\tLearning Rate (w_theta): 0.001000\t TIME:2686.8s\n",
      "\t\t\t\tDisc: 0.011698\t\tSym: 0.000000\t\tSpars: 0.000691\n",
      "\t TVw: 0.768956 | TVb: 2.281976 | GSw: -0.495548 | GSb: -0.154856 | TSUw: -0.428914 | TSUb: -0.036915\n",
      "Validating epoch 5751...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012910900557193704\n",
      "Average validation loss: 0.013423217074510064\n",
      "Training epoch 5752...\n",
      "\n",
      "Train Epoch: 5752 [0/8000 (0%)]\tBatch Loss: 0.012995\tLearning Rate (w_theta): 0.001000\t TIME:2689.1s\n",
      "\t\t\t\tDisc: 0.012360\t\tSym: 0.000000\t\tSpars: 0.000634\n",
      "\t TVw: 0.768980 | TVb: 2.282078 | GSw: -0.495564 | GSb: -0.154922 | TSUw: -0.429892 | TSUb: -0.037881\n",
      "\n",
      "Train Epoch: 5752 [4000/8000 (50%)]\tBatch Loss: 0.012650\tLearning Rate (w_theta): 0.001000\t TIME:2690.3s\n",
      "\t\t\t\tDisc: 0.011881\t\tSym: 0.000000\t\tSpars: 0.000769\n",
      "\t TVw: 0.768502 | TVb: 2.281672 | GSw: -0.495259 | GSb: -0.154632 | TSUw: -0.428939 | TSUb: -0.036915\n",
      "Validating epoch 5752...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012912679368795919\n",
      "Average validation loss: 0.013416134306235382\n",
      "Training epoch 5753...\n",
      "\n",
      "Train Epoch: 5753 [0/8000 (0%)]\tBatch Loss: 0.013243\tLearning Rate (w_theta): 0.001000\t TIME:2692.6s\n",
      "\t\t\t\tDisc: 0.012364\t\tSym: 0.000000\t\tSpars: 0.000879\n",
      "\t TVw: 0.768563 | TVb: 2.281690 | GSw: -0.495118 | GSb: -0.154521 | TSUw: -0.428965 | TSUb: -0.036929\n",
      "\n",
      "Train Epoch: 5753 [4000/8000 (50%)]\tBatch Loss: 0.012982\tLearning Rate (w_theta): 0.001000\t TIME:2693.9s\n",
      "\t\t\t\tDisc: 0.012118\t\tSym: 0.000000\t\tSpars: 0.000864\n",
      "\t TVw: 0.768864 | TVb: 2.282098 | GSw: -0.495112 | GSb: -0.154556 | TSUw: -0.429846 | TSUb: -0.037798\n",
      "Validating epoch 5753...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012908274364906781\n",
      "Average validation loss: 0.01341973653068087\n",
      "Training epoch 5754...\n",
      "\n",
      "Train Epoch: 5754 [0/8000 (0%)]\tBatch Loss: 0.013157\tLearning Rate (w_theta): 0.001000\t TIME:2696.3s\n",
      "\t\t\t\tDisc: 0.012356\t\tSym: 0.000000\t\tSpars: 0.000801\n",
      "\t TVw: 0.769260 | TVb: 2.282152 | GSw: -0.494891 | GSb: -0.154354 | TSUw: -0.429447 | TSUb: -0.037388\n",
      "\n",
      "Train Epoch: 5754 [4000/8000 (50%)]\tBatch Loss: 0.012868\tLearning Rate (w_theta): 0.001000\t TIME:2697.5s\n",
      "\t\t\t\tDisc: 0.012209\t\tSym: 0.000000\t\tSpars: 0.000659\n",
      "\t TVw: 0.769329 | TVb: 2.281958 | GSw: -0.494713 | GSb: -0.154199 | TSUw: -0.429380 | TSUb: -0.037310\n",
      "Validating epoch 5754...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012904573377834573\n",
      "Average validation loss: 0.013415542424093192\n",
      "Training epoch 5755...\n",
      "\n",
      "Train Epoch: 5755 [0/8000 (0%)]\tBatch Loss: 0.013164\tLearning Rate (w_theta): 0.001000\t TIME:2699.7s\n",
      "\t\t\t\tDisc: 0.012496\t\tSym: 0.000000\t\tSpars: 0.000668\n",
      "\t TVw: 0.769434 | TVb: 2.281858 | GSw: -0.494365 | GSb: -0.153859 | TSUw: -0.428333 | TSUb: -0.036253\n",
      "\n",
      "Train Epoch: 5755 [4000/8000 (50%)]\tBatch Loss: 0.012434\tLearning Rate (w_theta): 0.001000\t TIME:2701.0s\n",
      "\t\t\t\tDisc: 0.011874\t\tSym: 0.000000\t\tSpars: 0.000560\n",
      "\t TVw: 0.769678 | TVb: 2.281999 | GSw: -0.494320 | GSb: -0.153868 | TSUw: -0.428966 | TSUb: -0.036875\n",
      "Validating epoch 5755...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012909869938415738\n",
      "Average validation loss: 0.013425430110890287\n",
      "Training epoch 5756...\n",
      "\n",
      "Train Epoch: 5756 [0/8000 (0%)]\tBatch Loss: 0.012549\tLearning Rate (w_theta): 0.001000\t TIME:2703.3s\n",
      "\t\t\t\tDisc: 0.011742\t\tSym: 0.000000\t\tSpars: 0.000808\n",
      "\t TVw: 0.769737 | TVb: 2.282130 | GSw: -0.494373 | GSb: -0.153988 | TSUw: -0.430211 | TSUb: -0.038109\n",
      "\n",
      "Train Epoch: 5756 [4000/8000 (50%)]\tBatch Loss: 0.013245\tLearning Rate (w_theta): 0.001000\t TIME:2704.6s\n",
      "\t\t\t\tDisc: 0.012472\t\tSym: 0.000000\t\tSpars: 0.000773\n",
      "\t TVw: 0.770609 | TVb: 2.282540 | GSw: -0.494187 | GSb: -0.153831 | TSUw: -0.429940 | TSUb: -0.037826\n",
      "Validating epoch 5756...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012908371988054184\n",
      "Average validation loss: 0.013413259353410048\n",
      "Training epoch 5757...\n",
      "\n",
      "Train Epoch: 5757 [0/8000 (0%)]\tBatch Loss: 0.012798\tLearning Rate (w_theta): 0.001000\t TIME:2706.8s\n",
      "\t\t\t\tDisc: 0.011986\t\tSym: 0.000000\t\tSpars: 0.000813\n",
      "\t TVw: 0.770876 | TVb: 2.282578 | GSw: -0.493825 | GSb: -0.153479 | TSUw: -0.428604 | TSUb: -0.036478\n",
      "\n",
      "Train Epoch: 5757 [4000/8000 (50%)]\tBatch Loss: 0.013078\tLearning Rate (w_theta): 0.001000\t TIME:2708.0s\n",
      "\t\t\t\tDisc: 0.012265\t\tSym: 0.000000\t\tSpars: 0.000813\n",
      "\t TVw: 0.770606 | TVb: 2.282672 | GSw: -0.493677 | GSb: -0.153367 | TSUw: -0.428598 | TSUb: -0.036461\n",
      "Validating epoch 5757...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012910080974126534\n",
      "Average validation loss: 0.013422497633569343\n",
      "Training epoch 5758...\n",
      "\n",
      "Train Epoch: 5758 [0/8000 (0%)]\tBatch Loss: 0.013127\tLearning Rate (w_theta): 0.001000\t TIME:2710.3s\n",
      "\t\t\t\tDisc: 0.012403\t\tSym: 0.000000\t\tSpars: 0.000724\n",
      "\t TVw: 0.770436 | TVb: 2.282670 | GSw: -0.493789 | GSb: -0.153538 | TSUw: -0.429991 | TSUb: -0.037842\n",
      "\n",
      "Train Epoch: 5758 [4000/8000 (50%)]\tBatch Loss: 0.012367\tLearning Rate (w_theta): 0.001000\t TIME:2711.6s\n",
      "\t\t\t\tDisc: 0.011865\t\tSym: 0.000000\t\tSpars: 0.000502\n",
      "\t TVw: 0.770401 | TVb: 2.282514 | GSw: -0.493583 | GSb: -0.153350 | TSUw: -0.429513 | TSUb: -0.037353\n",
      "Validating epoch 5758...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012905976603147738\n",
      "Average validation loss: 0.013414726793127557\n",
      "Training epoch 5759...\n",
      "\n",
      "Train Epoch: 5759 [0/8000 (0%)]\tBatch Loss: 0.012994\tLearning Rate (w_theta): 0.001000\t TIME:2713.9s\n",
      "\t\t\t\tDisc: 0.012301\t\tSym: 0.000000\t\tSpars: 0.000693\n",
      "\t TVw: 0.770258 | TVb: 2.282337 | GSw: -0.493386 | GSb: -0.153189 | TSUw: -0.429256 | TSUb: -0.037084\n",
      "\n",
      "Train Epoch: 5759 [4000/8000 (50%)]\tBatch Loss: 0.013058\tLearning Rate (w_theta): 0.001000\t TIME:2715.2s\n",
      "\t\t\t\tDisc: 0.012076\t\tSym: 0.000000\t\tSpars: 0.000982\n",
      "\t TVw: 0.770657 | TVb: 2.282465 | GSw: -0.493246 | GSb: -0.153085 | TSUw: -0.429404 | TSUb: -0.037223\n",
      "Validating epoch 5759...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012904698022032618\n",
      "Average validation loss: 0.013415809611216701\n",
      "Training epoch 5760...\n",
      "\n",
      "Train Epoch: 5760 [0/8000 (0%)]\tBatch Loss: 0.012922\tLearning Rate (w_theta): 0.001000\t TIME:2717.5s\n",
      "\t\t\t\tDisc: 0.012305\t\tSym: 0.000000\t\tSpars: 0.000617\n",
      "\t TVw: 0.770836 | TVb: 2.282507 | GSw: -0.493069 | GSb: -0.152942 | TSUw: -0.429380 | TSUb: -0.037189\n",
      "\n",
      "Train Epoch: 5760 [4000/8000 (50%)]\tBatch Loss: 0.012918\tLearning Rate (w_theta): 0.001000\t TIME:2718.8s\n",
      "\t\t\t\tDisc: 0.012152\t\tSym: 0.000000\t\tSpars: 0.000765\n",
      "\t TVw: 0.770385 | TVb: 2.282221 | GSw: -0.492912 | GSb: -0.152809 | TSUw: -0.429484 | TSUb: -0.037282\n",
      "Validating epoch 5760...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0129052895376996\n",
      "Average validation loss: 0.01341658561220305\n",
      "Training epoch 5761...\n",
      "\n",
      "Train Epoch: 5761 [0/8000 (0%)]\tBatch Loss: 0.013109\tLearning Rate (w_theta): 0.001000\t TIME:2721.8s\n",
      "\t\t\t\tDisc: 0.012548\t\tSym: 0.000000\t\tSpars: 0.000561\n",
      "\t TVw: 0.770351 | TVb: 2.282200 | GSw: -0.492685 | GSb: -0.152614 | TSUw: -0.429220 | TSUb: -0.037009\n",
      "\n",
      "Train Epoch: 5761 [4000/8000 (50%)]\tBatch Loss: 0.012989\tLearning Rate (w_theta): 0.001000\t TIME:2723.1s\n",
      "\t\t\t\tDisc: 0.012330\t\tSym: 0.000000\t\tSpars: 0.000659\n",
      "\t TVw: 0.769746 | TVb: 2.282006 | GSw: -0.492455 | GSb: -0.152415 | TSUw: -0.428876 | TSUb: -0.036653\n",
      "Validating epoch 5761...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012910044245754499\n",
      "Average validation loss: 0.01342001979374874\n",
      "Training epoch 5762...\n",
      "\n",
      "Train Epoch: 5762 [0/8000 (0%)]\tBatch Loss: 0.012576\tLearning Rate (w_theta): 0.001000\t TIME:2725.4s\n",
      "\t\t\t\tDisc: 0.011752\t\tSym: 0.000000\t\tSpars: 0.000825\n",
      "\t TVw: 0.769862 | TVb: 2.282090 | GSw: -0.492490 | GSb: -0.152516 | TSUw: -0.430041 | TSUb: -0.037809\n",
      "\n",
      "Train Epoch: 5762 [4000/8000 (50%)]\tBatch Loss: 0.012851\tLearning Rate (w_theta): 0.001000\t TIME:2726.7s\n",
      "\t\t\t\tDisc: 0.011981\t\tSym: 0.000000\t\tSpars: 0.000869\n",
      "\t TVw: 0.770331 | TVb: 2.282165 | GSw: -0.492295 | GSb: -0.152360 | TSUw: -0.429802 | TSUb: -0.037559\n",
      "Validating epoch 5762...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012908475623713646\n",
      "Average validation loss: 0.013414880022999044\n",
      "Training epoch 5763...\n",
      "\n",
      "Train Epoch: 5763 [0/8000 (0%)]\tBatch Loss: 0.013087\tLearning Rate (w_theta): 0.001000\t TIME:2729.0s\n",
      "\t\t\t\tDisc: 0.012334\t\tSym: 0.000000\t\tSpars: 0.000753\n",
      "\t TVw: 0.770324 | TVb: 2.282153 | GSw: -0.492012 | GSb: -0.152098 | TSUw: -0.429071 | TSUb: -0.036817\n",
      "\n",
      "Train Epoch: 5763 [4000/8000 (50%)]\tBatch Loss: 0.012790\tLearning Rate (w_theta): 0.001000\t TIME:2730.3s\n",
      "\t\t\t\tDisc: 0.012044\t\tSym: 0.000000\t\tSpars: 0.000746\n",
      "\t TVw: 0.770059 | TVb: 2.282068 | GSw: -0.491888 | GSb: -0.152014 | TSUw: -0.429328 | TSUb: -0.037064\n",
      "Validating epoch 5763...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012906447824171512\n",
      "Average validation loss: 0.01341614118569564\n",
      "Training epoch 5764...\n",
      "\n",
      "Train Epoch: 5764 [0/8000 (0%)]\tBatch Loss: 0.012822\tLearning Rate (w_theta): 0.001000\t TIME:2732.5s\n",
      "\t\t\t\tDisc: 0.012000\t\tSym: 0.000000\t\tSpars: 0.000823\n",
      "\t TVw: 0.770174 | TVb: 2.282131 | GSw: -0.491769 | GSb: -0.151932 | TSUw: -0.429655 | TSUb: -0.037382\n",
      "\n",
      "Train Epoch: 5764 [4000/8000 (50%)]\tBatch Loss: 0.013053\tLearning Rate (w_theta): 0.001000\t TIME:2733.7s\n",
      "\t\t\t\tDisc: 0.012210\t\tSym: 0.000000\t\tSpars: 0.000843\n",
      "\t TVw: 0.769895 | TVb: 2.282085 | GSw: -0.491543 | GSb: -0.151731 | TSUw: -0.429395 | TSUb: -0.037111\n",
      "Validating epoch 5764...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012906733546828038\n",
      "Average validation loss: 0.013417084636116839\n",
      "Training epoch 5765...\n",
      "\n",
      "Train Epoch: 5765 [0/8000 (0%)]\tBatch Loss: 0.013215\tLearning Rate (w_theta): 0.001000\t TIME:2735.9s\n",
      "\t\t\t\tDisc: 0.012157\t\tSym: 0.000000\t\tSpars: 0.001058\n",
      "\t TVw: 0.770317 | TVb: 2.282251 | GSw: -0.491433 | GSb: -0.151657 | TSUw: -0.429789 | TSUb: -0.037496\n",
      "\n",
      "Train Epoch: 5765 [4000/8000 (50%)]\tBatch Loss: 0.012782\tLearning Rate (w_theta): 0.001000\t TIME:2737.3s\n",
      "\t\t\t\tDisc: 0.012180\t\tSym: 0.000000\t\tSpars: 0.000602\n",
      "\t TVw: 0.771581 | TVb: 2.282740 | GSw: -0.491302 | GSb: -0.151560 | TSUw: -0.430021 | TSUb: -0.037721\n",
      "Validating epoch 5765...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012905549760518265\n",
      "Average validation loss: 0.013413179069431302\n",
      "Training epoch 5766...\n",
      "\n",
      "Train Epoch: 5766 [0/8000 (0%)]\tBatch Loss: 0.012711\tLearning Rate (w_theta): 0.001000\t TIME:2739.5s\n",
      "\t\t\t\tDisc: 0.011950\t\tSym: 0.000000\t\tSpars: 0.000761\n",
      "\t TVw: 0.771561 | TVb: 2.282568 | GSw: -0.490979 | GSb: -0.151257 | TSUw: -0.429162 | TSUb: -0.036851\n",
      "\n",
      "Train Epoch: 5766 [4000/8000 (50%)]\tBatch Loss: 0.012953\tLearning Rate (w_theta): 0.001000\t TIME:2740.8s\n",
      "\t\t\t\tDisc: 0.012276\t\tSym: 0.000000\t\tSpars: 0.000677\n",
      "\t TVw: 0.770889 | TVb: 2.282315 | GSw: -0.490825 | GSb: -0.151142 | TSUw: -0.429262 | TSUb: -0.036941\n",
      "Validating epoch 5766...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012906469804806213\n",
      "Average validation loss: 0.013417645339972894\n",
      "Training epoch 5767...\n",
      "\n",
      "Train Epoch: 5767 [0/8000 (0%)]\tBatch Loss: 0.012611\tLearning Rate (w_theta): 0.001000\t TIME:2743.1s\n",
      "\t\t\t\tDisc: 0.011631\t\tSym: 0.000000\t\tSpars: 0.000980\n",
      "\t TVw: 0.770928 | TVb: 2.282406 | GSw: -0.490758 | GSb: -0.151128 | TSUw: -0.429874 | TSUb: -0.037543\n",
      "\n",
      "Train Epoch: 5767 [4000/8000 (50%)]\tBatch Loss: 0.013341\tLearning Rate (w_theta): 0.001000\t TIME:2744.5s\n",
      "\t\t\t\tDisc: 0.012448\t\tSym: 0.000000\t\tSpars: 0.000893\n",
      "\t TVw: 0.771049 | TVb: 2.282271 | GSw: -0.490505 | GSb: -0.150906 | TSUw: -0.429418 | TSUb: -0.037078\n",
      "Validating epoch 5767...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012906128458851647\n",
      "Average validation loss: 0.013414540154804505\n",
      "Training epoch 5768...\n",
      "\n",
      "Train Epoch: 5768 [0/8000 (0%)]\tBatch Loss: 0.013114\tLearning Rate (w_theta): 0.001000\t TIME:2746.7s\n",
      "\t\t\t\tDisc: 0.012379\t\tSym: 0.000000\t\tSpars: 0.000735\n",
      "\t TVw: 0.771073 | TVb: 2.282255 | GSw: -0.490314 | GSb: -0.150746 | TSUw: -0.429297 | TSUb: -0.036947\n",
      "\n",
      "Train Epoch: 5768 [4000/8000 (50%)]\tBatch Loss: 0.012816\tLearning Rate (w_theta): 0.001000\t TIME:2747.9s\n",
      "\t\t\t\tDisc: 0.012253\t\tSym: 0.000000\t\tSpars: 0.000564\n",
      "\t TVw: 0.771376 | TVb: 2.282456 | GSw: -0.490192 | GSb: -0.150658 | TSUw: -0.429565 | TSUb: -0.037206\n",
      "Validating epoch 5768...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012906758813422188\n",
      "Average validation loss: 0.013418705765014898\n",
      "Training epoch 5769...\n",
      "\n",
      "Train Epoch: 5769 [0/8000 (0%)]\tBatch Loss: 0.013228\tLearning Rate (w_theta): 0.001000\t TIME:2750.2s\n",
      "\t\t\t\tDisc: 0.012436\t\tSym: 0.000000\t\tSpars: 0.000793\n",
      "\t TVw: 0.771200 | TVb: 2.282446 | GSw: -0.490104 | GSb: -0.150613 | TSUw: -0.430039 | TSUb: -0.037671\n",
      "\n",
      "Train Epoch: 5769 [4000/8000 (50%)]\tBatch Loss: 0.013029\tLearning Rate (w_theta): 0.001000\t TIME:2751.4s\n",
      "\t\t\t\tDisc: 0.012216\t\tSym: 0.000000\t\tSpars: 0.000812\n",
      "\t TVw: 0.771011 | TVb: 2.282339 | GSw: -0.489891 | GSb: -0.150430 | TSUw: -0.429776 | TSUb: -0.037397\n",
      "Validating epoch 5769...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012907178460815145\n",
      "Average validation loss: 0.013415071171183015\n",
      "Training epoch 5770...\n",
      "\n",
      "Train Epoch: 5770 [0/8000 (0%)]\tBatch Loss: 0.013095\tLearning Rate (w_theta): 0.001000\t TIME:2753.7s\n",
      "\t\t\t\tDisc: 0.012205\t\tSym: 0.000000\t\tSpars: 0.000891\n",
      "\t TVw: 0.770907 | TVb: 2.282310 | GSw: -0.489658 | GSb: -0.150224 | TSUw: -0.429421 | TSUb: -0.037032\n",
      "\n",
      "Train Epoch: 5770 [4000/8000 (50%)]\tBatch Loss: 0.012811\tLearning Rate (w_theta): 0.001000\t TIME:2755.0s\n",
      "\t\t\t\tDisc: 0.012037\t\tSym: 0.000000\t\tSpars: 0.000774\n",
      "\t TVw: 0.770122 | TVb: 2.281836 | GSw: -0.489432 | GSb: -0.150022 | TSUw: -0.429153 | TSUb: -0.036754\n",
      "Validating epoch 5770...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012907502916115208\n",
      "Average validation loss: 0.013419109918837975\n",
      "Training epoch 5771...\n",
      "\n",
      "Train Epoch: 5771 [0/8000 (0%)]\tBatch Loss: 0.012299\tLearning Rate (w_theta): 0.001000\t TIME:2757.9s\n",
      "\t\t\t\tDisc: 0.011783\t\tSym: 0.000000\t\tSpars: 0.000516\n",
      "\t TVw: 0.770065 | TVb: 2.281919 | GSw: -0.489404 | GSb: -0.150048 | TSUw: -0.429986 | TSUb: -0.037578\n",
      "\n",
      "Train Epoch: 5771 [4000/8000 (50%)]\tBatch Loss: 0.013509\tLearning Rate (w_theta): 0.001000\t TIME:2759.1s\n",
      "\t\t\t\tDisc: 0.012687\t\tSym: 0.000000\t\tSpars: 0.000821\n",
      "\t TVw: 0.770076 | TVb: 2.281905 | GSw: -0.489285 | GSb: -0.149981 | TSUw: -0.430288 | TSUb: -0.037871\n",
      "Validating epoch 5771...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01290808361785981\n",
      "Average validation loss: 0.013418208440996062\n",
      "Training epoch 5772...\n",
      "\n",
      "Train Epoch: 5772 [0/8000 (0%)]\tBatch Loss: 0.013888\tLearning Rate (w_theta): 0.001000\t TIME:2761.3s\n",
      "\t\t\t\tDisc: 0.012908\t\tSym: 0.000000\t\tSpars: 0.000980\n",
      "\t TVw: 0.770419 | TVb: 2.281948 | GSw: -0.489016 | GSb: -0.149738 | TSUw: -0.429687 | TSUb: -0.037260\n",
      "\n",
      "Train Epoch: 5772 [4000/8000 (50%)]\tBatch Loss: 0.012666\tLearning Rate (w_theta): 0.001000\t TIME:2762.7s\n",
      "\t\t\t\tDisc: 0.011919\t\tSym: 0.000000\t\tSpars: 0.000747\n",
      "\t TVw: 0.770694 | TVb: 2.282103 | GSw: -0.488773 | GSb: -0.149526 | TSUw: -0.429292 | TSUb: -0.036855\n",
      "Validating epoch 5772...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012907405471169968\n",
      "Average validation loss: 0.013415927903537411\n",
      "Training epoch 5773...\n",
      "\n",
      "Train Epoch: 5773 [0/8000 (0%)]\tBatch Loss: 0.012368\tLearning Rate (w_theta): 0.001000\t TIME:2764.9s\n",
      "\t\t\t\tDisc: 0.011835\t\tSym: 0.000000\t\tSpars: 0.000533\n",
      "\t TVw: 0.770651 | TVb: 2.282108 | GSw: -0.488669 | GSb: -0.149471 | TSUw: -0.429682 | TSUb: -0.037236\n",
      "\n",
      "Train Epoch: 5773 [4000/8000 (50%)]\tBatch Loss: 0.012972\tLearning Rate (w_theta): 0.001000\t TIME:2766.1s\n",
      "\t\t\t\tDisc: 0.012125\t\tSym: 0.000000\t\tSpars: 0.000846\n",
      "\t TVw: 0.771287 | TVb: 2.282401 | GSw: -0.488612 | GSb: -0.149467 | TSUw: -0.430356 | TSUb: -0.037901\n",
      "Validating epoch 5773...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012907982495872147\n",
      "Average validation loss: 0.013417089589789865\n",
      "Training epoch 5774...\n",
      "\n",
      "Train Epoch: 5774 [0/8000 (0%)]\tBatch Loss: 0.012930\tLearning Rate (w_theta): 0.001000\t TIME:2768.3s\n",
      "\t\t\t\tDisc: 0.012327\t\tSym: 0.000000\t\tSpars: 0.000604\n",
      "\t TVw: 0.771170 | TVb: 2.282176 | GSw: -0.488328 | GSb: -0.149203 | TSUw: -0.429666 | TSUb: -0.037201\n",
      "\n",
      "Train Epoch: 5774 [4000/8000 (50%)]\tBatch Loss: 0.012469\tLearning Rate (w_theta): 0.001000\t TIME:2769.7s\n",
      "\t\t\t\tDisc: 0.011731\t\tSym: 0.000000\t\tSpars: 0.000739\n",
      "\t TVw: 0.771051 | TVb: 2.282161 | GSw: -0.488101 | GSb: -0.148998 | TSUw: -0.429311 | TSUb: -0.036836\n",
      "Validating epoch 5774...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012906417627166617\n",
      "Average validation loss: 0.013415820773022693\n",
      "Training epoch 5775...\n",
      "\n",
      "Train Epoch: 5775 [0/8000 (0%)]\tBatch Loss: 0.013331\tLearning Rate (w_theta): 0.001000\t TIME:2771.9s\n",
      "\t\t\t\tDisc: 0.012308\t\tSym: 0.000000\t\tSpars: 0.001023\n",
      "\t TVw: 0.771226 | TVb: 2.282256 | GSw: -0.487994 | GSb: -0.148938 | TSUw: -0.429669 | TSUb: -0.037185\n",
      "\n",
      "Train Epoch: 5775 [4000/8000 (50%)]\tBatch Loss: 0.012707\tLearning Rate (w_theta): 0.001000\t TIME:2773.2s\n",
      "\t\t\t\tDisc: 0.012104\t\tSym: 0.000000\t\tSpars: 0.000603\n",
      "\t TVw: 0.771622 | TVb: 2.282280 | GSw: -0.487891 | GSb: -0.148877 | TSUw: -0.430088 | TSUb: -0.037595\n",
      "Validating epoch 5775...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012905857687644937\n",
      "Average validation loss: 0.013417375440196645\n",
      "Training epoch 5776...\n",
      "\n",
      "Train Epoch: 5776 [0/8000 (0%)]\tBatch Loss: 0.012857\tLearning Rate (w_theta): 0.001000\t TIME:2775.4s\n",
      "\t\t\t\tDisc: 0.012100\t\tSym: 0.000000\t\tSpars: 0.000757\n",
      "\t TVw: 0.771582 | TVb: 2.282195 | GSw: -0.487661 | GSb: -0.148683 | TSUw: -0.429788 | TSUb: -0.037286\n",
      "\n",
      "Train Epoch: 5776 [4000/8000 (50%)]\tBatch Loss: 0.012650\tLearning Rate (w_theta): 0.001000\t TIME:2776.7s\n",
      "\t\t\t\tDisc: 0.011895\t\tSym: 0.000000\t\tSpars: 0.000755\n",
      "\t TVw: 0.771764 | TVb: 2.282372 | GSw: -0.487524 | GSb: -0.148604 | TSUw: -0.430003 | TSUb: -0.037491\n",
      "Validating epoch 5776...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012905433571749848\n",
      "Average validation loss: 0.013415089333892643\n",
      "Training epoch 5777...\n",
      "\n",
      "Train Epoch: 5777 [0/8000 (0%)]\tBatch Loss: 0.012379\tLearning Rate (w_theta): 0.001000\t TIME:2778.9s\n",
      "\t\t\t\tDisc: 0.011569\t\tSym: 0.000000\t\tSpars: 0.000811\n",
      "\t TVw: 0.771690 | TVb: 2.282324 | GSw: -0.487257 | GSb: -0.148375 | TSUw: -0.429523 | TSUb: -0.037001\n",
      "\n",
      "Train Epoch: 5777 [4000/8000 (50%)]\tBatch Loss: 0.012935\tLearning Rate (w_theta): 0.001000\t TIME:2780.2s\n",
      "\t\t\t\tDisc: 0.012019\t\tSym: 0.000000\t\tSpars: 0.000915\n",
      "\t TVw: 0.771419 | TVb: 2.282226 | GSw: -0.487099 | GSb: -0.148248 | TSUw: -0.429648 | TSUb: -0.037118\n",
      "Validating epoch 5777...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01290730276628524\n",
      "Average validation loss: 0.013419151810603273\n",
      "Training epoch 5778...\n",
      "\n",
      "Train Epoch: 5778 [0/8000 (0%)]\tBatch Loss: 0.012628\tLearning Rate (w_theta): 0.001000\t TIME:2782.5s\n",
      "\t\t\t\tDisc: 0.011902\t\tSym: 0.000000\t\tSpars: 0.000726\n",
      "\t TVw: 0.771319 | TVb: 2.282192 | GSw: -0.486978 | GSb: -0.148169 | TSUw: -0.429969 | TSUb: -0.037430\n",
      "\n",
      "Train Epoch: 5778 [4000/8000 (50%)]\tBatch Loss: 0.013335\tLearning Rate (w_theta): 0.001000\t TIME:2783.7s\n",
      "\t\t\t\tDisc: 0.012292\t\tSym: 0.000000\t\tSpars: 0.001043\n",
      "\t TVw: 0.770651 | TVb: 2.281737 | GSw: -0.486711 | GSb: -0.147923 | TSUw: -0.429438 | TSUb: -0.036888\n",
      "Validating epoch 5778...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012910929482620456\n",
      "Average validation loss: 0.01342301946489628\n",
      "Training epoch 5779...\n",
      "\n",
      "Train Epoch: 5779 [0/8000 (0%)]\tBatch Loss: 0.012605\tLearning Rate (w_theta): 0.001000\t TIME:2786.0s\n",
      "\t\t\t\tDisc: 0.012141\t\tSym: 0.000000\t\tSpars: 0.000464\n",
      "\t TVw: 0.770552 | TVb: 2.281768 | GSw: -0.486656 | GSb: -0.147918 | TSUw: -0.430016 | TSUb: -0.037457\n",
      "\n",
      "Train Epoch: 5779 [4000/8000 (50%)]\tBatch Loss: 0.012913\tLearning Rate (w_theta): 0.001000\t TIME:2787.3s\n",
      "\t\t\t\tDisc: 0.012281\t\tSym: 0.000000\t\tSpars: 0.000632\n",
      "\t TVw: 0.770114 | TVb: 2.281325 | GSw: -0.486437 | GSb: -0.147740 | TSUw: -0.429627 | TSUb: -0.037058\n",
      "Validating epoch 5779...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012912765391506365\n",
      "Average validation loss: 0.013423648051586185\n",
      "Training epoch 5780...\n",
      "\n",
      "Train Epoch: 5780 [0/8000 (0%)]\tBatch Loss: 0.012390\tLearning Rate (w_theta): 0.001000\t TIME:2789.5s\n",
      "\t\t\t\tDisc: 0.011758\t\tSym: 0.000000\t\tSpars: 0.000632\n",
      "\t TVw: 0.770236 | TVb: 2.281432 | GSw: -0.486398 | GSb: -0.147756 | TSUw: -0.430304 | TSUb: -0.037726\n",
      "\n",
      "Train Epoch: 5780 [4000/8000 (50%)]\tBatch Loss: 0.013070\tLearning Rate (w_theta): 0.001000\t TIME:2790.8s\n",
      "\t\t\t\tDisc: 0.012418\t\tSym: 0.000000\t\tSpars: 0.000653\n",
      "\t TVw: 0.770651 | TVb: 2.281823 | GSw: -0.486347 | GSb: -0.147756 | TSUw: -0.430936 | TSUb: -0.038348\n",
      "Validating epoch 5780...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012915142927149119\n",
      "Average validation loss: 0.013416758790583318\n",
      "Training epoch 5781...\n",
      "\n",
      "Train Epoch: 5781 [0/8000 (0%)]\tBatch Loss: 0.013100\tLearning Rate (w_theta): 0.001000\t TIME:2793.7s\n",
      "\t\t\t\tDisc: 0.012302\t\tSym: 0.000000\t\tSpars: 0.000797\n",
      "\t TVw: 0.771111 | TVb: 2.281903 | GSw: -0.485878 | GSb: -0.147297 | TSUw: -0.428987 | TSUb: -0.036386\n",
      "\n",
      "Train Epoch: 5781 [4000/8000 (50%)]\tBatch Loss: 0.012787\tLearning Rate (w_theta): 0.001000\t TIME:2795.0s\n",
      "\t\t\t\tDisc: 0.012140\t\tSym: 0.000000\t\tSpars: 0.000647\n",
      "\t TVw: 0.771141 | TVb: 2.281861 | GSw: -0.485716 | GSb: -0.147189 | TSUw: -0.428719 | TSUb: -0.036106\n",
      "Validating epoch 5781...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01291673626146465\n",
      "Average validation loss: 0.01342419727021428\n",
      "Training epoch 5782...\n",
      "\n",
      "Train Epoch: 5782 [0/8000 (0%)]\tBatch Loss: 0.012527\tLearning Rate (w_theta): 0.001000\t TIME:2797.2s\n",
      "\t\t\t\tDisc: 0.011805\t\tSym: 0.000000\t\tSpars: 0.000723\n",
      "\t TVw: 0.771205 | TVb: 2.282027 | GSw: -0.486041 | GSb: -0.147612 | TSUw: -0.430881 | TSUb: -0.038258\n",
      "\n",
      "Train Epoch: 5782 [4000/8000 (50%)]\tBatch Loss: 0.013069\tLearning Rate (w_theta): 0.001000\t TIME:2798.5s\n",
      "\t\t\t\tDisc: 0.012298\t\tSym: 0.000000\t\tSpars: 0.000771\n",
      "\t TVw: 0.771350 | TVb: 2.281945 | GSw: -0.485916 | GSb: -0.147528 | TSUw: -0.430490 | TSUb: -0.037853\n",
      "Validating epoch 5782...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012918561980685238\n",
      "Average validation loss: 0.013416734292141854\n",
      "Training epoch 5783...\n",
      "\n",
      "Train Epoch: 5783 [0/8000 (0%)]\tBatch Loss: 0.012848\tLearning Rate (w_theta): 0.001000\t TIME:2800.7s\n",
      "\t\t\t\tDisc: 0.012290\t\tSym: 0.000000\t\tSpars: 0.000558\n",
      "\t TVw: 0.771412 | TVb: 2.281919 | GSw: -0.485613 | GSb: -0.147255 | TSUw: -0.429175 | TSUb: -0.036525\n",
      "\n",
      "Train Epoch: 5783 [4000/8000 (50%)]\tBatch Loss: 0.013181\tLearning Rate (w_theta): 0.001000\t TIME:2802.0s\n",
      "\t\t\t\tDisc: 0.012471\t\tSym: 0.000000\t\tSpars: 0.000710\n",
      "\t TVw: 0.771035 | TVb: 2.281836 | GSw: -0.485700 | GSb: -0.147421 | TSUw: -0.430055 | TSUb: -0.037393\n",
      "Validating epoch 5783...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012912201489070721\n",
      "Average validation loss: 0.013425621916805113\n",
      "Training epoch 5784...\n",
      "\n",
      "Train Epoch: 5784 [0/8000 (0%)]\tBatch Loss: 0.012733\tLearning Rate (w_theta): 0.001000\t TIME:2804.4s\n",
      "\t\t\t\tDisc: 0.011888\t\tSym: 0.000000\t\tSpars: 0.000845\n",
      "\t TVw: 0.771138 | TVb: 2.281801 | GSw: -0.485632 | GSb: -0.147413 | TSUw: -0.430248 | TSUb: -0.037575\n",
      "\n",
      "Train Epoch: 5784 [4000/8000 (50%)]\tBatch Loss: 0.012434\tLearning Rate (w_theta): 0.001000\t TIME:2805.7s\n",
      "\t\t\t\tDisc: 0.011707\t\tSym: 0.000000\t\tSpars: 0.000727\n",
      "\t TVw: 0.771610 | TVb: 2.281884 | GSw: -0.485391 | GSb: -0.147222 | TSUw: -0.429565 | TSUb: -0.036881\n",
      "Validating epoch 5784...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012910582430999754\n",
      "Average validation loss: 0.013417253127816879\n",
      "Training epoch 5785...\n",
      "\n",
      "Train Epoch: 5785 [0/8000 (0%)]\tBatch Loss: 0.012497\tLearning Rate (w_theta): 0.001000\t TIME:2808.0s\n",
      "\t\t\t\tDisc: 0.011828\t\tSym: 0.000000\t\tSpars: 0.000670\n",
      "\t TVw: 0.771546 | TVb: 2.281941 | GSw: -0.485337 | GSb: -0.147222 | TSUw: -0.429999 | TSUb: -0.037306\n",
      "\n",
      "Train Epoch: 5785 [4000/8000 (50%)]\tBatch Loss: 0.012857\tLearning Rate (w_theta): 0.001000\t TIME:2809.3s\n",
      "\t\t\t\tDisc: 0.012020\t\tSym: 0.000000\t\tSpars: 0.000836\n",
      "\t TVw: 0.770255 | TVb: 2.281317 | GSw: -0.485227 | GSb: -0.147160 | TSUw: -0.430280 | TSUb: -0.037576\n",
      "Validating epoch 5785...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01291006908683867\n",
      "Average validation loss: 0.01342332965056928\n",
      "Training epoch 5786...\n",
      "\n",
      "Train Epoch: 5786 [0/8000 (0%)]\tBatch Loss: 0.013139\tLearning Rate (w_theta): 0.001000\t TIME:2811.6s\n",
      "\t\t\t\tDisc: 0.012229\t\tSym: 0.000000\t\tSpars: 0.000910\n",
      "\t TVw: 0.770424 | TVb: 2.281371 | GSw: -0.485074 | GSb: -0.147049 | TSUw: -0.430303 | TSUb: -0.037590\n",
      "\n",
      "Train Epoch: 5786 [4000/8000 (50%)]\tBatch Loss: 0.012490\tLearning Rate (w_theta): 0.001000\t TIME:2813.0s\n",
      "\t\t\t\tDisc: 0.011614\t\tSym: 0.000000\t\tSpars: 0.000876\n",
      "\t TVw: 0.770120 | TVb: 2.280998 | GSw: -0.484771 | GSb: -0.146766 | TSUw: -0.429515 | TSUb: -0.036793\n",
      "Validating epoch 5786...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012915757464816605\n",
      "Average validation loss: 0.0134201516942101\n",
      "Training epoch 5787...\n",
      "\n",
      "Train Epoch: 5787 [0/8000 (0%)]\tBatch Loss: 0.013052\tLearning Rate (w_theta): 0.001000\t TIME:2815.2s\n",
      "\t\t\t\tDisc: 0.012388\t\tSym: 0.000000\t\tSpars: 0.000664\n",
      "\t TVw: 0.770173 | TVb: 2.281142 | GSw: -0.484683 | GSb: -0.146729 | TSUw: -0.429793 | TSUb: -0.037061\n",
      "\n",
      "Train Epoch: 5787 [4000/8000 (50%)]\tBatch Loss: 0.012598\tLearning Rate (w_theta): 0.001000\t TIME:2816.5s\n",
      "\t\t\t\tDisc: 0.011916\t\tSym: 0.000000\t\tSpars: 0.000681\n",
      "\t TVw: 0.770971 | TVb: 2.281916 | GSw: -0.484642 | GSb: -0.146742 | TSUw: -0.430280 | TSUb: -0.037540\n",
      "Validating epoch 5787...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012909845890626723\n",
      "Average validation loss: 0.013421441547580966\n",
      "Training epoch 5788...\n",
      "\n",
      "Train Epoch: 5788 [0/8000 (0%)]\tBatch Loss: 0.012596\tLearning Rate (w_theta): 0.001000\t TIME:2818.8s\n",
      "\t\t\t\tDisc: 0.011901\t\tSym: 0.000000\t\tSpars: 0.000695\n",
      "\t TVw: 0.771145 | TVb: 2.282000 | GSw: -0.484470 | GSb: -0.146614 | TSUw: -0.430190 | TSUb: -0.037441\n",
      "\n",
      "Train Epoch: 5788 [4000/8000 (50%)]\tBatch Loss: 0.013021\tLearning Rate (w_theta): 0.001000\t TIME:2820.1s\n",
      "\t\t\t\tDisc: 0.012426\t\tSym: 0.000000\t\tSpars: 0.000595\n",
      "\t TVw: 0.771691 | TVb: 2.282083 | GSw: -0.484268 | GSb: -0.146455 | TSUw: -0.430020 | TSUb: -0.037262\n",
      "Validating epoch 5788...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012907920597082994\n",
      "Average validation loss: 0.01341642479286852\n",
      "Training epoch 5789...\n",
      "\n",
      "Train Epoch: 5789 [0/8000 (0%)]\tBatch Loss: 0.013014\tLearning Rate (w_theta): 0.001000\t TIME:2822.3s\n",
      "\t\t\t\tDisc: 0.012262\t\tSym: 0.000000\t\tSpars: 0.000752\n",
      "\t TVw: 0.771884 | TVb: 2.282079 | GSw: -0.484037 | GSb: -0.146261 | TSUw: -0.429688 | TSUb: -0.036922\n",
      "\n",
      "Train Epoch: 5789 [4000/8000 (50%)]\tBatch Loss: 0.013285\tLearning Rate (w_theta): 0.001000\t TIME:2823.6s\n",
      "\t\t\t\tDisc: 0.012438\t\tSym: 0.000000\t\tSpars: 0.000847\n",
      "\t TVw: 0.771657 | TVb: 2.281991 | GSw: -0.483948 | GSb: -0.146236 | TSUw: -0.430094 | TSUb: -0.037320\n",
      "Validating epoch 5789...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012907515233677731\n",
      "Average validation loss: 0.0134195319889873\n",
      "Training epoch 5790...\n",
      "\n",
      "Train Epoch: 5790 [0/8000 (0%)]\tBatch Loss: 0.012418\tLearning Rate (w_theta): 0.001000\t TIME:2826.0s\n",
      "\t\t\t\tDisc: 0.011580\t\tSym: 0.000000\t\tSpars: 0.000838\n",
      "\t TVw: 0.771800 | TVb: 2.282168 | GSw: -0.483837 | GSb: -0.146176 | TSUw: -0.430420 | TSUb: -0.037638\n",
      "\n",
      "Train Epoch: 5790 [4000/8000 (50%)]\tBatch Loss: 0.012697\tLearning Rate (w_theta): 0.001000\t TIME:2827.3s\n",
      "\t\t\t\tDisc: 0.012123\t\tSym: 0.000000\t\tSpars: 0.000573\n",
      "\t TVw: 0.772097 | TVb: 2.282305 | GSw: -0.483663 | GSb: -0.146047 | TSUw: -0.430354 | TSUb: -0.037563\n",
      "Validating epoch 5790...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012909626597516943\n",
      "Average validation loss: 0.013416699507771671\n",
      "Training epoch 5791...\n",
      "\n",
      "Train Epoch: 5791 [0/8000 (0%)]\tBatch Loss: 0.013632\tLearning Rate (w_theta): 0.001000\t TIME:2830.3s\n",
      "\t\t\t\tDisc: 0.012611\t\tSym: 0.000000\t\tSpars: 0.001020\n",
      "\t TVw: 0.772277 | TVb: 2.282313 | GSw: -0.483334 | GSb: -0.145739 | TSUw: -0.429431 | TSUb: -0.036631\n",
      "\n",
      "Train Epoch: 5791 [4000/8000 (50%)]\tBatch Loss: 0.012777\tLearning Rate (w_theta): 0.001000\t TIME:2831.6s\n",
      "\t\t\t\tDisc: 0.012105\t\tSym: 0.000000\t\tSpars: 0.000673\n",
      "\t TVw: 0.772584 | TVb: 2.282488 | GSw: -0.483262 | GSb: -0.145726 | TSUw: -0.429824 | TSUb: -0.037015\n",
      "Validating epoch 5791...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012909029238356228\n",
      "Average validation loss: 0.013420275022265898\n",
      "Training epoch 5792...\n",
      "\n",
      "Train Epoch: 5792 [0/8000 (0%)]\tBatch Loss: 0.012487\tLearning Rate (w_theta): 0.001000\t TIME:2833.8s\n",
      "\t\t\t\tDisc: 0.011793\t\tSym: 0.000000\t\tSpars: 0.000694\n",
      "\t TVw: 0.772280 | TVb: 2.282408 | GSw: -0.483236 | GSb: -0.145761 | TSUw: -0.430498 | TSUb: -0.037680\n",
      "\n",
      "Train Epoch: 5792 [4000/8000 (50%)]\tBatch Loss: 0.013186\tLearning Rate (w_theta): 0.001000\t TIME:2835.1s\n",
      "\t\t\t\tDisc: 0.012425\t\tSym: 0.000000\t\tSpars: 0.000761\n",
      "\t TVw: 0.771382 | TVb: 2.281917 | GSw: -0.483027 | GSb: -0.145608 | TSUw: -0.430252 | TSUb: -0.037425\n",
      "Validating epoch 5792...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012909667239698757\n",
      "Average validation loss: 0.013418434104732964\n",
      "Training epoch 5793...\n",
      "\n",
      "Train Epoch: 5793 [0/8000 (0%)]\tBatch Loss: 0.013104\tLearning Rate (w_theta): 0.001000\t TIME:2837.4s\n",
      "\t\t\t\tDisc: 0.012282\t\tSym: 0.000000\t\tSpars: 0.000822\n",
      "\t TVw: 0.771143 | TVb: 2.281766 | GSw: -0.482778 | GSb: -0.145391 | TSUw: -0.429767 | TSUb: -0.036930\n",
      "\n",
      "Train Epoch: 5793 [4000/8000 (50%)]\tBatch Loss: 0.013189\tLearning Rate (w_theta): 0.001000\t TIME:2838.6s\n",
      "\t\t\t\tDisc: 0.012392\t\tSym: 0.000000\t\tSpars: 0.000797\n",
      "\t TVw: 0.770870 | TVb: 2.281631 | GSw: -0.482666 | GSb: -0.145329 | TSUw: -0.429963 | TSUb: -0.037117\n",
      "Validating epoch 5793...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012910732063296317\n",
      "Average validation loss: 0.013423462519439908\n",
      "Training epoch 5794...\n",
      "\n",
      "Train Epoch: 5794 [0/8000 (0%)]\tBatch Loss: 0.013167\tLearning Rate (w_theta): 0.001000\t TIME:2840.9s\n",
      "\t\t\t\tDisc: 0.012287\t\tSym: 0.000000\t\tSpars: 0.000880\n",
      "\t TVw: 0.771220 | TVb: 2.281802 | GSw: -0.482612 | GSb: -0.145319 | TSUw: -0.430524 | TSUb: -0.037671\n",
      "\n",
      "Train Epoch: 5794 [4000/8000 (50%)]\tBatch Loss: 0.012946\tLearning Rate (w_theta): 0.001000\t TIME:2842.2s\n",
      "\t\t\t\tDisc: 0.012123\t\tSym: 0.000000\t\tSpars: 0.000823\n",
      "\t TVw: 0.772032 | TVb: 2.281982 | GSw: -0.482428 | GSb: -0.145153 | TSUw: -0.430398 | TSUb: -0.037537\n",
      "Validating epoch 5794...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012908143541796393\n",
      "Average validation loss: 0.01341719385451265\n",
      "Training epoch 5795...\n",
      "\n",
      "Train Epoch: 5795 [0/8000 (0%)]\tBatch Loss: 0.012896\tLearning Rate (w_theta): 0.001000\t TIME:2844.5s\n",
      "\t\t\t\tDisc: 0.012114\t\tSym: 0.000000\t\tSpars: 0.000782\n",
      "\t TVw: 0.772119 | TVb: 2.281930 | GSw: -0.482124 | GSb: -0.144878 | TSUw: -0.429697 | TSUb: -0.036827\n",
      "\n",
      "Train Epoch: 5795 [4000/8000 (50%)]\tBatch Loss: 0.012793\tLearning Rate (w_theta): 0.001000\t TIME:2845.8s\n",
      "\t\t\t\tDisc: 0.012066\t\tSym: 0.000000\t\tSpars: 0.000728\n",
      "\t TVw: 0.771388 | TVb: 2.281692 | GSw: -0.481995 | GSb: -0.144804 | TSUw: -0.429900 | TSUb: -0.037021\n",
      "Validating epoch 5795...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012910043802785381\n",
      "Average validation loss: 0.01342148456237011\n",
      "Training epoch 5796...\n",
      "\n",
      "Train Epoch: 5796 [0/8000 (0%)]\tBatch Loss: 0.013807\tLearning Rate (w_theta): 0.001000\t TIME:2848.1s\n",
      "\t\t\t\tDisc: 0.012847\t\tSym: 0.000000\t\tSpars: 0.000960\n",
      "\t TVw: 0.771100 | TVb: 2.281635 | GSw: -0.481921 | GSb: -0.144783 | TSUw: -0.430393 | TSUb: -0.037506\n",
      "\n",
      "Train Epoch: 5796 [4000/8000 (50%)]\tBatch Loss: 0.012361\tLearning Rate (w_theta): 0.001000\t TIME:2849.4s\n",
      "\t\t\t\tDisc: 0.011599\t\tSym: 0.000000\t\tSpars: 0.000762\n",
      "\t TVw: 0.772011 | TVb: 2.282095 | GSw: -0.481842 | GSb: -0.144759 | TSUw: -0.430849 | TSUb: -0.037955\n",
      "Validating epoch 5796...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012912081469279687\n",
      "Average validation loss: 0.013417401256184198\n",
      "Training epoch 5797...\n",
      "\n",
      "Train Epoch: 5797 [0/8000 (0%)]\tBatch Loss: 0.012959\tLearning Rate (w_theta): 0.001000\t TIME:2851.7s\n",
      "\t\t\t\tDisc: 0.012280\t\tSym: 0.000000\t\tSpars: 0.000679\n",
      "\t TVw: 0.771846 | TVb: 2.281818 | GSw: -0.481440 | GSb: -0.144377 | TSUw: -0.429536 | TSUb: -0.036632\n",
      "\n",
      "Train Epoch: 5797 [4000/8000 (50%)]\tBatch Loss: 0.012845\tLearning Rate (w_theta): 0.001000\t TIME:2853.0s\n",
      "\t\t\t\tDisc: 0.012037\t\tSym: 0.000000\t\tSpars: 0.000809\n",
      "\t TVw: 0.770488 | TVb: 2.280953 | GSw: -0.481276 | GSb: -0.144268 | TSUw: -0.429465 | TSUb: -0.036550\n",
      "Validating epoch 5797...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012914658468307564\n",
      "Average validation loss: 0.013424252918900864\n",
      "Training epoch 5798...\n",
      "\n",
      "Train Epoch: 5798 [0/8000 (0%)]\tBatch Loss: 0.013173\tLearning Rate (w_theta): 0.001000\t TIME:2855.2s\n",
      "\t\t\t\tDisc: 0.012417\t\tSym: 0.000000\t\tSpars: 0.000756\n",
      "\t TVw: 0.770356 | TVb: 2.281100 | GSw: -0.481428 | GSb: -0.144511 | TSUw: -0.430902 | TSUb: -0.037980\n",
      "\n",
      "Train Epoch: 5798 [4000/8000 (50%)]\tBatch Loss: 0.012278\tLearning Rate (w_theta): 0.001000\t TIME:2856.6s\n",
      "\t\t\t\tDisc: 0.011655\t\tSym: 0.000000\t\tSpars: 0.000623\n",
      "\t TVw: 0.770822 | TVb: 2.281538 | GSw: -0.481395 | GSb: -0.144553 | TSUw: -0.431173 | TSUb: -0.038240\n",
      "Validating epoch 5798...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012925751205485166\n",
      "Average validation loss: 0.013420936945196572\n",
      "Training epoch 5799...\n",
      "\n",
      "Train Epoch: 5799 [0/8000 (0%)]\tBatch Loss: 0.012788\tLearning Rate (w_theta): 0.001000\t TIME:2858.9s\n",
      "\t\t\t\tDisc: 0.011878\t\tSym: 0.000000\t\tSpars: 0.000910\n",
      "\t TVw: 0.770991 | TVb: 2.281478 | GSw: -0.480956 | GSb: -0.144139 | TSUw: -0.429184 | TSUb: -0.036238\n",
      "\n",
      "Train Epoch: 5799 [4000/8000 (50%)]\tBatch Loss: 0.013662\tLearning Rate (w_theta): 0.001000\t TIME:2860.2s\n",
      "\t\t\t\tDisc: 0.012684\t\tSym: 0.000000\t\tSpars: 0.000978\n",
      "\t TVw: 0.771534 | TVb: 2.281565 | GSw: -0.481064 | GSb: -0.144328 | TSUw: -0.429905 | TSUb: -0.036946\n",
      "Validating epoch 5799...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012918968039522688\n",
      "Average validation loss: 0.013430767846640808\n",
      "Training epoch 5800...\n",
      "\n",
      "Train Epoch: 5800 [0/8000 (0%)]\tBatch Loss: 0.012988\tLearning Rate (w_theta): 0.001000\t TIME:2862.4s\n",
      "\t\t\t\tDisc: 0.011811\t\tSym: 0.000000\t\tSpars: 0.001177\n",
      "\t TVw: 0.771742 | TVb: 2.281793 | GSw: -0.481242 | GSb: -0.144598 | TSUw: -0.431094 | TSUb: -0.038126\n",
      "\n",
      "Train Epoch: 5800 [4000/8000 (50%)]\tBatch Loss: 0.013080\tLearning Rate (w_theta): 0.001000\t TIME:2863.7s\n",
      "\t\t\t\tDisc: 0.012037\t\tSym: 0.000000\t\tSpars: 0.001043\n",
      "\t TVw: 0.772235 | TVb: 2.282046 | GSw: -0.481027 | GSb: -0.144427 | TSUw: -0.430371 | TSUb: -0.037391\n",
      "Validating epoch 5800...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012910591141943139\n",
      "Average validation loss: 0.013417801557572313\n",
      "Training epoch 5801...\n",
      "\n",
      "Train Epoch: 5801 [0/8000 (0%)]\tBatch Loss: 0.013385\tLearning Rate (w_theta): 0.001000\t TIME:2866.7s\n",
      "\t\t\t\tDisc: 0.012554\t\tSym: 0.000000\t\tSpars: 0.000830\n",
      "\t TVw: 0.772053 | TVb: 2.281917 | GSw: -0.480755 | GSb: -0.144191 | TSUw: -0.429550 | TSUb: -0.036559\n",
      "\n",
      "Train Epoch: 5801 [4000/8000 (50%)]\tBatch Loss: 0.012748\tLearning Rate (w_theta): 0.001000\t TIME:2868.0s\n",
      "\t\t\t\tDisc: 0.012024\t\tSym: 0.000000\t\tSpars: 0.000724\n",
      "\t TVw: 0.771721 | TVb: 2.281810 | GSw: -0.480677 | GSb: -0.144159 | TSUw: -0.429674 | TSUb: -0.036673\n",
      "Validating epoch 5801...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012913481800999363\n",
      "Average validation loss: 0.013427661369348766\n",
      "Training epoch 5802...\n",
      "\n",
      "Train Epoch: 5802 [0/8000 (0%)]\tBatch Loss: 0.013144\tLearning Rate (w_theta): 0.001000\t TIME:2870.3s\n",
      "\t\t\t\tDisc: 0.012324\t\tSym: 0.000000\t\tSpars: 0.000820\n",
      "\t TVw: 0.771444 | TVb: 2.281772 | GSw: -0.480831 | GSb: -0.144402 | TSUw: -0.430950 | TSUb: -0.037941\n",
      "\n",
      "Train Epoch: 5802 [4000/8000 (50%)]\tBatch Loss: 0.012621\tLearning Rate (w_theta): 0.001000\t TIME:2871.6s\n",
      "\t\t\t\tDisc: 0.011820\t\tSym: 0.000000\t\tSpars: 0.000801\n",
      "\t TVw: 0.771772 | TVb: 2.282052 | GSw: -0.480640 | GSb: -0.144271 | TSUw: -0.430514 | TSUb: -0.037495\n",
      "Validating epoch 5802...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012912584349078512\n",
      "Average validation loss: 0.013418998550362628\n",
      "Training epoch 5803...\n",
      "\n",
      "Train Epoch: 5803 [0/8000 (0%)]\tBatch Loss: 0.012664\tLearning Rate (w_theta): 0.001000\t TIME:2873.8s\n",
      "\t\t\t\tDisc: 0.012027\t\tSym: 0.000000\t\tSpars: 0.000637\n",
      "\t TVw: 0.771462 | TVb: 2.281794 | GSw: -0.480437 | GSb: -0.144117 | TSUw: -0.430144 | TSUb: -0.037116\n",
      "\n",
      "Train Epoch: 5803 [4000/8000 (50%)]\tBatch Loss: 0.012167\tLearning Rate (w_theta): 0.001000\t TIME:2875.1s\n",
      "\t\t\t\tDisc: 0.011449\t\tSym: 0.000000\t\tSpars: 0.000718\n",
      "\t TVw: 0.770683 | TVb: 2.281337 | GSw: -0.480357 | GSb: -0.144100 | TSUw: -0.430466 | TSUb: -0.037429\n",
      "Validating epoch 5803...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012911159998090902\n",
      "Average validation loss: 0.013422427370340198\n",
      "Training epoch 5804...\n",
      "\n",
      "Train Epoch: 5804 [0/8000 (0%)]\tBatch Loss: 0.012437\tLearning Rate (w_theta): 0.001000\t TIME:2877.4s\n",
      "\t\t\t\tDisc: 0.011686\t\tSym: 0.000000\t\tSpars: 0.000750\n",
      "\t TVw: 0.770732 | TVb: 2.281306 | GSw: -0.480157 | GSb: -0.143948 | TSUw: -0.430251 | TSUb: -0.037206\n",
      "\n",
      "Train Epoch: 5804 [4000/8000 (50%)]\tBatch Loss: 0.012760\tLearning Rate (w_theta): 0.001000\t TIME:2878.6s\n",
      "\t\t\t\tDisc: 0.011953\t\tSym: 0.000000\t\tSpars: 0.000807\n",
      "\t TVw: 0.770916 | TVb: 2.281319 | GSw: -0.479987 | GSb: -0.143818 | TSUw: -0.430198 | TSUb: -0.037145\n",
      "Validating epoch 5804...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012911041766694931\n",
      "Average validation loss: 0.013420410077315197\n",
      "Training epoch 5805...\n",
      "\n",
      "Train Epoch: 5805 [0/8000 (0%)]\tBatch Loss: 0.013061\tLearning Rate (w_theta): 0.001000\t TIME:2880.9s\n",
      "\t\t\t\tDisc: 0.012255\t\tSym: 0.000000\t\tSpars: 0.000807\n",
      "\t TVw: 0.771200 | TVb: 2.281466 | GSw: -0.479829 | GSb: -0.143708 | TSUw: -0.430231 | TSUb: -0.037170\n",
      "\n",
      "Train Epoch: 5805 [4000/8000 (50%)]\tBatch Loss: 0.012563\tLearning Rate (w_theta): 0.001000\t TIME:2882.2s\n",
      "\t\t\t\tDisc: 0.011884\t\tSym: 0.000000\t\tSpars: 0.000679\n",
      "\t TVw: 0.771441 | TVb: 2.281713 | GSw: -0.479725 | GSb: -0.143680 | TSUw: -0.430582 | TSUb: -0.037514\n",
      "Validating epoch 5805...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01291115183625606\n",
      "Average validation loss: 0.013419979752048835\n",
      "Training epoch 5806...\n",
      "\n",
      "Train Epoch: 5806 [0/8000 (0%)]\tBatch Loss: 0.012980\tLearning Rate (w_theta): 0.001000\t TIME:2884.5s\n",
      "\t\t\t\tDisc: 0.012133\t\tSym: 0.000000\t\tSpars: 0.000848\n",
      "\t TVw: 0.771389 | TVb: 2.281576 | GSw: -0.479456 | GSb: -0.143443 | TSUw: -0.430098 | TSUb: -0.037022\n",
      "\n",
      "Train Epoch: 5806 [4000/8000 (50%)]\tBatch Loss: 0.012633\tLearning Rate (w_theta): 0.001000\t TIME:2885.8s\n",
      "\t\t\t\tDisc: 0.011926\t\tSym: 0.000000\t\tSpars: 0.000707\n",
      "\t TVw: 0.771268 | TVb: 2.281415 | GSw: -0.479343 | GSb: -0.143375 | TSUw: -0.430342 | TSUb: -0.037258\n",
      "Validating epoch 5806...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012911794251856911\n",
      "Average validation loss: 0.013421994322540829\n",
      "Training epoch 5807...\n",
      "\n",
      "Train Epoch: 5807 [0/8000 (0%)]\tBatch Loss: 0.012857\tLearning Rate (w_theta): 0.001000\t TIME:2888.0s\n",
      "\t\t\t\tDisc: 0.011997\t\tSym: 0.000000\t\tSpars: 0.000860\n",
      "\t TVw: 0.771387 | TVb: 2.281461 | GSw: -0.479190 | GSb: -0.143271 | TSUw: -0.430421 | TSUb: -0.037330\n",
      "\n",
      "Train Epoch: 5807 [4000/8000 (50%)]\tBatch Loss: 0.013202\tLearning Rate (w_theta): 0.001000\t TIME:2889.3s\n",
      "\t\t\t\tDisc: 0.012393\t\tSym: 0.000000\t\tSpars: 0.000809\n",
      "\t TVw: 0.771012 | TVb: 2.281364 | GSw: -0.479009 | GSb: -0.143143 | TSUw: -0.430378 | TSUb: -0.037278\n",
      "Validating epoch 5807...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01291139028214335\n",
      "Average validation loss: 0.01342109055545097\n",
      "Training epoch 5808...\n",
      "\n",
      "Train Epoch: 5808 [0/8000 (0%)]\tBatch Loss: 0.012778\tLearning Rate (w_theta): 0.001000\t TIME:2891.7s\n",
      "\t\t\t\tDisc: 0.011788\t\tSym: 0.000000\t\tSpars: 0.000990\n",
      "\t TVw: 0.770722 | TVb: 2.281143 | GSw: -0.478759 | GSb: -0.142926 | TSUw: -0.430011 | TSUb: -0.036903\n",
      "\n",
      "Train Epoch: 5808 [4000/8000 (50%)]\tBatch Loss: 0.012834\tLearning Rate (w_theta): 0.001000\t TIME:2892.9s\n",
      "\t\t\t\tDisc: 0.012130\t\tSym: 0.000000\t\tSpars: 0.000704\n",
      "\t TVw: 0.770678 | TVb: 2.281154 | GSw: -0.478703 | GSb: -0.142912 | TSUw: -0.430549 | TSUb: -0.037435\n",
      "Validating epoch 5808...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012914421340854715\n",
      "Average validation loss: 0.013424887352393583\n",
      "Training epoch 5809...\n",
      "\n",
      "Train Epoch: 5809 [0/8000 (0%)]\tBatch Loss: 0.012877\tLearning Rate (w_theta): 0.001000\t TIME:2895.2s\n",
      "\t\t\t\tDisc: 0.012290\t\tSym: 0.000000\t\tSpars: 0.000587\n",
      "\t TVw: 0.770613 | TVb: 2.281069 | GSw: -0.478507 | GSb: -0.142758 | TSUw: -0.430389 | TSUb: -0.037267\n",
      "\n",
      "Train Epoch: 5809 [4000/8000 (50%)]\tBatch Loss: 0.013478\tLearning Rate (w_theta): 0.001000\t TIME:2896.4s\n",
      "\t\t\t\tDisc: 0.012499\t\tSym: 0.000000\t\tSpars: 0.000979\n",
      "\t TVw: 0.770979 | TVb: 2.281125 | GSw: -0.478371 | GSb: -0.142669 | TSUw: -0.430501 | TSUb: -0.037372\n",
      "Validating epoch 5809...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012915219528788865\n",
      "Average validation loss: 0.013424846779363567\n",
      "Training epoch 5810...\n",
      "\n",
      "Train Epoch: 5810 [0/8000 (0%)]\tBatch Loss: 0.012654\tLearning Rate (w_theta): 0.001000\t TIME:2898.7s\n",
      "\t\t\t\tDisc: 0.011840\t\tSym: 0.000000\t\tSpars: 0.000814\n",
      "\t TVw: 0.771342 | TVb: 2.281283 | GSw: -0.478200 | GSb: -0.142547 | TSUw: -0.430436 | TSUb: -0.037299\n",
      "\n",
      "Train Epoch: 5810 [4000/8000 (50%)]\tBatch Loss: 0.013534\tLearning Rate (w_theta): 0.001000\t TIME:2900.0s\n",
      "\t\t\t\tDisc: 0.012540\t\tSym: 0.000000\t\tSpars: 0.000994\n",
      "\t TVw: 0.770953 | TVb: 2.280943 | GSw: -0.477964 | GSb: -0.142356 | TSUw: -0.430063 | TSUb: -0.036917\n",
      "Validating epoch 5810...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012913665163731783\n",
      "Average validation loss: 0.013422319959439521\n",
      "Training epoch 5811...\n",
      "\n",
      "Train Epoch: 5811 [0/8000 (0%)]\tBatch Loss: 0.012437\tLearning Rate (w_theta): 0.001000\t TIME:2903.0s\n",
      "\t\t\t\tDisc: 0.011857\t\tSym: 0.000000\t\tSpars: 0.000581\n",
      "\t TVw: 0.770778 | TVb: 2.280968 | GSw: -0.477888 | GSb: -0.142338 | TSUw: -0.430476 | TSUb: -0.037323\n",
      "\n",
      "Train Epoch: 5811 [4000/8000 (50%)]\tBatch Loss: 0.012708\tLearning Rate (w_theta): 0.001000\t TIME:2904.3s\n",
      "\t\t\t\tDisc: 0.012274\t\tSym: 0.000000\t\tSpars: 0.000434\n",
      "\t TVw: 0.770675 | TVb: 2.280993 | GSw: -0.477895 | GSb: -0.142416 | TSUw: -0.431279 | TSUb: -0.038118\n",
      "Validating epoch 5811...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01291925692339139\n",
      "Average validation loss: 0.013422009896756699\n",
      "Training epoch 5812...\n",
      "\n",
      "Train Epoch: 5812 [0/8000 (0%)]\tBatch Loss: 0.012815\tLearning Rate (w_theta): 0.001000\t TIME:2906.6s\n",
      "\t\t\t\tDisc: 0.011914\t\tSym: 0.000000\t\tSpars: 0.000901\n",
      "\t TVw: 0.770895 | TVb: 2.280961 | GSw: -0.477482 | GSb: -0.142025 | TSUw: -0.429854 | TSUb: -0.036682\n",
      "\n",
      "Train Epoch: 5812 [4000/8000 (50%)]\tBatch Loss: 0.012931\tLearning Rate (w_theta): 0.001000\t TIME:2907.8s\n",
      "\t\t\t\tDisc: 0.012209\t\tSym: 0.000000\t\tSpars: 0.000722\n",
      "\t TVw: 0.771388 | TVb: 2.281371 | GSw: -0.477399 | GSb: -0.141984 | TSUw: -0.429954 | TSUb: -0.036774\n",
      "Validating epoch 5812...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012914800498073696\n",
      "Average validation loss: 0.013421534052394015\n",
      "Training epoch 5813...\n",
      "\n",
      "Train Epoch: 5813 [0/8000 (0%)]\tBatch Loss: 0.012907\tLearning Rate (w_theta): 0.001000\t TIME:2910.0s\n",
      "\t\t\t\tDisc: 0.012064\t\tSym: 0.000000\t\tSpars: 0.000843\n",
      "\t TVw: 0.771438 | TVb: 2.281530 | GSw: -0.477416 | GSb: -0.142072 | TSUw: -0.430633 | TSUb: -0.037445\n",
      "\n",
      "Train Epoch: 5813 [4000/8000 (50%)]\tBatch Loss: 0.013370\tLearning Rate (w_theta): 0.001000\t TIME:2911.3s\n",
      "\t\t\t\tDisc: 0.012410\t\tSym: 0.000000\t\tSpars: 0.000960\n",
      "\t TVw: 0.771587 | TVb: 2.281679 | GSw: -0.477375 | GSb: -0.142110 | TSUw: -0.431118 | TSUb: -0.037922\n",
      "Validating epoch 5813...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012914345449760457\n",
      "Average validation loss: 0.013420269070036864\n",
      "Training epoch 5814...\n",
      "\n",
      "Train Epoch: 5814 [0/8000 (0%)]\tBatch Loss: 0.012729\tLearning Rate (w_theta): 0.001000\t TIME:2913.5s\n",
      "\t\t\t\tDisc: 0.012023\t\tSym: 0.000000\t\tSpars: 0.000706\n",
      "\t TVw: 0.771544 | TVb: 2.281505 | GSw: -0.477007 | GSb: -0.141773 | TSUw: -0.429951 | TSUb: -0.036744\n",
      "\n",
      "Train Epoch: 5814 [4000/8000 (50%)]\tBatch Loss: 0.013251\tLearning Rate (w_theta): 0.001000\t TIME:2914.8s\n",
      "\t\t\t\tDisc: 0.012623\t\tSym: 0.000000\t\tSpars: 0.000628\n",
      "\t TVw: 0.771658 | TVb: 2.281657 | GSw: -0.476889 | GSb: -0.141706 | TSUw: -0.429973 | TSUb: -0.036759\n",
      "Validating epoch 5814...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01291503300401023\n",
      "Average validation loss: 0.013423934122621911\n",
      "Training epoch 5815...\n",
      "\n",
      "Train Epoch: 5815 [0/8000 (0%)]\tBatch Loss: 0.013007\tLearning Rate (w_theta): 0.001000\t TIME:2917.1s\n",
      "\t\t\t\tDisc: 0.012152\t\tSym: 0.000000\t\tSpars: 0.000855\n",
      "\t TVw: 0.771539 | TVb: 2.281656 | GSw: -0.476972 | GSb: -0.141870 | TSUw: -0.430949 | TSUb: -0.037727\n",
      "\n",
      "Train Epoch: 5815 [4000/8000 (50%)]\tBatch Loss: 0.012906\tLearning Rate (w_theta): 0.001000\t TIME:2918.3s\n",
      "\t\t\t\tDisc: 0.012325\t\tSym: 0.000000\t\tSpars: 0.000581\n",
      "\t TVw: 0.771349 | TVb: 2.281400 | GSw: -0.476883 | GSb: -0.141863 | TSUw: -0.431134 | TSUb: -0.037903\n",
      "Validating epoch 5815...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012917405853157309\n",
      "Average validation loss: 0.013421975487225454\n",
      "Training epoch 5816...\n",
      "\n",
      "Train Epoch: 5816 [0/8000 (0%)]\tBatch Loss: 0.013430\tLearning Rate (w_theta): 0.001000\t TIME:2920.6s\n",
      "\t\t\t\tDisc: 0.012449\t\tSym: 0.000000\t\tSpars: 0.000981\n",
      "\t TVw: 0.771318 | TVb: 2.281197 | GSw: -0.476513 | GSb: -0.141523 | TSUw: -0.429854 | TSUb: -0.036612\n",
      "\n",
      "Train Epoch: 5816 [4000/8000 (50%)]\tBatch Loss: 0.012264\tLearning Rate (w_theta): 0.001000\t TIME:2921.9s\n",
      "\t\t\t\tDisc: 0.011657\t\tSym: 0.000000\t\tSpars: 0.000607\n",
      "\t TVw: 0.771209 | TVb: 2.281120 | GSw: -0.476431 | GSb: -0.141503 | TSUw: -0.429950 | TSUb: -0.036700\n",
      "Validating epoch 5816...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012915195756706674\n",
      "Average validation loss: 0.013427213002091135\n",
      "Training epoch 5817...\n",
      "\n",
      "Train Epoch: 5817 [0/8000 (0%)]\tBatch Loss: 0.012371\tLearning Rate (w_theta): 0.001000\t TIME:2924.2s\n",
      "\t\t\t\tDisc: 0.011665\t\tSym: 0.000000\t\tSpars: 0.000706\n",
      "\t TVw: 0.770899 | TVb: 2.281120 | GSw: -0.476592 | GSb: -0.141756 | TSUw: -0.431272 | TSUb: -0.038015\n",
      "\n",
      "Train Epoch: 5817 [4000/8000 (50%)]\tBatch Loss: 0.013266\tLearning Rate (w_theta): 0.001000\t TIME:2925.4s\n",
      "\t\t\t\tDisc: 0.012456\t\tSym: 0.000000\t\tSpars: 0.000810\n",
      "\t TVw: 0.770992 | TVb: 2.281204 | GSw: -0.476427 | GSb: -0.141639 | TSUw: -0.430958 | TSUb: -0.037691\n",
      "Validating epoch 5817...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012919636286399784\n",
      "Average validation loss: 0.013422355258087798\n",
      "Training epoch 5818...\n",
      "\n",
      "Train Epoch: 5818 [0/8000 (0%)]\tBatch Loss: 0.012782\tLearning Rate (w_theta): 0.001000\t TIME:2927.6s\n",
      "\t\t\t\tDisc: 0.011944\t\tSym: 0.000000\t\tSpars: 0.000839\n",
      "\t TVw: 0.771120 | TVb: 2.281191 | GSw: -0.476112 | GSb: -0.141360 | TSUw: -0.429941 | TSUb: -0.036664\n",
      "\n",
      "Train Epoch: 5818 [4000/8000 (50%)]\tBatch Loss: 0.014059\tLearning Rate (w_theta): 0.001000\t TIME:2928.9s\n",
      "\t\t\t\tDisc: 0.013076\t\tSym: 0.000000\t\tSpars: 0.000983\n",
      "\t TVw: 0.770924 | TVb: 2.281193 | GSw: -0.476191 | GSb: -0.141524 | TSUw: -0.430747 | TSUb: -0.037461\n",
      "Validating epoch 5818...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01291761560452444\n",
      "Average validation loss: 0.013423877373587734\n",
      "Training epoch 5819...\n",
      "\n",
      "Train Epoch: 5819 [0/8000 (0%)]\tBatch Loss: 0.013149\tLearning Rate (w_theta): 0.001000\t TIME:2931.1s\n",
      "\t\t\t\tDisc: 0.012137\t\tSym: 0.000000\t\tSpars: 0.001012\n",
      "\t TVw: 0.771359 | TVb: 2.281399 | GSw: -0.476032 | GSb: -0.141413 | TSUw: -0.430540 | TSUb: -0.037246\n",
      "\n",
      "Train Epoch: 5819 [4000/8000 (50%)]\tBatch Loss: 0.013078\tLearning Rate (w_theta): 0.001000\t TIME:2932.4s\n",
      "\t\t\t\tDisc: 0.012240\t\tSym: 0.000000\t\tSpars: 0.000838\n",
      "\t TVw: 0.771833 | TVb: 2.281634 | GSw: -0.475887 | GSb: -0.141319 | TSUw: -0.430478 | TSUb: -0.037177\n",
      "Validating epoch 5819...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012911367249722236\n",
      "Average validation loss: 0.013420654185129211\n",
      "Training epoch 5820...\n",
      "\n",
      "Train Epoch: 5820 [0/8000 (0%)]\tBatch Loss: 0.013483\tLearning Rate (w_theta): 0.001000\t TIME:2934.6s\n",
      "\t\t\t\tDisc: 0.012762\t\tSym: 0.000000\t\tSpars: 0.000721\n",
      "\t TVw: 0.771708 | TVb: 2.281482 | GSw: -0.475667 | GSb: -0.141139 | TSUw: -0.430151 | TSUb: -0.036842\n",
      "\n",
      "Train Epoch: 5820 [4000/8000 (50%)]\tBatch Loss: 0.013246\tLearning Rate (w_theta): 0.001000\t TIME:2935.9s\n",
      "\t\t\t\tDisc: 0.012385\t\tSym: 0.000000\t\tSpars: 0.000861\n",
      "\t TVw: 0.771003 | TVb: 2.281190 | GSw: -0.475552 | GSb: -0.141103 | TSUw: -0.430368 | TSUb: -0.037051\n",
      "Validating epoch 5820...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012912319820710297\n",
      "Average validation loss: 0.013427691871943922\n",
      "Training epoch 5821...\n",
      "\n",
      "Train Epoch: 5821 [0/8000 (0%)]\tBatch Loss: 0.013240\tLearning Rate (w_theta): 0.001000\t TIME:2938.9s\n",
      "\t\t\t\tDisc: 0.012450\t\tSym: 0.000000\t\tSpars: 0.000789\n",
      "\t TVw: 0.771109 | TVb: 2.281183 | GSw: -0.475544 | GSb: -0.141165 | TSUw: -0.431069 | TSUb: -0.037746\n",
      "\n",
      "Train Epoch: 5821 [4000/8000 (50%)]\tBatch Loss: 0.013496\tLearning Rate (w_theta): 0.001000\t TIME:2940.1s\n",
      "\t\t\t\tDisc: 0.012477\t\tSym: 0.000000\t\tSpars: 0.001019\n",
      "\t TVw: 0.771296 | TVb: 2.281173 | GSw: -0.475440 | GSb: -0.141115 | TSUw: -0.431313 | TSUb: -0.037983\n",
      "Validating epoch 5821...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012916303212048416\n",
      "Average validation loss: 0.01342245585978211\n",
      "Training epoch 5822...\n",
      "\n",
      "Train Epoch: 5822 [0/8000 (0%)]\tBatch Loss: 0.012962\tLearning Rate (w_theta): 0.001000\t TIME:2942.4s\n",
      "\t\t\t\tDisc: 0.012054\t\tSym: 0.000000\t\tSpars: 0.000908\n",
      "\t TVw: 0.771575 | TVb: 2.281069 | GSw: -0.474951 | GSb: -0.140637 | TSUw: -0.429653 | TSUb: -0.036314\n",
      "\n",
      "Train Epoch: 5822 [4000/8000 (50%)]\tBatch Loss: 0.012773\tLearning Rate (w_theta): 0.001000\t TIME:2943.6s\n",
      "\t\t\t\tDisc: 0.012061\t\tSym: 0.000000\t\tSpars: 0.000712\n",
      "\t TVw: 0.771572 | TVb: 2.281198 | GSw: -0.474970 | GSb: -0.140729 | TSUw: -0.430090 | TSUb: -0.036741\n",
      "Validating epoch 5822...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012921093714327165\n",
      "Average validation loss: 0.01342903000711852\n",
      "Training epoch 5823...\n",
      "\n",
      "Train Epoch: 5823 [0/8000 (0%)]\tBatch Loss: 0.012624\tLearning Rate (w_theta): 0.001000\t TIME:2946.0s\n",
      "\t\t\t\tDisc: 0.011956\t\tSym: 0.000000\t\tSpars: 0.000668\n",
      "\t TVw: 0.771526 | TVb: 2.281381 | GSw: -0.475134 | GSb: -0.140991 | TSUw: -0.431207 | TSUb: -0.037851\n",
      "\n",
      "Train Epoch: 5823 [4000/8000 (50%)]\tBatch Loss: 0.013329\tLearning Rate (w_theta): 0.001000\t TIME:2947.3s\n",
      "\t\t\t\tDisc: 0.012638\t\tSym: 0.000000\t\tSpars: 0.000691\n",
      "\t TVw: 0.771734 | TVb: 2.281430 | GSw: -0.474993 | GSb: -0.140918 | TSUw: -0.430977 | TSUb: -0.037612\n",
      "Validating epoch 5823...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012915978717669528\n",
      "Average validation loss: 0.013422059487576422\n",
      "Training epoch 5824...\n",
      "\n",
      "Train Epoch: 5824 [0/8000 (0%)]\tBatch Loss: 0.012686\tLearning Rate (w_theta): 0.001000\t TIME:2949.5s\n",
      "\t\t\t\tDisc: 0.011906\t\tSym: 0.000000\t\tSpars: 0.000780\n",
      "\t TVw: 0.771726 | TVb: 2.281223 | GSw: -0.474636 | GSb: -0.140594 | TSUw: -0.429823 | TSUb: -0.036449\n",
      "\n",
      "Train Epoch: 5824 [4000/8000 (50%)]\tBatch Loss: 0.012427\tLearning Rate (w_theta): 0.001000\t TIME:2950.8s\n",
      "\t\t\t\tDisc: 0.011698\t\tSym: 0.000000\t\tSpars: 0.000729\n",
      "\t TVw: 0.771514 | TVb: 2.281010 | GSw: -0.474660 | GSb: -0.140694 | TSUw: -0.430332 | TSUb: -0.036949\n",
      "Validating epoch 5824...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012918869476335432\n",
      "Average validation loss: 0.0134409360527829\n",
      "Training epoch 5825...\n",
      "\n",
      "Train Epoch: 5825 [0/8000 (0%)]\tBatch Loss: 0.012249\tLearning Rate (w_theta): 0.001000\t TIME:2953.1s\n",
      "\t\t\t\tDisc: 0.011523\t\tSym: 0.000000\t\tSpars: 0.000725\n",
      "\t TVw: 0.771394 | TVb: 2.281088 | GSw: -0.474853 | GSb: -0.140989 | TSUw: -0.431571 | TSUb: -0.038180\n",
      "\n",
      "Train Epoch: 5825 [4000/8000 (50%)]\tBatch Loss: 0.012910\tLearning Rate (w_theta): 0.001000\t TIME:2954.4s\n",
      "\t\t\t\tDisc: 0.012156\t\tSym: 0.000000\t\tSpars: 0.000754\n",
      "\t TVw: 0.772233 | TVb: 2.281375 | GSw: -0.474604 | GSb: -0.140801 | TSUw: -0.430740 | TSUb: -0.037339\n",
      "Validating epoch 5825...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012916188594814446\n",
      "Average validation loss: 0.013422831118330118\n",
      "Training epoch 5826...\n",
      "\n",
      "Train Epoch: 5826 [0/8000 (0%)]\tBatch Loss: 0.013508\tLearning Rate (w_theta): 0.001000\t TIME:2956.6s\n",
      "\t\t\t\tDisc: 0.012450\t\tSym: 0.000000\t\tSpars: 0.001058\n",
      "\t TVw: 0.772565 | TVb: 2.281499 | GSw: -0.474319 | GSb: -0.140564 | TSUw: -0.429853 | TSUb: -0.036444\n",
      "\n",
      "Train Epoch: 5826 [4000/8000 (50%)]\tBatch Loss: 0.013789\tLearning Rate (w_theta): 0.001000\t TIME:2957.9s\n",
      "\t\t\t\tDisc: 0.012857\t\tSym: 0.000000\t\tSpars: 0.000933\n",
      "\t TVw: 0.773012 | TVb: 2.281838 | GSw: -0.474429 | GSb: -0.140758 | TSUw: -0.430717 | TSUb: -0.037300\n",
      "Validating epoch 5826...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012916788714174973\n",
      "Average validation loss: 0.013427325493312584\n",
      "Training epoch 5827...\n",
      "\n",
      "Train Epoch: 5827 [0/8000 (0%)]\tBatch Loss: 0.012823\tLearning Rate (w_theta): 0.001000\t TIME:2960.2s\n",
      "\t\t\t\tDisc: 0.012078\t\tSym: 0.000000\t\tSpars: 0.000745\n",
      "\t TVw: 0.772805 | TVb: 2.281882 | GSw: -0.474407 | GSb: -0.140807 | TSUw: -0.431083 | TSUb: -0.037657\n",
      "\n",
      "Train Epoch: 5827 [4000/8000 (50%)]\tBatch Loss: 0.012681\tLearning Rate (w_theta): 0.001000\t TIME:2961.5s\n",
      "\t\t\t\tDisc: 0.011976\t\tSym: 0.000000\t\tSpars: 0.000705\n",
      "\t TVw: 0.772423 | TVb: 2.281603 | GSw: -0.474042 | GSb: -0.140485 | TSUw: -0.429996 | TSUb: -0.036561\n",
      "Validating epoch 5827...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012916672543220783\n",
      "Average validation loss: 0.013421155916382075\n",
      "Training epoch 5828...\n",
      "\n",
      "Train Epoch: 5828 [0/8000 (0%)]\tBatch Loss: 0.012387\tLearning Rate (w_theta): 0.001000\t TIME:2963.7s\n",
      "\t\t\t\tDisc: 0.011792\t\tSym: 0.000000\t\tSpars: 0.000596\n",
      "\t TVw: 0.771978 | TVb: 2.281449 | GSw: -0.474071 | GSb: -0.140588 | TSUw: -0.430590 | TSUb: -0.037147\n",
      "\n",
      "Train Epoch: 5828 [4000/8000 (50%)]\tBatch Loss: 0.013207\tLearning Rate (w_theta): 0.001000\t TIME:2964.9s\n",
      "\t\t\t\tDisc: 0.012448\t\tSym: 0.000000\t\tSpars: 0.000759\n",
      "\t TVw: 0.772448 | TVb: 2.281739 | GSw: -0.474157 | GSb: -0.140751 | TSUw: -0.431391 | TSUb: -0.037941\n",
      "Validating epoch 5828...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012917778640274671\n",
      "Average validation loss: 0.013421173215629873\n",
      "Training epoch 5829...\n",
      "\n",
      "Train Epoch: 5829 [0/8000 (0%)]\tBatch Loss: 0.012821\tLearning Rate (w_theta): 0.001000\t TIME:2967.3s\n",
      "\t\t\t\tDisc: 0.012196\t\tSym: 0.000000\t\tSpars: 0.000625\n",
      "\t TVw: 0.772311 | TVb: 2.281538 | GSw: -0.473784 | GSb: -0.140403 | TSUw: -0.430148 | TSUb: -0.036688\n",
      "\n",
      "Train Epoch: 5829 [4000/8000 (50%)]\tBatch Loss: 0.013568\tLearning Rate (w_theta): 0.001000\t TIME:2968.6s\n",
      "\t\t\t\tDisc: 0.012577\t\tSym: 0.000000\t\tSpars: 0.000991\n",
      "\t TVw: 0.771769 | TVb: 2.281348 | GSw: -0.473770 | GSb: -0.140460 | TSUw: -0.430403 | TSUb: -0.036934\n",
      "Validating epoch 5829...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012919697552467349\n",
      "Average validation loss: 0.013427796269135381\n",
      "Training epoch 5830...\n",
      "\n",
      "Train Epoch: 5830 [0/8000 (0%)]\tBatch Loss: 0.013217\tLearning Rate (w_theta): 0.001000\t TIME:2970.9s\n",
      "\t\t\t\tDisc: 0.012435\t\tSym: 0.000000\t\tSpars: 0.000782\n",
      "\t TVw: 0.771697 | TVb: 2.281440 | GSw: -0.473853 | GSb: -0.140618 | TSUw: -0.431106 | TSUb: -0.037629\n",
      "\n",
      "Train Epoch: 5830 [4000/8000 (50%)]\tBatch Loss: 0.012668\tLearning Rate (w_theta): 0.001000\t TIME:2972.2s\n",
      "\t\t\t\tDisc: 0.011971\t\tSym: 0.000000\t\tSpars: 0.000697\n",
      "\t TVw: 0.771672 | TVb: 2.281073 | GSw: -0.473553 | GSb: -0.140354 | TSUw: -0.430255 | TSUb: -0.036769\n",
      "Validating epoch 5830...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012921396689636553\n",
      "Average validation loss: 0.01342270151537999\n",
      "Training epoch 5831...\n",
      "\n",
      "Train Epoch: 5831 [0/8000 (0%)]\tBatch Loss: 0.012952\tLearning Rate (w_theta): 0.001000\t TIME:2975.1s\n",
      "\t\t\t\tDisc: 0.011993\t\tSym: 0.000000\t\tSpars: 0.000958\n",
      "\t TVw: 0.771606 | TVb: 2.281163 | GSw: -0.473574 | GSb: -0.140443 | TSUw: -0.430715 | TSUb: -0.037221\n",
      "\n",
      "Train Epoch: 5831 [4000/8000 (50%)]\tBatch Loss: 0.012411\tLearning Rate (w_theta): 0.001000\t TIME:2976.4s\n",
      "\t\t\t\tDisc: 0.011863\t\tSym: 0.000000\t\tSpars: 0.000547\n",
      "\t TVw: 0.770985 | TVb: 2.281015 | GSw: -0.473468 | GSb: -0.140385 | TSUw: -0.430732 | TSUb: -0.037231\n",
      "Validating epoch 5831...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012913794787106591\n",
      "Average validation loss: 0.013427034938753895\n",
      "Training epoch 5832...\n",
      "\n",
      "Train Epoch: 5832 [0/8000 (0%)]\tBatch Loss: 0.013365\tLearning Rate (w_theta): 0.001000\t TIME:2978.6s\n",
      "\t\t\t\tDisc: 0.012486\t\tSym: 0.000000\t\tSpars: 0.000879\n",
      "\t TVw: 0.771087 | TVb: 2.281192 | GSw: -0.473421 | GSb: -0.140407 | TSUw: -0.431077 | TSUb: -0.037569\n",
      "\n",
      "Train Epoch: 5832 [4000/8000 (50%)]\tBatch Loss: 0.012776\tLearning Rate (w_theta): 0.001000\t TIME:2979.9s\n",
      "\t\t\t\tDisc: 0.011987\t\tSym: 0.000000\t\tSpars: 0.000790\n",
      "\t TVw: 0.771542 | TVb: 2.281458 | GSw: -0.473244 | GSb: -0.140288 | TSUw: -0.430844 | TSUb: -0.037329\n",
      "Validating epoch 5832...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01291475416564774\n",
      "Average validation loss: 0.013421488300976005\n",
      "Training epoch 5833...\n",
      "\n",
      "Train Epoch: 5833 [0/8000 (0%)]\tBatch Loss: 0.012626\tLearning Rate (w_theta): 0.001000\t TIME:2982.1s\n",
      "\t\t\t\tDisc: 0.011823\t\tSym: 0.000000\t\tSpars: 0.000802\n",
      "\t TVw: 0.771834 | TVb: 2.281517 | GSw: -0.472974 | GSb: -0.140059 | TSUw: -0.430256 | TSUb: -0.036733\n",
      "\n",
      "Train Epoch: 5833 [4000/8000 (50%)]\tBatch Loss: 0.012743\tLearning Rate (w_theta): 0.001000\t TIME:2983.4s\n",
      "\t\t\t\tDisc: 0.011915\t\tSym: 0.000000\t\tSpars: 0.000828\n",
      "\t TVw: 0.771847 | TVb: 2.281502 | GSw: -0.473034 | GSb: -0.140185 | TSUw: -0.431072 | TSUb: -0.037544\n",
      "Validating epoch 5833...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012918576365587076\n",
      "Average validation loss: 0.013426736895467183\n",
      "Training epoch 5834...\n",
      "\n",
      "Train Epoch: 5834 [0/8000 (0%)]\tBatch Loss: 0.012560\tLearning Rate (w_theta): 0.001000\t TIME:2985.6s\n",
      "\t\t\t\tDisc: 0.011679\t\tSym: 0.000000\t\tSpars: 0.000881\n",
      "\t TVw: 0.771870 | TVb: 2.281524 | GSw: -0.472879 | GSb: -0.140092 | TSUw: -0.430944 | TSUb: -0.037407\n",
      "\n",
      "Train Epoch: 5834 [4000/8000 (50%)]\tBatch Loss: 0.013309\tLearning Rate (w_theta): 0.001000\t TIME:2986.9s\n",
      "\t\t\t\tDisc: 0.012438\t\tSym: 0.000000\t\tSpars: 0.000870\n",
      "\t TVw: 0.771891 | TVb: 2.281583 | GSw: -0.472661 | GSb: -0.139933 | TSUw: -0.430572 | TSUb: -0.037029\n",
      "Validating epoch 5834...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012911434841793646\n",
      "Average validation loss: 0.01342235310578052\n",
      "Training epoch 5835...\n",
      "\n",
      "Train Epoch: 5835 [0/8000 (0%)]\tBatch Loss: 0.012967\tLearning Rate (w_theta): 0.001000\t TIME:2989.1s\n",
      "\t\t\t\tDisc: 0.012198\t\tSym: 0.000000\t\tSpars: 0.000769\n",
      "\t TVw: 0.771837 | TVb: 2.281474 | GSw: -0.472424 | GSb: -0.139748 | TSUw: -0.430190 | TSUb: -0.036639\n",
      "\n",
      "Train Epoch: 5835 [4000/8000 (50%)]\tBatch Loss: 0.012433\tLearning Rate (w_theta): 0.001000\t TIME:2990.4s\n",
      "\t\t\t\tDisc: 0.011728\t\tSym: 0.000000\t\tSpars: 0.000705\n",
      "\t TVw: 0.771545 | TVb: 2.281589 | GSw: -0.472383 | GSb: -0.139779 | TSUw: -0.430628 | TSUb: -0.037070\n",
      "Validating epoch 5835...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01291309913185329\n",
      "Average validation loss: 0.013429299091711134\n",
      "Training epoch 5836...\n",
      "\n",
      "Train Epoch: 5836 [0/8000 (0%)]\tBatch Loss: 0.013013\tLearning Rate (w_theta): 0.001000\t TIME:2992.5s\n",
      "\t\t\t\tDisc: 0.012169\t\tSym: 0.000000\t\tSpars: 0.000844\n",
      "\t TVw: 0.771587 | TVb: 2.281651 | GSw: -0.472363 | GSb: -0.139832 | TSUw: -0.431199 | TSUb: -0.037636\n",
      "\n",
      "Train Epoch: 5836 [4000/8000 (50%)]\tBatch Loss: 0.012716\tLearning Rate (w_theta): 0.001000\t TIME:2993.8s\n",
      "\t\t\t\tDisc: 0.012027\t\tSym: 0.000000\t\tSpars: 0.000689\n",
      "\t TVw: 0.772400 | TVb: 2.282256 | GSw: -0.472171 | GSb: -0.139698 | TSUw: -0.431015 | TSUb: -0.037446\n",
      "Validating epoch 5836...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012914041216978764\n",
      "Average validation loss: 0.01342054327436412\n",
      "Training epoch 5837...\n",
      "\n",
      "Train Epoch: 5837 [0/8000 (0%)]\tBatch Loss: 0.012743\tLearning Rate (w_theta): 0.001000\t TIME:2996.1s\n",
      "\t\t\t\tDisc: 0.011944\t\tSym: 0.000000\t\tSpars: 0.000799\n",
      "\t TVw: 0.772492 | TVb: 2.282053 | GSw: -0.471855 | GSb: -0.139424 | TSUw: -0.430262 | TSUb: -0.036686\n",
      "\n",
      "Train Epoch: 5837 [4000/8000 (50%)]\tBatch Loss: 0.013176\tLearning Rate (w_theta): 0.001000\t TIME:2997.3s\n",
      "\t\t\t\tDisc: 0.012068\t\tSym: 0.000000\t\tSpars: 0.001108\n",
      "\t TVw: 0.772442 | TVb: 2.281772 | GSw: -0.471838 | GSb: -0.139489 | TSUw: -0.430774 | TSUb: -0.037191\n",
      "Validating epoch 5837...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012913307920062372\n",
      "Average validation loss: 0.013425582317468812\n",
      "Training epoch 5838...\n",
      "\n",
      "Train Epoch: 5838 [0/8000 (0%)]\tBatch Loss: 0.013101\tLearning Rate (w_theta): 0.001000\t TIME:2999.6s\n",
      "\t\t\t\tDisc: 0.012026\t\tSym: 0.000000\t\tSpars: 0.001076\n",
      "\t TVw: 0.772238 | TVb: 2.281567 | GSw: -0.471738 | GSb: -0.139458 | TSUw: -0.430963 | TSUb: -0.037373\n",
      "\n",
      "Train Epoch: 5838 [4000/8000 (50%)]\tBatch Loss: 0.012729\tLearning Rate (w_theta): 0.001000\t TIME:3000.9s\n",
      "\t\t\t\tDisc: 0.011590\t\tSym: 0.000000\t\tSpars: 0.001138\n",
      "\t TVw: 0.772633 | TVb: 2.281708 | GSw: -0.471706 | GSb: -0.139516 | TSUw: -0.431488 | TSUb: -0.037893\n",
      "Validating epoch 5838...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012916048328764505\n",
      "Average validation loss: 0.013421807517343292\n",
      "Training epoch 5839...\n",
      "\n",
      "Train Epoch: 5839 [0/8000 (0%)]\tBatch Loss: 0.013218\tLearning Rate (w_theta): 0.001000\t TIME:3003.1s\n",
      "\t\t\t\tDisc: 0.012311\t\tSym: 0.000000\t\tSpars: 0.000907\n",
      "\t TVw: 0.772717 | TVb: 2.281584 | GSw: -0.471285 | GSb: -0.139118 | TSUw: -0.430238 | TSUb: -0.036635\n",
      "\n",
      "Train Epoch: 5839 [4000/8000 (50%)]\tBatch Loss: 0.012905\tLearning Rate (w_theta): 0.001000\t TIME:3004.4s\n",
      "\t\t\t\tDisc: 0.012051\t\tSym: 0.000000\t\tSpars: 0.000854\n",
      "\t TVw: 0.772176 | TVb: 2.281358 | GSw: -0.471122 | GSb: -0.138995 | TSUw: -0.430011 | TSUb: -0.036399\n",
      "Validating epoch 5839...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012917463271776756\n",
      "Average validation loss: 0.013424056881943296\n",
      "Training epoch 5840...\n",
      "\n",
      "Train Epoch: 5840 [0/8000 (0%)]\tBatch Loss: 0.012903\tLearning Rate (w_theta): 0.001000\t TIME:3006.6s\n",
      "\t\t\t\tDisc: 0.011988\t\tSym: 0.000000\t\tSpars: 0.000915\n",
      "\t TVw: 0.771948 | TVb: 2.281359 | GSw: -0.471333 | GSb: -0.139323 | TSUw: -0.431294 | TSUb: -0.037676\n",
      "\n",
      "Train Epoch: 5840 [4000/8000 (50%)]\tBatch Loss: 0.013046\tLearning Rate (w_theta): 0.001000\t TIME:3007.8s\n",
      "\t\t\t\tDisc: 0.012208\t\tSym: 0.000000\t\tSpars: 0.000838\n",
      "\t TVw: 0.771759 | TVb: 2.281310 | GSw: -0.471339 | GSb: -0.139421 | TSUw: -0.431653 | TSUb: -0.038028\n",
      "Validating epoch 5840...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012920068997547435\n",
      "Average validation loss: 0.013423104407214424\n",
      "Training epoch 5841...\n",
      "\n",
      "Train Epoch: 5841 [0/8000 (0%)]\tBatch Loss: 0.012804\tLearning Rate (w_theta): 0.001000\t TIME:3010.7s\n",
      "\t\t\t\tDisc: 0.012040\t\tSym: 0.000000\t\tSpars: 0.000764\n",
      "\t TVw: 0.771871 | TVb: 2.281157 | GSw: -0.470900 | GSb: -0.139013 | TSUw: -0.430120 | TSUb: -0.036485\n",
      "\n",
      "Train Epoch: 5841 [4000/8000 (50%)]\tBatch Loss: 0.012531\tLearning Rate (w_theta): 0.001000\t TIME:3012.0s\n",
      "\t\t\t\tDisc: 0.011720\t\tSym: 0.000000\t\tSpars: 0.000811\n",
      "\t TVw: 0.771666 | TVb: 2.280947 | GSw: -0.470929 | GSb: -0.139120 | TSUw: -0.430418 | TSUb: -0.036775\n",
      "Validating epoch 5841...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01292242094451105\n",
      "Average validation loss: 0.013429394631517723\n",
      "Training epoch 5842...\n",
      "\n",
      "Train Epoch: 5842 [0/8000 (0%)]\tBatch Loss: 0.012563\tLearning Rate (w_theta): 0.001000\t TIME:3014.2s\n",
      "\t\t\t\tDisc: 0.011947\t\tSym: 0.000000\t\tSpars: 0.000616\n",
      "\t TVw: 0.771354 | TVb: 2.280885 | GSw: -0.471024 | GSb: -0.139297 | TSUw: -0.431065 | TSUb: -0.037414\n",
      "\n",
      "Train Epoch: 5842 [4000/8000 (50%)]\tBatch Loss: 0.013608\tLearning Rate (w_theta): 0.001000\t TIME:3015.5s\n",
      "\t\t\t\tDisc: 0.012516\t\tSym: 0.000000\t\tSpars: 0.001092\n",
      "\t TVw: 0.771243 | TVb: 2.280888 | GSw: -0.470908 | GSb: -0.139243 | TSUw: -0.430973 | TSUb: -0.037314\n",
      "Validating epoch 5842...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012915883054203341\n",
      "Average validation loss: 0.013423739135660528\n",
      "Training epoch 5843...\n",
      "\n",
      "Train Epoch: 5843 [0/8000 (0%)]\tBatch Loss: 0.012895\tLearning Rate (w_theta): 0.001000\t TIME:3017.7s\n",
      "\t\t\t\tDisc: 0.011913\t\tSym: 0.000000\t\tSpars: 0.000982\n",
      "\t TVw: 0.771687 | TVb: 2.281171 | GSw: -0.470752 | GSb: -0.139153 | TSUw: -0.430778 | TSUb: -0.037113\n",
      "\n",
      "Train Epoch: 5843 [4000/8000 (50%)]\tBatch Loss: 0.012957\tLearning Rate (w_theta): 0.001000\t TIME:3019.0s\n",
      "\t\t\t\tDisc: 0.012115\t\tSym: 0.000000\t\tSpars: 0.000842\n",
      "\t TVw: 0.771977 | TVb: 2.281199 | GSw: -0.470697 | GSb: -0.139180 | TSUw: -0.431076 | TSUb: -0.037404\n",
      "Validating epoch 5843...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012915932220495507\n",
      "Average validation loss: 0.013424480548859356\n",
      "Training epoch 5844...\n",
      "\n",
      "Train Epoch: 5844 [0/8000 (0%)]\tBatch Loss: 0.012768\tLearning Rate (w_theta): 0.001000\t TIME:3021.2s\n",
      "\t\t\t\tDisc: 0.011996\t\tSym: 0.000000\t\tSpars: 0.000773\n",
      "\t TVw: 0.772158 | TVb: 2.281239 | GSw: -0.470438 | GSb: -0.138966 | TSUw: -0.430596 | TSUb: -0.036917\n",
      "\n",
      "Train Epoch: 5844 [4000/8000 (50%)]\tBatch Loss: 0.012814\tLearning Rate (w_theta): 0.001000\t TIME:3022.5s\n",
      "\t\t\t\tDisc: 0.011904\t\tSym: 0.000000\t\tSpars: 0.000910\n",
      "\t TVw: 0.772617 | TVb: 2.281443 | GSw: -0.470332 | GSb: -0.138929 | TSUw: -0.430723 | TSUb: -0.037038\n",
      "Validating epoch 5844...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012914662564422775\n",
      "Average validation loss: 0.013423097029127272\n",
      "Training epoch 5845...\n",
      "\n",
      "Train Epoch: 5845 [0/8000 (0%)]\tBatch Loss: 0.012857\tLearning Rate (w_theta): 0.001000\t TIME:3024.7s\n",
      "\t\t\t\tDisc: 0.011947\t\tSym: 0.000000\t\tSpars: 0.000910\n",
      "\t TVw: 0.772570 | TVb: 2.281479 | GSw: -0.470178 | GSb: -0.138837 | TSUw: -0.430693 | TSUb: -0.037002\n",
      "\n",
      "Train Epoch: 5845 [4000/8000 (50%)]\tBatch Loss: 0.012978\tLearning Rate (w_theta): 0.001000\t TIME:3025.9s\n",
      "\t\t\t\tDisc: 0.012026\t\tSym: 0.000000\t\tSpars: 0.000952\n",
      "\t TVw: 0.772495 | TVb: 2.281534 | GSw: -0.470049 | GSb: -0.138781 | TSUw: -0.430767 | TSUb: -0.037070\n",
      "Validating epoch 5845...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012914208216812986\n",
      "Average validation loss: 0.013425818896776428\n",
      "Training epoch 5846...\n",
      "\n",
      "Train Epoch: 5846 [0/8000 (0%)]\tBatch Loss: 0.012717\tLearning Rate (w_theta): 0.001000\t TIME:3028.1s\n",
      "\t\t\t\tDisc: 0.011977\t\tSym: 0.000000\t\tSpars: 0.000740\n",
      "\t TVw: 0.772310 | TVb: 2.281504 | GSw: -0.469975 | GSb: -0.138768 | TSUw: -0.431100 | TSUb: -0.037397\n",
      "\n",
      "Train Epoch: 5846 [4000/8000 (50%)]\tBatch Loss: 0.013229\tLearning Rate (w_theta): 0.001000\t TIME:3029.4s\n",
      "\t\t\t\tDisc: 0.012337\t\tSym: 0.000000\t\tSpars: 0.000892\n",
      "\t TVw: 0.772121 | TVb: 2.281214 | GSw: -0.469720 | GSb: -0.138550 | TSUw: -0.430724 | TSUb: -0.037015\n",
      "Validating epoch 5846...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012915132981337191\n",
      "Average validation loss: 0.013423845149000193\n",
      "Training epoch 5847...\n",
      "\n",
      "Train Epoch: 5847 [0/8000 (0%)]\tBatch Loss: 0.013263\tLearning Rate (w_theta): 0.001000\t TIME:3031.6s\n",
      "\t\t\t\tDisc: 0.012444\t\tSym: 0.000000\t\tSpars: 0.000819\n",
      "\t TVw: 0.771806 | TVb: 2.281105 | GSw: -0.469522 | GSb: -0.138401 | TSUw: -0.430541 | TSUb: -0.036825\n",
      "\n",
      "Train Epoch: 5847 [4000/8000 (50%)]\tBatch Loss: 0.012143\tLearning Rate (w_theta): 0.001000\t TIME:3032.9s\n",
      "\t\t\t\tDisc: 0.011535\t\tSym: 0.000000\t\tSpars: 0.000608\n",
      "\t TVw: 0.772715 | TVb: 2.281790 | GSw: -0.469517 | GSb: -0.138478 | TSUw: -0.431073 | TSUb: -0.037353\n",
      "Validating epoch 5847...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012914749720818089\n",
      "Average validation loss: 0.013425209065951143\n",
      "Training epoch 5848...\n",
      "\n",
      "Train Epoch: 5848 [0/8000 (0%)]\tBatch Loss: 0.012821\tLearning Rate (w_theta): 0.001000\t TIME:3035.1s\n",
      "\t\t\t\tDisc: 0.012095\t\tSym: 0.000000\t\tSpars: 0.000727\n",
      "\t TVw: 0.772225 | TVb: 2.281508 | GSw: -0.469377 | GSb: -0.138401 | TSUw: -0.431126 | TSUb: -0.037400\n",
      "\n",
      "Train Epoch: 5848 [4000/8000 (50%)]\tBatch Loss: 0.013161\tLearning Rate (w_theta): 0.001000\t TIME:3036.4s\n",
      "\t\t\t\tDisc: 0.012487\t\tSym: 0.000000\t\tSpars: 0.000675\n",
      "\t TVw: 0.771657 | TVb: 2.281305 | GSw: -0.469143 | GSb: -0.138225 | TSUw: -0.430780 | TSUb: -0.037047\n",
      "Validating epoch 5848...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012915325717805267\n",
      "Average validation loss: 0.013424188882079517\n",
      "Training epoch 5849...\n",
      "\n",
      "Train Epoch: 5849 [0/8000 (0%)]\tBatch Loss: 0.012822\tLearning Rate (w_theta): 0.001000\t TIME:3038.6s\n",
      "\t\t\t\tDisc: 0.011981\t\tSym: 0.000000\t\tSpars: 0.000841\n",
      "\t TVw: 0.771532 | TVb: 2.281286 | GSw: -0.469016 | GSb: -0.138161 | TSUw: -0.430868 | TSUb: -0.037129\n",
      "\n",
      "Train Epoch: 5849 [4000/8000 (50%)]\tBatch Loss: 0.012992\tLearning Rate (w_theta): 0.001000\t TIME:3039.9s\n",
      "\t\t\t\tDisc: 0.012094\t\tSym: 0.000000\t\tSpars: 0.000898\n",
      "\t TVw: 0.772136 | TVb: 2.281466 | GSw: -0.468982 | GSb: -0.138178 | TSUw: -0.431291 | TSUb: -0.037548\n",
      "Validating epoch 5849...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012915416710293181\n",
      "Average validation loss: 0.01342495145747904\n",
      "Training epoch 5850...\n",
      "\n",
      "Train Epoch: 5850 [0/8000 (0%)]\tBatch Loss: 0.013082\tLearning Rate (w_theta): 0.001000\t TIME:3042.0s\n",
      "\t\t\t\tDisc: 0.012217\t\tSym: 0.000000\t\tSpars: 0.000865\n",
      "\t TVw: 0.772305 | TVb: 2.281342 | GSw: -0.468701 | GSb: -0.137940 | TSUw: -0.430753 | TSUb: -0.037003\n",
      "\n",
      "Train Epoch: 5850 [4000/8000 (50%)]\tBatch Loss: 0.013104\tLearning Rate (w_theta): 0.001000\t TIME:3043.3s\n",
      "\t\t\t\tDisc: 0.012125\t\tSym: 0.000000\t\tSpars: 0.000979\n",
      "\t TVw: 0.771918 | TVb: 2.281161 | GSw: -0.468479 | GSb: -0.137771 | TSUw: -0.430459 | TSUb: -0.036702\n",
      "Validating epoch 5850...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012916898701622086\n",
      "Average validation loss: 0.013424817077555577\n",
      "Training epoch 5851...\n",
      "\n",
      "Train Epoch: 5851 [0/8000 (0%)]\tBatch Loss: 0.011916\tLearning Rate (w_theta): 0.001000\t TIME:3046.2s\n",
      "\t\t\t\tDisc: 0.011177\t\tSym: 0.000000\t\tSpars: 0.000739\n",
      "\t TVw: 0.771730 | TVb: 2.281122 | GSw: -0.468503 | GSb: -0.137878 | TSUw: -0.431126 | TSUb: -0.037363\n",
      "\n",
      "Train Epoch: 5851 [4000/8000 (50%)]\tBatch Loss: 0.012543\tLearning Rate (w_theta): 0.001000\t TIME:3047.5s\n",
      "\t\t\t\tDisc: 0.011716\t\tSym: 0.000000\t\tSpars: 0.000827\n",
      "\t TVw: 0.771482 | TVb: 2.280946 | GSw: -0.468522 | GSb: -0.137990 | TSUw: -0.431729 | TSUb: -0.037961\n",
      "Validating epoch 5851...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012923712396514457\n",
      "Average validation loss: 0.013426142569874991\n",
      "Training epoch 5852...\n",
      "\n",
      "Train Epoch: 5852 [0/8000 (0%)]\tBatch Loss: 0.013478\tLearning Rate (w_theta): 0.001000\t TIME:3049.7s\n",
      "\t\t\t\tDisc: 0.012552\t\tSym: 0.000000\t\tSpars: 0.000927\n",
      "\t TVw: 0.771478 | TVb: 2.280794 | GSw: -0.468044 | GSb: -0.137537 | TSUw: -0.430142 | TSUb: -0.036364\n",
      "\n",
      "Train Epoch: 5852 [4000/8000 (50%)]\tBatch Loss: 0.013779\tLearning Rate (w_theta): 0.001000\t TIME:3051.0s\n",
      "\t\t\t\tDisc: 0.012820\t\tSym: 0.000000\t\tSpars: 0.000959\n",
      "\t TVw: 0.771670 | TVb: 2.281045 | GSw: -0.467976 | GSb: -0.137554 | TSUw: -0.430132 | TSUb: -0.036346\n",
      "Validating epoch 5852...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012921337634161967\n",
      "Average validation loss: 0.013434772245783287\n",
      "Training epoch 5853...\n",
      "\n",
      "Train Epoch: 5853 [0/8000 (0%)]\tBatch Loss: 0.013093\tLearning Rate (w_theta): 0.001000\t TIME:3053.2s\n",
      "\t\t\t\tDisc: 0.012292\t\tSym: 0.000000\t\tSpars: 0.000801\n",
      "\t TVw: 0.771714 | TVb: 2.281393 | GSw: -0.468391 | GSb: -0.138094 | TSUw: -0.431965 | TSUb: -0.038173\n",
      "\n",
      "Train Epoch: 5853 [4000/8000 (50%)]\tBatch Loss: 0.012818\tLearning Rate (w_theta): 0.001000\t TIME:3054.5s\n",
      "\t\t\t\tDisc: 0.012262\t\tSym: 0.000000\t\tSpars: 0.000556\n",
      "\t TVw: 0.771183 | TVb: 2.281176 | GSw: -0.468248 | GSb: -0.138016 | TSUw: -0.431397 | TSUb: -0.037595\n",
      "Validating epoch 5853...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01293015197625254\n",
      "Average validation loss: 0.013425729031630768\n",
      "Training epoch 5854...\n",
      "\n",
      "Train Epoch: 5854 [0/8000 (0%)]\tBatch Loss: 0.012928\tLearning Rate (w_theta): 0.001000\t TIME:3056.7s\n",
      "\t\t\t\tDisc: 0.012198\t\tSym: 0.000000\t\tSpars: 0.000729\n",
      "\t TVw: 0.771431 | TVb: 2.281164 | GSw: -0.467945 | GSb: -0.137759 | TSUw: -0.430200 | TSUb: -0.036388\n",
      "\n",
      "Train Epoch: 5854 [4000/8000 (50%)]\tBatch Loss: 0.013639\tLearning Rate (w_theta): 0.001000\t TIME:3058.0s\n",
      "\t\t\t\tDisc: 0.012660\t\tSym: 0.000000\t\tSpars: 0.000979\n",
      "\t TVw: 0.771142 | TVb: 2.281016 | GSw: -0.468083 | GSb: -0.137996 | TSUw: -0.430848 | TSUb: -0.037027\n",
      "Validating epoch 5854...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012919285985229505\n",
      "Average validation loss: 0.013438311459757563\n",
      "Training epoch 5855...\n",
      "\n",
      "Train Epoch: 5855 [0/8000 (0%)]\tBatch Loss: 0.013382\tLearning Rate (w_theta): 0.001000\t TIME:3060.2s\n",
      "\t\t\t\tDisc: 0.012374\t\tSym: 0.000000\t\tSpars: 0.001008\n",
      "\t TVw: 0.771411 | TVb: 2.281227 | GSw: -0.468256 | GSb: -0.138264 | TSUw: -0.431701 | TSUb: -0.037873\n",
      "\n",
      "Train Epoch: 5855 [4000/8000 (50%)]\tBatch Loss: 0.012723\tLearning Rate (w_theta): 0.001000\t TIME:3061.5s\n",
      "\t\t\t\tDisc: 0.011779\t\tSym: 0.000000\t\tSpars: 0.000945\n",
      "\t TVw: 0.772063 | TVb: 2.281491 | GSw: -0.468083 | GSb: -0.138160 | TSUw: -0.431274 | TSUb: -0.037439\n",
      "Validating epoch 5855...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012915893954382422\n",
      "Average validation loss: 0.013424719857493675\n",
      "Training epoch 5856...\n",
      "\n",
      "Train Epoch: 5856 [0/8000 (0%)]\tBatch Loss: 0.012835\tLearning Rate (w_theta): 0.001000\t TIME:3063.8s\n",
      "\t\t\t\tDisc: 0.011952\t\tSym: 0.000000\t\tSpars: 0.000883\n",
      "\t TVw: 0.772044 | TVb: 2.281307 | GSw: -0.467719 | GSb: -0.137841 | TSUw: -0.430205 | TSUb: -0.036361\n",
      "\n",
      "Train Epoch: 5856 [4000/8000 (50%)]\tBatch Loss: 0.013278\tLearning Rate (w_theta): 0.001000\t TIME:3065.1s\n",
      "\t\t\t\tDisc: 0.012341\t\tSym: 0.000000\t\tSpars: 0.000937\n",
      "\t TVw: 0.772059 | TVb: 2.281349 | GSw: -0.467844 | GSb: -0.138075 | TSUw: -0.430952 | TSUb: -0.037102\n",
      "Validating epoch 5856...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01291933480993239\n",
      "Average validation loss: 0.013426659660639821\n",
      "Training epoch 5857...\n",
      "\n",
      "Train Epoch: 5857 [0/8000 (0%)]\tBatch Loss: 0.013067\tLearning Rate (w_theta): 0.001000\t TIME:3067.4s\n",
      "\t\t\t\tDisc: 0.012246\t\tSym: 0.000000\t\tSpars: 0.000820\n",
      "\t TVw: 0.771863 | TVb: 2.281301 | GSw: -0.467793 | GSb: -0.138097 | TSUw: -0.431146 | TSUb: -0.037290\n",
      "\n",
      "Train Epoch: 5857 [4000/8000 (50%)]\tBatch Loss: 0.013000\tLearning Rate (w_theta): 0.001000\t TIME:3068.6s\n",
      "\t\t\t\tDisc: 0.012158\t\tSym: 0.000000\t\tSpars: 0.000842\n",
      "\t TVw: 0.772365 | TVb: 2.281554 | GSw: -0.467776 | GSb: -0.138151 | TSUw: -0.431548 | TSUb: -0.037687\n",
      "Validating epoch 5857...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012916859502674308\n",
      "Average validation loss: 0.013423316085215959\n",
      "Training epoch 5858...\n",
      "\n",
      "Train Epoch: 5858 [0/8000 (0%)]\tBatch Loss: 0.012964\tLearning Rate (w_theta): 0.001000\t TIME:3070.8s\n",
      "\t\t\t\tDisc: 0.012380\t\tSym: 0.000000\t\tSpars: 0.000583\n",
      "\t TVw: 0.772270 | TVb: 2.281350 | GSw: -0.467341 | GSb: -0.137747 | TSUw: -0.430312 | TSUb: -0.036443\n",
      "\n",
      "Train Epoch: 5858 [4000/8000 (50%)]\tBatch Loss: 0.013127\tLearning Rate (w_theta): 0.001000\t TIME:3072.1s\n",
      "\t\t\t\tDisc: 0.012461\t\tSym: 0.000000\t\tSpars: 0.000666\n",
      "\t TVw: 0.771963 | TVb: 2.281369 | GSw: -0.467216 | GSb: -0.137682 | TSUw: -0.430164 | TSUb: -0.036288\n",
      "Validating epoch 5858...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012922072611006676\n",
      "Average validation loss: 0.013433609842020789\n",
      "Training epoch 5859...\n",
      "\n",
      "Train Epoch: 5859 [0/8000 (0%)]\tBatch Loss: 0.012943\tLearning Rate (w_theta): 0.001000\t TIME:3074.3s\n",
      "\t\t\t\tDisc: 0.012216\t\tSym: 0.000000\t\tSpars: 0.000727\n",
      "\t TVw: 0.771568 | TVb: 2.281365 | GSw: -0.467608 | GSb: -0.138190 | TSUw: -0.431853 | TSUb: -0.037971\n",
      "\n",
      "Train Epoch: 5859 [4000/8000 (50%)]\tBatch Loss: 0.012808\tLearning Rate (w_theta): 0.001000\t TIME:3075.6s\n",
      "\t\t\t\tDisc: 0.012076\t\tSym: 0.000000\t\tSpars: 0.000732\n",
      "\t TVw: 0.771411 | TVb: 2.281136 | GSw: -0.467387 | GSb: -0.138024 | TSUw: -0.431108 | TSUb: -0.037216\n",
      "Validating epoch 5859...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01293057670791566\n",
      "Average validation loss: 0.01342551705814217\n",
      "Training epoch 5860...\n",
      "\n",
      "Train Epoch: 5860 [0/8000 (0%)]\tBatch Loss: 0.013048\tLearning Rate (w_theta): 0.001000\t TIME:3077.8s\n",
      "\t\t\t\tDisc: 0.012033\t\tSym: 0.000000\t\tSpars: 0.001015\n",
      "\t TVw: 0.771567 | TVb: 2.281176 | GSw: -0.467239 | GSb: -0.137945 | TSUw: -0.430603 | TSUb: -0.036702\n",
      "\n",
      "Train Epoch: 5860 [4000/8000 (50%)]\tBatch Loss: 0.012824\tLearning Rate (w_theta): 0.001000\t TIME:3079.1s\n",
      "\t\t\t\tDisc: 0.012088\t\tSym: 0.000000\t\tSpars: 0.000736\n",
      "\t TVw: 0.771446 | TVb: 2.281214 | GSw: -0.467327 | GSb: -0.138124 | TSUw: -0.431102 | TSUb: -0.037195\n",
      "Validating epoch 5860...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012916601097741556\n",
      "Average validation loss: 0.013428631221993632\n",
      "Training epoch 5861...\n",
      "\n",
      "Train Epoch: 5861 [0/8000 (0%)]\tBatch Loss: 0.012956\tLearning Rate (w_theta): 0.001000\t TIME:3082.0s\n",
      "\t\t\t\tDisc: 0.012153\t\tSym: 0.000000\t\tSpars: 0.000803\n",
      "\t TVw: 0.771190 | TVb: 2.281069 | GSw: -0.467281 | GSb: -0.138158 | TSUw: -0.431240 | TSUb: -0.037325\n",
      "\n",
      "Train Epoch: 5861 [4000/8000 (50%)]\tBatch Loss: 0.013082\tLearning Rate (w_theta): 0.001000\t TIME:3083.3s\n",
      "\t\t\t\tDisc: 0.012154\t\tSym: 0.000000\t\tSpars: 0.000928\n",
      "\t TVw: 0.771559 | TVb: 2.281142 | GSw: -0.467193 | GSb: -0.138159 | TSUw: -0.431281 | TSUb: -0.037361\n",
      "Validating epoch 5861...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012918002554072478\n",
      "Average validation loss: 0.013424863657474015\n",
      "Training epoch 5862...\n",
      "\n",
      "Train Epoch: 5862 [0/8000 (0%)]\tBatch Loss: 0.013370\tLearning Rate (w_theta): 0.001000\t TIME:3085.6s\n",
      "\t\t\t\tDisc: 0.012502\t\tSym: 0.000000\t\tSpars: 0.000869\n",
      "\t TVw: 0.771662 | TVb: 2.281064 | GSw: -0.466893 | GSb: -0.137898 | TSUw: -0.430567 | TSUb: -0.036640\n",
      "\n",
      "Train Epoch: 5862 [4000/8000 (50%)]\tBatch Loss: 0.012312\tLearning Rate (w_theta): 0.001000\t TIME:3086.9s\n",
      "\t\t\t\tDisc: 0.011705\t\tSym: 0.000000\t\tSpars: 0.000608\n",
      "\t TVw: 0.771472 | TVb: 2.280885 | GSw: -0.466833 | GSb: -0.137913 | TSUw: -0.430761 | TSUb: -0.036827\n",
      "Validating epoch 5862...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012920558671278618\n",
      "Average validation loss: 0.013435445175005457\n",
      "Training epoch 5863...\n",
      "\n",
      "Train Epoch: 5863 [0/8000 (0%)]\tBatch Loss: 0.013299\tLearning Rate (w_theta): 0.001000\t TIME:3089.1s\n",
      "\t\t\t\tDisc: 0.012550\t\tSym: 0.000000\t\tSpars: 0.000749\n",
      "\t TVw: 0.771412 | TVb: 2.281039 | GSw: -0.466952 | GSb: -0.138121 | TSUw: -0.431547 | TSUb: -0.037608\n",
      "\n",
      "Train Epoch: 5863 [4000/8000 (50%)]\tBatch Loss: 0.012873\tLearning Rate (w_theta): 0.001000\t TIME:3090.3s\n",
      "\t\t\t\tDisc: 0.011934\t\tSym: 0.000000\t\tSpars: 0.000939\n",
      "\t TVw: 0.771408 | TVb: 2.281183 | GSw: -0.466773 | GSb: -0.137988 | TSUw: -0.431267 | TSUb: -0.037322\n",
      "Validating epoch 5863...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012917969945387117\n",
      "Average validation loss: 0.013425176651370321\n",
      "Training epoch 5864...\n",
      "\n",
      "Train Epoch: 5864 [0/8000 (0%)]\tBatch Loss: 0.012968\tLearning Rate (w_theta): 0.001000\t TIME:3092.6s\n",
      "\t\t\t\tDisc: 0.012009\t\tSym: 0.000000\t\tSpars: 0.000959\n",
      "\t TVw: 0.771563 | TVb: 2.281322 | GSw: -0.466567 | GSb: -0.137851 | TSUw: -0.430945 | TSUb: -0.036993\n",
      "\n",
      "Train Epoch: 5864 [4000/8000 (50%)]\tBatch Loss: 0.013221\tLearning Rate (w_theta): 0.001000\t TIME:3093.8s\n",
      "\t\t\t\tDisc: 0.012433\t\tSym: 0.000000\t\tSpars: 0.000788\n",
      "\t TVw: 0.771195 | TVb: 2.281219 | GSw: -0.466501 | GSb: -0.137874 | TSUw: -0.431212 | TSUb: -0.037255\n",
      "Validating epoch 5864...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012916910282172511\n",
      "Average validation loss: 0.013425375485969409\n",
      "Training epoch 5865...\n",
      "\n",
      "Train Epoch: 5865 [0/8000 (0%)]\tBatch Loss: 0.012879\tLearning Rate (w_theta): 0.001000\t TIME:3096.1s\n",
      "\t\t\t\tDisc: 0.011898\t\tSym: 0.000000\t\tSpars: 0.000980\n",
      "\t TVw: 0.771314 | TVb: 2.281254 | GSw: -0.466205 | GSb: -0.137619 | TSUw: -0.430658 | TSUb: -0.036695\n",
      "\n",
      "Train Epoch: 5865 [4000/8000 (50%)]\tBatch Loss: 0.012796\tLearning Rate (w_theta): 0.001000\t TIME:3097.4s\n",
      "\t\t\t\tDisc: 0.012081\t\tSym: 0.000000\t\tSpars: 0.000715\n",
      "\t TVw: 0.772325 | TVb: 2.282009 | GSw: -0.466176 | GSb: -0.137657 | TSUw: -0.431015 | TSUb: -0.037048\n",
      "Validating epoch 5865...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012916916543313043\n",
      "Average validation loss: 0.013428349070300894\n",
      "Training epoch 5866...\n",
      "\n",
      "Train Epoch: 5866 [0/8000 (0%)]\tBatch Loss: 0.013329\tLearning Rate (w_theta): 0.001000\t TIME:3099.6s\n",
      "\t\t\t\tDisc: 0.012466\t\tSym: 0.000000\t\tSpars: 0.000863\n",
      "\t TVw: 0.772207 | TVb: 2.281902 | GSw: -0.466133 | GSb: -0.137690 | TSUw: -0.431352 | TSUb: -0.037380\n",
      "\n",
      "Train Epoch: 5866 [4000/8000 (50%)]\tBatch Loss: 0.013033\tLearning Rate (w_theta): 0.001000\t TIME:3100.9s\n",
      "\t\t\t\tDisc: 0.012148\t\tSym: 0.000000\t\tSpars: 0.000885\n",
      "\t TVw: 0.771571 | TVb: 2.281329 | GSw: -0.465848 | GSb: -0.137456 | TSUw: -0.430806 | TSUb: -0.036827\n",
      "Validating epoch 5866...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01291725218220896\n",
      "Average validation loss: 0.01342553134741644\n",
      "Training epoch 5867...\n",
      "\n",
      "Train Epoch: 5867 [0/8000 (0%)]\tBatch Loss: 0.012514\tLearning Rate (w_theta): 0.001000\t TIME:3103.1s\n",
      "\t\t\t\tDisc: 0.011776\t\tSym: 0.000000\t\tSpars: 0.000737\n",
      "\t TVw: 0.771397 | TVb: 2.281214 | GSw: -0.465766 | GSb: -0.137444 | TSUw: -0.431028 | TSUb: -0.037043\n",
      "\n",
      "Train Epoch: 5867 [4000/8000 (50%)]\tBatch Loss: 0.012546\tLearning Rate (w_theta): 0.001000\t TIME:3104.4s\n",
      "\t\t\t\tDisc: 0.011920\t\tSym: 0.000000\t\tSpars: 0.000625\n",
      "\t TVw: 0.770594 | TVb: 2.280620 | GSw: -0.465620 | GSb: -0.137349 | TSUw: -0.431026 | TSUb: -0.037036\n",
      "Validating epoch 5867...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012917773604136505\n",
      "Average validation loss: 0.013429642141493048\n",
      "Training epoch 5868...\n",
      "\n",
      "Train Epoch: 5868 [0/8000 (0%)]\tBatch Loss: 0.012455\tLearning Rate (w_theta): 0.001000\t TIME:3106.5s\n",
      "\t\t\t\tDisc: 0.011729\t\tSym: 0.000000\t\tSpars: 0.000726\n",
      "\t TVw: 0.770572 | TVb: 2.280559 | GSw: -0.465548 | GSb: -0.137350 | TSUw: -0.431310 | TSUb: -0.037316\n",
      "\n",
      "Train Epoch: 5868 [4000/8000 (50%)]\tBatch Loss: 0.013489\tLearning Rate (w_theta): 0.001000\t TIME:3107.8s\n",
      "\t\t\t\tDisc: 0.012531\t\tSym: 0.000000\t\tSpars: 0.000958\n",
      "\t TVw: 0.770622 | TVb: 2.280534 | GSw: -0.465390 | GSb: -0.137264 | TSUw: -0.431288 | TSUb: -0.037288\n",
      "Validating epoch 5868...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012919566455071127\n",
      "Average validation loss: 0.013426613573717942\n",
      "Training epoch 5869...\n",
      "\n",
      "Train Epoch: 5869 [0/8000 (0%)]\tBatch Loss: 0.012933\tLearning Rate (w_theta): 0.001000\t TIME:3110.0s\n",
      "\t\t\t\tDisc: 0.012016\t\tSym: 0.000000\t\tSpars: 0.000917\n",
      "\t TVw: 0.771243 | TVb: 2.280811 | GSw: -0.465148 | GSb: -0.137072 | TSUw: -0.430918 | TSUb: -0.036913\n",
      "\n",
      "Train Epoch: 5869 [4000/8000 (50%)]\tBatch Loss: 0.013065\tLearning Rate (w_theta): 0.001000\t TIME:3111.3s\n",
      "\t\t\t\tDisc: 0.012253\t\tSym: 0.000000\t\tSpars: 0.000812\n",
      "\t TVw: 0.772038 | TVb: 2.281263 | GSw: -0.465116 | GSb: -0.137105 | TSUw: -0.431279 | TSUb: -0.037270\n",
      "Validating epoch 5869...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012918653440174272\n",
      "Average validation loss: 0.013425032154072947\n",
      "Training epoch 5870...\n",
      "\n",
      "Train Epoch: 5870 [0/8000 (0%)]\tBatch Loss: 0.012663\tLearning Rate (w_theta): 0.001000\t TIME:3113.6s\n",
      "\t\t\t\tDisc: 0.011851\t\tSym: 0.000000\t\tSpars: 0.000812\n",
      "\t TVw: 0.772221 | TVb: 2.281411 | GSw: -0.464838 | GSb: -0.136870 | TSUw: -0.430796 | TSUb: -0.036781\n",
      "\n",
      "Train Epoch: 5870 [4000/8000 (50%)]\tBatch Loss: 0.013276\tLearning Rate (w_theta): 0.001000\t TIME:3114.8s\n",
      "\t\t\t\tDisc: 0.012395\t\tSym: 0.000000\t\tSpars: 0.000881\n",
      "\t TVw: 0.772071 | TVb: 2.281467 | GSw: -0.464701 | GSb: -0.136803 | TSUw: -0.430830 | TSUb: -0.036810\n",
      "Validating epoch 5870...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012917004155052605\n",
      "Average validation loss: 0.013429069281335809\n",
      "Training epoch 5871...\n",
      "\n",
      "Train Epoch: 5871 [0/8000 (0%)]\tBatch Loss: 0.012384\tLearning Rate (w_theta): 0.001000\t TIME:3117.8s\n",
      "\t\t\t\tDisc: 0.011722\t\tSym: 0.000000\t\tSpars: 0.000661\n",
      "\t TVw: 0.771872 | TVb: 2.281394 | GSw: -0.464721 | GSb: -0.136909 | TSUw: -0.431396 | TSUb: -0.037370\n",
      "\n",
      "Train Epoch: 5871 [4000/8000 (50%)]\tBatch Loss: 0.012832\tLearning Rate (w_theta): 0.001000\t TIME:3119.1s\n",
      "\t\t\t\tDisc: 0.011814\t\tSym: 0.000000\t\tSpars: 0.001018\n",
      "\t TVw: 0.771554 | TVb: 2.281289 | GSw: -0.464501 | GSb: -0.136733 | TSUw: -0.431083 | TSUb: -0.037052\n",
      "Validating epoch 5871...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01291774396255066\n",
      "Average validation loss: 0.013426255772543045\n",
      "Training epoch 5872...\n",
      "\n",
      "Train Epoch: 5872 [0/8000 (0%)]\tBatch Loss: 0.013606\tLearning Rate (w_theta): 0.001000\t TIME:3121.4s\n",
      "\t\t\t\tDisc: 0.012556\t\tSym: 0.000000\t\tSpars: 0.001050\n",
      "\t TVw: 0.771678 | TVb: 2.281491 | GSw: -0.464397 | GSb: -0.136691 | TSUw: -0.431209 | TSUb: -0.037173\n",
      "\n",
      "Train Epoch: 5872 [4000/8000 (50%)]\tBatch Loss: 0.012250\tLearning Rate (w_theta): 0.001000\t TIME:3122.6s\n",
      "\t\t\t\tDisc: 0.011677\t\tSym: 0.000000\t\tSpars: 0.000573\n",
      "\t TVw: 0.772093 | TVb: 2.281817 | GSw: -0.464231 | GSb: -0.136579 | TSUw: -0.431115 | TSUb: -0.037073\n",
      "Validating epoch 5872...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01291686204494658\n",
      "Average validation loss: 0.013424755903126325\n",
      "Training epoch 5873...\n",
      "\n",
      "Train Epoch: 5873 [0/8000 (0%)]\tBatch Loss: 0.012260\tLearning Rate (w_theta): 0.001000\t TIME:3124.8s\n",
      "\t\t\t\tDisc: 0.011643\t\tSym: 0.000000\t\tSpars: 0.000617\n",
      "\t TVw: 0.771885 | TVb: 2.281555 | GSw: -0.464068 | GSb: -0.136486 | TSUw: -0.431065 | TSUb: -0.037019\n",
      "\n",
      "Train Epoch: 5873 [4000/8000 (50%)]\tBatch Loss: 0.012963\tLearning Rate (w_theta): 0.001000\t TIME:3126.1s\n",
      "\t\t\t\tDisc: 0.012119\t\tSym: 0.000000\t\tSpars: 0.000844\n",
      "\t TVw: 0.771066 | TVb: 2.280829 | GSw: -0.463877 | GSb: -0.136360 | TSUw: -0.430981 | TSUb: -0.036928\n",
      "Validating epoch 5873...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012917228917337086\n",
      "Average validation loss: 0.013432126403538658\n",
      "Training epoch 5874...\n",
      "\n",
      "Train Epoch: 5874 [0/8000 (0%)]\tBatch Loss: 0.012951\tLearning Rate (w_theta): 0.001000\t TIME:3128.4s\n",
      "\t\t\t\tDisc: 0.012323\t\tSym: 0.000000\t\tSpars: 0.000628\n",
      "\t TVw: 0.770817 | TVb: 2.280611 | GSw: -0.463850 | GSb: -0.136405 | TSUw: -0.431426 | TSUb: -0.037369\n",
      "\n",
      "Train Epoch: 5874 [4000/8000 (50%)]\tBatch Loss: 0.012865\tLearning Rate (w_theta): 0.001000\t TIME:3129.7s\n",
      "\t\t\t\tDisc: 0.012087\t\tSym: 0.000000\t\tSpars: 0.000778\n",
      "\t TVw: 0.771177 | TVb: 2.280822 | GSw: -0.463681 | GSb: -0.136286 | TSUw: -0.431317 | TSUb: -0.037255\n",
      "Validating epoch 5874...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012919738151438237\n",
      "Average validation loss: 0.013427505839383689\n",
      "Training epoch 5875...\n",
      "\n",
      "Train Epoch: 5875 [0/8000 (0%)]\tBatch Loss: 0.013021\tLearning Rate (w_theta): 0.001000\t TIME:3131.9s\n",
      "\t\t\t\tDisc: 0.012269\t\tSym: 0.000000\t\tSpars: 0.000752\n",
      "\t TVw: 0.771077 | TVb: 2.280718 | GSw: -0.463440 | GSb: -0.136099 | TSUw: -0.430969 | TSUb: -0.036901\n",
      "\n",
      "Train Epoch: 5875 [4000/8000 (50%)]\tBatch Loss: 0.013016\tLearning Rate (w_theta): 0.001000\t TIME:3133.2s\n",
      "\t\t\t\tDisc: 0.012210\t\tSym: 0.000000\t\tSpars: 0.000806\n",
      "\t TVw: 0.770809 | TVb: 2.280566 | GSw: -0.463403 | GSb: -0.136122 | TSUw: -0.431340 | TSUb: -0.037267\n",
      "Validating epoch 5875...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012919532384653619\n",
      "Average validation loss: 0.013430439268672201\n",
      "Training epoch 5876...\n",
      "\n",
      "Train Epoch: 5876 [0/8000 (0%)]\tBatch Loss: 0.013529\tLearning Rate (w_theta): 0.001000\t TIME:3135.5s\n",
      "\t\t\t\tDisc: 0.012614\t\tSym: 0.000000\t\tSpars: 0.000915\n",
      "\t TVw: 0.771020 | TVb: 2.280640 | GSw: -0.463248 | GSb: -0.136031 | TSUw: -0.431308 | TSUb: -0.037230\n",
      "\n",
      "Train Epoch: 5876 [4000/8000 (50%)]\tBatch Loss: 0.012737\tLearning Rate (w_theta): 0.001000\t TIME:3136.7s\n",
      "\t\t\t\tDisc: 0.012213\t\tSym: 0.000000\t\tSpars: 0.000523\n",
      "\t TVw: 0.772108 | TVb: 2.281240 | GSw: -0.463097 | GSb: -0.135950 | TSUw: -0.431293 | TSUb: -0.037211\n",
      "Validating epoch 5876...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01291829242547376\n",
      "Average validation loss: 0.013425808872972733\n",
      "Training epoch 5877...\n",
      "\n",
      "Train Epoch: 5877 [0/8000 (0%)]\tBatch Loss: 0.012102\tLearning Rate (w_theta): 0.001000\t TIME:3138.9s\n",
      "\t\t\t\tDisc: 0.011480\t\tSym: 0.000000\t\tSpars: 0.000622\n",
      "\t TVw: 0.771968 | TVb: 2.281101 | GSw: -0.462821 | GSb: -0.135742 | TSUw: -0.430840 | TSUb: -0.036753\n",
      "\n",
      "Train Epoch: 5877 [4000/8000 (50%)]\tBatch Loss: 0.013126\tLearning Rate (w_theta): 0.001000\t TIME:3140.2s\n",
      "\t\t\t\tDisc: 0.012367\t\tSym: 0.000000\t\tSpars: 0.000759\n",
      "\t TVw: 0.771472 | TVb: 2.280916 | GSw: -0.462703 | GSb: -0.135708 | TSUw: -0.430980 | TSUb: -0.036887\n",
      "Validating epoch 5877...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012917975464802322\n",
      "Average validation loss: 0.01343234429254048\n",
      "Training epoch 5878...\n",
      "\n",
      "Train Epoch: 5878 [0/8000 (0%)]\tBatch Loss: 0.012908\tLearning Rate (w_theta): 0.001000\t TIME:3142.4s\n",
      "\t\t\t\tDisc: 0.012097\t\tSym: 0.000000\t\tSpars: 0.000811\n",
      "\t TVw: 0.771352 | TVb: 2.281027 | GSw: -0.462764 | GSb: -0.135868 | TSUw: -0.431721 | TSUb: -0.037623\n",
      "\n",
      "Train Epoch: 5878 [4000/8000 (50%)]\tBatch Loss: 0.012888\tLearning Rate (w_theta): 0.001000\t TIME:3143.7s\n",
      "\t\t\t\tDisc: 0.012299\t\tSym: 0.000000\t\tSpars: 0.000588\n",
      "\t TVw: 0.771502 | TVb: 2.281033 | GSw: -0.462568 | GSb: -0.135732 | TSUw: -0.431444 | TSUb: -0.037340\n",
      "Validating epoch 5878...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012920264311697332\n",
      "Average validation loss: 0.01342669011294499\n",
      "Training epoch 5879...\n",
      "\n",
      "Train Epoch: 5879 [0/8000 (0%)]\tBatch Loss: 0.012961\tLearning Rate (w_theta): 0.001000\t TIME:3145.9s\n",
      "\t\t\t\tDisc: 0.012279\t\tSym: 0.000000\t\tSpars: 0.000682\n",
      "\t TVw: 0.771536 | TVb: 2.280952 | GSw: -0.462322 | GSb: -0.135540 | TSUw: -0.430997 | TSUb: -0.036887\n",
      "\n",
      "Train Epoch: 5879 [4000/8000 (50%)]\tBatch Loss: 0.012647\tLearning Rate (w_theta): 0.001000\t TIME:3147.2s\n",
      "\t\t\t\tDisc: 0.011830\t\tSym: 0.000000\t\tSpars: 0.000816\n",
      "\t TVw: 0.771210 | TVb: 2.280814 | GSw: -0.462290 | GSb: -0.135610 | TSUw: -0.431366 | TSUb: -0.037250\n",
      "Validating epoch 5879...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012921480875721992\n",
      "Average validation loss: 0.013431816754272526\n",
      "Training epoch 5880...\n",
      "\n",
      "Train Epoch: 5880 [0/8000 (0%)]\tBatch Loss: 0.013098\tLearning Rate (w_theta): 0.001000\t TIME:3149.4s\n",
      "\t\t\t\tDisc: 0.012052\t\tSym: 0.000000\t\tSpars: 0.001046\n",
      "\t TVw: 0.771483 | TVb: 2.280996 | GSw: -0.462194 | GSb: -0.135587 | TSUw: -0.431456 | TSUb: -0.037335\n",
      "\n",
      "Train Epoch: 5880 [4000/8000 (50%)]\tBatch Loss: 0.012549\tLearning Rate (w_theta): 0.001000\t TIME:3150.7s\n",
      "\t\t\t\tDisc: 0.011854\t\tSym: 0.000000\t\tSpars: 0.000696\n",
      "\t TVw: 0.771588 | TVb: 2.280902 | GSw: -0.461891 | GSb: -0.135327 | TSUw: -0.430769 | TSUb: -0.036642\n",
      "Validating epoch 5880...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012921691616192383\n",
      "Average validation loss: 0.013428806071931237\n",
      "Training epoch 5881...\n",
      "\n",
      "Train Epoch: 5881 [0/8000 (0%)]\tBatch Loss: 0.013219\tLearning Rate (w_theta): 0.001000\t TIME:3153.4s\n",
      "\t\t\t\tDisc: 0.012090\t\tSym: 0.000000\t\tSpars: 0.001129\n",
      "\t TVw: 0.771650 | TVb: 2.281100 | GSw: -0.462032 | GSb: -0.135556 | TSUw: -0.431653 | TSUb: -0.037522\n",
      "\n",
      "Train Epoch: 5881 [4000/8000 (50%)]\tBatch Loss: 0.012667\tLearning Rate (w_theta): 0.001000\t TIME:3154.7s\n",
      "\t\t\t\tDisc: 0.011908\t\tSym: 0.000000\t\tSpars: 0.000759\n",
      "\t TVw: 0.772225 | TVb: 2.281651 | GSw: -0.461972 | GSb: -0.135566 | TSUw: -0.431745 | TSUb: -0.037608\n",
      "Validating epoch 5881...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012923405818479672\n",
      "Average validation loss: 0.013425953990495043\n",
      "Training epoch 5882...\n",
      "\n",
      "Train Epoch: 5882 [0/8000 (0%)]\tBatch Loss: 0.013204\tLearning Rate (w_theta): 0.001000\t TIME:3156.9s\n",
      "\t\t\t\tDisc: 0.012331\t\tSym: 0.000000\t\tSpars: 0.000873\n",
      "\t TVw: 0.772031 | TVb: 2.281460 | GSw: -0.461591 | GSb: -0.135216 | TSUw: -0.430688 | TSUb: -0.036544\n",
      "\n",
      "Train Epoch: 5882 [4000/8000 (50%)]\tBatch Loss: 0.012619\tLearning Rate (w_theta): 0.001000\t TIME:3158.2s\n",
      "\t\t\t\tDisc: 0.011878\t\tSym: 0.000000\t\tSpars: 0.000741\n",
      "\t TVw: 0.772003 | TVb: 2.281277 | GSw: -0.461602 | GSb: -0.135305 | TSUw: -0.431015 | TSUb: -0.036865\n",
      "Validating epoch 5882...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01291869629779885\n",
      "Average validation loss: 0.013435162644477278\n",
      "Training epoch 5883...\n",
      "\n",
      "Train Epoch: 5883 [0/8000 (0%)]\tBatch Loss: 0.013130\tLearning Rate (w_theta): 0.001000\t TIME:3160.5s\n",
      "\t\t\t\tDisc: 0.012225\t\tSym: 0.000000\t\tSpars: 0.000905\n",
      "\t TVw: 0.771696 | TVb: 2.281277 | GSw: -0.461772 | GSb: -0.135572 | TSUw: -0.431956 | TSUb: -0.037801\n",
      "\n",
      "Train Epoch: 5883 [4000/8000 (50%)]\tBatch Loss: 0.012612\tLearning Rate (w_theta): 0.001000\t TIME:3161.7s\n",
      "\t\t\t\tDisc: 0.011990\t\tSym: 0.000000\t\tSpars: 0.000621\n",
      "\t TVw: 0.771193 | TVb: 2.280766 | GSw: -0.461387 | GSb: -0.135213 | TSUw: -0.430864 | TSUb: -0.036701\n",
      "Validating epoch 5883...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012930856744298957\n",
      "Average validation loss: 0.013427802669233069\n",
      "Training epoch 5884...\n",
      "\n",
      "Train Epoch: 5884 [0/8000 (0%)]\tBatch Loss: 0.012804\tLearning Rate (w_theta): 0.001000\t TIME:3164.0s\n",
      "\t\t\t\tDisc: 0.012033\t\tSym: 0.000000\t\tSpars: 0.000771\n",
      "\t TVw: 0.771154 | TVb: 2.280837 | GSw: -0.461417 | GSb: -0.135330 | TSUw: -0.431122 | TSUb: -0.036953\n",
      "\n",
      "Train Epoch: 5884 [4000/8000 (50%)]\tBatch Loss: 0.012537\tLearning Rate (w_theta): 0.001000\t TIME:3165.3s\n",
      "\t\t\t\tDisc: 0.011858\t\tSym: 0.000000\t\tSpars: 0.000679\n",
      "\t TVw: 0.770848 | TVb: 2.280782 | GSw: -0.461504 | GSb: -0.135524 | TSUw: -0.431636 | TSUb: -0.037460\n",
      "Validating epoch 5884...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012919392649298289\n",
      "Average validation loss: 0.013432272541832187\n",
      "Training epoch 5885...\n",
      "\n",
      "Train Epoch: 5885 [0/8000 (0%)]\tBatch Loss: 0.012581\tLearning Rate (w_theta): 0.001000\t TIME:3167.5s\n",
      "\t\t\t\tDisc: 0.011981\t\tSym: 0.000000\t\tSpars: 0.000600\n",
      "\t TVw: 0.770635 | TVb: 2.280742 | GSw: -0.461326 | GSb: -0.135410 | TSUw: -0.431338 | TSUb: -0.037156\n",
      "\n",
      "Train Epoch: 5885 [4000/8000 (50%)]\tBatch Loss: 0.012592\tLearning Rate (w_theta): 0.001000\t TIME:3168.7s\n",
      "\t\t\t\tDisc: 0.011808\t\tSym: 0.000000\t\tSpars: 0.000784\n",
      "\t TVw: 0.770793 | TVb: 2.280755 | GSw: -0.461149 | GSb: -0.135275 | TSUw: -0.431101 | TSUb: -0.036913\n",
      "Validating epoch 5885...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01292134547031314\n",
      "Average validation loss: 0.013431096286646892\n",
      "Training epoch 5886...\n",
      "\n",
      "Train Epoch: 5886 [0/8000 (0%)]\tBatch Loss: 0.012729\tLearning Rate (w_theta): 0.001000\t TIME:3171.0s\n",
      "\t\t\t\tDisc: 0.011970\t\tSym: 0.000000\t\tSpars: 0.000759\n",
      "\t TVw: 0.770894 | TVb: 2.280885 | GSw: -0.461178 | GSb: -0.135392 | TSUw: -0.431602 | TSUb: -0.037409\n",
      "\n",
      "Train Epoch: 5886 [4000/8000 (50%)]\tBatch Loss: 0.012595\tLearning Rate (w_theta): 0.001000\t TIME:3172.3s\n",
      "\t\t\t\tDisc: 0.011948\t\tSym: 0.000000\t\tSpars: 0.000647\n",
      "\t TVw: 0.770958 | TVb: 2.281116 | GSw: -0.461055 | GSb: -0.135340 | TSUw: -0.431572 | TSUb: -0.037374\n",
      "Validating epoch 5886...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01292365780927535\n",
      "Average validation loss: 0.01342848320513777\n",
      "Training epoch 5887...\n",
      "\n",
      "Train Epoch: 5887 [0/8000 (0%)]\tBatch Loss: 0.013390\tLearning Rate (w_theta): 0.001000\t TIME:3174.5s\n",
      "\t\t\t\tDisc: 0.012517\t\tSym: 0.000000\t\tSpars: 0.000873\n",
      "\t TVw: 0.771115 | TVb: 2.281127 | GSw: -0.460737 | GSb: -0.135063 | TSUw: -0.430819 | TSUb: -0.036614\n",
      "\n",
      "Train Epoch: 5887 [4000/8000 (50%)]\tBatch Loss: 0.012714\tLearning Rate (w_theta): 0.001000\t TIME:3175.7s\n",
      "\t\t\t\tDisc: 0.012087\t\tSym: 0.000000\t\tSpars: 0.000626\n",
      "\t TVw: 0.771667 | TVb: 2.281512 | GSw: -0.460944 | GSb: -0.135378 | TSUw: -0.431777 | TSUb: -0.037568\n",
      "Validating epoch 5887...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012923561708732935\n",
      "Average validation loss: 0.0134313525443261\n",
      "Training epoch 5888...\n",
      "\n",
      "Train Epoch: 5888 [0/8000 (0%)]\tBatch Loss: 0.012533\tLearning Rate (w_theta): 0.001000\t TIME:3178.0s\n",
      "\t\t\t\tDisc: 0.011771\t\tSym: 0.000000\t\tSpars: 0.000761\n",
      "\t TVw: 0.771550 | TVb: 2.281356 | GSw: -0.460764 | GSb: -0.135264 | TSUw: -0.431472 | TSUb: -0.037256\n",
      "\n",
      "Train Epoch: 5888 [4000/8000 (50%)]\tBatch Loss: 0.012051\tLearning Rate (w_theta): 0.001000\t TIME:3179.3s\n",
      "\t\t\t\tDisc: 0.011565\t\tSym: 0.000000\t\tSpars: 0.000486\n",
      "\t TVw: 0.771567 | TVb: 2.281065 | GSw: -0.460452 | GSb: -0.134999 | TSUw: -0.430769 | TSUb: -0.036547\n",
      "Validating epoch 5888...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012920013284333128\n",
      "Average validation loss: 0.01342720522539503\n",
      "Training epoch 5889...\n",
      "\n",
      "Train Epoch: 5889 [0/8000 (0%)]\tBatch Loss: 0.012657\tLearning Rate (w_theta): 0.001000\t TIME:3181.5s\n",
      "\t\t\t\tDisc: 0.011979\t\tSym: 0.000000\t\tSpars: 0.000678\n",
      "\t TVw: 0.771595 | TVb: 2.281199 | GSw: -0.460505 | GSb: -0.135152 | TSUw: -0.431274 | TSUb: -0.037047\n",
      "\n",
      "Train Epoch: 5889 [4000/8000 (50%)]\tBatch Loss: 0.013636\tLearning Rate (w_theta): 0.001000\t TIME:3182.8s\n",
      "\t\t\t\tDisc: 0.012649\t\tSym: 0.000000\t\tSpars: 0.000987\n",
      "\t TVw: 0.771690 | TVb: 2.281496 | GSw: -0.460590 | GSb: -0.135344 | TSUw: -0.431943 | TSUb: -0.037711\n",
      "Validating epoch 5889...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012919986381438013\n",
      "Average validation loss: 0.013429074063315232\n",
      "Training epoch 5890...\n",
      "\n",
      "Train Epoch: 5890 [0/8000 (0%)]\tBatch Loss: 0.012806\tLearning Rate (w_theta): 0.001000\t TIME:3185.0s\n",
      "\t\t\t\tDisc: 0.012127\t\tSym: 0.000000\t\tSpars: 0.000679\n",
      "\t TVw: 0.771648 | TVb: 2.281409 | GSw: -0.460315 | GSb: -0.135127 | TSUw: -0.431332 | TSUb: -0.037094\n",
      "\n",
      "Train Epoch: 5890 [4000/8000 (50%)]\tBatch Loss: 0.012636\tLearning Rate (w_theta): 0.001000\t TIME:3186.2s\n",
      "\t\t\t\tDisc: 0.011809\t\tSym: 0.000000\t\tSpars: 0.000827\n",
      "\t TVw: 0.771291 | TVb: 2.281298 | GSw: -0.460270 | GSb: -0.135176 | TSUw: -0.431529 | TSUb: -0.037285\n",
      "Validating epoch 5890...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012919805698792714\n",
      "Average validation loss: 0.013427692500417279\n",
      "Training epoch 5891...\n",
      "\n",
      "Train Epoch: 5891 [0/8000 (0%)]\tBatch Loss: 0.012685\tLearning Rate (w_theta): 0.001000\t TIME:3189.2s\n",
      "\t\t\t\tDisc: 0.012131\t\tSym: 0.000000\t\tSpars: 0.000554\n",
      "\t TVw: 0.771491 | TVb: 2.281299 | GSw: -0.459990 | GSb: -0.134945 | TSUw: -0.430992 | TSUb: -0.036743\n",
      "\n",
      "Train Epoch: 5891 [4000/8000 (50%)]\tBatch Loss: 0.012858\tLearning Rate (w_theta): 0.001000\t TIME:3190.4s\n",
      "\t\t\t\tDisc: 0.012091\t\tSym: 0.000000\t\tSpars: 0.000767\n",
      "\t TVw: 0.770637 | TVb: 2.280663 | GSw: -0.459807 | GSb: -0.134806 | TSUw: -0.430763 | TSUb: -0.036508\n",
      "Validating epoch 5891...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.0129257892649225\n",
      "Average validation loss: 0.013438050155578658\n",
      "Training epoch 5892...\n",
      "\n",
      "Train Epoch: 5892 [0/8000 (0%)]\tBatch Loss: 0.013433\tLearning Rate (w_theta): 0.001000\t TIME:3192.7s\n",
      "\t\t\t\tDisc: 0.012380\t\tSym: 0.000000\t\tSpars: 0.001053\n",
      "\t TVw: 0.771239 | TVb: 2.281341 | GSw: -0.460153 | GSb: -0.135283 | TSUw: -0.432113 | TSUb: -0.037853\n",
      "\n",
      "Train Epoch: 5892 [4000/8000 (50%)]\tBatch Loss: 0.012818\tLearning Rate (w_theta): 0.001000\t TIME:3194.0s\n",
      "\t\t\t\tDisc: 0.012029\t\tSym: 0.000000\t\tSpars: 0.000788\n",
      "\t TVw: 0.771335 | TVb: 2.281487 | GSw: -0.460055 | GSb: -0.135289 | TSUw: -0.431935 | TSUb: -0.037669\n",
      "Validating epoch 5892...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012923969610966164\n",
      "Average validation loss: 0.013430838903133365\n",
      "Training epoch 5893...\n",
      "\n",
      "Train Epoch: 5893 [0/8000 (0%)]\tBatch Loss: 0.012929\tLearning Rate (w_theta): 0.001000\t TIME:3196.2s\n",
      "\t\t\t\tDisc: 0.012109\t\tSym: 0.000000\t\tSpars: 0.000820\n",
      "\t TVw: 0.771403 | TVb: 2.281364 | GSw: -0.459546 | GSb: -0.134809 | TSUw: -0.430329 | TSUb: -0.036055\n",
      "\n",
      "Train Epoch: 5893 [4000/8000 (50%)]\tBatch Loss: 0.012902\tLearning Rate (w_theta): 0.001000\t TIME:3197.4s\n",
      "\t\t\t\tDisc: 0.011953\t\tSym: 0.000000\t\tSpars: 0.000949\n",
      "\t TVw: 0.771604 | TVb: 2.281777 | GSw: -0.459864 | GSb: -0.135235 | TSUw: -0.431271 | TSUb: -0.036990\n",
      "Validating epoch 5893...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012926333794066672\n",
      "Average validation loss: 0.013437960726562096\n",
      "Training epoch 5894...\n",
      "\n",
      "Train Epoch: 5894 [0/8000 (0%)]\tBatch Loss: 0.012488\tLearning Rate (w_theta): 0.001000\t TIME:3199.7s\n",
      "\t\t\t\tDisc: 0.011840\t\tSym: 0.000000\t\tSpars: 0.000647\n",
      "\t TVw: 0.771579 | TVb: 2.281779 | GSw: -0.460049 | GSb: -0.135510 | TSUw: -0.431935 | TSUb: -0.037648\n",
      "\n",
      "Train Epoch: 5894 [4000/8000 (50%)]\tBatch Loss: 0.013057\tLearning Rate (w_theta): 0.001000\t TIME:3201.0s\n",
      "\t\t\t\tDisc: 0.012435\t\tSym: 0.000000\t\tSpars: 0.000622\n",
      "\t TVw: 0.771352 | TVb: 2.281614 | GSw: -0.459769 | GSb: -0.135285 | TSUw: -0.431144 | TSUb: -0.036850\n",
      "Validating epoch 5894...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012924109296616108\n",
      "Average validation loss: 0.013427049324764488\n",
      "Training epoch 5895...\n",
      "\n",
      "Train Epoch: 5895 [0/8000 (0%)]\tBatch Loss: 0.013748\tLearning Rate (w_theta): 0.001000\t TIME:3203.2s\n",
      "\t\t\t\tDisc: 0.012756\t\tSym: 0.000000\t\tSpars: 0.000992\n",
      "\t TVw: 0.771522 | TVb: 2.281682 | GSw: -0.459796 | GSb: -0.135396 | TSUw: -0.431369 | TSUb: -0.037069\n",
      "\n",
      "Train Epoch: 5895 [4000/8000 (50%)]\tBatch Loss: 0.013083\tLearning Rate (w_theta): 0.001000\t TIME:3204.4s\n",
      "\t\t\t\tDisc: 0.012225\t\tSym: 0.000000\t\tSpars: 0.000858\n",
      "\t TVw: 0.771933 | TVb: 2.281821 | GSw: -0.459832 | GSb: -0.135510 | TSUw: -0.431585 | TSUb: -0.037279\n",
      "Validating epoch 5895...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012924657356687479\n",
      "Average validation loss: 0.013426495040527456\n",
      "Training epoch 5896...\n",
      "\n",
      "Train Epoch: 5896 [0/8000 (0%)]\tBatch Loss: 0.012903\tLearning Rate (w_theta): 0.001000\t TIME:3206.7s\n",
      "\t\t\t\tDisc: 0.012063\t\tSym: 0.000000\t\tSpars: 0.000840\n",
      "\t TVw: 0.771799 | TVb: 2.281620 | GSw: -0.459684 | GSb: -0.135433 | TSUw: -0.431283 | TSUb: -0.036971\n",
      "\n",
      "Train Epoch: 5896 [4000/8000 (50%)]\tBatch Loss: 0.012635\tLearning Rate (w_theta): 0.001000\t TIME:3208.0s\n",
      "\t\t\t\tDisc: 0.011883\t\tSym: 0.000000\t\tSpars: 0.000753\n",
      "\t TVw: 0.771994 | TVb: 2.281909 | GSw: -0.459733 | GSb: -0.135576 | TSUw: -0.431651 | TSUb: -0.037334\n",
      "Validating epoch 5896...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012918338817755622\n",
      "Average validation loss: 0.013426298262845993\n",
      "Training epoch 5897...\n",
      "\n",
      "Train Epoch: 5897 [0/8000 (0%)]\tBatch Loss: 0.013332\tLearning Rate (w_theta): 0.001000\t TIME:3210.2s\n",
      "\t\t\t\tDisc: 0.012372\t\tSym: 0.000000\t\tSpars: 0.000960\n",
      "\t TVw: 0.772241 | TVb: 2.281858 | GSw: -0.459460 | GSb: -0.135353 | TSUw: -0.431083 | TSUb: -0.036760\n",
      "\n",
      "Train Epoch: 5897 [4000/8000 (50%)]\tBatch Loss: 0.012949\tLearning Rate (w_theta): 0.001000\t TIME:3211.5s\n",
      "\t\t\t\tDisc: 0.012219\t\tSym: 0.000000\t\tSpars: 0.000730\n",
      "\t TVw: 0.772015 | TVb: 2.281726 | GSw: -0.459319 | GSb: -0.135297 | TSUw: -0.430970 | TSUb: -0.036643\n",
      "Validating epoch 5897...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012918724795939973\n",
      "Average validation loss: 0.013430483806599289\n",
      "Training epoch 5898...\n",
      "\n",
      "Train Epoch: 5898 [0/8000 (0%)]\tBatch Loss: 0.013055\tLearning Rate (w_theta): 0.001000\t TIME:3213.7s\n",
      "\t\t\t\tDisc: 0.012184\t\tSym: 0.000000\t\tSpars: 0.000870\n",
      "\t TVw: 0.771651 | TVb: 2.281636 | GSw: -0.459459 | GSb: -0.135531 | TSUw: -0.431784 | TSUb: -0.037452\n",
      "\n",
      "Train Epoch: 5898 [4000/8000 (50%)]\tBatch Loss: 0.012509\tLearning Rate (w_theta): 0.001000\t TIME:3215.0s\n",
      "\t\t\t\tDisc: 0.011734\t\tSym: 0.000000\t\tSpars: 0.000775\n",
      "\t TVw: 0.771084 | TVb: 2.281362 | GSw: -0.459250 | GSb: -0.135389 | TSUw: -0.431459 | TSUb: -0.037121\n",
      "Validating epoch 5898...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012920962874328968\n",
      "Average validation loss: 0.013429035800232686\n",
      "Training epoch 5899...\n",
      "\n",
      "Train Epoch: 5899 [0/8000 (0%)]\tBatch Loss: 0.012656\tLearning Rate (w_theta): 0.001000\t TIME:3217.1s\n",
      "\t\t\t\tDisc: 0.011939\t\tSym: 0.000000\t\tSpars: 0.000717\n",
      "\t TVw: 0.770904 | TVb: 2.281164 | GSw: -0.459124 | GSb: -0.135317 | TSUw: -0.431425 | TSUb: -0.037082\n",
      "\n",
      "Train Epoch: 5899 [4000/8000 (50%)]\tBatch Loss: 0.012655\tLearning Rate (w_theta): 0.001000\t TIME:3218.4s\n",
      "\t\t\t\tDisc: 0.011713\t\tSym: 0.000000\t\tSpars: 0.000942\n",
      "\t TVw: 0.770641 | TVb: 2.280895 | GSw: -0.458922 | GSb: -0.135149 | TSUw: -0.431183 | TSUb: -0.036835\n",
      "Validating epoch 5899...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01292074552930377\n",
      "Average validation loss: 0.013433934737808118\n",
      "Training epoch 5900...\n",
      "\n",
      "Train Epoch: 5900 [0/8000 (0%)]\tBatch Loss: 0.013142\tLearning Rate (w_theta): 0.001000\t TIME:3220.6s\n",
      "\t\t\t\tDisc: 0.011946\t\tSym: 0.000000\t\tSpars: 0.001196\n",
      "\t TVw: 0.771271 | TVb: 2.281301 | GSw: -0.459041 | GSb: -0.135365 | TSUw: -0.431928 | TSUb: -0.037576\n",
      "\n",
      "Train Epoch: 5900 [4000/8000 (50%)]\tBatch Loss: 0.012960\tLearning Rate (w_theta): 0.001000\t TIME:3221.9s\n",
      "\t\t\t\tDisc: 0.012096\t\tSym: 0.000000\t\tSpars: 0.000864\n",
      "\t TVw: 0.772288 | TVb: 2.281670 | GSw: -0.458820 | GSb: -0.135206 | TSUw: -0.431513 | TSUb: -0.037156\n",
      "Validating epoch 5900...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012920425563535868\n",
      "Average validation loss: 0.013426134946908492\n",
      "Training epoch 5901...\n",
      "\n",
      "Train Epoch: 5901 [0/8000 (0%)]\tBatch Loss: 0.012453\tLearning Rate (w_theta): 0.001000\t TIME:3224.8s\n",
      "\t\t\t\tDisc: 0.011707\t\tSym: 0.000000\t\tSpars: 0.000746\n",
      "\t TVw: 0.772432 | TVb: 2.281678 | GSw: -0.458586 | GSb: -0.135032 | TSUw: -0.431134 | TSUb: -0.036772\n",
      "\n",
      "Train Epoch: 5901 [4000/8000 (50%)]\tBatch Loss: 0.013114\tLearning Rate (w_theta): 0.001000\t TIME:3226.1s\n",
      "\t\t\t\tDisc: 0.012287\t\tSym: 0.000000\t\tSpars: 0.000827\n",
      "\t TVw: 0.772861 | TVb: 2.281950 | GSw: -0.458664 | GSb: -0.135196 | TSUw: -0.431717 | TSUb: -0.037352\n",
      "Validating epoch 5901...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012921472762740471\n",
      "Average validation loss: 0.013429039002957194\n",
      "Training epoch 5902...\n",
      "\n",
      "Train Epoch: 5902 [0/8000 (0%)]\tBatch Loss: 0.012949\tLearning Rate (w_theta): 0.001000\t TIME:3228.3s\n",
      "\t\t\t\tDisc: 0.012071\t\tSym: 0.000000\t\tSpars: 0.000878\n",
      "\t TVw: 0.772784 | TVb: 2.281868 | GSw: -0.458461 | GSb: -0.135051 | TSUw: -0.431383 | TSUb: -0.037012\n",
      "\n",
      "Train Epoch: 5902 [4000/8000 (50%)]\tBatch Loss: 0.013562\tLearning Rate (w_theta): 0.001000\t TIME:3229.6s\n",
      "\t\t\t\tDisc: 0.012432\t\tSym: 0.000000\t\tSpars: 0.001131\n",
      "\t TVw: 0.772834 | TVb: 2.281889 | GSw: -0.458330 | GSb: -0.135008 | TSUw: -0.431264 | TSUb: -0.036888\n",
      "Validating epoch 5902...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01291618851081039\n",
      "Average validation loss: 0.013426046502429538\n",
      "Training epoch 5903...\n",
      "\n",
      "Train Epoch: 5903 [0/8000 (0%)]\tBatch Loss: 0.012892\tLearning Rate (w_theta): 0.001000\t TIME:3231.8s\n",
      "\t\t\t\tDisc: 0.012192\t\tSym: 0.000000\t\tSpars: 0.000700\n",
      "\t TVw: 0.772435 | TVb: 2.281737 | GSw: -0.458193 | GSb: -0.134935 | TSUw: -0.431213 | TSUb: -0.036833\n",
      "\n",
      "Train Epoch: 5903 [4000/8000 (50%)]\tBatch Loss: 0.012554\tLearning Rate (w_theta): 0.001000\t TIME:3233.0s\n",
      "\t\t\t\tDisc: 0.011714\t\tSym: 0.000000\t\tSpars: 0.000840\n",
      "\t TVw: 0.772831 | TVb: 2.282252 | GSw: -0.458253 | GSb: -0.135059 | TSUw: -0.431771 | TSUb: -0.037387\n",
      "Validating epoch 5903...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012918226789568832\n",
      "Average validation loss: 0.01342654908924552\n",
      "Training epoch 5904...\n",
      "\n",
      "Train Epoch: 5904 [0/8000 (0%)]\tBatch Loss: 0.013252\tLearning Rate (w_theta): 0.001000\t TIME:3235.3s\n",
      "\t\t\t\tDisc: 0.012434\t\tSym: 0.000000\t\tSpars: 0.000819\n",
      "\t TVw: 0.772591 | TVb: 2.282012 | GSw: -0.457983 | GSb: -0.134835 | TSUw: -0.431285 | TSUb: -0.036896\n",
      "\n",
      "Train Epoch: 5904 [4000/8000 (50%)]\tBatch Loss: 0.012896\tLearning Rate (w_theta): 0.001000\t TIME:3236.6s\n",
      "\t\t\t\tDisc: 0.012142\t\tSym: 0.000000\t\tSpars: 0.000754\n",
      "\t TVw: 0.772554 | TVb: 2.281828 | GSw: -0.457822 | GSb: -0.134736 | TSUw: -0.431160 | TSUb: -0.036766\n",
      "Validating epoch 5904...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012917842238743475\n",
      "Average validation loss: 0.013429832003166468\n",
      "Training epoch 5905...\n",
      "\n",
      "Train Epoch: 5905 [0/8000 (0%)]\tBatch Loss: 0.012772\tLearning Rate (w_theta): 0.001000\t TIME:3238.8s\n",
      "\t\t\t\tDisc: 0.011971\t\tSym: 0.000000\t\tSpars: 0.000800\n",
      "\t TVw: 0.772372 | TVb: 2.281826 | GSw: -0.457893 | GSb: -0.134906 | TSUw: -0.431766 | TSUb: -0.037368\n",
      "\n",
      "Train Epoch: 5905 [4000/8000 (50%)]\tBatch Loss: 0.012662\tLearning Rate (w_theta): 0.001000\t TIME:3240.1s\n",
      "\t\t\t\tDisc: 0.012099\t\tSym: 0.000000\t\tSpars: 0.000562\n",
      "\t TVw: 0.772058 | TVb: 2.281442 | GSw: -0.457595 | GSb: -0.134653 | TSUw: -0.431236 | TSUb: -0.036833\n",
      "Validating epoch 5905...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012922793487450273\n",
      "Average validation loss: 0.01342796126080294\n",
      "Training epoch 5906...\n",
      "\n",
      "Train Epoch: 5906 [0/8000 (0%)]\tBatch Loss: 0.012454\tLearning Rate (w_theta): 0.001000\t TIME:3242.4s\n",
      "\t\t\t\tDisc: 0.011610\t\tSym: 0.000000\t\tSpars: 0.000844\n",
      "\t TVw: 0.771743 | TVb: 2.281381 | GSw: -0.457612 | GSb: -0.134763 | TSUw: -0.431594 | TSUb: -0.037186\n",
      "\n",
      "Train Epoch: 5906 [4000/8000 (50%)]\tBatch Loss: 0.012682\tLearning Rate (w_theta): 0.001000\t TIME:3243.7s\n",
      "\t\t\t\tDisc: 0.011918\t\tSym: 0.000000\t\tSpars: 0.000764\n",
      "\t TVw: 0.771763 | TVb: 2.281549 | GSw: -0.457512 | GSb: -0.134717 | TSUw: -0.431536 | TSUb: -0.037123\n",
      "Validating epoch 5906...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012921990806879124\n",
      "Average validation loss: 0.013428414908914693\n",
      "Training epoch 5907...\n",
      "\n",
      "Train Epoch: 5907 [0/8000 (0%)]\tBatch Loss: 0.012612\tLearning Rate (w_theta): 0.001000\t TIME:3245.9s\n",
      "\t\t\t\tDisc: 0.011876\t\tSym: 0.000000\t\tSpars: 0.000736\n",
      "\t TVw: 0.771386 | TVb: 2.281327 | GSw: -0.457328 | GSb: -0.134601 | TSUw: -0.431272 | TSUb: -0.036854\n",
      "\n",
      "Train Epoch: 5907 [4000/8000 (50%)]\tBatch Loss: 0.012665\tLearning Rate (w_theta): 0.001000\t TIME:3247.1s\n",
      "\t\t\t\tDisc: 0.011779\t\tSym: 0.000000\t\tSpars: 0.000886\n",
      "\t TVw: 0.771334 | TVb: 2.281235 | GSw: -0.457212 | GSb: -0.134555 | TSUw: -0.431242 | TSUb: -0.036819\n",
      "Validating epoch 5907...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012919543906321907\n",
      "Average validation loss: 0.013437192342520913\n",
      "Training epoch 5908...\n",
      "\n",
      "Train Epoch: 5908 [0/8000 (0%)]\tBatch Loss: 0.012633\tLearning Rate (w_theta): 0.001000\t TIME:3249.4s\n",
      "\t\t\t\tDisc: 0.011960\t\tSym: 0.000000\t\tSpars: 0.000673\n",
      "\t TVw: 0.771413 | TVb: 2.281360 | GSw: -0.457394 | GSb: -0.134848 | TSUw: -0.432142 | TSUb: -0.037716\n",
      "\n",
      "Train Epoch: 5908 [4000/8000 (50%)]\tBatch Loss: 0.013087\tLearning Rate (w_theta): 0.001000\t TIME:3250.7s\n",
      "\t\t\t\tDisc: 0.012406\t\tSym: 0.000000\t\tSpars: 0.000681\n",
      "\t TVw: 0.771131 | TVb: 2.280965 | GSw: -0.457010 | GSb: -0.134510 | TSUw: -0.431182 | TSUb: -0.036749\n",
      "Validating epoch 5908...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012930523818084322\n",
      "Average validation loss: 0.013429570405007278\n",
      "Training epoch 5909...\n",
      "\n",
      "Train Epoch: 5909 [0/8000 (0%)]\tBatch Loss: 0.012884\tLearning Rate (w_theta): 0.001000\t TIME:3252.8s\n",
      "\t\t\t\tDisc: 0.011890\t\tSym: 0.000000\t\tSpars: 0.000994\n",
      "\t TVw: 0.771571 | TVb: 2.281155 | GSw: -0.456979 | GSb: -0.134559 | TSUw: -0.431212 | TSUb: -0.036774\n",
      "\n",
      "Train Epoch: 5909 [4000/8000 (50%)]\tBatch Loss: 0.012354\tLearning Rate (w_theta): 0.001000\t TIME:3254.1s\n",
      "\t\t\t\tDisc: 0.011776\t\tSym: 0.000000\t\tSpars: 0.000578\n",
      "\t TVw: 0.772140 | TVb: 2.281699 | GSw: -0.457116 | GSb: -0.134805 | TSUw: -0.431732 | TSUb: -0.037290\n",
      "Validating epoch 5909...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012920169006729688\n",
      "Average validation loss: 0.013429055615677907\n",
      "Training epoch 5910...\n",
      "\n",
      "Train Epoch: 5910 [0/8000 (0%)]\tBatch Loss: 0.012917\tLearning Rate (w_theta): 0.001000\t TIME:3256.5s\n",
      "\t\t\t\tDisc: 0.012088\t\tSym: 0.000000\t\tSpars: 0.000829\n",
      "\t TVw: 0.772342 | TVb: 2.281836 | GSw: -0.457026 | GSb: -0.134790 | TSUw: -0.431688 | TSUb: -0.037241\n",
      "\n",
      "Train Epoch: 5910 [4000/8000 (50%)]\tBatch Loss: 0.013328\tLearning Rate (w_theta): 0.001000\t TIME:3257.7s\n",
      "\t\t\t\tDisc: 0.012237\t\tSym: 0.000000\t\tSpars: 0.001092\n",
      "\t TVw: 0.772330 | TVb: 2.281638 | GSw: -0.456848 | GSb: -0.134648 | TSUw: -0.431418 | TSUb: -0.036965\n",
      "Validating epoch 5910...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01291882960857921\n",
      "Average validation loss: 0.013428151904130629\n",
      "Training epoch 5911...\n",
      "\n",
      "Train Epoch: 5911 [0/8000 (0%)]\tBatch Loss: 0.012390\tLearning Rate (w_theta): 0.001000\t TIME:3260.5s\n",
      "\t\t\t\tDisc: 0.011649\t\tSym: 0.000000\t\tSpars: 0.000742\n",
      "\t TVw: 0.772580 | TVb: 2.281912 | GSw: -0.456794 | GSb: -0.134676 | TSUw: -0.431579 | TSUb: -0.037122\n",
      "\n",
      "Train Epoch: 5911 [4000/8000 (50%)]\tBatch Loss: 0.013347\tLearning Rate (w_theta): 0.001000\t TIME:3261.8s\n",
      "\t\t\t\tDisc: 0.012449\t\tSym: 0.000000\t\tSpars: 0.000898\n",
      "\t TVw: 0.771869 | TVb: 2.281665 | GSw: -0.456567 | GSb: -0.134511 | TSUw: -0.431265 | TSUb: -0.036803\n",
      "Validating epoch 5911...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012920384742793958\n",
      "Average validation loss: 0.013432267125353963\n",
      "Training epoch 5912...\n",
      "\n",
      "Train Epoch: 5912 [0/8000 (0%)]\tBatch Loss: 0.012986\tLearning Rate (w_theta): 0.001000\t TIME:3264.1s\n",
      "\t\t\t\tDisc: 0.012059\t\tSym: 0.000000\t\tSpars: 0.000927\n",
      "\t TVw: 0.771978 | TVb: 2.281778 | GSw: -0.456640 | GSb: -0.134678 | TSUw: -0.431796 | TSUb: -0.037329\n",
      "\n",
      "Train Epoch: 5912 [4000/8000 (50%)]\tBatch Loss: 0.013469\tLearning Rate (w_theta): 0.001000\t TIME:3265.3s\n",
      "\t\t\t\tDisc: 0.012537\t\tSym: 0.000000\t\tSpars: 0.000931\n",
      "\t TVw: 0.772446 | TVb: 2.281973 | GSw: -0.456505 | GSb: -0.134612 | TSUw: -0.431729 | TSUb: -0.037258\n",
      "Validating epoch 5912...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012917565291143716\n",
      "Average validation loss: 0.013426490224884251\n",
      "Training epoch 5913...\n",
      "\n",
      "Train Epoch: 5913 [0/8000 (0%)]\tBatch Loss: 0.013077\tLearning Rate (w_theta): 0.001000\t TIME:3267.5s\n",
      "\t\t\t\tDisc: 0.012450\t\tSym: 0.000000\t\tSpars: 0.000627\n",
      "\t TVw: 0.772464 | TVb: 2.281799 | GSw: -0.456166 | GSb: -0.134322 | TSUw: -0.431057 | TSUb: -0.036582\n",
      "\n",
      "Train Epoch: 5913 [4000/8000 (50%)]\tBatch Loss: 0.012930\tLearning Rate (w_theta): 0.001000\t TIME:3268.8s\n",
      "\t\t\t\tDisc: 0.012205\t\tSym: 0.000000\t\tSpars: 0.000725\n",
      "\t TVw: 0.772292 | TVb: 2.281827 | GSw: -0.456184 | GSb: -0.134444 | TSUw: -0.431455 | TSUb: -0.036975\n",
      "Validating epoch 5913...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012920088004878726\n",
      "Average validation loss: 0.013432371817559258\n",
      "Training epoch 5914...\n",
      "\n",
      "Train Epoch: 5914 [0/8000 (0%)]\tBatch Loss: 0.012987\tLearning Rate (w_theta): 0.001000\t TIME:3271.0s\n",
      "\t\t\t\tDisc: 0.012422\t\tSym: 0.000000\t\tSpars: 0.000565\n",
      "\t TVw: 0.771967 | TVb: 2.281663 | GSw: -0.456150 | GSb: -0.134494 | TSUw: -0.431693 | TSUb: -0.037209\n",
      "\n",
      "Train Epoch: 5914 [4000/8000 (50%)]\tBatch Loss: 0.013184\tLearning Rate (w_theta): 0.001000\t TIME:3272.3s\n",
      "\t\t\t\tDisc: 0.012319\t\tSym: 0.000000\t\tSpars: 0.000865\n",
      "\t TVw: 0.771434 | TVb: 2.281310 | GSw: -0.455920 | GSb: -0.134319 | TSUw: -0.431300 | TSUb: -0.036811\n",
      "Validating epoch 5914...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012922753815462837\n",
      "Average validation loss: 0.013434054375689468\n",
      "Training epoch 5915...\n",
      "\n",
      "Train Epoch: 5915 [0/8000 (0%)]\tBatch Loss: 0.012964\tLearning Rate (w_theta): 0.001000\t TIME:3274.5s\n",
      "\t\t\t\tDisc: 0.012296\t\tSym: 0.000000\t\tSpars: 0.000667\n",
      "\t TVw: 0.771573 | TVb: 2.281318 | GSw: -0.456044 | GSb: -0.134548 | TSUw: -0.431990 | TSUb: -0.037496\n",
      "\n",
      "Train Epoch: 5915 [4000/8000 (50%)]\tBatch Loss: 0.013181\tLearning Rate (w_theta): 0.001000\t TIME:3275.8s\n",
      "\t\t\t\tDisc: 0.012366\t\tSym: 0.000000\t\tSpars: 0.000815\n",
      "\t TVw: 0.771734 | TVb: 2.281332 | GSw: -0.455889 | GSb: -0.134455 | TSUw: -0.431843 | TSUb: -0.037346\n",
      "Validating epoch 5915...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012921329306319118\n",
      "Average validation loss: 0.013427985096341993\n",
      "Training epoch 5916...\n",
      "\n",
      "Train Epoch: 5916 [0/8000 (0%)]\tBatch Loss: 0.013150\tLearning Rate (w_theta): 0.001000\t TIME:3278.1s\n",
      "\t\t\t\tDisc: 0.012362\t\tSym: 0.000000\t\tSpars: 0.000788\n",
      "\t TVw: 0.772233 | TVb: 2.281414 | GSw: -0.455550 | GSb: -0.134168 | TSUw: -0.431097 | TSUb: -0.036595\n",
      "\n",
      "Train Epoch: 5916 [4000/8000 (50%)]\tBatch Loss: 0.012452\tLearning Rate (w_theta): 0.001000\t TIME:3279.3s\n",
      "\t\t\t\tDisc: 0.011757\t\tSym: 0.000000\t\tSpars: 0.000695\n",
      "\t TVw: 0.772209 | TVb: 2.281421 | GSw: -0.455598 | GSb: -0.134293 | TSUw: -0.431552 | TSUb: -0.037045\n",
      "Validating epoch 5916...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012921139099703773\n",
      "Average validation loss: 0.013429381187086142\n",
      "Training epoch 5917...\n",
      "\n",
      "Train Epoch: 5917 [0/8000 (0%)]\tBatch Loss: 0.012941\tLearning Rate (w_theta): 0.001000\t TIME:3281.5s\n",
      "\t\t\t\tDisc: 0.012231\t\tSym: 0.000000\t\tSpars: 0.000709\n",
      "\t TVw: 0.772336 | TVb: 2.281624 | GSw: -0.455598 | GSb: -0.134384 | TSUw: -0.431830 | TSUb: -0.037319\n",
      "\n",
      "Train Epoch: 5917 [4000/8000 (50%)]\tBatch Loss: 0.013693\tLearning Rate (w_theta): 0.001000\t TIME:3282.8s\n",
      "\t\t\t\tDisc: 0.012507\t\tSym: 0.000000\t\tSpars: 0.001186\n",
      "\t TVw: 0.771833 | TVb: 2.281173 | GSw: -0.455502 | GSb: -0.134384 | TSUw: -0.431887 | TSUb: -0.037371\n",
      "Validating epoch 5917...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012922198101940344\n",
      "Average validation loss: 0.013430444579124106\n",
      "Training epoch 5918...\n",
      "\n",
      "Train Epoch: 5918 [0/8000 (0%)]\tBatch Loss: 0.013097\tLearning Rate (w_theta): 0.001000\t TIME:3285.1s\n",
      "\t\t\t\tDisc: 0.012093\t\tSym: 0.000000\t\tSpars: 0.001003\n",
      "\t TVw: 0.772080 | TVb: 2.281263 | GSw: -0.455111 | GSb: -0.134042 | TSUw: -0.430951 | TSUb: -0.036430\n",
      "\n",
      "Train Epoch: 5918 [4000/8000 (50%)]\tBatch Loss: 0.012529\tLearning Rate (w_theta): 0.001000\t TIME:3286.3s\n",
      "\t\t\t\tDisc: 0.011626\t\tSym: 0.000000\t\tSpars: 0.000903\n",
      "\t TVw: 0.771853 | TVb: 2.281314 | GSw: -0.455080 | GSb: -0.134081 | TSUw: -0.431059 | TSUb: -0.036533\n",
      "Validating epoch 5918...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012923768120661438\n",
      "Average validation loss: 0.013438462976764657\n",
      "Training epoch 5919...\n",
      "\n",
      "Train Epoch: 5919 [0/8000 (0%)]\tBatch Loss: 0.012449\tLearning Rate (w_theta): 0.001000\t TIME:3288.6s\n",
      "\t\t\t\tDisc: 0.011740\t\tSym: 0.000000\t\tSpars: 0.000710\n",
      "\t TVw: 0.772025 | TVb: 2.281565 | GSw: -0.455390 | GSb: -0.134508 | TSUw: -0.432159 | TSUb: -0.037630\n",
      "\n",
      "Train Epoch: 5919 [4000/8000 (50%)]\tBatch Loss: 0.013053\tLearning Rate (w_theta): 0.001000\t TIME:3289.9s\n",
      "\t\t\t\tDisc: 0.012229\t\tSym: 0.000000\t\tSpars: 0.000825\n",
      "\t TVw: 0.772486 | TVb: 2.281940 | GSw: -0.455126 | GSb: -0.134289 | TSUw: -0.431484 | TSUb: -0.036950\n",
      "Validating epoch 5919...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01292409614282627\n",
      "Average validation loss: 0.013426680128373137\n",
      "Training epoch 5920...\n",
      "\n",
      "Train Epoch: 5920 [0/8000 (0%)]\tBatch Loss: 0.013124\tLearning Rate (w_theta): 0.001000\t TIME:3292.1s\n",
      "\t\t\t\tDisc: 0.012298\t\tSym: 0.000000\t\tSpars: 0.000826\n",
      "\t TVw: 0.772649 | TVb: 2.282062 | GSw: -0.455046 | GSb: -0.134287 | TSUw: -0.431418 | TSUb: -0.036878\n",
      "\n",
      "Train Epoch: 5920 [4000/8000 (50%)]\tBatch Loss: 0.012507\tLearning Rate (w_theta): 0.001000\t TIME:3293.4s\n",
      "\t\t\t\tDisc: 0.011750\t\tSym: 0.000000\t\tSpars: 0.000756\n",
      "\t TVw: 0.772892 | TVb: 2.282228 | GSw: -0.455196 | GSb: -0.134536 | TSUw: -0.432109 | TSUb: -0.037566\n",
      "Validating epoch 5920...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012922287506221595\n",
      "Average validation loss: 0.013429736718910297\n",
      "Training epoch 5921...\n",
      "\n",
      "Train Epoch: 5921 [0/8000 (0%)]\tBatch Loss: 0.012891\tLearning Rate (w_theta): 0.001000\t TIME:3296.2s\n",
      "\t\t\t\tDisc: 0.011955\t\tSym: 0.000000\t\tSpars: 0.000936\n",
      "\t TVw: 0.773095 | TVb: 2.282287 | GSw: -0.454980 | GSb: -0.134387 | TSUw: -0.431642 | TSUb: -0.037093\n",
      "\n",
      "Train Epoch: 5921 [4000/8000 (50%)]\tBatch Loss: 0.013672\tLearning Rate (w_theta): 0.001000\t TIME:3297.5s\n",
      "\t\t\t\tDisc: 0.012670\t\tSym: 0.000000\t\tSpars: 0.001001\n",
      "\t TVw: 0.772949 | TVb: 2.282049 | GSw: -0.454796 | GSb: -0.134276 | TSUw: -0.431359 | TSUb: -0.036804\n",
      "Validating epoch 5921...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012916204019263852\n",
      "Average validation loss: 0.01342753695514258\n",
      "Training epoch 5922...\n",
      "\n",
      "Train Epoch: 5922 [0/8000 (0%)]\tBatch Loss: 0.012944\tLearning Rate (w_theta): 0.001000\t TIME:3299.8s\n",
      "\t\t\t\tDisc: 0.012068\t\tSym: 0.000000\t\tSpars: 0.000875\n",
      "\t TVw: 0.772862 | TVb: 2.281931 | GSw: -0.454656 | GSb: -0.134208 | TSUw: -0.431214 | TSUb: -0.036655\n",
      "\n",
      "Train Epoch: 5922 [4000/8000 (50%)]\tBatch Loss: 0.013565\tLearning Rate (w_theta): 0.001000\t TIME:3301.1s\n",
      "\t\t\t\tDisc: 0.012611\t\tSym: 0.000000\t\tSpars: 0.000954\n",
      "\t TVw: 0.772724 | TVb: 2.282041 | GSw: -0.454631 | GSb: -0.134263 | TSUw: -0.431397 | TSUb: -0.036834\n",
      "Validating epoch 5922...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012917691542328011\n",
      "Average validation loss: 0.013440780363045227\n",
      "Training epoch 5923...\n",
      "\n",
      "Train Epoch: 5923 [0/8000 (0%)]\tBatch Loss: 0.012977\tLearning Rate (w_theta): 0.001000\t TIME:3303.3s\n",
      "\t\t\t\tDisc: 0.012168\t\tSym: 0.000000\t\tSpars: 0.000809\n",
      "\t TVw: 0.772610 | TVb: 2.282045 | GSw: -0.454866 | GSb: -0.134610 | TSUw: -0.432371 | TSUb: -0.037805\n",
      "\n",
      "Train Epoch: 5923 [4000/8000 (50%)]\tBatch Loss: 0.012718\tLearning Rate (w_theta): 0.001000\t TIME:3304.7s\n",
      "\t\t\t\tDisc: 0.011821\t\tSym: 0.000000\t\tSpars: 0.000897\n",
      "\t TVw: 0.771846 | TVb: 2.281202 | GSw: -0.454463 | GSb: -0.134243 | TSUw: -0.431353 | TSUb: -0.036780\n",
      "Validating epoch 5923...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012933157291997972\n",
      "Average validation loss: 0.013431857479256766\n",
      "Training epoch 5924...\n",
      "\n",
      "Train Epoch: 5924 [0/8000 (0%)]\tBatch Loss: 0.012627\tLearning Rate (w_theta): 0.001000\t TIME:3306.9s\n",
      "\t\t\t\tDisc: 0.011949\t\tSym: 0.000000\t\tSpars: 0.000678\n",
      "\t TVw: 0.771653 | TVb: 2.280877 | GSw: -0.454373 | GSb: -0.134229 | TSUw: -0.431123 | TSUb: -0.036544\n",
      "\n",
      "Train Epoch: 5924 [4000/8000 (50%)]\tBatch Loss: 0.012950\tLearning Rate (w_theta): 0.001000\t TIME:3308.2s\n",
      "\t\t\t\tDisc: 0.012175\t\tSym: 0.000000\t\tSpars: 0.000775\n",
      "\t TVw: 0.772567 | TVb: 2.281792 | GSw: -0.454924 | GSb: -0.134948 | TSUw: -0.432618 | TSUb: -0.038035\n",
      "Validating epoch 5924...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012933764452165378\n",
      "Average validation loss: 0.013429764156200752\n",
      "Training epoch 5925...\n",
      "\n",
      "Train Epoch: 5925 [0/8000 (0%)]\tBatch Loss: 0.012721\tLearning Rate (w_theta): 0.001000\t TIME:3310.5s\n",
      "\t\t\t\tDisc: 0.011853\t\tSym: 0.000000\t\tSpars: 0.000868\n",
      "\t TVw: 0.772952 | TVb: 2.281900 | GSw: -0.454553 | GSb: -0.134627 | TSUw: -0.431298 | TSUb: -0.036708\n",
      "\n",
      "Train Epoch: 5925 [4000/8000 (50%)]\tBatch Loss: 0.012565\tLearning Rate (w_theta): 0.001000\t TIME:3311.8s\n",
      "\t\t\t\tDisc: 0.011848\t\tSym: 0.000000\t\tSpars: 0.000716\n",
      "\t TVw: 0.772997 | TVb: 2.282096 | GSw: -0.454598 | GSb: -0.134754 | TSUw: -0.431195 | TSUb: -0.036597\n",
      "Validating epoch 5925...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012923187148190116\n",
      "Average validation loss: 0.013427722259312805\n",
      "Training epoch 5926...\n",
      "\n",
      "Train Epoch: 5926 [0/8000 (0%)]\tBatch Loss: 0.012801\tLearning Rate (w_theta): 0.001000\t TIME:3314.1s\n",
      "\t\t\t\tDisc: 0.012139\t\tSym: 0.000000\t\tSpars: 0.000662\n",
      "\t TVw: 0.772712 | TVb: 2.282022 | GSw: -0.454732 | GSb: -0.134988 | TSUw: -0.431535 | TSUb: -0.036931\n",
      "\n",
      "Train Epoch: 5926 [4000/8000 (50%)]\tBatch Loss: 0.012455\tLearning Rate (w_theta): 0.001000\t TIME:3315.3s\n",
      "\t\t\t\tDisc: 0.011828\t\tSym: 0.000000\t\tSpars: 0.000626\n",
      "\t TVw: 0.772510 | TVb: 2.281931 | GSw: -0.454702 | GSb: -0.135017 | TSUw: -0.431563 | TSUb: -0.036955\n",
      "Validating epoch 5926...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012920264975740739\n",
      "Average validation loss: 0.013438759355153054\n",
      "Training epoch 5927...\n",
      "\n",
      "Train Epoch: 5927 [0/8000 (0%)]\tBatch Loss: 0.013117\tLearning Rate (w_theta): 0.001000\t TIME:3317.6s\n",
      "\t\t\t\tDisc: 0.012495\t\tSym: 0.000000\t\tSpars: 0.000621\n",
      "\t TVw: 0.772411 | TVb: 2.281870 | GSw: -0.454805 | GSb: -0.135209 | TSUw: -0.431974 | TSUb: -0.037361\n",
      "\n",
      "Train Epoch: 5927 [4000/8000 (50%)]\tBatch Loss: 0.012373\tLearning Rate (w_theta): 0.001000\t TIME:3319.0s\n",
      "\t\t\t\tDisc: 0.011589\t\tSym: 0.000000\t\tSpars: 0.000784\n",
      "\t TVw: 0.771955 | TVb: 2.281279 | GSw: -0.454427 | GSb: -0.134864 | TSUw: -0.431071 | TSUb: -0.036452\n",
      "Validating epoch 5927...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012926166603843027\n",
      "Average validation loss: 0.013430073592727782\n",
      "Training epoch 5928...\n",
      "\n",
      "Train Epoch: 5928 [0/8000 (0%)]\tBatch Loss: 0.012642\tLearning Rate (w_theta): 0.001000\t TIME:3321.4s\n",
      "\t\t\t\tDisc: 0.012085\t\tSym: 0.000000\t\tSpars: 0.000558\n",
      "\t TVw: 0.772113 | TVb: 2.281428 | GSw: -0.454599 | GSb: -0.135143 | TSUw: -0.431656 | TSUb: -0.037033\n",
      "\n",
      "Train Epoch: 5928 [4000/8000 (50%)]\tBatch Loss: 0.012730\tLearning Rate (w_theta): 0.001000\t TIME:3322.7s\n",
      "\t\t\t\tDisc: 0.012016\t\tSym: 0.000000\t\tSpars: 0.000714\n",
      "\t TVw: 0.772176 | TVb: 2.281566 | GSw: -0.454599 | GSb: -0.135235 | TSUw: -0.431876 | TSUb: -0.037248\n",
      "Validating epoch 5928...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012919341458011468\n",
      "Average validation loss: 0.013430790721155793\n",
      "Training epoch 5929...\n",
      "\n",
      "Train Epoch: 5929 [0/8000 (0%)]\tBatch Loss: 0.012577\tLearning Rate (w_theta): 0.001000\t TIME:3325.0s\n",
      "\t\t\t\tDisc: 0.011750\t\tSym: 0.000000\t\tSpars: 0.000827\n",
      "\t TVw: 0.772680 | TVb: 2.281896 | GSw: -0.454424 | GSb: -0.135127 | TSUw: -0.431591 | TSUb: -0.036959\n",
      "\n",
      "Train Epoch: 5929 [4000/8000 (50%)]\tBatch Loss: 0.013425\tLearning Rate (w_theta): 0.001000\t TIME:3326.3s\n",
      "\t\t\t\tDisc: 0.012557\t\tSym: 0.000000\t\tSpars: 0.000868\n",
      "\t TVw: 0.772739 | TVb: 2.281925 | GSw: -0.454291 | GSb: -0.135073 | TSUw: -0.431451 | TSUb: -0.036815\n",
      "Validating epoch 5929...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012922107315104544\n",
      "Average validation loss: 0.0134313319816727\n",
      "Training epoch 5930...\n",
      "\n",
      "Train Epoch: 5930 [0/8000 (0%)]\tBatch Loss: 0.012837\tLearning Rate (w_theta): 0.001000\t TIME:3328.6s\n",
      "\t\t\t\tDisc: 0.012059\t\tSym: 0.000000\t\tSpars: 0.000778\n",
      "\t TVw: 0.772798 | TVb: 2.282098 | GSw: -0.454330 | GSb: -0.135194 | TSUw: -0.431772 | TSUb: -0.037132\n",
      "\n",
      "Train Epoch: 5930 [4000/8000 (50%)]\tBatch Loss: 0.013025\tLearning Rate (w_theta): 0.001000\t TIME:3329.9s\n",
      "\t\t\t\tDisc: 0.012359\t\tSym: 0.000000\t\tSpars: 0.000666\n",
      "\t TVw: 0.773217 | TVb: 2.282446 | GSw: -0.454168 | GSb: -0.135085 | TSUw: -0.431564 | TSUb: -0.036919\n",
      "Validating epoch 5930...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012916928657191882\n",
      "Average validation loss: 0.013425748323300925\n",
      "Training epoch 5931...\n",
      "\n",
      "Train Epoch: 5931 [0/8000 (0%)]\tBatch Loss: 0.012583\tLearning Rate (w_theta): 0.001000\t TIME:3333.0s\n",
      "\t\t\t\tDisc: 0.011995\t\tSym: 0.000000\t\tSpars: 0.000588\n",
      "\t TVw: 0.772931 | TVb: 2.282207 | GSw: -0.453937 | GSb: -0.134907 | TSUw: -0.431223 | TSUb: -0.036574\n",
      "\n",
      "Train Epoch: 5931 [4000/8000 (50%)]\tBatch Loss: 0.012396\tLearning Rate (w_theta): 0.001000\t TIME:3334.3s\n",
      "\t\t\t\tDisc: 0.011679\t\tSym: 0.000000\t\tSpars: 0.000717\n",
      "\t TVw: 0.772111 | TVb: 2.281558 | GSw: -0.453963 | GSb: -0.135013 | TSUw: -0.431607 | TSUb: -0.036954\n",
      "Validating epoch 5931...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012919334384116013\n",
      "Average validation loss: 0.013435578608892652\n",
      "Training epoch 5932...\n",
      "\n",
      "Train Epoch: 5932 [0/8000 (0%)]\tBatch Loss: 0.013470\tLearning Rate (w_theta): 0.001000\t TIME:3336.8s\n",
      "\t\t\t\tDisc: 0.012388\t\tSym: 0.000000\t\tSpars: 0.001082\n",
      "\t TVw: 0.772033 | TVb: 2.281530 | GSw: -0.453953 | GSb: -0.135082 | TSUw: -0.431890 | TSUb: -0.037234\n",
      "\n",
      "Train Epoch: 5932 [4000/8000 (50%)]\tBatch Loss: 0.012935\tLearning Rate (w_theta): 0.001000\t TIME:3338.0s\n",
      "\t\t\t\tDisc: 0.012059\t\tSym: 0.000000\t\tSpars: 0.000877\n",
      "\t TVw: 0.772366 | TVb: 2.281441 | GSw: -0.453721 | GSb: -0.134911 | TSUw: -0.431578 | TSUb: -0.036918\n",
      "Validating epoch 5932...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012920178555769149\n",
      "Average validation loss: 0.013428010751400123\n",
      "Training epoch 5933...\n",
      "\n",
      "Train Epoch: 5933 [0/8000 (0%)]\tBatch Loss: 0.012782\tLearning Rate (w_theta): 0.001000\t TIME:3340.2s\n",
      "\t\t\t\tDisc: 0.011869\t\tSym: 0.000000\t\tSpars: 0.000913\n",
      "\t TVw: 0.772745 | TVb: 2.281725 | GSw: -0.453594 | GSb: -0.134867 | TSUw: -0.431527 | TSUb: -0.036863\n",
      "\n",
      "Train Epoch: 5933 [4000/8000 (50%)]\tBatch Loss: 0.013683\tLearning Rate (w_theta): 0.001000\t TIME:3341.5s\n",
      "\t\t\t\tDisc: 0.012453\t\tSym: 0.000000\t\tSpars: 0.001229\n",
      "\t TVw: 0.773116 | TVb: 2.281997 | GSw: -0.453548 | GSb: -0.134897 | TSUw: -0.431721 | TSUb: -0.037054\n",
      "Validating epoch 5933...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012918323922131094\n",
      "Average validation loss: 0.013428331654972963\n",
      "Training epoch 5934...\n",
      "\n",
      "Train Epoch: 5934 [0/8000 (0%)]\tBatch Loss: 0.013040\tLearning Rate (w_theta): 0.001000\t TIME:3343.7s\n",
      "\t\t\t\tDisc: 0.012134\t\tSym: 0.000000\t\tSpars: 0.000906\n",
      "\t TVw: 0.773352 | TVb: 2.282211 | GSw: -0.453414 | GSb: -0.134836 | TSUw: -0.431680 | TSUb: -0.037011\n",
      "\n",
      "Train Epoch: 5934 [4000/8000 (50%)]\tBatch Loss: 0.012555\tLearning Rate (w_theta): 0.001000\t TIME:3345.0s\n",
      "\t\t\t\tDisc: 0.011966\t\tSym: 0.000000\t\tSpars: 0.000589\n",
      "\t TVw: 0.774701 | TVb: 2.283169 | GSw: -0.453359 | GSb: -0.134853 | TSUw: -0.431825 | TSUb: -0.037153\n",
      "Validating epoch 5934...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012916239340498228\n",
      "Average validation loss: 0.013424143301872861\n",
      "Training epoch 5935...\n",
      "\n",
      "Train Epoch: 5935 [0/8000 (0%)]\tBatch Loss: 0.012750\tLearning Rate (w_theta): 0.001000\t TIME:3347.2s\n",
      "\t\t\t\tDisc: 0.011934\t\tSym: 0.000000\t\tSpars: 0.000816\n",
      "\t TVw: 0.774464 | TVb: 2.282923 | GSw: -0.453094 | GSb: -0.134650 | TSUw: -0.431437 | TSUb: -0.036761\n",
      "\n",
      "Train Epoch: 5935 [4000/8000 (50%)]\tBatch Loss: 0.013379\tLearning Rate (w_theta): 0.001000\t TIME:3348.5s\n",
      "\t\t\t\tDisc: 0.012236\t\tSym: 0.000000\t\tSpars: 0.001142\n",
      "\t TVw: 0.773977 | TVb: 2.282366 | GSw: -0.452958 | GSb: -0.134585 | TSUw: -0.431422 | TSUb: -0.036742\n",
      "Validating epoch 5935...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012916642459675314\n",
      "Average validation loss: 0.01342721881578706\n",
      "Training epoch 5936...\n",
      "\n",
      "Train Epoch: 5936 [0/8000 (0%)]\tBatch Loss: 0.012567\tLearning Rate (w_theta): 0.001000\t TIME:3350.7s\n",
      "\t\t\t\tDisc: 0.011965\t\tSym: 0.000000\t\tSpars: 0.000602\n",
      "\t TVw: 0.773398 | TVb: 2.282072 | GSw: -0.452921 | GSb: -0.134614 | TSUw: -0.431673 | TSUb: -0.036989\n",
      "\n",
      "Train Epoch: 5936 [4000/8000 (50%)]\tBatch Loss: 0.012898\tLearning Rate (w_theta): 0.001000\t TIME:3352.0s\n",
      "\t\t\t\tDisc: 0.012245\t\tSym: 0.000000\t\tSpars: 0.000653\n",
      "\t TVw: 0.772984 | TVb: 2.281962 | GSw: -0.452813 | GSb: -0.134571 | TSUw: -0.431739 | TSUb: -0.037051\n",
      "Validating epoch 5936...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01291811234396296\n",
      "Average validation loss: 0.013430905348711365\n",
      "Training epoch 5937...\n",
      "\n",
      "Train Epoch: 5937 [0/8000 (0%)]\tBatch Loss: 0.013088\tLearning Rate (w_theta): 0.001000\t TIME:3354.2s\n",
      "\t\t\t\tDisc: 0.012206\t\tSym: 0.000000\t\tSpars: 0.000882\n",
      "\t TVw: 0.772855 | TVb: 2.281775 | GSw: -0.452710 | GSb: -0.134533 | TSUw: -0.431790 | TSUb: -0.037098\n",
      "\n",
      "Train Epoch: 5937 [4000/8000 (50%)]\tBatch Loss: 0.013265\tLearning Rate (w_theta): 0.001000\t TIME:3355.5s\n",
      "\t\t\t\tDisc: 0.012456\t\tSym: 0.000000\t\tSpars: 0.000809\n",
      "\t TVw: 0.773111 | TVb: 2.281650 | GSw: -0.452500 | GSb: -0.134389 | TSUw: -0.431518 | TSUb: -0.036823\n",
      "Validating epoch 5937...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012921178068456534\n",
      "Average validation loss: 0.01342846704265471\n",
      "Training epoch 5938...\n",
      "\n",
      "Train Epoch: 5938 [0/8000 (0%)]\tBatch Loss: 0.012812\tLearning Rate (w_theta): 0.001000\t TIME:3357.8s\n",
      "\t\t\t\tDisc: 0.011988\t\tSym: 0.000000\t\tSpars: 0.000824\n",
      "\t TVw: 0.772847 | TVb: 2.281492 | GSw: -0.452382 | GSb: -0.134338 | TSUw: -0.431501 | TSUb: -0.036803\n",
      "\n",
      "Train Epoch: 5938 [4000/8000 (50%)]\tBatch Loss: 0.013211\tLearning Rate (w_theta): 0.001000\t TIME:3359.1s\n",
      "\t\t\t\tDisc: 0.012309\t\tSym: 0.000000\t\tSpars: 0.000902\n",
      "\t TVw: 0.772618 | TVb: 2.281594 | GSw: -0.452440 | GSb: -0.134502 | TSUw: -0.431967 | TSUb: -0.037265\n",
      "Validating epoch 5938...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012920461531903038\n",
      "Average validation loss: 0.01343417340176196\n",
      "Training epoch 5939...\n",
      "\n",
      "Train Epoch: 5939 [0/8000 (0%)]\tBatch Loss: 0.012742\tLearning Rate (w_theta): 0.001000\t TIME:3361.3s\n",
      "\t\t\t\tDisc: 0.011971\t\tSym: 0.000000\t\tSpars: 0.000771\n",
      "\t TVw: 0.772321 | TVb: 2.281392 | GSw: -0.452271 | GSb: -0.134390 | TSUw: -0.431818 | TSUb: -0.037111\n",
      "\n",
      "Train Epoch: 5939 [4000/8000 (50%)]\tBatch Loss: 0.012895\tLearning Rate (w_theta): 0.001000\t TIME:3362.5s\n",
      "\t\t\t\tDisc: 0.011743\t\tSym: 0.000000\t\tSpars: 0.001152\n",
      "\t TVw: 0.771778 | TVb: 2.280942 | GSw: -0.451858 | GSb: -0.134012 | TSUw: -0.431023 | TSUb: -0.036312\n",
      "Validating epoch 5939...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012927567664963658\n",
      "Average validation loss: 0.013432778449811042\n",
      "Training epoch 5940...\n",
      "\n",
      "Train Epoch: 5940 [0/8000 (0%)]\tBatch Loss: 0.013025\tLearning Rate (w_theta): 0.001000\t TIME:3364.8s\n",
      "\t\t\t\tDisc: 0.012369\t\tSym: 0.000000\t\tSpars: 0.000656\n",
      "\t TVw: 0.771722 | TVb: 2.281110 | GSw: -0.452209 | GSb: -0.134477 | TSUw: -0.432126 | TSUb: -0.037411\n",
      "\n",
      "Train Epoch: 5940 [4000/8000 (50%)]\tBatch Loss: 0.012783\tLearning Rate (w_theta): 0.001000\t TIME:3366.1s\n",
      "\t\t\t\tDisc: 0.012058\t\tSym: 0.000000\t\tSpars: 0.000726\n",
      "\t TVw: 0.772353 | TVb: 2.281576 | GSw: -0.452229 | GSb: -0.134591 | TSUw: -0.432191 | TSUb: -0.037472\n",
      "Validating epoch 5940...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01292587541807334\n",
      "Average validation loss: 0.013429246028311755\n",
      "Training epoch 5941...\n",
      "\n",
      "Train Epoch: 5941 [0/8000 (0%)]\tBatch Loss: 0.012711\tLearning Rate (w_theta): 0.001000\t TIME:3369.0s\n",
      "\t\t\t\tDisc: 0.012112\t\tSym: 0.000000\t\tSpars: 0.000599\n",
      "\t TVw: 0.772131 | TVb: 2.281334 | GSw: -0.451811 | GSb: -0.134218 | TSUw: -0.431115 | TSUb: -0.036390\n",
      "\n",
      "Train Epoch: 5941 [4000/8000 (50%)]\tBatch Loss: 0.012851\tLearning Rate (w_theta): 0.001000\t TIME:3370.3s\n",
      "\t\t\t\tDisc: 0.012086\t\tSym: 0.000000\t\tSpars: 0.000765\n",
      "\t TVw: 0.771973 | TVb: 2.281220 | GSw: -0.451813 | GSb: -0.134307 | TSUw: -0.431141 | TSUb: -0.036411\n",
      "Validating epoch 5941...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012929091505712613\n",
      "Average validation loss: 0.013448631518400495\n",
      "Training epoch 5942...\n",
      "\n",
      "Train Epoch: 5942 [0/8000 (0%)]\tBatch Loss: 0.012725\tLearning Rate (w_theta): 0.001000\t TIME:3372.5s\n",
      "\t\t\t\tDisc: 0.012009\t\tSym: 0.000000\t\tSpars: 0.000716\n",
      "\t TVw: 0.772187 | TVb: 2.281578 | GSw: -0.452411 | GSb: -0.135061 | TSUw: -0.432646 | TSUb: -0.037912\n",
      "\n",
      "Train Epoch: 5942 [4000/8000 (50%)]\tBatch Loss: 0.013744\tLearning Rate (w_theta): 0.001000\t TIME:3373.8s\n",
      "\t\t\t\tDisc: 0.012795\t\tSym: 0.000000\t\tSpars: 0.000948\n",
      "\t TVw: 0.772798 | TVb: 2.281567 | GSw: -0.452332 | GSb: -0.135065 | TSUw: -0.432268 | TSUb: -0.037527\n",
      "Validating epoch 5942...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012924200328614162\n",
      "Average validation loss: 0.013430467857016074\n",
      "Training epoch 5943...\n",
      "\n",
      "Train Epoch: 5943 [0/8000 (0%)]\tBatch Loss: 0.012456\tLearning Rate (w_theta): 0.001000\t TIME:3376.0s\n",
      "\t\t\t\tDisc: 0.011684\t\tSym: 0.000000\t\tSpars: 0.000773\n",
      "\t TVw: 0.772891 | TVb: 2.281463 | GSw: -0.451764 | GSb: -0.134536 | TSUw: -0.430664 | TSUb: -0.035917\n",
      "\n",
      "Train Epoch: 5943 [4000/8000 (50%)]\tBatch Loss: 0.013240\tLearning Rate (w_theta): 0.001000\t TIME:3377.3s\n",
      "\t\t\t\tDisc: 0.012324\t\tSym: 0.000000\t\tSpars: 0.000916\n",
      "\t TVw: 0.772935 | TVb: 2.281822 | GSw: -0.452027 | GSb: -0.134916 | TSUw: -0.431107 | TSUb: -0.036354\n",
      "Validating epoch 5943...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012931123899617057\n",
      "Average validation loss: 0.013444313326415202\n",
      "Training epoch 5944...\n",
      "\n",
      "Train Epoch: 5944 [0/8000 (0%)]\tBatch Loss: 0.012681\tLearning Rate (w_theta): 0.001000\t TIME:3379.6s\n",
      "\t\t\t\tDisc: 0.011913\t\tSym: 0.000000\t\tSpars: 0.000768\n",
      "\t TVw: 0.772954 | TVb: 2.282326 | GSw: -0.452669 | GSb: -0.135699 | TSUw: -0.432535 | TSUb: -0.037777\n",
      "\n",
      "Train Epoch: 5944 [4000/8000 (50%)]\tBatch Loss: 0.011961\tLearning Rate (w_theta): 0.001000\t TIME:3380.8s\n",
      "\t\t\t\tDisc: 0.011411\t\tSym: 0.000000\t\tSpars: 0.000550\n",
      "\t TVw: 0.772711 | TVb: 2.282070 | GSw: -0.452528 | GSb: -0.135608 | TSUw: -0.431946 | TSUb: -0.037180\n",
      "Validating epoch 5944...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012922655503559798\n",
      "Average validation loss: 0.013428924731529951\n",
      "Training epoch 5945...\n",
      "\n",
      "Train Epoch: 5945 [0/8000 (0%)]\tBatch Loss: 0.013480\tLearning Rate (w_theta): 0.001000\t TIME:3383.1s\n",
      "\t\t\t\tDisc: 0.012332\t\tSym: 0.000000\t\tSpars: 0.001149\n",
      "\t TVw: 0.772747 | TVb: 2.281927 | GSw: -0.452185 | GSb: -0.135323 | TSUw: -0.430956 | TSUb: -0.036185\n",
      "\n",
      "Train Epoch: 5945 [4000/8000 (50%)]\tBatch Loss: 0.012915\tLearning Rate (w_theta): 0.001000\t TIME:3384.4s\n",
      "\t\t\t\tDisc: 0.012012\t\tSym: 0.000000\t\tSpars: 0.000903\n",
      "\t TVw: 0.772635 | TVb: 2.282188 | GSw: -0.452213 | GSb: -0.135430 | TSUw: -0.430965 | TSUb: -0.036189\n",
      "Validating epoch 5945...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012926009910061338\n",
      "Average validation loss: 0.013447173847607668\n",
      "Training epoch 5946...\n",
      "\n",
      "Train Epoch: 5946 [0/8000 (0%)]\tBatch Loss: 0.012981\tLearning Rate (w_theta): 0.001000\t TIME:3386.7s\n",
      "\t\t\t\tDisc: 0.012223\t\tSym: 0.000000\t\tSpars: 0.000758\n",
      "\t TVw: 0.772496 | TVb: 2.282454 | GSw: -0.452964 | GSb: -0.136329 | TSUw: -0.432722 | TSUb: -0.037941\n",
      "\n",
      "Train Epoch: 5946 [4000/8000 (50%)]\tBatch Loss: 0.012899\tLearning Rate (w_theta): 0.001000\t TIME:3387.9s\n",
      "\t\t\t\tDisc: 0.012191\t\tSym: 0.000000\t\tSpars: 0.000708\n",
      "\t TVw: 0.772230 | TVb: 2.281986 | GSw: -0.452688 | GSb: -0.136095 | TSUw: -0.431672 | TSUb: -0.036884\n",
      "Validating epoch 5946...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012933891743433188\n",
      "Average validation loss: 0.013428334095069761\n",
      "Training epoch 5947...\n",
      "\n",
      "Train Epoch: 5947 [0/8000 (0%)]\tBatch Loss: 0.013253\tLearning Rate (w_theta): 0.001000\t TIME:3390.1s\n",
      "\t\t\t\tDisc: 0.012379\t\tSym: 0.000000\t\tSpars: 0.000874\n",
      "\t TVw: 0.772414 | TVb: 2.281959 | GSw: -0.452553 | GSb: -0.136031 | TSUw: -0.431060 | TSUb: -0.036266\n",
      "\n",
      "Train Epoch: 5947 [4000/8000 (50%)]\tBatch Loss: 0.012730\tLearning Rate (w_theta): 0.001000\t TIME:3391.4s\n",
      "\t\t\t\tDisc: 0.011857\t\tSym: 0.000000\t\tSpars: 0.000874\n",
      "\t TVw: 0.772056 | TVb: 2.281760 | GSw: -0.452939 | GSb: -0.136536 | TSUw: -0.431929 | TSUb: -0.037129\n",
      "Validating epoch 5947...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012926559584359775\n",
      "Average validation loss: 0.01344130643828293\n",
      "Training epoch 5948...\n",
      "\n",
      "Train Epoch: 5948 [0/8000 (0%)]\tBatch Loss: 0.012831\tLearning Rate (w_theta): 0.001000\t TIME:3393.7s\n",
      "\t\t\t\tDisc: 0.011953\t\tSym: 0.000000\t\tSpars: 0.000879\n",
      "\t TVw: 0.772286 | TVb: 2.281952 | GSw: -0.453017 | GSb: -0.136713 | TSUw: -0.432010 | TSUb: -0.037205\n",
      "\n",
      "Train Epoch: 5948 [4000/8000 (50%)]\tBatch Loss: 0.013099\tLearning Rate (w_theta): 0.001000\t TIME:3395.0s\n",
      "\t\t\t\tDisc: 0.012347\t\tSym: 0.000000\t\tSpars: 0.000752\n",
      "\t TVw: 0.772138 | TVb: 2.281517 | GSw: -0.452706 | GSb: -0.136453 | TSUw: -0.431150 | TSUb: -0.036339\n",
      "Validating epoch 5948...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012922511815429616\n",
      "Average validation loss: 0.013428540188973671\n",
      "Training epoch 5949...\n",
      "\n",
      "Train Epoch: 5949 [0/8000 (0%)]\tBatch Loss: 0.013174\tLearning Rate (w_theta): 0.001000\t TIME:3397.2s\n",
      "\t\t\t\tDisc: 0.012259\t\tSym: 0.000000\t\tSpars: 0.000915\n",
      "\t TVw: 0.772181 | TVb: 2.281730 | GSw: -0.452787 | GSb: -0.136613 | TSUw: -0.431382 | TSUb: -0.036567\n",
      "\n",
      "Train Epoch: 5949 [4000/8000 (50%)]\tBatch Loss: 0.012744\tLearning Rate (w_theta): 0.001000\t TIME:3398.5s\n",
      "\t\t\t\tDisc: 0.011750\t\tSym: 0.000000\t\tSpars: 0.000994\n",
      "\t TVw: 0.772200 | TVb: 2.281987 | GSw: -0.453029 | GSb: -0.136928 | TSUw: -0.432128 | TSUb: -0.037309\n",
      "Validating epoch 5949...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012920526130110197\n",
      "Average validation loss: 0.0134348959257068\n",
      "Training epoch 5950...\n",
      "\n",
      "Train Epoch: 5950 [0/8000 (0%)]\tBatch Loss: 0.012933\tLearning Rate (w_theta): 0.001000\t TIME:3400.8s\n",
      "\t\t\t\tDisc: 0.011993\t\tSym: 0.000000\t\tSpars: 0.000939\n",
      "\t TVw: 0.772309 | TVb: 2.282066 | GSw: -0.452915 | GSb: -0.136889 | TSUw: -0.431955 | TSUb: -0.037132\n",
      "\n",
      "Train Epoch: 5950 [4000/8000 (50%)]\tBatch Loss: 0.013134\tLearning Rate (w_theta): 0.001000\t TIME:3402.1s\n",
      "\t\t\t\tDisc: 0.012235\t\tSym: 0.000000\t\tSpars: 0.000899\n",
      "\t TVw: 0.772599 | TVb: 2.282007 | GSw: -0.452499 | GSb: -0.136514 | TSUw: -0.431035 | TSUb: -0.036209\n",
      "Validating epoch 5950...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01292256116233714\n",
      "Average validation loss: 0.013427260363587955\n",
      "Training epoch 5951...\n",
      "\n",
      "Train Epoch: 5951 [0/8000 (0%)]\tBatch Loss: 0.012602\tLearning Rate (w_theta): 0.001000\t TIME:3404.9s\n",
      "\t\t\t\tDisc: 0.011768\t\tSym: 0.000000\t\tSpars: 0.000834\n",
      "\t TVw: 0.772524 | TVb: 2.282088 | GSw: -0.452689 | GSb: -0.136801 | TSUw: -0.431637 | TSUb: -0.036807\n",
      "\n",
      "Train Epoch: 5951 [4000/8000 (50%)]\tBatch Loss: 0.012545\tLearning Rate (w_theta): 0.001000\t TIME:3406.1s\n",
      "\t\t\t\tDisc: 0.011793\t\tSym: 0.000000\t\tSpars: 0.000752\n",
      "\t TVw: 0.772089 | TVb: 2.281764 | GSw: -0.452846 | GSb: -0.137054 | TSUw: -0.432181 | TSUb: -0.037347\n",
      "Validating epoch 5951...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012922364529470994\n",
      "Average validation loss: 0.013432865565623118\n",
      "Training epoch 5952...\n",
      "\n",
      "Train Epoch: 5952 [0/8000 (0%)]\tBatch Loss: 0.013478\tLearning Rate (w_theta): 0.001000\t TIME:3408.4s\n",
      "\t\t\t\tDisc: 0.012502\t\tSym: 0.000000\t\tSpars: 0.000975\n",
      "\t TVw: 0.772282 | TVb: 2.281808 | GSw: -0.452541 | GSb: -0.136803 | TSUw: -0.431553 | TSUb: -0.036714\n",
      "\n",
      "Train Epoch: 5952 [4000/8000 (50%)]\tBatch Loss: 0.012756\tLearning Rate (w_theta): 0.001000\t TIME:3409.7s\n",
      "\t\t\t\tDisc: 0.012020\t\tSym: 0.000000\t\tSpars: 0.000736\n",
      "\t TVw: 0.772013 | TVb: 2.281466 | GSw: -0.452283 | GSb: -0.136594 | TSUw: -0.431063 | TSUb: -0.036219\n",
      "Validating epoch 5952...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01292307126587814\n",
      "Average validation loss: 0.013430031111904665\n",
      "Training epoch 5953...\n",
      "\n",
      "Train Epoch: 5953 [0/8000 (0%)]\tBatch Loss: 0.012759\tLearning Rate (w_theta): 0.001000\t TIME:3411.9s\n",
      "\t\t\t\tDisc: 0.011903\t\tSym: 0.000000\t\tSpars: 0.000856\n",
      "\t TVw: 0.772184 | TVb: 2.281692 | GSw: -0.452563 | GSb: -0.136975 | TSUw: -0.431879 | TSUb: -0.037032\n",
      "\n",
      "Train Epoch: 5953 [4000/8000 (50%)]\tBatch Loss: 0.012748\tLearning Rate (w_theta): 0.001000\t TIME:3413.2s\n",
      "\t\t\t\tDisc: 0.012048\t\tSym: 0.000000\t\tSpars: 0.000700\n",
      "\t TVw: 0.772477 | TVb: 2.281814 | GSw: -0.452625 | GSb: -0.137099 | TSUw: -0.432200 | TSUb: -0.037350\n",
      "Validating epoch 5953...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012922966122985687\n",
      "Average validation loss: 0.013428505007701463\n",
      "Training epoch 5954...\n",
      "\n",
      "Train Epoch: 5954 [0/8000 (0%)]\tBatch Loss: 0.013272\tLearning Rate (w_theta): 0.001000\t TIME:3415.5s\n",
      "\t\t\t\tDisc: 0.012153\t\tSym: 0.000000\t\tSpars: 0.001119\n",
      "\t TVw: 0.772333 | TVb: 2.281600 | GSw: -0.452174 | GSb: -0.136669 | TSUw: -0.431215 | TSUb: -0.036360\n",
      "\n",
      "Train Epoch: 5954 [4000/8000 (50%)]\tBatch Loss: 0.012799\tLearning Rate (w_theta): 0.001000\t TIME:3416.8s\n",
      "\t\t\t\tDisc: 0.012248\t\tSym: 0.000000\t\tSpars: 0.000551\n",
      "\t TVw: 0.773045 | TVb: 2.281868 | GSw: -0.452422 | GSb: -0.136999 | TSUw: -0.431880 | TSUb: -0.037022\n",
      "Validating epoch 5954...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012924555492954713\n",
      "Average validation loss: 0.013427418958544993\n",
      "Training epoch 5955...\n",
      "\n",
      "Train Epoch: 5955 [0/8000 (0%)]\tBatch Loss: 0.013496\tLearning Rate (w_theta): 0.001000\t TIME:3419.0s\n",
      "\t\t\t\tDisc: 0.012515\t\tSym: 0.000000\t\tSpars: 0.000981\n",
      "\t TVw: 0.773216 | TVb: 2.281950 | GSw: -0.452147 | GSb: -0.136772 | TSUw: -0.431338 | TSUb: -0.036476\n",
      "\n",
      "Train Epoch: 5955 [4000/8000 (50%)]\tBatch Loss: 0.012427\tLearning Rate (w_theta): 0.001000\t TIME:3420.3s\n",
      "\t\t\t\tDisc: 0.011615\t\tSym: 0.000000\t\tSpars: 0.000812\n",
      "\t TVw: 0.772878 | TVb: 2.281972 | GSw: -0.452059 | GSb: -0.136753 | TSUw: -0.431274 | TSUb: -0.036409\n",
      "Validating epoch 5955...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012920335786055266\n",
      "Average validation loss: 0.0134295482622952\n",
      "Training epoch 5956...\n",
      "\n",
      "Train Epoch: 5956 [0/8000 (0%)]\tBatch Loss: 0.012695\tLearning Rate (w_theta): 0.001000\t TIME:3422.6s\n",
      "\t\t\t\tDisc: 0.011965\t\tSym: 0.000000\t\tSpars: 0.000729\n",
      "\t TVw: 0.772358 | TVb: 2.281880 | GSw: -0.452251 | GSb: -0.137040 | TSUw: -0.431955 | TSUb: -0.037086\n",
      "\n",
      "Train Epoch: 5956 [4000/8000 (50%)]\tBatch Loss: 0.013606\tLearning Rate (w_theta): 0.001000\t TIME:3423.8s\n",
      "\t\t\t\tDisc: 0.012752\t\tSym: 0.000000\t\tSpars: 0.000854\n",
      "\t TVw: 0.771751 | TVb: 2.281183 | GSw: -0.452274 | GSb: -0.137151 | TSUw: -0.432247 | TSUb: -0.037374\n",
      "Validating epoch 5956...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012926348783860325\n",
      "Average validation loss: 0.013430533311369923\n",
      "Training epoch 5957...\n",
      "\n",
      "Train Epoch: 5957 [0/8000 (0%)]\tBatch Loss: 0.012768\tLearning Rate (w_theta): 0.001000\t TIME:3426.0s\n",
      "\t\t\t\tDisc: 0.012042\t\tSym: 0.000000\t\tSpars: 0.000726\n",
      "\t TVw: 0.771501 | TVb: 2.280876 | GSw: -0.451792 | GSb: -0.136700 | TSUw: -0.431148 | TSUb: -0.036270\n",
      "\n",
      "Train Epoch: 5957 [4000/8000 (50%)]\tBatch Loss: 0.013047\tLearning Rate (w_theta): 0.001000\t TIME:3427.3s\n",
      "\t\t\t\tDisc: 0.012374\t\tSym: 0.000000\t\tSpars: 0.000674\n",
      "\t TVw: 0.771708 | TVb: 2.281176 | GSw: -0.452055 | GSb: -0.137051 | TSUw: -0.431809 | TSUb: -0.036927\n",
      "Validating epoch 5957...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012927122165118338\n",
      "Average validation loss: 0.013431662373863217\n",
      "Training epoch 5958...\n",
      "\n",
      "Train Epoch: 5958 [0/8000 (0%)]\tBatch Loss: 0.013139\tLearning Rate (w_theta): 0.001000\t TIME:3429.6s\n",
      "\t\t\t\tDisc: 0.012214\t\tSym: 0.000000\t\tSpars: 0.000924\n",
      "\t TVw: 0.771818 | TVb: 2.281400 | GSw: -0.451996 | GSb: -0.137052 | TSUw: -0.431761 | TSUb: -0.036876\n",
      "\n",
      "Train Epoch: 5958 [4000/8000 (50%)]\tBatch Loss: 0.011968\tLearning Rate (w_theta): 0.001000\t TIME:3430.8s\n",
      "\t\t\t\tDisc: 0.011468\t\tSym: 0.000000\t\tSpars: 0.000500\n",
      "\t TVw: 0.771925 | TVb: 2.281492 | GSw: -0.451842 | GSb: -0.136934 | TSUw: -0.431569 | TSUb: -0.036680\n",
      "Validating epoch 5958...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01292189706257\n",
      "Average validation loss: 0.01342960492557697\n",
      "Training epoch 5959...\n",
      "\n",
      "Train Epoch: 5959 [0/8000 (0%)]\tBatch Loss: 0.012841\tLearning Rate (w_theta): 0.001000\t TIME:3433.1s\n",
      "\t\t\t\tDisc: 0.012205\t\tSym: 0.000000\t\tSpars: 0.000636\n",
      "\t TVw: 0.771773 | TVb: 2.281376 | GSw: -0.451684 | GSb: -0.136837 | TSUw: -0.431411 | TSUb: -0.036518\n",
      "\n",
      "Train Epoch: 5959 [4000/8000 (50%)]\tBatch Loss: 0.012977\tLearning Rate (w_theta): 0.001000\t TIME:3434.3s\n",
      "\t\t\t\tDisc: 0.012096\t\tSym: 0.000000\t\tSpars: 0.000881\n",
      "\t TVw: 0.771654 | TVb: 2.281436 | GSw: -0.451867 | GSb: -0.137125 | TSUw: -0.432113 | TSUb: -0.037218\n",
      "Validating epoch 5959...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012923348119461348\n",
      "Average validation loss: 0.013433870761002385\n",
      "Training epoch 5960...\n",
      "\n",
      "Train Epoch: 5960 [0/8000 (0%)]\tBatch Loss: 0.013384\tLearning Rate (w_theta): 0.001000\t TIME:3436.6s\n",
      "\t\t\t\tDisc: 0.012427\t\tSym: 0.000000\t\tSpars: 0.000957\n",
      "\t TVw: 0.771801 | TVb: 2.281590 | GSw: -0.451677 | GSb: -0.136989 | TSUw: -0.431836 | TSUb: -0.036937\n",
      "\n",
      "Train Epoch: 5960 [4000/8000 (50%)]\tBatch Loss: 0.012786\tLearning Rate (w_theta): 0.001000\t TIME:3437.9s\n",
      "\t\t\t\tDisc: 0.012250\t\tSym: 0.000000\t\tSpars: 0.000536\n",
      "\t TVw: 0.771988 | TVb: 2.281473 | GSw: -0.451294 | GSb: -0.136646 | TSUw: -0.431184 | TSUb: -0.036282\n",
      "Validating epoch 5960...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012923226593819325\n",
      "Average validation loss: 0.013429752896451833\n",
      "Training epoch 5961...\n",
      "\n",
      "Train Epoch: 5961 [0/8000 (0%)]\tBatch Loss: 0.012937\tLearning Rate (w_theta): 0.001000\t TIME:3440.8s\n",
      "\t\t\t\tDisc: 0.011902\t\tSym: 0.000000\t\tSpars: 0.001034\n",
      "\t TVw: 0.771836 | TVb: 2.281590 | GSw: -0.451402 | GSb: -0.136836 | TSUw: -0.431616 | TSUb: -0.036711\n",
      "\n",
      "Train Epoch: 5961 [4000/8000 (50%)]\tBatch Loss: 0.013101\tLearning Rate (w_theta): 0.001000\t TIME:3442.0s\n",
      "\t\t\t\tDisc: 0.012341\t\tSym: 0.000000\t\tSpars: 0.000760\n",
      "\t TVw: 0.772286 | TVb: 2.281801 | GSw: -0.451453 | GSb: -0.136952 | TSUw: -0.431894 | TSUb: -0.036986\n",
      "Validating epoch 5961...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012920874732275621\n",
      "Average validation loss: 0.013431063738221997\n",
      "Training epoch 5962...\n",
      "\n",
      "Train Epoch: 5962 [0/8000 (0%)]\tBatch Loss: 0.013755\tLearning Rate (w_theta): 0.001000\t TIME:3444.3s\n",
      "\t\t\t\tDisc: 0.012943\t\tSym: 0.000000\t\tSpars: 0.000812\n",
      "\t TVw: 0.772410 | TVb: 2.281902 | GSw: -0.451286 | GSb: -0.136839 | TSUw: -0.431710 | TSUb: -0.036798\n",
      "\n",
      "Train Epoch: 5962 [4000/8000 (50%)]\tBatch Loss: 0.013021\tLearning Rate (w_theta): 0.001000\t TIME:3445.6s\n",
      "\t\t\t\tDisc: 0.012098\t\tSym: 0.000000\t\tSpars: 0.000923\n",
      "\t TVw: 0.772686 | TVb: 2.282047 | GSw: -0.451063 | GSb: -0.136659 | TSUw: -0.431391 | TSUb: -0.036476\n",
      "Validating epoch 5962...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01292098577243956\n",
      "Average validation loss: 0.01343083508233856\n",
      "Training epoch 5963...\n",
      "\n",
      "Train Epoch: 5963 [0/8000 (0%)]\tBatch Loss: 0.013079\tLearning Rate (w_theta): 0.001000\t TIME:3447.8s\n",
      "\t\t\t\tDisc: 0.012168\t\tSym: 0.000000\t\tSpars: 0.000910\n",
      "\t TVw: 0.772685 | TVb: 2.282146 | GSw: -0.451203 | GSb: -0.136882 | TSUw: -0.431946 | TSUb: -0.037029\n",
      "\n",
      "Train Epoch: 5963 [4000/8000 (50%)]\tBatch Loss: 0.012793\tLearning Rate (w_theta): 0.001000\t TIME:3449.1s\n",
      "\t\t\t\tDisc: 0.012299\t\tSym: 0.000000\t\tSpars: 0.000495\n",
      "\t TVw: 0.772666 | TVb: 2.282227 | GSw: -0.450975 | GSb: -0.136707 | TSUw: -0.431621 | TSUb: -0.036701\n",
      "Validating epoch 5963...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01292080345525282\n",
      "Average validation loss: 0.013429169631882835\n",
      "Training epoch 5964...\n",
      "\n",
      "Train Epoch: 5964 [0/8000 (0%)]\tBatch Loss: 0.012582\tLearning Rate (w_theta): 0.001000\t TIME:3451.3s\n",
      "\t\t\t\tDisc: 0.011654\t\tSym: 0.000000\t\tSpars: 0.000928\n",
      "\t TVw: 0.772496 | TVb: 2.282185 | GSw: -0.450956 | GSb: -0.136760 | TSUw: -0.431829 | TSUb: -0.036905\n",
      "\n",
      "Train Epoch: 5964 [4000/8000 (50%)]\tBatch Loss: 0.013037\tLearning Rate (w_theta): 0.001000\t TIME:3452.6s\n",
      "\t\t\t\tDisc: 0.012230\t\tSym: 0.000000\t\tSpars: 0.000807\n",
      "\t TVw: 0.772191 | TVb: 2.281658 | GSw: -0.450869 | GSb: -0.136734 | TSUw: -0.431889 | TSUb: -0.036963\n",
      "Validating epoch 5964...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012921099740605776\n",
      "Average validation loss: 0.013429282206949621\n",
      "Training epoch 5965...\n",
      "\n",
      "Train Epoch: 5965 [0/8000 (0%)]\tBatch Loss: 0.013430\tLearning Rate (w_theta): 0.001000\t TIME:3454.8s\n",
      "\t\t\t\tDisc: 0.012499\t\tSym: 0.000000\t\tSpars: 0.000930\n",
      "\t TVw: 0.772342 | TVb: 2.281636 | GSw: -0.450542 | GSb: -0.136441 | TSUw: -0.431350 | TSUb: -0.036420\n",
      "\n",
      "Train Epoch: 5965 [4000/8000 (50%)]\tBatch Loss: 0.012751\tLearning Rate (w_theta): 0.001000\t TIME:3456.0s\n",
      "\t\t\t\tDisc: 0.011910\t\tSym: 0.000000\t\tSpars: 0.000841\n",
      "\t TVw: 0.772671 | TVb: 2.282108 | GSw: -0.450568 | GSb: -0.136544 | TSUw: -0.431603 | TSUb: -0.036670\n",
      "Validating epoch 5965...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012920633441515148\n",
      "Average validation loss: 0.013429809724698472\n",
      "Training epoch 5966...\n",
      "\n",
      "Train Epoch: 5966 [0/8000 (0%)]\tBatch Loss: 0.012411\tLearning Rate (w_theta): 0.001000\t TIME:3458.2s\n",
      "\t\t\t\tDisc: 0.011655\t\tSym: 0.000000\t\tSpars: 0.000756\n",
      "\t TVw: 0.772588 | TVb: 2.281966 | GSw: -0.450521 | GSb: -0.136563 | TSUw: -0.431758 | TSUb: -0.036822\n",
      "\n",
      "Train Epoch: 5966 [4000/8000 (50%)]\tBatch Loss: 0.012751\tLearning Rate (w_theta): 0.001000\t TIME:3459.5s\n",
      "\t\t\t\tDisc: 0.011921\t\tSym: 0.000000\t\tSpars: 0.000829\n",
      "\t TVw: 0.772318 | TVb: 2.281522 | GSw: -0.450270 | GSb: -0.136352 | TSUw: -0.431442 | TSUb: -0.036503\n",
      "Validating epoch 5966...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01292199853493713\n",
      "Average validation loss: 0.013437321607818343\n",
      "Training epoch 5967...\n",
      "\n",
      "Train Epoch: 5967 [0/8000 (0%)]\tBatch Loss: 0.012862\tLearning Rate (w_theta): 0.001000\t TIME:3461.7s\n",
      "\t\t\t\tDisc: 0.012017\t\tSym: 0.000000\t\tSpars: 0.000845\n",
      "\t TVw: 0.772382 | TVb: 2.281696 | GSw: -0.450484 | GSb: -0.136660 | TSUw: -0.432195 | TSUb: -0.037254\n",
      "\n",
      "Train Epoch: 5967 [4000/8000 (50%)]\tBatch Loss: 0.012635\tLearning Rate (w_theta): 0.001000\t TIME:3462.9s\n",
      "\t\t\t\tDisc: 0.011912\t\tSym: 0.000000\t\tSpars: 0.000723\n",
      "\t TVw: 0.772904 | TVb: 2.282058 | GSw: -0.450260 | GSb: -0.136493 | TSUw: -0.431859 | TSUb: -0.036914\n",
      "Validating epoch 5967...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01292105621144543\n",
      "Average validation loss: 0.013427819949051853\n",
      "Training epoch 5968...\n",
      "\n",
      "Train Epoch: 5968 [0/8000 (0%)]\tBatch Loss: 0.012528\tLearning Rate (w_theta): 0.001000\t TIME:3465.3s\n",
      "\t\t\t\tDisc: 0.011769\t\tSym: 0.000000\t\tSpars: 0.000759\n",
      "\t TVw: 0.772884 | TVb: 2.282008 | GSw: -0.449931 | GSb: -0.136208 | TSUw: -0.431326 | TSUb: -0.036378\n",
      "\n",
      "Train Epoch: 5968 [4000/8000 (50%)]\tBatch Loss: 0.012822\tLearning Rate (w_theta): 0.001000\t TIME:3466.6s\n",
      "\t\t\t\tDisc: 0.012118\t\tSym: 0.000000\t\tSpars: 0.000704\n",
      "\t TVw: 0.773348 | TVb: 2.282451 | GSw: -0.450096 | GSb: -0.136459 | TSUw: -0.431946 | TSUb: -0.036995\n",
      "Validating epoch 5968...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012921153023766086\n",
      "Average validation loss: 0.013433231160503632\n",
      "Training epoch 5969...\n",
      "\n",
      "Train Epoch: 5969 [0/8000 (0%)]\tBatch Loss: 0.013164\tLearning Rate (w_theta): 0.001000\t TIME:3468.8s\n",
      "\t\t\t\tDisc: 0.012429\t\tSym: 0.000000\t\tSpars: 0.000735\n",
      "\t TVw: 0.773115 | TVb: 2.282212 | GSw: -0.450002 | GSb: -0.136411 | TSUw: -0.431946 | TSUb: -0.036992\n",
      "\n",
      "Train Epoch: 5969 [4000/8000 (50%)]\tBatch Loss: 0.012802\tLearning Rate (w_theta): 0.001000\t TIME:3470.1s\n",
      "\t\t\t\tDisc: 0.012120\t\tSym: 0.000000\t\tSpars: 0.000682\n",
      "\t TVw: 0.773202 | TVb: 2.282142 | GSw: -0.449757 | GSb: -0.136185 | TSUw: -0.431595 | TSUb: -0.036637\n",
      "Validating epoch 5969...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012918913577578597\n",
      "Average validation loss: 0.013428708129162229\n",
      "Training epoch 5970...\n",
      "\n",
      "Train Epoch: 5970 [0/8000 (0%)]\tBatch Loss: 0.012713\tLearning Rate (w_theta): 0.001000\t TIME:3472.4s\n",
      "\t\t\t\tDisc: 0.012043\t\tSym: 0.000000\t\tSpars: 0.000670\n",
      "\t TVw: 0.772816 | TVb: 2.281926 | GSw: -0.449669 | GSb: -0.136164 | TSUw: -0.431655 | TSUb: -0.036695\n",
      "\n",
      "Train Epoch: 5970 [4000/8000 (50%)]\tBatch Loss: 0.013242\tLearning Rate (w_theta): 0.001000\t TIME:3473.6s\n",
      "\t\t\t\tDisc: 0.012320\t\tSym: 0.000000\t\tSpars: 0.000923\n",
      "\t TVw: 0.772999 | TVb: 2.282090 | GSw: -0.449614 | GSb: -0.136183 | TSUw: -0.431804 | TSUb: -0.036842\n",
      "Validating epoch 5970...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012919562822241801\n",
      "Average validation loss: 0.013429636008557596\n",
      "Training epoch 5971...\n",
      "\n",
      "Train Epoch: 5971 [0/8000 (0%)]\tBatch Loss: 0.013097\tLearning Rate (w_theta): 0.001000\t TIME:3476.5s\n",
      "\t\t\t\tDisc: 0.012199\t\tSym: 0.000000\t\tSpars: 0.000898\n",
      "\t TVw: 0.772920 | TVb: 2.282079 | GSw: -0.449509 | GSb: -0.136147 | TSUw: -0.431829 | TSUb: -0.036863\n",
      "\n",
      "Train Epoch: 5971 [4000/8000 (50%)]\tBatch Loss: 0.013001\tLearning Rate (w_theta): 0.001000\t TIME:3477.8s\n",
      "\t\t\t\tDisc: 0.012168\t\tSym: 0.000000\t\tSpars: 0.000834\n",
      "\t TVw: 0.773226 | TVb: 2.282336 | GSw: -0.449454 | GSb: -0.136157 | TSUw: -0.431972 | TSUb: -0.037004\n",
      "Validating epoch 5971...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012920265586620482\n",
      "Average validation loss: 0.013428497327580727\n",
      "Training epoch 5972...\n",
      "\n",
      "Train Epoch: 5972 [0/8000 (0%)]\tBatch Loss: 0.013175\tLearning Rate (w_theta): 0.001000\t TIME:3480.0s\n",
      "\t\t\t\tDisc: 0.012536\t\tSym: 0.000000\t\tSpars: 0.000639\n",
      "\t TVw: 0.772825 | TVb: 2.281942 | GSw: -0.448999 | GSb: -0.135732 | TSUw: -0.431158 | TSUb: -0.036186\n",
      "\n",
      "Train Epoch: 5972 [4000/8000 (50%)]\tBatch Loss: 0.012940\tLearning Rate (w_theta): 0.001000\t TIME:3481.3s\n",
      "\t\t\t\tDisc: 0.012103\t\tSym: 0.000000\t\tSpars: 0.000837\n",
      "\t TVw: 0.772621 | TVb: 2.281751 | GSw: -0.449102 | GSb: -0.135922 | TSUw: -0.431541 | TSUb: -0.036566\n",
      "Validating epoch 5972...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01292224322643515\n",
      "Average validation loss: 0.013435601323711913\n",
      "Training epoch 5973...\n",
      "\n",
      "Train Epoch: 5973 [0/8000 (0%)]\tBatch Loss: 0.012961\tLearning Rate (w_theta): 0.001000\t TIME:3483.6s\n",
      "\t\t\t\tDisc: 0.012101\t\tSym: 0.000000\t\tSpars: 0.000861\n",
      "\t TVw: 0.772363 | TVb: 2.281655 | GSw: -0.449284 | GSb: -0.136216 | TSUw: -0.432167 | TSUb: -0.037189\n",
      "\n",
      "Train Epoch: 5973 [4000/8000 (50%)]\tBatch Loss: 0.012884\tLearning Rate (w_theta): 0.001000\t TIME:3484.9s\n",
      "\t\t\t\tDisc: 0.011937\t\tSym: 0.000000\t\tSpars: 0.000946\n",
      "\t TVw: 0.772605 | TVb: 2.282022 | GSw: -0.449132 | GSb: -0.136143 | TSUw: -0.431985 | TSUb: -0.037004\n",
      "Validating epoch 5973...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012920888904658038\n",
      "Average validation loss: 0.013429829366150956\n",
      "Training epoch 5974...\n",
      "\n",
      "Train Epoch: 5974 [0/8000 (0%)]\tBatch Loss: 0.012095\tLearning Rate (w_theta): 0.001000\t TIME:3487.1s\n",
      "\t\t\t\tDisc: 0.011547\t\tSym: 0.000000\t\tSpars: 0.000548\n",
      "\t TVw: 0.772045 | TVb: 2.281525 | GSw: -0.448787 | GSb: -0.135843 | TSUw: -0.431441 | TSUb: -0.036456\n",
      "\n",
      "Train Epoch: 5974 [4000/8000 (50%)]\tBatch Loss: 0.012661\tLearning Rate (w_theta): 0.001000\t TIME:3488.4s\n",
      "\t\t\t\tDisc: 0.011862\t\tSym: 0.000000\t\tSpars: 0.000799\n",
      "\t TVw: 0.770979 | TVb: 2.280953 | GSw: -0.448701 | GSb: -0.135818 | TSUw: -0.431499 | TSUb: -0.036510\n",
      "Validating epoch 5974...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012925588670631464\n",
      "Average validation loss: 0.01344232282028305\n",
      "Training epoch 5975...\n",
      "\n",
      "Train Epoch: 5975 [0/8000 (0%)]\tBatch Loss: 0.012724\tLearning Rate (w_theta): 0.001000\t TIME:3490.6s\n",
      "\t\t\t\tDisc: 0.011877\t\tSym: 0.000000\t\tSpars: 0.000847\n",
      "\t TVw: 0.771158 | TVb: 2.281091 | GSw: -0.448969 | GSb: -0.136167 | TSUw: -0.432276 | TSUb: -0.037284\n",
      "\n",
      "Train Epoch: 5975 [4000/8000 (50%)]\tBatch Loss: 0.012595\tLearning Rate (w_theta): 0.001000\t TIME:3491.9s\n",
      "\t\t\t\tDisc: 0.011965\t\tSym: 0.000000\t\tSpars: 0.000630\n",
      "\t TVw: 0.771773 | TVb: 2.281354 | GSw: -0.448705 | GSb: -0.135965 | TSUw: -0.431778 | TSUb: -0.036783\n",
      "Validating epoch 5975...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012924497449719935\n",
      "Average validation loss: 0.013430219446898576\n",
      "Training epoch 5976...\n",
      "\n",
      "Train Epoch: 5976 [0/8000 (0%)]\tBatch Loss: 0.012679\tLearning Rate (w_theta): 0.001000\t TIME:3494.1s\n",
      "\t\t\t\tDisc: 0.012044\t\tSym: 0.000000\t\tSpars: 0.000636\n",
      "\t TVw: 0.772233 | TVb: 2.281599 | GSw: -0.448549 | GSb: -0.135860 | TSUw: -0.431579 | TSUb: -0.036581\n",
      "\n",
      "Train Epoch: 5976 [4000/8000 (50%)]\tBatch Loss: 0.012958\tLearning Rate (w_theta): 0.001000\t TIME:3495.4s\n",
      "\t\t\t\tDisc: 0.012224\t\tSym: 0.000000\t\tSpars: 0.000735\n",
      "\t TVw: 0.772189 | TVb: 2.281332 | GSw: -0.448398 | GSb: -0.135769 | TSUw: -0.431457 | TSUb: -0.036455\n",
      "Validating epoch 5976...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012923278307525534\n",
      "Average validation loss: 0.013440009738389106\n",
      "Training epoch 5977...\n",
      "\n",
      "Train Epoch: 5977 [0/8000 (0%)]\tBatch Loss: 0.012548\tLearning Rate (w_theta): 0.001000\t TIME:3497.6s\n",
      "\t\t\t\tDisc: 0.011698\t\tSym: 0.000000\t\tSpars: 0.000850\n",
      "\t TVw: 0.772214 | TVb: 2.281433 | GSw: -0.448699 | GSb: -0.136174 | TSUw: -0.432346 | TSUb: -0.037342\n",
      "\n",
      "Train Epoch: 5977 [4000/8000 (50%)]\tBatch Loss: 0.012254\tLearning Rate (w_theta): 0.001000\t TIME:3498.9s\n",
      "\t\t\t\tDisc: 0.011584\t\tSym: 0.000000\t\tSpars: 0.000670\n",
      "\t TVw: 0.772536 | TVb: 2.281649 | GSw: -0.448271 | GSb: -0.135772 | TSUw: -0.431473 | TSUb: -0.036464\n",
      "Validating epoch 5977...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012930362649287139\n",
      "Average validation loss: 0.013429970189432846\n",
      "Training epoch 5978...\n",
      "\n",
      "Train Epoch: 5978 [0/8000 (0%)]\tBatch Loss: 0.012554\tLearning Rate (w_theta): 0.001000\t TIME:3501.2s\n",
      "\t\t\t\tDisc: 0.011733\t\tSym: 0.000000\t\tSpars: 0.000821\n",
      "\t TVw: 0.772548 | TVb: 2.281487 | GSw: -0.448285 | GSb: -0.135852 | TSUw: -0.431565 | TSUb: -0.036553\n",
      "\n",
      "Train Epoch: 5978 [4000/8000 (50%)]\tBatch Loss: 0.012729\tLearning Rate (w_theta): 0.001000\t TIME:3502.4s\n",
      "\t\t\t\tDisc: 0.012016\t\tSym: 0.000000\t\tSpars: 0.000713\n",
      "\t TVw: 0.772680 | TVb: 2.281367 | GSw: -0.448353 | GSb: -0.135979 | TSUw: -0.431821 | TSUb: -0.036807\n",
      "Validating epoch 5978...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012920396031843268\n",
      "Average validation loss: 0.013436262841596824\n",
      "Training epoch 5979...\n",
      "\n",
      "Train Epoch: 5979 [0/8000 (0%)]\tBatch Loss: 0.013177\tLearning Rate (w_theta): 0.001000\t TIME:3504.6s\n",
      "\t\t\t\tDisc: 0.012446\t\tSym: 0.000000\t\tSpars: 0.000731\n",
      "\t TVw: 0.772461 | TVb: 2.281245 | GSw: -0.448399 | GSb: -0.136099 | TSUw: -0.432092 | TSUb: -0.037074\n",
      "\n",
      "Train Epoch: 5979 [4000/8000 (50%)]\tBatch Loss: 0.012321\tLearning Rate (w_theta): 0.001000\t TIME:3505.9s\n",
      "\t\t\t\tDisc: 0.011535\t\tSym: 0.000000\t\tSpars: 0.000786\n",
      "\t TVw: 0.772368 | TVb: 2.281209 | GSw: -0.448275 | GSb: -0.136050 | TSUw: -0.432014 | TSUb: -0.036993\n",
      "Validating epoch 5979...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012922869086404198\n",
      "Average validation loss: 0.01343274531742708\n",
      "Training epoch 5980...\n",
      "\n",
      "Train Epoch: 5980 [0/8000 (0%)]\tBatch Loss: 0.013175\tLearning Rate (w_theta): 0.001000\t TIME:3508.2s\n",
      "\t\t\t\tDisc: 0.012141\t\tSym: 0.000000\t\tSpars: 0.001034\n",
      "\t TVw: 0.772773 | TVb: 2.281493 | GSw: -0.448085 | GSb: -0.135913 | TSUw: -0.431771 | TSUb: -0.036747\n",
      "\n",
      "Train Epoch: 5980 [4000/8000 (50%)]\tBatch Loss: 0.013077\tLearning Rate (w_theta): 0.001000\t TIME:3509.4s\n",
      "\t\t\t\tDisc: 0.012131\t\tSym: 0.000000\t\tSpars: 0.000946\n",
      "\t TVw: 0.773146 | TVb: 2.281487 | GSw: -0.447921 | GSb: -0.135775 | TSUw: -0.431596 | TSUb: -0.036569\n",
      "Validating epoch 5980...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012921288384234618\n",
      "Average validation loss: 0.013431232954597673\n",
      "Training epoch 5981...\n",
      "\n",
      "Train Epoch: 5981 [0/8000 (0%)]\tBatch Loss: 0.012737\tLearning Rate (w_theta): 0.001000\t TIME:3512.4s\n",
      "\t\t\t\tDisc: 0.011996\t\tSym: 0.000000\t\tSpars: 0.000741\n",
      "\t TVw: 0.773118 | TVb: 2.281580 | GSw: -0.447943 | GSb: -0.135881 | TSUw: -0.431892 | TSUb: -0.036862\n",
      "\n",
      "Train Epoch: 5981 [4000/8000 (50%)]\tBatch Loss: 0.012887\tLearning Rate (w_theta): 0.001000\t TIME:3513.7s\n",
      "\t\t\t\tDisc: 0.012082\t\tSym: 0.000000\t\tSpars: 0.000805\n",
      "\t TVw: 0.772974 | TVb: 2.281840 | GSw: -0.447739 | GSb: -0.135775 | TSUw: -0.431658 | TSUb: -0.036625\n",
      "Validating epoch 5981...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012921284349194661\n",
      "Average validation loss: 0.013434469311162569\n",
      "Training epoch 5982...\n",
      "\n",
      "Train Epoch: 5982 [0/8000 (0%)]\tBatch Loss: 0.012691\tLearning Rate (w_theta): 0.001000\t TIME:3515.9s\n",
      "\t\t\t\tDisc: 0.011911\t\tSym: 0.000000\t\tSpars: 0.000780\n",
      "\t TVw: 0.772810 | TVb: 2.281877 | GSw: -0.447834 | GSb: -0.135957 | TSUw: -0.432129 | TSUb: -0.037093\n",
      "\n",
      "Train Epoch: 5982 [4000/8000 (50%)]\tBatch Loss: 0.013498\tLearning Rate (w_theta): 0.001000\t TIME:3517.1s\n",
      "\t\t\t\tDisc: 0.012436\t\tSym: 0.000000\t\tSpars: 0.001063\n",
      "\t TVw: 0.773171 | TVb: 2.282252 | GSw: -0.447723 | GSb: -0.135912 | TSUw: -0.432111 | TSUb: -0.037073\n",
      "Validating epoch 5982...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012920455905112007\n",
      "Average validation loss: 0.013429430886401196\n",
      "Training epoch 5983...\n",
      "\n",
      "Train Epoch: 5983 [0/8000 (0%)]\tBatch Loss: 0.012776\tLearning Rate (w_theta): 0.001000\t TIME:3519.4s\n",
      "\t\t\t\tDisc: 0.012211\t\tSym: 0.000000\t\tSpars: 0.000565\n",
      "\t TVw: 0.773052 | TVb: 2.281926 | GSw: -0.447359 | GSb: -0.135578 | TSUw: -0.431517 | TSUb: -0.036475\n",
      "\n",
      "Train Epoch: 5983 [4000/8000 (50%)]\tBatch Loss: 0.013097\tLearning Rate (w_theta): 0.001000\t TIME:3520.7s\n",
      "\t\t\t\tDisc: 0.011953\t\tSym: 0.000000\t\tSpars: 0.001144\n",
      "\t TVw: 0.773216 | TVb: 2.282119 | GSw: -0.447354 | GSb: -0.135629 | TSUw: -0.431629 | TSUb: -0.036585\n",
      "Validating epoch 5983...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012924674954165938\n",
      "Average validation loss: 0.013437957400787334\n",
      "Training epoch 5984...\n",
      "\n",
      "Train Epoch: 5984 [0/8000 (0%)]\tBatch Loss: 0.012583\tLearning Rate (w_theta): 0.001000\t TIME:3522.9s\n",
      "\t\t\t\tDisc: 0.011848\t\tSym: 0.000000\t\tSpars: 0.000735\n",
      "\t TVw: 0.773032 | TVb: 2.282120 | GSw: -0.447586 | GSb: -0.135953 | TSUw: -0.432306 | TSUb: -0.037259\n",
      "\n",
      "Train Epoch: 5984 [4000/8000 (50%)]\tBatch Loss: 0.012879\tLearning Rate (w_theta): 0.001000\t TIME:3524.2s\n",
      "\t\t\t\tDisc: 0.012227\t\tSym: 0.000000\t\tSpars: 0.000652\n",
      "\t TVw: 0.772928 | TVb: 2.282093 | GSw: -0.447411 | GSb: -0.135819 | TSUw: -0.432058 | TSUb: -0.037007\n",
      "Validating epoch 5984...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012920690566878652\n",
      "Average validation loss: 0.013430104320209345\n",
      "Training epoch 5985...\n",
      "\n",
      "Train Epoch: 5985 [0/8000 (0%)]\tBatch Loss: 0.013016\tLearning Rate (w_theta): 0.001000\t TIME:3526.4s\n",
      "\t\t\t\tDisc: 0.012145\t\tSym: 0.000000\t\tSpars: 0.000871\n",
      "\t TVw: 0.772778 | TVb: 2.281787 | GSw: -0.447037 | GSb: -0.135475 | TSUw: -0.431367 | TSUb: -0.036313\n",
      "\n",
      "Train Epoch: 5985 [4000/8000 (50%)]\tBatch Loss: 0.012406\tLearning Rate (w_theta): 0.001000\t TIME:3527.8s\n",
      "\t\t\t\tDisc: 0.011541\t\tSym: 0.000000\t\tSpars: 0.000866\n",
      "\t TVw: 0.772984 | TVb: 2.282192 | GSw: -0.447166 | GSb: -0.135652 | TSUw: -0.431766 | TSUb: -0.036708\n",
      "Validating epoch 5985...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012923590959181757\n",
      "Average validation loss: 0.01343025745287192\n",
      "Training epoch 5986...\n",
      "\n",
      "Train Epoch: 5986 [0/8000 (0%)]\tBatch Loss: 0.013201\tLearning Rate (w_theta): 0.001000\t TIME:3530.0s\n",
      "\t\t\t\tDisc: 0.012430\t\tSym: 0.000000\t\tSpars: 0.000771\n",
      "\t TVw: 0.772741 | TVb: 2.282032 | GSw: -0.447149 | GSb: -0.135704 | TSUw: -0.431915 | TSUb: -0.036854\n",
      "\n",
      "Train Epoch: 5986 [4000/8000 (50%)]\tBatch Loss: 0.013055\tLearning Rate (w_theta): 0.001000\t TIME:3531.3s\n",
      "\t\t\t\tDisc: 0.012014\t\tSym: 0.000000\t\tSpars: 0.001041\n",
      "\t TVw: 0.772491 | TVb: 2.281759 | GSw: -0.447074 | GSb: -0.135710 | TSUw: -0.431980 | TSUb: -0.036916\n",
      "Validating epoch 5986...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012921627811680644\n",
      "Average validation loss: 0.013434986859226297\n",
      "Training epoch 5987...\n",
      "\n",
      "Train Epoch: 5987 [0/8000 (0%)]\tBatch Loss: 0.013614\tLearning Rate (w_theta): 0.001000\t TIME:3533.5s\n",
      "\t\t\t\tDisc: 0.012768\t\tSym: 0.000000\t\tSpars: 0.000846\n",
      "\t TVw: 0.772486 | TVb: 2.281649 | GSw: -0.446950 | GSb: -0.135650 | TSUw: -0.431883 | TSUb: -0.036816\n",
      "\n",
      "Train Epoch: 5987 [4000/8000 (50%)]\tBatch Loss: 0.012739\tLearning Rate (w_theta): 0.001000\t TIME:3534.8s\n",
      "\t\t\t\tDisc: 0.011911\t\tSym: 0.000000\t\tSpars: 0.000828\n",
      "\t TVw: 0.772253 | TVb: 2.281253 | GSw: -0.446799 | GSb: -0.135560 | TSUw: -0.431724 | TSUb: -0.036653\n",
      "Validating epoch 5987...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012925671891813813\n",
      "Average validation loss: 0.013437385902991348\n",
      "Training epoch 5988...\n",
      "\n",
      "Train Epoch: 5988 [0/8000 (0%)]\tBatch Loss: 0.012879\tLearning Rate (w_theta): 0.001000\t TIME:3537.1s\n",
      "\t\t\t\tDisc: 0.012091\t\tSym: 0.000000\t\tSpars: 0.000788\n",
      "\t TVw: 0.772409 | TVb: 2.281402 | GSw: -0.446897 | GSb: -0.135728 | TSUw: -0.432105 | TSUb: -0.037031\n",
      "\n",
      "Train Epoch: 5988 [4000/8000 (50%)]\tBatch Loss: 0.012523\tLearning Rate (w_theta): 0.001000\t TIME:3538.3s\n",
      "\t\t\t\tDisc: 0.011603\t\tSym: 0.000000\t\tSpars: 0.000920\n",
      "\t TVw: 0.771735 | TVb: 2.280834 | GSw: -0.446637 | GSb: -0.135508 | TSUw: -0.431705 | TSUb: -0.036628\n",
      "Validating epoch 5988...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012924661585963466\n",
      "Average validation loss: 0.013432948871003804\n",
      "Training epoch 5989...\n",
      "\n",
      "Train Epoch: 5989 [0/8000 (0%)]\tBatch Loss: 0.013267\tLearning Rate (w_theta): 0.001000\t TIME:3540.5s\n",
      "\t\t\t\tDisc: 0.012502\t\tSym: 0.000000\t\tSpars: 0.000766\n",
      "\t TVw: 0.771979 | TVb: 2.281021 | GSw: -0.446586 | GSb: -0.135517 | TSUw: -0.431792 | TSUb: -0.036712\n",
      "\n",
      "Train Epoch: 5989 [4000/8000 (50%)]\tBatch Loss: 0.012978\tLearning Rate (w_theta): 0.001000\t TIME:3541.8s\n",
      "\t\t\t\tDisc: 0.012011\t\tSym: 0.000000\t\tSpars: 0.000967\n",
      "\t TVw: 0.772175 | TVb: 2.281221 | GSw: -0.446513 | GSb: -0.135483 | TSUw: -0.431886 | TSUb: -0.036803\n",
      "Validating epoch 5989...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01292267976435422\n",
      "Average validation loss: 0.013436212253542894\n",
      "Training epoch 5990...\n",
      "\n",
      "Train Epoch: 5990 [0/8000 (0%)]\tBatch Loss: 0.012858\tLearning Rate (w_theta): 0.001000\t TIME:3544.3s\n",
      "\t\t\t\tDisc: 0.011982\t\tSym: 0.000000\t\tSpars: 0.000877\n",
      "\t TVw: 0.772680 | TVb: 2.281568 | GSw: -0.446589 | GSb: -0.135638 | TSUw: -0.432281 | TSUb: -0.037196\n",
      "\n",
      "Train Epoch: 5990 [4000/8000 (50%)]\tBatch Loss: 0.012567\tLearning Rate (w_theta): 0.001000\t TIME:3545.6s\n",
      "\t\t\t\tDisc: 0.011864\t\tSym: 0.000000\t\tSpars: 0.000703\n",
      "\t TVw: 0.772783 | TVb: 2.281529 | GSw: -0.446286 | GSb: -0.135398 | TSUw: -0.431799 | TSUb: -0.036711\n",
      "Validating epoch 5990...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012922950396674493\n",
      "Average validation loss: 0.013430651719297016\n",
      "Training epoch 5991...\n",
      "\n",
      "Train Epoch: 5991 [0/8000 (0%)]\tBatch Loss: 0.012498\tLearning Rate (w_theta): 0.001000\t TIME:3548.6s\n",
      "\t\t\t\tDisc: 0.012045\t\tSym: 0.000000\t\tSpars: 0.000453\n",
      "\t TVw: 0.772746 | TVb: 2.281394 | GSw: -0.446004 | GSb: -0.135153 | TSUw: -0.431384 | TSUb: -0.036293\n",
      "\n",
      "Train Epoch: 5991 [4000/8000 (50%)]\tBatch Loss: 0.013446\tLearning Rate (w_theta): 0.001000\t TIME:3549.9s\n",
      "\t\t\t\tDisc: 0.012364\t\tSym: 0.000000\t\tSpars: 0.001082\n",
      "\t TVw: 0.773026 | TVb: 2.281576 | GSw: -0.446060 | GSb: -0.135286 | TSUw: -0.431632 | TSUb: -0.036538\n",
      "Validating epoch 5991...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012932546925412618\n",
      "Average validation loss: 0.01346078425544997\n",
      "Training epoch 5992...\n",
      "\n",
      "Train Epoch: 5992 [0/8000 (0%)]\tBatch Loss: 0.012442\tLearning Rate (w_theta): 0.001000\t TIME:3552.1s\n",
      "\t\t\t\tDisc: 0.011594\t\tSym: 0.000000\t\tSpars: 0.000848\n",
      "\t TVw: 0.773368 | TVb: 2.282040 | GSw: -0.446716 | GSb: -0.136088 | TSUw: -0.432990 | TSUb: -0.037893\n",
      "\n",
      "Train Epoch: 5992 [4000/8000 (50%)]\tBatch Loss: 0.013308\tLearning Rate (w_theta): 0.001000\t TIME:3553.4s\n",
      "\t\t\t\tDisc: 0.012515\t\tSym: 0.000000\t\tSpars: 0.000793\n",
      "\t TVw: 0.773525 | TVb: 2.281884 | GSw: -0.446408 | GSb: -0.135835 | TSUw: -0.431969 | TSUb: -0.036866\n",
      "Validating epoch 5992...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012929506529782697\n",
      "Average validation loss: 0.013431888047358556\n",
      "Training epoch 5993...\n",
      "\n",
      "Train Epoch: 5993 [0/8000 (0%)]\tBatch Loss: 0.012438\tLearning Rate (w_theta): 0.001000\t TIME:3555.6s\n",
      "\t\t\t\tDisc: 0.011729\t\tSym: 0.000000\t\tSpars: 0.000709\n",
      "\t TVw: 0.773698 | TVb: 2.281914 | GSw: -0.446103 | GSb: -0.135569 | TSUw: -0.431144 | TSUb: -0.036036\n",
      "\n",
      "Train Epoch: 5993 [4000/8000 (50%)]\tBatch Loss: 0.013969\tLearning Rate (w_theta): 0.001000\t TIME:3556.9s\n",
      "\t\t\t\tDisc: 0.012974\t\tSym: 0.000000\t\tSpars: 0.000995\n",
      "\t TVw: 0.772889 | TVb: 2.281487 | GSw: -0.446469 | GSb: -0.136040 | TSUw: -0.431873 | TSUb: -0.036761\n",
      "Validating epoch 5993...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01292603775965854\n",
      "Average validation loss: 0.013446992054486451\n",
      "Training epoch 5994...\n",
      "\n",
      "Train Epoch: 5994 [0/8000 (0%)]\tBatch Loss: 0.012734\tLearning Rate (w_theta): 0.001000\t TIME:3559.2s\n",
      "\t\t\t\tDisc: 0.011965\t\tSym: 0.000000\t\tSpars: 0.000769\n",
      "\t TVw: 0.772961 | TVb: 2.281822 | GSw: -0.446763 | GSb: -0.136449 | TSUw: -0.432432 | TSUb: -0.037315\n",
      "\n",
      "Train Epoch: 5994 [4000/8000 (50%)]\tBatch Loss: 0.013255\tLearning Rate (w_theta): 0.001000\t TIME:3560.5s\n",
      "\t\t\t\tDisc: 0.012425\t\tSym: 0.000000\t\tSpars: 0.000831\n",
      "\t TVw: 0.773546 | TVb: 2.282151 | GSw: -0.446371 | GSb: -0.136076 | TSUw: -0.431461 | TSUb: -0.036340\n",
      "Validating epoch 5994...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012926049024996758\n",
      "Average validation loss: 0.01342821810103715\n",
      "Training epoch 5995...\n",
      "\n",
      "Train Epoch: 5995 [0/8000 (0%)]\tBatch Loss: 0.013056\tLearning Rate (w_theta): 0.001000\t TIME:3562.7s\n",
      "\t\t\t\tDisc: 0.012278\t\tSym: 0.000000\t\tSpars: 0.000779\n",
      "\t TVw: 0.773716 | TVb: 2.282274 | GSw: -0.446495 | GSb: -0.136276 | TSUw: -0.431667 | TSUb: -0.036542\n",
      "\n",
      "Train Epoch: 5995 [4000/8000 (50%)]\tBatch Loss: 0.012567\tLearning Rate (w_theta): 0.001000\t TIME:3564.0s\n",
      "\t\t\t\tDisc: 0.011790\t\tSym: 0.000000\t\tSpars: 0.000777\n",
      "\t TVw: 0.773403 | TVb: 2.282126 | GSw: -0.446583 | GSb: -0.136451 | TSUw: -0.431940 | TSUb: -0.036812\n",
      "Validating epoch 5995...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012919219607553937\n",
      "Average validation loss: 0.013435550422084662\n",
      "Training epoch 5996...\n",
      "\n",
      "Train Epoch: 5996 [0/8000 (0%)]\tBatch Loss: 0.012620\tLearning Rate (w_theta): 0.001000\t TIME:3566.2s\n",
      "\t\t\t\tDisc: 0.011724\t\tSym: 0.000000\t\tSpars: 0.000896\n",
      "\t TVw: 0.773444 | TVb: 2.282243 | GSw: -0.446643 | GSb: -0.136593 | TSUw: -0.432186 | TSUb: -0.037056\n",
      "\n",
      "Train Epoch: 5996 [4000/8000 (50%)]\tBatch Loss: 0.013118\tLearning Rate (w_theta): 0.001000\t TIME:3567.5s\n",
      "\t\t\t\tDisc: 0.012088\t\tSym: 0.000000\t\tSpars: 0.001030\n",
      "\t TVw: 0.772929 | TVb: 2.281649 | GSw: -0.446416 | GSb: -0.136431 | TSUw: -0.431857 | TSUb: -0.036722\n",
      "Validating epoch 5996...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012920410729688862\n",
      "Average validation loss: 0.013430896889925235\n",
      "Training epoch 5997...\n",
      "\n",
      "Train Epoch: 5997 [0/8000 (0%)]\tBatch Loss: 0.013405\tLearning Rate (w_theta): 0.001000\t TIME:3569.7s\n",
      "\t\t\t\tDisc: 0.012377\t\tSym: 0.000000\t\tSpars: 0.001027\n",
      "\t TVw: 0.772946 | TVb: 2.281578 | GSw: -0.446262 | GSb: -0.136321 | TSUw: -0.431706 | TSUb: -0.036569\n",
      "\n",
      "Train Epoch: 5997 [4000/8000 (50%)]\tBatch Loss: 0.012802\tLearning Rate (w_theta): 0.001000\t TIME:3571.0s\n",
      "\t\t\t\tDisc: 0.011969\t\tSym: 0.000000\t\tSpars: 0.000833\n",
      "\t TVw: 0.773107 | TVb: 2.282022 | GSw: -0.446334 | GSb: -0.136471 | TSUw: -0.432015 | TSUb: -0.036876\n",
      "Validating epoch 5997...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012924522789835663\n",
      "Average validation loss: 0.013429846735189032\n",
      "Training epoch 5998...\n",
      "\n",
      "Train Epoch: 5998 [0/8000 (0%)]\tBatch Loss: 0.012553\tLearning Rate (w_theta): 0.001000\t TIME:3573.3s\n",
      "\t\t\t\tDisc: 0.011805\t\tSym: 0.000000\t\tSpars: 0.000748\n",
      "\t TVw: 0.772897 | TVb: 2.281775 | GSw: -0.446044 | GSb: -0.136212 | TSUw: -0.431577 | TSUb: -0.036434\n",
      "\n",
      "Train Epoch: 5998 [4000/8000 (50%)]\tBatch Loss: 0.013011\tLearning Rate (w_theta): 0.001000\t TIME:3574.6s\n",
      "\t\t\t\tDisc: 0.012266\t\tSym: 0.000000\t\tSpars: 0.000745\n",
      "\t TVw: 0.773294 | TVb: 2.282223 | GSw: -0.446297 | GSb: -0.136561 | TSUw: -0.432290 | TSUb: -0.037145\n",
      "Validating epoch 5998...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012924801938979318\n",
      "Average validation loss: 0.013430710814323479\n",
      "Training epoch 5999...\n",
      "\n",
      "Train Epoch: 5999 [0/8000 (0%)]\tBatch Loss: 0.012236\tLearning Rate (w_theta): 0.001000\t TIME:3576.9s\n",
      "\t\t\t\tDisc: 0.011627\t\tSym: 0.000000\t\tSpars: 0.000609\n",
      "\t TVw: 0.772880 | TVb: 2.281723 | GSw: -0.445949 | GSb: -0.136234 | TSUw: -0.431672 | TSUb: -0.036523\n",
      "\n",
      "Train Epoch: 5999 [4000/8000 (50%)]\tBatch Loss: 0.012982\tLearning Rate (w_theta): 0.001000\t TIME:3578.1s\n",
      "\t\t\t\tDisc: 0.012231\t\tSym: 0.000000\t\tSpars: 0.000751\n",
      "\t TVw: 0.772689 | TVb: 2.281441 | GSw: -0.445848 | GSb: -0.136146 | TSUw: -0.431582 | TSUb: -0.036430\n",
      "Validating epoch 5999...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.01292367189216748\n",
      "Average validation loss: 0.013434707628009279\n",
      "Training epoch 6000...\n",
      "\n",
      "Train Epoch: 6000 [0/8000 (0%)]\tBatch Loss: 0.012800\tLearning Rate (w_theta): 0.001000\t TIME:3580.4s\n",
      "\t\t\t\tDisc: 0.011830\t\tSym: 0.000000\t\tSpars: 0.000970\n",
      "\t TVw: 0.773108 | TVb: 2.281919 | GSw: -0.446131 | GSb: -0.136525 | TSUw: -0.432327 | TSUb: -0.037173\n",
      "\n",
      "Train Epoch: 6000 [4000/8000 (50%)]\tBatch Loss: 0.012545\tLearning Rate (w_theta): 0.001000\t TIME:3581.7s\n",
      "\t\t\t\tDisc: 0.011828\t\tSym: 0.000000\t\tSpars: 0.000717\n",
      "\t TVw: 0.773721 | TVb: 2.281976 | GSw: -0.445905 | GSb: -0.136357 | TSUw: -0.431912 | TSUb: -0.036755\n",
      "Validating epoch 6000...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012925487011344924\n",
      "Average validation loss: 0.013431267639717298\n",
      "Training epoch 6001...\n",
      "\n",
      "Train Epoch: 6001 [0/8000 (0%)]\tBatch Loss: 0.012140\tLearning Rate (w_theta): 0.001000\t TIME:3584.6s\n",
      "\t\t\t\tDisc: 0.011480\t\tSym: 0.000000\t\tSpars: 0.000660\n",
      "\t TVw: 0.773373 | TVb: 2.281713 | GSw: -0.445578 | GSb: -0.136084 | TSUw: -0.431279 | TSUb: -0.036118\n",
      "\n",
      "Train Epoch: 6001 [4000/8000 (50%)]\tBatch Loss: 0.012946\tLearning Rate (w_theta): 0.001000\t TIME:3585.9s\n",
      "\t\t\t\tDisc: 0.012277\t\tSym: 0.000000\t\tSpars: 0.000669\n",
      "\t TVw: 0.772364 | TVb: 2.281265 | GSw: -0.445863 | GSb: -0.136450 | TSUw: -0.431970 | TSUb: -0.036805\n",
      "Validating epoch 6001...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012925826006259685\n",
      "Average validation loss: 0.013443309254147382\n",
      "Training epoch 6002...\n",
      "\n",
      "Train Epoch: 6002 [0/8000 (0%)]\tBatch Loss: 0.013381\tLearning Rate (w_theta): 0.001000\t TIME:3588.1s\n",
      "\t\t\t\tDisc: 0.012348\t\tSym: 0.000000\t\tSpars: 0.001032\n",
      "\t TVw: 0.772299 | TVb: 2.281488 | GSw: -0.446020 | GSb: -0.136685 | TSUw: -0.432379 | TSUb: -0.037211\n",
      "\n",
      "Train Epoch: 6002 [4000/8000 (50%)]\tBatch Loss: 0.013330\tLearning Rate (w_theta): 0.001000\t TIME:3589.4s\n",
      "\t\t\t\tDisc: 0.012481\t\tSym: 0.000000\t\tSpars: 0.000849\n",
      "\t TVw: 0.773003 | TVb: 2.281778 | GSw: -0.445585 | GSb: -0.136263 | TSUw: -0.431519 | TSUb: -0.036348\n",
      "Validating epoch 6002...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012924937360752627\n",
      "Average validation loss: 0.013429995873768356\n",
      "Training epoch 6003...\n",
      "\n",
      "Train Epoch: 6003 [0/8000 (0%)]\tBatch Loss: 0.012861\tLearning Rate (w_theta): 0.001000\t TIME:3591.8s\n",
      "\t\t\t\tDisc: 0.012042\t\tSym: 0.000000\t\tSpars: 0.000819\n",
      "\t TVw: 0.773101 | TVb: 2.281803 | GSw: -0.445659 | GSb: -0.136411 | TSUw: -0.431744 | TSUb: -0.036570\n",
      "\n",
      "Train Epoch: 6003 [4000/8000 (50%)]\tBatch Loss: 0.012777\tLearning Rate (w_theta): 0.001000\t TIME:3593.1s\n",
      "\t\t\t\tDisc: 0.012030\t\tSym: 0.000000\t\tSpars: 0.000747\n",
      "\t TVw: 0.773581 | TVb: 2.282114 | GSw: -0.445840 | GSb: -0.136681 | TSUw: -0.432228 | TSUb: -0.037052\n",
      "Validating epoch 6003...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012922303352688696\n",
      "Average validation loss: 0.013430920275459227\n",
      "Training epoch 6004...\n",
      "\n",
      "Train Epoch: 6004 [0/8000 (0%)]\tBatch Loss: 0.012990\tLearning Rate (w_theta): 0.001000\t TIME:3595.4s\n",
      "\t\t\t\tDisc: 0.011986\t\tSym: 0.000000\t\tSpars: 0.001004\n",
      "\t TVw: 0.773686 | TVb: 2.282015 | GSw: -0.445601 | GSb: -0.136497 | TSUw: -0.431813 | TSUb: -0.036634\n",
      "\n",
      "Train Epoch: 6004 [4000/8000 (50%)]\tBatch Loss: 0.013141\tLearning Rate (w_theta): 0.001000\t TIME:3596.7s\n",
      "\t\t\t\tDisc: 0.012317\t\tSym: 0.000000\t\tSpars: 0.000824\n",
      "\t TVw: 0.773922 | TVb: 2.282342 | GSw: -0.445672 | GSb: -0.136656 | TSUw: -0.432064 | TSUb: -0.036882\n",
      "Validating epoch 6004...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012920733926426547\n",
      "Average validation loss: 0.013429271882911707\n",
      "Training epoch 6005...\n",
      "\n",
      "Train Epoch: 6005 [0/8000 (0%)]\tBatch Loss: 0.012799\tLearning Rate (w_theta): 0.001000\t TIME:3598.9s\n",
      "\t\t\t\tDisc: 0.012120\t\tSym: 0.000000\t\tSpars: 0.000679\n",
      "\t TVw: 0.773331 | TVb: 2.281853 | GSw: -0.445343 | GSb: -0.136354 | TSUw: -0.431560 | TSUb: -0.036375\n",
      "\n",
      "Train Epoch: 6005 [4000/8000 (50%)]\tBatch Loss: 0.013170\tLearning Rate (w_theta): 0.001000\t TIME:3600.2s\n",
      "\t\t\t\tDisc: 0.012165\t\tSym: 0.000000\t\tSpars: 0.001005\n",
      "\t TVw: 0.772910 | TVb: 2.281410 | GSw: -0.445339 | GSb: -0.136404 | TSUw: -0.431796 | TSUb: -0.036607\n",
      "Validating epoch 6005...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 0.012924247997926366\n",
      "Average validation loss: 0.013436149285050375\n",
      "Training epoch 6006...\n",
      "\n",
      "Train Epoch: 6006 [0/8000 (0%)]\tBatch Loss: 0.012828\tLearning Rate (w_theta): 0.001000\t TIME:3602.5s\n",
      "\t\t\t\tDisc: 0.012151\t\tSym: 0.000000\t\tSpars: 0.000678\n",
      "\t TVw: 0.772527 | TVb: 2.281277 | GSw: -0.445401 | GSb: -0.136534 | TSUw: -0.432111 | TSUb: -0.036920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\galiger.gergo\\AppData\\Local\\Temp\\ipykernel_18196\\3719546261.py\", line 1, in <module>\n",
      "    solver.train()\n",
      "  File \"C:\\Users\\galiger.gergo\\Desktop\\ecg-denoising\\workspace\\src\\fistanet\\solver.py\", line 235, in train\n",
      "    for batch_idx, (x_in, y_target, x_0) in enumerate(self.data_loader):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 628, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 671, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 61, in fetch\n",
      "    return self.collate_fn(data)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 265, in default_collate\n",
      "    return collate(batch, collate_fn_map=default_collate_fn_map)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 143, in collate\n",
      "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 143, in <listcomp>\n",
      "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 120, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 172, in collate_numpy_array_fn\n",
      "    return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 120, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 163, in collate_tensor_fn\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1543, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1501, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 755, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\ntpath.py\", line 664, in realpath\n",
      "    if _getfinalpathname(spath) == path:\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\galiger.gergo\\AppData\\Local\\Temp\\ipykernel_18196\\3719546261.py\", line 1, in <module>\n",
      "    solver.train()\n",
      "  File \"C:\\Users\\galiger.gergo\\Desktop\\ecg-denoising\\workspace\\src\\fistanet\\solver.py\", line 235, in train\n",
      "    for batch_idx, (x_in, y_target, x_0) in enumerate(self.data_loader):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 628, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 671, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 61, in fetch\n",
      "    return self.collate_fn(data)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 265, in default_collate\n",
      "    return collate(batch, collate_fn_map=default_collate_fn_map)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 143, in collate\n",
      "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 143, in <listcomp>\n",
      "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 120, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 172, in collate_numpy_array_fn\n",
      "    return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 120, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 163, in collate_tensor_fn\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2079, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1543, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1501, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 752, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 721, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 706, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\galiger.gergo\\AppData\\Local\\Temp\\ipykernel_18196\\3719546261.py\", line 1, in <module>\n",
      "    solver.train()\n",
      "  File \"C:\\Users\\galiger.gergo\\Desktop\\ecg-denoising\\workspace\\src\\fistanet\\solver.py\", line 235, in train\n",
      "    for batch_idx, (x_in, y_target, x_0) in enumerate(self.data_loader):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 628, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 671, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 61, in fetch\n",
      "    return self.collate_fn(data)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 265, in default_collate\n",
      "    return collate(batch, collate_fn_map=default_collate_fn_map)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 143, in collate\n",
      "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 143, in <listcomp>\n",
      "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 120, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 172, in collate_numpy_array_fn\n",
      "    return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 120, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 163, in collate_tensor_fn\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2079, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3396, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2079, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1142, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1543, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1501, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 755, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\ntpath.py\", line 647, in realpath\n",
      "    path = _getfinalpathname(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504e485-5480-4fae-a0e1-4382092f3fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a993b5-8bff-4192-8e0a-389d302c2c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2186b40-3acc-4d32-9620-ae8dac4a8731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ecgenv)",
   "language": "python",
   "name": "ecgenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
