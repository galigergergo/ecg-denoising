{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7baaefd-888e-4894-9776-d7291899f1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.fistanet.M5FISTANet import FISTANet\n",
    "from src.fistanet.loader import DataSplit\n",
    "from src.fistanet.solver import Solver\n",
    "from os.path import join as pjoin\n",
    "from torchsummary import summary\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9846d1b1-46fe-471c-b4a9-93e7a8ce0ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data'\n",
    "DATA_FILE_GEN = 'generated/BW_master_10000_2024-04-07-12-43-32.pkl'\n",
    "DATA_FILE_SIGS = 'steinbrinker/testing_data_mvg_avg.npy'\n",
    "DATA_FILE_BW = 'mit-bih/bw'\n",
    "DATA_FILE_GAUSS = 'generated/gaussian_noise.npy'\n",
    "DATA_FILE_BPDN = 'generated/BW_alphas-BPDN_10000_2024-04-07-12-43-32.npy'\n",
    "DICT_FILE_BW = 'steinbrinker/dictionary_BW_real_data.npy'\n",
    "NOISE_TYPE = 'gauss'\n",
    "if NOISE_TYPE == 'bw':\n",
    "    DATA_FILE_NOISE = DATA_FILE_BW\n",
    "elif NOISE_TYPE == 'gauss':\n",
    "    DATA_FILE_NOISE = DATA_FILE_GAUSS\n",
    "DATA_SIZE = 10000\n",
    "BATCH_SIZE = 1000\n",
    "TVT_SPLIT = {\n",
    "    'train': 80,\n",
    "    'valid': 10,\n",
    "    'test': 10\n",
    "}\n",
    "\n",
    "FNET_LAYER_NO = 4\n",
    "FNET_FEATURE_NO = 16\n",
    "LAMBDA_SP_LOSS = 1e2\n",
    "LAMBDA_SYM_LOSS = 1e-1\n",
    "\n",
    "EPOCH_NO = 3000\n",
    "TEST_EPOCH = 10001\n",
    "LR_DEC_AFTER = 10000\n",
    "LR_DEC_EVERY = 10\n",
    "START_EPOCH = 999\n",
    "START_RUN = '2024-04-20-14-42-44'\n",
    "LOG_INTERVAL = 4\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "\n",
    "\n",
    "# DATA_FILE_GEN = 'generated/BW_master_7999-8000_2024-04-07-12-43-32.pkl'\n",
    "# DATA_SIZE = 2\n",
    "# BATCH_SIZE = 1\n",
    "# TVT_SPLIT = {\n",
    "#     'train': 50,\n",
    "#     'valid': 50,\n",
    "#     'test': 0\n",
    "# }\n",
    "# FNET_LAYER_NO = 4\n",
    "# FNET_FEATURE_NO = 16\n",
    "# LEARNING_RATE = 1e-3\n",
    "# LAMBDA_SP_LOSS = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74e188c4-1bdd-43bd-8fad-aa3c615aefbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ldr, val_ldr, tst_ldr = DataSplit(DATA_DIR, NOISE_TYPE, DATA_FILE_GEN, DATA_FILE_SIGS, DATA_FILE_NOISE, DATA_FILE_BPDN, TVT_SPLIT, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45bcd124-d0c4-4140-8607-2ed4ff8a8003",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36276fd7-c4b4-49e2-859c-6d09d87aae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Psi = np.load(pjoin(DATA_DIR, DICT_FILE_BW))\n",
    "Psi = torch.from_numpy(Psi)\n",
    "Psi = Psi.clone().detach().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03f7f9ea-e218-4790-84e8-caf0a10489d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fista_net = FISTANet(FNET_LAYER_NO, FNET_FEATURE_NO)\n",
    "fista_net = fista_net.to(device)# define arguments of fista_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f12c4823-35ea-41b9-97a1-bf6746dc204d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters fista net: 18871\n"
     ]
    }
   ],
   "source": [
    "# summary(fista_net, input_size=(1, 64, 298), device=str(device))\n",
    "print('Total number of parameters fista net:',\n",
    "          sum(p.numel() for p in fista_net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3579c675-faba-4918-bffe-7a3ee0c8afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "if START_EPOCH:\n",
    "    dt = START_RUN\n",
    "args = {\n",
    "    'model_name': 'FISTANet',\n",
    "    'num_epochs': EPOCH_NO,\n",
    "    'lr': LEARNING_RATE,\n",
    "    'data_dir': DATA_DIR,\n",
    "    'save_path': f'./runs/{dt}',\n",
    "    'start_epoch': START_EPOCH,\n",
    "    'start_run': START_RUN,\n",
    "    'multi_gpu': False,\n",
    "    'device': device,\n",
    "    'log_interval': LOG_INTERVAL,\n",
    "    'test_epoch': TEST_EPOCH,\n",
    "    'lr_dec_after': LR_DEC_AFTER,\n",
    "    'lr_dec_every': LR_DEC_EVERY,\n",
    "    'lambda_sp_loss': LAMBDA_SP_LOSS,\n",
    "    'lambda_sym_loss': LAMBDA_SYM_LOSS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37c787d6-372b-4189-b428-133486557995",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Solver(fista_net, Psi, trn_ldr, val_ldr, BATCH_SIZE, args, tst_ldr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dba58ed-bcde-4a91-994f-1b69c8decd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 1000...\n",
      "\n",
      "Train Epoch: 1000 [0/8000 (0%)]\tBatch Loss: 1174.782244\tLearning Rate (w_theta): 0.001000\t TIME:6.6s\n",
      "\t\t\t\tDisc: 1.804112\t\tSym: 21.282454\t\tSpars: 1151.695679\n",
      "\t TVw: -0.531766 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1000 [4000/8000 (50%)]\tBatch Loss: 1232.489828\tLearning Rate (w_theta): 0.001000\t TIME:8.1s\n",
      "\t\t\t\tDisc: 2.106847\t\tSym: 24.725266\t\tSpars: 1205.657715\n",
      "\t TVw: -0.531744 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1000...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1222.9144150249917\n",
      "Average validation loss: 234.96653688042127\n",
      "Training epoch 1001...\n",
      "\n",
      "Train Epoch: 1001 [0/8000 (0%)]\tBatch Loss: 1204.635356\tLearning Rate (w_theta): 0.001000\t TIME:11.0s\n",
      "\t\t\t\tDisc: 1.883180\t\tSym: 23.192606\t\tSpars: 1179.559570\n",
      "\t TVw: -0.531721 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1001 [4000/8000 (50%)]\tBatch Loss: 1184.713866\tLearning Rate (w_theta): 0.001000\t TIME:12.4s\n",
      "\t\t\t\tDisc: 1.922666\t\tSym: 23.053164\t\tSpars: 1159.738037\n",
      "\t TVw: -0.531699 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1001...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1220.7274643808032\n",
      "Average validation loss: 238.41954550711804\n",
      "Training epoch 1002...\n",
      "\n",
      "Train Epoch: 1002 [0/8000 (0%)]\tBatch Loss: 1222.954447\tLearning Rate (w_theta): 0.001000\t TIME:14.7s\n",
      "\t\t\t\tDisc: 2.078911\t\tSym: 25.042772\t\tSpars: 1195.832764\n",
      "\t TVw: -0.531676 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1002 [4000/8000 (50%)]\tBatch Loss: 1187.755384\tLearning Rate (w_theta): 0.001000\t TIME:16.2s\n",
      "\t\t\t\tDisc: 1.801244\t\tSym: 22.031166\t\tSpars: 1163.922974\n",
      "\t TVw: -0.531654 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1002...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1238.275671724341\n",
      "Average validation loss: 232.64250016131209\n",
      "Training epoch 1003...\n",
      "\n",
      "Train Epoch: 1003 [0/8000 (0%)]\tBatch Loss: 1240.451783\tLearning Rate (w_theta): 0.001000\t TIME:18.5s\n",
      "\t\t\t\tDisc: 2.118949\t\tSym: 25.231516\t\tSpars: 1213.101318\n",
      "\t TVw: -0.531632 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1003 [4000/8000 (50%)]\tBatch Loss: 1249.213992\tLearning Rate (w_theta): 0.001000\t TIME:19.9s\n",
      "\t\t\t\tDisc: 2.176345\t\tSym: 25.386280\t\tSpars: 1221.651367\n",
      "\t TVw: -0.531610 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1003...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1226.6399010463438\n",
      "Average validation loss: 231.56430828596257\n",
      "Training epoch 1004...\n",
      "\n",
      "Train Epoch: 1004 [0/8000 (0%)]\tBatch Loss: 1205.305312\tLearning Rate (w_theta): 0.001000\t TIME:22.3s\n",
      "\t\t\t\tDisc: 2.125392\t\tSym: 24.032337\t\tSpars: 1179.147583\n",
      "\t TVw: -0.531587 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1004 [4000/8000 (50%)]\tBatch Loss: 1241.179089\tLearning Rate (w_theta): 0.001000\t TIME:23.7s\n",
      "\t\t\t\tDisc: 2.025548\t\tSym: 24.045387\t\tSpars: 1215.108154\n",
      "\t TVw: -0.531565 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1004...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1224.6686715530766\n",
      "Average validation loss: 237.48492979358355\n",
      "Training epoch 1005...\n",
      "\n",
      "Train Epoch: 1005 [0/8000 (0%)]\tBatch Loss: 1256.827108\tLearning Rate (w_theta): 0.001000\t TIME:26.0s\n",
      "\t\t\t\tDisc: 2.089986\t\tSym: 25.686218\t\tSpars: 1229.050903\n",
      "\t TVw: -0.531542 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1005 [4000/8000 (50%)]\tBatch Loss: 1221.335139\tLearning Rate (w_theta): 0.001000\t TIME:27.5s\n",
      "\t\t\t\tDisc: 2.073642\t\tSym: 25.011253\t\tSpars: 1194.250244\n",
      "\t TVw: -0.531520 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1005...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1228.8145346119877\n",
      "Average validation loss: 237.20213262615368\n",
      "Training epoch 1006...\n",
      "\n",
      "Train Epoch: 1006 [0/8000 (0%)]\tBatch Loss: 1235.013839\tLearning Rate (w_theta): 0.001000\t TIME:29.7s\n",
      "\t\t\t\tDisc: 2.067596\t\tSym: 26.844559\t\tSpars: 1206.101685\n",
      "\t TVw: -0.531497 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1006 [4000/8000 (50%)]\tBatch Loss: 1223.793771\tLearning Rate (w_theta): 0.001000\t TIME:31.2s\n",
      "\t\t\t\tDisc: 2.090966\t\tSym: 25.786911\t\tSpars: 1195.915894\n",
      "\t TVw: -0.531475 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1006...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1226.569778984453\n",
      "Average validation loss: 231.8925843511496\n",
      "Training epoch 1007...\n",
      "\n",
      "Train Epoch: 1007 [0/8000 (0%)]\tBatch Loss: 1234.380372\tLearning Rate (w_theta): 0.001000\t TIME:33.4s\n",
      "\t\t\t\tDisc: 2.063550\t\tSym: 24.610401\t\tSpars: 1207.706421\n",
      "\t TVw: -0.531452 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1007 [4000/8000 (50%)]\tBatch Loss: 1234.588074\tLearning Rate (w_theta): 0.001000\t TIME:34.9s\n",
      "\t\t\t\tDisc: 2.090767\t\tSym: 25.195061\t\tSpars: 1207.302246\n",
      "\t TVw: -0.531430 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1007...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1224.398426920135\n",
      "Average validation loss: 232.80924774991115\n",
      "Training epoch 1008...\n",
      "\n",
      "Train Epoch: 1008 [0/8000 (0%)]\tBatch Loss: 1225.893122\tLearning Rate (w_theta): 0.001000\t TIME:37.1s\n",
      "\t\t\t\tDisc: 1.984265\t\tSym: 24.984663\t\tSpars: 1198.924194\n",
      "\t TVw: -0.531407 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1008 [4000/8000 (50%)]\tBatch Loss: 1180.971201\tLearning Rate (w_theta): 0.001000\t TIME:38.6s\n",
      "\t\t\t\tDisc: 1.811403\t\tSym: 22.798714\t\tSpars: 1156.361084\n",
      "\t TVw: -0.531384 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1008...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1216.4930708686513\n",
      "Average validation loss: 236.88190490185875\n",
      "Training epoch 1009...\n",
      "\n",
      "Train Epoch: 1009 [0/8000 (0%)]\tBatch Loss: 1201.895902\tLearning Rate (w_theta): 0.001000\t TIME:40.9s\n",
      "\t\t\t\tDisc: 1.945947\t\tSym: 22.646244\t\tSpars: 1177.303711\n",
      "\t TVw: -0.531361 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1009 [4000/8000 (50%)]\tBatch Loss: 1229.483368\tLearning Rate (w_theta): 0.001000\t TIME:42.4s\n",
      "\t\t\t\tDisc: 2.179735\t\tSym: 25.843672\t\tSpars: 1201.459961\n",
      "\t TVw: -0.531337 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1009...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1220.0851571029207\n",
      "Average validation loss: 231.9357554714944\n",
      "Training epoch 1010...\n",
      "\n",
      "Train Epoch: 1010 [0/8000 (0%)]\tBatch Loss: 1242.794745\tLearning Rate (w_theta): 0.001000\t TIME:44.6s\n",
      "\t\t\t\tDisc: 2.158011\t\tSym: 25.373062\t\tSpars: 1215.263672\n",
      "\t TVw: -0.531314 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1010 [4000/8000 (50%)]\tBatch Loss: 1180.858257\tLearning Rate (w_theta): 0.001000\t TIME:46.1s\n",
      "\t\t\t\tDisc: 1.918644\t\tSym: 23.472206\t\tSpars: 1155.467407\n",
      "\t TVw: -0.531291 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1010...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1217.046093607082\n",
      "Average validation loss: 234.56152577142527\n",
      "Training epoch 1011...\n",
      "\n",
      "Train Epoch: 1011 [0/8000 (0%)]\tBatch Loss: 1197.669649\tLearning Rate (w_theta): 0.001000\t TIME:49.1s\n",
      "\t\t\t\tDisc: 1.975780\t\tSym: 23.848776\t\tSpars: 1171.845093\n",
      "\t TVw: -0.531267 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1011 [4000/8000 (50%)]\tBatch Loss: 1224.042232\tLearning Rate (w_theta): 0.001000\t TIME:50.6s\n",
      "\t\t\t\tDisc: 2.011985\t\tSym: 23.886692\t\tSpars: 1198.143555\n",
      "\t TVw: -0.531244 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1011...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1215.277304524752\n",
      "Average validation loss: 234.0578268636299\n",
      "Training epoch 1012...\n",
      "\n",
      "Train Epoch: 1012 [0/8000 (0%)]\tBatch Loss: 1187.229177\tLearning Rate (w_theta): 0.001000\t TIME:52.9s\n",
      "\t\t\t\tDisc: 1.807901\t\tSym: 23.061657\t\tSpars: 1162.359619\n",
      "\t TVw: -0.531220 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1012 [4000/8000 (50%)]\tBatch Loss: 1219.502244\tLearning Rate (w_theta): 0.001000\t TIME:54.3s\n",
      "\t\t\t\tDisc: 1.973948\t\tSym: 24.205542\t\tSpars: 1193.322754\n",
      "\t TVw: -0.531196 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1012...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1215.9132028317954\n",
      "Average validation loss: 231.6680970190673\n",
      "Training epoch 1013...\n",
      "\n",
      "Train Epoch: 1013 [0/8000 (0%)]\tBatch Loss: 1250.507920\tLearning Rate (w_theta): 0.001000\t TIME:56.6s\n",
      "\t\t\t\tDisc: 2.036317\t\tSym: 25.738815\t\tSpars: 1222.732788\n",
      "\t TVw: -0.531172 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1013 [4000/8000 (50%)]\tBatch Loss: 1220.016692\tLearning Rate (w_theta): 0.001000\t TIME:58.1s\n",
      "\t\t\t\tDisc: 2.119509\t\tSym: 25.231411\t\tSpars: 1192.665771\n",
      "\t TVw: -0.531149 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1013...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1217.8902153065867\n",
      "Average validation loss: 233.5274684599643\n",
      "Training epoch 1014...\n",
      "\n",
      "Train Epoch: 1014 [0/8000 (0%)]\tBatch Loss: 1213.054849\tLearning Rate (w_theta): 0.001000\t TIME:60.5s\n",
      "\t\t\t\tDisc: 2.061437\t\tSym: 24.739140\t\tSpars: 1186.254272\n",
      "\t TVw: -0.531125 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1014 [4000/8000 (50%)]\tBatch Loss: 1219.692912\tLearning Rate (w_theta): 0.001000\t TIME:62.0s\n",
      "\t\t\t\tDisc: 1.951611\t\tSym: 25.397306\t\tSpars: 1192.343994\n",
      "\t TVw: -0.531101 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1014...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1213.0371439703567\n",
      "Average validation loss: 234.17670107729546\n",
      "Training epoch 1015...\n",
      "\n",
      "Train Epoch: 1015 [0/8000 (0%)]\tBatch Loss: 1217.323040\tLearning Rate (w_theta): 0.001000\t TIME:64.3s\n",
      "\t\t\t\tDisc: 1.964848\t\tSym: 24.759315\t\tSpars: 1190.598877\n",
      "\t TVw: -0.531077 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1015 [4000/8000 (50%)]\tBatch Loss: 1277.672176\tLearning Rate (w_theta): 0.001000\t TIME:65.8s\n",
      "\t\t\t\tDisc: 2.128095\t\tSym: 25.326796\t\tSpars: 1250.217285\n",
      "\t TVw: -0.531053 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1015...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1215.4631784746725\n",
      "Average validation loss: 233.89082780384595\n",
      "Training epoch 1016...\n",
      "\n",
      "Train Epoch: 1016 [0/8000 (0%)]\tBatch Loss: 1220.483061\tLearning Rate (w_theta): 0.001000\t TIME:68.1s\n",
      "\t\t\t\tDisc: 1.879614\t\tSym: 24.096367\t\tSpars: 1194.507080\n",
      "\t TVw: -0.531029 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1016 [4000/8000 (50%)]\tBatch Loss: 1220.384744\tLearning Rate (w_theta): 0.001000\t TIME:69.6s\n",
      "\t\t\t\tDisc: 2.002690\t\tSym: 25.984470\t\tSpars: 1192.397583\n",
      "\t TVw: -0.531005 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1016...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1213.3351495418788\n",
      "Average validation loss: 237.35961516280662\n",
      "Training epoch 1017...\n",
      "\n",
      "Train Epoch: 1017 [0/8000 (0%)]\tBatch Loss: 1194.647166\tLearning Rate (w_theta): 0.001000\t TIME:72.0s\n",
      "\t\t\t\tDisc: 1.960076\t\tSym: 23.440630\t\tSpars: 1169.246460\n",
      "\t TVw: -0.530981 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1017 [4000/8000 (50%)]\tBatch Loss: 1194.316308\tLearning Rate (w_theta): 0.001000\t TIME:73.5s\n",
      "\t\t\t\tDisc: 1.897200\t\tSym: 22.627848\t\tSpars: 1169.791260\n",
      "\t TVw: -0.530956 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1017...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1216.900884612492\n",
      "Average validation loss: 229.87605784347386\n",
      "Training epoch 1018...\n",
      "\n",
      "Train Epoch: 1018 [0/8000 (0%)]\tBatch Loss: 1207.606377\tLearning Rate (w_theta): 0.001000\t TIME:75.7s\n",
      "\t\t\t\tDisc: 1.980464\t\tSym: 23.774351\t\tSpars: 1181.851562\n",
      "\t TVw: -0.530932 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1018 [4000/8000 (50%)]\tBatch Loss: 1184.087565\tLearning Rate (w_theta): 0.001000\t TIME:77.3s\n",
      "\t\t\t\tDisc: 1.844601\t\tSym: 24.198042\t\tSpars: 1158.044922\n",
      "\t TVw: -0.530908 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1018...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1212.6625919959424\n",
      "Average validation loss: 232.10492074207\n",
      "Training epoch 1019...\n",
      "\n",
      "Train Epoch: 1019 [0/8000 (0%)]\tBatch Loss: 1225.622822\tLearning Rate (w_theta): 0.001000\t TIME:79.6s\n",
      "\t\t\t\tDisc: 1.968678\t\tSym: 25.334198\t\tSpars: 1198.319946\n",
      "\t TVw: -0.530884 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1019 [4000/8000 (50%)]\tBatch Loss: 1216.836353\tLearning Rate (w_theta): 0.001000\t TIME:81.1s\n",
      "\t\t\t\tDisc: 1.962828\t\tSym: 24.356436\t\tSpars: 1190.517090\n",
      "\t TVw: -0.530859 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1019...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1223.504013693358\n",
      "Average validation loss: 234.65943630762885\n",
      "Training epoch 1020...\n",
      "\n",
      "Train Epoch: 1020 [0/8000 (0%)]\tBatch Loss: 1230.957728\tLearning Rate (w_theta): 0.001000\t TIME:83.3s\n",
      "\t\t\t\tDisc: 2.077569\t\tSym: 25.278841\t\tSpars: 1203.601318\n",
      "\t TVw: -0.530835 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1020 [4000/8000 (50%)]\tBatch Loss: 1286.322092\tLearning Rate (w_theta): 0.001000\t TIME:84.8s\n",
      "\t\t\t\tDisc: 2.264908\t\tSym: 28.786188\t\tSpars: 1255.270996\n",
      "\t TVw: -0.530811 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1020...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1226.632533913671\n",
      "Average validation loss: 237.07245125738996\n",
      "Training epoch 1021...\n",
      "\n",
      "Train Epoch: 1021 [0/8000 (0%)]\tBatch Loss: 1237.074339\tLearning Rate (w_theta): 0.001000\t TIME:87.7s\n",
      "\t\t\t\tDisc: 2.098902\t\tSym: 25.587742\t\tSpars: 1209.387695\n",
      "\t TVw: -0.530787 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1021 [4000/8000 (50%)]\tBatch Loss: 1147.173411\tLearning Rate (w_theta): 0.001000\t TIME:89.2s\n",
      "\t\t\t\tDisc: 1.804341\t\tSym: 20.764212\t\tSpars: 1124.604858\n",
      "\t TVw: -0.530763 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1021...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1220.8993727994095\n",
      "Average validation loss: 230.1427812872891\n",
      "Training epoch 1022...\n",
      "\n",
      "Train Epoch: 1022 [0/8000 (0%)]\tBatch Loss: 1214.403040\tLearning Rate (w_theta): 0.001000\t TIME:91.5s\n",
      "\t\t\t\tDisc: 1.898243\t\tSym: 24.288977\t\tSpars: 1188.215820\n",
      "\t TVw: -0.530738 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1022 [4000/8000 (50%)]\tBatch Loss: 1238.163183\tLearning Rate (w_theta): 0.001000\t TIME:92.9s\n",
      "\t\t\t\tDisc: 2.044187\t\tSym: 24.975807\t\tSpars: 1211.143188\n",
      "\t TVw: -0.530714 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1022...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1214.727214348911\n",
      "Average validation loss: 230.2220087592011\n",
      "Training epoch 1023...\n",
      "\n",
      "Train Epoch: 1023 [0/8000 (0%)]\tBatch Loss: 1209.879736\tLearning Rate (w_theta): 0.001000\t TIME:95.2s\n",
      "\t\t\t\tDisc: 1.891405\t\tSym: 24.572071\t\tSpars: 1183.416260\n",
      "\t TVw: -0.530689 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1023 [4000/8000 (50%)]\tBatch Loss: 1178.435034\tLearning Rate (w_theta): 0.001000\t TIME:96.8s\n",
      "\t\t\t\tDisc: 1.883065\t\tSym: 22.434172\t\tSpars: 1154.117798\n",
      "\t TVw: -0.530665 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1023...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1212.509987426521\n",
      "Average validation loss: 232.63898113348435\n",
      "Training epoch 1024...\n",
      "\n",
      "Train Epoch: 1024 [0/8000 (0%)]\tBatch Loss: 1215.141335\tLearning Rate (w_theta): 0.001000\t TIME:99.0s\n",
      "\t\t\t\tDisc: 2.007014\t\tSym: 24.146650\t\tSpars: 1188.987671\n",
      "\t TVw: -0.530640 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1024 [4000/8000 (50%)]\tBatch Loss: 1219.873564\tLearning Rate (w_theta): 0.001000\t TIME:100.5s\n",
      "\t\t\t\tDisc: 2.109053\t\tSym: 24.318588\t\tSpars: 1193.445923\n",
      "\t TVw: -0.530615 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1024...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1211.5565823207912\n",
      "Average validation loss: 228.96144210927827\n",
      "Training epoch 1025...\n",
      "\n",
      "Train Epoch: 1025 [0/8000 (0%)]\tBatch Loss: 1215.474751\tLearning Rate (w_theta): 0.001000\t TIME:102.7s\n",
      "\t\t\t\tDisc: 1.915259\t\tSym: 24.574995\t\tSpars: 1188.984497\n",
      "\t TVw: -0.530590 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1025 [4000/8000 (50%)]\tBatch Loss: 1231.306782\tLearning Rate (w_theta): 0.001000\t TIME:104.2s\n",
      "\t\t\t\tDisc: 2.208874\t\tSym: 24.717171\t\tSpars: 1204.380737\n",
      "\t TVw: -0.530565 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1025...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1213.2871216459714\n",
      "Average validation loss: 228.2995897895631\n",
      "Training epoch 1026...\n",
      "\n",
      "Train Epoch: 1026 [0/8000 (0%)]\tBatch Loss: 1164.726400\tLearning Rate (w_theta): 0.001000\t TIME:106.5s\n",
      "\t\t\t\tDisc: 1.772718\t\tSym: 21.622261\t\tSpars: 1141.331421\n",
      "\t TVw: -0.530540 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1026 [4000/8000 (50%)]\tBatch Loss: 1252.459181\tLearning Rate (w_theta): 0.001000\t TIME:108.0s\n",
      "\t\t\t\tDisc: 2.067701\t\tSym: 26.751343\t\tSpars: 1223.640137\n",
      "\t TVw: -0.530515 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1026...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1217.8555332318435\n",
      "Average validation loss: 231.29341959874554\n",
      "Training epoch 1027...\n",
      "\n",
      "Train Epoch: 1027 [0/8000 (0%)]\tBatch Loss: 1207.398679\tLearning Rate (w_theta): 0.001000\t TIME:110.2s\n",
      "\t\t\t\tDisc: 2.067679\t\tSym: 25.532660\t\tSpars: 1179.798340\n",
      "\t TVw: -0.530490 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1027 [4000/8000 (50%)]\tBatch Loss: 1203.751291\tLearning Rate (w_theta): 0.001000\t TIME:111.7s\n",
      "\t\t\t\tDisc: 1.867718\t\tSym: 23.266630\t\tSpars: 1178.616943\n",
      "\t TVw: -0.530466 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1027...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1223.6662132856632\n",
      "Average validation loss: 228.4964429060428\n",
      "Training epoch 1028...\n",
      "\n",
      "Train Epoch: 1028 [0/8000 (0%)]\tBatch Loss: 1222.560883\tLearning Rate (w_theta): 0.001000\t TIME:114.0s\n",
      "\t\t\t\tDisc: 2.249699\t\tSym: 24.873806\t\tSpars: 1195.437378\n",
      "\t TVw: -0.530441 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1028 [4000/8000 (50%)]\tBatch Loss: 1210.528583\tLearning Rate (w_theta): 0.001000\t TIME:115.5s\n",
      "\t\t\t\tDisc: 2.088809\t\tSym: 24.316483\t\tSpars: 1184.123291\n",
      "\t TVw: -0.530416 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1028...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1218.436588265329\n",
      "Average validation loss: 229.5460642001976\n",
      "Training epoch 1029...\n",
      "\n",
      "Train Epoch: 1029 [0/8000 (0%)]\tBatch Loss: 1233.408777\tLearning Rate (w_theta): 0.001000\t TIME:117.8s\n",
      "\t\t\t\tDisc: 1.982685\t\tSym: 24.143011\t\tSpars: 1207.283081\n",
      "\t TVw: -0.530392 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1029 [4000/8000 (50%)]\tBatch Loss: 1201.361437\tLearning Rate (w_theta): 0.001000\t TIME:119.3s\n",
      "\t\t\t\tDisc: 2.036944\t\tSym: 24.476837\t\tSpars: 1174.847656\n",
      "\t TVw: -0.530367 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1029...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1210.2367333104635\n",
      "Average validation loss: 231.55399943650093\n",
      "Training epoch 1030...\n",
      "\n",
      "Train Epoch: 1030 [0/8000 (0%)]\tBatch Loss: 1224.719507\tLearning Rate (w_theta): 0.001000\t TIME:121.6s\n",
      "\t\t\t\tDisc: 2.135672\t\tSym: 25.912205\t\tSpars: 1196.671631\n",
      "\t TVw: -0.530342 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1030 [4000/8000 (50%)]\tBatch Loss: 1189.503577\tLearning Rate (w_theta): 0.001000\t TIME:123.1s\n",
      "\t\t\t\tDisc: 1.815677\t\tSym: 23.312168\t\tSpars: 1164.375732\n",
      "\t TVw: -0.530316 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1030...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1207.3735178309737\n",
      "Average validation loss: 231.3194851809235\n",
      "Training epoch 1031...\n",
      "\n",
      "Train Epoch: 1031 [0/8000 (0%)]\tBatch Loss: 1183.448961\tLearning Rate (w_theta): 0.001000\t TIME:125.9s\n",
      "\t\t\t\tDisc: 1.956951\t\tSym: 23.499701\t\tSpars: 1157.992310\n",
      "\t TVw: -0.530291 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1031 [4000/8000 (50%)]\tBatch Loss: 1219.870701\tLearning Rate (w_theta): 0.001000\t TIME:127.4s\n",
      "\t\t\t\tDisc: 2.019865\t\tSym: 24.903448\t\tSpars: 1192.947388\n",
      "\t TVw: -0.530265 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1031...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1207.7698383375432\n",
      "Average validation loss: 229.02096999472826\n",
      "Training epoch 1032...\n",
      "\n",
      "Train Epoch: 1032 [0/8000 (0%)]\tBatch Loss: 1179.135369\tLearning Rate (w_theta): 0.001000\t TIME:129.8s\n",
      "\t\t\t\tDisc: 1.895312\t\tSym: 22.290350\t\tSpars: 1154.949707\n",
      "\t TVw: -0.530240 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1032 [4000/8000 (50%)]\tBatch Loss: 1203.090294\tLearning Rate (w_theta): 0.001000\t TIME:131.2s\n",
      "\t\t\t\tDisc: 1.956660\t\tSym: 23.387419\t\tSpars: 1177.746216\n",
      "\t TVw: -0.530214 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1032...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1211.5695454512954\n",
      "Average validation loss: 232.81323148498214\n",
      "Training epoch 1033...\n",
      "\n",
      "Train Epoch: 1033 [0/8000 (0%)]\tBatch Loss: 1191.010198\tLearning Rate (w_theta): 0.001000\t TIME:133.5s\n",
      "\t\t\t\tDisc: 1.810037\t\tSym: 23.753139\t\tSpars: 1165.447021\n",
      "\t TVw: -0.530189 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1033 [4000/8000 (50%)]\tBatch Loss: 1226.852399\tLearning Rate (w_theta): 0.001000\t TIME:135.0s\n",
      "\t\t\t\tDisc: 2.048560\t\tSym: 24.525885\t\tSpars: 1200.277954\n",
      "\t TVw: -0.530163 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1033...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1215.1836460628801\n",
      "Average validation loss: 231.09090081014205\n",
      "Training epoch 1034...\n",
      "\n",
      "Train Epoch: 1034 [0/8000 (0%)]\tBatch Loss: 1183.422563\tLearning Rate (w_theta): 0.001000\t TIME:137.2s\n",
      "\t\t\t\tDisc: 1.829129\t\tSym: 23.038990\t\tSpars: 1158.554443\n",
      "\t TVw: -0.530137 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1034 [4000/8000 (50%)]\tBatch Loss: 1198.116859\tLearning Rate (w_theta): 0.001000\t TIME:138.7s\n",
      "\t\t\t\tDisc: 1.881753\t\tSym: 23.038084\t\tSpars: 1173.197021\n",
      "\t TVw: -0.530111 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1034...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1217.7047405645449\n",
      "Average validation loss: 226.4549416428375\n",
      "Training epoch 1035...\n",
      "\n",
      "Train Epoch: 1035 [0/8000 (0%)]\tBatch Loss: 1215.127535\tLearning Rate (w_theta): 0.001000\t TIME:141.1s\n",
      "\t\t\t\tDisc: 1.979177\t\tSym: 23.604778\t\tSpars: 1189.543579\n",
      "\t TVw: -0.530086 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1035 [4000/8000 (50%)]\tBatch Loss: 1235.176672\tLearning Rate (w_theta): 0.001000\t TIME:142.5s\n",
      "\t\t\t\tDisc: 2.085279\t\tSym: 25.270103\t\tSpars: 1207.821289\n",
      "\t TVw: -0.530060 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1035...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1218.0278554606493\n",
      "Average validation loss: 231.0865258098726\n",
      "Training epoch 1036...\n",
      "\n",
      "Train Epoch: 1036 [0/8000 (0%)]\tBatch Loss: 1233.891299\tLearning Rate (w_theta): 0.001000\t TIME:144.9s\n",
      "\t\t\t\tDisc: 2.007964\t\tSym: 24.348301\t\tSpars: 1207.535034\n",
      "\t TVw: -0.530034 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1036 [4000/8000 (50%)]\tBatch Loss: 1172.311031\tLearning Rate (w_theta): 0.001000\t TIME:146.4s\n",
      "\t\t\t\tDisc: 1.831125\t\tSym: 22.665331\t\tSpars: 1147.814575\n",
      "\t TVw: -0.530009 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1036...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1215.8052240039742\n",
      "Average validation loss: 227.43115596937122\n",
      "Training epoch 1037...\n",
      "\n",
      "Train Epoch: 1037 [0/8000 (0%)]\tBatch Loss: 1184.410001\tLearning Rate (w_theta): 0.001000\t TIME:148.6s\n",
      "\t\t\t\tDisc: 1.884613\t\tSym: 22.178709\t\tSpars: 1160.346680\n",
      "\t TVw: -0.529983 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1037 [4000/8000 (50%)]\tBatch Loss: 1220.133218\tLearning Rate (w_theta): 0.001000\t TIME:150.1s\n",
      "\t\t\t\tDisc: 2.009713\t\tSym: 24.751801\t\tSpars: 1193.371704\n",
      "\t TVw: -0.529958 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1037...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1213.5756397253244\n",
      "Average validation loss: 227.8169724245119\n",
      "Training epoch 1038...\n",
      "\n",
      "Train Epoch: 1038 [0/8000 (0%)]\tBatch Loss: 1225.063842\tLearning Rate (w_theta): 0.001000\t TIME:152.4s\n",
      "\t\t\t\tDisc: 2.059267\t\tSym: 25.430479\t\tSpars: 1197.574097\n",
      "\t TVw: -0.529933 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1038 [4000/8000 (50%)]\tBatch Loss: 1128.332428\tLearning Rate (w_theta): 0.001000\t TIME:153.8s\n",
      "\t\t\t\tDisc: 1.679480\t\tSym: 20.428827\t\tSpars: 1106.224121\n",
      "\t TVw: -0.529907 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1038...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1205.658036966834\n",
      "Average validation loss: 226.84956043182257\n",
      "Training epoch 1039...\n",
      "\n",
      "Train Epoch: 1039 [0/8000 (0%)]\tBatch Loss: 1222.801162\tLearning Rate (w_theta): 0.001000\t TIME:156.2s\n",
      "\t\t\t\tDisc: 1.939984\t\tSym: 24.347872\t\tSpars: 1196.513306\n",
      "\t TVw: -0.529881 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1039 [4000/8000 (50%)]\tBatch Loss: 1146.468084\tLearning Rate (w_theta): 0.001000\t TIME:157.7s\n",
      "\t\t\t\tDisc: 1.671114\t\tSym: 21.198704\t\tSpars: 1123.598267\n",
      "\t TVw: -0.529855 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1039...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1206.5376029239173\n",
      "Average validation loss: 228.31495551116228\n",
      "Training epoch 1040...\n",
      "\n",
      "Train Epoch: 1040 [0/8000 (0%)]\tBatch Loss: 1229.021301\tLearning Rate (w_theta): 0.001000\t TIME:160.0s\n",
      "\t\t\t\tDisc: 2.043417\t\tSym: 26.313822\t\tSpars: 1200.664062\n",
      "\t TVw: -0.529828 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1040 [4000/8000 (50%)]\tBatch Loss: 1192.880663\tLearning Rate (w_theta): 0.001000\t TIME:161.5s\n",
      "\t\t\t\tDisc: 2.026325\t\tSym: 23.371794\t\tSpars: 1167.482544\n",
      "\t TVw: -0.529802 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1040...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1207.8295324144435\n",
      "Average validation loss: 228.86287737814422\n",
      "Training epoch 1041...\n",
      "\n",
      "Train Epoch: 1041 [0/8000 (0%)]\tBatch Loss: 1230.307045\tLearning Rate (w_theta): 0.001000\t TIME:164.5s\n",
      "\t\t\t\tDisc: 2.042687\t\tSym: 25.523636\t\tSpars: 1202.740723\n",
      "\t TVw: -0.529776 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1041 [4000/8000 (50%)]\tBatch Loss: 1187.524731\tLearning Rate (w_theta): 0.001000\t TIME:166.0s\n",
      "\t\t\t\tDisc: 1.893904\t\tSym: 23.039274\t\tSpars: 1162.591553\n",
      "\t TVw: -0.529749 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1041...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1204.6154031072251\n",
      "Average validation loss: 232.92004432365854\n",
      "Training epoch 1042...\n",
      "\n",
      "Train Epoch: 1042 [0/8000 (0%)]\tBatch Loss: 1157.444488\tLearning Rate (w_theta): 0.001000\t TIME:168.2s\n",
      "\t\t\t\tDisc: 1.861265\t\tSym: 22.137545\t\tSpars: 1133.445679\n",
      "\t TVw: -0.529723 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1042 [4000/8000 (50%)]\tBatch Loss: 1211.006929\tLearning Rate (w_theta): 0.001000\t TIME:169.7s\n",
      "\t\t\t\tDisc: 2.028280\t\tSym: 25.179821\t\tSpars: 1183.798828\n",
      "\t TVw: -0.529696 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1042...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1209.2235467429416\n",
      "Average validation loss: 226.81045144210697\n",
      "Training epoch 1043...\n",
      "\n",
      "Train Epoch: 1043 [0/8000 (0%)]\tBatch Loss: 1259.633836\tLearning Rate (w_theta): 0.001000\t TIME:172.0s\n",
      "\t\t\t\tDisc: 2.246486\t\tSym: 25.337545\t\tSpars: 1232.049805\n",
      "\t TVw: -0.529670 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1043 [4000/8000 (50%)]\tBatch Loss: 1231.381154\tLearning Rate (w_theta): 0.001000\t TIME:173.5s\n",
      "\t\t\t\tDisc: 2.022252\t\tSym: 25.166031\t\tSpars: 1204.192871\n",
      "\t TVw: -0.529644 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1043...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1214.5989962126691\n",
      "Average validation loss: 228.55414648519127\n",
      "Training epoch 1044...\n",
      "\n",
      "Train Epoch: 1044 [0/8000 (0%)]\tBatch Loss: 1229.951287\tLearning Rate (w_theta): 0.001000\t TIME:175.9s\n",
      "\t\t\t\tDisc: 1.963921\t\tSym: 25.159607\t\tSpars: 1202.827759\n",
      "\t TVw: -0.529617 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1044 [4000/8000 (50%)]\tBatch Loss: 1227.980018\tLearning Rate (w_theta): 0.001000\t TIME:177.5s\n",
      "\t\t\t\tDisc: 2.077376\t\tSym: 25.260185\t\tSpars: 1200.642456\n",
      "\t TVw: -0.529590 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1044...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1204.37416272404\n",
      "Average validation loss: 227.87233146294844\n",
      "Training epoch 1045...\n",
      "\n",
      "Train Epoch: 1045 [0/8000 (0%)]\tBatch Loss: 1187.708103\tLearning Rate (w_theta): 0.001000\t TIME:179.8s\n",
      "\t\t\t\tDisc: 1.942307\t\tSym: 22.728199\t\tSpars: 1163.037598\n",
      "\t TVw: -0.529563 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1045 [4000/8000 (50%)]\tBatch Loss: 1199.336733\tLearning Rate (w_theta): 0.001000\t TIME:181.3s\n",
      "\t\t\t\tDisc: 2.013428\t\tSym: 24.371035\t\tSpars: 1172.952271\n",
      "\t TVw: -0.529536 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1045...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1207.3902490831458\n",
      "Average validation loss: 226.57440045643273\n",
      "Training epoch 1046...\n",
      "\n",
      "Train Epoch: 1046 [0/8000 (0%)]\tBatch Loss: 1215.478369\tLearning Rate (w_theta): 0.001000\t TIME:183.5s\n",
      "\t\t\t\tDisc: 2.102861\t\tSym: 26.210102\t\tSpars: 1187.165405\n",
      "\t TVw: -0.529509 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1046 [4000/8000 (50%)]\tBatch Loss: 1199.588617\tLearning Rate (w_theta): 0.001000\t TIME:185.0s\n",
      "\t\t\t\tDisc: 1.918319\t\tSym: 23.427988\t\tSpars: 1174.242310\n",
      "\t TVw: -0.529483 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1046...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1205.4498858591562\n",
      "Average validation loss: 227.21565315799847\n",
      "Training epoch 1047...\n",
      "\n",
      "Train Epoch: 1047 [0/8000 (0%)]\tBatch Loss: 1195.676108\tLearning Rate (w_theta): 0.001000\t TIME:187.3s\n",
      "\t\t\t\tDisc: 1.982387\t\tSym: 24.848019\t\tSpars: 1168.845703\n",
      "\t TVw: -0.529456 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1047 [4000/8000 (50%)]\tBatch Loss: 1169.547927\tLearning Rate (w_theta): 0.001000\t TIME:188.8s\n",
      "\t\t\t\tDisc: 1.819299\t\tSym: 22.652090\t\tSpars: 1145.076538\n",
      "\t TVw: -0.529429 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1047...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1203.3128848717047\n",
      "Average validation loss: 229.46564020948182\n",
      "Training epoch 1048...\n",
      "\n",
      "Train Epoch: 1048 [0/8000 (0%)]\tBatch Loss: 1218.904493\tLearning Rate (w_theta): 0.001000\t TIME:191.2s\n",
      "\t\t\t\tDisc: 2.000065\t\tSym: 23.700327\t\tSpars: 1193.204102\n",
      "\t TVw: -0.529402 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1048 [4000/8000 (50%)]\tBatch Loss: 1255.996039\tLearning Rate (w_theta): 0.001000\t TIME:192.7s\n",
      "\t\t\t\tDisc: 2.200629\t\tSym: 27.598145\t\tSpars: 1226.197266\n",
      "\t TVw: -0.529374 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1048...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1202.48378492326\n",
      "Average validation loss: 228.7247459778435\n",
      "Training epoch 1049...\n",
      "\n",
      "Train Epoch: 1049 [0/8000 (0%)]\tBatch Loss: 1190.025909\tLearning Rate (w_theta): 0.001000\t TIME:195.0s\n",
      "\t\t\t\tDisc: 1.916673\t\tSym: 23.895979\t\tSpars: 1164.213257\n",
      "\t TVw: -0.529347 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1049 [4000/8000 (50%)]\tBatch Loss: 1207.536225\tLearning Rate (w_theta): 0.001000\t TIME:196.5s\n",
      "\t\t\t\tDisc: 2.077263\t\tSym: 23.695290\t\tSpars: 1181.763672\n",
      "\t TVw: -0.529320 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1049...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1202.8717395675135\n",
      "Average validation loss: 231.06879276928373\n",
      "Training epoch 1050...\n",
      "\n",
      "Train Epoch: 1050 [0/8000 (0%)]\tBatch Loss: 1170.155469\tLearning Rate (w_theta): 0.001000\t TIME:198.8s\n",
      "\t\t\t\tDisc: 1.825389\t\tSym: 22.077394\t\tSpars: 1146.252686\n",
      "\t TVw: -0.529293 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1050 [4000/8000 (50%)]\tBatch Loss: 1211.956071\tLearning Rate (w_theta): 0.001000\t TIME:200.3s\n",
      "\t\t\t\tDisc: 2.049659\t\tSym: 23.540689\t\tSpars: 1186.365723\n",
      "\t TVw: -0.529265 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1050...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1203.0852706190929\n",
      "Average validation loss: 227.114553137224\n",
      "Training epoch 1051...\n",
      "\n",
      "Train Epoch: 1051 [0/8000 (0%)]\tBatch Loss: 1216.915729\tLearning Rate (w_theta): 0.001000\t TIME:203.4s\n",
      "\t\t\t\tDisc: 1.952485\t\tSym: 24.477404\t\tSpars: 1190.485840\n",
      "\t TVw: -0.529238 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1051 [4000/8000 (50%)]\tBatch Loss: 1157.193280\tLearning Rate (w_theta): 0.001000\t TIME:204.9s\n",
      "\t\t\t\tDisc: 1.754992\t\tSym: 21.934504\t\tSpars: 1133.503784\n",
      "\t TVw: -0.529211 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1051...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1206.6497987280786\n",
      "Average validation loss: 226.55346342862256\n",
      "Training epoch 1052...\n",
      "\n",
      "Train Epoch: 1052 [0/8000 (0%)]\tBatch Loss: 1174.934801\tLearning Rate (w_theta): 0.001000\t TIME:207.2s\n",
      "\t\t\t\tDisc: 1.859297\t\tSym: 23.060856\t\tSpars: 1150.014648\n",
      "\t TVw: -0.529183 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1052 [4000/8000 (50%)]\tBatch Loss: 1180.108720\tLearning Rate (w_theta): 0.001000\t TIME:208.8s\n",
      "\t\t\t\tDisc: 1.978229\t\tSym: 22.864012\t\tSpars: 1155.266479\n",
      "\t TVw: -0.529156 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1052...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1201.681584913922\n",
      "Average validation loss: 227.57793890303347\n",
      "Training epoch 1053...\n",
      "\n",
      "Train Epoch: 1053 [0/8000 (0%)]\tBatch Loss: 1216.938051\tLearning Rate (w_theta): 0.001000\t TIME:211.1s\n",
      "\t\t\t\tDisc: 1.995709\t\tSym: 25.880453\t\tSpars: 1189.061890\n",
      "\t TVw: -0.529128 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1053 [4000/8000 (50%)]\tBatch Loss: 1192.271342\tLearning Rate (w_theta): 0.001000\t TIME:212.6s\n",
      "\t\t\t\tDisc: 2.056886\t\tSym: 24.457499\t\tSpars: 1165.756958\n",
      "\t TVw: -0.529100 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1053...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1210.2416056262243\n",
      "Average validation loss: 229.56482457731758\n",
      "Training epoch 1054...\n",
      "\n",
      "Train Epoch: 1054 [0/8000 (0%)]\tBatch Loss: 1198.666751\tLearning Rate (w_theta): 0.001000\t TIME:215.0s\n",
      "\t\t\t\tDisc: 1.815930\t\tSym: 23.062979\t\tSpars: 1173.787842\n",
      "\t TVw: -0.529073 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1054 [4000/8000 (50%)]\tBatch Loss: 1215.737263\tLearning Rate (w_theta): 0.001000\t TIME:216.5s\n",
      "\t\t\t\tDisc: 2.113000\t\tSym: 25.503658\t\tSpars: 1188.120605\n",
      "\t TVw: -0.529045 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1054...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1209.8416105843257\n",
      "Average validation loss: 225.0110140238618\n",
      "Training epoch 1055...\n",
      "\n",
      "Train Epoch: 1055 [0/8000 (0%)]\tBatch Loss: 1201.229099\tLearning Rate (w_theta): 0.001000\t TIME:218.8s\n",
      "\t\t\t\tDisc: 2.137001\t\tSym: 24.203304\t\tSpars: 1174.888794\n",
      "\t TVw: -0.529018 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1055 [4000/8000 (50%)]\tBatch Loss: 1168.841237\tLearning Rate (w_theta): 0.001000\t TIME:220.3s\n",
      "\t\t\t\tDisc: 1.924018\t\tSym: 21.526594\t\tSpars: 1145.390625\n",
      "\t TVw: -0.528990 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1055...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1208.6295176086376\n",
      "Average validation loss: 227.61886824482917\n",
      "Training epoch 1056...\n",
      "\n",
      "Train Epoch: 1056 [0/8000 (0%)]\tBatch Loss: 1226.225032\tLearning Rate (w_theta): 0.001000\t TIME:222.6s\n",
      "\t\t\t\tDisc: 2.077375\t\tSym: 25.769850\t\tSpars: 1198.377808\n",
      "\t TVw: -0.528962 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1056 [4000/8000 (50%)]\tBatch Loss: 1195.344620\tLearning Rate (w_theta): 0.001000\t TIME:224.2s\n",
      "\t\t\t\tDisc: 1.989065\t\tSym: 24.189905\t\tSpars: 1169.165649\n",
      "\t TVw: -0.528934 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1056...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1201.5596850772522\n",
      "Average validation loss: 227.93617827061846\n",
      "Training epoch 1057...\n",
      "\n",
      "Train Epoch: 1057 [0/8000 (0%)]\tBatch Loss: 1197.336391\tLearning Rate (w_theta): 0.001000\t TIME:226.5s\n",
      "\t\t\t\tDisc: 1.902998\t\tSym: 23.570356\t\tSpars: 1171.863037\n",
      "\t TVw: -0.528906 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1057 [4000/8000 (50%)]\tBatch Loss: 1178.877711\tLearning Rate (w_theta): 0.001000\t TIME:228.0s\n",
      "\t\t\t\tDisc: 1.807286\t\tSym: 21.666861\t\tSpars: 1155.403564\n",
      "\t TVw: -0.528878 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1057...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1198.5716616074803\n",
      "Average validation loss: 226.98181790432625\n",
      "Training epoch 1058...\n",
      "\n",
      "Train Epoch: 1058 [0/8000 (0%)]\tBatch Loss: 1194.116621\tLearning Rate (w_theta): 0.001000\t TIME:230.4s\n",
      "\t\t\t\tDisc: 1.885358\t\tSym: 23.784119\t\tSpars: 1168.447144\n",
      "\t TVw: -0.528850 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1058 [4000/8000 (50%)]\tBatch Loss: 1203.484152\tLearning Rate (w_theta): 0.001000\t TIME:231.9s\n",
      "\t\t\t\tDisc: 2.028359\t\tSym: 25.369978\t\tSpars: 1176.085815\n",
      "\t TVw: -0.528822 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1058...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1199.5228893181381\n",
      "Average validation loss: 223.9126889462535\n",
      "Training epoch 1059...\n",
      "\n",
      "Train Epoch: 1059 [0/8000 (0%)]\tBatch Loss: 1221.265218\tLearning Rate (w_theta): 0.001000\t TIME:234.2s\n",
      "\t\t\t\tDisc: 2.070357\t\tSym: 24.301184\t\tSpars: 1194.893677\n",
      "\t TVw: -0.528794 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1059 [4000/8000 (50%)]\tBatch Loss: 1214.459675\tLearning Rate (w_theta): 0.001000\t TIME:235.7s\n",
      "\t\t\t\tDisc: 1.977108\t\tSym: 23.081200\t\tSpars: 1189.401367\n",
      "\t TVw: -0.528765 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1059...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1197.7422772568711\n",
      "Average validation loss: 224.56186006654275\n",
      "Training epoch 1060...\n",
      "\n",
      "Train Epoch: 1060 [0/8000 (0%)]\tBatch Loss: 1190.119497\tLearning Rate (w_theta): 0.001000\t TIME:238.0s\n",
      "\t\t\t\tDisc: 1.995778\t\tSym: 23.600281\t\tSpars: 1164.523438\n",
      "\t TVw: -0.528736 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1060 [4000/8000 (50%)]\tBatch Loss: 1219.041288\tLearning Rate (w_theta): 0.001000\t TIME:239.6s\n",
      "\t\t\t\tDisc: 2.093450\t\tSym: 24.818321\t\tSpars: 1192.129517\n",
      "\t TVw: -0.528708 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1060...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1196.9551446757744\n",
      "Average validation loss: 224.90840041267418\n",
      "Training epoch 1061...\n",
      "\n",
      "Train Epoch: 1061 [0/8000 (0%)]\tBatch Loss: 1160.855301\tLearning Rate (w_theta): 0.001000\t TIME:242.6s\n",
      "\t\t\t\tDisc: 1.804399\t\tSym: 22.831541\t\tSpars: 1136.219360\n",
      "\t TVw: -0.528679 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1061 [4000/8000 (50%)]\tBatch Loss: 1195.374393\tLearning Rate (w_theta): 0.001000\t TIME:244.1s\n",
      "\t\t\t\tDisc: 1.907771\t\tSym: 23.959908\t\tSpars: 1169.506714\n",
      "\t TVw: -0.528651 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1061...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1195.901650717874\n",
      "Average validation loss: 224.32319398409018\n",
      "Training epoch 1062...\n",
      "\n",
      "Train Epoch: 1062 [0/8000 (0%)]\tBatch Loss: 1172.270332\tLearning Rate (w_theta): 0.001000\t TIME:246.4s\n",
      "\t\t\t\tDisc: 1.817649\t\tSym: 22.155930\t\tSpars: 1148.296753\n",
      "\t TVw: -0.528622 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1062 [4000/8000 (50%)]\tBatch Loss: 1225.138786\tLearning Rate (w_theta): 0.001000\t TIME:247.9s\n",
      "\t\t\t\tDisc: 1.912900\t\tSym: 25.143122\t\tSpars: 1198.082764\n",
      "\t TVw: -0.528593 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1062...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1195.708073295737\n",
      "Average validation loss: 222.74374094174615\n",
      "Training epoch 1063...\n",
      "\n",
      "Train Epoch: 1063 [0/8000 (0%)]\tBatch Loss: 1214.448538\tLearning Rate (w_theta): 0.001000\t TIME:250.2s\n",
      "\t\t\t\tDisc: 2.087912\t\tSym: 26.137970\t\tSpars: 1186.222656\n",
      "\t TVw: -0.528564 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1063 [4000/8000 (50%)]\tBatch Loss: 1202.814200\tLearning Rate (w_theta): 0.001000\t TIME:251.7s\n",
      "\t\t\t\tDisc: 1.968495\t\tSym: 22.581057\t\tSpars: 1178.264648\n",
      "\t TVw: -0.528535 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1063...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1194.8591843005893\n",
      "Average validation loss: 225.2294827567051\n",
      "Training epoch 1064...\n",
      "\n",
      "Train Epoch: 1064 [0/8000 (0%)]\tBatch Loss: 1195.408687\tLearning Rate (w_theta): 0.001000\t TIME:254.1s\n",
      "\t\t\t\tDisc: 1.901786\t\tSym: 23.212955\t\tSpars: 1170.293945\n",
      "\t TVw: -0.528506 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1064 [4000/8000 (50%)]\tBatch Loss: 1230.948034\tLearning Rate (w_theta): 0.001000\t TIME:255.6s\n",
      "\t\t\t\tDisc: 2.044512\t\tSym: 26.015583\t\tSpars: 1202.887939\n",
      "\t TVw: -0.528477 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1064...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1195.6401851441258\n",
      "Average validation loss: 226.25289437467427\n",
      "Training epoch 1065...\n",
      "\n",
      "Train Epoch: 1065 [0/8000 (0%)]\tBatch Loss: 1159.874601\tLearning Rate (w_theta): 0.001000\t TIME:258.0s\n",
      "\t\t\t\tDisc: 1.890238\t\tSym: 22.579823\t\tSpars: 1135.404541\n",
      "\t TVw: -0.528447 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1065 [4000/8000 (50%)]\tBatch Loss: 1200.250122\tLearning Rate (w_theta): 0.001000\t TIME:259.5s\n",
      "\t\t\t\tDisc: 2.067278\t\tSym: 24.543318\t\tSpars: 1173.639526\n",
      "\t TVw: -0.528418 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1065...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1210.6500177670223\n",
      "Average validation loss: 222.75831329544022\n",
      "Training epoch 1066...\n",
      "\n",
      "Train Epoch: 1066 [0/8000 (0%)]\tBatch Loss: 1191.669506\tLearning Rate (w_theta): 0.001000\t TIME:261.8s\n",
      "\t\t\t\tDisc: 1.945230\t\tSym: 23.627352\t\tSpars: 1166.096924\n",
      "\t TVw: -0.528389 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1066 [4000/8000 (50%)]\tBatch Loss: 1165.969637\tLearning Rate (w_theta): 0.001000\t TIME:263.3s\n",
      "\t\t\t\tDisc: 1.833660\t\tSym: 21.718008\t\tSpars: 1142.417969\n",
      "\t TVw: -0.528361 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1066...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1199.5481433057028\n",
      "Average validation loss: 221.130050710276\n",
      "Training epoch 1067...\n",
      "\n",
      "Train Epoch: 1067 [0/8000 (0%)]\tBatch Loss: 1209.548575\tLearning Rate (w_theta): 0.001000\t TIME:265.6s\n",
      "\t\t\t\tDisc: 1.873526\t\tSym: 23.542236\t\tSpars: 1184.132812\n",
      "\t TVw: -0.528332 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1067 [4000/8000 (50%)]\tBatch Loss: 1154.974114\tLearning Rate (w_theta): 0.001000\t TIME:267.1s\n",
      "\t\t\t\tDisc: 1.669639\t\tSym: 21.239656\t\tSpars: 1132.064819\n",
      "\t TVw: -0.528303 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1067...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1197.1410542986007\n",
      "Average validation loss: 221.62427161475932\n",
      "Training epoch 1068...\n",
      "\n",
      "Train Epoch: 1068 [0/8000 (0%)]\tBatch Loss: 1177.467512\tLearning Rate (w_theta): 0.001000\t TIME:269.5s\n",
      "\t\t\t\tDisc: 1.896173\t\tSym: 22.448780\t\tSpars: 1153.122559\n",
      "\t TVw: -0.528274 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1068 [4000/8000 (50%)]\tBatch Loss: 1203.318514\tLearning Rate (w_theta): 0.001000\t TIME:271.0s\n",
      "\t\t\t\tDisc: 1.903311\t\tSym: 24.918865\t\tSpars: 1176.496338\n",
      "\t TVw: -0.528244 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1068...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1203.0240451100783\n",
      "Average validation loss: 229.26505295713966\n",
      "Training epoch 1069...\n",
      "\n",
      "Train Epoch: 1069 [0/8000 (0%)]\tBatch Loss: 1221.386066\tLearning Rate (w_theta): 0.001000\t TIME:273.4s\n",
      "\t\t\t\tDisc: 1.940580\t\tSym: 26.545340\t\tSpars: 1192.900146\n",
      "\t TVw: -0.528215 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1069 [4000/8000 (50%)]\tBatch Loss: 1191.956644\tLearning Rate (w_theta): 0.001000\t TIME:274.9s\n",
      "\t\t\t\tDisc: 1.896389\t\tSym: 22.668898\t\tSpars: 1167.391357\n",
      "\t TVw: -0.528186 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1069...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1218.3577439793658\n",
      "Average validation loss: 220.79909083612924\n",
      "Training epoch 1070...\n",
      "\n",
      "Train Epoch: 1070 [0/8000 (0%)]\tBatch Loss: 1160.767349\tLearning Rate (w_theta): 0.001000\t TIME:277.3s\n",
      "\t\t\t\tDisc: 1.819063\t\tSym: 21.398115\t\tSpars: 1137.550171\n",
      "\t TVw: -0.528157 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1070 [4000/8000 (50%)]\tBatch Loss: 1227.637674\tLearning Rate (w_theta): 0.001000\t TIME:278.8s\n",
      "\t\t\t\tDisc: 2.286854\t\tSym: 25.288565\t\tSpars: 1200.062256\n",
      "\t TVw: -0.528129 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1070...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1211.7305352471694\n",
      "Average validation loss: 218.77541286167545\n",
      "Training epoch 1071...\n",
      "\n",
      "Train Epoch: 1071 [0/8000 (0%)]\tBatch Loss: 1243.683764\tLearning Rate (w_theta): 0.001000\t TIME:281.8s\n",
      "\t\t\t\tDisc: 2.256509\t\tSym: 25.382212\t\tSpars: 1216.045044\n",
      "\t TVw: -0.528100 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1071 [4000/8000 (50%)]\tBatch Loss: 1224.440300\tLearning Rate (w_theta): 0.001000\t TIME:283.3s\n",
      "\t\t\t\tDisc: 1.928493\t\tSym: 23.923061\t\tSpars: 1198.588745\n",
      "\t TVw: -0.528071 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1071...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1215.5582223662277\n",
      "Average validation loss: 216.6256491070316\n",
      "Training epoch 1072...\n",
      "\n",
      "Train Epoch: 1072 [0/8000 (0%)]\tBatch Loss: 1213.845929\tLearning Rate (w_theta): 0.001000\t TIME:285.6s\n",
      "\t\t\t\tDisc: 1.990977\t\tSym: 23.323092\t\tSpars: 1188.531860\n",
      "\t TVw: -0.528042 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1072 [4000/8000 (50%)]\tBatch Loss: 1166.727287\tLearning Rate (w_theta): 0.001000\t TIME:287.1s\n",
      "\t\t\t\tDisc: 1.758730\t\tSym: 22.330862\t\tSpars: 1142.637695\n",
      "\t TVw: -0.528014 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1072...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1212.016761770302\n",
      "Average validation loss: 219.34966659017724\n",
      "Training epoch 1073...\n",
      "\n",
      "Train Epoch: 1073 [0/8000 (0%)]\tBatch Loss: 1203.040700\tLearning Rate (w_theta): 0.001000\t TIME:289.5s\n",
      "\t\t\t\tDisc: 1.910544\t\tSym: 24.049711\t\tSpars: 1177.080444\n",
      "\t TVw: -0.527985 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1073 [4000/8000 (50%)]\tBatch Loss: 1203.899212\tLearning Rate (w_theta): 0.001000\t TIME:291.0s\n",
      "\t\t\t\tDisc: 1.838944\t\tSym: 23.623623\t\tSpars: 1178.436646\n",
      "\t TVw: -0.527955 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1073...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1196.0597462660594\n",
      "Average validation loss: 219.77483460606447\n",
      "Training epoch 1074...\n",
      "\n",
      "Train Epoch: 1074 [0/8000 (0%)]\tBatch Loss: 1203.986021\tLearning Rate (w_theta): 0.001000\t TIME:293.4s\n",
      "\t\t\t\tDisc: 1.998051\t\tSym: 23.611750\t\tSpars: 1178.376221\n",
      "\t TVw: -0.527926 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1074 [4000/8000 (50%)]\tBatch Loss: 1176.989530\tLearning Rate (w_theta): 0.001000\t TIME:294.9s\n",
      "\t\t\t\tDisc: 1.882232\t\tSym: 22.927000\t\tSpars: 1152.180298\n",
      "\t TVw: -0.527896 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1074...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1196.6461641430578\n",
      "Average validation loss: 221.8883396775263\n",
      "Training epoch 1075...\n",
      "\n",
      "Train Epoch: 1075 [0/8000 (0%)]\tBatch Loss: 1196.102605\tLearning Rate (w_theta): 0.001000\t TIME:297.2s\n",
      "\t\t\t\tDisc: 1.938903\t\tSym: 24.093023\t\tSpars: 1170.070679\n",
      "\t TVw: -0.527866 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1075 [4000/8000 (50%)]\tBatch Loss: 1143.750437\tLearning Rate (w_theta): 0.001000\t TIME:298.7s\n",
      "\t\t\t\tDisc: 1.744164\t\tSym: 21.220751\t\tSpars: 1120.785522\n",
      "\t TVw: -0.527835 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1075...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1193.1050936008608\n",
      "Average validation loss: 220.45003331089146\n",
      "Training epoch 1076...\n",
      "\n",
      "Train Epoch: 1076 [0/8000 (0%)]\tBatch Loss: 1242.826549\tLearning Rate (w_theta): 0.001000\t TIME:301.1s\n",
      "\t\t\t\tDisc: 2.111827\t\tSym: 25.464111\t\tSpars: 1215.250610\n",
      "\t TVw: -0.527805 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1076 [4000/8000 (50%)]\tBatch Loss: 1174.256220\tLearning Rate (w_theta): 0.001000\t TIME:302.6s\n",
      "\t\t\t\tDisc: 1.729223\t\tSym: 21.026020\t\tSpars: 1151.500977\n",
      "\t TVw: -0.527775 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1076...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1199.3616740312027\n",
      "Average validation loss: 220.6912372753333\n",
      "Training epoch 1077...\n",
      "\n",
      "Train Epoch: 1077 [0/8000 (0%)]\tBatch Loss: 1206.151985\tLearning Rate (w_theta): 0.001000\t TIME:305.0s\n",
      "\t\t\t\tDisc: 2.018271\t\tSym: 24.119799\t\tSpars: 1180.013916\n",
      "\t TVw: -0.527745 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1077 [4000/8000 (50%)]\tBatch Loss: 1199.721022\tLearning Rate (w_theta): 0.001000\t TIME:306.5s\n",
      "\t\t\t\tDisc: 2.083268\t\tSym: 23.304014\t\tSpars: 1174.333740\n",
      "\t TVw: -0.527714 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1077...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1210.751905949009\n",
      "Average validation loss: 223.62032351574183\n",
      "Training epoch 1078...\n",
      "\n",
      "Train Epoch: 1078 [0/8000 (0%)]\tBatch Loss: 1181.682149\tLearning Rate (w_theta): 0.001000\t TIME:308.9s\n",
      "\t\t\t\tDisc: 1.762006\t\tSym: 21.528542\t\tSpars: 1158.391602\n",
      "\t TVw: -0.527685 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1078 [4000/8000 (50%)]\tBatch Loss: 1230.348671\tLearning Rate (w_theta): 0.001000\t TIME:310.4s\n",
      "\t\t\t\tDisc: 2.118179\t\tSym: 25.398705\t\tSpars: 1202.831787\n",
      "\t TVw: -0.527655 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1078...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1225.044081376844\n",
      "Average validation loss: 223.34662223721463\n",
      "Training epoch 1079...\n",
      "\n",
      "Train Epoch: 1079 [0/8000 (0%)]\tBatch Loss: 1285.342754\tLearning Rate (w_theta): 0.001000\t TIME:312.7s\n",
      "\t\t\t\tDisc: 2.404838\t\tSym: 27.433277\t\tSpars: 1255.504639\n",
      "\t TVw: -0.527626 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1079 [4000/8000 (50%)]\tBatch Loss: 1151.639011\tLearning Rate (w_theta): 0.001000\t TIME:314.2s\n",
      "\t\t\t\tDisc: 1.788135\t\tSym: 20.863083\t\tSpars: 1128.987793\n",
      "\t TVw: -0.527597 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1079...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1211.2261073282789\n",
      "Average validation loss: 227.39875946671907\n",
      "Training epoch 1080...\n",
      "\n",
      "Train Epoch: 1080 [0/8000 (0%)]\tBatch Loss: 1220.293281\tLearning Rate (w_theta): 0.001000\t TIME:316.6s\n",
      "\t\t\t\tDisc: 1.835374\t\tSym: 23.412008\t\tSpars: 1195.045898\n",
      "\t TVw: -0.527567 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1080 [4000/8000 (50%)]\tBatch Loss: 1230.617100\tLearning Rate (w_theta): 0.001000\t TIME:318.1s\n",
      "\t\t\t\tDisc: 2.138965\t\tSym: 25.005722\t\tSpars: 1203.472412\n",
      "\t TVw: -0.527537 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1080...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1212.6870326386404\n",
      "Average validation loss: 229.72174989246722\n",
      "Training epoch 1081...\n",
      "\n",
      "Train Epoch: 1081 [0/8000 (0%)]\tBatch Loss: 1191.763342\tLearning Rate (w_theta): 0.001000\t TIME:321.2s\n",
      "\t\t\t\tDisc: 1.715964\t\tSym: 23.493301\t\tSpars: 1166.554077\n",
      "\t TVw: -0.527508 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1081 [4000/8000 (50%)]\tBatch Loss: 1181.526695\tLearning Rate (w_theta): 0.001000\t TIME:322.7s\n",
      "\t\t\t\tDisc: 2.005661\t\tSym: 22.917152\t\tSpars: 1156.603882\n",
      "\t TVw: -0.527477 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1081...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1196.6490020944595\n",
      "Average validation loss: 226.17279849151828\n",
      "Training epoch 1082...\n",
      "\n",
      "Train Epoch: 1082 [0/8000 (0%)]\tBatch Loss: 1177.536157\tLearning Rate (w_theta): 0.001000\t TIME:325.0s\n",
      "\t\t\t\tDisc: 1.727420\t\tSym: 21.918356\t\tSpars: 1153.890381\n",
      "\t TVw: -0.527447 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1082 [4000/8000 (50%)]\tBatch Loss: 1195.629221\tLearning Rate (w_theta): 0.001000\t TIME:326.5s\n",
      "\t\t\t\tDisc: 1.851547\t\tSym: 24.048914\t\tSpars: 1169.728760\n",
      "\t TVw: -0.527416 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1082...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1192.3648928218972\n",
      "Average validation loss: 223.56884154438237\n",
      "Training epoch 1083...\n",
      "\n",
      "Train Epoch: 1083 [0/8000 (0%)]\tBatch Loss: 1192.871925\tLearning Rate (w_theta): 0.001000\t TIME:328.8s\n",
      "\t\t\t\tDisc: 1.960565\t\tSym: 23.051863\t\tSpars: 1167.859497\n",
      "\t TVw: -0.527385 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1083 [4000/8000 (50%)]\tBatch Loss: 1196.938910\tLearning Rate (w_theta): 0.001000\t TIME:330.3s\n",
      "\t\t\t\tDisc: 1.867642\t\tSym: 24.560770\t\tSpars: 1170.510498\n",
      "\t TVw: -0.527354 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1083...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1189.1841281612594\n",
      "Average validation loss: 222.54195354822983\n",
      "Training epoch 1084...\n",
      "\n",
      "Train Epoch: 1084 [0/8000 (0%)]\tBatch Loss: 1170.391692\tLearning Rate (w_theta): 0.001000\t TIME:332.6s\n",
      "\t\t\t\tDisc: 1.881890\t\tSym: 22.866613\t\tSpars: 1145.643188\n",
      "\t TVw: -0.527322 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1084 [4000/8000 (50%)]\tBatch Loss: 1172.487921\tLearning Rate (w_theta): 0.001000\t TIME:334.2s\n",
      "\t\t\t\tDisc: 1.751831\t\tSym: 22.719976\t\tSpars: 1148.016113\n",
      "\t TVw: -0.527290 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1084...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1188.6588409955593\n",
      "Average validation loss: 220.97039269647024\n",
      "Training epoch 1085...\n",
      "\n",
      "Train Epoch: 1085 [0/8000 (0%)]\tBatch Loss: 1195.723076\tLearning Rate (w_theta): 0.001000\t TIME:336.5s\n",
      "\t\t\t\tDisc: 1.832802\t\tSym: 23.631729\t\tSpars: 1170.258545\n",
      "\t TVw: -0.527259 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1085 [4000/8000 (50%)]\tBatch Loss: 1168.179894\tLearning Rate (w_theta): 0.001000\t TIME:338.0s\n",
      "\t\t\t\tDisc: 1.897204\t\tSym: 22.179785\t\tSpars: 1144.102905\n",
      "\t TVw: -0.527228 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1085...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1189.597957197569\n",
      "Average validation loss: 219.3499110254754\n",
      "Training epoch 1086...\n",
      "\n",
      "Train Epoch: 1086 [0/8000 (0%)]\tBatch Loss: 1182.809092\tLearning Rate (w_theta): 0.001000\t TIME:340.4s\n",
      "\t\t\t\tDisc: 1.837391\t\tSym: 23.195944\t\tSpars: 1157.775757\n",
      "\t TVw: -0.527196 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1086 [4000/8000 (50%)]\tBatch Loss: 1164.010336\tLearning Rate (w_theta): 0.001000\t TIME:341.9s\n",
      "\t\t\t\tDisc: 1.761093\t\tSym: 21.025000\t\tSpars: 1141.224243\n",
      "\t TVw: -0.527165 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1086...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1188.533631282976\n",
      "Average validation loss: 219.26449106107097\n",
      "Training epoch 1087...\n",
      "\n",
      "Train Epoch: 1087 [0/8000 (0%)]\tBatch Loss: 1206.555294\tLearning Rate (w_theta): 0.001000\t TIME:344.2s\n",
      "\t\t\t\tDisc: 1.826347\t\tSym: 24.445499\t\tSpars: 1180.283447\n",
      "\t TVw: -0.527133 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1087 [4000/8000 (50%)]\tBatch Loss: 1207.034705\tLearning Rate (w_theta): 0.001000\t TIME:345.7s\n",
      "\t\t\t\tDisc: 1.936833\t\tSym: 24.499239\t\tSpars: 1180.598633\n",
      "\t TVw: -0.527102 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1087...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1188.8684007842603\n",
      "Average validation loss: 219.94030823963035\n",
      "Training epoch 1088...\n",
      "\n",
      "Train Epoch: 1088 [0/8000 (0%)]\tBatch Loss: 1173.387641\tLearning Rate (w_theta): 0.001000\t TIME:348.0s\n",
      "\t\t\t\tDisc: 1.811113\t\tSym: 22.274771\t\tSpars: 1149.301758\n",
      "\t TVw: -0.527070 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1088 [4000/8000 (50%)]\tBatch Loss: 1217.685870\tLearning Rate (w_theta): 0.001000\t TIME:349.6s\n",
      "\t\t\t\tDisc: 1.981865\t\tSym: 25.607935\t\tSpars: 1190.096069\n",
      "\t TVw: -0.527038 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1088...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1190.2254977485622\n",
      "Average validation loss: 220.0715352934781\n",
      "Training epoch 1089...\n",
      "\n",
      "Train Epoch: 1089 [0/8000 (0%)]\tBatch Loss: 1142.672696\tLearning Rate (w_theta): 0.001000\t TIME:351.9s\n",
      "\t\t\t\tDisc: 1.857663\t\tSym: 21.920258\t\tSpars: 1118.894775\n",
      "\t TVw: -0.527006 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1089 [4000/8000 (50%)]\tBatch Loss: 1196.721780\tLearning Rate (w_theta): 0.001000\t TIME:353.4s\n",
      "\t\t\t\tDisc: 1.949537\t\tSym: 23.657742\t\tSpars: 1171.114502\n",
      "\t TVw: -0.526974 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1089...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1189.412596216637\n",
      "Average validation loss: 221.86739460170165\n",
      "Training epoch 1090...\n",
      "\n",
      "Train Epoch: 1090 [0/8000 (0%)]\tBatch Loss: 1187.554529\tLearning Rate (w_theta): 0.001000\t TIME:355.7s\n",
      "\t\t\t\tDisc: 1.868034\t\tSym: 23.989351\t\tSpars: 1161.697144\n",
      "\t TVw: -0.526942 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1090 [4000/8000 (50%)]\tBatch Loss: 1195.247095\tLearning Rate (w_theta): 0.001000\t TIME:357.3s\n",
      "\t\t\t\tDisc: 1.923120\t\tSym: 23.528564\t\tSpars: 1169.795410\n",
      "\t TVw: -0.526909 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1090...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1187.0117646086821\n",
      "Average validation loss: 221.05109998250072\n",
      "Training epoch 1091...\n",
      "\n",
      "Train Epoch: 1091 [0/8000 (0%)]\tBatch Loss: 1158.871202\tLearning Rate (w_theta): 0.001000\t TIME:360.3s\n",
      "\t\t\t\tDisc: 1.720859\t\tSym: 21.260572\t\tSpars: 1135.889771\n",
      "\t TVw: -0.526877 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1091 [4000/8000 (50%)]\tBatch Loss: 1215.853489\tLearning Rate (w_theta): 0.001000\t TIME:361.8s\n",
      "\t\t\t\tDisc: 1.982014\t\tSym: 25.737320\t\tSpars: 1188.134155\n",
      "\t TVw: -0.526845 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1091...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1187.435387878696\n",
      "Average validation loss: 220.9373021242981\n",
      "Training epoch 1092...\n",
      "\n",
      "Train Epoch: 1092 [0/8000 (0%)]\tBatch Loss: 1162.594288\tLearning Rate (w_theta): 0.001000\t TIME:364.1s\n",
      "\t\t\t\tDisc: 1.795483\t\tSym: 24.153542\t\tSpars: 1136.645264\n",
      "\t TVw: -0.526813 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1092 [4000/8000 (50%)]\tBatch Loss: 1164.324000\tLearning Rate (w_theta): 0.001000\t TIME:365.7s\n",
      "\t\t\t\tDisc: 1.858824\t\tSym: 21.823330\t\tSpars: 1140.641846\n",
      "\t TVw: -0.526781 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1092...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1185.242997879352\n",
      "Average validation loss: 220.0418994175697\n",
      "Training epoch 1093...\n",
      "\n",
      "Train Epoch: 1093 [0/8000 (0%)]\tBatch Loss: 1190.321333\tLearning Rate (w_theta): 0.001000\t TIME:368.0s\n",
      "\t\t\t\tDisc: 1.928784\t\tSym: 24.472506\t\tSpars: 1163.920044\n",
      "\t TVw: -0.526749 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1093 [4000/8000 (50%)]\tBatch Loss: 1164.557239\tLearning Rate (w_theta): 0.001000\t TIME:369.5s\n",
      "\t\t\t\tDisc: 1.754833\t\tSym: 22.286537\t\tSpars: 1140.515869\n",
      "\t TVw: -0.526716 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1093...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1186.2450542567371\n",
      "Average validation loss: 217.71721745869198\n",
      "Training epoch 1094...\n",
      "\n",
      "Train Epoch: 1094 [0/8000 (0%)]\tBatch Loss: 1194.971748\tLearning Rate (w_theta): 0.001000\t TIME:371.8s\n",
      "\t\t\t\tDisc: 2.045738\t\tSym: 23.264633\t\tSpars: 1169.661377\n",
      "\t TVw: -0.526684 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1094 [4000/8000 (50%)]\tBatch Loss: 1255.453214\tLearning Rate (w_theta): 0.001000\t TIME:373.4s\n",
      "\t\t\t\tDisc: 2.329873\t\tSym: 26.212940\t\tSpars: 1226.910400\n",
      "\t TVw: -0.526653 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1094...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1217.7973778240698\n",
      "Average validation loss: 212.83705793766194\n",
      "Training epoch 1095...\n",
      "\n",
      "Train Epoch: 1095 [0/8000 (0%)]\tBatch Loss: 1244.358721\tLearning Rate (w_theta): 0.001000\t TIME:375.7s\n",
      "\t\t\t\tDisc: 2.024472\t\tSym: 23.162130\t\tSpars: 1219.172119\n",
      "\t TVw: -0.526621 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1095 [4000/8000 (50%)]\tBatch Loss: 1278.941734\tLearning Rate (w_theta): 0.001000\t TIME:377.2s\n",
      "\t\t\t\tDisc: 2.135603\t\tSym: 24.604227\t\tSpars: 1252.201904\n",
      "\t TVw: -0.526590 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1095...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1251.1164434927305\n",
      "Average validation loss: 233.3607686358045\n",
      "Training epoch 1096...\n",
      "\n",
      "Train Epoch: 1096 [0/8000 (0%)]\tBatch Loss: 1340.008136\tLearning Rate (w_theta): 0.001000\t TIME:379.6s\n",
      "\t\t\t\tDisc: 1.516675\t\tSym: 28.449713\t\tSpars: 1310.041748\n",
      "\t TVw: -0.526560 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1096 [4000/8000 (50%)]\tBatch Loss: 1418.834965\tLearning Rate (w_theta): 0.001000\t TIME:381.1s\n",
      "\t\t\t\tDisc: 1.171955\t\tSym: 33.446091\t\tSpars: 1384.216919\n",
      "\t TVw: -0.526529 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1096...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1306.5555481979131\n",
      "Average validation loss: 234.9701236795542\n",
      "Training epoch 1097...\n",
      "\n",
      "Train Epoch: 1097 [0/8000 (0%)]\tBatch Loss: 1388.369017\tLearning Rate (w_theta): 0.001000\t TIME:383.4s\n",
      "\t\t\t\tDisc: 1.802733\t\tSym: 32.480957\t\tSpars: 1354.085327\n",
      "\t TVw: -0.526502 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1097 [4000/8000 (50%)]\tBatch Loss: 1299.773731\tLearning Rate (w_theta): 0.001000\t TIME:384.9s\n",
      "\t\t\t\tDisc: 1.537592\t\tSym: 26.039118\t\tSpars: 1272.197021\n",
      "\t TVw: -0.526474 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1097...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1283.5060015353638\n",
      "Average validation loss: 218.76813370420547\n",
      "Training epoch 1098...\n",
      "\n",
      "Train Epoch: 1098 [0/8000 (0%)]\tBatch Loss: 1213.747114\tLearning Rate (w_theta): 0.001000\t TIME:387.2s\n",
      "\t\t\t\tDisc: 1.635297\t\tSym: 22.722168\t\tSpars: 1189.389648\n",
      "\t TVw: -0.526446 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1098 [4000/8000 (50%)]\tBatch Loss: 1230.117192\tLearning Rate (w_theta): 0.001000\t TIME:388.7s\n",
      "\t\t\t\tDisc: 1.819411\t\tSym: 25.375906\t\tSpars: 1202.921875\n",
      "\t TVw: -0.526416 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1098...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1230.585483704626\n",
      "Average validation loss: 220.85208709632212\n",
      "Training epoch 1099...\n",
      "\n",
      "Train Epoch: 1099 [0/8000 (0%)]\tBatch Loss: 1224.898350\tLearning Rate (w_theta): 0.001000\t TIME:391.1s\n",
      "\t\t\t\tDisc: 1.903330\t\tSym: 24.419092\t\tSpars: 1198.575928\n",
      "\t TVw: -0.526384 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1099 [4000/8000 (50%)]\tBatch Loss: 1184.618172\tLearning Rate (w_theta): 0.001000\t TIME:392.6s\n",
      "\t\t\t\tDisc: 1.825058\t\tSym: 22.866722\t\tSpars: 1159.926392\n",
      "\t TVw: -0.526350 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1099...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1198.7876154648338\n",
      "Average validation loss: 220.224311306236\n",
      "Training epoch 1100...\n",
      "\n",
      "Train Epoch: 1100 [0/8000 (0%)]\tBatch Loss: 1166.679919\tLearning Rate (w_theta): 0.001000\t TIME:394.9s\n",
      "\t\t\t\tDisc: 1.840317\t\tSym: 22.645388\t\tSpars: 1142.194214\n",
      "\t TVw: -0.526316 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1100 [4000/8000 (50%)]\tBatch Loss: 1271.143420\tLearning Rate (w_theta): 0.001000\t TIME:396.4s\n",
      "\t\t\t\tDisc: 2.114739\t\tSym: 27.303095\t\tSpars: 1241.725586\n",
      "\t TVw: -0.526281 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1100...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1192.2641379808738\n",
      "Average validation loss: 219.1850285532066\n",
      "Training epoch 1101...\n",
      "\n",
      "Train Epoch: 1101 [0/8000 (0%)]\tBatch Loss: 1240.919078\tLearning Rate (w_theta): 0.001000\t TIME:399.5s\n",
      "\t\t\t\tDisc: 2.155622\t\tSym: 27.165922\t\tSpars: 1211.597534\n",
      "\t TVw: -0.526246 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1101 [4000/8000 (50%)]\tBatch Loss: 1164.394285\tLearning Rate (w_theta): 0.001000\t TIME:401.0s\n",
      "\t\t\t\tDisc: 1.736847\t\tSym: 21.732389\t\tSpars: 1140.925049\n",
      "\t TVw: -0.526212 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1101...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1201.3118056868173\n",
      "Average validation loss: 216.48981155054295\n",
      "Training epoch 1102...\n",
      "\n",
      "Train Epoch: 1102 [0/8000 (0%)]\tBatch Loss: 1198.958967\tLearning Rate (w_theta): 0.001000\t TIME:403.3s\n",
      "\t\t\t\tDisc: 1.999460\t\tSym: 24.210239\t\tSpars: 1172.749268\n",
      "\t TVw: -0.526178 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1102 [4000/8000 (50%)]\tBatch Loss: 1218.392506\tLearning Rate (w_theta): 0.001000\t TIME:404.9s\n",
      "\t\t\t\tDisc: 2.024214\t\tSym: 23.170904\t\tSpars: 1193.197388\n",
      "\t TVw: -0.526144 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1102...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1197.3674336274548\n",
      "Average validation loss: 219.71887124244415\n",
      "Training epoch 1103...\n",
      "\n",
      "Train Epoch: 1103 [0/8000 (0%)]\tBatch Loss: 1190.417277\tLearning Rate (w_theta): 0.001000\t TIME:407.2s\n",
      "\t\t\t\tDisc: 1.942896\t\tSym: 23.521011\t\tSpars: 1164.953369\n",
      "\t TVw: -0.526110 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1103 [4000/8000 (50%)]\tBatch Loss: 1216.107906\tLearning Rate (w_theta): 0.001000\t TIME:408.7s\n",
      "\t\t\t\tDisc: 2.019724\t\tSym: 24.270067\t\tSpars: 1189.818115\n",
      "\t TVw: -0.526076 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1103...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1189.7533834925616\n",
      "Average validation loss: 221.40644738531066\n",
      "Training epoch 1104...\n",
      "\n",
      "Train Epoch: 1104 [0/8000 (0%)]\tBatch Loss: 1200.024371\tLearning Rate (w_theta): 0.001000\t TIME:411.0s\n",
      "\t\t\t\tDisc: 1.858428\t\tSym: 23.320240\t\tSpars: 1174.845703\n",
      "\t TVw: -0.526042 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1104 [4000/8000 (50%)]\tBatch Loss: 1166.564626\tLearning Rate (w_theta): 0.001000\t TIME:412.5s\n",
      "\t\t\t\tDisc: 1.944242\t\tSym: 22.085350\t\tSpars: 1142.535034\n",
      "\t TVw: -0.526008 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1104...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1192.856411978294\n",
      "Average validation loss: 215.77925645211266\n",
      "Training epoch 1105...\n",
      "\n",
      "Train Epoch: 1105 [0/8000 (0%)]\tBatch Loss: 1172.853079\tLearning Rate (w_theta): 0.001000\t TIME:414.9s\n",
      "\t\t\t\tDisc: 1.881917\t\tSym: 22.094576\t\tSpars: 1148.876587\n",
      "\t TVw: -0.525974 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1105 [4000/8000 (50%)]\tBatch Loss: 1196.599243\tLearning Rate (w_theta): 0.001000\t TIME:416.4s\n",
      "\t\t\t\tDisc: 2.075952\t\tSym: 23.382666\t\tSpars: 1171.140625\n",
      "\t TVw: -0.525941 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1105...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1191.5814210477467\n",
      "Average validation loss: 214.64564072967804\n",
      "Training epoch 1106...\n",
      "\n",
      "Train Epoch: 1106 [0/8000 (0%)]\tBatch Loss: 1177.527655\tLearning Rate (w_theta): 0.001000\t TIME:418.7s\n",
      "\t\t\t\tDisc: 1.946763\t\tSym: 23.090658\t\tSpars: 1152.490234\n",
      "\t TVw: -0.525907 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1106 [4000/8000 (50%)]\tBatch Loss: 1150.798610\tLearning Rate (w_theta): 0.001000\t TIME:420.2s\n",
      "\t\t\t\tDisc: 1.737418\t\tSym: 21.045811\t\tSpars: 1128.015381\n",
      "\t TVw: -0.525873 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1106...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1189.6172675416112\n",
      "Average validation loss: 216.63680491595824\n",
      "Training epoch 1107...\n",
      "\n",
      "Train Epoch: 1107 [0/8000 (0%)]\tBatch Loss: 1153.842754\tLearning Rate (w_theta): 0.001000\t TIME:422.6s\n",
      "\t\t\t\tDisc: 1.828690\t\tSym: 22.485867\t\tSpars: 1129.528198\n",
      "\t TVw: -0.525839 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1107 [4000/8000 (50%)]\tBatch Loss: 1213.662837\tLearning Rate (w_theta): 0.001000\t TIME:424.1s\n",
      "\t\t\t\tDisc: 1.904101\t\tSym: 25.081367\t\tSpars: 1186.677368\n",
      "\t TVw: -0.525805 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1107...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1185.5564813496408\n",
      "Average validation loss: 216.53875717698799\n",
      "Training epoch 1108...\n",
      "\n",
      "Train Epoch: 1108 [0/8000 (0%)]\tBatch Loss: 1194.023332\tLearning Rate (w_theta): 0.001000\t TIME:426.4s\n",
      "\t\t\t\tDisc: 1.962131\t\tSym: 24.525679\t\tSpars: 1167.535522\n",
      "\t TVw: -0.525771 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1108 [4000/8000 (50%)]\tBatch Loss: 1163.320906\tLearning Rate (w_theta): 0.001000\t TIME:427.9s\n",
      "\t\t\t\tDisc: 1.756533\t\tSym: 21.635784\t\tSpars: 1139.928589\n",
      "\t TVw: -0.525736 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1108...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1184.288500113913\n",
      "Average validation loss: 218.96929322092038\n",
      "Training epoch 1109...\n",
      "\n",
      "Train Epoch: 1109 [0/8000 (0%)]\tBatch Loss: 1188.822278\tLearning Rate (w_theta): 0.001000\t TIME:430.3s\n",
      "\t\t\t\tDisc: 1.853015\t\tSym: 24.235376\t\tSpars: 1162.733887\n",
      "\t TVw: -0.525701 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1109 [4000/8000 (50%)]\tBatch Loss: 1201.249871\tLearning Rate (w_theta): 0.001000\t TIME:431.8s\n",
      "\t\t\t\tDisc: 1.855012\t\tSym: 23.229332\t\tSpars: 1176.165527\n",
      "\t TVw: -0.525666 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1109...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1183.8486778185134\n",
      "Average validation loss: 218.674752027218\n",
      "Training epoch 1110...\n",
      "\n",
      "Train Epoch: 1110 [0/8000 (0%)]\tBatch Loss: 1191.797920\tLearning Rate (w_theta): 0.001000\t TIME:434.1s\n",
      "\t\t\t\tDisc: 1.809483\t\tSym: 23.723057\t\tSpars: 1166.265381\n",
      "\t TVw: -0.525632 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1110 [4000/8000 (50%)]\tBatch Loss: 1216.666672\tLearning Rate (w_theta): 0.001000\t TIME:435.6s\n",
      "\t\t\t\tDisc: 2.116913\t\tSym: 25.746292\t\tSpars: 1188.803467\n",
      "\t TVw: -0.525597 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1110...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1183.900637886723\n",
      "Average validation loss: 216.44463365905125\n",
      "Training epoch 1111...\n",
      "\n",
      "Train Epoch: 1111 [0/8000 (0%)]\tBatch Loss: 1187.994663\tLearning Rate (w_theta): 0.001000\t TIME:438.6s\n",
      "\t\t\t\tDisc: 1.841749\t\tSym: 22.750937\t\tSpars: 1163.401978\n",
      "\t TVw: -0.525562 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1111 [4000/8000 (50%)]\tBatch Loss: 1156.194904\tLearning Rate (w_theta): 0.001000\t TIME:440.1s\n",
      "\t\t\t\tDisc: 1.739446\t\tSym: 21.763075\t\tSpars: 1132.692383\n",
      "\t TVw: -0.525527 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1111...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1183.873367767012\n",
      "Average validation loss: 215.61134421015896\n",
      "Training epoch 1112...\n",
      "\n",
      "Train Epoch: 1112 [0/8000 (0%)]\tBatch Loss: 1211.375359\tLearning Rate (w_theta): 0.001000\t TIME:442.5s\n",
      "\t\t\t\tDisc: 1.864528\t\tSym: 24.956755\t\tSpars: 1184.554077\n",
      "\t TVw: -0.525492 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1112 [4000/8000 (50%)]\tBatch Loss: 1183.408705\tLearning Rate (w_theta): 0.001000\t TIME:444.0s\n",
      "\t\t\t\tDisc: 1.903704\t\tSym: 22.758663\t\tSpars: 1158.746338\n",
      "\t TVw: -0.525456 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1112...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1181.5581308796784\n",
      "Average validation loss: 213.06907574642398\n",
      "Training epoch 1113...\n",
      "\n",
      "Train Epoch: 1113 [0/8000 (0%)]\tBatch Loss: 1155.271197\tLearning Rate (w_theta): 0.001000\t TIME:446.3s\n",
      "\t\t\t\tDisc: 1.824238\t\tSym: 21.912535\t\tSpars: 1131.534424\n",
      "\t TVw: -0.525421 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1113 [4000/8000 (50%)]\tBatch Loss: 1196.296054\tLearning Rate (w_theta): 0.001000\t TIME:447.8s\n",
      "\t\t\t\tDisc: 1.901275\t\tSym: 23.995365\t\tSpars: 1170.399414\n",
      "\t TVw: -0.525385 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1113...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1183.8709702035228\n",
      "Average validation loss: 214.11646979843565\n",
      "Training epoch 1114...\n",
      "\n",
      "Train Epoch: 1114 [0/8000 (0%)]\tBatch Loss: 1222.823124\tLearning Rate (w_theta): 0.001000\t TIME:450.2s\n",
      "\t\t\t\tDisc: 2.038181\t\tSym: 24.440338\t\tSpars: 1196.344604\n",
      "\t TVw: -0.525350 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1114 [4000/8000 (50%)]\tBatch Loss: 1197.478350\tLearning Rate (w_theta): 0.001000\t TIME:451.7s\n",
      "\t\t\t\tDisc: 1.915348\t\tSym: 25.161757\t\tSpars: 1170.401245\n",
      "\t TVw: -0.525315 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1114...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1181.1491261209978\n",
      "Average validation loss: 216.22485889330395\n",
      "Training epoch 1115...\n",
      "\n",
      "Train Epoch: 1115 [0/8000 (0%)]\tBatch Loss: 1194.116398\tLearning Rate (w_theta): 0.001000\t TIME:454.0s\n",
      "\t\t\t\tDisc: 1.808067\t\tSym: 23.122417\t\tSpars: 1169.185913\n",
      "\t TVw: -0.525280 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1115 [4000/8000 (50%)]\tBatch Loss: 1191.354665\tLearning Rate (w_theta): 0.001000\t TIME:455.5s\n",
      "\t\t\t\tDisc: 1.809991\t\tSym: 23.997189\t\tSpars: 1165.547485\n",
      "\t TVw: -0.525245 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1115...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1183.905403509656\n",
      "Average validation loss: 218.22192664158553\n",
      "Training epoch 1116...\n",
      "\n",
      "Train Epoch: 1116 [0/8000 (0%)]\tBatch Loss: 1144.467613\tLearning Rate (w_theta): 0.001000\t TIME:457.9s\n",
      "\t\t\t\tDisc: 1.802004\t\tSym: 21.472250\t\tSpars: 1121.193359\n",
      "\t TVw: -0.525209 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1116 [4000/8000 (50%)]\tBatch Loss: 1176.385982\tLearning Rate (w_theta): 0.001000\t TIME:459.4s\n",
      "\t\t\t\tDisc: 1.801885\t\tSym: 23.020254\t\tSpars: 1151.563843\n",
      "\t TVw: -0.525173 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1116...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1188.3821345567053\n",
      "Average validation loss: 223.5049681871975\n",
      "Training epoch 1117...\n",
      "\n",
      "Train Epoch: 1117 [0/8000 (0%)]\tBatch Loss: 1244.670149\tLearning Rate (w_theta): 0.001000\t TIME:461.7s\n",
      "\t\t\t\tDisc: 1.663010\t\tSym: 24.657408\t\tSpars: 1218.349731\n",
      "\t TVw: -0.525137 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1117 [4000/8000 (50%)]\tBatch Loss: 1202.004453\tLearning Rate (w_theta): 0.001000\t TIME:463.2s\n",
      "\t\t\t\tDisc: 2.059463\t\tSym: 25.321455\t\tSpars: 1174.623535\n",
      "\t TVw: -0.525101 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1117...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1205.517568102005\n",
      "Average validation loss: 217.3139868435853\n",
      "Training epoch 1118...\n",
      "\n",
      "Train Epoch: 1118 [0/8000 (0%)]\tBatch Loss: 1219.087602\tLearning Rate (w_theta): 0.001000\t TIME:465.6s\n",
      "\t\t\t\tDisc: 1.905987\t\tSym: 24.867041\t\tSpars: 1192.314575\n",
      "\t TVw: -0.525066 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1118 [4000/8000 (50%)]\tBatch Loss: 1132.331472\tLearning Rate (w_theta): 0.001000\t TIME:467.1s\n",
      "\t\t\t\tDisc: 1.573303\t\tSym: 19.912466\t\tSpars: 1110.845703\n",
      "\t TVw: -0.525031 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1118...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1193.0508622747332\n",
      "Average validation loss: 209.57251817588872\n",
      "Training epoch 1119...\n",
      "\n",
      "Train Epoch: 1119 [0/8000 (0%)]\tBatch Loss: 1191.249571\tLearning Rate (w_theta): 0.001000\t TIME:469.4s\n",
      "\t\t\t\tDisc: 2.049807\t\tSym: 23.666073\t\tSpars: 1165.533691\n",
      "\t TVw: -0.524996 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1119 [4000/8000 (50%)]\tBatch Loss: 1173.129273\tLearning Rate (w_theta): 0.001000\t TIME:470.9s\n",
      "\t\t\t\tDisc: 1.653247\t\tSym: 21.904860\t\tSpars: 1149.571167\n",
      "\t TVw: -0.524960 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1119...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1183.538804324688\n",
      "Average validation loss: 211.05184429373858\n",
      "Training epoch 1120...\n",
      "\n",
      "Train Epoch: 1120 [0/8000 (0%)]\tBatch Loss: 1121.484905\tLearning Rate (w_theta): 0.001000\t TIME:473.3s\n",
      "\t\t\t\tDisc: 1.773439\t\tSym: 20.580118\t\tSpars: 1099.131348\n",
      "\t TVw: -0.524924 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1120 [4000/8000 (50%)]\tBatch Loss: 1143.034640\tLearning Rate (w_theta): 0.001000\t TIME:474.8s\n",
      "\t\t\t\tDisc: 1.707831\t\tSym: 20.740627\t\tSpars: 1120.586182\n",
      "\t TVw: -0.524888 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1120...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1178.562332681585\n",
      "Average validation loss: 212.8156587038351\n",
      "Training epoch 1121...\n",
      "\n",
      "Train Epoch: 1121 [0/8000 (0%)]\tBatch Loss: 1181.783445\tLearning Rate (w_theta): 0.001000\t TIME:477.7s\n",
      "\t\t\t\tDisc: 1.900932\t\tSym: 23.405218\t\tSpars: 1156.477295\n",
      "\t TVw: -0.524852 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1121 [4000/8000 (50%)]\tBatch Loss: 1185.935443\tLearning Rate (w_theta): 0.001000\t TIME:479.2s\n",
      "\t\t\t\tDisc: 1.904317\t\tSym: 22.057981\t\tSpars: 1161.973145\n",
      "\t TVw: -0.524816 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1121...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1183.896238267589\n",
      "Average validation loss: 215.85596415312142\n",
      "Training epoch 1122...\n",
      "\n",
      "Train Epoch: 1122 [0/8000 (0%)]\tBatch Loss: 1138.592008\tLearning Rate (w_theta): 0.001000\t TIME:481.6s\n",
      "\t\t\t\tDisc: 1.720786\t\tSym: 21.141851\t\tSpars: 1115.729370\n",
      "\t TVw: -0.524780 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1122 [4000/8000 (50%)]\tBatch Loss: 1184.404987\tLearning Rate (w_theta): 0.001000\t TIME:483.1s\n",
      "\t\t\t\tDisc: 1.615690\t\tSym: 22.318716\t\tSpars: 1160.470581\n",
      "\t TVw: -0.524744 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1122...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1194.251019563283\n",
      "Average validation loss: 217.69082994262988\n",
      "Training epoch 1123...\n",
      "\n",
      "Train Epoch: 1123 [0/8000 (0%)]\tBatch Loss: 1246.324711\tLearning Rate (w_theta): 0.001000\t TIME:485.5s\n",
      "\t\t\t\tDisc: 1.852972\t\tSym: 25.778135\t\tSpars: 1218.693604\n",
      "\t TVw: -0.524709 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1123 [4000/8000 (50%)]\tBatch Loss: 1174.758409\tLearning Rate (w_theta): 0.001000\t TIME:487.0s\n",
      "\t\t\t\tDisc: 1.808094\t\tSym: 22.878538\t\tSpars: 1150.071777\n",
      "\t TVw: -0.524674 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1123...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1192.6648996468393\n",
      "Average validation loss: 214.24386625210863\n",
      "Training epoch 1124...\n",
      "\n",
      "Train Epoch: 1124 [0/8000 (0%)]\tBatch Loss: 1192.769593\tLearning Rate (w_theta): 0.001000\t TIME:489.3s\n",
      "\t\t\t\tDisc: 1.823030\t\tSym: 23.700714\t\tSpars: 1167.245850\n",
      "\t TVw: -0.524639 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1124 [4000/8000 (50%)]\tBatch Loss: 1196.298461\tLearning Rate (w_theta): 0.001000\t TIME:490.8s\n",
      "\t\t\t\tDisc: 2.120362\t\tSym: 23.984251\t\tSpars: 1170.193848\n",
      "\t TVw: -0.524604 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1124...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1187.083742496101\n",
      "Average validation loss: 215.2244287318781\n",
      "Training epoch 1125...\n",
      "\n",
      "Train Epoch: 1125 [0/8000 (0%)]\tBatch Loss: 1187.599023\tLearning Rate (w_theta): 0.001000\t TIME:493.1s\n",
      "\t\t\t\tDisc: 1.867427\t\tSym: 22.895903\t\tSpars: 1162.835693\n",
      "\t TVw: -0.524568 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1125 [4000/8000 (50%)]\tBatch Loss: 1147.506207\tLearning Rate (w_theta): 0.001000\t TIME:494.6s\n",
      "\t\t\t\tDisc: 1.779322\t\tSym: 21.424517\t\tSpars: 1124.302368\n",
      "\t TVw: -0.524532 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1125...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1182.9559812670175\n",
      "Average validation loss: 219.3004632681228\n",
      "Training epoch 1126...\n",
      "\n",
      "Train Epoch: 1126 [0/8000 (0%)]\tBatch Loss: 1187.891350\tLearning Rate (w_theta): 0.001000\t TIME:497.0s\n",
      "\t\t\t\tDisc: 1.855101\t\tSym: 23.502314\t\tSpars: 1162.533936\n",
      "\t TVw: -0.524496 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1126 [4000/8000 (50%)]\tBatch Loss: 1246.430980\tLearning Rate (w_theta): 0.001000\t TIME:498.5s\n",
      "\t\t\t\tDisc: 2.011818\t\tSym: 27.125950\t\tSpars: 1217.293213\n",
      "\t TVw: -0.524459 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1126...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1180.2516527509006\n",
      "Average validation loss: 214.0682368790541\n",
      "Training epoch 1127...\n",
      "\n",
      "Train Epoch: 1127 [0/8000 (0%)]\tBatch Loss: 1177.282356\tLearning Rate (w_theta): 0.001000\t TIME:500.9s\n",
      "\t\t\t\tDisc: 1.900674\t\tSym: 23.305998\t\tSpars: 1152.075684\n",
      "\t TVw: -0.524423 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1127 [4000/8000 (50%)]\tBatch Loss: 1186.816761\tLearning Rate (w_theta): 0.001000\t TIME:502.4s\n",
      "\t\t\t\tDisc: 1.819153\t\tSym: 23.013599\t\tSpars: 1161.984009\n",
      "\t TVw: -0.524386 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1127...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1178.1259021534054\n",
      "Average validation loss: 214.83526101901026\n",
      "Training epoch 1128...\n",
      "\n",
      "Train Epoch: 1128 [0/8000 (0%)]\tBatch Loss: 1167.467666\tLearning Rate (w_theta): 0.001000\t TIME:504.7s\n",
      "\t\t\t\tDisc: 1.786248\t\tSym: 22.878195\t\tSpars: 1142.803223\n",
      "\t TVw: -0.524349 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1128 [4000/8000 (50%)]\tBatch Loss: 1160.378566\tLearning Rate (w_theta): 0.001000\t TIME:506.2s\n",
      "\t\t\t\tDisc: 1.674863\t\tSym: 22.312834\t\tSpars: 1136.390869\n",
      "\t TVw: -0.524313 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1128...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1180.4301559011028\n",
      "Average validation loss: 213.30593274260698\n",
      "Training epoch 1129...\n",
      "\n",
      "Train Epoch: 1129 [0/8000 (0%)]\tBatch Loss: 1166.686422\tLearning Rate (w_theta): 0.001000\t TIME:508.5s\n",
      "\t\t\t\tDisc: 1.850555\t\tSym: 23.151663\t\tSpars: 1141.684204\n",
      "\t TVw: -0.524275 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1129 [4000/8000 (50%)]\tBatch Loss: 1159.398836\tLearning Rate (w_theta): 0.001000\t TIME:510.1s\n",
      "\t\t\t\tDisc: 1.689342\t\tSym: 21.484518\t\tSpars: 1136.224976\n",
      "\t TVw: -0.524239 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1129...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1182.9998760369015\n",
      "Average validation loss: 215.51534027736312\n",
      "Training epoch 1130...\n",
      "\n",
      "Train Epoch: 1130 [0/8000 (0%)]\tBatch Loss: 1188.345366\tLearning Rate (w_theta): 0.001000\t TIME:512.4s\n",
      "\t\t\t\tDisc: 1.685511\t\tSym: 23.570744\t\tSpars: 1163.089111\n",
      "\t TVw: -0.524202 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1130 [4000/8000 (50%)]\tBatch Loss: 1150.459648\tLearning Rate (w_theta): 0.001000\t TIME:513.9s\n",
      "\t\t\t\tDisc: 1.695451\t\tSym: 21.308142\t\tSpars: 1127.456055\n",
      "\t TVw: -0.524165 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1130...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1185.2818394641224\n",
      "Average validation loss: 211.65748678856656\n",
      "Training epoch 1131...\n",
      "\n",
      "Train Epoch: 1131 [0/8000 (0%)]\tBatch Loss: 1150.895705\tLearning Rate (w_theta): 0.001000\t TIME:517.1s\n",
      "\t\t\t\tDisc: 1.726089\t\tSym: 21.263245\t\tSpars: 1127.906372\n",
      "\t TVw: -0.524129 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1131 [4000/8000 (50%)]\tBatch Loss: 1230.875485\tLearning Rate (w_theta): 0.001000\t TIME:518.6s\n",
      "\t\t\t\tDisc: 2.007018\t\tSym: 25.419615\t\tSpars: 1203.448853\n",
      "\t TVw: -0.524091 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1131...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1184.8644695269395\n",
      "Average validation loss: 213.2393919100989\n",
      "Training epoch 1132...\n",
      "\n",
      "Train Epoch: 1132 [0/8000 (0%)]\tBatch Loss: 1148.857429\tLearning Rate (w_theta): 0.001000\t TIME:520.9s\n",
      "\t\t\t\tDisc: 1.710014\t\tSym: 23.269608\t\tSpars: 1123.877808\n",
      "\t TVw: -0.524054 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1132 [4000/8000 (50%)]\tBatch Loss: 1170.630187\tLearning Rate (w_theta): 0.001000\t TIME:522.4s\n",
      "\t\t\t\tDisc: 1.800284\t\tSym: 22.549507\t\tSpars: 1146.280396\n",
      "\t TVw: -0.524017 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1132...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1177.4700537728384\n",
      "Average validation loss: 211.38714083103156\n",
      "Training epoch 1133...\n",
      "\n",
      "Train Epoch: 1133 [0/8000 (0%)]\tBatch Loss: 1214.003223\tLearning Rate (w_theta): 0.001000\t TIME:524.7s\n",
      "\t\t\t\tDisc: 1.998350\t\tSym: 23.386587\t\tSpars: 1188.618286\n",
      "\t TVw: -0.523979 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1133 [4000/8000 (50%)]\tBatch Loss: 1225.598702\tLearning Rate (w_theta): 0.001000\t TIME:526.2s\n",
      "\t\t\t\tDisc: 1.930749\t\tSym: 25.198471\t\tSpars: 1198.469482\n",
      "\t TVw: -0.523941 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1133...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1176.0886165389054\n",
      "Average validation loss: 213.2615286799089\n",
      "Training epoch 1134...\n",
      "\n",
      "Train Epoch: 1134 [0/8000 (0%)]\tBatch Loss: 1164.848022\tLearning Rate (w_theta): 0.001000\t TIME:528.6s\n",
      "\t\t\t\tDisc: 1.801627\t\tSym: 22.232430\t\tSpars: 1140.813965\n",
      "\t TVw: -0.523903 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1134 [4000/8000 (50%)]\tBatch Loss: 1170.280747\tLearning Rate (w_theta): 0.001000\t TIME:530.1s\n",
      "\t\t\t\tDisc: 1.849090\t\tSym: 22.729509\t\tSpars: 1145.702148\n",
      "\t TVw: -0.523866 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1134...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1174.8605860541702\n",
      "Average validation loss: 213.33351515364745\n",
      "Training epoch 1135...\n",
      "\n",
      "Train Epoch: 1135 [0/8000 (0%)]\tBatch Loss: 1174.506089\tLearning Rate (w_theta): 0.001000\t TIME:532.4s\n",
      "\t\t\t\tDisc: 1.827105\t\tSym: 22.367582\t\tSpars: 1150.311401\n",
      "\t TVw: -0.523828 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1135 [4000/8000 (50%)]\tBatch Loss: 1169.498981\tLearning Rate (w_theta): 0.001000\t TIME:533.9s\n",
      "\t\t\t\tDisc: 1.799886\t\tSym: 23.446165\t\tSpars: 1144.252930\n",
      "\t TVw: -0.523790 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1135...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1174.0350905360428\n",
      "Average validation loss: 211.50097516520435\n",
      "Training epoch 1136...\n",
      "\n",
      "Train Epoch: 1136 [0/8000 (0%)]\tBatch Loss: 1157.656281\tLearning Rate (w_theta): 0.001000\t TIME:536.2s\n",
      "\t\t\t\tDisc: 1.703303\t\tSym: 21.795019\t\tSpars: 1134.157959\n",
      "\t TVw: -0.523752 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1136 [4000/8000 (50%)]\tBatch Loss: 1162.489014\tLearning Rate (w_theta): 0.001000\t TIME:537.7s\n",
      "\t\t\t\tDisc: 1.759448\t\tSym: 22.655592\t\tSpars: 1138.073975\n",
      "\t TVw: -0.523714 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1136...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1171.832243169932\n",
      "Average validation loss: 212.2217533263077\n",
      "Training epoch 1137...\n",
      "\n",
      "Train Epoch: 1137 [0/8000 (0%)]\tBatch Loss: 1165.083977\tLearning Rate (w_theta): 0.001000\t TIME:540.0s\n",
      "\t\t\t\tDisc: 1.723036\t\tSym: 22.586161\t\tSpars: 1140.774780\n",
      "\t TVw: -0.523676 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1137 [4000/8000 (50%)]\tBatch Loss: 1141.842163\tLearning Rate (w_theta): 0.001000\t TIME:541.5s\n",
      "\t\t\t\tDisc: 1.662580\t\tSym: 20.530901\t\tSpars: 1119.648682\n",
      "\t TVw: -0.523637 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1137...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1172.3295520475306\n",
      "Average validation loss: 214.00496356230252\n",
      "Training epoch 1138...\n",
      "\n",
      "Train Epoch: 1138 [0/8000 (0%)]\tBatch Loss: 1157.514453\tLearning Rate (w_theta): 0.001000\t TIME:543.8s\n",
      "\t\t\t\tDisc: 1.723886\t\tSym: 21.550699\t\tSpars: 1134.239868\n",
      "\t TVw: -0.523599 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1138 [4000/8000 (50%)]\tBatch Loss: 1149.634180\tLearning Rate (w_theta): 0.001000\t TIME:545.3s\n",
      "\t\t\t\tDisc: 1.755854\t\tSym: 21.973297\t\tSpars: 1125.905029\n",
      "\t TVw: -0.523561 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1138...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1172.262393424141\n",
      "Average validation loss: 211.3287377806856\n",
      "Training epoch 1139...\n",
      "\n",
      "Train Epoch: 1139 [0/8000 (0%)]\tBatch Loss: 1186.037812\tLearning Rate (w_theta): 0.001000\t TIME:547.7s\n",
      "\t\t\t\tDisc: 1.883975\t\tSym: 22.818876\t\tSpars: 1161.334961\n",
      "\t TVw: -0.523522 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1139 [4000/8000 (50%)]\tBatch Loss: 1185.596896\tLearning Rate (w_theta): 0.001000\t TIME:549.2s\n",
      "\t\t\t\tDisc: 1.847339\t\tSym: 22.998581\t\tSpars: 1160.750977\n",
      "\t TVw: -0.523484 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1139...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1171.803957181049\n",
      "Average validation loss: 211.00767705370498\n",
      "Training epoch 1140...\n",
      "\n",
      "Train Epoch: 1140 [0/8000 (0%)]\tBatch Loss: 1158.496074\tLearning Rate (w_theta): 0.001000\t TIME:551.5s\n",
      "\t\t\t\tDisc: 1.775445\t\tSym: 21.168505\t\tSpars: 1135.552124\n",
      "\t TVw: -0.523445 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1140 [4000/8000 (50%)]\tBatch Loss: 1220.840386\tLearning Rate (w_theta): 0.001000\t TIME:553.0s\n",
      "\t\t\t\tDisc: 1.925301\t\tSym: 25.188034\t\tSpars: 1193.727051\n",
      "\t TVw: -0.523406 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1140...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1174.373552487109\n",
      "Average validation loss: 213.03194756146272\n",
      "Training epoch 1141...\n",
      "\n",
      "Train Epoch: 1141 [0/8000 (0%)]\tBatch Loss: 1138.837479\tLearning Rate (w_theta): 0.001000\t TIME:556.0s\n",
      "\t\t\t\tDisc: 1.634443\t\tSym: 21.479280\t\tSpars: 1115.723755\n",
      "\t TVw: -0.523368 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1141 [4000/8000 (50%)]\tBatch Loss: 1184.904934\tLearning Rate (w_theta): 0.001000\t TIME:557.5s\n",
      "\t\t\t\tDisc: 1.813139\t\tSym: 22.237913\t\tSpars: 1160.853882\n",
      "\t TVw: -0.523329 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1141...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1174.1661379379498\n",
      "Average validation loss: 209.5588129207647\n",
      "Training epoch 1142...\n",
      "\n",
      "Train Epoch: 1142 [0/8000 (0%)]\tBatch Loss: 1197.666944\tLearning Rate (w_theta): 0.001000\t TIME:559.8s\n",
      "\t\t\t\tDisc: 1.780508\t\tSym: 23.465050\t\tSpars: 1172.421387\n",
      "\t TVw: -0.523290 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1142 [4000/8000 (50%)]\tBatch Loss: 1201.084489\tLearning Rate (w_theta): 0.001000\t TIME:561.3s\n",
      "\t\t\t\tDisc: 1.729373\t\tSym: 23.516981\t\tSpars: 1175.838135\n",
      "\t TVw: -0.523251 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1142...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1171.3418449180926\n",
      "Average validation loss: 209.83945744105128\n",
      "Training epoch 1143...\n",
      "\n",
      "Train Epoch: 1143 [0/8000 (0%)]\tBatch Loss: 1156.965620\tLearning Rate (w_theta): 0.001000\t TIME:563.6s\n",
      "\t\t\t\tDisc: 1.631155\t\tSym: 20.823601\t\tSpars: 1134.510864\n",
      "\t TVw: -0.523212 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1143 [4000/8000 (50%)]\tBatch Loss: 1190.994794\tLearning Rate (w_theta): 0.001000\t TIME:565.1s\n",
      "\t\t\t\tDisc: 2.017482\t\tSym: 23.732683\t\tSpars: 1165.244629\n",
      "\t TVw: -0.523173 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1143...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1183.1632237628123\n",
      "Average validation loss: 213.40934101229038\n",
      "Training epoch 1144...\n",
      "\n",
      "Train Epoch: 1144 [0/8000 (0%)]\tBatch Loss: 1215.686605\tLearning Rate (w_theta): 0.001000\t TIME:567.4s\n",
      "\t\t\t\tDisc: 2.030443\t\tSym: 25.087437\t\tSpars: 1188.568726\n",
      "\t TVw: -0.523134 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1144 [4000/8000 (50%)]\tBatch Loss: 1160.061086\tLearning Rate (w_theta): 0.001000\t TIME:568.9s\n",
      "\t\t\t\tDisc: 1.705058\t\tSym: 21.105783\t\tSpars: 1137.250244\n",
      "\t TVw: -0.523096 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1144...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1173.352794381674\n",
      "Average validation loss: 209.29219131634056\n",
      "Training epoch 1145...\n",
      "\n",
      "Train Epoch: 1145 [0/8000 (0%)]\tBatch Loss: 1235.656624\tLearning Rate (w_theta): 0.001000\t TIME:571.2s\n",
      "\t\t\t\tDisc: 2.129154\t\tSym: 25.988529\t\tSpars: 1207.538940\n",
      "\t TVw: -0.523057 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1145 [4000/8000 (50%)]\tBatch Loss: 1146.175398\tLearning Rate (w_theta): 0.001000\t TIME:572.7s\n",
      "\t\t\t\tDisc: 1.648848\t\tSym: 21.260559\t\tSpars: 1123.265991\n",
      "\t TVw: -0.523018 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1145...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1174.4280669673956\n",
      "Average validation loss: 209.02341009238654\n",
      "Training epoch 1146...\n",
      "\n",
      "Train Epoch: 1146 [0/8000 (0%)]\tBatch Loss: 1172.104058\tLearning Rate (w_theta): 0.001000\t TIME:575.1s\n",
      "\t\t\t\tDisc: 1.715874\t\tSym: 22.313477\t\tSpars: 1148.074707\n",
      "\t TVw: -0.522979 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1146 [4000/8000 (50%)]\tBatch Loss: 1148.709966\tLearning Rate (w_theta): 0.001000\t TIME:576.6s\n",
      "\t\t\t\tDisc: 1.784242\t\tSym: 21.561344\t\tSpars: 1125.364380\n",
      "\t TVw: -0.522940 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1146...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1171.7236465924202\n",
      "Average validation loss: 209.38011028662967\n",
      "Training epoch 1147...\n",
      "\n",
      "Train Epoch: 1147 [0/8000 (0%)]\tBatch Loss: 1188.966514\tLearning Rate (w_theta): 0.001000\t TIME:578.9s\n",
      "\t\t\t\tDisc: 1.737653\t\tSym: 22.503153\t\tSpars: 1164.725708\n",
      "\t TVw: -0.522900 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1147 [4000/8000 (50%)]\tBatch Loss: 1135.871353\tLearning Rate (w_theta): 0.001000\t TIME:580.4s\n",
      "\t\t\t\tDisc: 1.680998\t\tSym: 21.920824\t\tSpars: 1112.269531\n",
      "\t TVw: -0.522860 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1147...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1175.2721497723992\n",
      "Average validation loss: 214.04159449040483\n",
      "Training epoch 1148...\n",
      "\n",
      "Train Epoch: 1148 [0/8000 (0%)]\tBatch Loss: 1150.473806\tLearning Rate (w_theta): 0.001000\t TIME:582.7s\n",
      "\t\t\t\tDisc: 1.823896\t\tSym: 22.256355\t\tSpars: 1126.393555\n",
      "\t TVw: -0.522820 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1148 [4000/8000 (50%)]\tBatch Loss: 1155.656752\tLearning Rate (w_theta): 0.001000\t TIME:584.3s\n",
      "\t\t\t\tDisc: 1.682164\t\tSym: 21.766336\t\tSpars: 1132.208252\n",
      "\t TVw: -0.522781 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1148...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1172.5684703271354\n",
      "Average validation loss: 211.75693022819425\n",
      "Training epoch 1149...\n",
      "\n",
      "Train Epoch: 1149 [0/8000 (0%)]\tBatch Loss: 1139.087879\tLearning Rate (w_theta): 0.001000\t TIME:586.6s\n",
      "\t\t\t\tDisc: 1.660299\t\tSym: 19.995329\t\tSpars: 1117.432251\n",
      "\t TVw: -0.522741 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1149 [4000/8000 (50%)]\tBatch Loss: 1199.362602\tLearning Rate (w_theta): 0.001000\t TIME:588.1s\n",
      "\t\t\t\tDisc: 1.759882\t\tSym: 24.155943\t\tSpars: 1173.446777\n",
      "\t TVw: -0.522701 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1149...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1176.064048389789\n",
      "Average validation loss: 217.46947701915008\n",
      "Training epoch 1150...\n",
      "\n",
      "Train Epoch: 1150 [0/8000 (0%)]\tBatch Loss: 1185.268375\tLearning Rate (w_theta): 0.001000\t TIME:590.5s\n",
      "\t\t\t\tDisc: 1.535444\t\tSym: 21.762838\t\tSpars: 1161.970093\n",
      "\t TVw: -0.522661 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1150 [4000/8000 (50%)]\tBatch Loss: 1128.099983\tLearning Rate (w_theta): 0.001000\t TIME:592.0s\n",
      "\t\t\t\tDisc: 1.606637\t\tSym: 21.237486\t\tSpars: 1105.255859\n",
      "\t TVw: -0.522623 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1150...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1176.3503550168034\n",
      "Average validation loss: 211.98699548542098\n",
      "Training epoch 1151...\n",
      "\n",
      "Train Epoch: 1151 [0/8000 (0%)]\tBatch Loss: 1198.525662\tLearning Rate (w_theta): 0.001000\t TIME:595.0s\n",
      "\t\t\t\tDisc: 1.785847\t\tSym: 24.260201\t\tSpars: 1172.479614\n",
      "\t TVw: -0.522583 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1151 [4000/8000 (50%)]\tBatch Loss: 1185.202522\tLearning Rate (w_theta): 0.001000\t TIME:596.5s\n",
      "\t\t\t\tDisc: 1.765841\t\tSym: 23.753576\t\tSpars: 1159.683105\n",
      "\t TVw: -0.522543 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1151...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1169.6969847210253\n",
      "Average validation loss: 208.97706925725063\n",
      "Training epoch 1152...\n",
      "\n",
      "Train Epoch: 1152 [0/8000 (0%)]\tBatch Loss: 1197.791968\tLearning Rate (w_theta): 0.001000\t TIME:598.8s\n",
      "\t\t\t\tDisc: 1.812972\t\tSym: 24.330803\t\tSpars: 1171.648193\n",
      "\t TVw: -0.522502 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1152 [4000/8000 (50%)]\tBatch Loss: 1175.379079\tLearning Rate (w_theta): 0.001000\t TIME:600.3s\n",
      "\t\t\t\tDisc: 1.696830\t\tSym: 21.990110\t\tSpars: 1151.692139\n",
      "\t TVw: -0.522462 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1152...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1170.7965870674777\n",
      "Average validation loss: 208.4229424234804\n",
      "Training epoch 1153...\n",
      "\n",
      "Train Epoch: 1153 [0/8000 (0%)]\tBatch Loss: 1161.272629\tLearning Rate (w_theta): 0.001000\t TIME:602.7s\n",
      "\t\t\t\tDisc: 1.761664\t\tSym: 23.246927\t\tSpars: 1136.264038\n",
      "\t TVw: -0.522422 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1153 [4000/8000 (50%)]\tBatch Loss: 1188.605989\tLearning Rate (w_theta): 0.001000\t TIME:604.2s\n",
      "\t\t\t\tDisc: 2.030272\t\tSym: 23.357700\t\tSpars: 1163.218018\n",
      "\t TVw: -0.522382 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1153...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1175.9876207123357\n",
      "Average validation loss: 207.20210930165038\n",
      "Training epoch 1154...\n",
      "\n",
      "Train Epoch: 1154 [0/8000 (0%)]\tBatch Loss: 1174.742140\tLearning Rate (w_theta): 0.001000\t TIME:606.5s\n",
      "\t\t\t\tDisc: 1.838257\t\tSym: 22.272779\t\tSpars: 1150.631104\n",
      "\t TVw: -0.522343 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1154 [4000/8000 (50%)]\tBatch Loss: 1198.862540\tLearning Rate (w_theta): 0.001000\t TIME:608.0s\n",
      "\t\t\t\tDisc: 2.031087\t\tSym: 24.362947\t\tSpars: 1172.468506\n",
      "\t TVw: -0.522303 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1154...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1202.6232839252039\n",
      "Average validation loss: 205.02165538118118\n",
      "Training epoch 1155...\n",
      "\n",
      "Train Epoch: 1155 [0/8000 (0%)]\tBatch Loss: 1230.338723\tLearning Rate (w_theta): 0.001000\t TIME:610.3s\n",
      "\t\t\t\tDisc: 1.825839\t\tSym: 22.437445\t\tSpars: 1206.075439\n",
      "\t TVw: -0.522264 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1155 [4000/8000 (50%)]\tBatch Loss: 1242.487961\tLearning Rate (w_theta): 0.001000\t TIME:611.8s\n",
      "\t\t\t\tDisc: 2.054062\t\tSym: 24.053406\t\tSpars: 1216.380493\n",
      "\t TVw: -0.522226 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1155...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1244.7075211828096\n",
      "Average validation loss: 214.7035425747184\n",
      "Training epoch 1156...\n",
      "\n",
      "Train Epoch: 1156 [0/8000 (0%)]\tBatch Loss: 1242.347627\tLearning Rate (w_theta): 0.001000\t TIME:614.1s\n",
      "\t\t\t\tDisc: 1.511430\t\tSym: 26.571060\t\tSpars: 1214.265137\n",
      "\t TVw: -0.522190 | TVb: -2.043251 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1156 [4000/8000 (50%)]\tBatch Loss: 1191.050715\tLearning Rate (w_theta): 0.001000\t TIME:615.6s\n",
      "\t\t\t\tDisc: 1.616816\t\tSym: 22.818542\t\tSpars: 1166.615356\n",
      "\t TVw: -0.522156 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1156...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1225.2488211206771\n",
      "Average validation loss: 201.5287668884867\n",
      "Training epoch 1157...\n",
      "\n",
      "Train Epoch: 1157 [0/8000 (0%)]\tBatch Loss: 1254.470635\tLearning Rate (w_theta): 0.001000\t TIME:617.9s\n",
      "\t\t\t\tDisc: 2.104451\t\tSym: 26.424412\t\tSpars: 1225.941772\n",
      "\t TVw: -0.522121 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1157 [4000/8000 (50%)]\tBatch Loss: 1235.234576\tLearning Rate (w_theta): 0.001000\t TIME:619.4s\n",
      "\t\t\t\tDisc: 1.585483\t\tSym: 23.631027\t\tSpars: 1210.018066\n",
      "\t TVw: -0.522084 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1157...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1196.2698205503602\n",
      "Average validation loss: 200.88738798421122\n",
      "Training epoch 1158...\n",
      "\n",
      "Train Epoch: 1158 [0/8000 (0%)]\tBatch Loss: 1177.296018\tLearning Rate (w_theta): 0.001000\t TIME:621.8s\n",
      "\t\t\t\tDisc: 1.849754\t\tSym: 22.748755\t\tSpars: 1152.697510\n",
      "\t TVw: -0.522043 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1158 [4000/8000 (50%)]\tBatch Loss: 1189.696965\tLearning Rate (w_theta): 0.001000\t TIME:623.3s\n",
      "\t\t\t\tDisc: 1.524388\t\tSym: 22.505585\t\tSpars: 1165.666992\n",
      "\t TVw: -0.522002 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1158...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1181.8023501759933\n",
      "Average validation loss: 205.8107915220821\n",
      "Training epoch 1159...\n",
      "\n",
      "Train Epoch: 1159 [0/8000 (0%)]\tBatch Loss: 1122.930748\tLearning Rate (w_theta): 0.001000\t TIME:625.7s\n",
      "\t\t\t\tDisc: 1.580607\t\tSym: 20.895185\t\tSpars: 1100.454956\n",
      "\t TVw: -0.521959 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1159 [4000/8000 (50%)]\tBatch Loss: 1190.751697\tLearning Rate (w_theta): 0.001000\t TIME:627.2s\n",
      "\t\t\t\tDisc: 1.647268\t\tSym: 22.629576\t\tSpars: 1166.474854\n",
      "\t TVw: -0.521916 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1159...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1176.075449747318\n",
      "Average validation loss: 205.8754529012262\n",
      "Training epoch 1160...\n",
      "\n",
      "Train Epoch: 1160 [0/8000 (0%)]\tBatch Loss: 1187.845505\tLearning Rate (w_theta): 0.001000\t TIME:629.5s\n",
      "\t\t\t\tDisc: 1.857905\t\tSym: 22.878103\t\tSpars: 1163.109497\n",
      "\t TVw: -0.521873 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1160 [4000/8000 (50%)]\tBatch Loss: 1178.104355\tLearning Rate (w_theta): 0.001000\t TIME:631.0s\n",
      "\t\t\t\tDisc: 1.614342\t\tSym: 21.823631\t\tSpars: 1154.666382\n",
      "\t TVw: -0.521831 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1160...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1178.008080338468\n",
      "Average validation loss: 205.55735980838102\n",
      "Training epoch 1161...\n",
      "\n",
      "Train Epoch: 1161 [0/8000 (0%)]\tBatch Loss: 1208.328193\tLearning Rate (w_theta): 0.001000\t TIME:634.0s\n",
      "\t\t\t\tDisc: 1.962585\t\tSym: 23.596443\t\tSpars: 1182.769165\n",
      "\t TVw: -0.521790 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1161 [4000/8000 (50%)]\tBatch Loss: 1169.426035\tLearning Rate (w_theta): 0.001000\t TIME:635.5s\n",
      "\t\t\t\tDisc: 1.773190\t\tSym: 22.286757\t\tSpars: 1145.366089\n",
      "\t TVw: -0.521749 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1161...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1171.641731989834\n",
      "Average validation loss: 206.63346651878877\n",
      "Training epoch 1162...\n",
      "\n",
      "Train Epoch: 1162 [0/8000 (0%)]\tBatch Loss: 1193.629616\tLearning Rate (w_theta): 0.001000\t TIME:637.8s\n",
      "\t\t\t\tDisc: 1.698404\t\tSym: 22.716734\t\tSpars: 1169.214478\n",
      "\t TVw: -0.521707 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1162 [4000/8000 (50%)]\tBatch Loss: 1151.004899\tLearning Rate (w_theta): 0.001000\t TIME:639.3s\n",
      "\t\t\t\tDisc: 1.608277\t\tSym: 21.218643\t\tSpars: 1128.177979\n",
      "\t TVw: -0.521665 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1162...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1166.8313270362398\n",
      "Average validation loss: 208.62722844220514\n",
      "Training epoch 1163...\n",
      "\n",
      "Train Epoch: 1163 [0/8000 (0%)]\tBatch Loss: 1137.857044\tLearning Rate (w_theta): 0.001000\t TIME:641.6s\n",
      "\t\t\t\tDisc: 1.583700\t\tSym: 20.452421\t\tSpars: 1115.820923\n",
      "\t TVw: -0.521623 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1163 [4000/8000 (50%)]\tBatch Loss: 1144.920852\tLearning Rate (w_theta): 0.001000\t TIME:643.1s\n",
      "\t\t\t\tDisc: 1.679338\t\tSym: 21.781553\t\tSpars: 1121.459961\n",
      "\t TVw: -0.521580 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1163...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1166.618834795601\n",
      "Average validation loss: 210.10145381684706\n",
      "Training epoch 1164...\n",
      "\n",
      "Train Epoch: 1164 [0/8000 (0%)]\tBatch Loss: 1147.887130\tLearning Rate (w_theta): 0.001000\t TIME:645.4s\n",
      "\t\t\t\tDisc: 1.695893\t\tSym: 21.997999\t\tSpars: 1124.193237\n",
      "\t TVw: -0.521537 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1164 [4000/8000 (50%)]\tBatch Loss: 1181.820076\tLearning Rate (w_theta): 0.001000\t TIME:646.9s\n",
      "\t\t\t\tDisc: 1.820704\t\tSym: 23.895247\t\tSpars: 1156.104126\n",
      "\t TVw: -0.521494 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1164...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1165.2450623508994\n",
      "Average validation loss: 207.93985537962567\n",
      "Training epoch 1165...\n",
      "\n",
      "Train Epoch: 1165 [0/8000 (0%)]\tBatch Loss: 1140.521355\tLearning Rate (w_theta): 0.001000\t TIME:649.3s\n",
      "\t\t\t\tDisc: 1.761938\t\tSym: 22.235247\t\tSpars: 1116.524170\n",
      "\t TVw: -0.521452 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1165 [4000/8000 (50%)]\tBatch Loss: 1155.581618\tLearning Rate (w_theta): 0.001000\t TIME:650.8s\n",
      "\t\t\t\tDisc: 1.663544\t\tSym: 21.569319\t\tSpars: 1132.348755\n",
      "\t TVw: -0.521410 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1165...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1163.900228107321\n",
      "Average validation loss: 208.97082631912633\n",
      "Training epoch 1166...\n",
      "\n",
      "Train Epoch: 1166 [0/8000 (0%)]\tBatch Loss: 1144.353745\tLearning Rate (w_theta): 0.001000\t TIME:653.1s\n",
      "\t\t\t\tDisc: 1.666743\t\tSym: 22.067862\t\tSpars: 1120.619141\n",
      "\t TVw: -0.521368 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1166 [4000/8000 (50%)]\tBatch Loss: 1167.525628\tLearning Rate (w_theta): 0.001000\t TIME:654.6s\n",
      "\t\t\t\tDisc: 1.669749\t\tSym: 21.455244\t\tSpars: 1144.400635\n",
      "\t TVw: -0.521325 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1166...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1163.8421309637724\n",
      "Average validation loss: 208.6504255024511\n",
      "Training epoch 1167...\n",
      "\n",
      "Train Epoch: 1167 [0/8000 (0%)]\tBatch Loss: 1206.646022\tLearning Rate (w_theta): 0.001000\t TIME:657.0s\n",
      "\t\t\t\tDisc: 1.850858\t\tSym: 24.238401\t\tSpars: 1180.556763\n",
      "\t TVw: -0.521282 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1167 [4000/8000 (50%)]\tBatch Loss: 1177.468311\tLearning Rate (w_theta): 0.001000\t TIME:658.5s\n",
      "\t\t\t\tDisc: 1.790653\t\tSym: 23.474167\t\tSpars: 1152.203491\n",
      "\t TVw: -0.521239 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1167...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1163.1483788866242\n",
      "Average validation loss: 208.72577460190914\n",
      "Training epoch 1168...\n",
      "\n",
      "Train Epoch: 1168 [0/8000 (0%)]\tBatch Loss: 1142.947257\tLearning Rate (w_theta): 0.001000\t TIME:660.8s\n",
      "\t\t\t\tDisc: 1.656367\t\tSym: 22.619625\t\tSpars: 1118.671265\n",
      "\t TVw: -0.521196 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1168 [4000/8000 (50%)]\tBatch Loss: 1171.825140\tLearning Rate (w_theta): 0.001000\t TIME:662.3s\n",
      "\t\t\t\tDisc: 1.654213\t\tSym: 21.941435\t\tSpars: 1148.229492\n",
      "\t TVw: -0.521153 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1168...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1163.1617334928965\n",
      "Average validation loss: 208.74505025016614\n",
      "Training epoch 1169...\n",
      "\n",
      "Train Epoch: 1169 [0/8000 (0%)]\tBatch Loss: 1184.239741\tLearning Rate (w_theta): 0.001000\t TIME:664.7s\n",
      "\t\t\t\tDisc: 1.886395\t\tSym: 25.014967\t\tSpars: 1157.338379\n",
      "\t TVw: -0.521110 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1169 [4000/8000 (50%)]\tBatch Loss: 1143.525595\tLearning Rate (w_theta): 0.001000\t TIME:666.2s\n",
      "\t\t\t\tDisc: 1.570706\t\tSym: 20.938044\t\tSpars: 1121.016846\n",
      "\t TVw: -0.521066 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1169...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1163.597936957275\n",
      "Average validation loss: 206.3784862136898\n",
      "Training epoch 1170...\n",
      "\n",
      "Train Epoch: 1170 [0/8000 (0%)]\tBatch Loss: 1163.928272\tLearning Rate (w_theta): 0.001000\t TIME:668.6s\n",
      "\t\t\t\tDisc: 1.673078\t\tSym: 22.806585\t\tSpars: 1139.448608\n",
      "\t TVw: -0.521024 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1170 [4000/8000 (50%)]\tBatch Loss: 1170.627058\tLearning Rate (w_theta): 0.001000\t TIME:670.1s\n",
      "\t\t\t\tDisc: 1.779652\t\tSym: 23.380243\t\tSpars: 1145.467163\n",
      "\t TVw: -0.520980 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1170...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1162.6209973456148\n",
      "Average validation loss: 206.83407902189182\n",
      "Training epoch 1171...\n",
      "\n",
      "Train Epoch: 1171 [0/8000 (0%)]\tBatch Loss: 1181.756697\tLearning Rate (w_theta): 0.001000\t TIME:673.2s\n",
      "\t\t\t\tDisc: 1.734452\t\tSym: 23.743193\t\tSpars: 1156.279053\n",
      "\t TVw: -0.520937 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1171 [4000/8000 (50%)]\tBatch Loss: 1140.504326\tLearning Rate (w_theta): 0.001000\t TIME:674.7s\n",
      "\t\t\t\tDisc: 1.619501\t\tSym: 20.631041\t\tSpars: 1118.253784\n",
      "\t TVw: -0.520894 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1171...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1163.823729874174\n",
      "Average validation loss: 208.05043088708402\n",
      "Training epoch 1172...\n",
      "\n",
      "Train Epoch: 1172 [0/8000 (0%)]\tBatch Loss: 1167.949788\tLearning Rate (w_theta): 0.001000\t TIME:677.0s\n",
      "\t\t\t\tDisc: 1.671652\t\tSym: 21.695982\t\tSpars: 1144.582153\n",
      "\t TVw: -0.520850 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1172 [4000/8000 (50%)]\tBatch Loss: 1167.770322\tLearning Rate (w_theta): 0.001000\t TIME:678.5s\n",
      "\t\t\t\tDisc: 1.702335\t\tSym: 22.947748\t\tSpars: 1143.120239\n",
      "\t TVw: -0.520806 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1172...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1161.287164674172\n",
      "Average validation loss: 205.99460131110004\n",
      "Training epoch 1173...\n",
      "\n",
      "Train Epoch: 1173 [0/8000 (0%)]\tBatch Loss: 1178.303117\tLearning Rate (w_theta): 0.001000\t TIME:680.9s\n",
      "\t\t\t\tDisc: 1.797740\t\tSym: 23.985846\t\tSpars: 1152.519531\n",
      "\t TVw: -0.520763 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1173 [4000/8000 (50%)]\tBatch Loss: 1132.575964\tLearning Rate (w_theta): 0.001000\t TIME:682.4s\n",
      "\t\t\t\tDisc: 1.584511\t\tSym: 20.008787\t\tSpars: 1110.982666\n",
      "\t TVw: -0.520719 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1173...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1162.2500340188697\n",
      "Average validation loss: 204.58247690166706\n",
      "Training epoch 1174...\n",
      "\n",
      "Train Epoch: 1174 [0/8000 (0%)]\tBatch Loss: 1199.257958\tLearning Rate (w_theta): 0.001000\t TIME:684.8s\n",
      "\t\t\t\tDisc: 1.879654\t\tSym: 23.581917\t\tSpars: 1173.796387\n",
      "\t TVw: -0.520675 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1174 [4000/8000 (50%)]\tBatch Loss: 1209.199188\tLearning Rate (w_theta): 0.001000\t TIME:686.3s\n",
      "\t\t\t\tDisc: 1.768984\t\tSym: 23.884184\t\tSpars: 1183.546021\n",
      "\t TVw: -0.520631 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1174...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1169.8999709859797\n",
      "Average validation loss: 206.29332834552605\n",
      "Training epoch 1175...\n",
      "\n",
      "Train Epoch: 1175 [0/8000 (0%)]\tBatch Loss: 1150.127314\tLearning Rate (w_theta): 0.001000\t TIME:688.7s\n",
      "\t\t\t\tDisc: 1.895379\t\tSym: 22.800173\t\tSpars: 1125.431763\n",
      "\t TVw: -0.520587 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1175 [4000/8000 (50%)]\tBatch Loss: 1177.245376\tLearning Rate (w_theta): 0.001000\t TIME:690.2s\n",
      "\t\t\t\tDisc: 1.775029\t\tSym: 23.481089\t\tSpars: 1151.989258\n",
      "\t TVw: -0.520544 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1175...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1167.430790067921\n",
      "Average validation loss: 209.11090803051817\n",
      "Training epoch 1176...\n",
      "\n",
      "Train Epoch: 1176 [0/8000 (0%)]\tBatch Loss: 1140.723710\tLearning Rate (w_theta): 0.001000\t TIME:692.5s\n",
      "\t\t\t\tDisc: 1.592313\t\tSym: 20.604176\t\tSpars: 1118.527222\n",
      "\t TVw: -0.520501 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1176 [4000/8000 (50%)]\tBatch Loss: 1154.010636\tLearning Rate (w_theta): 0.001000\t TIME:694.1s\n",
      "\t\t\t\tDisc: 1.587268\t\tSym: 22.102934\t\tSpars: 1130.320435\n",
      "\t TVw: -0.520457 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1176...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1163.6777815719192\n",
      "Average validation loss: 207.31591438780254\n",
      "Training epoch 1177...\n",
      "\n",
      "Train Epoch: 1177 [0/8000 (0%)]\tBatch Loss: 1116.677325\tLearning Rate (w_theta): 0.001000\t TIME:696.4s\n",
      "\t\t\t\tDisc: 1.564822\t\tSym: 19.577713\t\tSpars: 1095.534790\n",
      "\t TVw: -0.520413 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1177 [4000/8000 (50%)]\tBatch Loss: 1150.001600\tLearning Rate (w_theta): 0.001000\t TIME:697.9s\n",
      "\t\t\t\tDisc: 1.658756\t\tSym: 22.649485\t\tSpars: 1125.693359\n",
      "\t TVw: -0.520368 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1177...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1160.3839144250576\n",
      "Average validation loss: 207.07396459425024\n",
      "Training epoch 1178...\n",
      "\n",
      "Train Epoch: 1178 [0/8000 (0%)]\tBatch Loss: 1171.002239\tLearning Rate (w_theta): 0.001000\t TIME:700.4s\n",
      "\t\t\t\tDisc: 1.656445\t\tSym: 22.734344\t\tSpars: 1146.611450\n",
      "\t TVw: -0.520324 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1178 [4000/8000 (50%)]\tBatch Loss: 1135.684504\tLearning Rate (w_theta): 0.001000\t TIME:701.9s\n",
      "\t\t\t\tDisc: 1.677131\t\tSym: 21.529346\t\tSpars: 1112.478027\n",
      "\t TVw: -0.520279 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1178...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1160.552641712072\n",
      "Average validation loss: 204.2990039054861\n",
      "Training epoch 1179...\n",
      "\n",
      "Train Epoch: 1179 [0/8000 (0%)]\tBatch Loss: 1182.497903\tLearning Rate (w_theta): 0.001000\t TIME:704.3s\n",
      "\t\t\t\tDisc: 1.757370\t\tSym: 24.158991\t\tSpars: 1156.581543\n",
      "\t TVw: -0.520234 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1179 [4000/8000 (50%)]\tBatch Loss: 1229.112313\tLearning Rate (w_theta): 0.001000\t TIME:705.8s\n",
      "\t\t\t\tDisc: 1.688827\t\tSym: 24.773829\t\tSpars: 1202.649658\n",
      "\t TVw: -0.520190 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1179...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1172.8777392143681\n",
      "Average validation loss: 205.65152938320247\n",
      "Training epoch 1180...\n",
      "\n",
      "Train Epoch: 1180 [0/8000 (0%)]\tBatch Loss: 1167.398238\tLearning Rate (w_theta): 0.001000\t TIME:708.1s\n",
      "\t\t\t\tDisc: 1.881007\t\tSym: 22.874897\t\tSpars: 1142.642334\n",
      "\t TVw: -0.520146 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1180 [4000/8000 (50%)]\tBatch Loss: 1195.824148\tLearning Rate (w_theta): 0.001000\t TIME:709.7s\n",
      "\t\t\t\tDisc: 1.942363\t\tSym: 22.553537\t\tSpars: 1171.328247\n",
      "\t TVw: -0.520102 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1180...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1172.6327696008818\n",
      "Average validation loss: 210.69021470783505\n",
      "Training epoch 1181...\n",
      "\n",
      "Train Epoch: 1181 [0/8000 (0%)]\tBatch Loss: 1157.332915\tLearning Rate (w_theta): 0.001000\t TIME:712.7s\n",
      "\t\t\t\tDisc: 1.626559\t\tSym: 21.909969\t\tSpars: 1133.796387\n",
      "\t TVw: -0.520058 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1181 [4000/8000 (50%)]\tBatch Loss: 1176.621096\tLearning Rate (w_theta): 0.001000\t TIME:714.2s\n",
      "\t\t\t\tDisc: 1.757292\t\tSym: 23.375645\t\tSpars: 1151.488159\n",
      "\t TVw: -0.520013 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1181...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1163.7202080169386\n",
      "Average validation loss: 207.4745773190438\n",
      "Training epoch 1182...\n",
      "\n",
      "Train Epoch: 1182 [0/8000 (0%)]\tBatch Loss: 1129.994914\tLearning Rate (w_theta): 0.001000\t TIME:716.6s\n",
      "\t\t\t\tDisc: 1.499947\t\tSym: 20.646456\t\tSpars: 1107.848511\n",
      "\t TVw: -0.519969 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1182 [4000/8000 (50%)]\tBatch Loss: 1124.596185\tLearning Rate (w_theta): 0.001000\t TIME:718.1s\n",
      "\t\t\t\tDisc: 1.508907\t\tSym: 19.783812\t\tSpars: 1103.303467\n",
      "\t TVw: -0.519924 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1182...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1158.7292638569957\n",
      "Average validation loss: 205.86323031720116\n",
      "Training epoch 1183...\n",
      "\n",
      "Train Epoch: 1183 [0/8000 (0%)]\tBatch Loss: 1159.151663\tLearning Rate (w_theta): 0.001000\t TIME:720.4s\n",
      "\t\t\t\tDisc: 1.517054\t\tSym: 21.723843\t\tSpars: 1135.910767\n",
      "\t TVw: -0.519878 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1183 [4000/8000 (50%)]\tBatch Loss: 1177.953277\tLearning Rate (w_theta): 0.001000\t TIME:722.0s\n",
      "\t\t\t\tDisc: 1.719979\t\tSym: 22.797628\t\tSpars: 1153.435669\n",
      "\t TVw: -0.519833 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1183...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1159.54221366411\n",
      "Average validation loss: 205.66692741099072\n",
      "Training epoch 1184...\n",
      "\n",
      "Train Epoch: 1184 [0/8000 (0%)]\tBatch Loss: 1184.129575\tLearning Rate (w_theta): 0.001000\t TIME:724.3s\n",
      "\t\t\t\tDisc: 1.735052\t\tSym: 24.547600\t\tSpars: 1157.846924\n",
      "\t TVw: -0.519787 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1184 [4000/8000 (50%)]\tBatch Loss: 1151.858808\tLearning Rate (w_theta): 0.001000\t TIME:725.8s\n",
      "\t\t\t\tDisc: 1.596485\t\tSym: 20.597651\t\tSpars: 1129.664673\n",
      "\t TVw: -0.519742 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1184...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1157.8341503036359\n",
      "Average validation loss: 203.45753158609597\n",
      "Training epoch 1185...\n",
      "\n",
      "Train Epoch: 1185 [0/8000 (0%)]\tBatch Loss: 1186.154150\tLearning Rate (w_theta): 0.001000\t TIME:728.1s\n",
      "\t\t\t\tDisc: 1.748160\t\tSym: 23.687851\t\tSpars: 1160.718140\n",
      "\t TVw: -0.519697 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1185 [4000/8000 (50%)]\tBatch Loss: 1149.315186\tLearning Rate (w_theta): 0.001000\t TIME:729.7s\n",
      "\t\t\t\tDisc: 1.713313\t\tSym: 22.095037\t\tSpars: 1125.506836\n",
      "\t TVw: -0.519651 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1185...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1160.046261374545\n",
      "Average validation loss: 206.2311273327502\n",
      "Training epoch 1186...\n",
      "\n",
      "Train Epoch: 1186 [0/8000 (0%)]\tBatch Loss: 1142.521370\tLearning Rate (w_theta): 0.001000\t TIME:732.1s\n",
      "\t\t\t\tDisc: 1.734002\t\tSym: 21.784805\t\tSpars: 1119.002563\n",
      "\t TVw: -0.519606 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1186 [4000/8000 (50%)]\tBatch Loss: 1201.904009\tLearning Rate (w_theta): 0.001000\t TIME:733.6s\n",
      "\t\t\t\tDisc: 1.746769\t\tSym: 24.107069\t\tSpars: 1176.050171\n",
      "\t TVw: -0.519560 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1186...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1159.4245001189106\n",
      "Average validation loss: 207.05324292120852\n",
      "Training epoch 1187...\n",
      "\n",
      "Train Epoch: 1187 [0/8000 (0%)]\tBatch Loss: 1160.105096\tLearning Rate (w_theta): 0.001000\t TIME:735.9s\n",
      "\t\t\t\tDisc: 1.676204\t\tSym: 21.349791\t\tSpars: 1137.079102\n",
      "\t TVw: -0.519514 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1187 [4000/8000 (50%)]\tBatch Loss: 1154.465835\tLearning Rate (w_theta): 0.001000\t TIME:737.4s\n",
      "\t\t\t\tDisc: 1.673558\t\tSym: 21.426065\t\tSpars: 1131.366211\n",
      "\t TVw: -0.519469 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1187...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1162.7056988394147\n",
      "Average validation loss: 207.83747767788256\n",
      "Training epoch 1188...\n",
      "\n",
      "Train Epoch: 1188 [0/8000 (0%)]\tBatch Loss: 1204.693147\tLearning Rate (w_theta): 0.001000\t TIME:739.8s\n",
      "\t\t\t\tDisc: 1.596744\t\tSym: 23.444059\t\tSpars: 1179.652344\n",
      "\t TVw: -0.519423 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1188 [4000/8000 (50%)]\tBatch Loss: 1186.761687\tLearning Rate (w_theta): 0.001000\t TIME:741.3s\n",
      "\t\t\t\tDisc: 1.859262\t\tSym: 24.786947\t\tSpars: 1160.115479\n",
      "\t TVw: -0.519378 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1188...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1187.2448534184532\n",
      "Average validation loss: 206.16534981008894\n",
      "Training epoch 1189...\n",
      "\n",
      "Train Epoch: 1189 [0/8000 (0%)]\tBatch Loss: 1160.735006\tLearning Rate (w_theta): 0.001000\t TIME:743.6s\n",
      "\t\t\t\tDisc: 1.702642\t\tSym: 21.812149\t\tSpars: 1137.220215\n",
      "\t TVw: -0.519334 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1189 [4000/8000 (50%)]\tBatch Loss: 1142.447983\tLearning Rate (w_theta): 0.001000\t TIME:745.1s\n",
      "\t\t\t\tDisc: 1.496790\t\tSym: 20.883810\t\tSpars: 1120.067383\n",
      "\t TVw: -0.519290 | TVb: -2.043252 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1189...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1191.727130730807\n",
      "Average validation loss: 211.8152922601816\n",
      "Training epoch 1190...\n",
      "\n",
      "Train Epoch: 1190 [0/8000 (0%)]\tBatch Loss: 1303.034637\tLearning Rate (w_theta): 0.001000\t TIME:747.4s\n",
      "\t\t\t\tDisc: 1.736711\t\tSym: 29.186964\t\tSpars: 1272.110962\n",
      "\t TVw: -0.519247 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1190 [4000/8000 (50%)]\tBatch Loss: 1376.605998\tLearning Rate (w_theta): 0.001000\t TIME:749.0s\n",
      "\t\t\t\tDisc: 1.050040\t\tSym: 27.680592\t\tSpars: 1347.875366\n",
      "\t TVw: -0.519204 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1190...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1264.9069663208456\n",
      "Average validation loss: 201.8435730757577\n",
      "Training epoch 1191...\n",
      "\n",
      "Train Epoch: 1191 [0/8000 (0%)]\tBatch Loss: 1166.607556\tLearning Rate (w_theta): 0.001000\t TIME:752.0s\n",
      "\t\t\t\tDisc: 1.725893\t\tSym: 22.626169\t\tSpars: 1142.255493\n",
      "\t TVw: -0.519165 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1191 [4000/8000 (50%)]\tBatch Loss: 1159.905989\tLearning Rate (w_theta): 0.001000\t TIME:753.6s\n",
      "\t\t\t\tDisc: 1.654714\t\tSym: 21.504814\t\tSpars: 1136.746460\n",
      "\t TVw: -0.519123 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1191...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1201.450935014597\n",
      "Average validation loss: 209.5775228081005\n",
      "Training epoch 1192...\n",
      "\n",
      "Train Epoch: 1192 [0/8000 (0%)]\tBatch Loss: 1149.623185\tLearning Rate (w_theta): 0.001000\t TIME:755.9s\n",
      "\t\t\t\tDisc: 1.558681\t\tSym: 21.805349\t\tSpars: 1126.259155\n",
      "\t TVw: -0.519078 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1192 [4000/8000 (50%)]\tBatch Loss: 1191.215938\tLearning Rate (w_theta): 0.001000\t TIME:757.4s\n",
      "\t\t\t\tDisc: 1.669355\t\tSym: 22.973707\t\tSpars: 1166.572876\n",
      "\t TVw: -0.519032 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1192...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1181.1099569690869\n",
      "Average validation loss: 211.4540168763874\n",
      "Training epoch 1193...\n",
      "\n",
      "Train Epoch: 1193 [0/8000 (0%)]\tBatch Loss: 1140.461764\tLearning Rate (w_theta): 0.001000\t TIME:759.8s\n",
      "\t\t\t\tDisc: 1.395811\t\tSym: 21.013584\t\tSpars: 1118.052368\n",
      "\t TVw: -0.518984 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1193 [4000/8000 (50%)]\tBatch Loss: 1207.789861\tLearning Rate (w_theta): 0.001000\t TIME:761.3s\n",
      "\t\t\t\tDisc: 1.725078\t\tSym: 24.850061\t\tSpars: 1181.214722\n",
      "\t TVw: -0.518935 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1193...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1173.1881198247534\n",
      "Average validation loss: 213.59261270963373\n",
      "Training epoch 1194...\n",
      "\n",
      "Train Epoch: 1194 [0/8000 (0%)]\tBatch Loss: 1195.959620\tLearning Rate (w_theta): 0.001000\t TIME:763.7s\n",
      "\t\t\t\tDisc: 1.596379\t\tSym: 22.390341\t\tSpars: 1171.972900\n",
      "\t TVw: -0.518887 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1194 [4000/8000 (50%)]\tBatch Loss: 1184.529586\tLearning Rate (w_theta): 0.001000\t TIME:765.2s\n",
      "\t\t\t\tDisc: 1.725064\t\tSym: 22.412798\t\tSpars: 1160.391724\n",
      "\t TVw: -0.518839 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1194...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1174.8533333761889\n",
      "Average validation loss: 206.45480094594154\n",
      "Training epoch 1195...\n",
      "\n",
      "Train Epoch: 1195 [0/8000 (0%)]\tBatch Loss: 1137.369301\tLearning Rate (w_theta): 0.001000\t TIME:767.5s\n",
      "\t\t\t\tDisc: 1.574778\t\tSym: 21.561735\t\tSpars: 1114.232788\n",
      "\t TVw: -0.518792 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1195 [4000/8000 (50%)]\tBatch Loss: 1134.786260\tLearning Rate (w_theta): 0.001000\t TIME:769.1s\n",
      "\t\t\t\tDisc: 1.479251\t\tSym: 20.942751\t\tSpars: 1112.364258\n",
      "\t TVw: -0.518745 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1195...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1173.1667885777915\n",
      "Average validation loss: 211.84431754847006\n",
      "Training epoch 1196...\n",
      "\n",
      "Train Epoch: 1196 [0/8000 (0%)]\tBatch Loss: 1231.122573\tLearning Rate (w_theta): 0.001000\t TIME:771.4s\n",
      "\t\t\t\tDisc: 1.575765\t\tSym: 25.926081\t\tSpars: 1203.620728\n",
      "\t TVw: -0.518698 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1196 [4000/8000 (50%)]\tBatch Loss: 1122.349427\tLearning Rate (w_theta): 0.001000\t TIME:772.9s\n",
      "\t\t\t\tDisc: 1.517449\t\tSym: 21.320747\t\tSpars: 1099.511230\n",
      "\t TVw: -0.518652 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1196...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1174.5279100193009\n",
      "Average validation loss: 202.91350559665835\n",
      "Training epoch 1197...\n",
      "\n",
      "Train Epoch: 1197 [0/8000 (0%)]\tBatch Loss: 1164.864846\tLearning Rate (w_theta): 0.001000\t TIME:775.3s\n",
      "\t\t\t\tDisc: 1.774210\t\tSym: 21.676817\t\tSpars: 1141.413818\n",
      "\t TVw: -0.518605 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1197 [4000/8000 (50%)]\tBatch Loss: 1171.605346\tLearning Rate (w_theta): 0.001000\t TIME:776.8s\n",
      "\t\t\t\tDisc: 1.706950\t\tSym: 23.405964\t\tSpars: 1146.492432\n",
      "\t TVw: -0.518558 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1197...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1161.1026052746902\n",
      "Average validation loss: 204.4746381691449\n",
      "Training epoch 1198...\n",
      "\n",
      "Train Epoch: 1198 [0/8000 (0%)]\tBatch Loss: 1147.725770\tLearning Rate (w_theta): 0.001000\t TIME:779.1s\n",
      "\t\t\t\tDisc: 1.608566\t\tSym: 21.826677\t\tSpars: 1124.290527\n",
      "\t TVw: -0.518510 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1198 [4000/8000 (50%)]\tBatch Loss: 1158.881532\tLearning Rate (w_theta): 0.001000\t TIME:780.6s\n",
      "\t\t\t\tDisc: 1.670451\t\tSym: 23.198385\t\tSpars: 1134.012695\n",
      "\t TVw: -0.518462 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1198...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1157.8848885355712\n",
      "Average validation loss: 203.98589542817865\n",
      "Training epoch 1199...\n",
      "\n",
      "Train Epoch: 1199 [0/8000 (0%)]\tBatch Loss: 1154.227178\tLearning Rate (w_theta): 0.001000\t TIME:783.1s\n",
      "\t\t\t\tDisc: 1.686357\t\tSym: 22.005909\t\tSpars: 1130.534912\n",
      "\t TVw: -0.518414 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1199 [4000/8000 (50%)]\tBatch Loss: 1201.460617\tLearning Rate (w_theta): 0.001000\t TIME:784.6s\n",
      "\t\t\t\tDisc: 1.834162\t\tSym: 24.010611\t\tSpars: 1175.615845\n",
      "\t TVw: -0.518367 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1199...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1157.6038506575385\n",
      "Average validation loss: 202.27101629410768\n",
      "Training epoch 1200...\n",
      "\n",
      "Train Epoch: 1200 [0/8000 (0%)]\tBatch Loss: 1172.097978\tLearning Rate (w_theta): 0.001000\t TIME:786.9s\n",
      "\t\t\t\tDisc: 1.587533\t\tSym: 21.768867\t\tSpars: 1148.741577\n",
      "\t TVw: -0.518319 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1200 [4000/8000 (50%)]\tBatch Loss: 1150.218081\tLearning Rate (w_theta): 0.001000\t TIME:788.4s\n",
      "\t\t\t\tDisc: 1.610060\t\tSym: 21.228260\t\tSpars: 1127.379761\n",
      "\t TVw: -0.518272 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1200...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1169.4399513323592\n",
      "Average validation loss: 201.66712113189007\n",
      "Training epoch 1201...\n",
      "\n",
      "Train Epoch: 1201 [0/8000 (0%)]\tBatch Loss: 1146.297950\tLearning Rate (w_theta): 0.001000\t TIME:791.4s\n",
      "\t\t\t\tDisc: 1.669407\t\tSym: 20.863407\t\tSpars: 1123.765137\n",
      "\t TVw: -0.518225 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1201 [4000/8000 (50%)]\tBatch Loss: 1115.059713\tLearning Rate (w_theta): 0.001000\t TIME:792.9s\n",
      "\t\t\t\tDisc: 1.586122\t\tSym: 21.403522\t\tSpars: 1092.070068\n",
      "\t TVw: -0.518178 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1201...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1163.28390945075\n",
      "Average validation loss: 203.36796782877207\n",
      "Training epoch 1202...\n",
      "\n",
      "Train Epoch: 1202 [0/8000 (0%)]\tBatch Loss: 1194.044357\tLearning Rate (w_theta): 0.001000\t TIME:795.3s\n",
      "\t\t\t\tDisc: 1.595432\t\tSym: 23.467358\t\tSpars: 1168.981567\n",
      "\t TVw: -0.518132 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1202 [4000/8000 (50%)]\tBatch Loss: 1222.370820\tLearning Rate (w_theta): 0.001000\t TIME:796.9s\n",
      "\t\t\t\tDisc: 1.869761\t\tSym: 25.434286\t\tSpars: 1195.066772\n",
      "\t TVw: -0.518084 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1202...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1174.0571075298099\n",
      "Average validation loss: 202.27806387211362\n",
      "Training epoch 1203...\n",
      "\n",
      "Train Epoch: 1203 [0/8000 (0%)]\tBatch Loss: 1153.354322\tLearning Rate (w_theta): 0.001000\t TIME:799.2s\n",
      "\t\t\t\tDisc: 1.598005\t\tSym: 21.637421\t\tSpars: 1130.118896\n",
      "\t TVw: -0.518038 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1203 [4000/8000 (50%)]\tBatch Loss: 1196.543980\tLearning Rate (w_theta): 0.001000\t TIME:800.8s\n",
      "\t\t\t\tDisc: 1.866181\t\tSym: 24.495182\t\tSpars: 1170.182617\n",
      "\t TVw: -0.517991 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1203...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1164.2134077920464\n",
      "Average validation loss: 203.8076014452331\n",
      "Training epoch 1204...\n",
      "\n",
      "Train Epoch: 1204 [0/8000 (0%)]\tBatch Loss: 1118.125670\tLearning Rate (w_theta): 0.001000\t TIME:803.1s\n",
      "\t\t\t\tDisc: 1.568156\t\tSym: 20.907978\t\tSpars: 1095.649536\n",
      "\t TVw: -0.517943 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1204 [4000/8000 (50%)]\tBatch Loss: 1140.379338\tLearning Rate (w_theta): 0.001000\t TIME:804.6s\n",
      "\t\t\t\tDisc: 1.512252\t\tSym: 21.175192\t\tSpars: 1117.691895\n",
      "\t TVw: -0.517895 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1204...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1159.3006362312094\n",
      "Average validation loss: 206.55275270416976\n",
      "Training epoch 1205...\n",
      "\n",
      "Train Epoch: 1205 [0/8000 (0%)]\tBatch Loss: 1163.078242\tLearning Rate (w_theta): 0.001000\t TIME:806.9s\n",
      "\t\t\t\tDisc: 1.552520\t\tSym: 21.868862\t\tSpars: 1139.656860\n",
      "\t TVw: -0.517846 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1205 [4000/8000 (50%)]\tBatch Loss: 1174.331047\tLearning Rate (w_theta): 0.001000\t TIME:808.4s\n",
      "\t\t\t\tDisc: 1.875391\t\tSym: 24.407072\t\tSpars: 1148.048584\n",
      "\t TVw: -0.517798 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1205...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1165.131985202497\n",
      "Average validation loss: 201.84564526869895\n",
      "Training epoch 1206...\n",
      "\n",
      "Train Epoch: 1206 [0/8000 (0%)]\tBatch Loss: 1143.239678\tLearning Rate (w_theta): 0.001000\t TIME:810.8s\n",
      "\t\t\t\tDisc: 1.666722\t\tSym: 20.900105\t\tSpars: 1120.672852\n",
      "\t TVw: -0.517750 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1206 [4000/8000 (50%)]\tBatch Loss: 1186.417598\tLearning Rate (w_theta): 0.001000\t TIME:812.3s\n",
      "\t\t\t\tDisc: 1.955802\t\tSym: 22.793705\t\tSpars: 1161.668091\n",
      "\t TVw: -0.517702 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1206...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1173.8268457754978\n",
      "Average validation loss: 204.3708705924011\n",
      "Training epoch 1207...\n",
      "\n",
      "Train Epoch: 1207 [0/8000 (0%)]\tBatch Loss: 1153.661361\tLearning Rate (w_theta): 0.001000\t TIME:814.7s\n",
      "\t\t\t\tDisc: 1.696904\t\tSym: 21.222513\t\tSpars: 1130.741943\n",
      "\t TVw: -0.517654 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1207 [4000/8000 (50%)]\tBatch Loss: 1156.154397\tLearning Rate (w_theta): 0.001000\t TIME:816.2s\n",
      "\t\t\t\tDisc: 1.657138\t\tSym: 23.387030\t\tSpars: 1131.110229\n",
      "\t TVw: -0.517605 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1207...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1159.4788857436638\n",
      "Average validation loss: 203.8516057603533\n",
      "Training epoch 1208...\n",
      "\n",
      "Train Epoch: 1208 [0/8000 (0%)]\tBatch Loss: 1130.101942\tLearning Rate (w_theta): 0.001000\t TIME:818.6s\n",
      "\t\t\t\tDisc: 1.593235\t\tSym: 20.923868\t\tSpars: 1107.584839\n",
      "\t TVw: -0.517556 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1208 [4000/8000 (50%)]\tBatch Loss: 1159.610544\tLearning Rate (w_theta): 0.001000\t TIME:820.1s\n",
      "\t\t\t\tDisc: 1.664173\t\tSym: 21.955282\t\tSpars: 1135.991089\n",
      "\t TVw: -0.517507 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1208...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1154.1556164200338\n",
      "Average validation loss: 203.4805957819809\n",
      "Training epoch 1209...\n",
      "\n",
      "Train Epoch: 1209 [0/8000 (0%)]\tBatch Loss: 1198.769974\tLearning Rate (w_theta): 0.001000\t TIME:822.4s\n",
      "\t\t\t\tDisc: 1.728334\t\tSym: 23.726820\t\tSpars: 1173.314819\n",
      "\t TVw: -0.517458 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1209 [4000/8000 (50%)]\tBatch Loss: 1161.485766\tLearning Rate (w_theta): 0.001000\t TIME:824.0s\n",
      "\t\t\t\tDisc: 1.546910\t\tSym: 21.063612\t\tSpars: 1138.875244\n",
      "\t TVw: -0.517408 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1209...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1152.205736403132\n",
      "Average validation loss: 202.30851315569817\n",
      "Training epoch 1210...\n",
      "\n",
      "Train Epoch: 1210 [0/8000 (0%)]\tBatch Loss: 1170.490238\tLearning Rate (w_theta): 0.001000\t TIME:826.3s\n",
      "\t\t\t\tDisc: 1.647695\t\tSym: 23.513075\t\tSpars: 1145.329468\n",
      "\t TVw: -0.517358 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1210 [4000/8000 (50%)]\tBatch Loss: 1199.407866\tLearning Rate (w_theta): 0.001000\t TIME:827.8s\n",
      "\t\t\t\tDisc: 1.590094\t\tSym: 23.984032\t\tSpars: 1173.833740\n",
      "\t TVw: -0.517307 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1210...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1161.621414697715\n",
      "Average validation loss: 202.5431014492025\n",
      "Training epoch 1211...\n",
      "\n",
      "Train Epoch: 1211 [0/8000 (0%)]\tBatch Loss: 1175.263410\tLearning Rate (w_theta): 0.001000\t TIME:830.9s\n",
      "\t\t\t\tDisc: 1.730926\t\tSym: 23.333876\t\tSpars: 1150.198608\n",
      "\t TVw: -0.517258 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1211 [4000/8000 (50%)]\tBatch Loss: 1110.992916\tLearning Rate (w_theta): 0.001000\t TIME:832.4s\n",
      "\t\t\t\tDisc: 1.524935\t\tSym: 19.624964\t\tSpars: 1089.843018\n",
      "\t TVw: -0.517207 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1211...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1152.0938740107072\n",
      "Average validation loss: 201.24659384195857\n",
      "Training epoch 1212...\n",
      "\n",
      "Train Epoch: 1212 [0/8000 (0%)]\tBatch Loss: 1149.955533\tLearning Rate (w_theta): 0.001000\t TIME:834.8s\n",
      "\t\t\t\tDisc: 1.580249\t\tSym: 21.420328\t\tSpars: 1126.954956\n",
      "\t TVw: -0.517158 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1212 [4000/8000 (50%)]\tBatch Loss: 1172.458229\tLearning Rate (w_theta): 0.001000\t TIME:836.3s\n",
      "\t\t\t\tDisc: 1.801645\t\tSym: 22.919279\t\tSpars: 1147.737305\n",
      "\t TVw: -0.517108 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1212...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1153.4383210264864\n",
      "Average validation loss: 199.47655737012545\n",
      "Training epoch 1213...\n",
      "\n",
      "Train Epoch: 1213 [0/8000 (0%)]\tBatch Loss: 1138.652236\tLearning Rate (w_theta): 0.001000\t TIME:838.6s\n",
      "\t\t\t\tDisc: 1.607583\t\tSym: 21.396704\t\tSpars: 1115.647949\n",
      "\t TVw: -0.517058 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1213 [4000/8000 (50%)]\tBatch Loss: 1161.664531\tLearning Rate (w_theta): 0.001000\t TIME:840.1s\n",
      "\t\t\t\tDisc: 1.619554\t\tSym: 22.094416\t\tSpars: 1137.950562\n",
      "\t TVw: -0.517008 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1213...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1152.0122164093718\n",
      "Average validation loss: 199.67168563894433\n",
      "Training epoch 1214...\n",
      "\n",
      "Train Epoch: 1214 [0/8000 (0%)]\tBatch Loss: 1172.555155\tLearning Rate (w_theta): 0.001000\t TIME:842.5s\n",
      "\t\t\t\tDisc: 1.712563\t\tSym: 23.039248\t\tSpars: 1147.803345\n",
      "\t TVw: -0.516957 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1214 [4000/8000 (50%)]\tBatch Loss: 1117.712166\tLearning Rate (w_theta): 0.001000\t TIME:844.0s\n",
      "\t\t\t\tDisc: 1.621062\t\tSym: 20.131388\t\tSpars: 1095.959717\n",
      "\t TVw: -0.516906 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1214...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1152.8731156540223\n",
      "Average validation loss: 199.32347392952713\n",
      "Training epoch 1215...\n",
      "\n",
      "Train Epoch: 1215 [0/8000 (0%)]\tBatch Loss: 1141.543158\tLearning Rate (w_theta): 0.001000\t TIME:846.3s\n",
      "\t\t\t\tDisc: 1.541375\t\tSym: 21.153151\t\tSpars: 1118.848633\n",
      "\t TVw: -0.516855 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1215 [4000/8000 (50%)]\tBatch Loss: 1188.149300\tLearning Rate (w_theta): 0.001000\t TIME:847.8s\n",
      "\t\t\t\tDisc: 1.544352\t\tSym: 22.797209\t\tSpars: 1163.807739\n",
      "\t TVw: -0.516804 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1215...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1163.3715296659857\n",
      "Average validation loss: 199.40452204973914\n",
      "Training epoch 1216...\n",
      "\n",
      "Train Epoch: 1216 [0/8000 (0%)]\tBatch Loss: 1157.515563\tLearning Rate (w_theta): 0.001000\t TIME:850.3s\n",
      "\t\t\t\tDisc: 1.638957\t\tSym: 21.873066\t\tSpars: 1134.003540\n",
      "\t TVw: -0.516754 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1216 [4000/8000 (50%)]\tBatch Loss: 1134.643645\tLearning Rate (w_theta): 0.001000\t TIME:851.8s\n",
      "\t\t\t\tDisc: 1.778851\t\tSym: 21.066454\t\tSpars: 1111.798340\n",
      "\t TVw: -0.516704 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1216...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1164.1110682972999\n",
      "Average validation loss: 200.46800714829803\n",
      "Training epoch 1217...\n",
      "\n",
      "Train Epoch: 1217 [0/8000 (0%)]\tBatch Loss: 1200.312221\tLearning Rate (w_theta): 0.001000\t TIME:854.1s\n",
      "\t\t\t\tDisc: 1.867921\t\tSym: 23.614588\t\tSpars: 1174.829712\n",
      "\t TVw: -0.516654 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1217 [4000/8000 (50%)]\tBatch Loss: 1135.456712\tLearning Rate (w_theta): 0.001000\t TIME:855.6s\n",
      "\t\t\t\tDisc: 1.681607\t\tSym: 21.680378\t\tSpars: 1112.094727\n",
      "\t TVw: -0.516603 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1217...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1163.971276654019\n",
      "Average validation loss: 203.45284937223093\n",
      "Training epoch 1218...\n",
      "\n",
      "Train Epoch: 1218 [0/8000 (0%)]\tBatch Loss: 1135.332518\tLearning Rate (w_theta): 0.001000\t TIME:858.0s\n",
      "\t\t\t\tDisc: 1.649910\t\tSym: 21.496572\t\tSpars: 1112.186035\n",
      "\t TVw: -0.516552 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1218 [4000/8000 (50%)]\tBatch Loss: 1171.816244\tLearning Rate (w_theta): 0.001000\t TIME:859.5s\n",
      "\t\t\t\tDisc: 1.436967\t\tSym: 21.998295\t\tSpars: 1148.380981\n",
      "\t TVw: -0.516502 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1218...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1161.8032578410396\n",
      "Average validation loss: 202.0265186883051\n",
      "Training epoch 1219...\n",
      "\n",
      "Train Epoch: 1219 [0/8000 (0%)]\tBatch Loss: 1122.197604\tLearning Rate (w_theta): 0.001000\t TIME:861.8s\n",
      "\t\t\t\tDisc: 1.514407\t\tSym: 21.015594\t\tSpars: 1099.667603\n",
      "\t TVw: -0.516451 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1219 [4000/8000 (50%)]\tBatch Loss: 1186.121509\tLearning Rate (w_theta): 0.001000\t TIME:863.3s\n",
      "\t\t\t\tDisc: 1.704130\t\tSym: 22.569113\t\tSpars: 1161.848267\n",
      "\t TVw: -0.516400 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1219...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1154.3721828101834\n",
      "Average validation loss: 200.4301030539851\n",
      "Training epoch 1220...\n",
      "\n",
      "Train Epoch: 1220 [0/8000 (0%)]\tBatch Loss: 1216.332468\tLearning Rate (w_theta): 0.001000\t TIME:865.7s\n",
      "\t\t\t\tDisc: 1.797791\t\tSym: 25.207041\t\tSpars: 1189.327637\n",
      "\t TVw: -0.516348 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1220 [4000/8000 (50%)]\tBatch Loss: 1184.787369\tLearning Rate (w_theta): 0.001000\t TIME:867.2s\n",
      "\t\t\t\tDisc: 1.584372\t\tSym: 22.012812\t\tSpars: 1161.190186\n",
      "\t TVw: -0.516296 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1220...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1150.7376322502414\n",
      "Average validation loss: 201.27097172373487\n",
      "Training epoch 1221...\n",
      "\n",
      "Train Epoch: 1221 [0/8000 (0%)]\tBatch Loss: 1170.982874\tLearning Rate (w_theta): 0.001000\t TIME:870.3s\n",
      "\t\t\t\tDisc: 1.648691\t\tSym: 22.501419\t\tSpars: 1146.832764\n",
      "\t TVw: -0.516243 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1221 [4000/8000 (50%)]\tBatch Loss: 1156.812933\tLearning Rate (w_theta): 0.001000\t TIME:871.8s\n",
      "\t\t\t\tDisc: 1.667000\t\tSym: 22.844419\t\tSpars: 1132.301514\n",
      "\t TVw: -0.516190 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1221...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1148.3385912160566\n",
      "Average validation loss: 199.76207425552283\n",
      "Training epoch 1222...\n",
      "\n",
      "Train Epoch: 1222 [0/8000 (0%)]\tBatch Loss: 1152.115994\tLearning Rate (w_theta): 0.001000\t TIME:874.2s\n",
      "\t\t\t\tDisc: 1.663330\t\tSym: 21.628445\t\tSpars: 1128.824219\n",
      "\t TVw: -0.516137 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1222 [4000/8000 (50%)]\tBatch Loss: 1157.104947\tLearning Rate (w_theta): 0.001000\t TIME:875.7s\n",
      "\t\t\t\tDisc: 1.565049\t\tSym: 21.855083\t\tSpars: 1133.684814\n",
      "\t TVw: -0.516083 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1222...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1148.1495283910829\n",
      "Average validation loss: 199.64622581917456\n",
      "Training epoch 1223...\n",
      "\n",
      "Train Epoch: 1223 [0/8000 (0%)]\tBatch Loss: 1149.345780\tLearning Rate (w_theta): 0.001000\t TIME:878.0s\n",
      "\t\t\t\tDisc: 1.655184\t\tSym: 20.818525\t\tSpars: 1126.872070\n",
      "\t TVw: -0.516030 | TVb: -2.043254 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1223 [4000/8000 (50%)]\tBatch Loss: 1119.025127\tLearning Rate (w_theta): 0.001000\t TIME:879.5s\n",
      "\t\t\t\tDisc: 1.570613\t\tSym: 19.815964\t\tSpars: 1097.638550\n",
      "\t TVw: -0.515978 | TVb: -2.043255 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1223...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1160.7706812186627\n",
      "Average validation loss: 202.2247531301613\n",
      "Training epoch 1224...\n",
      "\n",
      "Train Epoch: 1224 [0/8000 (0%)]\tBatch Loss: 1128.888866\tLearning Rate (w_theta): 0.001000\t TIME:881.9s\n",
      "\t\t\t\tDisc: 1.527001\t\tSym: 20.968676\t\tSpars: 1106.393188\n",
      "\t TVw: -0.515926 | TVb: -2.043255 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1224 [4000/8000 (50%)]\tBatch Loss: 1170.269556\tLearning Rate (w_theta): 0.001000\t TIME:883.5s\n",
      "\t\t\t\tDisc: 1.595043\t\tSym: 22.385328\t\tSpars: 1146.289185\n",
      "\t TVw: -0.515874 | TVb: -2.043255 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1224...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1152.4067736224679\n",
      "Average validation loss: 199.80920101250098\n",
      "Training epoch 1225...\n",
      "\n",
      "Train Epoch: 1225 [0/8000 (0%)]\tBatch Loss: 1135.105991\tLearning Rate (w_theta): 0.001000\t TIME:885.8s\n",
      "\t\t\t\tDisc: 1.596458\t\tSym: 20.101940\t\tSpars: 1113.407593\n",
      "\t TVw: -0.515821 | TVb: -2.043255 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1225 [4000/8000 (50%)]\tBatch Loss: 1161.046899\tLearning Rate (w_theta): 0.001000\t TIME:887.3s\n",
      "\t\t\t\tDisc: 1.656602\t\tSym: 21.716713\t\tSpars: 1137.673584\n",
      "\t TVw: -0.515769 | TVb: -2.043255 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1225...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1158.9037079584673\n",
      "Average validation loss: 202.81600536485976\n",
      "Training epoch 1226...\n",
      "\n",
      "Train Epoch: 1226 [0/8000 (0%)]\tBatch Loss: 1156.648569\tLearning Rate (w_theta): 0.001000\t TIME:889.6s\n",
      "\t\t\t\tDisc: 1.693310\t\tSym: 22.205503\t\tSpars: 1132.749756\n",
      "\t TVw: -0.515715 | TVb: -2.043255 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1226 [4000/8000 (50%)]\tBatch Loss: 1159.257239\tLearning Rate (w_theta): 0.001000\t TIME:891.1s\n",
      "\t\t\t\tDisc: 1.621087\t\tSym: 22.489668\t\tSpars: 1135.146484\n",
      "\t TVw: -0.515661 | TVb: -2.043255 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1226...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1147.9380334225912\n",
      "Average validation loss: 201.76861345996576\n",
      "Training epoch 1227...\n",
      "\n",
      "Train Epoch: 1227 [0/8000 (0%)]\tBatch Loss: 1174.306407\tLearning Rate (w_theta): 0.001000\t TIME:893.4s\n",
      "\t\t\t\tDisc: 1.734222\t\tSym: 22.728191\t\tSpars: 1149.843994\n",
      "\t TVw: -0.515607 | TVb: -2.043255 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1227 [4000/8000 (50%)]\tBatch Loss: 1111.343164\tLearning Rate (w_theta): 0.001000\t TIME:894.9s\n",
      "\t\t\t\tDisc: 1.471342\t\tSym: 19.075924\t\tSpars: 1090.795898\n",
      "\t TVw: -0.515553 | TVb: -2.043255 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1227...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1146.7739367555946\n",
      "Average validation loss: 199.62742054461398\n",
      "Training epoch 1228...\n",
      "\n",
      "Train Epoch: 1228 [0/8000 (0%)]\tBatch Loss: 1160.995510\tLearning Rate (w_theta): 0.001000\t TIME:897.3s\n",
      "\t\t\t\tDisc: 1.705217\t\tSym: 22.872568\t\tSpars: 1136.417725\n",
      "\t TVw: -0.515500 | TVb: -2.043255 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1228 [4000/8000 (50%)]\tBatch Loss: 1161.657136\tLearning Rate (w_theta): 0.001000\t TIME:898.8s\n",
      "\t\t\t\tDisc: 1.655239\t\tSym: 21.742743\t\tSpars: 1138.259155\n",
      "\t TVw: -0.515446 | TVb: -2.043255 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1228...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1145.775289273922\n",
      "Average validation loss: 199.25087849229206\n",
      "Training epoch 1229...\n",
      "\n",
      "Train Epoch: 1229 [0/8000 (0%)]\tBatch Loss: 1133.221908\tLearning Rate (w_theta): 0.001000\t TIME:901.2s\n",
      "\t\t\t\tDisc: 1.599822\t\tSym: 21.404190\t\tSpars: 1110.217896\n",
      "\t TVw: -0.515393 | TVb: -2.043255 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1229 [4000/8000 (50%)]\tBatch Loss: 1133.620722\tLearning Rate (w_theta): 0.001000\t TIME:902.7s\n",
      "\t\t\t\tDisc: 1.500786\t\tSym: 19.426821\t\tSpars: 1112.693115\n",
      "\t TVw: -0.515339 | TVb: -2.043255 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1229...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1149.5418742965721\n",
      "Average validation loss: 198.56105396412312\n",
      "Training epoch 1230...\n",
      "\n",
      "Train Epoch: 1230 [0/8000 (0%)]\tBatch Loss: 1161.315547\tLearning Rate (w_theta): 0.001000\t TIME:905.0s\n",
      "\t\t\t\tDisc: 1.643714\t\tSym: 22.804523\t\tSpars: 1136.867310\n",
      "\t TVw: -0.515285 | TVb: -2.043255 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1230 [4000/8000 (50%)]\tBatch Loss: 1186.797057\tLearning Rate (w_theta): 0.001000\t TIME:906.5s\n",
      "\t\t\t\tDisc: 1.557297\t\tSym: 24.105848\t\tSpars: 1161.133911\n",
      "\t TVw: -0.515232 | TVb: -2.043256 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1230...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1155.1512735016083\n",
      "Average validation loss: 197.34876858391556\n",
      "Training epoch 1231...\n",
      "\n",
      "Train Epoch: 1231 [0/8000 (0%)]\tBatch Loss: 1153.916357\tLearning Rate (w_theta): 0.001000\t TIME:909.5s\n",
      "\t\t\t\tDisc: 1.737308\t\tSym: 22.002169\t\tSpars: 1130.176880\n",
      "\t TVw: -0.515179 | TVb: -2.043256 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1231 [4000/8000 (50%)]\tBatch Loss: 1174.527687\tLearning Rate (w_theta): 0.001000\t TIME:911.0s\n",
      "\t\t\t\tDisc: 1.741097\t\tSym: 23.207245\t\tSpars: 1149.579346\n",
      "\t TVw: -0.515125 | TVb: -2.043256 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1231...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1150.027061195709\n",
      "Average validation loss: 199.76370424579136\n",
      "Training epoch 1232...\n",
      "\n",
      "Train Epoch: 1232 [0/8000 (0%)]\tBatch Loss: 1139.930158\tLearning Rate (w_theta): 0.001000\t TIME:913.5s\n",
      "\t\t\t\tDisc: 1.460836\t\tSym: 20.787071\t\tSpars: 1117.682251\n",
      "\t TVw: -0.515071 | TVb: -2.043256 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1232 [4000/8000 (50%)]\tBatch Loss: 1139.449942\tLearning Rate (w_theta): 0.001000\t TIME:915.0s\n",
      "\t\t\t\tDisc: 1.743632\t\tSym: 21.826427\t\tSpars: 1115.879883\n",
      "\t TVw: -0.515017 | TVb: -2.043256 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1232...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1157.5128077382556\n",
      "Average validation loss: 198.87334662125997\n",
      "Training epoch 1233...\n",
      "\n",
      "Train Epoch: 1233 [0/8000 (0%)]\tBatch Loss: 1190.090717\tLearning Rate (w_theta): 0.001000\t TIME:917.3s\n",
      "\t\t\t\tDisc: 1.882373\t\tSym: 23.424530\t\tSpars: 1164.783813\n",
      "\t TVw: -0.514963 | TVb: -2.043256 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1233 [4000/8000 (50%)]\tBatch Loss: 1197.911667\tLearning Rate (w_theta): 0.001000\t TIME:918.8s\n",
      "\t\t\t\tDisc: 1.770336\t\tSym: 24.511326\t\tSpars: 1171.630005\n",
      "\t TVw: -0.514909 | TVb: -2.043256 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1233...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1148.9583286980894\n",
      "Average validation loss: 198.99357063729173\n",
      "Training epoch 1234...\n",
      "\n",
      "Train Epoch: 1234 [0/8000 (0%)]\tBatch Loss: 1192.132409\tLearning Rate (w_theta): 0.001000\t TIME:921.1s\n",
      "\t\t\t\tDisc: 1.883061\t\tSym: 24.899616\t\tSpars: 1165.349731\n",
      "\t TVw: -0.514855 | TVb: -2.043256 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1234 [4000/8000 (50%)]\tBatch Loss: 1129.526746\tLearning Rate (w_theta): 0.001000\t TIME:922.6s\n",
      "\t\t\t\tDisc: 1.633781\t\tSym: 21.503317\t\tSpars: 1106.389648\n",
      "\t TVw: -0.514801 | TVb: -2.043256 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1234...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1152.4311990183944\n",
      "Average validation loss: 202.31806510821448\n",
      "Training epoch 1235...\n",
      "\n",
      "Train Epoch: 1235 [0/8000 (0%)]\tBatch Loss: 1174.532826\tLearning Rate (w_theta): 0.001000\t TIME:924.9s\n",
      "\t\t\t\tDisc: 1.532889\t\tSym: 23.415709\t\tSpars: 1149.584229\n",
      "\t TVw: -0.514746 | TVb: -2.043256 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1235 [4000/8000 (50%)]\tBatch Loss: 1109.669457\tLearning Rate (w_theta): 0.001000\t TIME:926.5s\n",
      "\t\t\t\tDisc: 1.567559\t\tSym: 20.469330\t\tSpars: 1087.632568\n",
      "\t TVw: -0.514691 | TVb: -2.043257 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1235...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1149.8613579476876\n",
      "Average validation loss: 198.35950176705296\n",
      "Training epoch 1236...\n",
      "\n",
      "Train Epoch: 1236 [0/8000 (0%)]\tBatch Loss: 1125.656361\tLearning Rate (w_theta): 0.001000\t TIME:928.8s\n",
      "\t\t\t\tDisc: 1.599112\t\tSym: 20.761595\t\tSpars: 1103.295654\n",
      "\t TVw: -0.514636 | TVb: -2.043257 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1236 [4000/8000 (50%)]\tBatch Loss: 1194.181704\tLearning Rate (w_theta): 0.001000\t TIME:930.3s\n",
      "\t\t\t\tDisc: 1.764775\t\tSym: 24.824156\t\tSpars: 1167.592773\n",
      "\t TVw: -0.514581 | TVb: -2.043257 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1236...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1158.4864471363\n",
      "Average validation loss: 198.14001841779475\n",
      "Training epoch 1237...\n",
      "\n",
      "Train Epoch: 1237 [0/8000 (0%)]\tBatch Loss: 1114.547765\tLearning Rate (w_theta): 0.001000\t TIME:932.7s\n",
      "\t\t\t\tDisc: 1.542373\t\tSym: 19.986837\t\tSpars: 1093.018555\n",
      "\t TVw: -0.514527 | TVb: -2.043257 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1237 [4000/8000 (50%)]\tBatch Loss: 1172.585916\tLearning Rate (w_theta): 0.001000\t TIME:934.3s\n",
      "\t\t\t\tDisc: 2.006977\t\tSym: 22.956869\t\tSpars: 1147.622070\n",
      "\t TVw: -0.514473 | TVb: -2.043257 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1237...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1173.4749698253374\n",
      "Average validation loss: 194.1610203898651\n",
      "Training epoch 1238...\n",
      "\n",
      "Train Epoch: 1238 [0/8000 (0%)]\tBatch Loss: 1136.189338\tLearning Rate (w_theta): 0.001000\t TIME:936.6s\n",
      "\t\t\t\tDisc: 1.517068\t\tSym: 19.550077\t\tSpars: 1115.122192\n",
      "\t TVw: -0.514420 | TVb: -2.043257 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1238 [4000/8000 (50%)]\tBatch Loss: 1158.581722\tLearning Rate (w_theta): 0.001000\t TIME:938.1s\n",
      "\t\t\t\tDisc: 1.660173\t\tSym: 21.317789\t\tSpars: 1135.603760\n",
      "\t TVw: -0.514366 | TVb: -2.043258 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1238...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1165.5547907919615\n",
      "Average validation loss: 193.96142685402577\n",
      "Training epoch 1239...\n",
      "\n",
      "Train Epoch: 1239 [0/8000 (0%)]\tBatch Loss: 1091.532827\tLearning Rate (w_theta): 0.001000\t TIME:940.4s\n",
      "\t\t\t\tDisc: 1.491784\t\tSym: 19.293240\t\tSpars: 1070.747803\n",
      "\t TVw: -0.514312 | TVb: -2.043258 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1239 [4000/8000 (50%)]\tBatch Loss: 1178.909934\tLearning Rate (w_theta): 0.001000\t TIME:941.9s\n",
      "\t\t\t\tDisc: 1.573505\t\tSym: 23.200565\t\tSpars: 1154.135864\n",
      "\t TVw: -0.514257 | TVb: -2.043258 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1239...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1155.0828533375745\n",
      "Average validation loss: 195.63995001361164\n",
      "Training epoch 1240...\n",
      "\n",
      "Train Epoch: 1240 [0/8000 (0%)]\tBatch Loss: 1195.140130\tLearning Rate (w_theta): 0.001000\t TIME:944.2s\n",
      "\t\t\t\tDisc: 1.955396\t\tSym: 24.684490\t\tSpars: 1168.500244\n",
      "\t TVw: -0.514201 | TVb: -2.043258 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1240 [4000/8000 (50%)]\tBatch Loss: 1119.161861\tLearning Rate (w_theta): 0.001000\t TIME:945.8s\n",
      "\t\t\t\tDisc: 1.402446\t\tSym: 18.549820\t\tSpars: 1099.209595\n",
      "\t TVw: -0.514144 | TVb: -2.043258 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1240...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1147.9518139968018\n",
      "Average validation loss: 199.702004532985\n",
      "Training epoch 1241...\n",
      "\n",
      "Train Epoch: 1241 [0/8000 (0%)]\tBatch Loss: 1158.962814\tLearning Rate (w_theta): 0.001000\t TIME:948.9s\n",
      "\t\t\t\tDisc: 1.664198\t\tSym: 22.860994\t\tSpars: 1134.437622\n",
      "\t TVw: -0.514087 | TVb: -2.043258 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1241 [4000/8000 (50%)]\tBatch Loss: 1146.116875\tLearning Rate (w_theta): 0.001000\t TIME:950.4s\n",
      "\t\t\t\tDisc: 1.549795\t\tSym: 21.883608\t\tSpars: 1122.683472\n",
      "\t TVw: -0.514030 | TVb: -2.043258 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1241...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1142.8406844601307\n",
      "Average validation loss: 197.80431704392345\n",
      "Training epoch 1242...\n",
      "\n",
      "Train Epoch: 1242 [0/8000 (0%)]\tBatch Loss: 1145.180521\tLearning Rate (w_theta): 0.001000\t TIME:952.7s\n",
      "\t\t\t\tDisc: 1.701924\t\tSym: 22.200155\t\tSpars: 1121.278442\n",
      "\t TVw: -0.513973 | TVb: -2.043258 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1242 [4000/8000 (50%)]\tBatch Loss: 1102.449934\tLearning Rate (w_theta): 0.001000\t TIME:954.2s\n",
      "\t\t\t\tDisc: 1.429294\t\tSym: 19.161264\t\tSpars: 1081.859375\n",
      "\t TVw: -0.513915 | TVb: -2.043258 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1242...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1146.5297954562056\n",
      "Average validation loss: 200.90411173436596\n",
      "Training epoch 1243...\n",
      "\n",
      "Train Epoch: 1243 [0/8000 (0%)]\tBatch Loss: 1168.535597\tLearning Rate (w_theta): 0.001000\t TIME:956.5s\n",
      "\t\t\t\tDisc: 1.445906\t\tSym: 22.125336\t\tSpars: 1144.964355\n",
      "\t TVw: -0.513858 | TVb: -2.043258 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1243 [4000/8000 (50%)]\tBatch Loss: 1168.067082\tLearning Rate (w_theta): 0.001000\t TIME:958.0s\n",
      "\t\t\t\tDisc: 1.693272\t\tSym: 22.563873\t\tSpars: 1143.809937\n",
      "\t TVw: -0.513802 | TVb: -2.043258 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1243...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1159.623979363249\n",
      "Average validation loss: 197.83311375003413\n",
      "Training epoch 1244...\n",
      "\n",
      "Train Epoch: 1244 [0/8000 (0%)]\tBatch Loss: 1134.724972\tLearning Rate (w_theta): 0.001000\t TIME:960.4s\n",
      "\t\t\t\tDisc: 1.617560\t\tSym: 20.862906\t\tSpars: 1112.244507\n",
      "\t TVw: -0.513745 | TVb: -2.043258 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1244 [4000/8000 (50%)]\tBatch Loss: 1183.187195\tLearning Rate (w_theta): 0.001000\t TIME:961.9s\n",
      "\t\t\t\tDisc: 1.947107\t\tSym: 23.139746\t\tSpars: 1158.100342\n",
      "\t TVw: -0.513689 | TVb: -2.043258 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1244...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1155.7334681182554\n",
      "Average validation loss: 196.56881202925035\n",
      "Training epoch 1245...\n",
      "\n",
      "Train Epoch: 1245 [0/8000 (0%)]\tBatch Loss: 1145.943588\tLearning Rate (w_theta): 0.001000\t TIME:964.2s\n",
      "\t\t\t\tDisc: 1.924820\t\tSym: 22.923187\t\tSpars: 1121.095581\n",
      "\t TVw: -0.513633 | TVb: -2.043259 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1245 [4000/8000 (50%)]\tBatch Loss: 1166.606408\tLearning Rate (w_theta): 0.001000\t TIME:965.7s\n",
      "\t\t\t\tDisc: 1.874644\t\tSym: 22.435499\t\tSpars: 1142.296265\n",
      "\t TVw: -0.513578 | TVb: -2.043259 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1245...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1174.2970253412382\n",
      "Average validation loss: 193.7106381102634\n",
      "Training epoch 1246...\n",
      "\n",
      "Train Epoch: 1246 [0/8000 (0%)]\tBatch Loss: 1233.560323\tLearning Rate (w_theta): 0.001000\t TIME:968.1s\n",
      "\t\t\t\tDisc: 1.847942\t\tSym: 23.861307\t\tSpars: 1207.851074\n",
      "\t TVw: -0.513524 | TVb: -2.043259 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1246 [4000/8000 (50%)]\tBatch Loss: 1186.955030\tLearning Rate (w_theta): 0.001000\t TIME:969.7s\n",
      "\t\t\t\tDisc: 1.645050\t\tSym: 21.781904\t\tSpars: 1163.528076\n",
      "\t TVw: -0.513470 | TVb: -2.043260 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1246...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1167.0142925524895\n",
      "Average validation loss: 197.5414254662492\n",
      "Training epoch 1247...\n",
      "\n",
      "Train Epoch: 1247 [0/8000 (0%)]\tBatch Loss: 1189.231625\tLearning Rate (w_theta): 0.001000\t TIME:971.9s\n",
      "\t\t\t\tDisc: 1.909091\t\tSym: 23.154200\t\tSpars: 1164.168335\n",
      "\t TVw: -0.513415 | TVb: -2.043260 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1247 [4000/8000 (50%)]\tBatch Loss: 1107.921434\tLearning Rate (w_theta): 0.001000\t TIME:973.5s\n",
      "\t\t\t\tDisc: 1.397523\t\tSym: 19.396957\t\tSpars: 1087.126953\n",
      "\t TVw: -0.513358 | TVb: -2.043260 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1247...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1150.1918387136484\n",
      "Average validation loss: 199.23853360313643\n",
      "Training epoch 1248...\n",
      "\n",
      "Train Epoch: 1248 [0/8000 (0%)]\tBatch Loss: 1175.398099\tLearning Rate (w_theta): 0.001000\t TIME:975.8s\n",
      "\t\t\t\tDisc: 1.697284\t\tSym: 24.151377\t\tSpars: 1149.549438\n",
      "\t TVw: -0.513300 | TVb: -2.043260 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1248 [4000/8000 (50%)]\tBatch Loss: 1086.660162\tLearning Rate (w_theta): 0.001000\t TIME:977.3s\n",
      "\t\t\t\tDisc: 1.331564\t\tSym: 18.634262\t\tSpars: 1066.694336\n",
      "\t TVw: -0.513242 | TVb: -2.043260 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1248...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1147.43628775626\n",
      "Average validation loss: 196.92716392835973\n",
      "Training epoch 1249...\n",
      "\n",
      "Train Epoch: 1249 [0/8000 (0%)]\tBatch Loss: 1117.612680\tLearning Rate (w_theta): 0.001000\t TIME:979.6s\n",
      "\t\t\t\tDisc: 1.435581\t\tSym: 19.395727\t\tSpars: 1096.781372\n",
      "\t TVw: -0.513184 | TVb: -2.043260 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1249 [4000/8000 (50%)]\tBatch Loss: 1157.277668\tLearning Rate (w_theta): 0.001000\t TIME:981.1s\n",
      "\t\t\t\tDisc: 1.670729\t\tSym: 22.514044\t\tSpars: 1133.092896\n",
      "\t TVw: -0.513126 | TVb: -2.043260 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1249...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1145.0741034057\n",
      "Average validation loss: 201.11184197854536\n",
      "Training epoch 1250...\n",
      "\n",
      "Train Epoch: 1250 [0/8000 (0%)]\tBatch Loss: 1121.548351\tLearning Rate (w_theta): 0.001000\t TIME:983.4s\n",
      "\t\t\t\tDisc: 1.487710\t\tSym: 20.030001\t\tSpars: 1100.030640\n",
      "\t TVw: -0.513068 | TVb: -2.043260 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1250 [4000/8000 (50%)]\tBatch Loss: 1129.087541\tLearning Rate (w_theta): 0.001000\t TIME:984.9s\n",
      "\t\t\t\tDisc: 1.533880\t\tSym: 20.992992\t\tSpars: 1106.560669\n",
      "\t TVw: -0.513009 | TVb: -2.043260 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1250...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1146.8543919135993\n",
      "Average validation loss: 198.10018574829266\n",
      "Training epoch 1251...\n",
      "\n",
      "Train Epoch: 1251 [0/8000 (0%)]\tBatch Loss: 1208.620134\tLearning Rate (w_theta): 0.001000\t TIME:988.0s\n",
      "\t\t\t\tDisc: 1.971561\t\tSym: 24.957899\t\tSpars: 1181.690674\n",
      "\t TVw: -0.512951 | TVb: -2.043260 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1251 [4000/8000 (50%)]\tBatch Loss: 1113.060181\tLearning Rate (w_theta): 0.001000\t TIME:989.5s\n",
      "\t\t\t\tDisc: 1.500170\t\tSym: 19.551954\t\tSpars: 1092.008057\n",
      "\t TVw: -0.512893 | TVb: -2.043260 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1251...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1145.0953383298072\n",
      "Average validation loss: 195.49099275052532\n",
      "Training epoch 1252...\n",
      "\n",
      "Train Epoch: 1252 [0/8000 (0%)]\tBatch Loss: 1135.420906\tLearning Rate (w_theta): 0.001000\t TIME:991.9s\n",
      "\t\t\t\tDisc: 1.496282\t\tSym: 21.334536\t\tSpars: 1112.590088\n",
      "\t TVw: -0.512835 | TVb: -2.043260 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1252 [4000/8000 (50%)]\tBatch Loss: 1179.555556\tLearning Rate (w_theta): 0.001000\t TIME:993.4s\n",
      "\t\t\t\tDisc: 1.338166\t\tSym: 22.568098\t\tSpars: 1155.649292\n",
      "\t TVw: -0.512777 | TVb: -2.043260 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1252...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1157.5764647589974\n",
      "Average validation loss: 197.5179679572297\n",
      "Training epoch 1253...\n",
      "\n",
      "Train Epoch: 1253 [0/8000 (0%)]\tBatch Loss: 1233.382156\tLearning Rate (w_theta): 0.001000\t TIME:995.7s\n",
      "\t\t\t\tDisc: 1.502870\t\tSym: 24.512342\t\tSpars: 1207.366943\n",
      "\t TVw: -0.512719 | TVb: -2.043261 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1253 [4000/8000 (50%)]\tBatch Loss: 1186.172138\tLearning Rate (w_theta): 0.001000\t TIME:997.2s\n",
      "\t\t\t\tDisc: 1.439212\t\tSym: 23.130753\t\tSpars: 1161.602173\n",
      "\t TVw: -0.512662 | TVb: -2.043261 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1253...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1171.30839335119\n",
      "Average validation loss: 193.41104763029614\n",
      "Training epoch 1254...\n",
      "\n",
      "Train Epoch: 1254 [0/8000 (0%)]\tBatch Loss: 1179.830866\tLearning Rate (w_theta): 0.001000\t TIME:999.5s\n",
      "\t\t\t\tDisc: 1.606741\t\tSym: 22.833256\t\tSpars: 1155.390869\n",
      "\t TVw: -0.512605 | TVb: -2.043261 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1254 [4000/8000 (50%)]\tBatch Loss: 1171.984893\tLearning Rate (w_theta): 0.001000\t TIME:1001.0s\n",
      "\t\t\t\tDisc: 1.600770\t\tSym: 23.078215\t\tSpars: 1147.305908\n",
      "\t TVw: -0.512547 | TVb: -2.043261 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1254...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1152.819021916374\n",
      "Average validation loss: 193.44493679611614\n",
      "Training epoch 1255...\n",
      "\n",
      "Train Epoch: 1255 [0/8000 (0%)]\tBatch Loss: 1147.886860\tLearning Rate (w_theta): 0.001000\t TIME:1003.4s\n",
      "\t\t\t\tDisc: 1.455147\t\tSym: 22.016552\t\tSpars: 1124.415161\n",
      "\t TVw: -0.512488 | TVb: -2.043261 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1255 [4000/8000 (50%)]\tBatch Loss: 1150.218776\tLearning Rate (w_theta): 0.001000\t TIME:1005.0s\n",
      "\t\t\t\tDisc: 1.588300\t\tSym: 21.565535\t\tSpars: 1127.064941\n",
      "\t TVw: -0.512427 | TVb: -2.043262 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1255...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1160.1631138245666\n",
      "Average validation loss: 193.21594063898107\n",
      "Training epoch 1256...\n",
      "\n",
      "Train Epoch: 1256 [0/8000 (0%)]\tBatch Loss: 1165.003512\tLearning Rate (w_theta): 0.001000\t TIME:1007.3s\n",
      "\t\t\t\tDisc: 1.764332\t\tSym: 22.476118\t\tSpars: 1140.763062\n",
      "\t TVw: -0.512368 | TVb: -2.043262 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1256 [4000/8000 (50%)]\tBatch Loss: 1168.698159\tLearning Rate (w_theta): 0.001000\t TIME:1008.8s\n",
      "\t\t\t\tDisc: 1.607758\t\tSym: 20.846382\t\tSpars: 1146.244019\n",
      "\t TVw: -0.512308 | TVb: -2.043262 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1256...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1172.9507816654318\n",
      "Average validation loss: 194.95883537731564\n",
      "Training epoch 1257...\n",
      "\n",
      "Train Epoch: 1257 [0/8000 (0%)]\tBatch Loss: 1141.952278\tLearning Rate (w_theta): 0.001000\t TIME:1011.1s\n",
      "\t\t\t\tDisc: 1.524705\t\tSym: 20.462851\t\tSpars: 1119.964722\n",
      "\t TVw: -0.512249 | TVb: -2.043262 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1257 [4000/8000 (50%)]\tBatch Loss: 1132.109353\tLearning Rate (w_theta): 0.001000\t TIME:1012.6s\n",
      "\t\t\t\tDisc: 1.530135\t\tSym: 20.274530\t\tSpars: 1110.304688\n",
      "\t TVw: -0.512189 | TVb: -2.043262 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1257...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1177.3649139342263\n",
      "Average validation loss: 193.34444166071097\n",
      "Training epoch 1258...\n",
      "\n",
      "Train Epoch: 1258 [0/8000 (0%)]\tBatch Loss: 1158.454125\tLearning Rate (w_theta): 0.001000\t TIME:1014.9s\n",
      "\t\t\t\tDisc: 1.677706\t\tSym: 21.609549\t\tSpars: 1135.166870\n",
      "\t TVw: -0.512128 | TVb: -2.043263 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1258 [4000/8000 (50%)]\tBatch Loss: 1201.663617\tLearning Rate (w_theta): 0.001000\t TIME:1016.5s\n",
      "\t\t\t\tDisc: 1.848939\t\tSym: 23.558941\t\tSpars: 1176.255737\n",
      "\t TVw: -0.512067 | TVb: -2.043263 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1258...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1166.2873938156288\n",
      "Average validation loss: 193.87625197534328\n",
      "Training epoch 1259...\n",
      "\n",
      "Train Epoch: 1259 [0/8000 (0%)]\tBatch Loss: 1115.616277\tLearning Rate (w_theta): 0.001000\t TIME:1018.8s\n",
      "\t\t\t\tDisc: 1.597755\t\tSym: 19.657682\t\tSpars: 1094.360840\n",
      "\t TVw: -0.512005 | TVb: -2.043263 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1259 [4000/8000 (50%)]\tBatch Loss: 1152.566895\tLearning Rate (w_theta): 0.001000\t TIME:1020.3s\n",
      "\t\t\t\tDisc: 1.532559\t\tSym: 20.442295\t\tSpars: 1130.592041\n",
      "\t TVw: -0.511944 | TVb: -2.043264 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1259...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1161.5694199754835\n",
      "Average validation loss: 196.79101439578906\n",
      "Training epoch 1260...\n",
      "\n",
      "Train Epoch: 1260 [0/8000 (0%)]\tBatch Loss: 1147.768831\tLearning Rate (w_theta): 0.001000\t TIME:1022.7s\n",
      "\t\t\t\tDisc: 1.646277\t\tSym: 20.851315\t\tSpars: 1125.271240\n",
      "\t TVw: -0.511884 | TVb: -2.043264 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1260 [4000/8000 (50%)]\tBatch Loss: 1172.914218\tLearning Rate (w_theta): 0.001000\t TIME:1024.2s\n",
      "\t\t\t\tDisc: 1.711189\t\tSym: 21.994534\t\tSpars: 1149.208496\n",
      "\t TVw: -0.511825 | TVb: -2.043264 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1260...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1160.1281024154946\n",
      "Average validation loss: 199.6691849924896\n",
      "Training epoch 1261...\n",
      "\n",
      "Train Epoch: 1261 [0/8000 (0%)]\tBatch Loss: 1134.781004\tLearning Rate (w_theta): 0.001000\t TIME:1027.2s\n",
      "\t\t\t\tDisc: 1.605316\t\tSym: 21.197538\t\tSpars: 1111.978149\n",
      "\t TVw: -0.511766 | TVb: -2.043264 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1261 [4000/8000 (50%)]\tBatch Loss: 1131.045902\tLearning Rate (w_theta): 0.001000\t TIME:1028.7s\n",
      "\t\t\t\tDisc: 1.598164\t\tSym: 21.740952\t\tSpars: 1107.706787\n",
      "\t TVw: -0.511706 | TVb: -2.043264 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1261...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1147.9441081199707\n",
      "Average validation loss: 200.75438255915952\n",
      "Training epoch 1262...\n",
      "\n",
      "Train Epoch: 1262 [0/8000 (0%)]\tBatch Loss: 1162.418122\tLearning Rate (w_theta): 0.001000\t TIME:1031.0s\n",
      "\t\t\t\tDisc: 1.620061\t\tSym: 22.703823\t\tSpars: 1138.094238\n",
      "\t TVw: -0.511646 | TVb: -2.043265 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1262 [4000/8000 (50%)]\tBatch Loss: 1131.970340\tLearning Rate (w_theta): 0.001000\t TIME:1032.5s\n",
      "\t\t\t\tDisc: 1.435386\t\tSym: 21.032879\t\tSpars: 1109.502075\n",
      "\t TVw: -0.511584 | TVb: -2.043265 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1262...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1142.7268544454398\n",
      "Average validation loss: 196.98799578281117\n",
      "Training epoch 1263...\n",
      "\n",
      "Train Epoch: 1263 [0/8000 (0%)]\tBatch Loss: 1093.691522\tLearning Rate (w_theta): 0.001000\t TIME:1034.8s\n",
      "\t\t\t\tDisc: 1.541904\t\tSym: 19.679892\t\tSpars: 1072.469727\n",
      "\t TVw: -0.511523 | TVb: -2.043265 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1263 [4000/8000 (50%)]\tBatch Loss: 1142.102157\tLearning Rate (w_theta): 0.001000\t TIME:1036.3s\n",
      "\t\t\t\tDisc: 1.492467\t\tSym: 20.087107\t\tSpars: 1120.522583\n",
      "\t TVw: -0.511462 | TVb: -2.043265 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1263...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1140.0381639680518\n",
      "Average validation loss: 197.08581163704667\n",
      "Training epoch 1264...\n",
      "\n",
      "Train Epoch: 1264 [0/8000 (0%)]\tBatch Loss: 1189.470739\tLearning Rate (w_theta): 0.001000\t TIME:1038.8s\n",
      "\t\t\t\tDisc: 1.795263\t\tSym: 25.153381\t\tSpars: 1162.522095\n",
      "\t TVw: -0.511401 | TVb: -2.043265 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1264 [4000/8000 (50%)]\tBatch Loss: 1140.233335\tLearning Rate (w_theta): 0.001000\t TIME:1040.3s\n",
      "\t\t\t\tDisc: 1.553830\t\tSym: 21.252014\t\tSpars: 1117.427490\n",
      "\t TVw: -0.511340 | TVb: -2.043265 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1264...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1140.0761673336935\n",
      "Average validation loss: 197.63231758690378\n",
      "Training epoch 1265...\n",
      "\n",
      "Train Epoch: 1265 [0/8000 (0%)]\tBatch Loss: 1146.517294\tLearning Rate (w_theta): 0.001000\t TIME:1042.6s\n",
      "\t\t\t\tDisc: 1.576843\t\tSym: 21.175680\t\tSpars: 1123.764771\n",
      "\t TVw: -0.511279 | TVb: -2.043265 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1265 [4000/8000 (50%)]\tBatch Loss: 1124.970216\tLearning Rate (w_theta): 0.001000\t TIME:1044.1s\n",
      "\t\t\t\tDisc: 1.521587\t\tSym: 20.545797\t\tSpars: 1102.902832\n",
      "\t TVw: -0.511217 | TVb: -2.043265 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1265...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1138.82982916937\n",
      "Average validation loss: 194.58686680446394\n",
      "Training epoch 1266...\n",
      "\n",
      "Train Epoch: 1266 [0/8000 (0%)]\tBatch Loss: 1158.729084\tLearning Rate (w_theta): 0.001000\t TIME:1046.4s\n",
      "\t\t\t\tDisc: 1.567047\t\tSym: 22.091358\t\tSpars: 1135.070679\n",
      "\t TVw: -0.511155 | TVb: -2.043265 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1266 [4000/8000 (50%)]\tBatch Loss: 1177.129632\tLearning Rate (w_theta): 0.001000\t TIME:1048.0s\n",
      "\t\t\t\tDisc: 1.707515\t\tSym: 24.413328\t\tSpars: 1151.008789\n",
      "\t TVw: -0.511092 | TVb: -2.043265 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1266...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1135.8467671965532\n",
      "Average validation loss: 195.50892342584496\n",
      "Training epoch 1267...\n",
      "\n",
      "Train Epoch: 1267 [0/8000 (0%)]\tBatch Loss: 1150.490240\tLearning Rate (w_theta): 0.001000\t TIME:1050.3s\n",
      "\t\t\t\tDisc: 1.621803\t\tSym: 21.821318\t\tSpars: 1127.047119\n",
      "\t TVw: -0.511029 | TVb: -2.043265 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1267 [4000/8000 (50%)]\tBatch Loss: 1149.395816\tLearning Rate (w_theta): 0.001000\t TIME:1051.8s\n",
      "\t\t\t\tDisc: 1.615506\t\tSym: 21.309118\t\tSpars: 1126.471191\n",
      "\t TVw: -0.510965 | TVb: -2.043265 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1267...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1135.3673170333027\n",
      "Average validation loss: 195.9116558130807\n",
      "Training epoch 1268...\n",
      "\n",
      "Train Epoch: 1268 [0/8000 (0%)]\tBatch Loss: 1152.908090\tLearning Rate (w_theta): 0.001000\t TIME:1054.1s\n",
      "\t\t\t\tDisc: 1.589161\t\tSym: 21.780600\t\tSpars: 1129.538330\n",
      "\t TVw: -0.510902 | TVb: -2.043265 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1268 [4000/8000 (50%)]\tBatch Loss: 1150.613036\tLearning Rate (w_theta): 0.001000\t TIME:1055.6s\n",
      "\t\t\t\tDisc: 1.775359\t\tSym: 21.574127\t\tSpars: 1127.263550\n",
      "\t TVw: -0.510840 | TVb: -2.043265 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1268...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1144.5628047659718\n",
      "Average validation loss: 194.34376615997184\n",
      "Training epoch 1269...\n",
      "\n",
      "Train Epoch: 1269 [0/8000 (0%)]\tBatch Loss: 1152.959116\tLearning Rate (w_theta): 0.001000\t TIME:1058.0s\n",
      "\t\t\t\tDisc: 1.730713\t\tSym: 21.179819\t\tSpars: 1130.048584\n",
      "\t TVw: -0.510777 | TVb: -2.043265 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1269 [4000/8000 (50%)]\tBatch Loss: 1124.045291\tLearning Rate (w_theta): 0.001000\t TIME:1059.6s\n",
      "\t\t\t\tDisc: 1.556867\t\tSym: 19.500143\t\tSpars: 1102.988281\n",
      "\t TVw: -0.510716 | TVb: -2.043265 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1269...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1152.822038338532\n",
      "Average validation loss: 193.63078180331186\n",
      "Training epoch 1270...\n",
      "\n",
      "Train Epoch: 1270 [0/8000 (0%)]\tBatch Loss: 1154.210166\tLearning Rate (w_theta): 0.001000\t TIME:1061.9s\n",
      "\t\t\t\tDisc: 1.814397\t\tSym: 21.702776\t\tSpars: 1130.692993\n",
      "\t TVw: -0.510655 | TVb: -2.043265 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1270 [4000/8000 (50%)]\tBatch Loss: 1139.961595\tLearning Rate (w_theta): 0.001000\t TIME:1063.4s\n",
      "\t\t\t\tDisc: 1.685390\t\tSym: 20.854086\t\tSpars: 1117.422119\n",
      "\t TVw: -0.510593 | TVb: -2.043266 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1270...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1157.6579701776718\n",
      "Average validation loss: 193.6718797667171\n",
      "Training epoch 1271...\n",
      "\n",
      "Train Epoch: 1271 [0/8000 (0%)]\tBatch Loss: 1146.064197\tLearning Rate (w_theta): 0.001000\t TIME:1066.3s\n",
      "\t\t\t\tDisc: 1.851270\t\tSym: 21.792517\t\tSpars: 1122.420410\n",
      "\t TVw: -0.510532 | TVb: -2.043266 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1271 [4000/8000 (50%)]\tBatch Loss: 1150.605852\tLearning Rate (w_theta): 0.001000\t TIME:1067.8s\n",
      "\t\t\t\tDisc: 1.632403\t\tSym: 21.718323\t\tSpars: 1127.255127\n",
      "\t TVw: -0.510470 | TVb: -2.043267 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1271...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1149.2016727909695\n",
      "Average validation loss: 197.15620759243436\n",
      "Training epoch 1272...\n",
      "\n",
      "Train Epoch: 1272 [0/8000 (0%)]\tBatch Loss: 1152.972593\tLearning Rate (w_theta): 0.001000\t TIME:1070.1s\n",
      "\t\t\t\tDisc: 1.502939\t\tSym: 21.646534\t\tSpars: 1129.823120\n",
      "\t TVw: -0.510407 | TVb: -2.043267 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1272 [4000/8000 (50%)]\tBatch Loss: 1149.256347\tLearning Rate (w_theta): 0.001000\t TIME:1071.6s\n",
      "\t\t\t\tDisc: 1.540292\t\tSym: 22.218130\t\tSpars: 1125.497925\n",
      "\t TVw: -0.510343 | TVb: -2.043267 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1272...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1136.6226126204083\n",
      "Average validation loss: 195.48571647324692\n",
      "Training epoch 1273...\n",
      "\n",
      "Train Epoch: 1273 [0/8000 (0%)]\tBatch Loss: 1146.841467\tLearning Rate (w_theta): 0.001000\t TIME:1074.1s\n",
      "\t\t\t\tDisc: 1.526240\t\tSym: 21.055950\t\tSpars: 1124.259277\n",
      "\t TVw: -0.510278 | TVb: -2.043267 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1273 [4000/8000 (50%)]\tBatch Loss: 1131.547264\tLearning Rate (w_theta): 0.001000\t TIME:1075.6s\n",
      "\t\t\t\tDisc: 1.587228\t\tSym: 21.479689\t\tSpars: 1108.480347\n",
      "\t TVw: -0.510212 | TVb: -2.043267 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1273...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1133.8338106275423\n",
      "Average validation loss: 194.52398891900407\n",
      "Training epoch 1274...\n",
      "\n",
      "Train Epoch: 1274 [0/8000 (0%)]\tBatch Loss: 1130.006179\tLearning Rate (w_theta): 0.001000\t TIME:1077.9s\n",
      "\t\t\t\tDisc: 1.570789\t\tSym: 21.474941\t\tSpars: 1106.960449\n",
      "\t TVw: -0.510147 | TVb: -2.043267 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1274 [4000/8000 (50%)]\tBatch Loss: 1117.328778\tLearning Rate (w_theta): 0.001000\t TIME:1079.4s\n",
      "\t\t\t\tDisc: 1.456883\t\tSym: 20.239204\t\tSpars: 1095.632690\n",
      "\t TVw: -0.510080 | TVb: -2.043267 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1274...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1135.3102959778903\n",
      "Average validation loss: 194.94853562595787\n",
      "Training epoch 1275...\n",
      "\n",
      "Train Epoch: 1275 [0/8000 (0%)]\tBatch Loss: 1142.457604\tLearning Rate (w_theta): 0.001000\t TIME:1081.8s\n",
      "\t\t\t\tDisc: 1.651278\t\tSym: 22.190481\t\tSpars: 1118.615845\n",
      "\t TVw: -0.510015 | TVb: -2.043267 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1275 [4000/8000 (50%)]\tBatch Loss: 1147.562496\tLearning Rate (w_theta): 0.001000\t TIME:1083.3s\n",
      "\t\t\t\tDisc: 1.753364\t\tSym: 22.278492\t\tSpars: 1123.530640\n",
      "\t TVw: -0.509949 | TVb: -2.043267 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1275...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1134.2468210580964\n",
      "Average validation loss: 194.71723022989545\n",
      "Training epoch 1276...\n",
      "\n",
      "Train Epoch: 1276 [0/8000 (0%)]\tBatch Loss: 1141.477219\tLearning Rate (w_theta): 0.001000\t TIME:1085.6s\n",
      "\t\t\t\tDisc: 1.562655\t\tSym: 21.706678\t\tSpars: 1118.207886\n",
      "\t TVw: -0.509883 | TVb: -2.043267 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1276 [4000/8000 (50%)]\tBatch Loss: 1128.710255\tLearning Rate (w_theta): 0.001000\t TIME:1087.1s\n",
      "\t\t\t\tDisc: 1.504730\t\tSym: 19.536091\t\tSpars: 1107.669434\n",
      "\t TVw: -0.509818 | TVb: -2.043267 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1276...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1136.1227243210187\n",
      "Average validation loss: 194.58177615908036\n",
      "Training epoch 1277...\n",
      "\n",
      "Train Epoch: 1277 [0/8000 (0%)]\tBatch Loss: 1161.525842\tLearning Rate (w_theta): 0.001000\t TIME:1089.5s\n",
      "\t\t\t\tDisc: 1.840228\t\tSym: 23.751654\t\tSpars: 1135.933960\n",
      "\t TVw: -0.509753 | TVb: -2.043267 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1277 [4000/8000 (50%)]\tBatch Loss: 1143.639493\tLearning Rate (w_theta): 0.001000\t TIME:1091.0s\n",
      "\t\t\t\tDisc: 1.566030\t\tSym: 22.273903\t\tSpars: 1119.799561\n",
      "\t TVw: -0.509687 | TVb: -2.043267 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1277...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1134.5061392498276\n",
      "Average validation loss: 194.8664049289314\n",
      "Training epoch 1278...\n",
      "\n",
      "Train Epoch: 1278 [0/8000 (0%)]\tBatch Loss: 1137.363010\tLearning Rate (w_theta): 0.001000\t TIME:1093.3s\n",
      "\t\t\t\tDisc: 1.612932\t\tSym: 21.326738\t\tSpars: 1114.423340\n",
      "\t TVw: -0.509620 | TVb: -2.043267 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1278 [4000/8000 (50%)]\tBatch Loss: 1124.022725\tLearning Rate (w_theta): 0.001000\t TIME:1094.9s\n",
      "\t\t\t\tDisc: 1.523830\t\tSym: 20.206537\t\tSpars: 1102.292358\n",
      "\t TVw: -0.509554 | TVb: -2.043267 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1278...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1133.5523441770777\n",
      "Average validation loss: 194.7862242785407\n",
      "Training epoch 1279...\n",
      "\n",
      "Train Epoch: 1279 [0/8000 (0%)]\tBatch Loss: 1135.322803\tLearning Rate (w_theta): 0.001000\t TIME:1097.3s\n",
      "\t\t\t\tDisc: 1.542000\t\tSym: 20.746502\t\tSpars: 1113.034302\n",
      "\t TVw: -0.509488 | TVb: -2.043267 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1279 [4000/8000 (50%)]\tBatch Loss: 1167.224970\tLearning Rate (w_theta): 0.001000\t TIME:1098.8s\n",
      "\t\t\t\tDisc: 1.513970\t\tSym: 22.743349\t\tSpars: 1142.967651\n",
      "\t TVw: -0.509423 | TVb: -2.043267 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1279...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1140.719134356927\n",
      "Average validation loss: 193.95686262509514\n",
      "Training epoch 1280...\n",
      "\n",
      "Train Epoch: 1280 [0/8000 (0%)]\tBatch Loss: 1109.530636\tLearning Rate (w_theta): 0.001000\t TIME:1101.1s\n",
      "\t\t\t\tDisc: 1.507925\t\tSym: 20.418463\t\tSpars: 1087.604248\n",
      "\t TVw: -0.509357 | TVb: -2.043267 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1280 [4000/8000 (50%)]\tBatch Loss: 1160.269322\tLearning Rate (w_theta): 0.001000\t TIME:1102.6s\n",
      "\t\t\t\tDisc: 1.745801\t\tSym: 22.187096\t\tSpars: 1136.336426\n",
      "\t TVw: -0.509291 | TVb: -2.043267 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1280...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1137.3965774632945\n",
      "Average validation loss: 195.93573517491308\n",
      "Training epoch 1281...\n",
      "\n",
      "Train Epoch: 1281 [0/8000 (0%)]\tBatch Loss: 1142.138829\tLearning Rate (w_theta): 0.001000\t TIME:1105.7s\n",
      "\t\t\t\tDisc: 1.545721\t\tSym: 21.533903\t\tSpars: 1119.059204\n",
      "\t TVw: -0.509225 | TVb: -2.043267 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1281 [4000/8000 (50%)]\tBatch Loss: 1167.719243\tLearning Rate (w_theta): 0.001000\t TIME:1107.2s\n",
      "\t\t\t\tDisc: 1.605596\t\tSym: 22.919067\t\tSpars: 1143.194580\n",
      "\t TVw: -0.509159 | TVb: -2.043267 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1281...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1135.3937672590318\n",
      "Average validation loss: 192.74870131164192\n",
      "Training epoch 1282...\n",
      "\n",
      "Train Epoch: 1282 [0/8000 (0%)]\tBatch Loss: 1155.709859\tLearning Rate (w_theta): 0.001000\t TIME:1109.7s\n",
      "\t\t\t\tDisc: 1.805818\t\tSym: 22.389637\t\tSpars: 1131.514404\n",
      "\t TVw: -0.509092 | TVb: -2.043268 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1282 [4000/8000 (50%)]\tBatch Loss: 1158.490213\tLearning Rate (w_theta): 0.001000\t TIME:1111.2s\n",
      "\t\t\t\tDisc: 1.670423\t\tSym: 22.902187\t\tSpars: 1133.917603\n",
      "\t TVw: -0.509025 | TVb: -2.043268 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1282...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1141.7318789010462\n",
      "Average validation loss: 196.66760548366761\n",
      "Training epoch 1283...\n",
      "\n",
      "Train Epoch: 1283 [0/8000 (0%)]\tBatch Loss: 1139.975917\tLearning Rate (w_theta): 0.001000\t TIME:1113.5s\n",
      "\t\t\t\tDisc: 1.579884\t\tSym: 21.675940\t\tSpars: 1116.720093\n",
      "\t TVw: -0.508958 | TVb: -2.043268 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1283 [4000/8000 (50%)]\tBatch Loss: 1101.846209\tLearning Rate (w_theta): 0.001000\t TIME:1115.0s\n",
      "\t\t\t\tDisc: 1.487910\t\tSym: 19.475121\t\tSpars: 1080.883179\n",
      "\t TVw: -0.508892 | TVb: -2.043268 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1283...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1135.3334305965811\n",
      "Average validation loss: 194.38303262272146\n",
      "Training epoch 1284...\n",
      "\n",
      "Train Epoch: 1284 [0/8000 (0%)]\tBatch Loss: 1119.700512\tLearning Rate (w_theta): 0.001000\t TIME:1117.4s\n",
      "\t\t\t\tDisc: 1.485520\t\tSym: 20.007473\t\tSpars: 1098.207520\n",
      "\t TVw: -0.508826 | TVb: -2.043269 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1284 [4000/8000 (50%)]\tBatch Loss: 1131.798071\tLearning Rate (w_theta): 0.001000\t TIME:1118.9s\n",
      "\t\t\t\tDisc: 1.470595\t\tSym: 21.321007\t\tSpars: 1109.006470\n",
      "\t TVw: -0.508759 | TVb: -2.043269 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1284...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1132.6655590930552\n",
      "Average validation loss: 192.48919482076803\n",
      "Training epoch 1285...\n",
      "\n",
      "Train Epoch: 1285 [0/8000 (0%)]\tBatch Loss: 1178.686945\tLearning Rate (w_theta): 0.001000\t TIME:1121.3s\n",
      "\t\t\t\tDisc: 1.670971\t\tSym: 23.870222\t\tSpars: 1153.145752\n",
      "\t TVw: -0.508692 | TVb: -2.043269 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1285 [4000/8000 (50%)]\tBatch Loss: 1111.977433\tLearning Rate (w_theta): 0.001000\t TIME:1122.8s\n",
      "\t\t\t\tDisc: 1.415827\t\tSym: 19.465048\t\tSpars: 1091.096558\n",
      "\t TVw: -0.508625 | TVb: -2.043269 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1285...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1133.9237758490399\n",
      "Average validation loss: 191.98492243631287\n",
      "Training epoch 1286...\n",
      "\n",
      "Train Epoch: 1286 [0/8000 (0%)]\tBatch Loss: 1156.976852\tLearning Rate (w_theta): 0.001000\t TIME:1125.1s\n",
      "\t\t\t\tDisc: 1.578708\t\tSym: 21.186596\t\tSpars: 1134.211548\n",
      "\t TVw: -0.508556 | TVb: -2.043269 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1286 [4000/8000 (50%)]\tBatch Loss: 1110.457688\tLearning Rate (w_theta): 0.001000\t TIME:1126.6s\n",
      "\t\t\t\tDisc: 1.447153\t\tSym: 19.701574\t\tSpars: 1089.308960\n",
      "\t TVw: -0.508489 | TVb: -2.043269 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1286...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1135.162736078265\n",
      "Average validation loss: 193.39795479084026\n",
      "Training epoch 1287...\n",
      "\n",
      "Train Epoch: 1287 [0/8000 (0%)]\tBatch Loss: 1157.929270\tLearning Rate (w_theta): 0.001000\t TIME:1129.0s\n",
      "\t\t\t\tDisc: 1.371681\t\tSym: 21.651827\t\tSpars: 1134.905762\n",
      "\t TVw: -0.508421 | TVb: -2.043269 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1287 [4000/8000 (50%)]\tBatch Loss: 1123.964987\tLearning Rate (w_theta): 0.001000\t TIME:1130.5s\n",
      "\t\t\t\tDisc: 1.634201\t\tSym: 22.086157\t\tSpars: 1100.244629\n",
      "\t TVw: -0.508354 | TVb: -2.043269 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1287...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1138.5810787549492\n",
      "Average validation loss: 191.55178070846137\n",
      "Training epoch 1288...\n",
      "\n",
      "Train Epoch: 1288 [0/8000 (0%)]\tBatch Loss: 1199.608907\tLearning Rate (w_theta): 0.001000\t TIME:1132.9s\n",
      "\t\t\t\tDisc: 1.974077\t\tSym: 24.304386\t\tSpars: 1173.330444\n",
      "\t TVw: -0.508287 | TVb: -2.043269 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1288 [4000/8000 (50%)]\tBatch Loss: 1140.053124\tLearning Rate (w_theta): 0.001000\t TIME:1134.4s\n",
      "\t\t\t\tDisc: 1.609699\t\tSym: 22.275089\t\tSpars: 1116.168335\n",
      "\t TVw: -0.508220 | TVb: -2.043269 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1288...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1134.7670547391804\n",
      "Average validation loss: 193.42906217157636\n",
      "Training epoch 1289...\n",
      "\n",
      "Train Epoch: 1289 [0/8000 (0%)]\tBatch Loss: 1167.908204\tLearning Rate (w_theta): 0.001000\t TIME:1136.8s\n",
      "\t\t\t\tDisc: 1.347973\t\tSym: 21.752247\t\tSpars: 1144.807983\n",
      "\t TVw: -0.508152 | TVb: -2.043270 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1289 [4000/8000 (50%)]\tBatch Loss: 1138.542382\tLearning Rate (w_theta): 0.001000\t TIME:1138.3s\n",
      "\t\t\t\tDisc: 1.474963\t\tSym: 21.740271\t\tSpars: 1115.327148\n",
      "\t TVw: -0.508084 | TVb: -2.043270 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1289...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1146.9765622169248\n",
      "Average validation loss: 191.65833604291706\n",
      "Training epoch 1290...\n",
      "\n",
      "Train Epoch: 1290 [0/8000 (0%)]\tBatch Loss: 1114.917001\tLearning Rate (w_theta): 0.001000\t TIME:1140.6s\n",
      "\t\t\t\tDisc: 1.651399\t\tSym: 20.524025\t\tSpars: 1092.741577\n",
      "\t TVw: -0.508017 | TVb: -2.043270 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1290 [4000/8000 (50%)]\tBatch Loss: 1134.984238\tLearning Rate (w_theta): 0.001000\t TIME:1142.1s\n",
      "\t\t\t\tDisc: 1.635569\t\tSym: 19.929846\t\tSpars: 1113.418823\n",
      "\t TVw: -0.507951 | TVb: -2.043270 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1290...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1141.7195134226097\n",
      "Average validation loss: 190.4560594344788\n",
      "Training epoch 1291...\n",
      "\n",
      "Train Epoch: 1291 [0/8000 (0%)]\tBatch Loss: 1202.078040\tLearning Rate (w_theta): 0.001000\t TIME:1145.1s\n",
      "\t\t\t\tDisc: 2.002958\t\tSym: 23.977304\t\tSpars: 1176.097778\n",
      "\t TVw: -0.507884 | TVb: -2.043271 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1291 [4000/8000 (50%)]\tBatch Loss: 1154.651585\tLearning Rate (w_theta): 0.001000\t TIME:1146.6s\n",
      "\t\t\t\tDisc: 1.648310\t\tSym: 21.436502\t\tSpars: 1131.566772\n",
      "\t TVw: -0.507817 | TVb: -2.043271 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1291...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1141.7868250026572\n",
      "Average validation loss: 189.7892385228379\n",
      "Training epoch 1292...\n",
      "\n",
      "Train Epoch: 1292 [0/8000 (0%)]\tBatch Loss: 1129.255240\tLearning Rate (w_theta): 0.001000\t TIME:1149.0s\n",
      "\t\t\t\tDisc: 1.488095\t\tSym: 20.784723\t\tSpars: 1106.982422\n",
      "\t TVw: -0.507750 | TVb: -2.043271 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1292 [4000/8000 (50%)]\tBatch Loss: 1148.049839\tLearning Rate (w_theta): 0.001000\t TIME:1150.6s\n",
      "\t\t\t\tDisc: 1.512478\t\tSym: 22.320686\t\tSpars: 1124.216675\n",
      "\t TVw: -0.507681 | TVb: -2.043271 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1292...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1137.251436026168\n",
      "Average validation loss: 188.16201873185028\n",
      "Training epoch 1293...\n",
      "\n",
      "Train Epoch: 1293 [0/8000 (0%)]\tBatch Loss: 1139.191926\tLearning Rate (w_theta): 0.001000\t TIME:1152.9s\n",
      "\t\t\t\tDisc: 1.825333\t\tSym: 23.098892\t\tSpars: 1114.267700\n",
      "\t TVw: -0.507611 | TVb: -2.043271 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1293 [4000/8000 (50%)]\tBatch Loss: 1101.058468\tLearning Rate (w_theta): 0.001000\t TIME:1154.5s\n",
      "\t\t\t\tDisc: 1.502453\t\tSym: 19.582626\t\tSpars: 1079.973389\n",
      "\t TVw: -0.507541 | TVb: -2.043271 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1293...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1136.9598888204005\n",
      "Average validation loss: 194.21862875216055\n",
      "Training epoch 1294...\n",
      "\n",
      "Train Epoch: 1294 [0/8000 (0%)]\tBatch Loss: 1156.828475\tLearning Rate (w_theta): 0.001000\t TIME:1156.8s\n",
      "\t\t\t\tDisc: 1.507381\t\tSym: 21.404102\t\tSpars: 1133.916992\n",
      "\t TVw: -0.507470 | TVb: -2.043272 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1294 [4000/8000 (50%)]\tBatch Loss: 1135.761890\tLearning Rate (w_theta): 0.001000\t TIME:1158.3s\n",
      "\t\t\t\tDisc: 1.613256\t\tSym: 21.207106\t\tSpars: 1112.941528\n",
      "\t TVw: -0.507400 | TVb: -2.043272 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1294...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1137.040981453581\n",
      "Average validation loss: 191.4857342200323\n",
      "Training epoch 1295...\n",
      "\n",
      "Train Epoch: 1295 [0/8000 (0%)]\tBatch Loss: 1124.469450\tLearning Rate (w_theta): 0.001000\t TIME:1160.6s\n",
      "\t\t\t\tDisc: 1.552870\t\tSym: 20.457230\t\tSpars: 1102.459351\n",
      "\t TVw: -0.507331 | TVb: -2.043272 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1295 [4000/8000 (50%)]\tBatch Loss: 1113.198478\tLearning Rate (w_theta): 0.001000\t TIME:1162.1s\n",
      "\t\t\t\tDisc: 1.500198\t\tSym: 20.438148\t\tSpars: 1091.260132\n",
      "\t TVw: -0.507261 | TVb: -2.043272 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1295...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1129.5799200453912\n",
      "Average validation loss: 190.17976377034168\n",
      "Training epoch 1296...\n",
      "\n",
      "Train Epoch: 1296 [0/8000 (0%)]\tBatch Loss: 1178.483548\tLearning Rate (w_theta): 0.001000\t TIME:1164.5s\n",
      "\t\t\t\tDisc: 1.676675\t\tSym: 22.525013\t\tSpars: 1154.281860\n",
      "\t TVw: -0.507192 | TVb: -2.043272 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1296 [4000/8000 (50%)]\tBatch Loss: 1087.114899\tLearning Rate (w_theta): 0.001000\t TIME:1166.0s\n",
      "\t\t\t\tDisc: 1.486973\t\tSym: 18.911739\t\tSpars: 1066.716187\n",
      "\t TVw: -0.507122 | TVb: -2.043273 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1296...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1136.6622747457068\n",
      "Average validation loss: 192.08419307657635\n",
      "Training epoch 1297...\n",
      "\n",
      "Train Epoch: 1297 [0/8000 (0%)]\tBatch Loss: 1157.105085\tLearning Rate (w_theta): 0.001000\t TIME:1168.5s\n",
      "\t\t\t\tDisc: 1.386291\t\tSym: 21.118574\t\tSpars: 1134.600220\n",
      "\t TVw: -0.507052 | TVb: -2.043273 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1297 [4000/8000 (50%)]\tBatch Loss: 1142.424401\tLearning Rate (w_theta): 0.001000\t TIME:1170.0s\n",
      "\t\t\t\tDisc: 1.548625\t\tSym: 20.994307\t\tSpars: 1119.881470\n",
      "\t TVw: -0.506983 | TVb: -2.043273 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1297...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1138.5372374497974\n",
      "Average validation loss: 190.09469269715964\n",
      "Training epoch 1298...\n",
      "\n",
      "Train Epoch: 1298 [0/8000 (0%)]\tBatch Loss: 1125.415970\tLearning Rate (w_theta): 0.001000\t TIME:1172.3s\n",
      "\t\t\t\tDisc: 1.454144\t\tSym: 19.215366\t\tSpars: 1104.746460\n",
      "\t TVw: -0.506914 | TVb: -2.043273 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1298 [4000/8000 (50%)]\tBatch Loss: 1153.291750\tLearning Rate (w_theta): 0.001000\t TIME:1173.8s\n",
      "\t\t\t\tDisc: 1.758049\t\tSym: 21.679087\t\tSpars: 1129.854614\n",
      "\t TVw: -0.506843 | TVb: -2.043273 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1298...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1134.0784616230928\n",
      "Average validation loss: 189.8645054387573\n",
      "Training epoch 1299...\n",
      "\n",
      "Train Epoch: 1299 [0/8000 (0%)]\tBatch Loss: 1119.654442\tLearning Rate (w_theta): 0.001000\t TIME:1176.1s\n",
      "\t\t\t\tDisc: 1.501612\t\tSym: 20.439695\t\tSpars: 1097.713135\n",
      "\t TVw: -0.506773 | TVb: -2.043273 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1299 [4000/8000 (50%)]\tBatch Loss: 1102.867968\tLearning Rate (w_theta): 0.001000\t TIME:1177.7s\n",
      "\t\t\t\tDisc: 1.500744\t\tSym: 20.017736\t\tSpars: 1081.349487\n",
      "\t TVw: -0.506702 | TVb: -2.043273 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1299...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1127.644997124873\n",
      "Average validation loss: 188.89874382810413\n",
      "Training epoch 1300...\n",
      "\n",
      "Train Epoch: 1300 [0/8000 (0%)]\tBatch Loss: 1097.198436\tLearning Rate (w_theta): 0.001000\t TIME:1180.0s\n",
      "\t\t\t\tDisc: 1.405935\t\tSym: 19.163473\t\tSpars: 1076.629028\n",
      "\t TVw: -0.506630 | TVb: -2.043273 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1300 [4000/8000 (50%)]\tBatch Loss: 1147.094409\tLearning Rate (w_theta): 0.001000\t TIME:1181.5s\n",
      "\t\t\t\tDisc: 1.241074\t\tSym: 20.630800\t\tSpars: 1125.222534\n",
      "\t TVw: -0.506558 | TVb: -2.043274 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1300...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1142.2489242153517\n",
      "Average validation loss: 190.5944847818358\n",
      "Training epoch 1301...\n",
      "\n",
      "Train Epoch: 1301 [0/8000 (0%)]\tBatch Loss: 1183.884854\tLearning Rate (w_theta): 0.001000\t TIME:1184.7s\n",
      "\t\t\t\tDisc: 1.423343\t\tSym: 24.007532\t\tSpars: 1158.453979\n",
      "\t TVw: -0.506488 | TVb: -2.043274 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1301 [4000/8000 (50%)]\tBatch Loss: 1153.880830\tLearning Rate (w_theta): 0.001000\t TIME:1186.2s\n",
      "\t\t\t\tDisc: 1.283849\t\tSym: 21.193295\t\tSpars: 1131.403687\n",
      "\t TVw: -0.506418 | TVb: -2.043274 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1301...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1147.7252427092617\n",
      "Average validation loss: 189.11567559888377\n",
      "Training epoch 1302...\n",
      "\n",
      "Train Epoch: 1302 [0/8000 (0%)]\tBatch Loss: 1148.777801\tLearning Rate (w_theta): 0.001000\t TIME:1188.5s\n",
      "\t\t\t\tDisc: 1.527551\t\tSym: 20.921515\t\tSpars: 1126.328735\n",
      "\t TVw: -0.506347 | TVb: -2.043274 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1302 [4000/8000 (50%)]\tBatch Loss: 1124.402301\tLearning Rate (w_theta): 0.001000\t TIME:1190.0s\n",
      "\t\t\t\tDisc: 1.486913\t\tSym: 21.111067\t\tSpars: 1101.804321\n",
      "\t TVw: -0.506275 | TVb: -2.043274 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1302...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1137.7294573172057\n",
      "Average validation loss: 188.93895371602517\n",
      "Training epoch 1303...\n",
      "\n",
      "Train Epoch: 1303 [0/8000 (0%)]\tBatch Loss: 1117.907309\tLearning Rate (w_theta): 0.001000\t TIME:1192.3s\n",
      "\t\t\t\tDisc: 1.497093\t\tSym: 20.684996\t\tSpars: 1095.725220\n",
      "\t TVw: -0.506202 | TVb: -2.043274 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1303 [4000/8000 (50%)]\tBatch Loss: 1100.811088\tLearning Rate (w_theta): 0.001000\t TIME:1193.9s\n",
      "\t\t\t\tDisc: 1.344583\t\tSym: 19.371168\t\tSpars: 1080.095337\n",
      "\t TVw: -0.506128 | TVb: -2.043274 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1303...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1131.7492516432078\n",
      "Average validation loss: 189.20562077974688\n",
      "Training epoch 1304...\n",
      "\n",
      "Train Epoch: 1304 [0/8000 (0%)]\tBatch Loss: 1141.669075\tLearning Rate (w_theta): 0.001000\t TIME:1196.2s\n",
      "\t\t\t\tDisc: 1.580930\t\tSym: 21.532724\t\tSpars: 1118.555420\n",
      "\t TVw: -0.506054 | TVb: -2.043274 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1304 [4000/8000 (50%)]\tBatch Loss: 1136.061354\tLearning Rate (w_theta): 0.001000\t TIME:1197.7s\n",
      "\t\t\t\tDisc: 1.575258\t\tSym: 21.313488\t\tSpars: 1113.172607\n",
      "\t TVw: -0.505981 | TVb: -2.043274 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1304...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1136.6789924748298\n",
      "Average validation loss: 190.5269006509003\n",
      "Training epoch 1305...\n",
      "\n",
      "Train Epoch: 1305 [0/8000 (0%)]\tBatch Loss: 1119.387889\tLearning Rate (w_theta): 0.001000\t TIME:1200.0s\n",
      "\t\t\t\tDisc: 1.403954\t\tSym: 19.653856\t\tSpars: 1098.330078\n",
      "\t TVw: -0.505909 | TVb: -2.043275 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1305 [4000/8000 (50%)]\tBatch Loss: 1126.072916\tLearning Rate (w_theta): 0.001000\t TIME:1201.6s\n",
      "\t\t\t\tDisc: 1.464962\t\tSym: 21.021528\t\tSpars: 1103.586426\n",
      "\t TVw: -0.505838 | TVb: -2.043275 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1305...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1133.236072396208\n",
      "Average validation loss: 191.0658014772964\n",
      "Training epoch 1306...\n",
      "\n",
      "Train Epoch: 1306 [0/8000 (0%)]\tBatch Loss: 1140.697956\tLearning Rate (w_theta): 0.001000\t TIME:1203.9s\n",
      "\t\t\t\tDisc: 1.612658\t\tSym: 21.604708\t\tSpars: 1117.480591\n",
      "\t TVw: -0.505767 | TVb: -2.043275 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1306 [4000/8000 (50%)]\tBatch Loss: 1106.876112\tLearning Rate (w_theta): 0.001000\t TIME:1205.4s\n",
      "\t\t\t\tDisc: 1.449452\t\tSym: 20.254053\t\tSpars: 1085.172607\n",
      "\t TVw: -0.505695 | TVb: -2.043275 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1306...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1125.7206305659088\n",
      "Average validation loss: 189.67248926767687\n",
      "Training epoch 1307...\n",
      "\n",
      "Train Epoch: 1307 [0/8000 (0%)]\tBatch Loss: 1122.667474\tLearning Rate (w_theta): 0.001000\t TIME:1207.8s\n",
      "\t\t\t\tDisc: 1.460073\t\tSym: 20.592899\t\tSpars: 1100.614502\n",
      "\t TVw: -0.505622 | TVb: -2.043275 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1307 [4000/8000 (50%)]\tBatch Loss: 1112.588228\tLearning Rate (w_theta): 0.001000\t TIME:1209.3s\n",
      "\t\t\t\tDisc: 1.506264\t\tSym: 20.521296\t\tSpars: 1090.560669\n",
      "\t TVw: -0.505548 | TVb: -2.043275 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1307...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1128.202761790465\n",
      "Average validation loss: 192.02955601976552\n",
      "Training epoch 1308...\n",
      "\n",
      "Train Epoch: 1308 [0/8000 (0%)]\tBatch Loss: 1153.375577\tLearning Rate (w_theta): 0.001000\t TIME:1211.7s\n",
      "\t\t\t\tDisc: 1.611342\t\tSym: 22.579176\t\tSpars: 1129.185059\n",
      "\t TVw: -0.505475 | TVb: -2.043276 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1308 [4000/8000 (50%)]\tBatch Loss: 1131.379808\tLearning Rate (w_theta): 0.001000\t TIME:1213.2s\n",
      "\t\t\t\tDisc: 1.557643\t\tSym: 20.422873\t\tSpars: 1109.399292\n",
      "\t TVw: -0.505403 | TVb: -2.043276 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1308...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1126.918685374337\n",
      "Average validation loss: 189.0809068511392\n",
      "Training epoch 1309...\n",
      "\n",
      "Train Epoch: 1309 [0/8000 (0%)]\tBatch Loss: 1131.071373\tLearning Rate (w_theta): 0.001000\t TIME:1215.5s\n",
      "\t\t\t\tDisc: 1.669758\t\tSym: 21.042240\t\tSpars: 1108.359375\n",
      "\t TVw: -0.505331 | TVb: -2.043276 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1309 [4000/8000 (50%)]\tBatch Loss: 1138.995590\tLearning Rate (w_theta): 0.001000\t TIME:1217.0s\n",
      "\t\t\t\tDisc: 1.496335\t\tSym: 20.701647\t\tSpars: 1116.797607\n",
      "\t TVw: -0.505258 | TVb: -2.043276 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1309...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1127.3684955229235\n",
      "Average validation loss: 189.40223092631211\n",
      "Training epoch 1310...\n",
      "\n",
      "Train Epoch: 1310 [0/8000 (0%)]\tBatch Loss: 1184.370941\tLearning Rate (w_theta): 0.001000\t TIME:1219.3s\n",
      "\t\t\t\tDisc: 1.654276\t\tSym: 23.890249\t\tSpars: 1158.826416\n",
      "\t TVw: -0.505185 | TVb: -2.043276 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1310 [4000/8000 (50%)]\tBatch Loss: 1120.253512\tLearning Rate (w_theta): 0.001000\t TIME:1220.9s\n",
      "\t\t\t\tDisc: 1.697638\t\tSym: 21.122768\t\tSpars: 1097.433105\n",
      "\t TVw: -0.505112 | TVb: -2.043276 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1310...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1134.1834163145327\n",
      "Average validation loss: 186.918963406592\n",
      "Training epoch 1311...\n",
      "\n",
      "Train Epoch: 1311 [0/8000 (0%)]\tBatch Loss: 1117.126967\tLearning Rate (w_theta): 0.001000\t TIME:1224.0s\n",
      "\t\t\t\tDisc: 1.618624\t\tSym: 20.711834\t\tSpars: 1094.796509\n",
      "\t TVw: -0.505039 | TVb: -2.043277 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1311 [4000/8000 (50%)]\tBatch Loss: 1139.599712\tLearning Rate (w_theta): 0.001000\t TIME:1225.5s\n",
      "\t\t\t\tDisc: 1.727329\t\tSym: 21.072701\t\tSpars: 1116.799683\n",
      "\t TVw: -0.504966 | TVb: -2.043277 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1311...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1130.6111132508327\n",
      "Average validation loss: 187.8104099048048\n",
      "Training epoch 1312...\n",
      "\n",
      "Train Epoch: 1312 [0/8000 (0%)]\tBatch Loss: 1121.252457\tLearning Rate (w_theta): 0.001000\t TIME:1227.8s\n",
      "\t\t\t\tDisc: 1.385508\t\tSym: 20.687628\t\tSpars: 1099.179321\n",
      "\t TVw: -0.504892 | TVb: -2.043278 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1312 [4000/8000 (50%)]\tBatch Loss: 1120.377511\tLearning Rate (w_theta): 0.001000\t TIME:1229.3s\n",
      "\t\t\t\tDisc: 1.503837\t\tSym: 19.320940\t\tSpars: 1099.552734\n",
      "\t TVw: -0.504818 | TVb: -2.043278 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1312...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1132.0398231853578\n",
      "Average validation loss: 186.5451095035527\n",
      "Training epoch 1313...\n",
      "\n",
      "Train Epoch: 1313 [0/8000 (0%)]\tBatch Loss: 1129.411422\tLearning Rate (w_theta): 0.001000\t TIME:1231.7s\n",
      "\t\t\t\tDisc: 1.770545\t\tSym: 22.185799\t\tSpars: 1105.455078\n",
      "\t TVw: -0.504744 | TVb: -2.043278 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1313 [4000/8000 (50%)]\tBatch Loss: 1083.042200\tLearning Rate (w_theta): 0.001000\t TIME:1233.2s\n",
      "\t\t\t\tDisc: 1.423155\t\tSym: 19.165798\t\tSpars: 1062.453247\n",
      "\t TVw: -0.504669 | TVb: -2.043279 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1313...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1128.1687021847652\n",
      "Average validation loss: 188.8314937205172\n",
      "Training epoch 1314...\n",
      "\n",
      "Train Epoch: 1314 [0/8000 (0%)]\tBatch Loss: 1123.760581\tLearning Rate (w_theta): 0.001000\t TIME:1235.5s\n",
      "\t\t\t\tDisc: 1.366977\t\tSym: 19.603199\t\tSpars: 1102.790405\n",
      "\t TVw: -0.504594 | TVb: -2.043279 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1314 [4000/8000 (50%)]\tBatch Loss: 1127.690090\tLearning Rate (w_theta): 0.001000\t TIME:1237.1s\n",
      "\t\t\t\tDisc: 1.585527\t\tSym: 22.110056\t\tSpars: 1103.994507\n",
      "\t TVw: -0.504519 | TVb: -2.043279 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1314...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1128.4935604261013\n",
      "Average validation loss: 186.48227258462725\n",
      "Training epoch 1315...\n",
      "\n",
      "Train Epoch: 1315 [0/8000 (0%)]\tBatch Loss: 1168.278623\tLearning Rate (w_theta): 0.001000\t TIME:1239.4s\n",
      "\t\t\t\tDisc: 1.829082\t\tSym: 23.200762\t\tSpars: 1143.248779\n",
      "\t TVw: -0.504444 | TVb: -2.043279 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1315 [4000/8000 (50%)]\tBatch Loss: 1144.233139\tLearning Rate (w_theta): 0.001000\t TIME:1240.9s\n",
      "\t\t\t\tDisc: 1.585712\t\tSym: 20.328579\t\tSpars: 1122.318848\n",
      "\t TVw: -0.504370 | TVb: -2.043280 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1315...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1134.4588037539768\n",
      "Average validation loss: 189.72559789968108\n",
      "Training epoch 1316...\n",
      "\n",
      "Train Epoch: 1316 [0/8000 (0%)]\tBatch Loss: 1151.990147\tLearning Rate (w_theta): 0.001000\t TIME:1243.2s\n",
      "\t\t\t\tDisc: 1.628533\t\tSym: 21.643230\t\tSpars: 1128.718384\n",
      "\t TVw: -0.504297 | TVb: -2.043280 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1316 [4000/8000 (50%)]\tBatch Loss: 1117.830764\tLearning Rate (w_theta): 0.001000\t TIME:1244.7s\n",
      "\t\t\t\tDisc: 1.431118\t\tSym: 20.655384\t\tSpars: 1095.744263\n",
      "\t TVw: -0.504223 | TVb: -2.043281 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1316...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1129.5229080156928\n",
      "Average validation loss: 190.65052161439485\n",
      "Training epoch 1317...\n",
      "\n",
      "Train Epoch: 1317 [0/8000 (0%)]\tBatch Loss: 1183.526080\tLearning Rate (w_theta): 0.001000\t TIME:1247.2s\n",
      "\t\t\t\tDisc: 1.572238\t\tSym: 23.044907\t\tSpars: 1158.908936\n",
      "\t TVw: -0.504148 | TVb: -2.043281 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1317 [4000/8000 (50%)]\tBatch Loss: 1141.257357\tLearning Rate (w_theta): 0.001000\t TIME:1248.7s\n",
      "\t\t\t\tDisc: 1.526473\t\tSym: 21.133228\t\tSpars: 1118.597656\n",
      "\t TVw: -0.504074 | TVb: -2.043281 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1317...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1126.0147530562028\n",
      "Average validation loss: 189.22307590793562\n",
      "Training epoch 1318...\n",
      "\n",
      "Train Epoch: 1318 [0/8000 (0%)]\tBatch Loss: 1144.298566\tLearning Rate (w_theta): 0.001000\t TIME:1251.1s\n",
      "\t\t\t\tDisc: 1.548804\t\tSym: 21.185431\t\tSpars: 1121.564331\n",
      "\t TVw: -0.503997 | TVb: -2.043282 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1318 [4000/8000 (50%)]\tBatch Loss: 1082.265380\tLearning Rate (w_theta): 0.001000\t TIME:1252.6s\n",
      "\t\t\t\tDisc: 1.402006\t\tSym: 18.779879\t\tSpars: 1062.083496\n",
      "\t TVw: -0.503921 | TVb: -2.043282 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1318...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1123.6551479347431\n",
      "Average validation loss: 189.3418631114036\n",
      "Training epoch 1319...\n",
      "\n",
      "Train Epoch: 1319 [0/8000 (0%)]\tBatch Loss: 1144.665565\tLearning Rate (w_theta): 0.001000\t TIME:1254.9s\n",
      "\t\t\t\tDisc: 1.619586\t\tSym: 22.451496\t\tSpars: 1120.594482\n",
      "\t TVw: -0.503843 | TVb: -2.043282 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1319 [4000/8000 (50%)]\tBatch Loss: 1158.973084\tLearning Rate (w_theta): 0.001000\t TIME:1256.4s\n",
      "\t\t\t\tDisc: 1.673846\t\tSym: 21.752851\t\tSpars: 1135.546387\n",
      "\t TVw: -0.503766 | TVb: -2.043283 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1319...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1125.4808299266742\n",
      "Average validation loss: 187.10128774417714\n",
      "Training epoch 1320...\n",
      "\n",
      "Train Epoch: 1320 [0/8000 (0%)]\tBatch Loss: 1107.877263\tLearning Rate (w_theta): 0.001000\t TIME:1258.7s\n",
      "\t\t\t\tDisc: 1.703391\t\tSym: 21.047285\t\tSpars: 1085.126587\n",
      "\t TVw: -0.503690 | TVb: -2.043283 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1320 [4000/8000 (50%)]\tBatch Loss: 1168.360737\tLearning Rate (w_theta): 0.001000\t TIME:1260.2s\n",
      "\t\t\t\tDisc: 1.684971\t\tSym: 23.230942\t\tSpars: 1143.444824\n",
      "\t TVw: -0.503613 | TVb: -2.043283 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1320...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1126.7001113052588\n",
      "Average validation loss: 190.16932778632042\n",
      "Training epoch 1321...\n",
      "\n",
      "Train Epoch: 1321 [0/8000 (0%)]\tBatch Loss: 1060.913089\tLearning Rate (w_theta): 0.001000\t TIME:1263.2s\n",
      "\t\t\t\tDisc: 1.251733\t\tSym: 18.228495\t\tSpars: 1041.432861\n",
      "\t TVw: -0.503536 | TVb: -2.043283 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1321 [4000/8000 (50%)]\tBatch Loss: 1104.902432\tLearning Rate (w_theta): 0.001000\t TIME:1264.8s\n",
      "\t\t\t\tDisc: 1.490542\t\tSym: 19.890772\t\tSpars: 1083.521118\n",
      "\t TVw: -0.503459 | TVb: -2.043283 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1321...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1125.9128509997026\n",
      "Average validation loss: 188.01110678991537\n",
      "Training epoch 1322...\n",
      "\n",
      "Train Epoch: 1322 [0/8000 (0%)]\tBatch Loss: 1140.116304\tLearning Rate (w_theta): 0.001000\t TIME:1267.2s\n",
      "\t\t\t\tDisc: 1.724208\t\tSym: 21.696173\t\tSpars: 1116.695923\n",
      "\t TVw: -0.503382 | TVb: -2.043284 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1322 [4000/8000 (50%)]\tBatch Loss: 1159.536792\tLearning Rate (w_theta): 0.001000\t TIME:1268.7s\n",
      "\t\t\t\tDisc: 1.554774\t\tSym: 22.877037\t\tSpars: 1135.104980\n",
      "\t TVw: -0.503305 | TVb: -2.043284 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1322...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1124.9291643020601\n",
      "Average validation loss: 190.8367348327055\n",
      "Training epoch 1323...\n",
      "\n",
      "Train Epoch: 1323 [0/8000 (0%)]\tBatch Loss: 1148.931395\tLearning Rate (w_theta): 0.001000\t TIME:1271.0s\n",
      "\t\t\t\tDisc: 1.501085\t\tSym: 20.845104\t\tSpars: 1126.585205\n",
      "\t TVw: -0.503228 | TVb: -2.043284 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1323 [4000/8000 (50%)]\tBatch Loss: 1149.502311\tLearning Rate (w_theta): 0.001000\t TIME:1272.5s\n",
      "\t\t\t\tDisc: 1.446551\t\tSym: 22.161472\t\tSpars: 1125.894287\n",
      "\t TVw: -0.503150 | TVb: -2.043284 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1323...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1133.0975531668\n",
      "Average validation loss: 189.8814960508554\n",
      "Training epoch 1324...\n",
      "\n",
      "Train Epoch: 1324 [0/8000 (0%)]\tBatch Loss: 1111.072248\tLearning Rate (w_theta): 0.001000\t TIME:1274.8s\n",
      "\t\t\t\tDisc: 1.500797\t\tSym: 19.582682\t\tSpars: 1089.988770\n",
      "\t TVw: -0.503072 | TVb: -2.043285 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1324 [4000/8000 (50%)]\tBatch Loss: 1141.781160\tLearning Rate (w_theta): 0.001000\t TIME:1276.3s\n",
      "\t\t\t\tDisc: 1.552197\t\tSym: 20.946859\t\tSpars: 1119.282104\n",
      "\t TVw: -0.502995 | TVb: -2.043285 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1324...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1128.2085244401612\n",
      "Average validation loss: 187.28066388987\n",
      "Training epoch 1325...\n",
      "\n",
      "Train Epoch: 1325 [0/8000 (0%)]\tBatch Loss: 1154.854768\tLearning Rate (w_theta): 0.001000\t TIME:1278.7s\n",
      "\t\t\t\tDisc: 1.714328\t\tSym: 22.696470\t\tSpars: 1130.443970\n",
      "\t TVw: -0.502918 | TVb: -2.043285 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1325 [4000/8000 (50%)]\tBatch Loss: 1103.891688\tLearning Rate (w_theta): 0.001000\t TIME:1280.2s\n",
      "\t\t\t\tDisc: 1.325076\t\tSym: 18.795616\t\tSpars: 1083.770996\n",
      "\t TVw: -0.502839 | TVb: -2.043286 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1325...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1124.2884708773274\n",
      "Average validation loss: 187.9243044437871\n",
      "Training epoch 1326...\n",
      "\n",
      "Train Epoch: 1326 [0/8000 (0%)]\tBatch Loss: 1103.213031\tLearning Rate (w_theta): 0.001000\t TIME:1282.5s\n",
      "\t\t\t\tDisc: 1.490966\t\tSym: 19.652607\t\tSpars: 1082.069458\n",
      "\t TVw: -0.502760 | TVb: -2.043286 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1326 [4000/8000 (50%)]\tBatch Loss: 1141.076326\tLearning Rate (w_theta): 0.001000\t TIME:1284.0s\n",
      "\t\t\t\tDisc: 1.462404\t\tSym: 20.717682\t\tSpars: 1118.896240\n",
      "\t TVw: -0.502681 | TVb: -2.043286 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1326...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1120.458919343726\n",
      "Average validation loss: 189.05200036661907\n",
      "Training epoch 1327...\n",
      "\n",
      "Train Epoch: 1327 [0/8000 (0%)]\tBatch Loss: 1098.685188\tLearning Rate (w_theta): 0.001000\t TIME:1286.5s\n",
      "\t\t\t\tDisc: 1.403284\t\tSym: 19.447676\t\tSpars: 1077.834229\n",
      "\t TVw: -0.502601 | TVb: -2.043286 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1327 [4000/8000 (50%)]\tBatch Loss: 1082.549443\tLearning Rate (w_theta): 0.001000\t TIME:1288.0s\n",
      "\t\t\t\tDisc: 1.365544\t\tSym: 18.740662\t\tSpars: 1062.443237\n",
      "\t TVw: -0.502521 | TVb: -2.043286 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1327...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1120.1063077583892\n",
      "Average validation loss: 188.4574750762876\n",
      "Training epoch 1328...\n",
      "\n",
      "Train Epoch: 1328 [0/8000 (0%)]\tBatch Loss: 1107.504674\tLearning Rate (w_theta): 0.001000\t TIME:1290.3s\n",
      "\t\t\t\tDisc: 1.467668\t\tSym: 20.275898\t\tSpars: 1085.761108\n",
      "\t TVw: -0.502442 | TVb: -2.043286 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1328 [4000/8000 (50%)]\tBatch Loss: 1099.641154\tLearning Rate (w_theta): 0.001000\t TIME:1291.8s\n",
      "\t\t\t\tDisc: 1.448485\t\tSym: 20.151409\t\tSpars: 1078.041260\n",
      "\t TVw: -0.502363 | TVb: -2.043286 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1328...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1121.3979512633875\n",
      "Average validation loss: 187.48447947449847\n",
      "Training epoch 1329...\n",
      "\n",
      "Train Epoch: 1329 [0/8000 (0%)]\tBatch Loss: 1130.441631\tLearning Rate (w_theta): 0.001000\t TIME:1294.1s\n",
      "\t\t\t\tDisc: 1.511937\t\tSym: 20.821783\t\tSpars: 1108.107910\n",
      "\t TVw: -0.502284 | TVb: -2.043287 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1329 [4000/8000 (50%)]\tBatch Loss: 1136.823460\tLearning Rate (w_theta): 0.001000\t TIME:1295.7s\n",
      "\t\t\t\tDisc: 1.431184\t\tSym: 21.588566\t\tSpars: 1113.803711\n",
      "\t TVw: -0.502204 | TVb: -2.043287 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1329...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1127.1888079665607\n",
      "Average validation loss: 186.8427024516203\n",
      "Training epoch 1330...\n",
      "\n",
      "Train Epoch: 1330 [0/8000 (0%)]\tBatch Loss: 1144.155528\tLearning Rate (w_theta): 0.001000\t TIME:1298.0s\n",
      "\t\t\t\tDisc: 1.594938\t\tSym: 21.245649\t\tSpars: 1121.314941\n",
      "\t TVw: -0.502125 | TVb: -2.043287 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1330 [4000/8000 (50%)]\tBatch Loss: 1146.163196\tLearning Rate (w_theta): 0.001000\t TIME:1299.5s\n",
      "\t\t\t\tDisc: 1.634319\t\tSym: 20.771675\t\tSpars: 1123.757202\n",
      "\t TVw: -0.502046 | TVb: -2.043288 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1330...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1129.3841683414846\n",
      "Average validation loss: 184.61824066282048\n",
      "Training epoch 1331...\n",
      "\n",
      "Train Epoch: 1331 [0/8000 (0%)]\tBatch Loss: 1183.427099\tLearning Rate (w_theta): 0.001000\t TIME:1302.5s\n",
      "\t\t\t\tDisc: 1.875772\t\tSym: 23.327938\t\tSpars: 1158.223389\n",
      "\t TVw: -0.501966 | TVb: -2.043288 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1331 [4000/8000 (50%)]\tBatch Loss: 1124.955948\tLearning Rate (w_theta): 0.001000\t TIME:1304.0s\n",
      "\t\t\t\tDisc: 1.578326\t\tSym: 20.469297\t\tSpars: 1102.908325\n",
      "\t TVw: -0.501887 | TVb: -2.043289 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1331...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1131.2623950530322\n",
      "Average validation loss: 186.07580516617156\n",
      "Training epoch 1332...\n",
      "\n",
      "Train Epoch: 1332 [0/8000 (0%)]\tBatch Loss: 1102.003267\tLearning Rate (w_theta): 0.001000\t TIME:1306.5s\n",
      "\t\t\t\tDisc: 1.457535\t\tSym: 19.992144\t\tSpars: 1080.553589\n",
      "\t TVw: -0.501807 | TVb: -2.043289 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1332 [4000/8000 (50%)]\tBatch Loss: 1121.553402\tLearning Rate (w_theta): 0.001000\t TIME:1308.0s\n",
      "\t\t\t\tDisc: 1.525534\t\tSym: 20.872595\t\tSpars: 1099.155273\n",
      "\t TVw: -0.501726 | TVb: -2.043289 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1332...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1123.7515283255918\n",
      "Average validation loss: 186.4345842117491\n",
      "Training epoch 1333...\n",
      "\n",
      "Train Epoch: 1333 [0/8000 (0%)]\tBatch Loss: 1086.133988\tLearning Rate (w_theta): 0.001000\t TIME:1310.3s\n",
      "\t\t\t\tDisc: 1.404864\t\tSym: 19.315672\t\tSpars: 1065.413452\n",
      "\t TVw: -0.501646 | TVb: -2.043289 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1333 [4000/8000 (50%)]\tBatch Loss: 1120.967987\tLearning Rate (w_theta): 0.001000\t TIME:1311.8s\n",
      "\t\t\t\tDisc: 1.494745\t\tSym: 19.737646\t\tSpars: 1099.735596\n",
      "\t TVw: -0.501565 | TVb: -2.043289 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1333...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1127.5775038586758\n",
      "Average validation loss: 185.27971467880195\n",
      "Training epoch 1334...\n",
      "\n",
      "Train Epoch: 1334 [0/8000 (0%)]\tBatch Loss: 1103.483004\tLearning Rate (w_theta): 0.001000\t TIME:1314.2s\n",
      "\t\t\t\tDisc: 1.475536\t\tSym: 19.894918\t\tSpars: 1082.112549\n",
      "\t TVw: -0.501485 | TVb: -2.043290 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1334 [4000/8000 (50%)]\tBatch Loss: 1137.933826\tLearning Rate (w_theta): 0.001000\t TIME:1315.7s\n",
      "\t\t\t\tDisc: 1.467071\t\tSym: 20.573200\t\tSpars: 1115.893555\n",
      "\t TVw: -0.501403 | TVb: -2.043290 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1334...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1121.313170566841\n",
      "Average validation loss: 185.9487374480843\n",
      "Training epoch 1335...\n",
      "\n",
      "Train Epoch: 1335 [0/8000 (0%)]\tBatch Loss: 1123.265523\tLearning Rate (w_theta): 0.001000\t TIME:1318.0s\n",
      "\t\t\t\tDisc: 1.574432\t\tSym: 20.223196\t\tSpars: 1101.467896\n",
      "\t TVw: -0.501321 | TVb: -2.043290 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1335 [4000/8000 (50%)]\tBatch Loss: 1108.071793\tLearning Rate (w_theta): 0.001000\t TIME:1319.5s\n",
      "\t\t\t\tDisc: 1.475384\t\tSym: 20.398533\t\tSpars: 1086.197876\n",
      "\t TVw: -0.501239 | TVb: -2.043290 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1335...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1117.4069327418872\n",
      "Average validation loss: 186.24874002420566\n",
      "Training epoch 1336...\n",
      "\n",
      "Train Epoch: 1336 [0/8000 (0%)]\tBatch Loss: 1107.427451\tLearning Rate (w_theta): 0.001000\t TIME:1321.8s\n",
      "\t\t\t\tDisc: 1.467989\t\tSym: 20.440296\t\tSpars: 1085.519165\n",
      "\t TVw: -0.501156 | TVb: -2.043290 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1336 [4000/8000 (50%)]\tBatch Loss: 1113.829143\tLearning Rate (w_theta): 0.001000\t TIME:1323.4s\n",
      "\t\t\t\tDisc: 1.552427\t\tSym: 19.891462\t\tSpars: 1092.385254\n",
      "\t TVw: -0.501073 | TVb: -2.043290 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1336...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1122.9141440484707\n",
      "Average validation loss: 184.96018957525592\n",
      "Training epoch 1337...\n",
      "\n",
      "Train Epoch: 1337 [0/8000 (0%)]\tBatch Loss: 1118.993018\tLearning Rate (w_theta): 0.001000\t TIME:1325.7s\n",
      "\t\t\t\tDisc: 1.580476\t\tSym: 20.717596\t\tSpars: 1096.694946\n",
      "\t TVw: -0.500991 | TVb: -2.043291 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1337 [4000/8000 (50%)]\tBatch Loss: 1069.249737\tLearning Rate (w_theta): 0.001000\t TIME:1327.3s\n",
      "\t\t\t\tDisc: 1.331519\t\tSym: 18.663458\t\tSpars: 1049.254761\n",
      "\t TVw: -0.500908 | TVb: -2.043292 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1337...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1124.8394800406109\n",
      "Average validation loss: 186.28708853534036\n",
      "Training epoch 1338...\n",
      "\n",
      "Train Epoch: 1338 [0/8000 (0%)]\tBatch Loss: 1135.915252\tLearning Rate (w_theta): 0.001000\t TIME:1329.7s\n",
      "\t\t\t\tDisc: 1.303903\t\tSym: 20.859640\t\tSpars: 1113.751709\n",
      "\t TVw: -0.500827 | TVb: -2.043292 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1338 [4000/8000 (50%)]\tBatch Loss: 1096.883050\tLearning Rate (w_theta): 0.001000\t TIME:1331.2s\n",
      "\t\t\t\tDisc: 1.402134\t\tSym: 19.275837\t\tSpars: 1076.205078\n",
      "\t TVw: -0.500744 | TVb: -2.043292 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1338...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1123.2548159068413\n",
      "Average validation loss: 184.97234846533468\n",
      "Training epoch 1339...\n",
      "\n",
      "Train Epoch: 1339 [0/8000 (0%)]\tBatch Loss: 1122.982733\tLearning Rate (w_theta): 0.001000\t TIME:1333.5s\n",
      "\t\t\t\tDisc: 1.521313\t\tSym: 20.030146\t\tSpars: 1101.431274\n",
      "\t TVw: -0.500661 | TVb: -2.043292 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1339 [4000/8000 (50%)]\tBatch Loss: 1119.204799\tLearning Rate (w_theta): 0.001000\t TIME:1335.0s\n",
      "\t\t\t\tDisc: 1.574510\t\tSym: 20.354776\t\tSpars: 1097.275513\n",
      "\t TVw: -0.500578 | TVb: -2.043293 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1339...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1124.517887430453\n",
      "Average validation loss: 189.0520933313939\n",
      "Training epoch 1340...\n",
      "\n",
      "Train Epoch: 1340 [0/8000 (0%)]\tBatch Loss: 1120.761065\tLearning Rate (w_theta): 0.001000\t TIME:1337.3s\n",
      "\t\t\t\tDisc: 1.440655\t\tSym: 19.678930\t\tSpars: 1099.641479\n",
      "\t TVw: -0.500494 | TVb: -2.043293 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1340 [4000/8000 (50%)]\tBatch Loss: 1108.046968\tLearning Rate (w_theta): 0.001000\t TIME:1338.8s\n",
      "\t\t\t\tDisc: 1.379002\t\tSym: 20.435545\t\tSpars: 1086.232422\n",
      "\t TVw: -0.500410 | TVb: -2.043293 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1340...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1123.3879466196488\n",
      "Average validation loss: 185.1921806973277\n",
      "Training epoch 1341...\n",
      "\n",
      "Train Epoch: 1341 [0/8000 (0%)]\tBatch Loss: 1152.360129\tLearning Rate (w_theta): 0.001000\t TIME:1341.9s\n",
      "\t\t\t\tDisc: 1.679856\t\tSym: 21.989477\t\tSpars: 1128.690796\n",
      "\t TVw: -0.500327 | TVb: -2.043294 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1341 [4000/8000 (50%)]\tBatch Loss: 1078.426655\tLearning Rate (w_theta): 0.001000\t TIME:1343.4s\n",
      "\t\t\t\tDisc: 1.508902\t\tSym: 19.193388\t\tSpars: 1057.724365\n",
      "\t TVw: -0.500244 | TVb: -2.043295 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1341...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1123.7480445014012\n",
      "Average validation loss: 185.48097468009075\n",
      "Training epoch 1342...\n",
      "\n",
      "Train Epoch: 1342 [0/8000 (0%)]\tBatch Loss: 1119.773644\tLearning Rate (w_theta): 0.001000\t TIME:1345.9s\n",
      "\t\t\t\tDisc: 1.534760\t\tSym: 20.722527\t\tSpars: 1097.516357\n",
      "\t TVw: -0.500161 | TVb: -2.043295 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1342 [4000/8000 (50%)]\tBatch Loss: 1122.986542\tLearning Rate (w_theta): 0.001000\t TIME:1347.4s\n",
      "\t\t\t\tDisc: 1.422171\t\tSym: 20.327799\t\tSpars: 1101.236572\n",
      "\t TVw: -0.500077 | TVb: -2.043295 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1342...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1119.6785261532448\n",
      "Average validation loss: 184.80280421119335\n",
      "Training epoch 1343...\n",
      "\n",
      "Train Epoch: 1343 [0/8000 (0%)]\tBatch Loss: 1130.188373\tLearning Rate (w_theta): 0.001000\t TIME:1349.8s\n",
      "\t\t\t\tDisc: 1.474212\t\tSym: 20.863087\t\tSpars: 1107.851074\n",
      "\t TVw: -0.499993 | TVb: -2.043295 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1343 [4000/8000 (50%)]\tBatch Loss: 1109.420819\tLearning Rate (w_theta): 0.001000\t TIME:1351.3s\n",
      "\t\t\t\tDisc: 1.535094\t\tSym: 19.835066\t\tSpars: 1088.050659\n",
      "\t TVw: -0.499907 | TVb: -2.043295 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1343...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1118.6148859916534\n",
      "Average validation loss: 185.705067751029\n",
      "Training epoch 1344...\n",
      "\n",
      "Train Epoch: 1344 [0/8000 (0%)]\tBatch Loss: 1129.042068\tLearning Rate (w_theta): 0.001000\t TIME:1353.6s\n",
      "\t\t\t\tDisc: 1.615560\t\tSym: 21.367670\t\tSpars: 1106.058838\n",
      "\t TVw: -0.499823 | TVb: -2.043296 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1344 [4000/8000 (50%)]\tBatch Loss: 1117.983763\tLearning Rate (w_theta): 0.001000\t TIME:1355.1s\n",
      "\t\t\t\tDisc: 1.436602\t\tSym: 21.114056\t\tSpars: 1095.433105\n",
      "\t TVw: -0.499738 | TVb: -2.043296 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1344...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1127.5667680727163\n",
      "Average validation loss: 185.95980392891514\n",
      "Training epoch 1345...\n",
      "\n",
      "Train Epoch: 1345 [0/8000 (0%)]\tBatch Loss: 1152.330502\tLearning Rate (w_theta): 0.001000\t TIME:1357.4s\n",
      "\t\t\t\tDisc: 1.628070\t\tSym: 21.885782\t\tSpars: 1128.816650\n",
      "\t TVw: -0.499654 | TVb: -2.043296 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1345 [4000/8000 (50%)]\tBatch Loss: 1150.247094\tLearning Rate (w_theta): 0.001000\t TIME:1358.9s\n",
      "\t\t\t\tDisc: 1.634448\t\tSym: 22.190405\t\tSpars: 1126.422241\n",
      "\t TVw: -0.499570 | TVb: -2.043297 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1345...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1115.5675064641052\n",
      "Average validation loss: 185.34328679275143\n",
      "Training epoch 1346...\n",
      "\n",
      "Train Epoch: 1346 [0/8000 (0%)]\tBatch Loss: 1118.814811\tLearning Rate (w_theta): 0.001000\t TIME:1361.3s\n",
      "\t\t\t\tDisc: 1.485587\t\tSym: 20.995483\t\tSpars: 1096.333740\n",
      "\t TVw: -0.499485 | TVb: -2.043297 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1346 [4000/8000 (50%)]\tBatch Loss: 1121.204404\tLearning Rate (w_theta): 0.001000\t TIME:1362.8s\n",
      "\t\t\t\tDisc: 1.432413\t\tSym: 19.911762\t\tSpars: 1099.860229\n",
      "\t TVw: -0.499399 | TVb: -2.043297 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1346...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1114.5441549340624\n",
      "Average validation loss: 184.32435971295985\n",
      "Training epoch 1347...\n",
      "\n",
      "Train Epoch: 1347 [0/8000 (0%)]\tBatch Loss: 1160.113963\tLearning Rate (w_theta): 0.001000\t TIME:1365.1s\n",
      "\t\t\t\tDisc: 1.575976\t\tSym: 22.335594\t\tSpars: 1136.202393\n",
      "\t TVw: -0.499313 | TVb: -2.043297 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1347 [4000/8000 (50%)]\tBatch Loss: 1099.077830\tLearning Rate (w_theta): 0.001000\t TIME:1366.7s\n",
      "\t\t\t\tDisc: 1.431158\t\tSym: 18.921818\t\tSpars: 1078.724854\n",
      "\t TVw: -0.499227 | TVb: -2.043297 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1347...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1116.2551745505605\n",
      "Average validation loss: 184.2016721536955\n",
      "Training epoch 1348...\n",
      "\n",
      "Train Epoch: 1348 [0/8000 (0%)]\tBatch Loss: 1113.789609\tLearning Rate (w_theta): 0.001000\t TIME:1369.1s\n",
      "\t\t\t\tDisc: 1.521020\t\tSym: 19.583897\t\tSpars: 1092.684692\n",
      "\t TVw: -0.499141 | TVb: -2.043298 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1348 [4000/8000 (50%)]\tBatch Loss: 1129.817057\tLearning Rate (w_theta): 0.001000\t TIME:1370.7s\n",
      "\t\t\t\tDisc: 1.419594\t\tSym: 20.208986\t\tSpars: 1108.188477\n",
      "\t TVw: -0.499055 | TVb: -2.043298 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1348...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1119.7021138726454\n",
      "Average validation loss: 185.73536940318866\n",
      "Training epoch 1349...\n",
      "\n",
      "Train Epoch: 1349 [0/8000 (0%)]\tBatch Loss: 1149.655439\tLearning Rate (w_theta): 0.001000\t TIME:1373.0s\n",
      "\t\t\t\tDisc: 1.655180\t\tSym: 23.054459\t\tSpars: 1124.945801\n",
      "\t TVw: -0.498969 | TVb: -2.043298 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1349 [4000/8000 (50%)]\tBatch Loss: 1112.836428\tLearning Rate (w_theta): 0.001000\t TIME:1374.5s\n",
      "\t\t\t\tDisc: 1.496094\t\tSym: 19.055300\t\tSpars: 1092.285034\n",
      "\t TVw: -0.498885 | TVb: -2.043299 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1349...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1125.5982123843937\n",
      "Average validation loss: 182.22588647790096\n",
      "Training epoch 1350...\n",
      "\n",
      "Train Epoch: 1350 [0/8000 (0%)]\tBatch Loss: 1124.942858\tLearning Rate (w_theta): 0.001000\t TIME:1376.9s\n",
      "\t\t\t\tDisc: 1.609925\t\tSym: 21.350756\t\tSpars: 1101.982178\n",
      "\t TVw: -0.498801 | TVb: -2.043300 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1350 [4000/8000 (50%)]\tBatch Loss: 1117.461899\tLearning Rate (w_theta): 0.001000\t TIME:1378.4s\n",
      "\t\t\t\tDisc: 1.432525\t\tSym: 20.595901\t\tSpars: 1095.433472\n",
      "\t TVw: -0.498715 | TVb: -2.043300 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1350...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1116.3370596130237\n",
      "Average validation loss: 185.480632600876\n",
      "Training epoch 1351...\n",
      "\n",
      "Train Epoch: 1351 [0/8000 (0%)]\tBatch Loss: 1114.173848\tLearning Rate (w_theta): 0.001000\t TIME:1381.3s\n",
      "\t\t\t\tDisc: 1.475686\t\tSym: 21.320477\t\tSpars: 1091.377686\n",
      "\t TVw: -0.498627 | TVb: -2.043300 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1351 [4000/8000 (50%)]\tBatch Loss: 1111.562591\tLearning Rate (w_theta): 0.001000\t TIME:1382.9s\n",
      "\t\t\t\tDisc: 1.453290\t\tSym: 18.829393\t\tSpars: 1091.279907\n",
      "\t TVw: -0.498539 | TVb: -2.043301 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1351...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1123.6828876914915\n",
      "Average validation loss: 182.55329132647682\n",
      "Training epoch 1352...\n",
      "\n",
      "Train Epoch: 1352 [0/8000 (0%)]\tBatch Loss: 1114.274560\tLearning Rate (w_theta): 0.001000\t TIME:1385.3s\n",
      "\t\t\t\tDisc: 1.512055\t\tSym: 19.456718\t\tSpars: 1093.305786\n",
      "\t TVw: -0.498452 | TVb: -2.043301 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1352 [4000/8000 (50%)]\tBatch Loss: 1130.466472\tLearning Rate (w_theta): 0.001000\t TIME:1386.8s\n",
      "\t\t\t\tDisc: 1.513679\t\tSym: 19.984653\t\tSpars: 1108.968140\n",
      "\t TVw: -0.498365 | TVb: -2.043302 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1352...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1116.5661859347565\n",
      "Average validation loss: 183.0858990168785\n",
      "Training epoch 1353...\n",
      "\n",
      "Train Epoch: 1353 [0/8000 (0%)]\tBatch Loss: 1084.817019\tLearning Rate (w_theta): 0.001000\t TIME:1389.2s\n",
      "\t\t\t\tDisc: 1.347042\t\tSym: 18.744146\t\tSpars: 1064.725830\n",
      "\t TVw: -0.498278 | TVb: -2.043302 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1353 [4000/8000 (50%)]\tBatch Loss: 1086.161351\tLearning Rate (w_theta): 0.001000\t TIME:1390.7s\n",
      "\t\t\t\tDisc: 1.462941\t\tSym: 19.099777\t\tSpars: 1065.598633\n",
      "\t TVw: -0.498191 | TVb: -2.043302 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1353...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1118.4012927853803\n",
      "Average validation loss: 181.26212902445994\n",
      "Training epoch 1354...\n",
      "\n",
      "Train Epoch: 1354 [0/8000 (0%)]\tBatch Loss: 1095.218534\tLearning Rate (w_theta): 0.001000\t TIME:1393.1s\n",
      "\t\t\t\tDisc: 1.451747\t\tSym: 18.805361\t\tSpars: 1074.961426\n",
      "\t TVw: -0.498103 | TVb: -2.043302 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1354 [4000/8000 (50%)]\tBatch Loss: 1144.821010\tLearning Rate (w_theta): 0.001000\t TIME:1394.6s\n",
      "\t\t\t\tDisc: 1.626238\t\tSym: 22.671213\t\tSpars: 1120.523560\n",
      "\t TVw: -0.498014 | TVb: -2.043302 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1354...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1120.1179683448331\n",
      "Average validation loss: 183.2013006798983\n",
      "Training epoch 1355...\n",
      "\n",
      "Train Epoch: 1355 [0/8000 (0%)]\tBatch Loss: 1125.753566\tLearning Rate (w_theta): 0.001000\t TIME:1396.9s\n",
      "\t\t\t\tDisc: 1.392465\t\tSym: 19.985735\t\tSpars: 1104.375366\n",
      "\t TVw: -0.497925 | TVb: -2.043303 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1355 [4000/8000 (50%)]\tBatch Loss: 1115.188622\tLearning Rate (w_theta): 0.001000\t TIME:1398.4s\n",
      "\t\t\t\tDisc: 1.465737\t\tSym: 20.205307\t\tSpars: 1093.517578\n",
      "\t TVw: -0.497837 | TVb: -2.043303 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1355...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1115.2138951488193\n",
      "Average validation loss: 184.10654543874318\n",
      "Training epoch 1356...\n",
      "\n",
      "Train Epoch: 1356 [0/8000 (0%)]\tBatch Loss: 1068.806284\tLearning Rate (w_theta): 0.001000\t TIME:1400.8s\n",
      "\t\t\t\tDisc: 1.306982\t\tSym: 18.260166\t\tSpars: 1049.239136\n",
      "\t TVw: -0.497748 | TVb: -2.043303 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1356 [4000/8000 (50%)]\tBatch Loss: 1153.678271\tLearning Rate (w_theta): 0.001000\t TIME:1402.3s\n",
      "\t\t\t\tDisc: 1.618855\t\tSym: 22.452604\t\tSpars: 1129.606812\n",
      "\t TVw: -0.497659 | TVb: -2.043303 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1356...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1112.5314509758582\n",
      "Average validation loss: 184.36162076390357\n",
      "Training epoch 1357...\n",
      "\n",
      "Train Epoch: 1357 [0/8000 (0%)]\tBatch Loss: 1144.590954\tLearning Rate (w_theta): 0.001000\t TIME:1404.6s\n",
      "\t\t\t\tDisc: 1.625691\t\tSym: 21.483330\t\tSpars: 1121.481934\n",
      "\t TVw: -0.497570 | TVb: -2.043303 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1357 [4000/8000 (50%)]\tBatch Loss: 1089.914520\tLearning Rate (w_theta): 0.001000\t TIME:1406.1s\n",
      "\t\t\t\tDisc: 1.310930\t\tSym: 19.275831\t\tSpars: 1069.327759\n",
      "\t TVw: -0.497482 | TVb: -2.043303 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1357...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1111.2706012743638\n",
      "Average validation loss: 182.98179160738476\n",
      "Training epoch 1358...\n",
      "\n",
      "Train Epoch: 1358 [0/8000 (0%)]\tBatch Loss: 1127.839687\tLearning Rate (w_theta): 0.001000\t TIME:1408.7s\n",
      "\t\t\t\tDisc: 1.409099\t\tSym: 20.145920\t\tSpars: 1106.284668\n",
      "\t TVw: -0.497393 | TVb: -2.043303 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1358 [4000/8000 (50%)]\tBatch Loss: 1111.145750\tLearning Rate (w_theta): 0.001000\t TIME:1410.2s\n",
      "\t\t\t\tDisc: 1.396353\t\tSym: 20.375740\t\tSpars: 1089.373657\n",
      "\t TVw: -0.497303 | TVb: -2.043304 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1358...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1111.3355629193125\n",
      "Average validation loss: 181.3969234107694\n",
      "Training epoch 1359...\n",
      "\n",
      "Train Epoch: 1359 [0/8000 (0%)]\tBatch Loss: 1098.284852\tLearning Rate (w_theta): 0.001000\t TIME:1412.5s\n",
      "\t\t\t\tDisc: 1.560620\t\tSym: 19.359119\t\tSpars: 1077.365112\n",
      "\t TVw: -0.497214 | TVb: -2.043304 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1359 [4000/8000 (50%)]\tBatch Loss: 1109.101792\tLearning Rate (w_theta): 0.001000\t TIME:1414.0s\n",
      "\t\t\t\tDisc: 1.508236\t\tSym: 18.937183\t\tSpars: 1088.656372\n",
      "\t TVw: -0.497125 | TVb: -2.043305 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1359...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1118.6899850048042\n",
      "Average validation loss: 182.57389196211656\n",
      "Training epoch 1360...\n",
      "\n",
      "Train Epoch: 1360 [0/8000 (0%)]\tBatch Loss: 1137.758195\tLearning Rate (w_theta): 0.001000\t TIME:1416.3s\n",
      "\t\t\t\tDisc: 1.585253\t\tSym: 21.617399\t\tSpars: 1114.555542\n",
      "\t TVw: -0.497036 | TVb: -2.043305 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1360 [4000/8000 (50%)]\tBatch Loss: 1126.081089\tLearning Rate (w_theta): 0.001000\t TIME:1417.9s\n",
      "\t\t\t\tDisc: 1.452170\t\tSym: 21.164564\t\tSpars: 1103.464355\n",
      "\t TVw: -0.496947 | TVb: -2.043306 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1360...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1112.261749231099\n",
      "Average validation loss: 182.2179946951682\n",
      "Training epoch 1361...\n",
      "\n",
      "Train Epoch: 1361 [0/8000 (0%)]\tBatch Loss: 1091.256597\tLearning Rate (w_theta): 0.001000\t TIME:1421.0s\n",
      "\t\t\t\tDisc: 1.472698\t\tSym: 19.869593\t\tSpars: 1069.914307\n",
      "\t TVw: -0.496856 | TVb: -2.043306 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1361 [4000/8000 (50%)]\tBatch Loss: 1082.065450\tLearning Rate (w_theta): 0.001000\t TIME:1422.5s\n",
      "\t\t\t\tDisc: 1.376170\t\tSym: 18.565989\t\tSpars: 1062.123291\n",
      "\t TVw: -0.496765 | TVb: -2.043307 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1361...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1112.702901688578\n",
      "Average validation loss: 182.53131931716365\n",
      "Training epoch 1362...\n",
      "\n",
      "Train Epoch: 1362 [0/8000 (0%)]\tBatch Loss: 1100.055913\tLearning Rate (w_theta): 0.001000\t TIME:1425.1s\n",
      "\t\t\t\tDisc: 1.447850\t\tSym: 20.172028\t\tSpars: 1078.436035\n",
      "\t TVw: -0.496675 | TVb: -2.043308 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1362 [4000/8000 (50%)]\tBatch Loss: 1114.351015\tLearning Rate (w_theta): 0.001000\t TIME:1426.6s\n",
      "\t\t\t\tDisc: 1.421321\t\tSym: 20.683477\t\tSpars: 1092.246216\n",
      "\t TVw: -0.496585 | TVb: -2.043308 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1362...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1118.464897267752\n",
      "Average validation loss: 185.51913471486503\n",
      "Training epoch 1363...\n",
      "\n",
      "Train Epoch: 1363 [0/8000 (0%)]\tBatch Loss: 1157.668293\tLearning Rate (w_theta): 0.001000\t TIME:1428.9s\n",
      "\t\t\t\tDisc: 1.218967\t\tSym: 21.973495\t\tSpars: 1134.475830\n",
      "\t TVw: -0.496495 | TVb: -2.043309 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1363 [4000/8000 (50%)]\tBatch Loss: 1121.828998\tLearning Rate (w_theta): 0.001000\t TIME:1430.4s\n",
      "\t\t\t\tDisc: 1.390821\t\tSym: 20.130682\t\tSpars: 1100.307495\n",
      "\t TVw: -0.496405 | TVb: -2.043309 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1363...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1128.514294332544\n",
      "Average validation loss: 182.87702557544247\n",
      "Training epoch 1364...\n",
      "\n",
      "Train Epoch: 1364 [0/8000 (0%)]\tBatch Loss: 1121.584052\tLearning Rate (w_theta): 0.001000\t TIME:1432.7s\n",
      "\t\t\t\tDisc: 1.520322\t\tSym: 20.438608\t\tSpars: 1099.625122\n",
      "\t TVw: -0.496316 | TVb: -2.043310 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1364 [4000/8000 (50%)]\tBatch Loss: 1118.609999\tLearning Rate (w_theta): 0.001000\t TIME:1434.2s\n",
      "\t\t\t\tDisc: 1.436861\t\tSym: 19.405315\t\tSpars: 1097.767822\n",
      "\t TVw: -0.496225 | TVb: -2.043310 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1364...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1117.4074474046652\n",
      "Average validation loss: 180.62858962655713\n",
      "Training epoch 1365...\n",
      "\n",
      "Train Epoch: 1365 [0/8000 (0%)]\tBatch Loss: 1113.001273\tLearning Rate (w_theta): 0.001000\t TIME:1436.5s\n",
      "\t\t\t\tDisc: 1.662885\t\tSym: 21.932383\t\tSpars: 1089.406006\n",
      "\t TVw: -0.496133 | TVb: -2.043311 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1365 [4000/8000 (50%)]\tBatch Loss: 1109.072179\tLearning Rate (w_theta): 0.001000\t TIME:1438.0s\n",
      "\t\t\t\tDisc: 1.461021\t\tSym: 19.571730\t\tSpars: 1088.039429\n",
      "\t TVw: -0.496041 | TVb: -2.043311 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1365...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1113.4384774964906\n",
      "Average validation loss: 180.64828311505113\n",
      "Training epoch 1366...\n",
      "\n",
      "Train Epoch: 1366 [0/8000 (0%)]\tBatch Loss: 1141.715917\tLearning Rate (w_theta): 0.001000\t TIME:1440.4s\n",
      "\t\t\t\tDisc: 1.508651\t\tSym: 22.267569\t\tSpars: 1117.939697\n",
      "\t TVw: -0.495947 | TVb: -2.043311 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1366 [4000/8000 (50%)]\tBatch Loss: 1097.489478\tLearning Rate (w_theta): 0.001000\t TIME:1441.9s\n",
      "\t\t\t\tDisc: 1.420445\t\tSym: 19.840395\t\tSpars: 1076.228638\n",
      "\t TVw: -0.495854 | TVb: -2.043311 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1366...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1109.462600223794\n",
      "Average validation loss: 181.75772952813404\n",
      "Training epoch 1367...\n",
      "\n",
      "Train Epoch: 1367 [0/8000 (0%)]\tBatch Loss: 1059.946734\tLearning Rate (w_theta): 0.001000\t TIME:1444.2s\n",
      "\t\t\t\tDisc: 1.212819\t\tSym: 17.644438\t\tSpars: 1041.089478\n",
      "\t TVw: -0.495761 | TVb: -2.043311 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1367 [4000/8000 (50%)]\tBatch Loss: 1135.770252\tLearning Rate (w_theta): 0.001000\t TIME:1445.7s\n",
      "\t\t\t\tDisc: 1.316671\t\tSym: 20.533537\t\tSpars: 1113.920044\n",
      "\t TVw: -0.495670 | TVb: -2.043312 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1367...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1119.0072151213608\n",
      "Average validation loss: 183.26681462239253\n",
      "Training epoch 1368...\n",
      "\n",
      "Train Epoch: 1368 [0/8000 (0%)]\tBatch Loss: 1131.692209\tLearning Rate (w_theta): 0.001000\t TIME:1448.2s\n",
      "\t\t\t\tDisc: 1.487365\t\tSym: 20.672373\t\tSpars: 1109.532471\n",
      "\t TVw: -0.495580 | TVb: -2.043312 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1368 [4000/8000 (50%)]\tBatch Loss: 1095.518142\tLearning Rate (w_theta): 0.001000\t TIME:1449.7s\n",
      "\t\t\t\tDisc: 1.556133\t\tSym: 19.473850\t\tSpars: 1074.488159\n",
      "\t TVw: -0.495490 | TVb: -2.043313 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1368...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1117.7837042354972\n",
      "Average validation loss: 182.01374197833064\n",
      "Training epoch 1369...\n",
      "\n",
      "Train Epoch: 1369 [0/8000 (0%)]\tBatch Loss: 1132.564557\tLearning Rate (w_theta): 0.001000\t TIME:1452.0s\n",
      "\t\t\t\tDisc: 1.658559\t\tSym: 21.700676\t\tSpars: 1109.205322\n",
      "\t TVw: -0.495399 | TVb: -2.043314 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1369 [4000/8000 (50%)]\tBatch Loss: 1101.814258\tLearning Rate (w_theta): 0.001000\t TIME:1453.5s\n",
      "\t\t\t\tDisc: 1.410062\t\tSym: 19.316183\t\tSpars: 1081.088013\n",
      "\t TVw: -0.495306 | TVb: -2.043314 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1369...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1108.067176718038\n",
      "Average validation loss: 181.67305253386576\n",
      "Training epoch 1370...\n",
      "\n",
      "Train Epoch: 1370 [0/8000 (0%)]\tBatch Loss: 1094.716029\tLearning Rate (w_theta): 0.001000\t TIME:1455.8s\n",
      "\t\t\t\tDisc: 1.355024\t\tSym: 19.388838\t\tSpars: 1073.972168\n",
      "\t TVw: -0.495211 | TVb: -2.043314 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1370 [4000/8000 (50%)]\tBatch Loss: 1061.519438\tLearning Rate (w_theta): 0.001000\t TIME:1457.4s\n",
      "\t\t\t\tDisc: 1.312922\t\tSym: 17.548679\t\tSpars: 1042.657837\n",
      "\t TVw: -0.495115 | TVb: -2.043314 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1370...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1107.5306025518848\n",
      "Average validation loss: 181.3837444695658\n",
      "Training epoch 1371...\n",
      "\n",
      "Train Epoch: 1371 [0/8000 (0%)]\tBatch Loss: 1107.602772\tLearning Rate (w_theta): 0.001000\t TIME:1460.3s\n",
      "\t\t\t\tDisc: 1.458668\t\tSym: 19.956604\t\tSpars: 1086.187500\n",
      "\t TVw: -0.495020 | TVb: -2.043314 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1371 [4000/8000 (50%)]\tBatch Loss: 1116.679803\tLearning Rate (w_theta): 0.001000\t TIME:1461.8s\n",
      "\t\t\t\tDisc: 1.404994\t\tSym: 19.929350\t\tSpars: 1095.345459\n",
      "\t TVw: -0.494925 | TVb: -2.043314 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1371...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1109.5214579957803\n",
      "Average validation loss: 180.1618521734345\n",
      "Training epoch 1372...\n",
      "\n",
      "Train Epoch: 1372 [0/8000 (0%)]\tBatch Loss: 1111.902730\tLearning Rate (w_theta): 0.001000\t TIME:1464.1s\n",
      "\t\t\t\tDisc: 1.528617\t\tSym: 20.409880\t\tSpars: 1089.964233\n",
      "\t TVw: -0.494831 | TVb: -2.043314 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1372 [4000/8000 (50%)]\tBatch Loss: 1088.560701\tLearning Rate (w_theta): 0.001000\t TIME:1465.6s\n",
      "\t\t\t\tDisc: 1.430934\t\tSym: 19.543219\t\tSpars: 1067.586548\n",
      "\t TVw: -0.494738 | TVb: -2.043314 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1372...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1107.809907019912\n",
      "Average validation loss: 180.55786899843122\n",
      "Training epoch 1373...\n",
      "\n",
      "Train Epoch: 1373 [0/8000 (0%)]\tBatch Loss: 1086.964938\tLearning Rate (w_theta): 0.001000\t TIME:1468.1s\n",
      "\t\t\t\tDisc: 1.491384\t\tSym: 19.615644\t\tSpars: 1065.857910\n",
      "\t TVw: -0.494644 | TVb: -2.043315 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1373 [4000/8000 (50%)]\tBatch Loss: 1122.681341\tLearning Rate (w_theta): 0.001000\t TIME:1469.6s\n",
      "\t\t\t\tDisc: 1.648274\t\tSym: 22.347155\t\tSpars: 1098.685913\n",
      "\t TVw: -0.494550 | TVb: -2.043315 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1373...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1106.0776470690344\n",
      "Average validation loss: 180.09625738281858\n",
      "Training epoch 1374...\n",
      "\n",
      "Train Epoch: 1374 [0/8000 (0%)]\tBatch Loss: 1098.769229\tLearning Rate (w_theta): 0.001000\t TIME:1471.9s\n",
      "\t\t\t\tDisc: 1.486184\t\tSym: 19.201136\t\tSpars: 1078.081909\n",
      "\t TVw: -0.494456 | TVb: -2.043315 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1374 [4000/8000 (50%)]\tBatch Loss: 1092.475853\tLearning Rate (w_theta): 0.001000\t TIME:1473.4s\n",
      "\t\t\t\tDisc: 1.409625\t\tSym: 19.576849\t\tSpars: 1071.489380\n",
      "\t TVw: -0.494361 | TVb: -2.043316 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1374...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1110.269410524097\n",
      "Average validation loss: 182.43086757683076\n",
      "Training epoch 1375...\n",
      "\n",
      "Train Epoch: 1375 [0/8000 (0%)]\tBatch Loss: 1127.009407\tLearning Rate (w_theta): 0.001000\t TIME:1475.7s\n",
      "\t\t\t\tDisc: 1.382434\t\tSym: 19.620869\t\tSpars: 1106.006104\n",
      "\t TVw: -0.494266 | TVb: -2.043316 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1375 [4000/8000 (50%)]\tBatch Loss: 1101.485138\tLearning Rate (w_theta): 0.001000\t TIME:1477.3s\n",
      "\t\t\t\tDisc: 1.502880\t\tSym: 20.753986\t\tSpars: 1079.228271\n",
      "\t TVw: -0.494173 | TVb: -2.043317 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1375...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1113.0179239550744\n",
      "Average validation loss: 179.33172321667172\n",
      "Training epoch 1376...\n",
      "\n",
      "Train Epoch: 1376 [0/8000 (0%)]\tBatch Loss: 1113.533036\tLearning Rate (w_theta): 0.001000\t TIME:1479.6s\n",
      "\t\t\t\tDisc: 1.563901\t\tSym: 20.865620\t\tSpars: 1091.103516\n",
      "\t TVw: -0.494078 | TVb: -2.043317 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1376 [4000/8000 (50%)]\tBatch Loss: 1084.580463\tLearning Rate (w_theta): 0.001000\t TIME:1481.1s\n",
      "\t\t\t\tDisc: 1.414360\t\tSym: 19.594936\t\tSpars: 1063.571167\n",
      "\t TVw: -0.493983 | TVb: -2.043317 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1376...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1107.535188720861\n",
      "Average validation loss: 180.97339712028557\n",
      "Training epoch 1377...\n",
      "\n",
      "Train Epoch: 1377 [0/8000 (0%)]\tBatch Loss: 1143.389412\tLearning Rate (w_theta): 0.001000\t TIME:1483.4s\n",
      "\t\t\t\tDisc: 1.582193\t\tSym: 22.344206\t\tSpars: 1119.463013\n",
      "\t TVw: -0.493887 | TVb: -2.043317 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1377 [4000/8000 (50%)]\tBatch Loss: 1126.221202\tLearning Rate (w_theta): 0.001000\t TIME:1484.9s\n",
      "\t\t\t\tDisc: 1.460507\t\tSym: 20.582838\t\tSpars: 1104.177856\n",
      "\t TVw: -0.493789 | TVb: -2.043317 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1377...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1104.2496868859052\n",
      "Average validation loss: 180.78370768777197\n",
      "Training epoch 1378...\n",
      "\n",
      "Train Epoch: 1378 [0/8000 (0%)]\tBatch Loss: 1064.983683\tLearning Rate (w_theta): 0.001000\t TIME:1487.2s\n",
      "\t\t\t\tDisc: 1.334355\t\tSym: 18.585608\t\tSpars: 1045.063721\n",
      "\t TVw: -0.493692 | TVb: -2.043318 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1378 [4000/8000 (50%)]\tBatch Loss: 1144.291760\tLearning Rate (w_theta): 0.001000\t TIME:1488.7s\n",
      "\t\t\t\tDisc: 1.493230\t\tSym: 21.958687\t\tSpars: 1120.839844\n",
      "\t TVw: -0.493596 | TVb: -2.043318 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1378...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1115.1328629802929\n",
      "Average validation loss: 178.20215394961232\n",
      "Training epoch 1379...\n",
      "\n",
      "Train Epoch: 1379 [0/8000 (0%)]\tBatch Loss: 1140.463597\tLearning Rate (w_theta): 0.001000\t TIME:1491.2s\n",
      "\t\t\t\tDisc: 1.851145\t\tSym: 22.277491\t\tSpars: 1116.334961\n",
      "\t TVw: -0.493502 | TVb: -2.043319 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1379 [4000/8000 (50%)]\tBatch Loss: 1107.377141\tLearning Rate (w_theta): 0.001000\t TIME:1492.7s\n",
      "\t\t\t\tDisc: 1.432722\t\tSym: 19.291710\t\tSpars: 1086.652710\n",
      "\t TVw: -0.493409 | TVb: -2.043319 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1379...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1118.212941351686\n",
      "Average validation loss: 177.3131395362665\n",
      "Training epoch 1380...\n",
      "\n",
      "Train Epoch: 1380 [0/8000 (0%)]\tBatch Loss: 1123.514624\tLearning Rate (w_theta): 0.001000\t TIME:1495.0s\n",
      "\t\t\t\tDisc: 1.572964\t\tSym: 19.754892\t\tSpars: 1102.186768\n",
      "\t TVw: -0.493314 | TVb: -2.043319 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1380 [4000/8000 (50%)]\tBatch Loss: 1114.286649\tLearning Rate (w_theta): 0.001000\t TIME:1496.6s\n",
      "\t\t\t\tDisc: 1.581894\t\tSym: 21.025801\t\tSpars: 1091.678955\n",
      "\t TVw: -0.493219 | TVb: -2.043320 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1380...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1111.1299477019047\n",
      "Average validation loss: 179.59004947940736\n",
      "Training epoch 1381...\n",
      "\n",
      "Train Epoch: 1381 [0/8000 (0%)]\tBatch Loss: 1095.785412\tLearning Rate (w_theta): 0.001000\t TIME:1499.5s\n",
      "\t\t\t\tDisc: 1.367016\t\tSym: 19.428772\t\tSpars: 1074.989624\n",
      "\t TVw: -0.493122 | TVb: -2.043320 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1381 [4000/8000 (50%)]\tBatch Loss: 1062.241829\tLearning Rate (w_theta): 0.001000\t TIME:1501.0s\n",
      "\t\t\t\tDisc: 1.209977\t\tSym: 17.621696\t\tSpars: 1043.410156\n",
      "\t TVw: -0.493023 | TVb: -2.043321 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1381...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1105.1110689975383\n",
      "Average validation loss: 179.14803134592708\n",
      "Training epoch 1382...\n",
      "\n",
      "Train Epoch: 1382 [0/8000 (0%)]\tBatch Loss: 1105.692611\tLearning Rate (w_theta): 0.001000\t TIME:1503.3s\n",
      "\t\t\t\tDisc: 1.486341\t\tSym: 20.550875\t\tSpars: 1083.655396\n",
      "\t TVw: -0.492924 | TVb: -2.043321 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1382 [4000/8000 (50%)]\tBatch Loss: 1152.409105\tLearning Rate (w_theta): 0.001000\t TIME:1504.9s\n",
      "\t\t\t\tDisc: 1.495262\t\tSym: 21.587305\t\tSpars: 1129.326538\n",
      "\t TVw: -0.492826 | TVb: -2.043322 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1382...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1109.1254331169653\n",
      "Average validation loss: 178.7042699827133\n",
      "Training epoch 1383...\n",
      "\n",
      "Train Epoch: 1383 [0/8000 (0%)]\tBatch Loss: 1115.650036\tLearning Rate (w_theta): 0.001000\t TIME:1507.2s\n",
      "\t\t\t\tDisc: 1.455098\t\tSym: 21.158073\t\tSpars: 1093.036865\n",
      "\t TVw: -0.492729 | TVb: -2.043322 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1383 [4000/8000 (50%)]\tBatch Loss: 1072.938535\tLearning Rate (w_theta): 0.001000\t TIME:1508.8s\n",
      "\t\t\t\tDisc: 1.410468\t\tSym: 18.874014\t\tSpars: 1052.654053\n",
      "\t TVw: -0.492633 | TVb: -2.043323 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1383...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1104.731367079293\n",
      "Average validation loss: 178.0225868635219\n",
      "Training epoch 1384...\n",
      "\n",
      "Train Epoch: 1384 [0/8000 (0%)]\tBatch Loss: 1140.015711\tLearning Rate (w_theta): 0.001000\t TIME:1511.1s\n",
      "\t\t\t\tDisc: 1.518971\t\tSym: 21.166174\t\tSpars: 1117.330566\n",
      "\t TVw: -0.492535 | TVb: -2.043323 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1384 [4000/8000 (50%)]\tBatch Loss: 1086.585344\tLearning Rate (w_theta): 0.001000\t TIME:1512.7s\n",
      "\t\t\t\tDisc: 1.365614\t\tSym: 18.606815\t\tSpars: 1066.612915\n",
      "\t TVw: -0.492437 | TVb: -2.043323 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1384...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1105.3596120583782\n",
      "Average validation loss: 178.73292690465937\n",
      "Training epoch 1385...\n",
      "\n",
      "Train Epoch: 1385 [0/8000 (0%)]\tBatch Loss: 1134.369774\tLearning Rate (w_theta): 0.001000\t TIME:1515.0s\n",
      "\t\t\t\tDisc: 1.557133\t\tSym: 23.143574\t\tSpars: 1109.669067\n",
      "\t TVw: -0.492338 | TVb: -2.043324 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1385 [4000/8000 (50%)]\tBatch Loss: 1095.032572\tLearning Rate (w_theta): 0.001000\t TIME:1516.5s\n",
      "\t\t\t\tDisc: 1.332128\t\tSym: 18.035404\t\tSpars: 1075.665039\n",
      "\t TVw: -0.492242 | TVb: -2.043324 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1385...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1116.8159991114708\n",
      "Average validation loss: 178.1861375316156\n",
      "Training epoch 1386...\n",
      "\n",
      "Train Epoch: 1386 [0/8000 (0%)]\tBatch Loss: 1113.892396\tLearning Rate (w_theta): 0.001000\t TIME:1518.8s\n",
      "\t\t\t\tDisc: 1.629674\t\tSym: 20.115749\t\tSpars: 1092.146973\n",
      "\t TVw: -0.492145 | TVb: -2.043325 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1386 [4000/8000 (50%)]\tBatch Loss: 1159.789816\tLearning Rate (w_theta): 0.001000\t TIME:1520.4s\n",
      "\t\t\t\tDisc: 1.790718\t\tSym: 22.045851\t\tSpars: 1135.953247\n",
      "\t TVw: -0.492048 | TVb: -2.043325 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1386...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1113.8746589848918\n",
      "Average validation loss: 182.02954341790814\n",
      "Training epoch 1387...\n",
      "\n",
      "Train Epoch: 1387 [0/8000 (0%)]\tBatch Loss: 1136.326165\tLearning Rate (w_theta): 0.001000\t TIME:1522.7s\n",
      "\t\t\t\tDisc: 1.366801\t\tSym: 21.027845\t\tSpars: 1113.931519\n",
      "\t TVw: -0.491950 | TVb: -2.043326 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1387 [4000/8000 (50%)]\tBatch Loss: 1105.787236\tLearning Rate (w_theta): 0.001000\t TIME:1524.3s\n",
      "\t\t\t\tDisc: 1.304610\t\tSym: 20.549520\t\tSpars: 1083.933105\n",
      "\t TVw: -0.491850 | TVb: -2.043326 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1387...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1104.6845465244755\n",
      "Average validation loss: 180.6232639761866\n",
      "Training epoch 1388...\n",
      "\n",
      "Train Epoch: 1388 [0/8000 (0%)]\tBatch Loss: 1110.851633\tLearning Rate (w_theta): 0.001000\t TIME:1526.7s\n",
      "\t\t\t\tDisc: 1.458862\t\tSym: 20.521677\t\tSpars: 1088.871094\n",
      "\t TVw: -0.491748 | TVb: -2.043326 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1388 [4000/8000 (50%)]\tBatch Loss: 1125.279546\tLearning Rate (w_theta): 0.001000\t TIME:1528.2s\n",
      "\t\t\t\tDisc: 1.575908\t\tSym: 22.236353\t\tSpars: 1101.467285\n",
      "\t TVw: -0.491646 | TVb: -2.043326 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1388...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1103.906402235722\n",
      "Average validation loss: 180.01989892641487\n",
      "Training epoch 1389...\n",
      "\n",
      "Train Epoch: 1389 [0/8000 (0%)]\tBatch Loss: 1126.184886\tLearning Rate (w_theta): 0.001000\t TIME:1530.5s\n",
      "\t\t\t\tDisc: 1.539916\t\tSym: 21.740673\t\tSpars: 1102.904297\n",
      "\t TVw: -0.491544 | TVb: -2.043326 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1389 [4000/8000 (50%)]\tBatch Loss: 1130.813827\tLearning Rate (w_theta): 0.001000\t TIME:1532.0s\n",
      "\t\t\t\tDisc: 1.634305\t\tSym: 21.282915\t\tSpars: 1107.896606\n",
      "\t TVw: -0.491444 | TVb: -2.043327 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1389...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1103.4507899932346\n",
      "Average validation loss: 177.9112581700088\n",
      "Training epoch 1390...\n",
      "\n",
      "Train Epoch: 1390 [0/8000 (0%)]\tBatch Loss: 1129.486491\tLearning Rate (w_theta): 0.001000\t TIME:1534.5s\n",
      "\t\t\t\tDisc: 1.650953\t\tSym: 22.604826\t\tSpars: 1105.230713\n",
      "\t TVw: -0.491343 | TVb: -2.043328 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1390 [4000/8000 (50%)]\tBatch Loss: 1115.736620\tLearning Rate (w_theta): 0.001000\t TIME:1536.1s\n",
      "\t\t\t\tDisc: 1.295445\t\tSym: 19.871229\t\tSpars: 1094.569946\n",
      "\t TVw: -0.491244 | TVb: -2.043328 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1390...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1109.950977180492\n",
      "Average validation loss: 177.73162050073276\n",
      "Training epoch 1391...\n",
      "\n",
      "Train Epoch: 1391 [0/8000 (0%)]\tBatch Loss: 1110.547350\tLearning Rate (w_theta): 0.001000\t TIME:1539.1s\n",
      "\t\t\t\tDisc: 1.467999\t\tSym: 19.947027\t\tSpars: 1089.132324\n",
      "\t TVw: -0.491145 | TVb: -2.043329 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1391 [4000/8000 (50%)]\tBatch Loss: 1068.279480\tLearning Rate (w_theta): 0.001000\t TIME:1540.6s\n",
      "\t\t\t\tDisc: 1.348786\t\tSym: 19.119904\t\tSpars: 1047.810791\n",
      "\t TVw: -0.491045 | TVb: -2.043330 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1391...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1102.5290794213724\n",
      "Average validation loss: 179.93820824398392\n",
      "Training epoch 1392...\n",
      "\n",
      "Train Epoch: 1392 [0/8000 (0%)]\tBatch Loss: 1123.898649\tLearning Rate (w_theta): 0.001000\t TIME:1542.9s\n",
      "\t\t\t\tDisc: 1.457590\t\tSym: 21.527363\t\tSpars: 1100.913696\n",
      "\t TVw: -0.490942 | TVb: -2.043330 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1392 [4000/8000 (50%)]\tBatch Loss: 1056.228522\tLearning Rate (w_theta): 0.001000\t TIME:1544.4s\n",
      "\t\t\t\tDisc: 1.420682\t\tSym: 18.640970\t\tSpars: 1036.166870\n",
      "\t TVw: -0.490840 | TVb: -2.043330 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1392...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1104.2903423722503\n",
      "Average validation loss: 176.84523054695674\n",
      "Training epoch 1393...\n",
      "\n",
      "Train Epoch: 1393 [0/8000 (0%)]\tBatch Loss: 1108.174589\tLearning Rate (w_theta): 0.001000\t TIME:1546.8s\n",
      "\t\t\t\tDisc: 1.564132\t\tSym: 19.633894\t\tSpars: 1086.976562\n",
      "\t TVw: -0.490738 | TVb: -2.043331 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1393 [4000/8000 (50%)]\tBatch Loss: 1082.886726\tLearning Rate (w_theta): 0.001000\t TIME:1548.3s\n",
      "\t\t\t\tDisc: 1.478904\t\tSym: 18.747787\t\tSpars: 1062.660034\n",
      "\t TVw: -0.490637 | TVb: -2.043332 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1393...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1111.783690571837\n",
      "Average validation loss: 175.71040460688104\n",
      "Training epoch 1394...\n",
      "\n",
      "Train Epoch: 1394 [0/8000 (0%)]\tBatch Loss: 1141.476307\tLearning Rate (w_theta): 0.001000\t TIME:1550.7s\n",
      "\t\t\t\tDisc: 1.748263\t\tSym: 21.420794\t\tSpars: 1118.307251\n",
      "\t TVw: -0.490538 | TVb: -2.043333 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1394 [4000/8000 (50%)]\tBatch Loss: 1104.943911\tLearning Rate (w_theta): 0.001000\t TIME:1552.3s\n",
      "\t\t\t\tDisc: 1.431000\t\tSym: 19.336885\t\tSpars: 1084.176025\n",
      "\t TVw: -0.490440 | TVb: -2.043333 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1394...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1113.464893700702\n",
      "Average validation loss: 176.78681700675583\n",
      "Training epoch 1395...\n",
      "\n",
      "Train Epoch: 1395 [0/8000 (0%)]\tBatch Loss: 1131.222352\tLearning Rate (w_theta): 0.001000\t TIME:1554.6s\n",
      "\t\t\t\tDisc: 1.494624\t\tSym: 20.806829\t\tSpars: 1108.920898\n",
      "\t TVw: -0.490340 | TVb: -2.043334 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1395 [4000/8000 (50%)]\tBatch Loss: 1121.473880\tLearning Rate (w_theta): 0.001000\t TIME:1556.2s\n",
      "\t\t\t\tDisc: 1.573096\t\tSym: 21.255398\t\tSpars: 1098.645386\n",
      "\t TVw: -0.490237 | TVb: -2.043334 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1395...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1101.5363556154718\n",
      "Average validation loss: 178.83843679762637\n",
      "Training epoch 1396...\n",
      "\n",
      "Train Epoch: 1396 [0/8000 (0%)]\tBatch Loss: 1094.571242\tLearning Rate (w_theta): 0.001000\t TIME:1558.5s\n",
      "\t\t\t\tDisc: 1.335732\t\tSym: 19.304480\t\tSpars: 1073.931030\n",
      "\t TVw: -0.490132 | TVb: -2.043334 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1396 [4000/8000 (50%)]\tBatch Loss: 1114.618199\tLearning Rate (w_theta): 0.001000\t TIME:1560.0s\n",
      "\t\t\t\tDisc: 1.447249\t\tSym: 20.021780\t\tSpars: 1093.149170\n",
      "\t TVw: -0.490028 | TVb: -2.043334 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1396...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1099.7911404157078\n",
      "Average validation loss: 178.1157912120594\n",
      "Training epoch 1397...\n",
      "\n",
      "Train Epoch: 1397 [0/8000 (0%)]\tBatch Loss: 1087.767049\tLearning Rate (w_theta): 0.001000\t TIME:1562.4s\n",
      "\t\t\t\tDisc: 1.415944\t\tSym: 19.781525\t\tSpars: 1066.569580\n",
      "\t TVw: -0.489923 | TVb: -2.043334 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1397 [4000/8000 (50%)]\tBatch Loss: 1133.891199\tLearning Rate (w_theta): 0.001000\t TIME:1563.9s\n",
      "\t\t\t\tDisc: 1.540218\t\tSym: 20.901152\t\tSpars: 1111.449829\n",
      "\t TVw: -0.489819 | TVb: -2.043334 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1397...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1100.106478900634\n",
      "Average validation loss: 178.7897431517904\n",
      "Training epoch 1398...\n",
      "\n",
      "Train Epoch: 1398 [0/8000 (0%)]\tBatch Loss: 1086.971967\tLearning Rate (w_theta): 0.001000\t TIME:1566.2s\n",
      "\t\t\t\tDisc: 1.516178\t\tSym: 20.199198\t\tSpars: 1065.256592\n",
      "\t TVw: -0.489715 | TVb: -2.043334 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1398 [4000/8000 (50%)]\tBatch Loss: 1079.761482\tLearning Rate (w_theta): 0.001000\t TIME:1567.7s\n",
      "\t\t\t\tDisc: 1.350456\t\tSym: 18.685196\t\tSpars: 1059.725830\n",
      "\t TVw: -0.489611 | TVb: -2.043335 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1398...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1098.7743812021752\n",
      "Average validation loss: 177.0750176697692\n",
      "Training epoch 1399...\n",
      "\n",
      "Train Epoch: 1399 [0/8000 (0%)]\tBatch Loss: 1130.764167\tLearning Rate (w_theta): 0.001000\t TIME:1570.1s\n",
      "\t\t\t\tDisc: 1.567136\t\tSym: 21.216806\t\tSpars: 1107.980225\n",
      "\t TVw: -0.489508 | TVb: -2.043336 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1399 [4000/8000 (50%)]\tBatch Loss: 1079.002002\tLearning Rate (w_theta): 0.001000\t TIME:1571.6s\n",
      "\t\t\t\tDisc: 1.346253\t\tSym: 18.048815\t\tSpars: 1059.606934\n",
      "\t TVw: -0.489404 | TVb: -2.043336 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1399...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1104.0012892618631\n",
      "Average validation loss: 177.93659524908887\n",
      "Training epoch 1400...\n",
      "\n",
      "Train Epoch: 1400 [0/8000 (0%)]\tBatch Loss: 1133.850079\tLearning Rate (w_theta): 0.001000\t TIME:1573.9s\n",
      "\t\t\t\tDisc: 1.394760\t\tSym: 20.414303\t\tSpars: 1112.041016\n",
      "\t TVw: -0.489300 | TVb: -2.043337 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1400 [4000/8000 (50%)]\tBatch Loss: 1061.325913\tLearning Rate (w_theta): 0.001000\t TIME:1575.5s\n",
      "\t\t\t\tDisc: 1.079449\t\tSym: 17.058964\t\tSpars: 1043.187500\n",
      "\t TVw: -0.489199 | TVb: -2.043337 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1400...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1109.3459658977156\n",
      "Average validation loss: 178.42860469881137\n",
      "Training epoch 1401...\n",
      "\n",
      "Train Epoch: 1401 [0/8000 (0%)]\tBatch Loss: 1129.258738\tLearning Rate (w_theta): 0.001000\t TIME:1578.6s\n",
      "\t\t\t\tDisc: 1.286971\t\tSym: 20.249966\t\tSpars: 1107.721802\n",
      "\t TVw: -0.489097 | TVb: -2.043338 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1401 [4000/8000 (50%)]\tBatch Loss: 1066.065181\tLearning Rate (w_theta): 0.001000\t TIME:1580.2s\n",
      "\t\t\t\tDisc: 1.351506\t\tSym: 18.074881\t\tSpars: 1046.638794\n",
      "\t TVw: -0.488995 | TVb: -2.043338 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1401...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1112.269995026627\n",
      "Average validation loss: 174.88351425136491\n",
      "Training epoch 1402...\n",
      "\n",
      "Train Epoch: 1402 [0/8000 (0%)]\tBatch Loss: 1138.826543\tLearning Rate (w_theta): 0.001000\t TIME:1582.5s\n",
      "\t\t\t\tDisc: 1.718708\t\tSym: 21.254930\t\tSpars: 1115.852905\n",
      "\t TVw: -0.488893 | TVb: -2.043339 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1402 [4000/8000 (50%)]\tBatch Loss: 1097.658392\tLearning Rate (w_theta): 0.001000\t TIME:1584.0s\n",
      "\t\t\t\tDisc: 1.448692\t\tSym: 18.871565\t\tSpars: 1077.338135\n",
      "\t TVw: -0.488793 | TVb: -2.043340 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1402...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1121.92622229126\n",
      "Average validation loss: 175.1101601789188\n",
      "Training epoch 1403...\n",
      "\n",
      "Train Epoch: 1403 [0/8000 (0%)]\tBatch Loss: 1132.890623\tLearning Rate (w_theta): 0.001000\t TIME:1586.4s\n",
      "\t\t\t\tDisc: 1.392164\t\tSym: 19.110031\t\tSpars: 1112.388428\n",
      "\t TVw: -0.488692 | TVb: -2.043341 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1403 [4000/8000 (50%)]\tBatch Loss: 1122.834972\tLearning Rate (w_theta): 0.001000\t TIME:1587.9s\n",
      "\t\t\t\tDisc: 1.396749\t\tSym: 20.984854\t\tSpars: 1100.453369\n",
      "\t TVw: -0.488595 | TVb: -2.043342 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1403...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1138.4871067184986\n",
      "Average validation loss: 183.98813087690596\n",
      "Training epoch 1404...\n",
      "\n",
      "Train Epoch: 1404 [0/8000 (0%)]\tBatch Loss: 1141.754278\tLearning Rate (w_theta): 0.001000\t TIME:1590.2s\n",
      "\t\t\t\tDisc: 1.185494\t\tSym: 21.436949\t\tSpars: 1119.131836\n",
      "\t TVw: -0.488498 | TVb: -2.043343 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1404 [4000/8000 (50%)]\tBatch Loss: 1160.467284\tLearning Rate (w_theta): 0.001000\t TIME:1591.8s\n",
      "\t\t\t\tDisc: 1.802812\t\tSym: 24.092085\t\tSpars: 1134.572388\n",
      "\t TVw: -0.488399 | TVb: -2.043344 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1404...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1128.2619255895465\n",
      "Average validation loss: 176.85929999712133\n",
      "Training epoch 1405...\n",
      "\n",
      "Train Epoch: 1405 [0/8000 (0%)]\tBatch Loss: 1160.351772\tLearning Rate (w_theta): 0.001000\t TIME:1594.1s\n",
      "\t\t\t\tDisc: 1.744022\t\tSym: 22.611290\t\tSpars: 1135.996460\n",
      "\t TVw: -0.488295 | TVb: -2.043344 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1405 [4000/8000 (50%)]\tBatch Loss: 1120.894419\tLearning Rate (w_theta): 0.001000\t TIME:1595.7s\n",
      "\t\t\t\tDisc: 1.609189\t\tSym: 20.158644\t\tSpars: 1099.126587\n",
      "\t TVw: -0.488188 | TVb: -2.043344 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1405...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1113.6414546117073\n",
      "Average validation loss: 178.14403904554007\n",
      "Training epoch 1406...\n",
      "\n",
      "Train Epoch: 1406 [0/8000 (0%)]\tBatch Loss: 1111.148892\tLearning Rate (w_theta): 0.001000\t TIME:1598.1s\n",
      "\t\t\t\tDisc: 1.438025\t\tSym: 19.843679\t\tSpars: 1089.867188\n",
      "\t TVw: -0.488077 | TVb: -2.043344 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1406 [4000/8000 (50%)]\tBatch Loss: 1066.249149\tLearning Rate (w_theta): 0.001000\t TIME:1599.6s\n",
      "\t\t\t\tDisc: 1.343927\t\tSym: 18.246653\t\tSpars: 1046.658569\n",
      "\t TVw: -0.487965 | TVb: -2.043344 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1406...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1103.3225540539192\n",
      "Average validation loss: 176.94831479095677\n",
      "Training epoch 1407...\n",
      "\n",
      "Train Epoch: 1407 [0/8000 (0%)]\tBatch Loss: 1094.286304\tLearning Rate (w_theta): 0.001000\t TIME:1602.0s\n",
      "\t\t\t\tDisc: 1.490061\t\tSym: 19.394510\t\tSpars: 1073.401733\n",
      "\t TVw: -0.487853 | TVb: -2.043345 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1407 [4000/8000 (50%)]\tBatch Loss: 1085.334420\tLearning Rate (w_theta): 0.001000\t TIME:1603.5s\n",
      "\t\t\t\tDisc: 1.373668\t\tSym: 19.759947\t\tSpars: 1064.200806\n",
      "\t TVw: -0.487741 | TVb: -2.043345 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1407...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1102.3681947695623\n",
      "Average validation loss: 176.51758190278474\n",
      "Training epoch 1408...\n",
      "\n",
      "Train Epoch: 1408 [0/8000 (0%)]\tBatch Loss: 1072.716961\tLearning Rate (w_theta): 0.001000\t TIME:1605.9s\n",
      "\t\t\t\tDisc: 1.360771\t\tSym: 19.295155\t\tSpars: 1052.061035\n",
      "\t TVw: -0.487630 | TVb: -2.043345 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1408 [4000/8000 (50%)]\tBatch Loss: 1102.219208\tLearning Rate (w_theta): 0.001000\t TIME:1607.4s\n",
      "\t\t\t\tDisc: 1.399027\t\tSym: 21.205069\t\tSpars: 1079.615112\n",
      "\t TVw: -0.487521 | TVb: -2.043345 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1408...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1100.4159983975314\n",
      "Average validation loss: 176.77184898737084\n",
      "Training epoch 1409...\n",
      "\n",
      "Train Epoch: 1409 [0/8000 (0%)]\tBatch Loss: 1106.044325\tLearning Rate (w_theta): 0.001000\t TIME:1609.7s\n",
      "\t\t\t\tDisc: 1.476086\t\tSym: 21.611452\t\tSpars: 1082.956787\n",
      "\t TVw: -0.487411 | TVb: -2.043346 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1409 [4000/8000 (50%)]\tBatch Loss: 1143.961605\tLearning Rate (w_theta): 0.001000\t TIME:1611.2s\n",
      "\t\t\t\tDisc: 1.502766\t\tSym: 21.125587\t\tSpars: 1121.333252\n",
      "\t TVw: -0.487301 | TVb: -2.043346 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1409...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1097.76086892104\n",
      "Average validation loss: 175.82647173513521\n",
      "Training epoch 1410...\n",
      "\n",
      "Train Epoch: 1410 [0/8000 (0%)]\tBatch Loss: 1127.856734\tLearning Rate (w_theta): 0.001000\t TIME:1613.6s\n",
      "\t\t\t\tDisc: 1.511576\t\tSym: 20.124821\t\tSpars: 1106.220337\n",
      "\t TVw: -0.487192 | TVb: -2.043347 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1410 [4000/8000 (50%)]\tBatch Loss: 1121.413312\tLearning Rate (w_theta): 0.001000\t TIME:1615.1s\n",
      "\t\t\t\tDisc: 1.443730\t\tSym: 20.896706\t\tSpars: 1099.072876\n",
      "\t TVw: -0.487082 | TVb: -2.043347 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1410...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1097.993266110039\n",
      "Average validation loss: 176.8012690936849\n",
      "Training epoch 1411...\n",
      "\n",
      "Train Epoch: 1411 [0/8000 (0%)]\tBatch Loss: 1069.277324\tLearning Rate (w_theta): 0.001000\t TIME:1618.3s\n",
      "\t\t\t\tDisc: 1.381952\t\tSym: 18.802843\t\tSpars: 1049.092529\n",
      "\t TVw: -0.486972 | TVb: -2.043348 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1411 [4000/8000 (50%)]\tBatch Loss: 1081.054852\tLearning Rate (w_theta): 0.001000\t TIME:1619.8s\n",
      "\t\t\t\tDisc: 1.310018\t\tSym: 18.039391\t\tSpars: 1061.705444\n",
      "\t TVw: -0.486863 | TVb: -2.043348 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1411...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1100.2288352606608\n",
      "Average validation loss: 176.85249794246468\n",
      "Training epoch 1412...\n",
      "\n",
      "Train Epoch: 1412 [0/8000 (0%)]\tBatch Loss: 1089.293208\tLearning Rate (w_theta): 0.001000\t TIME:1622.2s\n",
      "\t\t\t\tDisc: 1.440484\t\tSym: 19.651674\t\tSpars: 1068.201050\n",
      "\t TVw: -0.486753 | TVb: -2.043349 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1412 [4000/8000 (50%)]\tBatch Loss: 1125.870558\tLearning Rate (w_theta): 0.001000\t TIME:1623.7s\n",
      "\t\t\t\tDisc: 1.469765\t\tSym: 20.890661\t\tSpars: 1103.510132\n",
      "\t TVw: -0.486643 | TVb: -2.043349 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1412...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1096.245219859156\n",
      "Average validation loss: 175.36086454785953\n",
      "Training epoch 1413...\n",
      "\n",
      "Train Epoch: 1413 [0/8000 (0%)]\tBatch Loss: 1085.749955\tLearning Rate (w_theta): 0.001000\t TIME:1626.0s\n",
      "\t\t\t\tDisc: 1.430808\t\tSym: 19.485773\t\tSpars: 1064.833374\n",
      "\t TVw: -0.486532 | TVb: -2.043350 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1413 [4000/8000 (50%)]\tBatch Loss: 1090.812055\tLearning Rate (w_theta): 0.001000\t TIME:1627.5s\n",
      "\t\t\t\tDisc: 1.389081\t\tSym: 19.519653\t\tSpars: 1069.903320\n",
      "\t TVw: -0.486420 | TVb: -2.043350 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1413...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1094.3067641616421\n",
      "Average validation loss: 175.6920046279291\n",
      "Training epoch 1414...\n",
      "\n",
      "Train Epoch: 1414 [0/8000 (0%)]\tBatch Loss: 1085.732372\tLearning Rate (w_theta): 0.001000\t TIME:1629.9s\n",
      "\t\t\t\tDisc: 1.406194\t\tSym: 19.480230\t\tSpars: 1064.845947\n",
      "\t TVw: -0.486308 | TVb: -2.043350 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1414 [4000/8000 (50%)]\tBatch Loss: 1094.656971\tLearning Rate (w_theta): 0.001000\t TIME:1631.4s\n",
      "\t\t\t\tDisc: 1.332937\t\tSym: 18.008116\t\tSpars: 1075.315918\n",
      "\t TVw: -0.486199 | TVb: -2.043351 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1414...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1095.0281560171484\n",
      "Average validation loss: 175.40596344379992\n",
      "Training epoch 1415...\n",
      "\n",
      "Train Epoch: 1415 [0/8000 (0%)]\tBatch Loss: 1115.609081\tLearning Rate (w_theta): 0.001000\t TIME:1633.7s\n",
      "\t\t\t\tDisc: 1.592749\t\tSym: 20.884863\t\tSpars: 1093.131470\n",
      "\t TVw: -0.486090 | TVb: -2.043352 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1415 [4000/8000 (50%)]\tBatch Loss: 1063.168505\tLearning Rate (w_theta): 0.001000\t TIME:1635.3s\n",
      "\t\t\t\tDisc: 1.408794\t\tSym: 18.638983\t\tSpars: 1043.120728\n",
      "\t TVw: -0.485979 | TVb: -2.043353 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1415...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1094.4558312251625\n",
      "Average validation loss: 177.31728013723037\n",
      "Training epoch 1416...\n",
      "\n",
      "Train Epoch: 1416 [0/8000 (0%)]\tBatch Loss: 1159.825101\tLearning Rate (w_theta): 0.001000\t TIME:1637.6s\n",
      "\t\t\t\tDisc: 1.538575\t\tSym: 23.952541\t\tSpars: 1134.333984\n",
      "\t TVw: -0.485869 | TVb: -2.043353 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1416 [4000/8000 (50%)]\tBatch Loss: 1104.451574\tLearning Rate (w_theta): 0.001000\t TIME:1639.1s\n",
      "\t\t\t\tDisc: 1.545669\t\tSym: 19.653341\t\tSpars: 1083.252563\n",
      "\t TVw: -0.485758 | TVb: -2.043354 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1416...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1101.6496138949503\n",
      "Average validation loss: 173.92689180709024\n",
      "Training epoch 1417...\n",
      "\n",
      "Train Epoch: 1417 [0/8000 (0%)]\tBatch Loss: 1132.295075\tLearning Rate (w_theta): 0.001000\t TIME:1641.6s\n",
      "\t\t\t\tDisc: 1.776782\t\tSym: 22.072981\t\tSpars: 1108.445312\n",
      "\t TVw: -0.485647 | TVb: -2.043355 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1417 [4000/8000 (50%)]\tBatch Loss: 1107.507465\tLearning Rate (w_theta): 0.001000\t TIME:1643.1s\n",
      "\t\t\t\tDisc: 1.456533\t\tSym: 19.690092\t\tSpars: 1086.360840\n",
      "\t TVw: -0.485535 | TVb: -2.043355 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1417...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1097.3883921862202\n",
      "Average validation loss: 175.23007855934264\n",
      "Training epoch 1418...\n",
      "\n",
      "Train Epoch: 1418 [0/8000 (0%)]\tBatch Loss: 1072.199730\tLearning Rate (w_theta): 0.001000\t TIME:1645.4s\n",
      "\t\t\t\tDisc: 1.452965\t\tSym: 18.733948\t\tSpars: 1052.012817\n",
      "\t TVw: -0.485423 | TVb: -2.043355 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1418 [4000/8000 (50%)]\tBatch Loss: 1076.368662\tLearning Rate (w_theta): 0.001000\t TIME:1646.9s\n",
      "\t\t\t\tDisc: 1.290278\t\tSym: 18.118179\t\tSpars: 1056.960205\n",
      "\t TVw: -0.485310 | TVb: -2.043355 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1418...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1095.9265955634005\n",
      "Average validation loss: 174.83488290887817\n",
      "Training epoch 1419...\n",
      "\n",
      "Train Epoch: 1419 [0/8000 (0%)]\tBatch Loss: 1116.526895\tLearning Rate (w_theta): 0.001000\t TIME:1649.3s\n",
      "\t\t\t\tDisc: 1.501178\t\tSym: 21.510580\t\tSpars: 1093.515137\n",
      "\t TVw: -0.485198 | TVb: -2.043356 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1419 [4000/8000 (50%)]\tBatch Loss: 1064.455718\tLearning Rate (w_theta): 0.001000\t TIME:1650.8s\n",
      "\t\t\t\tDisc: 1.309373\t\tSym: 18.392927\t\tSpars: 1044.753418\n",
      "\t TVw: -0.485084 | TVb: -2.043356 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1419...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1095.4203607635586\n",
      "Average validation loss: 177.4104536614616\n",
      "Training epoch 1420...\n",
      "\n",
      "Train Epoch: 1420 [0/8000 (0%)]\tBatch Loss: 1098.140388\tLearning Rate (w_theta): 0.001000\t TIME:1653.2s\n",
      "\t\t\t\tDisc: 1.203363\t\tSym: 19.376112\t\tSpars: 1077.560913\n",
      "\t TVw: -0.484972 | TVb: -2.043357 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1420 [4000/8000 (50%)]\tBatch Loss: 1127.150801\tLearning Rate (w_theta): 0.001000\t TIME:1654.7s\n",
      "\t\t\t\tDisc: 1.618811\t\tSym: 20.371590\t\tSpars: 1105.160400\n",
      "\t TVw: -0.484860 | TVb: -2.043358 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1420...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1101.962409752418\n",
      "Average validation loss: 173.9635324671306\n",
      "Training epoch 1421...\n",
      "\n",
      "Train Epoch: 1421 [0/8000 (0%)]\tBatch Loss: 1077.087669\tLearning Rate (w_theta): 0.001000\t TIME:1657.6s\n",
      "\t\t\t\tDisc: 1.550699\t\tSym: 19.212629\t\tSpars: 1056.324341\n",
      "\t TVw: -0.484750 | TVb: -2.043358 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1421 [4000/8000 (50%)]\tBatch Loss: 1071.916780\tLearning Rate (w_theta): 0.001000\t TIME:1659.1s\n",
      "\t\t\t\tDisc: 1.503935\t\tSym: 19.124882\t\tSpars: 1051.287964\n",
      "\t TVw: -0.484638 | TVb: -2.043359 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1421...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1096.2068669936841\n",
      "Average validation loss: 174.58100429268396\n",
      "Training epoch 1422...\n",
      "\n",
      "Train Epoch: 1422 [0/8000 (0%)]\tBatch Loss: 1075.339353\tLearning Rate (w_theta): 0.001000\t TIME:1661.6s\n",
      "\t\t\t\tDisc: 1.430252\t\tSym: 18.675581\t\tSpars: 1055.233521\n",
      "\t TVw: -0.484525 | TVb: -2.043359 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1422 [4000/8000 (50%)]\tBatch Loss: 1109.263725\tLearning Rate (w_theta): 0.001000\t TIME:1663.1s\n",
      "\t\t\t\tDisc: 1.361356\t\tSym: 19.606470\t\tSpars: 1088.295898\n",
      "\t TVw: -0.484409 | TVb: -2.043360 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1422...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1095.8868981702665\n",
      "Average validation loss: 173.90730547630386\n",
      "Training epoch 1423...\n",
      "\n",
      "Train Epoch: 1423 [0/8000 (0%)]\tBatch Loss: 1103.711147\tLearning Rate (w_theta): 0.001000\t TIME:1665.5s\n",
      "\t\t\t\tDisc: 1.516931\t\tSym: 20.284060\t\tSpars: 1081.910156\n",
      "\t TVw: -0.484295 | TVb: -2.043360 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1423 [4000/8000 (50%)]\tBatch Loss: 1100.647004\tLearning Rate (w_theta): 0.001000\t TIME:1667.0s\n",
      "\t\t\t\tDisc: 1.580466\t\tSym: 20.122934\t\tSpars: 1078.943604\n",
      "\t TVw: -0.484181 | TVb: -2.043361 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1423...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1094.5009417499\n",
      "Average validation loss: 174.415433421824\n",
      "Training epoch 1424...\n",
      "\n",
      "Train Epoch: 1424 [0/8000 (0%)]\tBatch Loss: 1071.508547\tLearning Rate (w_theta): 0.001000\t TIME:1669.3s\n",
      "\t\t\t\tDisc: 1.446919\t\tSym: 18.002546\t\tSpars: 1052.059082\n",
      "\t TVw: -0.484068 | TVb: -2.043362 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1424 [4000/8000 (50%)]\tBatch Loss: 1087.363547\tLearning Rate (w_theta): 0.001000\t TIME:1670.9s\n",
      "\t\t\t\tDisc: 1.413426\t\tSym: 19.512499\t\tSpars: 1066.437622\n",
      "\t TVw: -0.483954 | TVb: -2.043362 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1424...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1092.5667082035045\n",
      "Average validation loss: 173.79390552948448\n",
      "Training epoch 1425...\n",
      "\n",
      "Train Epoch: 1425 [0/8000 (0%)]\tBatch Loss: 1093.182903\tLearning Rate (w_theta): 0.001000\t TIME:1673.2s\n",
      "\t\t\t\tDisc: 1.414131\t\tSym: 19.199924\t\tSpars: 1072.568848\n",
      "\t TVw: -0.483841 | TVb: -2.043363 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1425 [4000/8000 (50%)]\tBatch Loss: 1098.316095\tLearning Rate (w_theta): 0.001000\t TIME:1674.7s\n",
      "\t\t\t\tDisc: 1.377209\t\tSym: 19.387861\t\tSpars: 1077.551025\n",
      "\t TVw: -0.483728 | TVb: -2.043364 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1425...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1098.494440788201\n",
      "Average validation loss: 175.19373655557808\n",
      "Training epoch 1426...\n",
      "\n",
      "Train Epoch: 1426 [0/8000 (0%)]\tBatch Loss: 1104.557702\tLearning Rate (w_theta): 0.001000\t TIME:1677.0s\n",
      "\t\t\t\tDisc: 1.394447\t\tSym: 19.914843\t\tSpars: 1083.248413\n",
      "\t TVw: -0.483614 | TVb: -2.043364 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1426 [4000/8000 (50%)]\tBatch Loss: 1096.280944\tLearning Rate (w_theta): 0.001000\t TIME:1678.6s\n",
      "\t\t\t\tDisc: 1.325463\t\tSym: 19.325720\t\tSpars: 1075.629761\n",
      "\t TVw: -0.483501 | TVb: -2.043365 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1426...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1100.370152742044\n",
      "Average validation loss: 176.52558915890734\n",
      "Training epoch 1427...\n",
      "\n",
      "Train Epoch: 1427 [0/8000 (0%)]\tBatch Loss: 1109.037112\tLearning Rate (w_theta): 0.001000\t TIME:1680.9s\n",
      "\t\t\t\tDisc: 1.365172\t\tSym: 20.518742\t\tSpars: 1087.153198\n",
      "\t TVw: -0.483386 | TVb: -2.043365 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1427 [4000/8000 (50%)]\tBatch Loss: 1053.587149\tLearning Rate (w_theta): 0.001000\t TIME:1682.5s\n",
      "\t\t\t\tDisc: 1.264057\t\tSym: 17.264132\t\tSpars: 1035.058960\n",
      "\t TVw: -0.483272 | TVb: -2.043366 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1427...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1104.3183215071938\n",
      "Average validation loss: 173.6667093867167\n",
      "Training epoch 1428...\n",
      "\n",
      "Train Epoch: 1428 [0/8000 (0%)]\tBatch Loss: 1140.885045\tLearning Rate (w_theta): 0.001000\t TIME:1685.0s\n",
      "\t\t\t\tDisc: 1.525230\t\tSym: 21.274122\t\tSpars: 1118.085693\n",
      "\t TVw: -0.483159 | TVb: -2.043366 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1428 [4000/8000 (50%)]\tBatch Loss: 1129.743233\tLearning Rate (w_theta): 0.001000\t TIME:1686.5s\n",
      "\t\t\t\tDisc: 1.693270\t\tSym: 20.996496\t\tSpars: 1107.053467\n",
      "\t TVw: -0.483045 | TVb: -2.043367 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1428...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1097.5249519415581\n",
      "Average validation loss: 172.61201164832127\n",
      "Training epoch 1429...\n",
      "\n",
      "Train Epoch: 1429 [0/8000 (0%)]\tBatch Loss: 1126.547238\tLearning Rate (w_theta): 0.001000\t TIME:1688.8s\n",
      "\t\t\t\tDisc: 1.543958\t\tSym: 20.048325\t\tSpars: 1104.954956\n",
      "\t TVw: -0.482930 | TVb: -2.043368 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1429 [4000/8000 (50%)]\tBatch Loss: 1122.285056\tLearning Rate (w_theta): 0.001000\t TIME:1690.3s\n",
      "\t\t\t\tDisc: 1.667758\t\tSym: 20.482777\t\tSpars: 1100.134521\n",
      "\t TVw: -0.482816 | TVb: -2.043368 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1429...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1102.4753604343234\n",
      "Average validation loss: 174.78883307782465\n",
      "Training epoch 1430...\n",
      "\n",
      "Train Epoch: 1430 [0/8000 (0%)]\tBatch Loss: 1084.773694\tLearning Rate (w_theta): 0.001000\t TIME:1692.6s\n",
      "\t\t\t\tDisc: 1.361821\t\tSym: 18.233650\t\tSpars: 1065.178223\n",
      "\t TVw: -0.482701 | TVb: -2.043369 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1430 [4000/8000 (50%)]\tBatch Loss: 1044.691902\tLearning Rate (w_theta): 0.001000\t TIME:1694.2s\n",
      "\t\t\t\tDisc: 1.203857\t\tSym: 16.744881\t\tSpars: 1026.743164\n",
      "\t TVw: -0.482584 | TVb: -2.043370 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1430...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1092.2295200129402\n",
      "Average validation loss: 175.74856708565179\n",
      "Training epoch 1431...\n",
      "\n",
      "Train Epoch: 1431 [0/8000 (0%)]\tBatch Loss: 1088.195602\tLearning Rate (w_theta): 0.001000\t TIME:1697.3s\n",
      "\t\t\t\tDisc: 1.312692\t\tSym: 19.448950\t\tSpars: 1067.433960\n",
      "\t TVw: -0.482464 | TVb: -2.043370 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1431 [4000/8000 (50%)]\tBatch Loss: 1069.036976\tLearning Rate (w_theta): 0.001000\t TIME:1698.8s\n",
      "\t\t\t\tDisc: 1.391129\t\tSym: 18.957737\t\tSpars: 1048.688110\n",
      "\t TVw: -0.482346 | TVb: -2.043370 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1431...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1091.5227821898338\n",
      "Average validation loss: 173.2249840352242\n",
      "Training epoch 1432...\n",
      "\n",
      "Train Epoch: 1432 [0/8000 (0%)]\tBatch Loss: 1044.238891\tLearning Rate (w_theta): 0.001000\t TIME:1701.1s\n",
      "\t\t\t\tDisc: 1.312226\t\tSym: 18.283476\t\tSpars: 1024.643188\n",
      "\t TVw: -0.482226 | TVb: -2.043370 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1432 [4000/8000 (50%)]\tBatch Loss: 1105.472298\tLearning Rate (w_theta): 0.001000\t TIME:1702.7s\n",
      "\t\t\t\tDisc: 1.534594\t\tSym: 20.237753\t\tSpars: 1083.699951\n",
      "\t TVw: -0.482107 | TVb: -2.043370 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1432...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1089.9192701692932\n",
      "Average validation loss: 172.15514337801076\n",
      "Training epoch 1433...\n",
      "\n",
      "Train Epoch: 1433 [0/8000 (0%)]\tBatch Loss: 1085.879850\tLearning Rate (w_theta): 0.001000\t TIME:1705.2s\n",
      "\t\t\t\tDisc: 1.417862\t\tSym: 19.295729\t\tSpars: 1065.166260\n",
      "\t TVw: -0.481987 | TVb: -2.043371 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1433 [4000/8000 (50%)]\tBatch Loss: 1088.630097\tLearning Rate (w_theta): 0.001000\t TIME:1706.7s\n",
      "\t\t\t\tDisc: 1.413751\t\tSym: 19.604897\t\tSpars: 1067.611450\n",
      "\t TVw: -0.481868 | TVb: -2.043371 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1433...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1090.5498962355834\n",
      "Average validation loss: 173.09990111530988\n",
      "Training epoch 1434...\n",
      "\n",
      "Train Epoch: 1434 [0/8000 (0%)]\tBatch Loss: 1121.861824\tLearning Rate (w_theta): 0.001000\t TIME:1709.0s\n",
      "\t\t\t\tDisc: 1.425341\t\tSym: 20.967489\t\tSpars: 1099.468994\n",
      "\t TVw: -0.481749 | TVb: -2.043372 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1434 [4000/8000 (50%)]\tBatch Loss: 1068.018157\tLearning Rate (w_theta): 0.001000\t TIME:1710.5s\n",
      "\t\t\t\tDisc: 1.349089\t\tSym: 19.094360\t\tSpars: 1047.574707\n",
      "\t TVw: -0.481632 | TVb: -2.043373 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1434...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1095.7553802505947\n",
      "Average validation loss: 172.7858344791268\n",
      "Training epoch 1435...\n",
      "\n",
      "Train Epoch: 1435 [0/8000 (0%)]\tBatch Loss: 1147.159822\tLearning Rate (w_theta): 0.001000\t TIME:1712.9s\n",
      "\t\t\t\tDisc: 1.623287\t\tSym: 22.128088\t\tSpars: 1123.408447\n",
      "\t TVw: -0.481515 | TVb: -2.043373 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1435 [4000/8000 (50%)]\tBatch Loss: 1100.440872\tLearning Rate (w_theta): 0.001000\t TIME:1714.4s\n",
      "\t\t\t\tDisc: 1.362417\t\tSym: 19.225550\t\tSpars: 1079.852905\n",
      "\t TVw: -0.481398 | TVb: -2.043374 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1435...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1090.3708171758335\n",
      "Average validation loss: 174.89859087345377\n",
      "Training epoch 1436...\n",
      "\n",
      "Train Epoch: 1436 [0/8000 (0%)]\tBatch Loss: 1104.009173\tLearning Rate (w_theta): 0.001000\t TIME:1716.7s\n",
      "\t\t\t\tDisc: 1.328118\t\tSym: 19.396265\t\tSpars: 1083.284790\n",
      "\t TVw: -0.481277 | TVb: -2.043375 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1436 [4000/8000 (50%)]\tBatch Loss: 1071.869795\tLearning Rate (w_theta): 0.001000\t TIME:1718.2s\n",
      "\t\t\t\tDisc: 1.363077\t\tSym: 18.657719\t\tSpars: 1051.848999\n",
      "\t TVw: -0.481155 | TVb: -2.043375 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1436...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1092.1099169457743\n",
      "Average validation loss: 173.05544573012497\n",
      "Training epoch 1437...\n",
      "\n",
      "Train Epoch: 1437 [0/8000 (0%)]\tBatch Loss: 1054.360600\tLearning Rate (w_theta): 0.001000\t TIME:1720.6s\n",
      "\t\t\t\tDisc: 1.159296\t\tSym: 17.224741\t\tSpars: 1035.976562\n",
      "\t TVw: -0.481034 | TVb: -2.043376 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1437 [4000/8000 (50%)]\tBatch Loss: 1113.506717\tLearning Rate (w_theta): 0.001000\t TIME:1722.1s\n",
      "\t\t\t\tDisc: 1.392683\t\tSym: 20.423849\t\tSpars: 1091.690186\n",
      "\t TVw: -0.480914 | TVb: -2.043376 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1437...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1088.930588856849\n",
      "Average validation loss: 171.55695821964017\n",
      "Training epoch 1438...\n",
      "\n",
      "Train Epoch: 1438 [0/8000 (0%)]\tBatch Loss: 1086.598832\tLearning Rate (w_theta): 0.001000\t TIME:1724.4s\n",
      "\t\t\t\tDisc: 1.455499\t\tSym: 20.587914\t\tSpars: 1064.555420\n",
      "\t TVw: -0.480794 | TVb: -2.043377 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1438 [4000/8000 (50%)]\tBatch Loss: 1082.789955\tLearning Rate (w_theta): 0.001000\t TIME:1725.9s\n",
      "\t\t\t\tDisc: 1.288075\t\tSym: 18.003956\t\tSpars: 1063.497925\n",
      "\t TVw: -0.480674 | TVb: -2.043378 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1438...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1089.6683344458859\n",
      "Average validation loss: 172.39702567155973\n",
      "Training epoch 1439...\n",
      "\n",
      "Train Epoch: 1439 [0/8000 (0%)]\tBatch Loss: 1074.340198\tLearning Rate (w_theta): 0.001000\t TIME:1728.3s\n",
      "\t\t\t\tDisc: 1.406116\t\tSym: 20.013062\t\tSpars: 1052.921021\n",
      "\t TVw: -0.480554 | TVb: -2.043378 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1439 [4000/8000 (50%)]\tBatch Loss: 1111.606811\tLearning Rate (w_theta): 0.001000\t TIME:1729.8s\n",
      "\t\t\t\tDisc: 1.528650\t\tSym: 20.667028\t\tSpars: 1089.411133\n",
      "\t TVw: -0.480431 | TVb: -2.043379 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1439...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1094.2599661554964\n",
      "Average validation loss: 172.52923554909998\n",
      "Training epoch 1440...\n",
      "\n",
      "Train Epoch: 1440 [0/8000 (0%)]\tBatch Loss: 1103.065418\tLearning Rate (w_theta): 0.001000\t TIME:1732.3s\n",
      "\t\t\t\tDisc: 1.447224\t\tSym: 19.534210\t\tSpars: 1082.083984\n",
      "\t TVw: -0.480311 | TVb: -2.043380 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1440 [4000/8000 (50%)]\tBatch Loss: 1064.569473\tLearning Rate (w_theta): 0.001000\t TIME:1733.8s\n",
      "\t\t\t\tDisc: 1.429697\t\tSym: 18.658453\t\tSpars: 1044.481323\n",
      "\t TVw: -0.480190 | TVb: -2.043380 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1440...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1089.6680310124646\n",
      "Average validation loss: 175.48949392082625\n",
      "Training epoch 1441...\n",
      "\n",
      "Train Epoch: 1441 [0/8000 (0%)]\tBatch Loss: 1077.991692\tLearning Rate (w_theta): 0.001000\t TIME:1736.7s\n",
      "\t\t\t\tDisc: 1.143386\t\tSym: 19.901041\t\tSpars: 1056.947266\n",
      "\t TVw: -0.480069 | TVb: -2.043381 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1441 [4000/8000 (50%)]\tBatch Loss: 1122.605392\tLearning Rate (w_theta): 0.001000\t TIME:1738.3s\n",
      "\t\t\t\tDisc: 1.406708\t\tSym: 19.811966\t\tSpars: 1101.386719\n",
      "\t TVw: -0.479948 | TVb: -2.043381 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1441...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1097.7883920985703\n",
      "Average validation loss: 172.93045945607588\n",
      "Training epoch 1442...\n",
      "\n",
      "Train Epoch: 1442 [0/8000 (0%)]\tBatch Loss: 1107.749579\tLearning Rate (w_theta): 0.001000\t TIME:1740.6s\n",
      "\t\t\t\tDisc: 1.456175\t\tSym: 20.017403\t\tSpars: 1086.276001\n",
      "\t TVw: -0.479828 | TVb: -2.043382 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1442 [4000/8000 (50%)]\tBatch Loss: 1090.407879\tLearning Rate (w_theta): 0.001000\t TIME:1742.1s\n",
      "\t\t\t\tDisc: 1.461634\t\tSym: 18.815508\t\tSpars: 1070.130737\n",
      "\t TVw: -0.479706 | TVb: -2.043382 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1442...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1092.1528772724946\n",
      "Average validation loss: 169.85750267762862\n",
      "Training epoch 1443...\n",
      "\n",
      "Train Epoch: 1443 [0/8000 (0%)]\tBatch Loss: 1126.054417\tLearning Rate (w_theta): 0.001000\t TIME:1744.5s\n",
      "\t\t\t\tDisc: 1.498447\t\tSym: 19.667175\t\tSpars: 1104.888794\n",
      "\t TVw: -0.479586 | TVb: -2.043383 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1443 [4000/8000 (50%)]\tBatch Loss: 1078.414121\tLearning Rate (w_theta): 0.001000\t TIME:1746.0s\n",
      "\t\t\t\tDisc: 1.511261\t\tSym: 19.413237\t\tSpars: 1057.489624\n",
      "\t TVw: -0.479468 | TVb: -2.043384 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1443...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1104.6090681195694\n",
      "Average validation loss: 168.96753345580524\n",
      "Training epoch 1444...\n",
      "\n",
      "Train Epoch: 1444 [0/8000 (0%)]\tBatch Loss: 1135.101336\tLearning Rate (w_theta): 0.001000\t TIME:1748.4s\n",
      "\t\t\t\tDisc: 1.488404\t\tSym: 19.945330\t\tSpars: 1113.667603\n",
      "\t TVw: -0.479350 | TVb: -2.043385 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1444 [4000/8000 (50%)]\tBatch Loss: 1111.021529\tLearning Rate (w_theta): 0.001000\t TIME:1749.9s\n",
      "\t\t\t\tDisc: 1.344933\t\tSym: 18.298788\t\tSpars: 1091.377808\n",
      "\t TVw: -0.479233 | TVb: -2.043386 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1444...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1106.6484173978574\n",
      "Average validation loss: 169.23450872668644\n",
      "Training epoch 1445...\n",
      "\n",
      "Train Epoch: 1445 [0/8000 (0%)]\tBatch Loss: 1078.410186\tLearning Rate (w_theta): 0.001000\t TIME:1752.4s\n",
      "\t\t\t\tDisc: 1.473153\t\tSym: 18.018454\t\tSpars: 1058.918579\n",
      "\t TVw: -0.479114 | TVb: -2.043387 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1445 [4000/8000 (50%)]\tBatch Loss: 1076.947314\tLearning Rate (w_theta): 0.001000\t TIME:1753.9s\n",
      "\t\t\t\tDisc: 1.206527\t\tSym: 17.717228\t\tSpars: 1058.023560\n",
      "\t TVw: -0.478993 | TVb: -2.043388 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1445...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1101.469383813674\n",
      "Average validation loss: 170.9219592948904\n",
      "Training epoch 1446...\n",
      "\n",
      "Train Epoch: 1446 [0/8000 (0%)]\tBatch Loss: 1158.171368\tLearning Rate (w_theta): 0.001000\t TIME:1756.2s\n",
      "\t\t\t\tDisc: 1.548970\t\tSym: 21.594810\t\tSpars: 1135.027588\n",
      "\t TVw: -0.478868 | TVb: -2.043388 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1446 [4000/8000 (50%)]\tBatch Loss: 1065.129742\tLearning Rate (w_theta): 0.001000\t TIME:1757.7s\n",
      "\t\t\t\tDisc: 1.332625\t\tSym: 17.770018\t\tSpars: 1046.027100\n",
      "\t TVw: -0.478741 | TVb: -2.043389 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1446...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1096.4030774618273\n",
      "Average validation loss: 170.9015522933344\n",
      "Training epoch 1447...\n",
      "\n",
      "Train Epoch: 1447 [0/8000 (0%)]\tBatch Loss: 1089.143233\tLearning Rate (w_theta): 0.001000\t TIME:1760.1s\n",
      "\t\t\t\tDisc: 1.525303\t\tSym: 19.557749\t\tSpars: 1068.060181\n",
      "\t TVw: -0.478613 | TVb: -2.043389 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1447 [4000/8000 (50%)]\tBatch Loss: 1097.926771\tLearning Rate (w_theta): 0.001000\t TIME:1761.6s\n",
      "\t\t\t\tDisc: 1.458450\t\tSym: 19.501524\t\tSpars: 1076.966797\n",
      "\t TVw: -0.478487 | TVb: -2.043390 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1447...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1092.2980390278105\n",
      "Average validation loss: 172.28914091977043\n",
      "Training epoch 1448...\n",
      "\n",
      "Train Epoch: 1448 [0/8000 (0%)]\tBatch Loss: 1064.800439\tLearning Rate (w_theta): 0.001000\t TIME:1764.0s\n",
      "\t\t\t\tDisc: 1.271030\t\tSym: 17.285269\t\tSpars: 1046.244141\n",
      "\t TVw: -0.478362 | TVb: -2.043390 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1448 [4000/8000 (50%)]\tBatch Loss: 1114.354501\tLearning Rate (w_theta): 0.001000\t TIME:1765.5s\n",
      "\t\t\t\tDisc: 1.431468\t\tSym: 19.600523\t\tSpars: 1093.322510\n",
      "\t TVw: -0.478237 | TVb: -2.043391 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1448...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1092.8792637693637\n",
      "Average validation loss: 171.91345738489423\n",
      "Training epoch 1449...\n",
      "\n",
      "Train Epoch: 1449 [0/8000 (0%)]\tBatch Loss: 1087.346183\tLearning Rate (w_theta): 0.001000\t TIME:1767.8s\n",
      "\t\t\t\tDisc: 1.423033\t\tSym: 19.229057\t\tSpars: 1066.694092\n",
      "\t TVw: -0.478114 | TVb: -2.043391 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1449 [4000/8000 (50%)]\tBatch Loss: 1034.233949\tLearning Rate (w_theta): 0.001000\t TIME:1769.3s\n",
      "\t\t\t\tDisc: 1.182666\t\tSym: 17.220594\t\tSpars: 1015.830688\n",
      "\t TVw: -0.477989 | TVb: -2.043392 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1449...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1088.9470659691397\n",
      "Average validation loss: 172.88848665171437\n",
      "Training epoch 1450...\n",
      "\n",
      "Train Epoch: 1450 [0/8000 (0%)]\tBatch Loss: 1075.345440\tLearning Rate (w_theta): 0.001000\t TIME:1771.7s\n",
      "\t\t\t\tDisc: 1.270658\t\tSym: 18.171217\t\tSpars: 1055.903564\n",
      "\t TVw: -0.477862 | TVb: -2.043392 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1450 [4000/8000 (50%)]\tBatch Loss: 1098.738752\tLearning Rate (w_theta): 0.001000\t TIME:1773.2s\n",
      "\t\t\t\tDisc: 1.352573\t\tSym: 20.398386\t\tSpars: 1076.987793\n",
      "\t TVw: -0.477733 | TVb: -2.043392 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1450...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1084.3639495195666\n",
      "Average validation loss: 173.0040020429881\n",
      "Training epoch 1451...\n",
      "\n",
      "Train Epoch: 1451 [0/8000 (0%)]\tBatch Loss: 1110.100265\tLearning Rate (w_theta): 0.001000\t TIME:1776.4s\n",
      "\t\t\t\tDisc: 1.461941\t\tSym: 20.496845\t\tSpars: 1088.141479\n",
      "\t TVw: -0.477605 | TVb: -2.043393 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1451 [4000/8000 (50%)]\tBatch Loss: 1117.463058\tLearning Rate (w_theta): 0.001000\t TIME:1777.9s\n",
      "\t\t\t\tDisc: 1.445624\t\tSym: 20.556740\t\tSpars: 1095.460693\n",
      "\t TVw: -0.477477 | TVb: -2.043393 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1451...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1084.9113920583607\n",
      "Average validation loss: 169.67483122870155\n",
      "Training epoch 1452...\n",
      "\n",
      "Train Epoch: 1452 [0/8000 (0%)]\tBatch Loss: 1062.234323\tLearning Rate (w_theta): 0.001000\t TIME:1780.2s\n",
      "\t\t\t\tDisc: 1.422556\t\tSym: 18.121826\t\tSpars: 1042.689941\n",
      "\t TVw: -0.477349 | TVb: -2.043394 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1452 [4000/8000 (50%)]\tBatch Loss: 1084.068476\tLearning Rate (w_theta): 0.001000\t TIME:1781.8s\n",
      "\t\t\t\tDisc: 1.346642\t\tSym: 18.003084\t\tSpars: 1064.718750\n",
      "\t TVw: -0.477224 | TVb: -2.043394 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1452...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1093.8214805011967\n",
      "Average validation loss: 169.02974218895932\n",
      "Training epoch 1453...\n",
      "\n",
      "Train Epoch: 1453 [0/8000 (0%)]\tBatch Loss: 1153.519364\tLearning Rate (w_theta): 0.001000\t TIME:1784.1s\n",
      "\t\t\t\tDisc: 1.766611\t\tSym: 22.406805\t\tSpars: 1129.345947\n",
      "\t TVw: -0.477102 | TVb: -2.043395 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1453 [4000/8000 (50%)]\tBatch Loss: 1040.987367\tLearning Rate (w_theta): 0.001000\t TIME:1785.6s\n",
      "\t\t\t\tDisc: 1.267812\t\tSym: 17.087048\t\tSpars: 1022.632507\n",
      "\t TVw: -0.476976 | TVb: -2.043396 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1453...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1090.9560174067747\n",
      "Average validation loss: 169.70417091640948\n",
      "Training epoch 1454...\n",
      "\n",
      "Train Epoch: 1454 [0/8000 (0%)]\tBatch Loss: 1102.706249\tLearning Rate (w_theta): 0.001000\t TIME:1787.9s\n",
      "\t\t\t\tDisc: 1.433235\t\tSym: 19.356632\t\tSpars: 1081.916382\n",
      "\t TVw: -0.476849 | TVb: -2.043396 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "\n",
      "Train Epoch: 1454 [4000/8000 (50%)]\tBatch Loss: 1126.674627\tLearning Rate (w_theta): 0.001000\t TIME:1789.4s\n",
      "\t\t\t\tDisc: 1.517189\t\tSym: 21.984221\t\tSpars: 1103.173218\n",
      "\t TVw: -0.476722 | TVb: -2.043397 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034764\n",
      "Validating epoch 1454...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1085.168424335941\n",
      "Average validation loss: 170.06297471817098\n",
      "Training epoch 1455...\n",
      "\n",
      "Train Epoch: 1455 [0/8000 (0%)]\tBatch Loss: 1102.249804\tLearning Rate (w_theta): 0.001000\t TIME:1791.8s\n",
      "\t\t\t\tDisc: 1.347994\t\tSym: 21.158279\t\tSpars: 1079.743530\n",
      "\t TVw: -0.476592 | TVb: -2.043398 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1455 [4000/8000 (50%)]\tBatch Loss: 1041.437703\tLearning Rate (w_theta): 0.001000\t TIME:1793.3s\n",
      "\t\t\t\tDisc: 1.280883\t\tSym: 16.992331\t\tSpars: 1023.164490\n",
      "\t TVw: -0.476459 | TVb: -2.043398 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1455...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1082.9696299320028\n",
      "Average validation loss: 171.34308195091802\n",
      "Training epoch 1456...\n",
      "\n",
      "Train Epoch: 1456 [0/8000 (0%)]\tBatch Loss: 1050.752156\tLearning Rate (w_theta): 0.001000\t TIME:1795.6s\n",
      "\t\t\t\tDisc: 1.273374\t\tSym: 16.982689\t\tSpars: 1032.496094\n",
      "\t TVw: -0.476329 | TVb: -2.043398 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1456 [4000/8000 (50%)]\tBatch Loss: 1022.943183\tLearning Rate (w_theta): 0.001000\t TIME:1797.2s\n",
      "\t\t\t\tDisc: 1.171747\t\tSym: 16.239759\t\tSpars: 1005.531677\n",
      "\t TVw: -0.476198 | TVb: -2.043399 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1456...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1081.211908152027\n",
      "Average validation loss: 171.72595858909295\n",
      "Training epoch 1457...\n",
      "\n",
      "Train Epoch: 1457 [0/8000 (0%)]\tBatch Loss: 1066.048806\tLearning Rate (w_theta): 0.001000\t TIME:1799.6s\n",
      "\t\t\t\tDisc: 1.292042\t\tSym: 18.511646\t\tSpars: 1046.245117\n",
      "\t TVw: -0.476067 | TVb: -2.043399 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1457 [4000/8000 (50%)]\tBatch Loss: 1087.801434\tLearning Rate (w_theta): 0.001000\t TIME:1801.1s\n",
      "\t\t\t\tDisc: 1.430069\t\tSym: 19.184475\t\tSpars: 1067.186890\n",
      "\t TVw: -0.475937 | TVb: -2.043400 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1457...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1082.7366370355985\n",
      "Average validation loss: 170.1574450458956\n",
      "Training epoch 1458...\n",
      "\n",
      "Train Epoch: 1458 [0/8000 (0%)]\tBatch Loss: 1048.753645\tLearning Rate (w_theta): 0.001000\t TIME:1803.4s\n",
      "\t\t\t\tDisc: 1.451611\t\tSym: 17.769075\t\tSpars: 1029.532959\n",
      "\t TVw: -0.475810 | TVb: -2.043400 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1458 [4000/8000 (50%)]\tBatch Loss: 1133.130792\tLearning Rate (w_theta): 0.001000\t TIME:1805.0s\n",
      "\t\t\t\tDisc: 1.591838\t\tSym: 23.241835\t\tSpars: 1108.297119\n",
      "\t TVw: -0.475685 | TVb: -2.043401 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1458...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1087.1128431335524\n",
      "Average validation loss: 172.85328324027248\n",
      "Training epoch 1459...\n",
      "\n",
      "Train Epoch: 1459 [0/8000 (0%)]\tBatch Loss: 1061.476370\tLearning Rate (w_theta): 0.001000\t TIME:1807.3s\n",
      "\t\t\t\tDisc: 1.248044\t\tSym: 18.852106\t\tSpars: 1041.376221\n",
      "\t TVw: -0.475557 | TVb: -2.043402 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1459 [4000/8000 (50%)]\tBatch Loss: 1083.162847\tLearning Rate (w_theta): 0.001000\t TIME:1808.8s\n",
      "\t\t\t\tDisc: 1.351698\t\tSym: 18.254143\t\tSpars: 1063.557007\n",
      "\t TVw: -0.475429 | TVb: -2.043403 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1459...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1086.236927730364\n",
      "Average validation loss: 170.4251673577104\n",
      "Training epoch 1460...\n",
      "\n",
      "Train Epoch: 1460 [0/8000 (0%)]\tBatch Loss: 1077.134727\tLearning Rate (w_theta): 0.001000\t TIME:1811.1s\n",
      "\t\t\t\tDisc: 1.363017\t\tSym: 17.469952\t\tSpars: 1058.301758\n",
      "\t TVw: -0.475298 | TVb: -2.043403 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1460 [4000/8000 (50%)]\tBatch Loss: 1078.540962\tLearning Rate (w_theta): 0.001000\t TIME:1812.7s\n",
      "\t\t\t\tDisc: 1.400220\t\tSym: 18.851557\t\tSpars: 1058.289185\n",
      "\t TVw: -0.475167 | TVb: -2.043404 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1460...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1086.2677166123074\n",
      "Average validation loss: 170.88919512136374\n",
      "Training epoch 1461...\n",
      "\n",
      "Train Epoch: 1461 [0/8000 (0%)]\tBatch Loss: 1126.142150\tLearning Rate (w_theta): 0.001000\t TIME:1815.6s\n",
      "\t\t\t\tDisc: 1.513519\t\tSym: 21.958832\t\tSpars: 1102.669800\n",
      "\t TVw: -0.475034 | TVb: -2.043405 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1461 [4000/8000 (50%)]\tBatch Loss: 1099.509509\tLearning Rate (w_theta): 0.001000\t TIME:1817.2s\n",
      "\t\t\t\tDisc: 1.398070\t\tSym: 20.957630\t\tSpars: 1077.153809\n",
      "\t TVw: -0.474899 | TVb: -2.043405 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1461...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1079.8019906409158\n",
      "Average validation loss: 170.80718191935543\n",
      "Training epoch 1462...\n",
      "\n",
      "Train Epoch: 1462 [0/8000 (0%)]\tBatch Loss: 1137.377955\tLearning Rate (w_theta): 0.001000\t TIME:1819.5s\n",
      "\t\t\t\tDisc: 1.492848\t\tSym: 21.541113\t\tSpars: 1114.343994\n",
      "\t TVw: -0.474764 | TVb: -2.043406 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1462 [4000/8000 (50%)]\tBatch Loss: 1064.203938\tLearning Rate (w_theta): 0.001000\t TIME:1821.0s\n",
      "\t\t\t\tDisc: 1.305373\t\tSym: 18.699835\t\tSpars: 1044.198730\n",
      "\t TVw: -0.474629 | TVb: -2.043406 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1462...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1082.1356596205346\n",
      "Average validation loss: 170.429762064186\n",
      "Training epoch 1463...\n",
      "\n",
      "Train Epoch: 1463 [0/8000 (0%)]\tBatch Loss: 1087.624184\tLearning Rate (w_theta): 0.001000\t TIME:1823.5s\n",
      "\t\t\t\tDisc: 1.394221\t\tSym: 19.406965\t\tSpars: 1066.822998\n",
      "\t TVw: -0.474496 | TVb: -2.043407 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1463 [4000/8000 (50%)]\tBatch Loss: 1097.456537\tLearning Rate (w_theta): 0.001000\t TIME:1825.0s\n",
      "\t\t\t\tDisc: 1.431186\t\tSym: 19.493734\t\tSpars: 1076.531616\n",
      "\t TVw: -0.474363 | TVb: -2.043407 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1463...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1082.983974289666\n",
      "Average validation loss: 170.14270437341108\n",
      "Training epoch 1464...\n",
      "\n",
      "Train Epoch: 1464 [0/8000 (0%)]\tBatch Loss: 1055.131084\tLearning Rate (w_theta): 0.001000\t TIME:1827.3s\n",
      "\t\t\t\tDisc: 1.397676\t\tSym: 17.793955\t\tSpars: 1035.939453\n",
      "\t TVw: -0.474234 | TVb: -2.043408 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1464 [4000/8000 (50%)]\tBatch Loss: 1056.726061\tLearning Rate (w_theta): 0.001000\t TIME:1828.8s\n",
      "\t\t\t\tDisc: 1.302353\t\tSym: 18.647097\t\tSpars: 1036.776611\n",
      "\t TVw: -0.474102 | TVb: -2.043409 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1464...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1080.0404803808328\n",
      "Average validation loss: 172.26336871333356\n",
      "Training epoch 1465...\n",
      "\n",
      "Train Epoch: 1465 [0/8000 (0%)]\tBatch Loss: 1131.234482\tLearning Rate (w_theta): 0.001000\t TIME:1831.1s\n",
      "\t\t\t\tDisc: 1.412798\t\tSym: 21.718290\t\tSpars: 1108.103394\n",
      "\t TVw: -0.473969 | TVb: -2.043409 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1465 [4000/8000 (50%)]\tBatch Loss: 1046.626262\tLearning Rate (w_theta): 0.001000\t TIME:1832.7s\n",
      "\t\t\t\tDisc: 1.283777\t\tSym: 18.615313\t\tSpars: 1026.727173\n",
      "\t TVw: -0.473836 | TVb: -2.043410 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1465...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1089.5181023132218\n",
      "Average validation loss: 169.9456615479157\n",
      "Training epoch 1466...\n",
      "\n",
      "Train Epoch: 1466 [0/8000 (0%)]\tBatch Loss: 1104.174213\tLearning Rate (w_theta): 0.001000\t TIME:1835.0s\n",
      "\t\t\t\tDisc: 1.423118\t\tSym: 19.167110\t\tSpars: 1083.583984\n",
      "\t TVw: -0.473702 | TVb: -2.043411 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1466 [4000/8000 (50%)]\tBatch Loss: 1079.379817\tLearning Rate (w_theta): 0.001000\t TIME:1836.5s\n",
      "\t\t\t\tDisc: 1.373550\t\tSym: 18.045330\t\tSpars: 1059.960938\n",
      "\t TVw: -0.473569 | TVb: -2.043412 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1466...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1091.6027000970234\n",
      "Average validation loss: 168.65848297848814\n",
      "Training epoch 1467...\n",
      "\n",
      "Train Epoch: 1467 [0/8000 (0%)]\tBatch Loss: 1053.452610\tLearning Rate (w_theta): 0.001000\t TIME:1838.9s\n",
      "\t\t\t\tDisc: 1.330410\t\tSym: 17.195442\t\tSpars: 1034.926758\n",
      "\t TVw: -0.473437 | TVb: -2.043412 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1467 [4000/8000 (50%)]\tBatch Loss: 1122.177070\tLearning Rate (w_theta): 0.001000\t TIME:1840.4s\n",
      "\t\t\t\tDisc: 1.561187\t\tSym: 20.266884\t\tSpars: 1100.348999\n",
      "\t TVw: -0.473303 | TVb: -2.043413 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1467...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1094.2690084935032\n",
      "Average validation loss: 168.01711373441202\n",
      "Training epoch 1468...\n",
      "\n",
      "Train Epoch: 1468 [0/8000 (0%)]\tBatch Loss: 1092.551782\tLearning Rate (w_theta): 0.001000\t TIME:1842.7s\n",
      "\t\t\t\tDisc: 1.451321\t\tSym: 19.043699\t\tSpars: 1072.056763\n",
      "\t TVw: -0.473169 | TVb: -2.043413 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1468 [4000/8000 (50%)]\tBatch Loss: 1160.694334\tLearning Rate (w_theta): 0.001000\t TIME:1844.2s\n",
      "\t\t\t\tDisc: 1.526794\t\tSym: 20.738707\t\tSpars: 1138.428833\n",
      "\t TVw: -0.473036 | TVb: -2.043414 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1468...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1101.9365412914544\n",
      "Average validation loss: 166.85325770514922\n",
      "Training epoch 1469...\n",
      "\n",
      "Train Epoch: 1469 [0/8000 (0%)]\tBatch Loss: 1106.899386\tLearning Rate (w_theta): 0.001000\t TIME:1846.5s\n",
      "\t\t\t\tDisc: 1.271021\t\tSym: 18.816231\t\tSpars: 1086.812134\n",
      "\t TVw: -0.472906 | TVb: -2.043415 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1469 [4000/8000 (50%)]\tBatch Loss: 1102.844338\tLearning Rate (w_theta): 0.001000\t TIME:1848.1s\n",
      "\t\t\t\tDisc: 1.405450\t\tSym: 19.009445\t\tSpars: 1082.429443\n",
      "\t TVw: -0.472775 | TVb: -2.043416 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1469...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1107.3809391621346\n",
      "Average validation loss: 168.02869678040844\n",
      "Training epoch 1470...\n",
      "\n",
      "Train Epoch: 1470 [0/8000 (0%)]\tBatch Loss: 1136.089045\tLearning Rate (w_theta): 0.001000\t TIME:1850.5s\n",
      "\t\t\t\tDisc: 1.448370\t\tSym: 20.178150\t\tSpars: 1114.462524\n",
      "\t TVw: -0.472645 | TVb: -2.043417 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1470 [4000/8000 (50%)]\tBatch Loss: 1083.760059\tLearning Rate (w_theta): 0.001000\t TIME:1852.1s\n",
      "\t\t\t\tDisc: 1.420064\t\tSym: 19.627348\t\tSpars: 1062.712646\n",
      "\t TVw: -0.472518 | TVb: -2.043418 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1470...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1109.3730526890909\n",
      "Average validation loss: 175.18511162304472\n",
      "Training epoch 1471...\n",
      "\n",
      "Train Epoch: 1471 [0/8000 (0%)]\tBatch Loss: 1104.080694\tLearning Rate (w_theta): 0.001000\t TIME:1855.0s\n",
      "\t\t\t\tDisc: 1.089777\t\tSym: 18.904491\t\tSpars: 1084.086426\n",
      "\t TVw: -0.472388 | TVb: -2.043419 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1471 [4000/8000 (50%)]\tBatch Loss: 1132.317331\tLearning Rate (w_theta): 0.001000\t TIME:1856.6s\n",
      "\t\t\t\tDisc: 1.532298\t\tSym: 21.658445\t\tSpars: 1109.126587\n",
      "\t TVw: -0.472252 | TVb: -2.043420 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1471...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1089.9438255973726\n",
      "Average validation loss: 171.2790595836836\n",
      "Training epoch 1472...\n",
      "\n",
      "Train Epoch: 1472 [0/8000 (0%)]\tBatch Loss: 1104.272517\tLearning Rate (w_theta): 0.001000\t TIME:1858.9s\n",
      "\t\t\t\tDisc: 1.338433\t\tSym: 19.845705\t\tSpars: 1083.088379\n",
      "\t TVw: -0.472107 | TVb: -2.043420 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1472 [4000/8000 (50%)]\tBatch Loss: 1057.045745\tLearning Rate (w_theta): 0.001000\t TIME:1860.4s\n",
      "\t\t\t\tDisc: 1.271432\t\tSym: 19.031271\t\tSpars: 1036.743042\n",
      "\t TVw: -0.471959 | TVb: -2.043420 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1472...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1079.4978406779833\n",
      "Average validation loss: 170.45051832165245\n",
      "Training epoch 1473...\n",
      "\n",
      "Train Epoch: 1473 [0/8000 (0%)]\tBatch Loss: 1110.615820\tLearning Rate (w_theta): 0.001000\t TIME:1862.7s\n",
      "\t\t\t\tDisc: 1.375447\t\tSym: 21.553972\t\tSpars: 1087.686401\n",
      "\t TVw: -0.471810 | TVb: -2.043420 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1473 [4000/8000 (50%)]\tBatch Loss: 1110.019986\tLearning Rate (w_theta): 0.001000\t TIME:1864.3s\n",
      "\t\t\t\tDisc: 1.376332\t\tSym: 19.732643\t\tSpars: 1088.911011\n",
      "\t TVw: -0.471663 | TVb: -2.043419 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1473...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1078.7753116847148\n",
      "Average validation loss: 169.99138311835\n",
      "Training epoch 1474...\n",
      "\n",
      "Train Epoch: 1474 [0/8000 (0%)]\tBatch Loss: 1116.984134\tLearning Rate (w_theta): 0.001000\t TIME:1866.6s\n",
      "\t\t\t\tDisc: 1.497415\t\tSym: 20.705713\t\tSpars: 1094.781006\n",
      "\t TVw: -0.471518 | TVb: -2.043419 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1474 [4000/8000 (50%)]\tBatch Loss: 1069.293978\tLearning Rate (w_theta): 0.001000\t TIME:1868.1s\n",
      "\t\t\t\tDisc: 1.296232\t\tSym: 18.642399\t\tSpars: 1049.355347\n",
      "\t TVw: -0.471374 | TVb: -2.043419 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1474...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1075.3086134011335\n",
      "Average validation loss: 169.24686925351702\n",
      "Training epoch 1475...\n",
      "\n",
      "Train Epoch: 1475 [0/8000 (0%)]\tBatch Loss: 1048.522409\tLearning Rate (w_theta): 0.001000\t TIME:1870.6s\n",
      "\t\t\t\tDisc: 1.249431\t\tSym: 18.220732\t\tSpars: 1029.052246\n",
      "\t TVw: -0.471232 | TVb: -2.043420 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1475 [4000/8000 (50%)]\tBatch Loss: 1049.190000\tLearning Rate (w_theta): 0.001000\t TIME:1872.1s\n",
      "\t\t\t\tDisc: 1.267326\t\tSym: 18.526190\t\tSpars: 1029.396484\n",
      "\t TVw: -0.471091 | TVb: -2.043420 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1475...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1074.608142097287\n",
      "Average validation loss: 168.61968358769644\n",
      "Training epoch 1476...\n",
      "\n",
      "Train Epoch: 1476 [0/8000 (0%)]\tBatch Loss: 1125.306639\tLearning Rate (w_theta): 0.001000\t TIME:1874.5s\n",
      "\t\t\t\tDisc: 1.427537\t\tSym: 21.542433\t\tSpars: 1102.336670\n",
      "\t TVw: -0.470948 | TVb: -2.043421 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1476 [4000/8000 (50%)]\tBatch Loss: 1059.135749\tLearning Rate (w_theta): 0.001000\t TIME:1876.0s\n",
      "\t\t\t\tDisc: 1.293565\t\tSym: 18.159079\t\tSpars: 1039.683105\n",
      "\t TVw: -0.470807 | TVb: -2.043422 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1476...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1074.1693547228865\n",
      "Average validation loss: 168.90339122754838\n",
      "Training epoch 1477...\n",
      "\n",
      "Train Epoch: 1477 [0/8000 (0%)]\tBatch Loss: 1088.900718\tLearning Rate (w_theta): 0.001000\t TIME:1878.4s\n",
      "\t\t\t\tDisc: 1.403644\t\tSym: 19.284794\t\tSpars: 1068.212280\n",
      "\t TVw: -0.470667 | TVb: -2.043423 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1477 [4000/8000 (50%)]\tBatch Loss: 1072.455560\tLearning Rate (w_theta): 0.001000\t TIME:1879.9s\n",
      "\t\t\t\tDisc: 1.453399\t\tSym: 19.749475\t\tSpars: 1051.252686\n",
      "\t TVw: -0.470528 | TVb: -2.043424 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1477...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1078.6298781071757\n",
      "Average validation loss: 169.25804904246593\n",
      "Training epoch 1478...\n",
      "\n",
      "Train Epoch: 1478 [0/8000 (0%)]\tBatch Loss: 1107.162984\tLearning Rate (w_theta): 0.001000\t TIME:1882.2s\n",
      "\t\t\t\tDisc: 1.512269\t\tSym: 21.674641\t\tSpars: 1083.976074\n",
      "\t TVw: -0.470391 | TVb: -2.043425 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1478 [4000/8000 (50%)]\tBatch Loss: 1024.285060\tLearning Rate (w_theta): 0.001000\t TIME:1883.8s\n",
      "\t\t\t\tDisc: 1.228993\t\tSym: 17.201391\t\tSpars: 1005.854675\n",
      "\t TVw: -0.470251 | TVb: -2.043426 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1478...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1072.9231017003838\n",
      "Average validation loss: 168.8211108020575\n",
      "Training epoch 1479...\n",
      "\n",
      "Train Epoch: 1479 [0/8000 (0%)]\tBatch Loss: 1091.807106\tLearning Rate (w_theta): 0.001000\t TIME:1886.1s\n",
      "\t\t\t\tDisc: 1.378473\t\tSym: 20.105024\t\tSpars: 1070.323608\n",
      "\t TVw: -0.470110 | TVb: -2.043427 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1479 [4000/8000 (50%)]\tBatch Loss: 1099.551774\tLearning Rate (w_theta): 0.001000\t TIME:1887.6s\n",
      "\t\t\t\tDisc: 1.483781\t\tSym: 19.427734\t\tSpars: 1078.640259\n",
      "\t TVw: -0.469968 | TVb: -2.043427 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1479...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1075.5934103768768\n",
      "Average validation loss: 169.65832911148505\n",
      "Training epoch 1480...\n",
      "\n",
      "Train Epoch: 1480 [0/8000 (0%)]\tBatch Loss: 1064.470660\tLearning Rate (w_theta): 0.001000\t TIME:1889.9s\n",
      "\t\t\t\tDisc: 1.377957\t\tSym: 18.951101\t\tSpars: 1044.141602\n",
      "\t TVw: -0.469826 | TVb: -2.043428 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1480 [4000/8000 (50%)]\tBatch Loss: 1043.113513\tLearning Rate (w_theta): 0.001000\t TIME:1891.5s\n",
      "\t\t\t\tDisc: 1.178462\t\tSym: 17.196037\t\tSpars: 1024.739014\n",
      "\t TVw: -0.469684 | TVb: -2.043429 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1480...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1072.7364120220768\n",
      "Average validation loss: 169.4956686348392\n",
      "Training epoch 1481...\n",
      "\n",
      "Train Epoch: 1481 [0/8000 (0%)]\tBatch Loss: 1075.409148\tLearning Rate (w_theta): 0.001000\t TIME:1894.6s\n",
      "\t\t\t\tDisc: 1.374655\t\tSym: 18.978706\t\tSpars: 1055.055786\n",
      "\t TVw: -0.469541 | TVb: -2.043429 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1481 [4000/8000 (50%)]\tBatch Loss: 1111.240913\tLearning Rate (w_theta): 0.001000\t TIME:1896.1s\n",
      "\t\t\t\tDisc: 1.639129\t\tSym: 20.439674\t\tSpars: 1089.162109\n",
      "\t TVw: -0.469397 | TVb: -2.043430 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1481...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1080.0380096398649\n",
      "Average validation loss: 167.56264976849928\n",
      "Training epoch 1482...\n",
      "\n",
      "Train Epoch: 1482 [0/8000 (0%)]\tBatch Loss: 1119.164820\tLearning Rate (w_theta): 0.001000\t TIME:1898.4s\n",
      "\t\t\t\tDisc: 1.570391\t\tSym: 21.213570\t\tSpars: 1096.380859\n",
      "\t TVw: -0.469258 | TVb: -2.043431 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1482 [4000/8000 (50%)]\tBatch Loss: 1049.751884\tLearning Rate (w_theta): 0.001000\t TIME:1900.0s\n",
      "\t\t\t\tDisc: 1.357318\t\tSym: 18.284336\t\tSpars: 1030.110229\n",
      "\t TVw: -0.469117 | TVb: -2.043432 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1482...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1080.2800862690033\n",
      "Average validation loss: 169.82557884998573\n",
      "Training epoch 1483...\n",
      "\n",
      "Train Epoch: 1483 [0/8000 (0%)]\tBatch Loss: 1080.063387\tLearning Rate (w_theta): 0.001000\t TIME:1902.3s\n",
      "\t\t\t\tDisc: 1.337483\t\tSym: 19.076002\t\tSpars: 1059.649902\n",
      "\t TVw: -0.468976 | TVb: -2.043432 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1483 [4000/8000 (50%)]\tBatch Loss: 1096.582054\tLearning Rate (w_theta): 0.001000\t TIME:1903.8s\n",
      "\t\t\t\tDisc: 1.371067\t\tSym: 20.254810\t\tSpars: 1074.956177\n",
      "\t TVw: -0.468836 | TVb: -2.043433 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1483...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1078.814097728372\n",
      "Average validation loss: 170.4951890765822\n",
      "Training epoch 1484...\n",
      "\n",
      "Train Epoch: 1484 [0/8000 (0%)]\tBatch Loss: 1043.103646\tLearning Rate (w_theta): 0.001000\t TIME:1906.2s\n",
      "\t\t\t\tDisc: 1.198046\t\tSym: 16.991537\t\tSpars: 1024.914062\n",
      "\t TVw: -0.468692 | TVb: -2.043434 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1484 [4000/8000 (50%)]\tBatch Loss: 1134.350302\tLearning Rate (w_theta): 0.001000\t TIME:1907.7s\n",
      "\t\t\t\tDisc: 1.432030\t\tSym: 22.252256\t\tSpars: 1110.666016\n",
      "\t TVw: -0.468548 | TVb: -2.043434 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1484...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1087.897229465002\n",
      "Average validation loss: 167.52399785630348\n",
      "Training epoch 1485...\n",
      "\n",
      "Train Epoch: 1485 [0/8000 (0%)]\tBatch Loss: 1057.987324\tLearning Rate (w_theta): 0.001000\t TIME:1910.1s\n",
      "\t\t\t\tDisc: 1.402612\t\tSym: 17.516720\t\tSpars: 1039.067993\n",
      "\t TVw: -0.468406 | TVb: -2.043435 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1485 [4000/8000 (50%)]\tBatch Loss: 1091.429596\tLearning Rate (w_theta): 0.001000\t TIME:1911.6s\n",
      "\t\t\t\tDisc: 1.462094\t\tSym: 19.762424\t\tSpars: 1070.205078\n",
      "\t TVw: -0.468264 | TVb: -2.043436 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1485...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1086.4809087460028\n",
      "Average validation loss: 168.12720659161687\n",
      "Training epoch 1486...\n",
      "\n",
      "Train Epoch: 1486 [0/8000 (0%)]\tBatch Loss: 1030.138971\tLearning Rate (w_theta): 0.001000\t TIME:1913.9s\n",
      "\t\t\t\tDisc: 1.147783\t\tSym: 16.585915\t\tSpars: 1012.405273\n",
      "\t TVw: -0.468120 | TVb: -2.043436 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1486 [4000/8000 (50%)]\tBatch Loss: 1064.128717\tLearning Rate (w_theta): 0.001000\t TIME:1915.5s\n",
      "\t\t\t\tDisc: 1.236772\t\tSym: 17.679787\t\tSpars: 1045.212158\n",
      "\t TVw: -0.467971 | TVb: -2.043437 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1486...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1077.3227213469306\n",
      "Average validation loss: 168.66988719566857\n",
      "Training epoch 1487...\n",
      "\n",
      "Train Epoch: 1487 [0/8000 (0%)]\tBatch Loss: 1061.525538\tLearning Rate (w_theta): 0.001000\t TIME:1917.9s\n",
      "\t\t\t\tDisc: 1.351695\t\tSym: 18.148453\t\tSpars: 1042.025391\n",
      "\t TVw: -0.467820 | TVb: -2.043437 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1487 [4000/8000 (50%)]\tBatch Loss: 1090.828279\tLearning Rate (w_theta): 0.001000\t TIME:1919.5s\n",
      "\t\t\t\tDisc: 1.379410\t\tSym: 19.797014\t\tSpars: 1069.651855\n",
      "\t TVw: -0.467666 | TVb: -2.043437 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "Validating epoch 1487...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1076.3305718157853\n",
      "Average validation loss: 167.09423340377947\n",
      "Training epoch 1488...\n",
      "\n",
      "Train Epoch: 1488 [0/8000 (0%)]\tBatch Loss: 1059.373054\tLearning Rate (w_theta): 0.001000\t TIME:1921.8s\n",
      "\t\t\t\tDisc: 1.241677\t\tSym: 17.276396\t\tSpars: 1040.854980\n",
      "\t TVw: -0.467513 | TVb: -2.043437 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034765\n",
      "\n",
      "Train Epoch: 1488 [4000/8000 (50%)]\tBatch Loss: 1080.333806\tLearning Rate (w_theta): 0.001000\t TIME:1923.4s\n",
      "\t\t\t\tDisc: 1.401235\t\tSym: 18.636673\t\tSpars: 1060.295898\n",
      "\t TVw: -0.467363 | TVb: -2.043438 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1488...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1075.2666586251116\n",
      "Average validation loss: 166.5424359715267\n",
      "Training epoch 1489...\n",
      "\n",
      "Train Epoch: 1489 [0/8000 (0%)]\tBatch Loss: 1097.905453\tLearning Rate (w_theta): 0.001000\t TIME:1925.7s\n",
      "\t\t\t\tDisc: 1.419488\t\tSym: 20.053104\t\tSpars: 1076.432861\n",
      "\t TVw: -0.467216 | TVb: -2.043438 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1489 [4000/8000 (50%)]\tBatch Loss: 1127.149646\tLearning Rate (w_theta): 0.001000\t TIME:1927.2s\n",
      "\t\t\t\tDisc: 1.622234\t\tSym: 21.549019\t\tSpars: 1103.978394\n",
      "\t TVw: -0.467071 | TVb: -2.043439 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1489...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1077.8525551087853\n",
      "Average validation loss: 167.46726063101949\n",
      "Training epoch 1490...\n",
      "\n",
      "Train Epoch: 1490 [0/8000 (0%)]\tBatch Loss: 1060.977619\tLearning Rate (w_theta): 0.001000\t TIME:1929.5s\n",
      "\t\t\t\tDisc: 1.279891\t\tSym: 18.012669\t\tSpars: 1041.685059\n",
      "\t TVw: -0.466924 | TVb: -2.043439 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1490 [4000/8000 (50%)]\tBatch Loss: 1082.994512\tLearning Rate (w_theta): 0.001000\t TIME:1931.0s\n",
      "\t\t\t\tDisc: 1.338941\t\tSym: 18.705864\t\tSpars: 1062.949707\n",
      "\t TVw: -0.466775 | TVb: -2.043440 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1490...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1069.9996608504598\n",
      "Average validation loss: 168.66696177015365\n",
      "Training epoch 1491...\n",
      "\n",
      "Train Epoch: 1491 [0/8000 (0%)]\tBatch Loss: 1051.004491\tLearning Rate (w_theta): 0.001000\t TIME:1934.0s\n",
      "\t\t\t\tDisc: 1.265186\t\tSym: 17.430712\t\tSpars: 1032.308594\n",
      "\t TVw: -0.466625 | TVb: -2.043440 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1491 [4000/8000 (50%)]\tBatch Loss: 1018.200987\tLearning Rate (w_theta): 0.001000\t TIME:1935.5s\n",
      "\t\t\t\tDisc: 1.214228\t\tSym: 16.648014\t\tSpars: 1000.338745\n",
      "\t TVw: -0.466477 | TVb: -2.043441 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1491...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1070.1310279864692\n",
      "Average validation loss: 167.2388959944105\n",
      "Training epoch 1492...\n",
      "\n",
      "Train Epoch: 1492 [0/8000 (0%)]\tBatch Loss: 1052.799470\tLearning Rate (w_theta): 0.001000\t TIME:1938.0s\n",
      "\t\t\t\tDisc: 1.294604\t\tSym: 17.925276\t\tSpars: 1033.579590\n",
      "\t TVw: -0.466327 | TVb: -2.043441 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1492 [4000/8000 (50%)]\tBatch Loss: 1132.948782\tLearning Rate (w_theta): 0.001000\t TIME:1939.6s\n",
      "\t\t\t\tDisc: 1.479643\t\tSym: 21.651268\t\tSpars: 1109.817871\n",
      "\t TVw: -0.466180 | TVb: -2.043442 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1492...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1069.3654594205823\n",
      "Average validation loss: 165.03608033822695\n",
      "Training epoch 1493...\n",
      "\n",
      "Train Epoch: 1493 [0/8000 (0%)]\tBatch Loss: 1104.040014\tLearning Rate (w_theta): 0.001000\t TIME:1941.9s\n",
      "\t\t\t\tDisc: 1.502102\t\tSym: 20.844553\t\tSpars: 1081.693359\n",
      "\t TVw: -0.466033 | TVb: -2.043443 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1493 [4000/8000 (50%)]\tBatch Loss: 1103.761086\tLearning Rate (w_theta): 0.001000\t TIME:1943.4s\n",
      "\t\t\t\tDisc: 1.336104\t\tSym: 20.264582\t\tSpars: 1082.160400\n",
      "\t TVw: -0.465885 | TVb: -2.043443 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1493...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1072.7012874312481\n",
      "Average validation loss: 165.98156830407916\n",
      "Training epoch 1494...\n",
      "\n",
      "Train Epoch: 1494 [0/8000 (0%)]\tBatch Loss: 1084.752301\tLearning Rate (w_theta): 0.001000\t TIME:1945.7s\n",
      "\t\t\t\tDisc: 1.398948\t\tSym: 18.574911\t\tSpars: 1064.778442\n",
      "\t TVw: -0.465739 | TVb: -2.043444 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1494 [4000/8000 (50%)]\tBatch Loss: 1082.402208\tLearning Rate (w_theta): 0.001000\t TIME:1947.2s\n",
      "\t\t\t\tDisc: 1.354387\t\tSym: 19.258636\t\tSpars: 1061.789185\n",
      "\t TVw: -0.465592 | TVb: -2.043445 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1494...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1071.9749997570987\n",
      "Average validation loss: 168.54736065369408\n",
      "Training epoch 1495...\n",
      "\n",
      "Train Epoch: 1495 [0/8000 (0%)]\tBatch Loss: 1088.610737\tLearning Rate (w_theta): 0.001000\t TIME:1949.6s\n",
      "\t\t\t\tDisc: 1.268775\t\tSym: 18.790693\t\tSpars: 1068.551270\n",
      "\t TVw: -0.465444 | TVb: -2.043446 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1495 [4000/8000 (50%)]\tBatch Loss: 1098.901572\tLearning Rate (w_theta): 0.001000\t TIME:1951.1s\n",
      "\t\t\t\tDisc: 1.415099\t\tSym: 19.719627\t\tSpars: 1077.766846\n",
      "\t TVw: -0.465294 | TVb: -2.043447 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1495...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1072.820133497395\n",
      "Average validation loss: 167.9621539177793\n",
      "Training epoch 1496...\n",
      "\n",
      "Train Epoch: 1496 [0/8000 (0%)]\tBatch Loss: 1014.916127\tLearning Rate (w_theta): 0.001000\t TIME:1953.4s\n",
      "\t\t\t\tDisc: 1.084259\t\tSym: 15.405599\t\tSpars: 998.426270\n",
      "\t TVw: -0.465146 | TVb: -2.043448 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1496 [4000/8000 (50%)]\tBatch Loss: 1103.322239\tLearning Rate (w_theta): 0.001000\t TIME:1955.0s\n",
      "\t\t\t\tDisc: 1.406710\t\tSym: 19.941286\t\tSpars: 1081.974243\n",
      "\t TVw: -0.464995 | TVb: -2.043449 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1496...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1071.08024778964\n",
      "Average validation loss: 165.9409369768683\n",
      "Training epoch 1497...\n",
      "\n",
      "Train Epoch: 1497 [0/8000 (0%)]\tBatch Loss: 1047.850106\tLearning Rate (w_theta): 0.001000\t TIME:1957.3s\n",
      "\t\t\t\tDisc: 1.280257\t\tSym: 17.471216\t\tSpars: 1029.098633\n",
      "\t TVw: -0.464843 | TVb: -2.043449 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1497 [4000/8000 (50%)]\tBatch Loss: 1086.602010\tLearning Rate (w_theta): 0.001000\t TIME:1958.8s\n",
      "\t\t\t\tDisc: 1.320130\t\tSym: 18.407856\t\tSpars: 1066.874023\n",
      "\t TVw: -0.464689 | TVb: -2.043450 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1497...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1067.280404486851\n",
      "Average validation loss: 165.27428736923923\n",
      "Training epoch 1498...\n",
      "\n",
      "Train Epoch: 1498 [0/8000 (0%)]\tBatch Loss: 1035.436641\tLearning Rate (w_theta): 0.001000\t TIME:1961.2s\n",
      "\t\t\t\tDisc: 1.275230\t\tSym: 16.725010\t\tSpars: 1017.436401\n",
      "\t TVw: -0.464533 | TVb: -2.043450 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1498 [4000/8000 (50%)]\tBatch Loss: 1074.879852\tLearning Rate (w_theta): 0.001000\t TIME:1962.7s\n",
      "\t\t\t\tDisc: 1.336580\t\tSym: 18.872618\t\tSpars: 1054.670654\n",
      "\t TVw: -0.464378 | TVb: -2.043451 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1498...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1067.2075984554492\n",
      "Average validation loss: 166.64180995861523\n",
      "Training epoch 1499...\n",
      "\n",
      "Train Epoch: 1499 [0/8000 (0%)]\tBatch Loss: 1065.855115\tLearning Rate (w_theta): 0.001000\t TIME:1965.0s\n",
      "\t\t\t\tDisc: 1.391877\t\tSym: 19.323589\t\tSpars: 1045.139648\n",
      "\t TVw: -0.464225 | TVb: -2.043452 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1499 [4000/8000 (50%)]\tBatch Loss: 1046.697673\tLearning Rate (w_theta): 0.001000\t TIME:1966.5s\n",
      "\t\t\t\tDisc: 1.221757\t\tSym: 17.234705\t\tSpars: 1028.241211\n",
      "\t TVw: -0.464074 | TVb: -2.043452 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1499...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1070.6785183461095\n",
      "Average validation loss: 165.4173490032466\n",
      "Training epoch 1500...\n",
      "\n",
      "Train Epoch: 1500 [0/8000 (0%)]\tBatch Loss: 1094.279301\tLearning Rate (w_theta): 0.001000\t TIME:1969.1s\n",
      "\t\t\t\tDisc: 1.389765\t\tSym: 19.087290\t\tSpars: 1073.802246\n",
      "\t TVw: -0.463926 | TVb: -2.043453 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1500 [4000/8000 (50%)]\tBatch Loss: 1066.397869\tLearning Rate (w_theta): 0.001000\t TIME:1970.6s\n",
      "\t\t\t\tDisc: 1.373477\t\tSym: 18.156960\t\tSpars: 1046.867432\n",
      "\t TVw: -0.463779 | TVb: -2.043454 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1500...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1076.1046029209306\n",
      "Average validation loss: 166.73383167280662\n",
      "Training epoch 1501...\n",
      "\n",
      "Train Epoch: 1501 [0/8000 (0%)]\tBatch Loss: 1030.478327\tLearning Rate (w_theta): 0.001000\t TIME:1973.6s\n",
      "\t\t\t\tDisc: 1.195622\t\tSym: 17.728933\t\tSpars: 1011.553772\n",
      "\t TVw: -0.463630 | TVb: -2.043455 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1501 [4000/8000 (50%)]\tBatch Loss: 1095.673286\tLearning Rate (w_theta): 0.001000\t TIME:1975.1s\n",
      "\t\t\t\tDisc: 1.454950\t\tSym: 19.487989\t\tSpars: 1074.730347\n",
      "\t TVw: -0.463482 | TVb: -2.043456 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1501...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1084.688251948287\n",
      "Average validation loss: 169.13841753717685\n",
      "Training epoch 1502...\n",
      "\n",
      "Train Epoch: 1502 [0/8000 (0%)]\tBatch Loss: 1073.528877\tLearning Rate (w_theta): 0.001000\t TIME:1977.5s\n",
      "\t\t\t\tDisc: 1.166590\t\tSym: 17.865461\t\tSpars: 1054.496826\n",
      "\t TVw: -0.463333 | TVb: -2.043457 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1502 [4000/8000 (50%)]\tBatch Loss: 1122.567646\tLearning Rate (w_theta): 0.001000\t TIME:1979.0s\n",
      "\t\t\t\tDisc: 1.472557\t\tSym: 21.681637\t\tSpars: 1099.413452\n",
      "\t TVw: -0.463186 | TVb: -2.043458 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1502...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1086.1120989683077\n",
      "Average validation loss: 169.45407423745618\n",
      "Training epoch 1503...\n",
      "\n",
      "Train Epoch: 1503 [0/8000 (0%)]\tBatch Loss: 1066.915006\tLearning Rate (w_theta): 0.001000\t TIME:1981.4s\n",
      "\t\t\t\tDisc: 1.060377\t\tSym: 17.497818\t\tSpars: 1048.356812\n",
      "\t TVw: -0.463034 | TVb: -2.043459 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1503 [4000/8000 (50%)]\tBatch Loss: 1064.684177\tLearning Rate (w_theta): 0.001000\t TIME:1982.9s\n",
      "\t\t\t\tDisc: 1.265695\t\tSym: 17.574366\t\tSpars: 1045.844116\n",
      "\t TVw: -0.462876 | TVb: -2.043459 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1503...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1073.9759706572456\n",
      "Average validation loss: 167.4508939789168\n",
      "Training epoch 1504...\n",
      "\n",
      "Train Epoch: 1504 [0/8000 (0%)]\tBatch Loss: 1051.278342\tLearning Rate (w_theta): 0.001000\t TIME:1985.3s\n",
      "\t\t\t\tDisc: 1.194657\t\tSym: 16.838079\t\tSpars: 1033.245605\n",
      "\t TVw: -0.462715 | TVb: -2.043460 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1504 [4000/8000 (50%)]\tBatch Loss: 1084.302232\tLearning Rate (w_theta): 0.001000\t TIME:1986.8s\n",
      "\t\t\t\tDisc: 1.352596\t\tSym: 19.491629\t\tSpars: 1063.458008\n",
      "\t TVw: -0.462552 | TVb: -2.043460 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1504...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1068.065697169906\n",
      "Average validation loss: 167.39530526508048\n",
      "Training epoch 1505...\n",
      "\n",
      "Train Epoch: 1505 [0/8000 (0%)]\tBatch Loss: 1097.291536\tLearning Rate (w_theta): 0.001000\t TIME:1989.3s\n",
      "\t\t\t\tDisc: 1.327675\t\tSym: 20.101313\t\tSpars: 1075.862549\n",
      "\t TVw: -0.462390 | TVb: -2.043460 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1505 [4000/8000 (50%)]\tBatch Loss: 1070.924829\tLearning Rate (w_theta): 0.001000\t TIME:1990.9s\n",
      "\t\t\t\tDisc: 1.307168\t\tSym: 18.428085\t\tSpars: 1051.189575\n",
      "\t TVw: -0.462228 | TVb: -2.043460 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1505...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1065.1920976592269\n",
      "Average validation loss: 165.6595478499952\n",
      "Training epoch 1506...\n",
      "\n",
      "Train Epoch: 1506 [0/8000 (0%)]\tBatch Loss: 1072.139696\tLearning Rate (w_theta): 0.001000\t TIME:1993.2s\n",
      "\t\t\t\tDisc: 1.342253\t\tSym: 18.736774\t\tSpars: 1052.060669\n",
      "\t TVw: -0.462067 | TVb: -2.043461 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1506 [4000/8000 (50%)]\tBatch Loss: 1113.916629\tLearning Rate (w_theta): 0.001000\t TIME:1994.7s\n",
      "\t\t\t\tDisc: 1.424135\t\tSym: 20.367006\t\tSpars: 1092.125488\n",
      "\t TVw: -0.461910 | TVb: -2.043462 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1506...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1063.3701414932661\n",
      "Average validation loss: 165.06431791525705\n",
      "Training epoch 1507...\n",
      "\n",
      "Train Epoch: 1507 [0/8000 (0%)]\tBatch Loss: 1050.695144\tLearning Rate (w_theta): 0.001000\t TIME:1997.1s\n",
      "\t\t\t\tDisc: 1.289749\t\tSym: 18.256714\t\tSpars: 1031.148682\n",
      "\t TVw: -0.461753 | TVb: -2.043463 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1507 [4000/8000 (50%)]\tBatch Loss: 1064.058017\tLearning Rate (w_theta): 0.001000\t TIME:1998.6s\n",
      "\t\t\t\tDisc: 1.393392\t\tSym: 18.482374\t\tSpars: 1044.182251\n",
      "\t TVw: -0.461597 | TVb: -2.043464 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1507...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1064.7573806824425\n",
      "Average validation loss: 166.40228553871276\n",
      "Training epoch 1508...\n",
      "\n",
      "Train Epoch: 1508 [0/8000 (0%)]\tBatch Loss: 1074.117720\tLearning Rate (w_theta): 0.001000\t TIME:2000.9s\n",
      "\t\t\t\tDisc: 1.380433\t\tSym: 19.694685\t\tSpars: 1053.042603\n",
      "\t TVw: -0.461441 | TVb: -2.043464 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1508 [4000/8000 (50%)]\tBatch Loss: 1094.429644\tLearning Rate (w_theta): 0.001000\t TIME:2002.5s\n",
      "\t\t\t\tDisc: 1.368306\t\tSym: 19.001036\t\tSpars: 1074.060303\n",
      "\t TVw: -0.461286 | TVb: -2.043465 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1508...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1066.8090579719567\n",
      "Average validation loss: 164.3932936420516\n",
      "Training epoch 1509...\n",
      "\n",
      "Train Epoch: 1509 [0/8000 (0%)]\tBatch Loss: 1104.926975\tLearning Rate (w_theta): 0.001000\t TIME:2004.8s\n",
      "\t\t\t\tDisc: 1.485626\t\tSym: 20.397160\t\tSpars: 1083.044189\n",
      "\t TVw: -0.461131 | TVb: -2.043466 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1509 [4000/8000 (50%)]\tBatch Loss: 1056.428544\tLearning Rate (w_theta): 0.001000\t TIME:2006.3s\n",
      "\t\t\t\tDisc: 1.295569\t\tSym: 17.018473\t\tSpars: 1038.114502\n",
      "\t TVw: -0.460978 | TVb: -2.043467 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1509...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1078.5140920025476\n",
      "Average validation loss: 165.59076219529643\n",
      "Training epoch 1510...\n",
      "\n",
      "Train Epoch: 1510 [0/8000 (0%)]\tBatch Loss: 1064.458991\tLearning Rate (w_theta): 0.001000\t TIME:2008.6s\n",
      "\t\t\t\tDisc: 1.205919\t\tSym: 17.670919\t\tSpars: 1045.582153\n",
      "\t TVw: -0.460825 | TVb: -2.043468 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1510 [4000/8000 (50%)]\tBatch Loss: 1067.418571\tLearning Rate (w_theta): 0.001000\t TIME:2010.1s\n",
      "\t\t\t\tDisc: 1.350633\t\tSym: 18.880072\t\tSpars: 1047.187866\n",
      "\t TVw: -0.460668 | TVb: -2.043469 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1510...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1070.2005973772011\n",
      "Average validation loss: 166.13994010016933\n",
      "Training epoch 1511...\n",
      "\n",
      "Train Epoch: 1511 [0/8000 (0%)]\tBatch Loss: 1056.467172\tLearning Rate (w_theta): 0.001000\t TIME:2013.3s\n",
      "\t\t\t\tDisc: 1.218673\t\tSym: 17.795862\t\tSpars: 1037.452637\n",
      "\t TVw: -0.460508 | TVb: -2.043470 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1511 [4000/8000 (50%)]\tBatch Loss: 1081.553095\tLearning Rate (w_theta): 0.001000\t TIME:2014.9s\n",
      "\t\t\t\tDisc: 1.367421\t\tSym: 19.315924\t\tSpars: 1060.869751\n",
      "\t TVw: -0.460346 | TVb: -2.043470 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1511...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1064.2475396208386\n",
      "Average validation loss: 165.88108494620795\n",
      "Training epoch 1512...\n",
      "\n",
      "Train Epoch: 1512 [0/8000 (0%)]\tBatch Loss: 1039.824425\tLearning Rate (w_theta): 0.001000\t TIME:2017.2s\n",
      "\t\t\t\tDisc: 1.216936\t\tSym: 17.677313\t\tSpars: 1020.930176\n",
      "\t TVw: -0.460180 | TVb: -2.043470 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1512 [4000/8000 (50%)]\tBatch Loss: 1093.150964\tLearning Rate (w_theta): 0.001000\t TIME:2018.7s\n",
      "\t\t\t\tDisc: 1.379047\t\tSym: 19.940130\t\tSpars: 1071.831787\n",
      "\t TVw: -0.460012 | TVb: -2.043470 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1512...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1060.7637163575162\n",
      "Average validation loss: 164.7882514989792\n",
      "Training epoch 1513...\n",
      "\n",
      "Train Epoch: 1513 [0/8000 (0%)]\tBatch Loss: 1049.804803\tLearning Rate (w_theta): 0.001000\t TIME:2021.1s\n",
      "\t\t\t\tDisc: 1.391849\t\tSym: 17.737295\t\tSpars: 1030.675659\n",
      "\t TVw: -0.459847 | TVb: -2.043470 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1513 [4000/8000 (50%)]\tBatch Loss: 1036.791094\tLearning Rate (w_theta): 0.001000\t TIME:2022.6s\n",
      "\t\t\t\tDisc: 1.249077\t\tSym: 17.094507\t\tSpars: 1018.447510\n",
      "\t TVw: -0.459687 | TVb: -2.043471 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1513...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1063.4132945352662\n",
      "Average validation loss: 163.43749830663268\n",
      "Training epoch 1514...\n",
      "\n",
      "Train Epoch: 1514 [0/8000 (0%)]\tBatch Loss: 1064.767877\tLearning Rate (w_theta): 0.001000\t TIME:2024.9s\n",
      "\t\t\t\tDisc: 1.426580\t\tSym: 18.520741\t\tSpars: 1044.820557\n",
      "\t TVw: -0.459526 | TVb: -2.043472 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1514 [4000/8000 (50%)]\tBatch Loss: 1040.270595\tLearning Rate (w_theta): 0.001000\t TIME:2026.4s\n",
      "\t\t\t\tDisc: 1.146995\t\tSym: 17.557987\t\tSpars: 1021.565613\n",
      "\t TVw: -0.459365 | TVb: -2.043473 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1514...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1062.6781612398281\n",
      "Average validation loss: 164.7587534208123\n",
      "Training epoch 1515...\n",
      "\n",
      "Train Epoch: 1515 [0/8000 (0%)]\tBatch Loss: 1078.867157\tLearning Rate (w_theta): 0.001000\t TIME:2028.8s\n",
      "\t\t\t\tDisc: 1.452297\t\tSym: 20.302311\t\tSpars: 1057.112549\n",
      "\t TVw: -0.459205 | TVb: -2.043473 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1515 [4000/8000 (50%)]\tBatch Loss: 1067.153879\tLearning Rate (w_theta): 0.001000\t TIME:2030.3s\n",
      "\t\t\t\tDisc: 1.260565\t\tSym: 17.890751\t\tSpars: 1048.002563\n",
      "\t TVw: -0.459046 | TVb: -2.043474 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1515...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1061.6305211407955\n",
      "Average validation loss: 164.91416129891482\n",
      "Training epoch 1516...\n",
      "\n",
      "Train Epoch: 1516 [0/8000 (0%)]\tBatch Loss: 1044.383992\tLearning Rate (w_theta): 0.001000\t TIME:2032.7s\n",
      "\t\t\t\tDisc: 1.284001\t\tSym: 18.261246\t\tSpars: 1024.838745\n",
      "\t TVw: -0.458886 | TVb: -2.043475 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1516 [4000/8000 (50%)]\tBatch Loss: 1096.418369\tLearning Rate (w_theta): 0.001000\t TIME:2034.2s\n",
      "\t\t\t\tDisc: 1.317953\t\tSym: 20.234938\t\tSpars: 1074.865479\n",
      "\t TVw: -0.458726 | TVb: -2.043476 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1516...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1067.9314574496552\n",
      "Average validation loss: 164.59616742259644\n",
      "Training epoch 1517...\n",
      "\n",
      "Train Epoch: 1517 [0/8000 (0%)]\tBatch Loss: 1037.389534\tLearning Rate (w_theta): 0.001000\t TIME:2036.6s\n",
      "\t\t\t\tDisc: 1.202862\t\tSym: 17.250149\t\tSpars: 1018.936523\n",
      "\t TVw: -0.458569 | TVb: -2.043477 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1517 [4000/8000 (50%)]\tBatch Loss: 1086.240336\tLearning Rate (w_theta): 0.001000\t TIME:2038.1s\n",
      "\t\t\t\tDisc: 1.312941\t\tSym: 19.241238\t\tSpars: 1065.686157\n",
      "\t TVw: -0.458410 | TVb: -2.043478 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1517...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1064.3230251548378\n",
      "Average validation loss: 163.32669801671472\n",
      "Training epoch 1518...\n",
      "\n",
      "Train Epoch: 1518 [0/8000 (0%)]\tBatch Loss: 1104.148694\tLearning Rate (w_theta): 0.001000\t TIME:2040.6s\n",
      "\t\t\t\tDisc: 1.446025\t\tSym: 20.289217\t\tSpars: 1082.413452\n",
      "\t TVw: -0.458249 | TVb: -2.043479 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1518 [4000/8000 (50%)]\tBatch Loss: 1066.932227\tLearning Rate (w_theta): 0.001000\t TIME:2042.1s\n",
      "\t\t\t\tDisc: 1.205728\t\tSym: 17.664854\t\tSpars: 1048.061646\n",
      "\t TVw: -0.458089 | TVb: -2.043480 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1518...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1064.020003606038\n",
      "Average validation loss: 165.15443420314486\n",
      "Training epoch 1519...\n",
      "\n",
      "Train Epoch: 1519 [0/8000 (0%)]\tBatch Loss: 1072.698052\tLearning Rate (w_theta): 0.001000\t TIME:2044.4s\n",
      "\t\t\t\tDisc: 1.389233\t\tSym: 19.259502\t\tSpars: 1052.049316\n",
      "\t TVw: -0.457925 | TVb: -2.043480 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1519 [4000/8000 (50%)]\tBatch Loss: 1047.606495\tLearning Rate (w_theta): 0.001000\t TIME:2045.9s\n",
      "\t\t\t\tDisc: 1.354380\t\tSym: 17.767496\t\tSpars: 1028.484619\n",
      "\t TVw: -0.457760 | TVb: -2.043481 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1519...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1065.6953829308995\n",
      "Average validation loss: 164.0556199488732\n",
      "Training epoch 1520...\n",
      "\n",
      "Train Epoch: 1520 [0/8000 (0%)]\tBatch Loss: 1044.710724\tLearning Rate (w_theta): 0.001000\t TIME:2048.3s\n",
      "\t\t\t\tDisc: 1.271294\t\tSym: 17.891212\t\tSpars: 1025.548218\n",
      "\t TVw: -0.457596 | TVb: -2.043482 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1520 [4000/8000 (50%)]\tBatch Loss: 1093.926560\tLearning Rate (w_theta): 0.001000\t TIME:2049.9s\n",
      "\t\t\t\tDisc: 1.508161\t\tSym: 20.268986\t\tSpars: 1072.149414\n",
      "\t TVw: -0.457430 | TVb: -2.043483 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1520...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1064.6860924691773\n",
      "Average validation loss: 165.7441716700594\n",
      "Training epoch 1521...\n",
      "\n",
      "Train Epoch: 1521 [0/8000 (0%)]\tBatch Loss: 1096.337418\tLearning Rate (w_theta): 0.001000\t TIME:2052.9s\n",
      "\t\t\t\tDisc: 1.335430\t\tSym: 20.170322\t\tSpars: 1074.831665\n",
      "\t TVw: -0.457266 | TVb: -2.043484 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "\n",
      "Train Epoch: 1521 [4000/8000 (50%)]\tBatch Loss: 1073.185306\tLearning Rate (w_theta): 0.001000\t TIME:2054.4s\n",
      "\t\t\t\tDisc: 1.362676\t\tSym: 18.256224\t\tSpars: 1053.566406\n",
      "\t TVw: -0.457101 | TVb: -2.043485 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034766\n",
      "Validating epoch 1521...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1066.0526730774823\n",
      "Average validation loss: 165.90001152213588\n",
      "Training epoch 1522...\n",
      "\n",
      "Train Epoch: 1522 [0/8000 (0%)]\tBatch Loss: 1053.515153\tLearning Rate (w_theta): 0.001000\t TIME:2056.8s\n",
      "\t\t\t\tDisc: 1.288547\t\tSym: 18.143476\t\tSpars: 1034.083130\n",
      "\t TVw: -0.456933 | TVb: -2.043486 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1522 [4000/8000 (50%)]\tBatch Loss: 1049.185092\tLearning Rate (w_theta): 0.001000\t TIME:2058.3s\n",
      "\t\t\t\tDisc: 1.246691\t\tSym: 17.896286\t\tSpars: 1030.042114\n",
      "\t TVw: -0.456762 | TVb: -2.043487 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1522...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1065.9825348787497\n",
      "Average validation loss: 163.75576960124437\n",
      "Training epoch 1523...\n",
      "\n",
      "Train Epoch: 1523 [0/8000 (0%)]\tBatch Loss: 1081.724217\tLearning Rate (w_theta): 0.001000\t TIME:2060.6s\n",
      "\t\t\t\tDisc: 1.366520\t\tSym: 19.500153\t\tSpars: 1060.857544\n",
      "\t TVw: -0.456593 | TVb: -2.043487 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1523 [4000/8000 (50%)]\tBatch Loss: 977.855756\tLearning Rate (w_theta): 0.001000\t TIME:2062.1s\n",
      "\t\t\t\tDisc: 1.096365\t\tSym: 15.635734\t\tSpars: 961.123657\n",
      "\t TVw: -0.456424 | TVb: -2.043488 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1523...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1062.1129121003555\n",
      "Average validation loss: 163.81548306472\n",
      "Training epoch 1524...\n",
      "\n",
      "Train Epoch: 1524 [0/8000 (0%)]\tBatch Loss: 1058.035118\tLearning Rate (w_theta): 0.001000\t TIME:2064.7s\n",
      "\t\t\t\tDisc: 1.278286\t\tSym: 18.332760\t\tSpars: 1038.424072\n",
      "\t TVw: -0.456252 | TVb: -2.043488 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1524 [4000/8000 (50%)]\tBatch Loss: 1060.548655\tLearning Rate (w_theta): 0.001000\t TIME:2066.2s\n",
      "\t\t\t\tDisc: 1.289160\t\tSym: 19.232273\t\tSpars: 1040.027222\n",
      "\t TVw: -0.456080 | TVb: -2.043489 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1524...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1062.059155732643\n",
      "Average validation loss: 162.17955368174847\n",
      "Training epoch 1525...\n",
      "\n",
      "Train Epoch: 1525 [0/8000 (0%)]\tBatch Loss: 1087.996894\tLearning Rate (w_theta): 0.001000\t TIME:2068.5s\n",
      "\t\t\t\tDisc: 1.468350\t\tSym: 19.850443\t\tSpars: 1066.678101\n",
      "\t TVw: -0.455909 | TVb: -2.043489 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1525 [4000/8000 (50%)]\tBatch Loss: 1081.110362\tLearning Rate (w_theta): 0.001000\t TIME:2070.1s\n",
      "\t\t\t\tDisc: 1.392530\t\tSym: 19.285460\t\tSpars: 1060.432373\n",
      "\t TVw: -0.455742 | TVb: -2.043490 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1525...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1062.885082213776\n",
      "Average validation loss: 164.1854589013571\n",
      "Training epoch 1526...\n",
      "\n",
      "Train Epoch: 1526 [0/8000 (0%)]\tBatch Loss: 1103.279991\tLearning Rate (w_theta): 0.001000\t TIME:2072.4s\n",
      "\t\t\t\tDisc: 1.452825\t\tSym: 20.157976\t\tSpars: 1081.669189\n",
      "\t TVw: -0.455575 | TVb: -2.043491 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1526 [4000/8000 (50%)]\tBatch Loss: 1049.040741\tLearning Rate (w_theta): 0.001000\t TIME:2073.9s\n",
      "\t\t\t\tDisc: 1.296602\t\tSym: 18.793577\t\tSpars: 1028.950562\n",
      "\t TVw: -0.455410 | TVb: -2.043492 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1526...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1071.9395082517767\n",
      "Average validation loss: 162.83898980448683\n",
      "Training epoch 1527...\n",
      "\n",
      "Train Epoch: 1527 [0/8000 (0%)]\tBatch Loss: 1033.953637\tLearning Rate (w_theta): 0.001000\t TIME:2076.2s\n",
      "\t\t\t\tDisc: 1.184432\t\tSym: 16.596415\t\tSpars: 1016.172791\n",
      "\t TVw: -0.455244 | TVb: -2.043493 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1527 [4000/8000 (50%)]\tBatch Loss: 1099.865836\tLearning Rate (w_theta): 0.001000\t TIME:2077.8s\n",
      "\t\t\t\tDisc: 1.442008\t\tSym: 19.778198\t\tSpars: 1078.645630\n",
      "\t TVw: -0.455078 | TVb: -2.043494 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1527...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1071.4289506272628\n",
      "Average validation loss: 163.2397249137986\n",
      "Training epoch 1528...\n",
      "\n",
      "Train Epoch: 1528 [0/8000 (0%)]\tBatch Loss: 1068.747559\tLearning Rate (w_theta): 0.001000\t TIME:2080.1s\n",
      "\t\t\t\tDisc: 1.445705\t\tSym: 19.299778\t\tSpars: 1048.002075\n",
      "\t TVw: -0.454915 | TVb: -2.043495 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1528 [4000/8000 (50%)]\tBatch Loss: 1063.241302\tLearning Rate (w_theta): 0.001000\t TIME:2081.6s\n",
      "\t\t\t\tDisc: 1.387140\t\tSym: 18.290442\t\tSpars: 1043.563721\n",
      "\t TVw: -0.454747 | TVb: -2.043497 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1528...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1064.011085722111\n",
      "Average validation loss: 164.76512486381318\n",
      "Training epoch 1529...\n",
      "\n",
      "Train Epoch: 1529 [0/8000 (0%)]\tBatch Loss: 1071.949851\tLearning Rate (w_theta): 0.001000\t TIME:2084.0s\n",
      "\t\t\t\tDisc: 1.341193\t\tSym: 18.382828\t\tSpars: 1052.225830\n",
      "\t TVw: -0.454579 | TVb: -2.043497 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1529 [4000/8000 (50%)]\tBatch Loss: 1052.876921\tLearning Rate (w_theta): 0.001000\t TIME:2085.5s\n",
      "\t\t\t\tDisc: 1.257609\t\tSym: 18.142506\t\tSpars: 1033.476807\n",
      "\t TVw: -0.454409 | TVb: -2.043498 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1529...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1058.5288728724288\n",
      "Average validation loss: 163.75458633994074\n",
      "Training epoch 1530...\n",
      "\n",
      "Train Epoch: 1530 [0/8000 (0%)]\tBatch Loss: 1058.058883\tLearning Rate (w_theta): 0.001000\t TIME:2087.8s\n",
      "\t\t\t\tDisc: 1.293943\t\tSym: 18.857103\t\tSpars: 1037.907837\n",
      "\t TVw: -0.454235 | TVb: -2.043499 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1530 [4000/8000 (50%)]\tBatch Loss: 1053.641766\tLearning Rate (w_theta): 0.001000\t TIME:2089.4s\n",
      "\t\t\t\tDisc: 1.248595\t\tSym: 19.334944\t\tSpars: 1033.058228\n",
      "\t TVw: -0.454057 | TVb: -2.043500 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1530...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1054.803863849253\n",
      "Average validation loss: 163.0594222087464\n",
      "Training epoch 1531...\n",
      "\n",
      "Train Epoch: 1531 [0/8000 (0%)]\tBatch Loss: 1021.141721\tLearning Rate (w_theta): 0.001000\t TIME:2092.6s\n",
      "\t\t\t\tDisc: 1.179191\t\tSym: 16.603888\t\tSpars: 1003.358643\n",
      "\t TVw: -0.453876 | TVb: -2.043501 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1531 [4000/8000 (50%)]\tBatch Loss: 1031.844140\tLearning Rate (w_theta): 0.001000\t TIME:2094.1s\n",
      "\t\t\t\tDisc: 1.165095\t\tSym: 17.408598\t\tSpars: 1013.270447\n",
      "\t TVw: -0.453698 | TVb: -2.043501 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1531...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1056.213557833423\n",
      "Average validation loss: 161.84046407043763\n",
      "Training epoch 1532...\n",
      "\n",
      "Train Epoch: 1532 [0/8000 (0%)]\tBatch Loss: 1054.150106\tLearning Rate (w_theta): 0.001000\t TIME:2096.5s\n",
      "\t\t\t\tDisc: 1.277862\t\tSym: 16.999319\t\tSpars: 1035.872925\n",
      "\t TVw: -0.453522 | TVb: -2.043502 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1532 [4000/8000 (50%)]\tBatch Loss: 1082.039988\tLearning Rate (w_theta): 0.001000\t TIME:2098.0s\n",
      "\t\t\t\tDisc: 1.337148\t\tSym: 18.557089\t\tSpars: 1062.145752\n",
      "\t TVw: -0.453348 | TVb: -2.043503 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1532...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1063.9870503374498\n",
      "Average validation loss: 162.34843026902578\n",
      "Training epoch 1533...\n",
      "\n",
      "Train Epoch: 1533 [0/8000 (0%)]\tBatch Loss: 1080.500616\tLearning Rate (w_theta): 0.001000\t TIME:2100.4s\n",
      "\t\t\t\tDisc: 1.358058\t\tSym: 18.623758\t\tSpars: 1060.518799\n",
      "\t TVw: -0.453177 | TVb: -2.043504 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1533 [4000/8000 (50%)]\tBatch Loss: 1026.317866\tLearning Rate (w_theta): 0.001000\t TIME:2101.9s\n",
      "\t\t\t\tDisc: 1.249716\t\tSym: 18.082127\t\tSpars: 1006.986023\n",
      "\t TVw: -0.453006 | TVb: -2.043505 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1533...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1057.018306542527\n",
      "Average validation loss: 163.8103219799546\n",
      "Training epoch 1534...\n",
      "\n",
      "Train Epoch: 1534 [0/8000 (0%)]\tBatch Loss: 1066.621011\tLearning Rate (w_theta): 0.001000\t TIME:2104.2s\n",
      "\t\t\t\tDisc: 1.353347\t\tSym: 19.681726\t\tSpars: 1045.585938\n",
      "\t TVw: -0.452832 | TVb: -2.043505 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1534 [4000/8000 (50%)]\tBatch Loss: 1106.678209\tLearning Rate (w_theta): 0.001000\t TIME:2105.7s\n",
      "\t\t\t\tDisc: 1.538936\t\tSym: 20.814077\t\tSpars: 1084.325195\n",
      "\t TVw: -0.452656 | TVb: -2.043506 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1534...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1056.2775101745347\n",
      "Average validation loss: 162.41199028081434\n",
      "Training epoch 1535...\n",
      "\n",
      "Train Epoch: 1535 [0/8000 (0%)]\tBatch Loss: 1032.135432\tLearning Rate (w_theta): 0.001000\t TIME:2108.0s\n",
      "\t\t\t\tDisc: 1.260777\t\tSym: 16.986105\t\tSpars: 1013.888550\n",
      "\t TVw: -0.452483 | TVb: -2.043507 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1535 [4000/8000 (50%)]\tBatch Loss: 1013.387691\tLearning Rate (w_theta): 0.001000\t TIME:2109.6s\n",
      "\t\t\t\tDisc: 1.083372\t\tSym: 16.392515\t\tSpars: 995.911804\n",
      "\t TVw: -0.452308 | TVb: -2.043507 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1535...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1060.3014069924598\n",
      "Average validation loss: 163.6750629222047\n",
      "Training epoch 1536...\n",
      "\n",
      "Train Epoch: 1536 [0/8000 (0%)]\tBatch Loss: 1095.348147\tLearning Rate (w_theta): 0.001000\t TIME:2111.9s\n",
      "\t\t\t\tDisc: 1.365048\t\tSym: 20.367620\t\tSpars: 1073.615479\n",
      "\t TVw: -0.452134 | TVb: -2.043508 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1536 [4000/8000 (50%)]\tBatch Loss: 1035.133134\tLearning Rate (w_theta): 0.001000\t TIME:2113.5s\n",
      "\t\t\t\tDisc: 1.084512\t\tSym: 17.209755\t\tSpars: 1016.838867\n",
      "\t TVw: -0.451962 | TVb: -2.043509 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1536...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1059.338426829\n",
      "Average validation loss: 162.454735427251\n",
      "Training epoch 1537...\n",
      "\n",
      "Train Epoch: 1537 [0/8000 (0%)]\tBatch Loss: 1069.017160\tLearning Rate (w_theta): 0.001000\t TIME:2116.0s\n",
      "\t\t\t\tDisc: 1.317844\t\tSym: 20.014257\t\tSpars: 1047.685059\n",
      "\t TVw: -0.451786 | TVb: -2.043510 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1537 [4000/8000 (50%)]\tBatch Loss: 1029.424351\tLearning Rate (w_theta): 0.001000\t TIME:2117.5s\n",
      "\t\t\t\tDisc: 1.213599\t\tSym: 17.100035\t\tSpars: 1011.110718\n",
      "\t TVw: -0.451602 | TVb: -2.043511 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1537...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1057.1199523050225\n",
      "Average validation loss: 164.2708512206726\n",
      "Training epoch 1538...\n",
      "\n",
      "Train Epoch: 1538 [0/8000 (0%)]\tBatch Loss: 1047.578707\tLearning Rate (w_theta): 0.001000\t TIME:2119.8s\n",
      "\t\t\t\tDisc: 1.255970\t\tSym: 17.887434\t\tSpars: 1028.435303\n",
      "\t TVw: -0.451418 | TVb: -2.043511 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1538 [4000/8000 (50%)]\tBatch Loss: 1024.443386\tLearning Rate (w_theta): 0.001000\t TIME:2121.4s\n",
      "\t\t\t\tDisc: 1.251683\t\tSym: 16.867790\t\tSpars: 1006.323914\n",
      "\t TVw: -0.451238 | TVb: -2.043511 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1538...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1064.900629752636\n",
      "Average validation loss: 162.04249919490948\n",
      "Training epoch 1539...\n",
      "\n",
      "Train Epoch: 1539 [0/8000 (0%)]\tBatch Loss: 1048.634544\tLearning Rate (w_theta): 0.001000\t TIME:2123.7s\n",
      "\t\t\t\tDisc: 1.309831\t\tSym: 18.899542\t\tSpars: 1028.425171\n",
      "\t TVw: -0.451064 | TVb: -2.043512 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1539 [4000/8000 (50%)]\tBatch Loss: 1093.308479\tLearning Rate (w_theta): 0.001000\t TIME:2125.2s\n",
      "\t\t\t\tDisc: 1.392376\t\tSym: 20.716396\t\tSpars: 1071.199707\n",
      "\t TVw: -0.450890 | TVb: -2.043513 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1539...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1057.078456976552\n",
      "Average validation loss: 162.35170921912288\n",
      "Training epoch 1540...\n",
      "\n",
      "Train Epoch: 1540 [0/8000 (0%)]\tBatch Loss: 1061.002804\tLearning Rate (w_theta): 0.001000\t TIME:2127.5s\n",
      "\t\t\t\tDisc: 1.329095\t\tSym: 18.743168\t\tSpars: 1040.930542\n",
      "\t TVw: -0.450709 | TVb: -2.043514 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1540 [4000/8000 (50%)]\tBatch Loss: 1052.079366\tLearning Rate (w_theta): 0.001000\t TIME:2129.1s\n",
      "\t\t\t\tDisc: 1.278070\t\tSym: 18.645290\t\tSpars: 1032.156006\n",
      "\t TVw: -0.450526 | TVb: -2.043515 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1540...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1054.9546617561982\n",
      "Average validation loss: 163.70680058793033\n",
      "Training epoch 1541...\n",
      "\n",
      "Train Epoch: 1541 [0/8000 (0%)]\tBatch Loss: 1050.966163\tLearning Rate (w_theta): 0.001000\t TIME:2132.1s\n",
      "\t\t\t\tDisc: 1.125881\t\tSym: 17.824535\t\tSpars: 1032.015747\n",
      "\t TVw: -0.450342 | TVb: -2.043515 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1541 [4000/8000 (50%)]\tBatch Loss: 1065.648391\tLearning Rate (w_theta): 0.001000\t TIME:2133.6s\n",
      "\t\t\t\tDisc: 1.380904\t\tSym: 19.522247\t\tSpars: 1044.745239\n",
      "\t TVw: -0.450159 | TVb: -2.043516 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1541...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1052.7867941602017\n",
      "Average validation loss: 162.74075123357488\n",
      "Training epoch 1542...\n",
      "\n",
      "Train Epoch: 1542 [0/8000 (0%)]\tBatch Loss: 1047.862640\tLearning Rate (w_theta): 0.001000\t TIME:2136.0s\n",
      "\t\t\t\tDisc: 1.301241\t\tSym: 18.368406\t\tSpars: 1028.192993\n",
      "\t TVw: -0.449973 | TVb: -2.043516 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1542 [4000/8000 (50%)]\tBatch Loss: 1020.628841\tLearning Rate (w_theta): 0.001000\t TIME:2137.5s\n",
      "\t\t\t\tDisc: 1.225595\t\tSym: 16.487291\t\tSpars: 1002.915955\n",
      "\t TVw: -0.449789 | TVb: -2.043517 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1542...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1055.5291485612738\n",
      "Average validation loss: 160.80682533464565\n",
      "Training epoch 1543...\n",
      "\n",
      "Train Epoch: 1543 [0/8000 (0%)]\tBatch Loss: 1070.501258\tLearning Rate (w_theta): 0.001000\t TIME:2140.0s\n",
      "\t\t\t\tDisc: 1.326801\t\tSym: 19.155537\t\tSpars: 1050.018921\n",
      "\t TVw: -0.449608 | TVb: -2.043518 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1543 [4000/8000 (50%)]\tBatch Loss: 1030.022704\tLearning Rate (w_theta): 0.001000\t TIME:2141.5s\n",
      "\t\t\t\tDisc: 1.154529\t\tSym: 18.291149\t\tSpars: 1010.577026\n",
      "\t TVw: -0.449427 | TVb: -2.043519 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1543...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1055.4883621230406\n",
      "Average validation loss: 160.49516086720178\n",
      "Training epoch 1544...\n",
      "\n",
      "Train Epoch: 1544 [0/8000 (0%)]\tBatch Loss: 1050.926377\tLearning Rate (w_theta): 0.001000\t TIME:2143.8s\n",
      "\t\t\t\tDisc: 1.313233\t\tSym: 18.096909\t\tSpars: 1031.516235\n",
      "\t TVw: -0.449247 | TVb: -2.043520 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1544 [4000/8000 (50%)]\tBatch Loss: 1078.975208\tLearning Rate (w_theta): 0.001000\t TIME:2145.4s\n",
      "\t\t\t\tDisc: 1.332324\t\tSym: 18.318665\t\tSpars: 1059.324219\n",
      "\t TVw: -0.449066 | TVb: -2.043521 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1544...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1053.7814328817287\n",
      "Average validation loss: 163.08303732843274\n",
      "Training epoch 1545...\n",
      "\n",
      "Train Epoch: 1545 [0/8000 (0%)]\tBatch Loss: 1086.382122\tLearning Rate (w_theta): 0.001000\t TIME:2147.7s\n",
      "\t\t\t\tDisc: 1.231896\t\tSym: 18.770222\t\tSpars: 1066.380005\n",
      "\t TVw: -0.448882 | TVb: -2.043522 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1545 [4000/8000 (50%)]\tBatch Loss: 1056.684125\tLearning Rate (w_theta): 0.001000\t TIME:2149.3s\n",
      "\t\t\t\tDisc: 1.308249\t\tSym: 18.482809\t\tSpars: 1036.893066\n",
      "\t TVw: -0.448695 | TVb: -2.043522 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1545...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1051.2267552579888\n",
      "Average validation loss: 160.90084534182404\n",
      "Training epoch 1546...\n",
      "\n",
      "Train Epoch: 1546 [0/8000 (0%)]\tBatch Loss: 1028.934126\tLearning Rate (w_theta): 0.001000\t TIME:2151.6s\n",
      "\t\t\t\tDisc: 1.219437\t\tSym: 17.352324\t\tSpars: 1010.362366\n",
      "\t TVw: -0.448509 | TVb: -2.043523 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1546 [4000/8000 (50%)]\tBatch Loss: 1072.421177\tLearning Rate (w_theta): 0.001000\t TIME:2153.1s\n",
      "\t\t\t\tDisc: 1.299101\t\tSym: 19.504400\t\tSpars: 1051.617676\n",
      "\t TVw: -0.448323 | TVb: -2.043524 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1546...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1049.3989072369852\n",
      "Average validation loss: 161.46282400560472\n",
      "Training epoch 1547...\n",
      "\n",
      "Train Epoch: 1547 [0/8000 (0%)]\tBatch Loss: 1045.475088\tLearning Rate (w_theta): 0.001000\t TIME:2155.5s\n",
      "\t\t\t\tDisc: 1.310453\t\tSym: 18.265953\t\tSpars: 1025.898682\n",
      "\t TVw: -0.448138 | TVb: -2.043525 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1547 [4000/8000 (50%)]\tBatch Loss: 1072.574273\tLearning Rate (w_theta): 0.001000\t TIME:2157.0s\n",
      "\t\t\t\tDisc: 1.325295\t\tSym: 19.939163\t\tSpars: 1051.309814\n",
      "\t TVw: -0.447953 | TVb: -2.043525 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1547...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1050.7292314579972\n",
      "Average validation loss: 164.0697635009844\n",
      "Training epoch 1548...\n",
      "\n",
      "Train Epoch: 1548 [0/8000 (0%)]\tBatch Loss: 1110.917233\tLearning Rate (w_theta): 0.001000\t TIME:2159.3s\n",
      "\t\t\t\tDisc: 1.181149\t\tSym: 20.960327\t\tSpars: 1088.775757\n",
      "\t TVw: -0.447768 | TVb: -2.043526 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1548 [4000/8000 (50%)]\tBatch Loss: 1055.494621\tLearning Rate (w_theta): 0.001000\t TIME:2160.9s\n",
      "\t\t\t\tDisc: 1.292574\t\tSym: 18.573263\t\tSpars: 1035.628784\n",
      "\t TVw: -0.447592 | TVb: -2.043527 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1548...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1068.4774478155882\n",
      "Average validation loss: 161.64446771360824\n",
      "Training epoch 1549...\n",
      "\n",
      "Train Epoch: 1549 [0/8000 (0%)]\tBatch Loss: 1050.546629\tLearning Rate (w_theta): 0.001000\t TIME:2163.3s\n",
      "\t\t\t\tDisc: 1.247367\t\tSym: 17.797674\t\tSpars: 1031.501587\n",
      "\t TVw: -0.447413 | TVb: -2.043528 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1549 [4000/8000 (50%)]\tBatch Loss: 1055.842112\tLearning Rate (w_theta): 0.001000\t TIME:2164.8s\n",
      "\t\t\t\tDisc: 1.266751\t\tSym: 17.794966\t\tSpars: 1036.780396\n",
      "\t TVw: -0.447231 | TVb: -2.043529 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1549...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1051.9895554111474\n",
      "Average validation loss: 161.48642822031982\n",
      "Training epoch 1550...\n",
      "\n",
      "Train Epoch: 1550 [0/8000 (0%)]\tBatch Loss: 1059.733407\tLearning Rate (w_theta): 0.001000\t TIME:2167.1s\n",
      "\t\t\t\tDisc: 1.218807\t\tSym: 19.157301\t\tSpars: 1039.357300\n",
      "\t TVw: -0.447045 | TVb: -2.043530 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1550 [4000/8000 (50%)]\tBatch Loss: 1030.901505\tLearning Rate (w_theta): 0.001000\t TIME:2168.7s\n",
      "\t\t\t\tDisc: 1.173390\t\tSym: 17.413723\t\tSpars: 1012.314392\n",
      "\t TVw: -0.446855 | TVb: -2.043531 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1550...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1048.3619616242704\n",
      "Average validation loss: 160.6438000369772\n",
      "Training epoch 1551...\n",
      "\n",
      "Train Epoch: 1551 [0/8000 (0%)]\tBatch Loss: 1027.689619\tLearning Rate (w_theta): 0.001000\t TIME:2171.8s\n",
      "\t\t\t\tDisc: 1.237232\t\tSym: 17.681452\t\tSpars: 1008.770935\n",
      "\t TVw: -0.446663 | TVb: -2.043532 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1551 [4000/8000 (50%)]\tBatch Loss: 1082.257402\tLearning Rate (w_theta): 0.001000\t TIME:2173.4s\n",
      "\t\t\t\tDisc: 1.373865\t\tSym: 19.507317\t\tSpars: 1061.376221\n",
      "\t TVw: -0.446471 | TVb: -2.043532 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1551...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1048.332476619808\n",
      "Average validation loss: 161.09180359244777\n",
      "Training epoch 1552...\n",
      "\n",
      "Train Epoch: 1552 [0/8000 (0%)]\tBatch Loss: 1011.115130\tLearning Rate (w_theta): 0.001000\t TIME:2175.7s\n",
      "\t\t\t\tDisc: 1.221779\t\tSym: 15.912455\t\tSpars: 993.980896\n",
      "\t TVw: -0.446282 | TVb: -2.043533 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1552 [4000/8000 (50%)]\tBatch Loss: 1080.523115\tLearning Rate (w_theta): 0.001000\t TIME:2177.2s\n",
      "\t\t\t\tDisc: 1.318125\t\tSym: 20.423496\t\tSpars: 1058.781494\n",
      "\t TVw: -0.446093 | TVb: -2.043534 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1552...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1046.86029292009\n",
      "Average validation loss: 161.8603477892502\n",
      "Training epoch 1553...\n",
      "\n",
      "Train Epoch: 1553 [0/8000 (0%)]\tBatch Loss: 1061.186919\tLearning Rate (w_theta): 0.001000\t TIME:2179.6s\n",
      "\t\t\t\tDisc: 1.292090\t\tSym: 18.703545\t\tSpars: 1041.191284\n",
      "\t TVw: -0.445904 | TVb: -2.043535 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1553 [4000/8000 (50%)]\tBatch Loss: 1009.319523\tLearning Rate (w_theta): 0.001000\t TIME:2181.1s\n",
      "\t\t\t\tDisc: 1.219847\t\tSym: 16.033880\t\tSpars: 992.065796\n",
      "\t TVw: -0.445717 | TVb: -2.043536 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1553...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1046.0079372894284\n",
      "Average validation loss: 160.65845683357753\n",
      "Training epoch 1554...\n",
      "\n",
      "Train Epoch: 1554 [0/8000 (0%)]\tBatch Loss: 1024.420166\tLearning Rate (w_theta): 0.001000\t TIME:2183.4s\n",
      "\t\t\t\tDisc: 1.200057\t\tSym: 17.418352\t\tSpars: 1005.801758\n",
      "\t TVw: -0.445529 | TVb: -2.043537 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1554 [4000/8000 (50%)]\tBatch Loss: 1090.010758\tLearning Rate (w_theta): 0.001000\t TIME:2185.0s\n",
      "\t\t\t\tDisc: 1.354918\t\tSym: 19.752275\t\tSpars: 1068.903564\n",
      "\t TVw: -0.445342 | TVb: -2.043538 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "Validating epoch 1554...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1047.866350876671\n",
      "Average validation loss: 162.12816542973945\n",
      "Training epoch 1555...\n",
      "\n",
      "Train Epoch: 1555 [0/8000 (0%)]\tBatch Loss: 1068.105938\tLearning Rate (w_theta): 0.001000\t TIME:2187.3s\n",
      "\t\t\t\tDisc: 1.272442\t\tSym: 19.034424\t\tSpars: 1047.799072\n",
      "\t TVw: -0.445156 | TVb: -2.043539 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034767\n",
      "\n",
      "Train Epoch: 1555 [4000/8000 (50%)]\tBatch Loss: 1042.270452\tLearning Rate (w_theta): 0.001000\t TIME:2188.8s\n",
      "\t\t\t\tDisc: 1.385970\t\tSym: 17.859457\t\tSpars: 1023.025024\n",
      "\t TVw: -0.444967 | TVb: -2.043540 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1555...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1055.7536918249355\n",
      "Average validation loss: 160.8262294281094\n",
      "Training epoch 1556...\n",
      "\n",
      "Train Epoch: 1556 [0/8000 (0%)]\tBatch Loss: 1069.163048\tLearning Rate (w_theta): 0.001000\t TIME:2191.2s\n",
      "\t\t\t\tDisc: 1.299028\t\tSym: 18.931036\t\tSpars: 1048.932983\n",
      "\t TVw: -0.444780 | TVb: -2.043542 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1556 [4000/8000 (50%)]\tBatch Loss: 1133.747384\tLearning Rate (w_theta): 0.001000\t TIME:2192.7s\n",
      "\t\t\t\tDisc: 1.602504\t\tSym: 23.153303\t\tSpars: 1108.991577\n",
      "\t TVw: -0.444588 | TVb: -2.043542 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1556...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1056.1124545402492\n",
      "Average validation loss: 163.25862048552378\n",
      "Training epoch 1557...\n",
      "\n",
      "Train Epoch: 1557 [0/8000 (0%)]\tBatch Loss: 1045.269022\tLearning Rate (w_theta): 0.001000\t TIME:2195.2s\n",
      "\t\t\t\tDisc: 1.237660\t\tSym: 18.757437\t\tSpars: 1025.273926\n",
      "\t TVw: -0.444398 | TVb: -2.043543 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1557 [4000/8000 (50%)]\tBatch Loss: 1043.307043\tLearning Rate (w_theta): 0.001000\t TIME:2196.7s\n",
      "\t\t\t\tDisc: 1.236174\t\tSym: 18.416145\t\tSpars: 1023.654724\n",
      "\t TVw: -0.444209 | TVb: -2.043544 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1557...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1052.7927340558947\n",
      "Average validation loss: 161.01950170699996\n",
      "Training epoch 1558...\n",
      "\n",
      "Train Epoch: 1558 [0/8000 (0%)]\tBatch Loss: 1053.431688\tLearning Rate (w_theta): 0.001000\t TIME:2199.1s\n",
      "\t\t\t\tDisc: 1.274715\t\tSym: 18.970205\t\tSpars: 1033.186768\n",
      "\t TVw: -0.444016 | TVb: -2.043545 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1558 [4000/8000 (50%)]\tBatch Loss: 1079.564235\tLearning Rate (w_theta): 0.001000\t TIME:2200.6s\n",
      "\t\t\t\tDisc: 1.371433\t\tSym: 20.700737\t\tSpars: 1057.492065\n",
      "\t TVw: -0.443817 | TVb: -2.043546 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1558...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1050.2406394899974\n",
      "Average validation loss: 162.60944076659726\n",
      "Training epoch 1559...\n",
      "\n",
      "Train Epoch: 1559 [0/8000 (0%)]\tBatch Loss: 1051.596407\tLearning Rate (w_theta): 0.001000\t TIME:2202.9s\n",
      "\t\t\t\tDisc: 1.171123\t\tSym: 18.770376\t\tSpars: 1031.654907\n",
      "\t TVw: -0.443621 | TVb: -2.043546 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1559 [4000/8000 (50%)]\tBatch Loss: 1048.032544\tLearning Rate (w_theta): 0.001000\t TIME:2204.5s\n",
      "\t\t\t\tDisc: 1.252804\t\tSym: 18.965408\t\tSpars: 1027.814331\n",
      "\t TVw: -0.443428 | TVb: -2.043547 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1559...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1052.363682093754\n",
      "Average validation loss: 161.51559245603272\n",
      "Training epoch 1560...\n",
      "\n",
      "Train Epoch: 1560 [0/8000 (0%)]\tBatch Loss: 995.431923\tLearning Rate (w_theta): 0.001000\t TIME:2206.8s\n",
      "\t\t\t\tDisc: 1.126695\t\tSym: 15.447928\t\tSpars: 978.857300\n",
      "\t TVw: -0.443233 | TVb: -2.043548 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1560 [4000/8000 (50%)]\tBatch Loss: 1085.011209\tLearning Rate (w_theta): 0.001000\t TIME:2208.4s\n",
      "\t\t\t\tDisc: 1.388732\t\tSym: 20.134317\t\tSpars: 1063.488159\n",
      "\t TVw: -0.443036 | TVb: -2.043549 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1560...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1048.5471170435865\n",
      "Average validation loss: 162.1161121875005\n",
      "Training epoch 1561...\n",
      "\n",
      "Train Epoch: 1561 [0/8000 (0%)]\tBatch Loss: 1021.481853\tLearning Rate (w_theta): 0.001000\t TIME:2211.4s\n",
      "\t\t\t\tDisc: 1.098480\t\tSym: 16.814892\t\tSpars: 1003.568481\n",
      "\t TVw: -0.442840 | TVb: -2.043550 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1561 [4000/8000 (50%)]\tBatch Loss: 1066.390124\tLearning Rate (w_theta): 0.001000\t TIME:2212.9s\n",
      "\t\t\t\tDisc: 1.272426\t\tSym: 17.950218\t\tSpars: 1047.167480\n",
      "\t TVw: -0.442645 | TVb: -2.043550 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1561...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1055.4611215795692\n",
      "Average validation loss: 160.66704147579\n",
      "Training epoch 1562...\n",
      "\n",
      "Train Epoch: 1562 [0/8000 (0%)]\tBatch Loss: 1041.070929\tLearning Rate (w_theta): 0.001000\t TIME:2215.3s\n",
      "\t\t\t\tDisc: 1.177232\t\tSym: 16.928061\t\tSpars: 1022.965637\n",
      "\t TVw: -0.442450 | TVb: -2.043551 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1562 [4000/8000 (50%)]\tBatch Loss: 1084.484435\tLearning Rate (w_theta): 0.001000\t TIME:2216.8s\n",
      "\t\t\t\tDisc: 1.400279\t\tSym: 19.011646\t\tSpars: 1064.072510\n",
      "\t TVw: -0.442255 | TVb: -2.043552 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1562...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1056.524154045257\n",
      "Average validation loss: 160.40807041128926\n",
      "Training epoch 1563...\n",
      "\n",
      "Train Epoch: 1563 [0/8000 (0%)]\tBatch Loss: 1022.273914\tLearning Rate (w_theta): 0.001000\t TIME:2219.3s\n",
      "\t\t\t\tDisc: 1.211717\t\tSym: 16.359804\t\tSpars: 1004.702393\n",
      "\t TVw: -0.442061 | TVb: -2.043554 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1563 [4000/8000 (50%)]\tBatch Loss: 1077.720909\tLearning Rate (w_theta): 0.001000\t TIME:2220.9s\n",
      "\t\t\t\tDisc: 1.322221\t\tSym: 19.835333\t\tSpars: 1056.563354\n",
      "\t TVw: -0.441862 | TVb: -2.043554 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1563...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1050.6639628963437\n",
      "Average validation loss: 162.05144763123417\n",
      "Training epoch 1564...\n",
      "\n",
      "Train Epoch: 1564 [0/8000 (0%)]\tBatch Loss: 1070.969556\tLearning Rate (w_theta): 0.001000\t TIME:2223.2s\n",
      "\t\t\t\tDisc: 1.274840\t\tSym: 20.024061\t\tSpars: 1049.670654\n",
      "\t TVw: -0.441667 | TVb: -2.043555 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1564 [4000/8000 (50%)]\tBatch Loss: 1046.679168\tLearning Rate (w_theta): 0.001000\t TIME:2224.8s\n",
      "\t\t\t\tDisc: 1.290082\t\tSym: 17.598680\t\tSpars: 1027.790405\n",
      "\t TVw: -0.441469 | TVb: -2.043556 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1564...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1043.6920654774292\n",
      "Average validation loss: 161.37668870577664\n",
      "Training epoch 1565...\n",
      "\n",
      "Train Epoch: 1565 [0/8000 (0%)]\tBatch Loss: 1013.276162\tLearning Rate (w_theta): 0.001000\t TIME:2227.1s\n",
      "\t\t\t\tDisc: 1.097385\t\tSym: 17.596319\t\tSpars: 994.582458\n",
      "\t TVw: -0.441267 | TVb: -2.043557 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1565 [4000/8000 (50%)]\tBatch Loss: 1032.546697\tLearning Rate (w_theta): 0.001000\t TIME:2228.6s\n",
      "\t\t\t\tDisc: 1.170564\t\tSym: 16.659824\t\tSpars: 1014.716309\n",
      "\t TVw: -0.441063 | TVb: -2.043558 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1565...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1044.875034935071\n",
      "Average validation loss: 161.33795624302368\n",
      "Training epoch 1566...\n",
      "\n",
      "Train Epoch: 1566 [0/8000 (0%)]\tBatch Loss: 1051.567568\tLearning Rate (w_theta): 0.001000\t TIME:2231.0s\n",
      "\t\t\t\tDisc: 1.275231\t\tSym: 18.386454\t\tSpars: 1031.905884\n",
      "\t TVw: -0.440859 | TVb: -2.043558 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1566 [4000/8000 (50%)]\tBatch Loss: 1041.781690\tLearning Rate (w_theta): 0.001000\t TIME:2232.5s\n",
      "\t\t\t\tDisc: 1.234970\t\tSym: 17.429289\t\tSpars: 1023.117432\n",
      "\t TVw: -0.440656 | TVb: -2.043559 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1566...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1041.8505187233977\n",
      "Average validation loss: 159.88871710203583\n",
      "Training epoch 1567...\n",
      "\n",
      "Train Epoch: 1567 [0/8000 (0%)]\tBatch Loss: 1006.863250\tLearning Rate (w_theta): 0.001000\t TIME:2234.8s\n",
      "\t\t\t\tDisc: 1.118808\t\tSym: 16.538143\t\tSpars: 989.206299\n",
      "\t TVw: -0.440451 | TVb: -2.043559 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1567 [4000/8000 (50%)]\tBatch Loss: 1026.659590\tLearning Rate (w_theta): 0.001000\t TIME:2236.4s\n",
      "\t\t\t\tDisc: 1.213248\t\tSym: 16.197624\t\tSpars: 1009.248718\n",
      "\t TVw: -0.440246 | TVb: -2.043560 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1567...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1041.8432366864847\n",
      "Average validation loss: 160.82307957786892\n",
      "Training epoch 1568...\n",
      "\n",
      "Train Epoch: 1568 [0/8000 (0%)]\tBatch Loss: 1009.240378\tLearning Rate (w_theta): 0.001000\t TIME:2238.7s\n",
      "\t\t\t\tDisc: 1.123082\t\tSym: 15.814013\t\tSpars: 992.303284\n",
      "\t TVw: -0.440042 | TVb: -2.043561 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1568 [4000/8000 (50%)]\tBatch Loss: 1070.791068\tLearning Rate (w_theta): 0.001000\t TIME:2240.2s\n",
      "\t\t\t\tDisc: 1.352963\t\tSym: 19.693598\t\tSpars: 1049.744507\n",
      "\t TVw: -0.439840 | TVb: -2.043561 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1568...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1041.588812153486\n",
      "Average validation loss: 160.51041356228626\n",
      "Training epoch 1569...\n",
      "\n",
      "Train Epoch: 1569 [0/8000 (0%)]\tBatch Loss: 1045.235725\tLearning Rate (w_theta): 0.001000\t TIME:2242.6s\n",
      "\t\t\t\tDisc: 1.240646\t\tSym: 19.039513\t\tSpars: 1024.955566\n",
      "\t TVw: -0.439637 | TVb: -2.043562 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1569 [4000/8000 (50%)]\tBatch Loss: 1079.906403\tLearning Rate (w_theta): 0.001000\t TIME:2244.1s\n",
      "\t\t\t\tDisc: 1.156710\t\tSym: 19.600645\t\tSpars: 1059.149048\n",
      "\t TVw: -0.439440 | TVb: -2.043563 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1569...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1050.873046107604\n",
      "Average validation loss: 161.46222137804224\n",
      "Training epoch 1570...\n",
      "\n",
      "Train Epoch: 1570 [0/8000 (0%)]\tBatch Loss: 1059.589719\tLearning Rate (w_theta): 0.001000\t TIME:2246.5s\n",
      "\t\t\t\tDisc: 1.225011\t\tSym: 18.697716\t\tSpars: 1039.666992\n",
      "\t TVw: -0.439242 | TVb: -2.043564 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1570 [4000/8000 (50%)]\tBatch Loss: 1034.995055\tLearning Rate (w_theta): 0.001000\t TIME:2248.0s\n",
      "\t\t\t\tDisc: 1.315774\t\tSym: 18.504965\t\tSpars: 1015.174316\n",
      "\t TVw: -0.439045 | TVb: -2.043565 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1570...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1063.20725191884\n",
      "Average validation loss: 160.5970126734248\n",
      "Training epoch 1571...\n",
      "\n",
      "Train Epoch: 1571 [0/8000 (0%)]\tBatch Loss: 1069.163953\tLearning Rate (w_theta): 0.001000\t TIME:2251.1s\n",
      "\t\t\t\tDisc: 1.267188\t\tSym: 19.755041\t\tSpars: 1048.141724\n",
      "\t TVw: -0.438844 | TVb: -2.043566 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1571 [4000/8000 (50%)]\tBatch Loss: 1003.163547\tLearning Rate (w_theta): 0.001000\t TIME:2252.7s\n",
      "\t\t\t\tDisc: 1.156083\t\tSym: 15.791705\t\tSpars: 986.215759\n",
      "\t TVw: -0.438641 | TVb: -2.043566 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1571...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1053.877792801432\n",
      "Average validation loss: 160.3810326913634\n",
      "Training epoch 1572...\n",
      "\n",
      "Train Epoch: 1572 [0/8000 (0%)]\tBatch Loss: 1015.812241\tLearning Rate (w_theta): 0.001000\t TIME:2255.0s\n",
      "\t\t\t\tDisc: 1.123489\t\tSym: 16.433990\t\tSpars: 998.254761\n",
      "\t TVw: -0.438438 | TVb: -2.043567 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1572 [4000/8000 (50%)]\tBatch Loss: 1065.737821\tLearning Rate (w_theta): 0.001000\t TIME:2256.6s\n",
      "\t\t\t\tDisc: 1.294612\t\tSym: 17.838717\t\tSpars: 1046.604492\n",
      "\t TVw: -0.438236 | TVb: -2.043568 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1572...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1048.598858124683\n",
      "Average validation loss: 159.14649364688879\n",
      "Training epoch 1573...\n",
      "\n",
      "Train Epoch: 1573 [0/8000 (0%)]\tBatch Loss: 1044.145948\tLearning Rate (w_theta): 0.001000\t TIME:2258.9s\n",
      "\t\t\t\tDisc: 1.288702\t\tSym: 17.405830\t\tSpars: 1025.451416\n",
      "\t TVw: -0.438032 | TVb: -2.043569 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1573 [4000/8000 (50%)]\tBatch Loss: 1076.820871\tLearning Rate (w_theta): 0.001000\t TIME:2260.5s\n",
      "\t\t\t\tDisc: 1.426771\t\tSym: 20.434994\t\tSpars: 1054.959106\n",
      "\t TVw: -0.437825 | TVb: -2.043569 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1573...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1044.9581054726386\n",
      "Average validation loss: 160.13513213137068\n",
      "Training epoch 1574...\n",
      "\n",
      "Train Epoch: 1574 [0/8000 (0%)]\tBatch Loss: 1015.204506\tLearning Rate (w_theta): 0.001000\t TIME:2262.8s\n",
      "\t\t\t\tDisc: 1.199150\t\tSym: 16.866501\t\tSpars: 997.138855\n",
      "\t TVw: -0.437615 | TVb: -2.043569 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1574 [4000/8000 (50%)]\tBatch Loss: 1071.588823\tLearning Rate (w_theta): 0.001000\t TIME:2264.3s\n",
      "\t\t\t\tDisc: 1.364635\t\tSym: 20.124090\t\tSpars: 1050.100098\n",
      "\t TVw: -0.437404 | TVb: -2.043569 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1574...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1038.4507711964354\n",
      "Average validation loss: 158.869180892456\n",
      "Training epoch 1575...\n",
      "\n",
      "Train Epoch: 1575 [0/8000 (0%)]\tBatch Loss: 1013.431298\tLearning Rate (w_theta): 0.001000\t TIME:2266.7s\n",
      "\t\t\t\tDisc: 1.159861\t\tSym: 18.020948\t\tSpars: 994.250488\n",
      "\t TVw: -0.437188 | TVb: -2.043569 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1575 [4000/8000 (50%)]\tBatch Loss: 1050.681594\tLearning Rate (w_theta): 0.001000\t TIME:2268.2s\n",
      "\t\t\t\tDisc: 1.269658\t\tSym: 17.845163\t\tSpars: 1031.566772\n",
      "\t TVw: -0.436974 | TVb: -2.043570 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1575...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1043.876629159793\n",
      "Average validation loss: 157.55290756376957\n",
      "Training epoch 1576...\n",
      "\n",
      "Train Epoch: 1576 [0/8000 (0%)]\tBatch Loss: 1068.819012\tLearning Rate (w_theta): 0.001000\t TIME:2270.5s\n",
      "\t\t\t\tDisc: 1.365873\t\tSym: 19.083754\t\tSpars: 1048.369385\n",
      "\t TVw: -0.436764 | TVb: -2.043570 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1576 [4000/8000 (50%)]\tBatch Loss: 1021.492916\tLearning Rate (w_theta): 0.001000\t TIME:2272.1s\n",
      "\t\t\t\tDisc: 1.164018\t\tSym: 16.888895\t\tSpars: 1003.440002\n",
      "\t TVw: -0.436556 | TVb: -2.043571 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1576...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1044.0994284547303\n",
      "Average validation loss: 159.34826197911732\n",
      "Training epoch 1577...\n",
      "\n",
      "Train Epoch: 1577 [0/8000 (0%)]\tBatch Loss: 1046.915627\tLearning Rate (w_theta): 0.001000\t TIME:2274.6s\n",
      "\t\t\t\tDisc: 1.271960\t\tSym: 17.845816\t\tSpars: 1027.797852\n",
      "\t TVw: -0.436347 | TVb: -2.043572 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1577 [4000/8000 (50%)]\tBatch Loss: 1089.967279\tLearning Rate (w_theta): 0.001000\t TIME:2276.2s\n",
      "\t\t\t\tDisc: 1.214370\t\tSym: 20.626322\t\tSpars: 1068.126587\n",
      "\t TVw: -0.436138 | TVb: -2.043573 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1577...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1045.1851441189556\n",
      "Average validation loss: 161.26477353159805\n",
      "Training epoch 1578...\n",
      "\n",
      "Train Epoch: 1578 [0/8000 (0%)]\tBatch Loss: 1060.526451\tLearning Rate (w_theta): 0.001000\t TIME:2278.5s\n",
      "\t\t\t\tDisc: 1.195703\t\tSym: 18.653257\t\tSpars: 1040.677490\n",
      "\t TVw: -0.435928 | TVb: -2.043573 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1578 [4000/8000 (50%)]\tBatch Loss: 1008.569912\tLearning Rate (w_theta): 0.001000\t TIME:2280.0s\n",
      "\t\t\t\tDisc: 1.173611\t\tSym: 16.588013\t\tSpars: 990.808289\n",
      "\t TVw: -0.435717 | TVb: -2.043574 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1578...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1041.7695181052707\n",
      "Average validation loss: 158.4101940267528\n",
      "Training epoch 1579...\n",
      "\n",
      "Train Epoch: 1579 [0/8000 (0%)]\tBatch Loss: 1023.832138\tLearning Rate (w_theta): 0.001000\t TIME:2282.3s\n",
      "\t\t\t\tDisc: 1.195968\t\tSym: 16.970764\t\tSpars: 1005.665405\n",
      "\t TVw: -0.435505 | TVb: -2.043575 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1579 [4000/8000 (50%)]\tBatch Loss: 1050.751328\tLearning Rate (w_theta): 0.001000\t TIME:2283.9s\n",
      "\t\t\t\tDisc: 1.299296\t\tSym: 20.074224\t\tSpars: 1029.377808\n",
      "\t TVw: -0.435289 | TVb: -2.043575 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1579...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1038.1289603035084\n",
      "Average validation loss: 159.64267602591107\n",
      "Training epoch 1580...\n",
      "\n",
      "Train Epoch: 1580 [0/8000 (0%)]\tBatch Loss: 1083.854334\tLearning Rate (w_theta): 0.001000\t TIME:2286.2s\n",
      "\t\t\t\tDisc: 1.477978\t\tSym: 21.099012\t\tSpars: 1061.277344\n",
      "\t TVw: -0.435072 | TVb: -2.043576 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1580 [4000/8000 (50%)]\tBatch Loss: 1051.161627\tLearning Rate (w_theta): 0.001000\t TIME:2287.7s\n",
      "\t\t\t\tDisc: 1.229271\t\tSym: 18.092024\t\tSpars: 1031.840332\n",
      "\t TVw: -0.434859 | TVb: -2.043576 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1580...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1042.375016692961\n",
      "Average validation loss: 158.87500034552434\n",
      "Training epoch 1581...\n",
      "\n",
      "Train Epoch: 1581 [0/8000 (0%)]\tBatch Loss: 995.869346\tLearning Rate (w_theta): 0.001000\t TIME:2290.8s\n",
      "\t\t\t\tDisc: 1.185064\t\tSym: 15.905718\t\tSpars: 978.778564\n",
      "\t TVw: -0.434647 | TVb: -2.043577 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1581 [4000/8000 (50%)]\tBatch Loss: 1023.505580\tLearning Rate (w_theta): 0.001000\t TIME:2292.3s\n",
      "\t\t\t\tDisc: 1.172876\t\tSym: 17.582460\t\tSpars: 1004.750244\n",
      "\t TVw: -0.434433 | TVb: -2.043578 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1581...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1036.0753951474435\n",
      "Average validation loss: 158.91965512415914\n",
      "Training epoch 1582...\n",
      "\n",
      "Train Epoch: 1582 [0/8000 (0%)]\tBatch Loss: 1045.267038\tLearning Rate (w_theta): 0.001000\t TIME:2294.6s\n",
      "\t\t\t\tDisc: 1.193303\t\tSym: 18.201908\t\tSpars: 1025.871826\n",
      "\t TVw: -0.434220 | TVb: -2.043579 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1582 [4000/8000 (50%)]\tBatch Loss: 1063.325762\tLearning Rate (w_theta): 0.001000\t TIME:2296.2s\n",
      "\t\t\t\tDisc: 1.265286\t\tSym: 19.095266\t\tSpars: 1042.965210\n",
      "\t TVw: -0.434007 | TVb: -2.043579 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1582...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1038.2714332013807\n",
      "Average validation loss: 157.56374356329792\n",
      "Training epoch 1583...\n",
      "\n",
      "Train Epoch: 1583 [0/8000 (0%)]\tBatch Loss: 1036.232844\tLearning Rate (w_theta): 0.001000\t TIME:2298.7s\n",
      "\t\t\t\tDisc: 1.240129\t\tSym: 17.915079\t\tSpars: 1017.077637\n",
      "\t TVw: -0.433794 | TVb: -2.043580 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1583 [4000/8000 (50%)]\tBatch Loss: 1086.984941\tLearning Rate (w_theta): 0.001000\t TIME:2300.2s\n",
      "\t\t\t\tDisc: 1.403951\t\tSym: 19.312679\t\tSpars: 1066.268311\n",
      "\t TVw: -0.433579 | TVb: -2.043581 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1583...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1037.3491484128929\n",
      "Average validation loss: 158.6599925952156\n",
      "Training epoch 1584...\n",
      "\n",
      "Train Epoch: 1584 [0/8000 (0%)]\tBatch Loss: 1000.675716\tLearning Rate (w_theta): 0.001000\t TIME:2302.6s\n",
      "\t\t\t\tDisc: 1.153482\t\tSym: 16.248247\t\tSpars: 983.273987\n",
      "\t TVw: -0.433363 | TVb: -2.043582 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1584 [4000/8000 (50%)]\tBatch Loss: 1043.203112\tLearning Rate (w_theta): 0.001000\t TIME:2304.1s\n",
      "\t\t\t\tDisc: 1.147098\t\tSym: 17.642683\t\tSpars: 1024.413330\n",
      "\t TVw: -0.433146 | TVb: -2.043583 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1584...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1039.8312725040364\n",
      "Average validation loss: 159.74524404642494\n",
      "Training epoch 1585...\n",
      "\n",
      "Train Epoch: 1585 [0/8000 (0%)]\tBatch Loss: 1029.405295\tLearning Rate (w_theta): 0.001000\t TIME:2306.5s\n",
      "\t\t\t\tDisc: 1.219298\t\tSym: 17.284386\t\tSpars: 1010.901611\n",
      "\t TVw: -0.432929 | TVb: -2.043584 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1585 [4000/8000 (50%)]\tBatch Loss: 1056.226176\tLearning Rate (w_theta): 0.001000\t TIME:2308.0s\n",
      "\t\t\t\tDisc: 1.261874\t\tSym: 17.847359\t\tSpars: 1037.116943\n",
      "\t TVw: -0.432714 | TVb: -2.043585 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1585...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1040.4187261591883\n",
      "Average validation loss: 158.39888615682798\n",
      "Training epoch 1586...\n",
      "\n",
      "Train Epoch: 1586 [0/8000 (0%)]\tBatch Loss: 975.893063\tLearning Rate (w_theta): 0.001000\t TIME:2310.4s\n",
      "\t\t\t\tDisc: 1.018124\t\tSym: 14.589661\t\tSpars: 960.285278\n",
      "\t TVw: -0.432501 | TVb: -2.043586 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1586 [4000/8000 (50%)]\tBatch Loss: 1053.977833\tLearning Rate (w_theta): 0.001000\t TIME:2311.9s\n",
      "\t\t\t\tDisc: 1.315312\t\tSym: 18.889938\t\tSpars: 1033.772583\n",
      "\t TVw: -0.432287 | TVb: -2.043586 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1586...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1041.018401496626\n",
      "Average validation loss: 160.76389643485683\n",
      "Training epoch 1587...\n",
      "\n",
      "Train Epoch: 1587 [0/8000 (0%)]\tBatch Loss: 1019.848111\tLearning Rate (w_theta): 0.001000\t TIME:2314.3s\n",
      "\t\t\t\tDisc: 1.003000\t\tSym: 16.387592\t\tSpars: 1002.457520\n",
      "\t TVw: -0.432074 | TVb: -2.043587 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1587 [4000/8000 (50%)]\tBatch Loss: 1035.764879\tLearning Rate (w_theta): 0.001000\t TIME:2315.8s\n",
      "\t\t\t\tDisc: 1.300535\t\tSym: 17.498951\t\tSpars: 1016.965393\n",
      "\t TVw: -0.431860 | TVb: -2.043588 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1587...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1037.4610269705508\n",
      "Average validation loss: 157.00041704940801\n",
      "Training epoch 1588...\n",
      "\n",
      "Train Epoch: 1588 [0/8000 (0%)]\tBatch Loss: 1058.981453\tLearning Rate (w_theta): 0.001000\t TIME:2318.1s\n",
      "\t\t\t\tDisc: 1.385676\t\tSym: 18.369215\t\tSpars: 1039.226562\n",
      "\t TVw: -0.431643 | TVb: -2.043589 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "\n",
      "Train Epoch: 1588 [4000/8000 (50%)]\tBatch Loss: 1039.045869\tLearning Rate (w_theta): 0.001000\t TIME:2319.7s\n",
      "\t\t\t\tDisc: 1.246758\t\tSym: 17.541359\t\tSpars: 1020.257751\n",
      "\t TVw: -0.431432 | TVb: -2.043591 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034768\n",
      "Validating epoch 1588...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1038.7207794109556\n",
      "Average validation loss: 158.3349145415482\n",
      "Training epoch 1589...\n",
      "\n",
      "Train Epoch: 1589 [0/8000 (0%)]\tBatch Loss: 1012.389889\tLearning Rate (w_theta): 0.001000\t TIME:2322.0s\n",
      "\t\t\t\tDisc: 1.253646\t\tSym: 17.183424\t\tSpars: 993.952820\n",
      "\t TVw: -0.431218 | TVb: -2.043592 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1589 [4000/8000 (50%)]\tBatch Loss: 992.302985\tLearning Rate (w_theta): 0.001000\t TIME:2323.6s\n",
      "\t\t\t\tDisc: 1.126725\t\tSym: 16.132559\t\tSpars: 975.043701\n",
      "\t TVw: -0.431000 | TVb: -2.043592 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1589...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1031.2006193195978\n",
      "Average validation loss: 157.98512132140291\n",
      "Training epoch 1590...\n",
      "\n",
      "Train Epoch: 1590 [0/8000 (0%)]\tBatch Loss: 1041.439599\tLearning Rate (w_theta): 0.001000\t TIME:2326.1s\n",
      "\t\t\t\tDisc: 1.133176\t\tSym: 18.780544\t\tSpars: 1021.525879\n",
      "\t TVw: -0.430777 | TVb: -2.043592 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1590 [4000/8000 (50%)]\tBatch Loss: 1053.364747\tLearning Rate (w_theta): 0.001000\t TIME:2327.7s\n",
      "\t\t\t\tDisc: 1.304936\t\tSym: 18.882198\t\tSpars: 1033.177612\n",
      "\t TVw: -0.430554 | TVb: -2.043592 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1590...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1029.2843063570385\n",
      "Average validation loss: 157.49744998987651\n",
      "Training epoch 1591...\n",
      "\n",
      "Train Epoch: 1591 [0/8000 (0%)]\tBatch Loss: 1036.174177\tLearning Rate (w_theta): 0.001000\t TIME:2330.7s\n",
      "\t\t\t\tDisc: 1.293586\t\tSym: 17.791784\t\tSpars: 1017.088806\n",
      "\t TVw: -0.430331 | TVb: -2.043593 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1591 [4000/8000 (50%)]\tBatch Loss: 1052.723218\tLearning Rate (w_theta): 0.001000\t TIME:2332.2s\n",
      "\t\t\t\tDisc: 1.252934\t\tSym: 18.795601\t\tSpars: 1032.674683\n",
      "\t TVw: -0.430109 | TVb: -2.043595 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1591...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1031.593296824672\n",
      "Average validation loss: 156.65444401572353\n",
      "Training epoch 1592...\n",
      "\n",
      "Train Epoch: 1592 [0/8000 (0%)]\tBatch Loss: 1017.534237\tLearning Rate (w_theta): 0.001000\t TIME:2334.5s\n",
      "\t\t\t\tDisc: 1.184343\t\tSym: 17.115335\t\tSpars: 999.234558\n",
      "\t TVw: -0.429891 | TVb: -2.043596 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1592 [4000/8000 (50%)]\tBatch Loss: 1036.440191\tLearning Rate (w_theta): 0.001000\t TIME:2336.0s\n",
      "\t\t\t\tDisc: 1.360832\t\tSym: 18.665663\t\tSpars: 1016.413696\n",
      "\t TVw: -0.429674 | TVb: -2.043597 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1592...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1035.486843155979\n",
      "Average validation loss: 159.2209454946397\n",
      "Training epoch 1593...\n",
      "\n",
      "Train Epoch: 1593 [0/8000 (0%)]\tBatch Loss: 1012.331567\tLearning Rate (w_theta): 0.001000\t TIME:2338.4s\n",
      "\t\t\t\tDisc: 1.165829\t\tSym: 16.979702\t\tSpars: 994.186035\n",
      "\t TVw: -0.429456 | TVb: -2.043598 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1593 [4000/8000 (50%)]\tBatch Loss: 1030.098896\tLearning Rate (w_theta): 0.001000\t TIME:2339.9s\n",
      "\t\t\t\tDisc: 1.197420\t\tSym: 18.391771\t\tSpars: 1010.509705\n",
      "\t TVw: -0.429235 | TVb: -2.043599 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1593...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1035.2715140281025\n",
      "Average validation loss: 158.16858039234677\n",
      "Training epoch 1594...\n",
      "\n",
      "Train Epoch: 1594 [0/8000 (0%)]\tBatch Loss: 1030.419898\tLearning Rate (w_theta): 0.001000\t TIME:2342.2s\n",
      "\t\t\t\tDisc: 1.202594\t\tSym: 17.889179\t\tSpars: 1011.328125\n",
      "\t TVw: -0.429017 | TVb: -2.043600 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1594 [4000/8000 (50%)]\tBatch Loss: 1041.635569\tLearning Rate (w_theta): 0.001000\t TIME:2343.8s\n",
      "\t\t\t\tDisc: 1.267319\t\tSym: 18.569849\t\tSpars: 1021.798401\n",
      "\t TVw: -0.428796 | TVb: -2.043600 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1594...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1035.7410222976412\n",
      "Average validation loss: 157.65176584987265\n",
      "Training epoch 1595...\n",
      "\n",
      "Train Epoch: 1595 [0/8000 (0%)]\tBatch Loss: 1021.019065\tLearning Rate (w_theta): 0.001000\t TIME:2346.1s\n",
      "\t\t\t\tDisc: 1.198789\t\tSym: 17.453638\t\tSpars: 1002.366638\n",
      "\t TVw: -0.428578 | TVb: -2.043601 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1595 [4000/8000 (50%)]\tBatch Loss: 1019.991017\tLearning Rate (w_theta): 0.001000\t TIME:2347.6s\n",
      "\t\t\t\tDisc: 1.159010\t\tSym: 17.095922\t\tSpars: 1001.736084\n",
      "\t TVw: -0.428358 | TVb: -2.043602 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1595...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1032.270834472809\n",
      "Average validation loss: 156.9168950505065\n",
      "Training epoch 1596...\n",
      "\n",
      "Train Epoch: 1596 [0/8000 (0%)]\tBatch Loss: 1048.706117\tLearning Rate (w_theta): 0.001000\t TIME:2349.9s\n",
      "\t\t\t\tDisc: 1.325282\t\tSym: 18.225317\t\tSpars: 1029.155518\n",
      "\t TVw: -0.428134 | TVb: -2.043602 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1596 [4000/8000 (50%)]\tBatch Loss: 1025.751829\tLearning Rate (w_theta): 0.001000\t TIME:2351.4s\n",
      "\t\t\t\tDisc: 1.155025\t\tSym: 17.308229\t\tSpars: 1007.288574\n",
      "\t TVw: -0.427907 | TVb: -2.043603 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1596...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1030.7095317796952\n",
      "Average validation loss: 158.15769096404227\n",
      "Training epoch 1597...\n",
      "\n",
      "Train Epoch: 1597 [0/8000 (0%)]\tBatch Loss: 1016.817394\tLearning Rate (w_theta): 0.001000\t TIME:2354.0s\n",
      "\t\t\t\tDisc: 1.224478\t\tSym: 17.554708\t\tSpars: 998.038208\n",
      "\t TVw: -0.427678 | TVb: -2.043603 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1597 [4000/8000 (50%)]\tBatch Loss: 1042.400742\tLearning Rate (w_theta): 0.001000\t TIME:2355.5s\n",
      "\t\t\t\tDisc: 1.256649\t\tSym: 18.942432\t\tSpars: 1022.201660\n",
      "\t TVw: -0.427450 | TVb: -2.043604 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1597...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1028.9838510848176\n",
      "Average validation loss: 158.04795918607772\n",
      "Training epoch 1598...\n",
      "\n",
      "Train Epoch: 1598 [0/8000 (0%)]\tBatch Loss: 1015.512647\tLearning Rate (w_theta): 0.001000\t TIME:2357.8s\n",
      "\t\t\t\tDisc: 1.216281\t\tSym: 16.703226\t\tSpars: 997.593140\n",
      "\t TVw: -0.427224 | TVb: -2.043605 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1598 [4000/8000 (50%)]\tBatch Loss: 975.211944\tLearning Rate (w_theta): 0.001000\t TIME:2359.4s\n",
      "\t\t\t\tDisc: 1.078463\t\tSym: 15.253049\t\tSpars: 958.880432\n",
      "\t TVw: -0.426996 | TVb: -2.043606 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1598...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1027.5537283463707\n",
      "Average validation loss: 156.61015138965297\n",
      "Training epoch 1599...\n",
      "\n",
      "Train Epoch: 1599 [0/8000 (0%)]\tBatch Loss: 1021.771954\tLearning Rate (w_theta): 0.001000\t TIME:2361.7s\n",
      "\t\t\t\tDisc: 1.202498\t\tSym: 16.731016\t\tSpars: 1003.838440\n",
      "\t TVw: -0.426767 | TVb: -2.043607 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1599 [4000/8000 (50%)]\tBatch Loss: 1045.213224\tLearning Rate (w_theta): 0.001000\t TIME:2363.2s\n",
      "\t\t\t\tDisc: 1.322828\t\tSym: 18.566666\t\tSpars: 1025.323730\n",
      "\t TVw: -0.426538 | TVb: -2.043608 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1599...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1029.3314685026003\n",
      "Average validation loss: 157.75545921421028\n",
      "Training epoch 1600...\n",
      "\n",
      "Train Epoch: 1600 [0/8000 (0%)]\tBatch Loss: 1048.953531\tLearning Rate (w_theta): 0.001000\t TIME:2365.6s\n",
      "\t\t\t\tDisc: 1.348310\t\tSym: 18.747066\t\tSpars: 1028.858154\n",
      "\t TVw: -0.426309 | TVb: -2.043609 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1600 [4000/8000 (50%)]\tBatch Loss: 1034.420796\tLearning Rate (w_theta): 0.001000\t TIME:2367.1s\n",
      "\t\t\t\tDisc: 1.227230\t\tSym: 18.237572\t\tSpars: 1014.955994\n",
      "\t TVw: -0.426082 | TVb: -2.043610 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1600...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1028.7907640478297\n",
      "Average validation loss: 157.81113571684438\n",
      "Training epoch 1601...\n",
      "\n",
      "Train Epoch: 1601 [0/8000 (0%)]\tBatch Loss: 1032.090005\tLearning Rate (w_theta): 0.001000\t TIME:2370.2s\n",
      "\t\t\t\tDisc: 1.231387\t\tSym: 19.017920\t\tSpars: 1011.840698\n",
      "\t TVw: -0.425851 | TVb: -2.043611 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1601 [4000/8000 (50%)]\tBatch Loss: 1050.978842\tLearning Rate (w_theta): 0.001000\t TIME:2371.7s\n",
      "\t\t\t\tDisc: 1.223702\t\tSym: 18.167494\t\tSpars: 1031.587646\n",
      "\t TVw: -0.425620 | TVb: -2.043611 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1601...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1033.2222115226814\n",
      "Average validation loss: 158.38645102522324\n",
      "Training epoch 1602...\n",
      "\n",
      "Train Epoch: 1602 [0/8000 (0%)]\tBatch Loss: 1060.645660\tLearning Rate (w_theta): 0.001000\t TIME:2374.0s\n",
      "\t\t\t\tDisc: 1.354486\t\tSym: 18.691442\t\tSpars: 1040.599731\n",
      "\t TVw: -0.425392 | TVb: -2.043612 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1602 [4000/8000 (50%)]\tBatch Loss: 1041.235918\tLearning Rate (w_theta): 0.001000\t TIME:2375.5s\n",
      "\t\t\t\tDisc: 1.262220\t\tSym: 19.512211\t\tSpars: 1020.461487\n",
      "\t TVw: -0.425166 | TVb: -2.043613 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1602...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1033.8374482728893\n",
      "Average validation loss: 155.82631159091727\n",
      "Training epoch 1603...\n",
      "\n",
      "Train Epoch: 1603 [0/8000 (0%)]\tBatch Loss: 1069.254981\tLearning Rate (w_theta): 0.001000\t TIME:2378.0s\n",
      "\t\t\t\tDisc: 1.422809\t\tSym: 19.968403\t\tSpars: 1047.863770\n",
      "\t TVw: -0.424939 | TVb: -2.043614 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1603 [4000/8000 (50%)]\tBatch Loss: 1011.491080\tLearning Rate (w_theta): 0.001000\t TIME:2379.6s\n",
      "\t\t\t\tDisc: 1.085923\t\tSym: 17.832403\t\tSpars: 992.572754\n",
      "\t TVw: -0.424713 | TVb: -2.043615 | GSw: -0.234959 | GSb: 0.065070 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1603...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1032.5954105639214\n",
      "Average validation loss: 157.64731533707717\n",
      "Training epoch 1604...\n",
      "\n",
      "Train Epoch: 1604 [0/8000 (0%)]\tBatch Loss: 1082.842001\tLearning Rate (w_theta): 0.001000\t TIME:2381.9s\n",
      "\t\t\t\tDisc: 1.391670\t\tSym: 21.087904\t\tSpars: 1060.362427\n",
      "\t TVw: -0.424483 | TVb: -2.043616 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1604 [4000/8000 (50%)]\tBatch Loss: 1035.034537\tLearning Rate (w_theta): 0.001000\t TIME:2383.5s\n",
      "\t\t\t\tDisc: 1.220984\t\tSym: 18.048660\t\tSpars: 1015.764893\n",
      "\t TVw: -0.424252 | TVb: -2.043617 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1604...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1032.2763267818045\n",
      "Average validation loss: 156.8590287278526\n",
      "Training epoch 1605...\n",
      "\n",
      "Train Epoch: 1605 [0/8000 (0%)]\tBatch Loss: 1015.948621\tLearning Rate (w_theta): 0.001000\t TIME:2385.9s\n",
      "\t\t\t\tDisc: 1.225332\t\tSym: 17.458336\t\tSpars: 997.264954\n",
      "\t TVw: -0.424014 | TVb: -2.043618 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1605 [4000/8000 (50%)]\tBatch Loss: 1045.440818\tLearning Rate (w_theta): 0.001000\t TIME:2387.4s\n",
      "\t\t\t\tDisc: 1.197328\t\tSym: 18.800375\t\tSpars: 1025.443115\n",
      "\t TVw: -0.423773 | TVb: -2.043618 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1605...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1024.5274917307725\n",
      "Average validation loss: 157.38827481073162\n",
      "Training epoch 1606...\n",
      "\n",
      "Train Epoch: 1606 [0/8000 (0%)]\tBatch Loss: 986.484816\tLearning Rate (w_theta): 0.001000\t TIME:2389.8s\n",
      "\t\t\t\tDisc: 1.217087\t\tSym: 16.669828\t\tSpars: 968.597900\n",
      "\t TVw: -0.423535 | TVb: -2.043619 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1606 [4000/8000 (50%)]\tBatch Loss: 1047.024593\tLearning Rate (w_theta): 0.001000\t TIME:2391.3s\n",
      "\t\t\t\tDisc: 1.283687\t\tSym: 18.813049\t\tSpars: 1026.927856\n",
      "\t TVw: -0.423303 | TVb: -2.043620 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1606...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1028.9034572272171\n",
      "Average validation loss: 156.3315098525563\n",
      "Training epoch 1607...\n",
      "\n",
      "Train Epoch: 1607 [0/8000 (0%)]\tBatch Loss: 1079.592588\tLearning Rate (w_theta): 0.001000\t TIME:2393.6s\n",
      "\t\t\t\tDisc: 1.336479\t\tSym: 19.682135\t\tSpars: 1058.573975\n",
      "\t TVw: -0.423071 | TVb: -2.043622 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1607 [4000/8000 (50%)]\tBatch Loss: 1008.182094\tLearning Rate (w_theta): 0.001000\t TIME:2395.2s\n",
      "\t\t\t\tDisc: 1.088239\t\tSym: 17.100264\t\tSpars: 989.993591\n",
      "\t TVw: -0.422841 | TVb: -2.043623 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1607...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1025.5339201583045\n",
      "Average validation loss: 157.99902707002036\n",
      "Training epoch 1608...\n",
      "\n",
      "Train Epoch: 1608 [0/8000 (0%)]\tBatch Loss: 1015.671282\tLearning Rate (w_theta): 0.001000\t TIME:2397.5s\n",
      "\t\t\t\tDisc: 1.265854\t\tSym: 17.215548\t\tSpars: 997.189880\n",
      "\t TVw: -0.422607 | TVb: -2.043624 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1608 [4000/8000 (50%)]\tBatch Loss: 1052.267267\tLearning Rate (w_theta): 0.001000\t TIME:2399.0s\n",
      "\t\t\t\tDisc: 1.262838\t\tSym: 19.313999\t\tSpars: 1031.690430\n",
      "\t TVw: -0.422374 | TVb: -2.043625 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1608...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1024.5949417243996\n",
      "Average validation loss: 156.79000587417516\n",
      "Training epoch 1609...\n",
      "\n",
      "Train Epoch: 1609 [0/8000 (0%)]\tBatch Loss: 1025.495683\tLearning Rate (w_theta): 0.001000\t TIME:2401.4s\n",
      "\t\t\t\tDisc: 1.248202\t\tSym: 18.636824\t\tSpars: 1005.610657\n",
      "\t TVw: -0.422141 | TVb: -2.043626 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1609 [4000/8000 (50%)]\tBatch Loss: 1035.937990\tLearning Rate (w_theta): 0.001000\t TIME:2402.9s\n",
      "\t\t\t\tDisc: 1.070545\t\tSym: 17.524794\t\tSpars: 1017.342651\n",
      "\t TVw: -0.421905 | TVb: -2.043627 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1609...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1031.5029714878053\n",
      "Average validation loss: 157.39010119092467\n",
      "Training epoch 1610...\n",
      "\n",
      "Train Epoch: 1610 [0/8000 (0%)]\tBatch Loss: 1032.825601\tLearning Rate (w_theta): 0.001000\t TIME:2405.3s\n",
      "\t\t\t\tDisc: 1.273891\t\tSym: 17.030897\t\tSpars: 1014.520813\n",
      "\t TVw: -0.421668 | TVb: -2.043627 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1610 [4000/8000 (50%)]\tBatch Loss: 991.920383\tLearning Rate (w_theta): 0.001000\t TIME:2406.8s\n",
      "\t\t\t\tDisc: 1.112793\t\tSym: 17.007786\t\tSpars: 973.799805\n",
      "\t TVw: -0.421432 | TVb: -2.043628 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1610...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1024.4215643365178\n",
      "Average validation loss: 156.43454952258102\n",
      "Training epoch 1611...\n",
      "\n",
      "Train Epoch: 1611 [0/8000 (0%)]\tBatch Loss: 1069.963261\tLearning Rate (w_theta): 0.001000\t TIME:2410.0s\n",
      "\t\t\t\tDisc: 1.327376\t\tSym: 20.552145\t\tSpars: 1048.083740\n",
      "\t TVw: -0.421193 | TVb: -2.043629 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1611 [4000/8000 (50%)]\tBatch Loss: 1027.522828\tLearning Rate (w_theta): 0.001000\t TIME:2411.6s\n",
      "\t\t\t\tDisc: 1.322583\t\tSym: 17.714466\t\tSpars: 1008.485779\n",
      "\t TVw: -0.420953 | TVb: -2.043630 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1611...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1027.311142251455\n",
      "Average validation loss: 159.15975493965885\n",
      "Training epoch 1612...\n",
      "\n",
      "Train Epoch: 1612 [0/8000 (0%)]\tBatch Loss: 1035.312451\tLearning Rate (w_theta): 0.001000\t TIME:2413.9s\n",
      "\t\t\t\tDisc: 1.183554\t\tSym: 17.966665\t\tSpars: 1016.162231\n",
      "\t TVw: -0.420714 | TVb: -2.043630 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1612 [4000/8000 (50%)]\tBatch Loss: 1036.549588\tLearning Rate (w_theta): 0.001000\t TIME:2415.5s\n",
      "\t\t\t\tDisc: 1.278128\t\tSym: 18.445044\t\tSpars: 1016.826416\n",
      "\t TVw: -0.420473 | TVb: -2.043631 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1612...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1026.8986525997298\n",
      "Average validation loss: 155.73202799717305\n",
      "Training epoch 1613...\n",
      "\n",
      "Train Epoch: 1613 [0/8000 (0%)]\tBatch Loss: 1053.670831\tLearning Rate (w_theta): 0.001000\t TIME:2417.9s\n",
      "\t\t\t\tDisc: 1.326454\t\tSym: 18.857073\t\tSpars: 1033.487305\n",
      "\t TVw: -0.420231 | TVb: -2.043632 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1613 [4000/8000 (50%)]\tBatch Loss: 1039.029548\tLearning Rate (w_theta): 0.001000\t TIME:2419.4s\n",
      "\t\t\t\tDisc: 1.211348\t\tSym: 17.561668\t\tSpars: 1020.256531\n",
      "\t TVw: -0.419990 | TVb: -2.043633 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1613...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1025.3567867536437\n",
      "Average validation loss: 156.59659160493234\n",
      "Training epoch 1614...\n",
      "\n",
      "Train Epoch: 1614 [0/8000 (0%)]\tBatch Loss: 1005.309093\tLearning Rate (w_theta): 0.001000\t TIME:2421.7s\n",
      "\t\t\t\tDisc: 1.170749\t\tSym: 15.836586\t\tSpars: 988.301758\n",
      "\t TVw: -0.419746 | TVb: -2.043633 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1614 [4000/8000 (50%)]\tBatch Loss: 1060.703408\tLearning Rate (w_theta): 0.001000\t TIME:2423.2s\n",
      "\t\t\t\tDisc: 1.393282\t\tSym: 20.131536\t\tSpars: 1039.178589\n",
      "\t TVw: -0.419502 | TVb: -2.043634 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1614...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1022.3465653509195\n",
      "Average validation loss: 156.18626185059915\n",
      "Training epoch 1615...\n",
      "\n",
      "Train Epoch: 1615 [0/8000 (0%)]\tBatch Loss: 1006.651488\tLearning Rate (w_theta): 0.001000\t TIME:2425.6s\n",
      "\t\t\t\tDisc: 1.217860\t\tSym: 16.867222\t\tSpars: 988.566406\n",
      "\t TVw: -0.419257 | TVb: -2.043635 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1615 [4000/8000 (50%)]\tBatch Loss: 1007.517624\tLearning Rate (w_theta): 0.001000\t TIME:2427.1s\n",
      "\t\t\t\tDisc: 1.209513\t\tSym: 16.312811\t\tSpars: 989.995300\n",
      "\t TVw: -0.419008 | TVb: -2.043636 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1615...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1020.7438991839715\n",
      "Average validation loss: 155.9118732950736\n",
      "Training epoch 1616...\n",
      "\n",
      "Train Epoch: 1616 [0/8000 (0%)]\tBatch Loss: 1027.085083\tLearning Rate (w_theta): 0.001000\t TIME:2429.5s\n",
      "\t\t\t\tDisc: 1.305999\t\tSym: 17.458466\t\tSpars: 1008.320618\n",
      "\t TVw: -0.418764 | TVb: -2.043637 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1616 [4000/8000 (50%)]\tBatch Loss: 1062.068100\tLearning Rate (w_theta): 0.001000\t TIME:2431.0s\n",
      "\t\t\t\tDisc: 1.276898\t\tSym: 19.945011\t\tSpars: 1040.846191\n",
      "\t TVw: -0.418521 | TVb: -2.043637 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1616...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1022.9454057961907\n",
      "Average validation loss: 157.18923071819927\n",
      "Training epoch 1617...\n",
      "\n",
      "Train Epoch: 1617 [0/8000 (0%)]\tBatch Loss: 1036.277636\tLearning Rate (w_theta): 0.001000\t TIME:2433.6s\n",
      "\t\t\t\tDisc: 1.103413\t\tSym: 17.851713\t\tSpars: 1017.322510\n",
      "\t TVw: -0.418278 | TVb: -2.043638 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1617 [4000/8000 (50%)]\tBatch Loss: 1010.344637\tLearning Rate (w_theta): 0.001000\t TIME:2435.2s\n",
      "\t\t\t\tDisc: 1.184549\t\tSym: 16.439507\t\tSpars: 992.720581\n",
      "\t TVw: -0.418037 | TVb: -2.043639 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1617...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1022.4913641618317\n",
      "Average validation loss: 156.002714208868\n",
      "Training epoch 1618...\n",
      "\n",
      "Train Epoch: 1618 [0/8000 (0%)]\tBatch Loss: 1000.107217\tLearning Rate (w_theta): 0.001000\t TIME:2437.5s\n",
      "\t\t\t\tDisc: 1.139384\t\tSym: 16.967955\t\tSpars: 981.999878\n",
      "\t TVw: -0.417794 | TVb: -2.043640 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1618 [4000/8000 (50%)]\tBatch Loss: 1060.707682\tLearning Rate (w_theta): 0.001000\t TIME:2439.0s\n",
      "\t\t\t\tDisc: 1.199673\t\tSym: 19.326735\t\tSpars: 1040.181274\n",
      "\t TVw: -0.417547 | TVb: -2.043640 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1618...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1024.8073200670697\n",
      "Average validation loss: 155.86459789810627\n",
      "Training epoch 1619...\n",
      "\n",
      "Train Epoch: 1619 [0/8000 (0%)]\tBatch Loss: 1039.863903\tLearning Rate (w_theta): 0.001000\t TIME:2441.4s\n",
      "\t\t\t\tDisc: 1.235304\t\tSym: 18.903746\t\tSpars: 1019.724854\n",
      "\t TVw: -0.417300 | TVb: -2.043640 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1619 [4000/8000 (50%)]\tBatch Loss: 1075.560482\tLearning Rate (w_theta): 0.001000\t TIME:2442.9s\n",
      "\t\t\t\tDisc: 1.254332\t\tSym: 18.249266\t\tSpars: 1056.056885\n",
      "\t TVw: -0.417054 | TVb: -2.043640 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1619...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1031.687962602888\n",
      "Average validation loss: 155.47233080083382\n",
      "Training epoch 1620...\n",
      "\n",
      "Train Epoch: 1620 [0/8000 (0%)]\tBatch Loss: 1022.147714\tLearning Rate (w_theta): 0.001000\t TIME:2445.3s\n",
      "\t\t\t\tDisc: 1.153688\t\tSym: 16.811287\t\tSpars: 1004.182739\n",
      "\t TVw: -0.416814 | TVb: -2.043641 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1620 [4000/8000 (50%)]\tBatch Loss: 1032.853430\tLearning Rate (w_theta): 0.001000\t TIME:2446.8s\n",
      "\t\t\t\tDisc: 1.320019\t\tSym: 18.375208\t\tSpars: 1013.158203\n",
      "\t TVw: -0.416573 | TVb: -2.043642 | GSw: -0.234959 | GSb: 0.065069 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1620...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1025.0519308636417\n",
      "Average validation loss: 156.68832581022068\n",
      "Training epoch 1621...\n",
      "\n",
      "Train Epoch: 1621 [0/8000 (0%)]\tBatch Loss: 1048.172657\tLearning Rate (w_theta): 0.001000\t TIME:2450.0s\n",
      "\t\t\t\tDisc: 1.193761\t\tSym: 18.364515\t\tSpars: 1028.614380\n",
      "\t TVw: -0.416328 | TVb: -2.043643 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1621 [4000/8000 (50%)]\tBatch Loss: 971.126948\tLearning Rate (w_theta): 0.001000\t TIME:2451.5s\n",
      "\t\t\t\tDisc: 1.073612\t\tSym: 15.008048\t\tSpars: 955.045288\n",
      "\t TVw: -0.416080 | TVb: -2.043643 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "Validating epoch 1621...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1019.1593795236563\n",
      "Average validation loss: 156.27513583951742\n",
      "Training epoch 1622...\n",
      "\n",
      "Train Epoch: 1622 [0/8000 (0%)]\tBatch Loss: 1022.209347\tLearning Rate (w_theta): 0.001000\t TIME:2453.9s\n",
      "\t\t\t\tDisc: 1.188249\t\tSym: 18.515116\t\tSpars: 1002.505981\n",
      "\t TVw: -0.415826 | TVb: -2.043643 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034769\n",
      "\n",
      "Train Epoch: 1622 [4000/8000 (50%)]\tBatch Loss: 1023.472552\tLearning Rate (w_theta): 0.001000\t TIME:2455.4s\n",
      "\t\t\t\tDisc: 1.167674\t\tSym: 17.710640\t\tSpars: 1004.594238\n",
      "\t TVw: -0.415576 | TVb: -2.043644 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1622...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1019.9492593638536\n",
      "Average validation loss: 155.0922406503406\n",
      "Training epoch 1623...\n",
      "\n",
      "Train Epoch: 1623 [0/8000 (0%)]\tBatch Loss: 1014.666251\tLearning Rate (w_theta): 0.001000\t TIME:2457.8s\n",
      "\t\t\t\tDisc: 1.200509\t\tSym: 17.344526\t\tSpars: 996.121216\n",
      "\t TVw: -0.415326 | TVb: -2.043644 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1623 [4000/8000 (50%)]\tBatch Loss: 1042.017748\tLearning Rate (w_theta): 0.001000\t TIME:2459.3s\n",
      "\t\t\t\tDisc: 1.216160\t\tSym: 18.740797\t\tSpars: 1022.060791\n",
      "\t TVw: -0.415075 | TVb: -2.043645 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1623...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1015.7226733993699\n",
      "Average validation loss: 155.44445967678263\n",
      "Training epoch 1624...\n",
      "\n",
      "Train Epoch: 1624 [0/8000 (0%)]\tBatch Loss: 997.143065\tLearning Rate (w_theta): 0.001000\t TIME:2461.8s\n",
      "\t\t\t\tDisc: 1.154585\t\tSym: 16.581619\t\tSpars: 979.406860\n",
      "\t TVw: -0.414824 | TVb: -2.043646 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1624 [4000/8000 (50%)]\tBatch Loss: 1046.495055\tLearning Rate (w_theta): 0.001000\t TIME:2463.4s\n",
      "\t\t\t\tDisc: 1.174905\t\tSym: 18.610434\t\tSpars: 1026.709717\n",
      "\t TVw: -0.414570 | TVb: -2.043646 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1624...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1016.7377480874645\n",
      "Average validation loss: 157.361861846327\n",
      "Training epoch 1625...\n",
      "\n",
      "Train Epoch: 1625 [0/8000 (0%)]\tBatch Loss: 1020.074313\tLearning Rate (w_theta): 0.001000\t TIME:2465.8s\n",
      "\t\t\t\tDisc: 1.143590\t\tSym: 17.728148\t\tSpars: 1001.202576\n",
      "\t TVw: -0.414318 | TVb: -2.043647 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1625 [4000/8000 (50%)]\tBatch Loss: 987.865808\tLearning Rate (w_theta): 0.001000\t TIME:2467.4s\n",
      "\t\t\t\tDisc: 1.105245\t\tSym: 16.617252\t\tSpars: 970.143311\n",
      "\t TVw: -0.414066 | TVb: -2.043648 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1625...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1018.3671913685142\n",
      "Average validation loss: 153.5867633066771\n",
      "Training epoch 1626...\n",
      "\n",
      "Train Epoch: 1626 [0/8000 (0%)]\tBatch Loss: 990.287816\tLearning Rate (w_theta): 0.001000\t TIME:2469.7s\n",
      "\t\t\t\tDisc: 1.192072\t\tSym: 15.779826\t\tSpars: 973.315918\n",
      "\t TVw: -0.413814 | TVb: -2.043648 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1626 [4000/8000 (50%)]\tBatch Loss: 1004.667187\tLearning Rate (w_theta): 0.001000\t TIME:2471.2s\n",
      "\t\t\t\tDisc: 1.136465\t\tSym: 17.295126\t\tSpars: 986.235596\n",
      "\t TVw: -0.413567 | TVb: -2.043649 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1626...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1022.1264994614537\n",
      "Average validation loss: 155.038630782903\n",
      "Training epoch 1627...\n",
      "\n",
      "Train Epoch: 1627 [0/8000 (0%)]\tBatch Loss: 1007.453192\tLearning Rate (w_theta): 0.001000\t TIME:2473.6s\n",
      "\t\t\t\tDisc: 1.221058\t\tSym: 17.364275\t\tSpars: 988.867859\n",
      "\t TVw: -0.413314 | TVb: -2.043650 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1627 [4000/8000 (50%)]\tBatch Loss: 1006.982993\tLearning Rate (w_theta): 0.001000\t TIME:2475.2s\n",
      "\t\t\t\tDisc: 1.114055\t\tSym: 17.100750\t\tSpars: 988.768188\n",
      "\t TVw: -0.413058 | TVb: -2.043650 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1627...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1018.866469076397\n",
      "Average validation loss: 153.7438947436567\n",
      "Training epoch 1628...\n",
      "\n",
      "Train Epoch: 1628 [0/8000 (0%)]\tBatch Loss: 1007.564161\tLearning Rate (w_theta): 0.001000\t TIME:2477.5s\n",
      "\t\t\t\tDisc: 1.192610\t\tSym: 16.736481\t\tSpars: 989.635071\n",
      "\t TVw: -0.412803 | TVb: -2.043650 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1628 [4000/8000 (50%)]\tBatch Loss: 1032.685805\tLearning Rate (w_theta): 0.001000\t TIME:2479.0s\n",
      "\t\t\t\tDisc: 1.285176\t\tSym: 17.645319\t\tSpars: 1013.755310\n",
      "\t TVw: -0.412548 | TVb: -2.043651 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1628...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1025.2578409025682\n",
      "Average validation loss: 155.16797608197024\n",
      "Training epoch 1629...\n",
      "\n",
      "Train Epoch: 1629 [0/8000 (0%)]\tBatch Loss: 1006.577028\tLearning Rate (w_theta): 0.001000\t TIME:2481.5s\n",
      "\t\t\t\tDisc: 1.118259\t\tSym: 17.407255\t\tSpars: 988.051514\n",
      "\t TVw: -0.412296 | TVb: -2.043652 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1629 [4000/8000 (50%)]\tBatch Loss: 1034.056258\tLearning Rate (w_theta): 0.001000\t TIME:2483.0s\n",
      "\t\t\t\tDisc: 1.297576\t\tSym: 17.895645\t\tSpars: 1014.863037\n",
      "\t TVw: -0.412045 | TVb: -2.043652 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1629...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1028.0626112063976\n",
      "Average validation loss: 156.8392376424843\n",
      "Training epoch 1630...\n",
      "\n",
      "Train Epoch: 1630 [0/8000 (0%)]\tBatch Loss: 1034.855471\tLearning Rate (w_theta): 0.001000\t TIME:2485.4s\n",
      "\t\t\t\tDisc: 1.096897\t\tSym: 18.275969\t\tSpars: 1015.482605\n",
      "\t TVw: -0.411791 | TVb: -2.043653 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1630 [4000/8000 (50%)]\tBatch Loss: 1004.147980\tLearning Rate (w_theta): 0.001000\t TIME:2486.9s\n",
      "\t\t\t\tDisc: 1.186438\t\tSym: 16.451654\t\tSpars: 986.509888\n",
      "\t TVw: -0.411534 | TVb: -2.043653 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1630...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1021.8758716685658\n",
      "Average validation loss: 153.0444183601207\n",
      "Training epoch 1631...\n",
      "\n",
      "Train Epoch: 1631 [0/8000 (0%)]\tBatch Loss: 1004.494685\tLearning Rate (w_theta): 0.001000\t TIME:2490.0s\n",
      "\t\t\t\tDisc: 1.204218\t\tSym: 16.722595\t\tSpars: 986.567871\n",
      "\t TVw: -0.411274 | TVb: -2.043654 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1631 [4000/8000 (50%)]\tBatch Loss: 1041.558336\tLearning Rate (w_theta): 0.001000\t TIME:2491.6s\n",
      "\t\t\t\tDisc: 1.159143\t\tSym: 18.105553\t\tSpars: 1022.293640\n",
      "\t TVw: -0.411012 | TVb: -2.043655 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1631...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1017.7296564891534\n",
      "Average validation loss: 156.4287203439144\n",
      "Training epoch 1632...\n",
      "\n",
      "Train Epoch: 1632 [0/8000 (0%)]\tBatch Loss: 1049.727680\tLearning Rate (w_theta): 0.001000\t TIME:2493.9s\n",
      "\t\t\t\tDisc: 1.355657\t\tSym: 19.425734\t\tSpars: 1028.946289\n",
      "\t TVw: -0.410753 | TVb: -2.043655 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1632 [4000/8000 (50%)]\tBatch Loss: 1032.643820\tLearning Rate (w_theta): 0.001000\t TIME:2495.5s\n",
      "\t\t\t\tDisc: 1.186930\t\tSym: 18.522564\t\tSpars: 1012.934326\n",
      "\t TVw: -0.410496 | TVb: -2.043656 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1632...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1030.4908963286227\n",
      "Average validation loss: 153.30374733658942\n",
      "Training epoch 1633...\n",
      "\n",
      "Train Epoch: 1633 [0/8000 (0%)]\tBatch Loss: 1047.507811\tLearning Rate (w_theta): 0.001000\t TIME:2497.9s\n",
      "\t\t\t\tDisc: 1.366742\t\tSym: 19.714556\t\tSpars: 1026.426514\n",
      "\t TVw: -0.410245 | TVb: -2.043657 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1633 [4000/8000 (50%)]\tBatch Loss: 1007.752172\tLearning Rate (w_theta): 0.001000\t TIME:2499.4s\n",
      "\t\t\t\tDisc: 1.168931\t\tSym: 16.392445\t\tSpars: 990.190796\n",
      "\t TVw: -0.409998 | TVb: -2.043658 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1633...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1026.8209931291674\n",
      "Average validation loss: 153.2928199054556\n",
      "Training epoch 1634...\n",
      "\n",
      "Train Epoch: 1634 [0/8000 (0%)]\tBatch Loss: 1020.508483\tLearning Rate (w_theta): 0.001000\t TIME:2501.8s\n",
      "\t\t\t\tDisc: 1.154475\t\tSym: 18.567692\t\tSpars: 1000.786316\n",
      "\t TVw: -0.409751 | TVb: -2.043659 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1634 [4000/8000 (50%)]\tBatch Loss: 1029.049674\tLearning Rate (w_theta): 0.001000\t TIME:2503.3s\n",
      "\t\t\t\tDisc: 1.285831\t\tSym: 17.214649\t\tSpars: 1010.549194\n",
      "\t TVw: -0.409499 | TVb: -2.043660 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1634...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1021.4219732906867\n",
      "Average validation loss: 154.18932169821346\n",
      "Training epoch 1635...\n",
      "\n",
      "Train Epoch: 1635 [0/8000 (0%)]\tBatch Loss: 1007.556970\tLearning Rate (w_theta): 0.001000\t TIME:2505.7s\n",
      "\t\t\t\tDisc: 1.079029\t\tSym: 16.071447\t\tSpars: 990.406494\n",
      "\t TVw: -0.409251 | TVb: -2.043661 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1635 [4000/8000 (50%)]\tBatch Loss: 1003.107441\tLearning Rate (w_theta): 0.001000\t TIME:2507.2s\n",
      "\t\t\t\tDisc: 1.077580\t\tSym: 17.498245\t\tSpars: 984.531616\n",
      "\t TVw: -0.408999 | TVb: -2.043662 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1635...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1015.4025325550481\n",
      "Average validation loss: 156.53193655956088\n",
      "Training epoch 1636...\n",
      "\n",
      "Train Epoch: 1636 [0/8000 (0%)]\tBatch Loss: 1040.976318\tLearning Rate (w_theta): 0.001000\t TIME:2509.5s\n",
      "\t\t\t\tDisc: 1.191801\t\tSym: 18.361483\t\tSpars: 1021.423035\n",
      "\t TVw: -0.408743 | TVb: -2.043663 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1636 [4000/8000 (50%)]\tBatch Loss: 986.142198\tLearning Rate (w_theta): 0.001000\t TIME:2511.1s\n",
      "\t\t\t\tDisc: 1.148456\t\tSym: 16.316435\t\tSpars: 968.677307\n",
      "\t TVw: -0.408481 | TVb: -2.043663 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1636...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1010.9737065735094\n",
      "Average validation loss: 155.31982317101145\n",
      "Training epoch 1637...\n",
      "\n",
      "Train Epoch: 1637 [0/8000 (0%)]\tBatch Loss: 1009.283948\tLearning Rate (w_theta): 0.001000\t TIME:2513.5s\n",
      "\t\t\t\tDisc: 1.210052\t\tSym: 16.828657\t\tSpars: 991.245239\n",
      "\t TVw: -0.408218 | TVb: -2.043664 | GSw: -0.234959 | GSb: 0.065068 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1637 [4000/8000 (50%)]\tBatch Loss: 998.258041\tLearning Rate (w_theta): 0.001000\t TIME:2515.0s\n",
      "\t\t\t\tDisc: 1.034021\t\tSym: 16.900045\t\tSpars: 980.323975\n",
      "\t TVw: -0.407953 | TVb: -2.043664 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1637...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1009.244331374706\n",
      "Average validation loss: 153.7528813939637\n",
      "Training epoch 1638...\n",
      "\n",
      "Train Epoch: 1638 [0/8000 (0%)]\tBatch Loss: 998.277831\tLearning Rate (w_theta): 0.001000\t TIME:2517.3s\n",
      "\t\t\t\tDisc: 1.195853\t\tSym: 16.408943\t\tSpars: 980.673035\n",
      "\t TVw: -0.407685 | TVb: -2.043665 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1638 [4000/8000 (50%)]\tBatch Loss: 1051.944859\tLearning Rate (w_theta): 0.001000\t TIME:2519.1s\n",
      "\t\t\t\tDisc: 1.227742\t\tSym: 19.534988\t\tSpars: 1031.182129\n",
      "\t TVw: -0.407415 | TVb: -2.043666 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1638...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1009.6060781155156\n",
      "Average validation loss: 155.35005470819627\n",
      "Training epoch 1639...\n",
      "\n",
      "Train Epoch: 1639 [0/8000 (0%)]\tBatch Loss: 972.337669\tLearning Rate (w_theta): 0.001000\t TIME:2521.4s\n",
      "\t\t\t\tDisc: 1.081018\t\tSym: 14.904113\t\tSpars: 956.352539\n",
      "\t TVw: -0.407144 | TVb: -2.043666 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1639 [4000/8000 (50%)]\tBatch Loss: 1029.009657\tLearning Rate (w_theta): 0.001000\t TIME:2523.0s\n",
      "\t\t\t\tDisc: 1.183557\t\tSym: 17.896046\t\tSpars: 1009.930054\n",
      "\t TVw: -0.406876 | TVb: -2.043666 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1639...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1009.8037276610174\n",
      "Average validation loss: 154.47249409851935\n",
      "Training epoch 1640...\n",
      "\n",
      "Train Epoch: 1640 [0/8000 (0%)]\tBatch Loss: 978.888709\tLearning Rate (w_theta): 0.001000\t TIME:2525.3s\n",
      "\t\t\t\tDisc: 1.028444\t\tSym: 15.584020\t\tSpars: 962.276245\n",
      "\t TVw: -0.406612 | TVb: -2.043667 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1640 [4000/8000 (50%)]\tBatch Loss: 1040.983829\tLearning Rate (w_theta): 0.001000\t TIME:2526.9s\n",
      "\t\t\t\tDisc: 1.311378\t\tSym: 18.994228\t\tSpars: 1020.678223\n",
      "\t TVw: -0.406345 | TVb: -2.043668 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1640...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1011.3659047399819\n",
      "Average validation loss: 154.094572165815\n",
      "Training epoch 1641...\n",
      "\n",
      "Train Epoch: 1641 [0/8000 (0%)]\tBatch Loss: 986.850501\tLearning Rate (w_theta): 0.001000\t TIME:2530.0s\n",
      "\t\t\t\tDisc: 1.109861\t\tSym: 16.771463\t\tSpars: 968.969177\n",
      "\t TVw: -0.406081 | TVb: -2.043668 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1641 [4000/8000 (50%)]\tBatch Loss: 1019.039714\tLearning Rate (w_theta): 0.001000\t TIME:2531.5s\n",
      "\t\t\t\tDisc: 1.300748\t\tSym: 17.301832\t\tSpars: 1000.437134\n",
      "\t TVw: -0.405819 | TVb: -2.043669 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1641...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1009.9157740804789\n",
      "Average validation loss: 154.14823243456019\n",
      "Training epoch 1642...\n",
      "\n",
      "Train Epoch: 1642 [0/8000 (0%)]\tBatch Loss: 961.424380\tLearning Rate (w_theta): 0.001000\t TIME:2533.9s\n",
      "\t\t\t\tDisc: 1.070290\t\tSym: 15.439844\t\tSpars: 944.914246\n",
      "\t TVw: -0.405551 | TVb: -2.043669 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1642 [4000/8000 (50%)]\tBatch Loss: 996.395432\tLearning Rate (w_theta): 0.001000\t TIME:2535.4s\n",
      "\t\t\t\tDisc: 1.122166\t\tSym: 17.032116\t\tSpars: 978.241150\n",
      "\t TVw: -0.405278 | TVb: -2.043669 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1642...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1009.1290319863637\n",
      "Average validation loss: 153.02649495261315\n",
      "Training epoch 1643...\n",
      "\n",
      "Train Epoch: 1643 [0/8000 (0%)]\tBatch Loss: 1004.224237\tLearning Rate (w_theta): 0.001000\t TIME:2537.8s\n",
      "\t\t\t\tDisc: 1.101377\t\tSym: 17.444210\t\tSpars: 985.678650\n",
      "\t TVw: -0.405008 | TVb: -2.043669 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1643 [4000/8000 (50%)]\tBatch Loss: 1016.609898\tLearning Rate (w_theta): 0.001000\t TIME:2539.3s\n",
      "\t\t\t\tDisc: 1.160604\t\tSym: 18.408278\t\tSpars: 997.041016\n",
      "\t TVw: -0.404738 | TVb: -2.043669 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1643...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1008.8637784357093\n",
      "Average validation loss: 155.45847139974904\n",
      "Training epoch 1644...\n",
      "\n",
      "Train Epoch: 1644 [0/8000 (0%)]\tBatch Loss: 1031.702936\tLearning Rate (w_theta): 0.001000\t TIME:2541.6s\n",
      "\t\t\t\tDisc: 1.129366\t\tSym: 17.505943\t\tSpars: 1013.067627\n",
      "\t TVw: -0.404469 | TVb: -2.043670 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1644 [4000/8000 (50%)]\tBatch Loss: 1030.911952\tLearning Rate (w_theta): 0.001000\t TIME:2543.2s\n",
      "\t\t\t\tDisc: 1.127219\t\tSym: 18.603947\t\tSpars: 1011.180786\n",
      "\t TVw: -0.404198 | TVb: -2.043670 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1644...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1007.7777128889952\n",
      "Average validation loss: 153.35125752008494\n",
      "Training epoch 1645...\n",
      "\n",
      "Train Epoch: 1645 [0/8000 (0%)]\tBatch Loss: 1014.545246\tLearning Rate (w_theta): 0.001000\t TIME:2545.8s\n",
      "\t\t\t\tDisc: 1.166301\t\tSym: 17.137978\t\tSpars: 996.240967\n",
      "\t TVw: -0.403929 | TVb: -2.043670 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1645 [4000/8000 (50%)]\tBatch Loss: 978.135790\tLearning Rate (w_theta): 0.001000\t TIME:2547.3s\n",
      "\t\t\t\tDisc: 1.010513\t\tSym: 16.659945\t\tSpars: 960.465332\n",
      "\t TVw: -0.403657 | TVb: -2.043670 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1645...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1005.4846696567151\n",
      "Average validation loss: 154.13885679627103\n",
      "Training epoch 1646...\n",
      "\n",
      "Train Epoch: 1646 [0/8000 (0%)]\tBatch Loss: 1015.122363\tLearning Rate (w_theta): 0.001000\t TIME:2549.7s\n",
      "\t\t\t\tDisc: 1.220111\t\tSym: 17.423004\t\tSpars: 996.479248\n",
      "\t TVw: -0.403386 | TVb: -2.043670 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1646 [4000/8000 (50%)]\tBatch Loss: 1017.837385\tLearning Rate (w_theta): 0.001000\t TIME:2551.2s\n",
      "\t\t\t\tDisc: 1.054754\t\tSym: 16.976112\t\tSpars: 999.806519\n",
      "\t TVw: -0.403120 | TVb: -2.043670 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1646...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1008.0666893396096\n",
      "Average validation loss: 152.38249292926506\n",
      "Training epoch 1647...\n",
      "\n",
      "Train Epoch: 1647 [0/8000 (0%)]\tBatch Loss: 1022.670291\tLearning Rate (w_theta): 0.001000\t TIME:2553.6s\n",
      "\t\t\t\tDisc: 1.187927\t\tSym: 18.279667\t\tSpars: 1003.202698\n",
      "\t TVw: -0.402856 | TVb: -2.043671 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1647 [4000/8000 (50%)]\tBatch Loss: 979.250090\tLearning Rate (w_theta): 0.001000\t TIME:2555.1s\n",
      "\t\t\t\tDisc: 1.149681\t\tSym: 16.652411\t\tSpars: 961.447998\n",
      "\t TVw: -0.402586 | TVb: -2.043671 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1647...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1005.4365481053663\n",
      "Average validation loss: 152.08746683765622\n",
      "Training epoch 1648...\n",
      "\n",
      "Train Epoch: 1648 [0/8000 (0%)]\tBatch Loss: 1028.055694\tLearning Rate (w_theta): 0.001000\t TIME:2557.5s\n",
      "\t\t\t\tDisc: 1.097665\t\tSym: 18.664083\t\tSpars: 1008.293945\n",
      "\t TVw: -0.402317 | TVb: -2.043672 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1648 [4000/8000 (50%)]\tBatch Loss: 1033.256709\tLearning Rate (w_theta): 0.001000\t TIME:2559.0s\n",
      "\t\t\t\tDisc: 1.250402\t\tSym: 17.825338\t\tSpars: 1014.180969\n",
      "\t TVw: -0.402047 | TVb: -2.043672 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1648...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1004.9806595483948\n",
      "Average validation loss: 154.21765829758425\n",
      "Training epoch 1649...\n",
      "\n",
      "Train Epoch: 1649 [0/8000 (0%)]\tBatch Loss: 1047.569964\tLearning Rate (w_theta): 0.001000\t TIME:2561.5s\n",
      "\t\t\t\tDisc: 1.269246\t\tSym: 19.759947\t\tSpars: 1026.540771\n",
      "\t TVw: -0.401776 | TVb: -2.043673 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1649 [4000/8000 (50%)]\tBatch Loss: 994.750908\tLearning Rate (w_theta): 0.001000\t TIME:2563.0s\n",
      "\t\t\t\tDisc: 1.096003\t\tSym: 16.309263\t\tSpars: 977.345642\n",
      "\t TVw: -0.401505 | TVb: -2.043674 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1649...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1005.2028581491626\n",
      "Average validation loss: 153.43895101272457\n",
      "Training epoch 1650...\n",
      "\n",
      "Train Epoch: 1650 [0/8000 (0%)]\tBatch Loss: 976.169686\tLearning Rate (w_theta): 0.001000\t TIME:2565.4s\n",
      "\t\t\t\tDisc: 1.088742\t\tSym: 15.653209\t\tSpars: 959.427734\n",
      "\t TVw: -0.401235 | TVb: -2.043674 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1650 [4000/8000 (50%)]\tBatch Loss: 1062.450895\tLearning Rate (w_theta): 0.001000\t TIME:2566.9s\n",
      "\t\t\t\tDisc: 1.292776\t\tSym: 19.756508\t\tSpars: 1041.401611\n",
      "\t TVw: -0.400961 | TVb: -2.043674 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1650...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1006.7561092682051\n",
      "Average validation loss: 151.78900924813195\n",
      "Training epoch 1651...\n",
      "\n",
      "Train Epoch: 1651 [0/8000 (0%)]\tBatch Loss: 1052.693199\tLearning Rate (w_theta): 0.001000\t TIME:2569.9s\n",
      "\t\t\t\tDisc: 1.195969\t\tSym: 19.626137\t\tSpars: 1031.871094\n",
      "\t TVw: -0.400688 | TVb: -2.043674 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1651 [4000/8000 (50%)]\tBatch Loss: 986.882738\tLearning Rate (w_theta): 0.001000\t TIME:2571.4s\n",
      "\t\t\t\tDisc: 1.039570\t\tSym: 16.928495\t\tSpars: 968.914673\n",
      "\t TVw: -0.400413 | TVb: -2.043675 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1651...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1002.4331087117714\n",
      "Average validation loss: 152.04623683946747\n",
      "Training epoch 1652...\n",
      "\n",
      "Train Epoch: 1652 [0/8000 (0%)]\tBatch Loss: 1005.241183\tLearning Rate (w_theta): 0.001000\t TIME:2574.0s\n",
      "\t\t\t\tDisc: 1.169970\t\tSym: 17.221786\t\tSpars: 986.849426\n",
      "\t TVw: -0.400138 | TVb: -2.043675 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1652 [4000/8000 (50%)]\tBatch Loss: 1026.441099\tLearning Rate (w_theta): 0.001000\t TIME:2575.5s\n",
      "\t\t\t\tDisc: 1.250525\t\tSym: 17.486229\t\tSpars: 1007.704346\n",
      "\t TVw: -0.399860 | TVb: -2.043675 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1652...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1004.2501220398892\n",
      "Average validation loss: 151.71221238841895\n",
      "Training epoch 1653...\n",
      "\n",
      "Train Epoch: 1653 [0/8000 (0%)]\tBatch Loss: 961.559407\tLearning Rate (w_theta): 0.001000\t TIME:2577.9s\n",
      "\t\t\t\tDisc: 0.996988\t\tSym: 14.528850\t\tSpars: 946.033569\n",
      "\t TVw: -0.399584 | TVb: -2.043675 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1653 [4000/8000 (50%)]\tBatch Loss: 1012.628486\tLearning Rate (w_theta): 0.001000\t TIME:2579.5s\n",
      "\t\t\t\tDisc: 1.229328\t\tSym: 17.558826\t\tSpars: 993.840332\n",
      "\t TVw: -0.399305 | TVb: -2.043675 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1653...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1001.5130425350509\n",
      "Average validation loss: 151.8650185901061\n",
      "Training epoch 1654...\n",
      "\n",
      "Train Epoch: 1654 [0/8000 (0%)]\tBatch Loss: 992.801642\tLearning Rate (w_theta): 0.001000\t TIME:2581.8s\n",
      "\t\t\t\tDisc: 1.163680\t\tSym: 16.809898\t\tSpars: 974.828064\n",
      "\t TVw: -0.399027 | TVb: -2.043676 | GSw: -0.234959 | GSb: 0.065067 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1654 [4000/8000 (50%)]\tBatch Loss: 1001.497867\tLearning Rate (w_theta): 0.001000\t TIME:2583.3s\n",
      "\t\t\t\tDisc: 1.068502\t\tSym: 17.522810\t\tSpars: 982.906555\n",
      "\t TVw: -0.398751 | TVb: -2.043676 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1654...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1000.7547749813032\n",
      "Average validation loss: 152.1731357996664\n",
      "Training epoch 1655...\n",
      "\n",
      "Train Epoch: 1655 [0/8000 (0%)]\tBatch Loss: 1014.285244\tLearning Rate (w_theta): 0.001000\t TIME:2585.7s\n",
      "\t\t\t\tDisc: 1.188391\t\tSym: 17.506460\t\tSpars: 995.590393\n",
      "\t TVw: -0.398475 | TVb: -2.043677 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "\n",
      "Train Epoch: 1655 [4000/8000 (50%)]\tBatch Loss: 1003.883634\tLearning Rate (w_theta): 0.001000\t TIME:2587.2s\n",
      "\t\t\t\tDisc: 1.117296\t\tSym: 16.634075\t\tSpars: 986.132263\n",
      "\t TVw: -0.398199 | TVb: -2.043678 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034770\n",
      "Validating epoch 1655...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 999.2443538527679\n",
      "Average validation loss: 151.61995300408108\n",
      "Training epoch 1656...\n",
      "\n",
      "Train Epoch: 1656 [0/8000 (0%)]\tBatch Loss: 1002.669628\tLearning Rate (w_theta): 0.001000\t TIME:2589.6s\n",
      "\t\t\t\tDisc: 1.106549\t\tSym: 16.800385\t\tSpars: 984.762695\n",
      "\t TVw: -0.397922 | TVb: -2.043679 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1656 [4000/8000 (50%)]\tBatch Loss: 968.810775\tLearning Rate (w_theta): 0.001000\t TIME:2591.1s\n",
      "\t\t\t\tDisc: 1.021962\t\tSym: 16.365717\t\tSpars: 951.423096\n",
      "\t TVw: -0.397643 | TVb: -2.043679 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1656...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1002.1907786350349\n",
      "Average validation loss: 150.0880397810504\n",
      "Training epoch 1657...\n",
      "\n",
      "Train Epoch: 1657 [0/8000 (0%)]\tBatch Loss: 1005.340727\tLearning Rate (w_theta): 0.001000\t TIME:2593.6s\n",
      "\t\t\t\tDisc: 1.200760\t\tSym: 16.909010\t\tSpars: 987.230957\n",
      "\t TVw: -0.397361 | TVb: -2.043680 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1657 [4000/8000 (50%)]\tBatch Loss: 983.075230\tLearning Rate (w_theta): 0.001000\t TIME:2595.1s\n",
      "\t\t\t\tDisc: 1.005148\t\tSym: 16.283216\t\tSpars: 965.786865\n",
      "\t TVw: -0.397084 | TVb: -2.043681 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1657...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1004.4648320838213\n",
      "Average validation loss: 152.99759506846735\n",
      "Training epoch 1658...\n",
      "\n",
      "Train Epoch: 1658 [0/8000 (0%)]\tBatch Loss: 984.930509\tLearning Rate (w_theta): 0.001000\t TIME:2597.4s\n",
      "\t\t\t\tDisc: 1.100250\t\tSym: 15.955808\t\tSpars: 967.874451\n",
      "\t TVw: -0.396807 | TVb: -2.043681 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1658 [4000/8000 (50%)]\tBatch Loss: 957.839997\tLearning Rate (w_theta): 0.001000\t TIME:2599.0s\n",
      "\t\t\t\tDisc: 1.002683\t\tSym: 16.100376\t\tSpars: 940.736938\n",
      "\t TVw: -0.396531 | TVb: -2.043682 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1658...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 998.6178872187422\n",
      "Average validation loss: 151.30955500984652\n",
      "Training epoch 1659...\n",
      "\n",
      "Train Epoch: 1659 [0/8000 (0%)]\tBatch Loss: 1006.753974\tLearning Rate (w_theta): 0.001000\t TIME:2601.3s\n",
      "\t\t\t\tDisc: 1.040658\t\tSym: 18.215391\t\tSpars: 987.497925\n",
      "\t TVw: -0.396255 | TVb: -2.043683 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1659 [4000/8000 (50%)]\tBatch Loss: 951.824923\tLearning Rate (w_theta): 0.001000\t TIME:2602.9s\n",
      "\t\t\t\tDisc: 0.985049\t\tSym: 15.582611\t\tSpars: 935.257263\n",
      "\t TVw: -0.395973 | TVb: -2.043684 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1659...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 997.2931903255354\n",
      "Average validation loss: 151.89239399223015\n",
      "Training epoch 1660...\n",
      "\n",
      "Train Epoch: 1660 [0/8000 (0%)]\tBatch Loss: 1011.096290\tLearning Rate (w_theta): 0.001000\t TIME:2605.4s\n",
      "\t\t\t\tDisc: 1.111728\t\tSym: 17.776676\t\tSpars: 992.207886\n",
      "\t TVw: -0.395690 | TVb: -2.043684 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1660 [4000/8000 (50%)]\tBatch Loss: 995.337570\tLearning Rate (w_theta): 0.001000\t TIME:2607.0s\n",
      "\t\t\t\tDisc: 1.102205\t\tSym: 16.723951\t\tSpars: 977.511414\n",
      "\t TVw: -0.395407 | TVb: -2.043684 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1660...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 998.6326026250757\n",
      "Average validation loss: 151.4961847474745\n",
      "Training epoch 1661...\n",
      "\n",
      "Train Epoch: 1661 [0/8000 (0%)]\tBatch Loss: 998.702493\tLearning Rate (w_theta): 0.001000\t TIME:2610.1s\n",
      "\t\t\t\tDisc: 1.134130\t\tSym: 17.913273\t\tSpars: 979.655090\n",
      "\t TVw: -0.395122 | TVb: -2.043685 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1661 [4000/8000 (50%)]\tBatch Loss: 976.795632\tLearning Rate (w_theta): 0.001000\t TIME:2611.6s\n",
      "\t\t\t\tDisc: 1.070029\t\tSym: 16.453997\t\tSpars: 959.271606\n",
      "\t TVw: -0.394840 | TVb: -2.043685 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1661...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 998.7138390866621\n",
      "Average validation loss: 149.94711739888444\n",
      "Training epoch 1662...\n",
      "\n",
      "Train Epoch: 1662 [0/8000 (0%)]\tBatch Loss: 1042.848394\tLearning Rate (w_theta): 0.001000\t TIME:2614.0s\n",
      "\t\t\t\tDisc: 1.218837\t\tSym: 20.335733\t\tSpars: 1021.293823\n",
      "\t TVw: -0.394558 | TVb: -2.043686 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1662 [4000/8000 (50%)]\tBatch Loss: 936.116337\tLearning Rate (w_theta): 0.001000\t TIME:2615.5s\n",
      "\t\t\t\tDisc: 0.985424\t\tSym: 14.154533\t\tSpars: 920.976379\n",
      "\t TVw: -0.394279 | TVb: -2.043686 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1662...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 997.7922755765115\n",
      "Average validation loss: 151.1642510536646\n",
      "Training epoch 1663...\n",
      "\n",
      "Train Epoch: 1663 [0/8000 (0%)]\tBatch Loss: 1016.369053\tLearning Rate (w_theta): 0.001000\t TIME:2617.9s\n",
      "\t\t\t\tDisc: 1.109306\t\tSym: 17.336834\t\tSpars: 997.922913\n",
      "\t TVw: -0.393998 | TVb: -2.043687 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1663 [4000/8000 (50%)]\tBatch Loss: 989.607122\tLearning Rate (w_theta): 0.001000\t TIME:2619.4s\n",
      "\t\t\t\tDisc: 1.148549\t\tSym: 17.344803\t\tSpars: 971.113770\n",
      "\t TVw: -0.393714 | TVb: -2.043688 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1663...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 996.9419497589346\n",
      "Average validation loss: 149.3492851318176\n",
      "Training epoch 1664...\n",
      "\n",
      "Train Epoch: 1664 [0/8000 (0%)]\tBatch Loss: 1012.896929\tLearning Rate (w_theta): 0.001000\t TIME:2621.8s\n",
      "\t\t\t\tDisc: 1.188397\t\tSym: 17.008764\t\tSpars: 994.699768\n",
      "\t TVw: -0.393428 | TVb: -2.043688 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1664 [4000/8000 (50%)]\tBatch Loss: 1019.472897\tLearning Rate (w_theta): 0.001000\t TIME:2623.3s\n",
      "\t\t\t\tDisc: 1.082181\t\tSym: 17.426727\t\tSpars: 1000.963989\n",
      "\t TVw: -0.393146 | TVb: -2.043689 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1664...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1004.91596422565\n",
      "Average validation loss: 152.81499975767127\n",
      "Training epoch 1665...\n",
      "\n",
      "Train Epoch: 1665 [0/8000 (0%)]\tBatch Loss: 1027.722273\tLearning Rate (w_theta): 0.001000\t TIME:2625.7s\n",
      "\t\t\t\tDisc: 1.233652\t\tSym: 19.118809\t\tSpars: 1007.369812\n",
      "\t TVw: -0.392864 | TVb: -2.043689 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1665 [4000/8000 (50%)]\tBatch Loss: 979.820340\tLearning Rate (w_theta): 0.001000\t TIME:2627.2s\n",
      "\t\t\t\tDisc: 1.121274\t\tSym: 16.818878\t\tSpars: 961.880188\n",
      "\t TVw: -0.392582 | TVb: -2.043689 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1665...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1004.5297895897613\n",
      "Average validation loss: 149.64275232601022\n",
      "Training epoch 1666...\n",
      "\n",
      "Train Epoch: 1666 [0/8000 (0%)]\tBatch Loss: 980.392889\tLearning Rate (w_theta): 0.001000\t TIME:2629.6s\n",
      "\t\t\t\tDisc: 1.030849\t\tSym: 15.853067\t\tSpars: 963.508972\n",
      "\t TVw: -0.392304 | TVb: -2.043690 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1666 [4000/8000 (50%)]\tBatch Loss: 1005.646743\tLearning Rate (w_theta): 0.001000\t TIME:2631.1s\n",
      "\t\t\t\tDisc: 1.009976\t\tSym: 18.474779\t\tSpars: 986.161987\n",
      "\t TVw: -0.392024 | TVb: -2.043691 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1666...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 996.9344042821738\n",
      "Average validation loss: 150.6429524526379\n",
      "Training epoch 1667...\n",
      "\n",
      "Train Epoch: 1667 [0/8000 (0%)]\tBatch Loss: 976.040796\tLearning Rate (w_theta): 0.001000\t TIME:2633.7s\n",
      "\t\t\t\tDisc: 0.991534\t\tSym: 15.786323\t\tSpars: 959.262939\n",
      "\t TVw: -0.391734 | TVb: -2.043691 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1667 [4000/8000 (50%)]\tBatch Loss: 987.583635\tLearning Rate (w_theta): 0.001000\t TIME:2635.2s\n",
      "\t\t\t\tDisc: 1.018174\t\tSym: 16.924530\t\tSpars: 969.640930\n",
      "\t TVw: -0.391440 | TVb: -2.043691 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1667...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 996.4640829304079\n",
      "Average validation loss: 149.9943573978346\n",
      "Training epoch 1668...\n",
      "\n",
      "Train Epoch: 1668 [0/8000 (0%)]\tBatch Loss: 978.984086\tLearning Rate (w_theta): 0.001000\t TIME:2637.6s\n",
      "\t\t\t\tDisc: 1.025447\t\tSym: 16.218344\t\tSpars: 961.740295\n",
      "\t TVw: -0.391147 | TVb: -2.043691 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1668 [4000/8000 (50%)]\tBatch Loss: 1072.728038\tLearning Rate (w_theta): 0.001000\t TIME:2639.1s\n",
      "\t\t\t\tDisc: 1.353559\t\tSym: 20.073332\t\tSpars: 1051.301147\n",
      "\t TVw: -0.390852 | TVb: -2.043691 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1668...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 998.5623298111394\n",
      "Average validation loss: 150.24457480087776\n",
      "Training epoch 1669...\n",
      "\n",
      "Train Epoch: 1669 [0/8000 (0%)]\tBatch Loss: 1023.937607\tLearning Rate (w_theta): 0.001000\t TIME:2641.5s\n",
      "\t\t\t\tDisc: 1.092636\t\tSym: 18.624756\t\tSpars: 1004.220215\n",
      "\t TVw: -0.390563 | TVb: -2.043691 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1669 [4000/8000 (50%)]\tBatch Loss: 994.311382\tLearning Rate (w_theta): 0.001000\t TIME:2643.1s\n",
      "\t\t\t\tDisc: 1.001492\t\tSym: 16.764175\t\tSpars: 976.545715\n",
      "\t TVw: -0.390273 | TVb: -2.043692 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1669...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 993.5196096946219\n",
      "Average validation loss: 149.6773678975362\n",
      "Training epoch 1670...\n",
      "\n",
      "Train Epoch: 1670 [0/8000 (0%)]\tBatch Loss: 991.876762\tLearning Rate (w_theta): 0.001000\t TIME:2645.4s\n",
      "\t\t\t\tDisc: 1.109382\t\tSym: 17.239487\t\tSpars: 973.527893\n",
      "\t TVw: -0.389983 | TVb: -2.043693 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1670 [4000/8000 (50%)]\tBatch Loss: 972.209473\tLearning Rate (w_theta): 0.001000\t TIME:2647.0s\n",
      "\t\t\t\tDisc: 1.040629\t\tSym: 16.224142\t\tSpars: 954.944702\n",
      "\t TVw: -0.389692 | TVb: -2.043694 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1670...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 995.1486151817522\n",
      "Average validation loss: 149.8440671133903\n",
      "Training epoch 1671...\n",
      "\n",
      "Train Epoch: 1671 [0/8000 (0%)]\tBatch Loss: 959.337810\tLearning Rate (w_theta): 0.001000\t TIME:2650.0s\n",
      "\t\t\t\tDisc: 0.969745\t\tSym: 15.076195\t\tSpars: 943.291870\n",
      "\t TVw: -0.389402 | TVb: -2.043695 | GSw: -0.234959 | GSb: 0.065066 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1671 [4000/8000 (50%)]\tBatch Loss: 1013.228156\tLearning Rate (w_theta): 0.001000\t TIME:2651.5s\n",
      "\t\t\t\tDisc: 1.165852\t\tSym: 17.522631\t\tSpars: 994.539673\n",
      "\t TVw: -0.389110 | TVb: -2.043695 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1671...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 995.4382775088727\n",
      "Average validation loss: 149.771179509276\n",
      "Training epoch 1672...\n",
      "\n",
      "Train Epoch: 1672 [0/8000 (0%)]\tBatch Loss: 1027.691907\tLearning Rate (w_theta): 0.001000\t TIME:2653.9s\n",
      "\t\t\t\tDisc: 1.189689\t\tSym: 19.050314\t\tSpars: 1007.451904\n",
      "\t TVw: -0.388820 | TVb: -2.043696 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1672 [4000/8000 (50%)]\tBatch Loss: 962.291034\tLearning Rate (w_theta): 0.001000\t TIME:2655.4s\n",
      "\t\t\t\tDisc: 0.958672\t\tSym: 15.451564\t\tSpars: 945.880798\n",
      "\t TVw: -0.388530 | TVb: -2.043697 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1672...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 992.2828469562669\n",
      "Average validation loss: 150.06228334784754\n",
      "Training epoch 1673...\n",
      "\n",
      "Train Epoch: 1673 [0/8000 (0%)]\tBatch Loss: 994.387009\tLearning Rate (w_theta): 0.001000\t TIME:2658.1s\n",
      "\t\t\t\tDisc: 1.147859\t\tSym: 16.663588\t\tSpars: 976.575562\n",
      "\t TVw: -0.388236 | TVb: -2.043698 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1673 [4000/8000 (50%)]\tBatch Loss: 1001.384784\tLearning Rate (w_theta): 0.001000\t TIME:2659.6s\n",
      "\t\t\t\tDisc: 1.155504\t\tSym: 17.540010\t\tSpars: 982.689270\n",
      "\t TVw: -0.387942 | TVb: -2.043699 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1673...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 993.6653654260768\n",
      "Average validation loss: 147.96262977001433\n",
      "Training epoch 1674...\n",
      "\n",
      "Train Epoch: 1674 [0/8000 (0%)]\tBatch Loss: 1018.976354\tLearning Rate (w_theta): 0.001000\t TIME:2662.0s\n",
      "\t\t\t\tDisc: 1.164864\t\tSym: 17.041286\t\tSpars: 1000.770203\n",
      "\t TVw: -0.387648 | TVb: -2.043700 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1674 [4000/8000 (50%)]\tBatch Loss: 1001.013082\tLearning Rate (w_theta): 0.001000\t TIME:2663.5s\n",
      "\t\t\t\tDisc: 1.073012\t\tSym: 17.308966\t\tSpars: 982.631104\n",
      "\t TVw: -0.387351 | TVb: -2.043700 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1674...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1002.1833902821797\n",
      "Average validation loss: 152.0478982004484\n",
      "Training epoch 1675...\n",
      "\n",
      "Train Epoch: 1675 [0/8000 (0%)]\tBatch Loss: 1034.952382\tLearning Rate (w_theta): 0.001000\t TIME:2665.9s\n",
      "\t\t\t\tDisc: 1.250140\t\tSym: 19.792696\t\tSpars: 1013.909546\n",
      "\t TVw: -0.387057 | TVb: -2.043700 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1675 [4000/8000 (50%)]\tBatch Loss: 1017.613068\tLearning Rate (w_theta): 0.001000\t TIME:2667.4s\n",
      "\t\t\t\tDisc: 1.085904\t\tSym: 17.124943\t\tSpars: 999.402222\n",
      "\t TVw: -0.386767 | TVb: -2.043700 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1675...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1007.0238344625247\n",
      "Average validation loss: 150.65290928271125\n",
      "Training epoch 1676...\n",
      "\n",
      "Train Epoch: 1676 [0/8000 (0%)]\tBatch Loss: 987.664665\tLearning Rate (w_theta): 0.001000\t TIME:2669.8s\n",
      "\t\t\t\tDisc: 1.209440\t\tSym: 16.769495\t\tSpars: 969.685730\n",
      "\t TVw: -0.386479 | TVb: -2.043700 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1676 [4000/8000 (50%)]\tBatch Loss: 1001.482807\tLearning Rate (w_theta): 0.001000\t TIME:2671.3s\n",
      "\t\t\t\tDisc: 1.047043\t\tSym: 16.796543\t\tSpars: 983.639221\n",
      "\t TVw: -0.386194 | TVb: -2.043701 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1676...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1012.457540741089\n",
      "Average validation loss: 145.92801199965086\n",
      "Training epoch 1677...\n",
      "\n",
      "Train Epoch: 1677 [0/8000 (0%)]\tBatch Loss: 1019.390118\tLearning Rate (w_theta): 0.001000\t TIME:2673.7s\n",
      "\t\t\t\tDisc: 1.141082\t\tSym: 16.208265\t\tSpars: 1002.040771\n",
      "\t TVw: -0.385918 | TVb: -2.043702 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1677 [4000/8000 (50%)]\tBatch Loss: 1035.002059\tLearning Rate (w_theta): 0.001000\t TIME:2675.3s\n",
      "\t\t\t\tDisc: 1.091175\t\tSym: 18.032589\t\tSpars: 1015.878296\n",
      "\t TVw: -0.385647 | TVb: -2.043704 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1677...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1014.7467511149962\n",
      "Average validation loss: 148.1529163591731\n",
      "Training epoch 1678...\n",
      "\n",
      "Train Epoch: 1678 [0/8000 (0%)]\tBatch Loss: 991.638454\tLearning Rate (w_theta): 0.001000\t TIME:2677.7s\n",
      "\t\t\t\tDisc: 1.117351\t\tSym: 16.144150\t\tSpars: 974.376953\n",
      "\t TVw: -0.385367 | TVb: -2.043705 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1678 [4000/8000 (50%)]\tBatch Loss: 970.797876\tLearning Rate (w_theta): 0.001000\t TIME:2679.2s\n",
      "\t\t\t\tDisc: 0.975855\t\tSym: 15.924622\t\tSpars: 953.897400\n",
      "\t TVw: -0.385081 | TVb: -2.043707 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1678...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 996.3464100988363\n",
      "Average validation loss: 150.14020273626977\n",
      "Training epoch 1679...\n",
      "\n",
      "Train Epoch: 1679 [0/8000 (0%)]\tBatch Loss: 1023.760020\tLearning Rate (w_theta): 0.001000\t TIME:2681.6s\n",
      "\t\t\t\tDisc: 1.124452\t\tSym: 18.378489\t\tSpars: 1004.257080\n",
      "\t TVw: -0.384787 | TVb: -2.043707 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1679 [4000/8000 (50%)]\tBatch Loss: 963.276168\tLearning Rate (w_theta): 0.001000\t TIME:2683.1s\n",
      "\t\t\t\tDisc: 1.028392\t\tSym: 16.475620\t\tSpars: 945.772156\n",
      "\t TVw: -0.384489 | TVb: -2.043707 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1679...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 992.5054381217128\n",
      "Average validation loss: 150.42951786453466\n",
      "Training epoch 1680...\n",
      "\n",
      "Train Epoch: 1680 [0/8000 (0%)]\tBatch Loss: 978.595993\tLearning Rate (w_theta): 0.001000\t TIME:2685.5s\n",
      "\t\t\t\tDisc: 1.039696\t\tSym: 15.967918\t\tSpars: 961.588379\n",
      "\t TVw: -0.384183 | TVb: -2.043707 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1680 [4000/8000 (50%)]\tBatch Loss: 1004.050954\tLearning Rate (w_theta): 0.001000\t TIME:2687.0s\n",
      "\t\t\t\tDisc: 1.144834\t\tSym: 18.448723\t\tSpars: 984.457397\n",
      "\t TVw: -0.383869 | TVb: -2.043707 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1680...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 988.7023249757204\n",
      "Average validation loss: 149.56005052685802\n",
      "Training epoch 1681...\n",
      "\n",
      "Train Epoch: 1681 [0/8000 (0%)]\tBatch Loss: 958.593800\tLearning Rate (w_theta): 0.001000\t TIME:2690.4s\n",
      "\t\t\t\tDisc: 1.014677\t\tSym: 15.703452\t\tSpars: 941.875671\n",
      "\t TVw: -0.383555 | TVb: -2.043707 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1681 [4000/8000 (50%)]\tBatch Loss: 984.914289\tLearning Rate (w_theta): 0.001000\t TIME:2692.0s\n",
      "\t\t\t\tDisc: 1.043983\t\tSym: 16.757757\t\tSpars: 967.112549\n",
      "\t TVw: -0.383238 | TVb: -2.043707 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1681...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 987.312281772002\n",
      "Average validation loss: 147.87044471810273\n",
      "Training epoch 1682...\n",
      "\n",
      "Train Epoch: 1682 [0/8000 (0%)]\tBatch Loss: 1026.177146\tLearning Rate (w_theta): 0.001000\t TIME:2694.3s\n",
      "\t\t\t\tDisc: 1.060312\t\tSym: 18.483046\t\tSpars: 1006.633789\n",
      "\t TVw: -0.382924 | TVb: -2.043707 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1682 [4000/8000 (50%)]\tBatch Loss: 970.411223\tLearning Rate (w_theta): 0.001000\t TIME:2695.8s\n",
      "\t\t\t\tDisc: 1.081521\t\tSym: 16.352835\t\tSpars: 952.976868\n",
      "\t TVw: -0.382610 | TVb: -2.043707 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1682...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 987.1818250549933\n",
      "Average validation loss: 148.29459443963273\n",
      "Training epoch 1683...\n",
      "\n",
      "Train Epoch: 1683 [0/8000 (0%)]\tBatch Loss: 1016.496657\tLearning Rate (w_theta): 0.001000\t TIME:2698.2s\n",
      "\t\t\t\tDisc: 1.230667\t\tSym: 19.110899\t\tSpars: 996.155090\n",
      "\t TVw: -0.382297 | TVb: -2.043707 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1683 [4000/8000 (50%)]\tBatch Loss: 997.565414\tLearning Rate (w_theta): 0.001000\t TIME:2699.7s\n",
      "\t\t\t\tDisc: 1.060859\t\tSym: 17.893288\t\tSpars: 978.611267\n",
      "\t TVw: -0.381987 | TVb: -2.043707 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1683...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 985.6887477218474\n",
      "Average validation loss: 148.41321179644353\n",
      "Training epoch 1684...\n",
      "\n",
      "Train Epoch: 1684 [0/8000 (0%)]\tBatch Loss: 982.959630\tLearning Rate (w_theta): 0.001000\t TIME:2702.1s\n",
      "\t\t\t\tDisc: 1.016829\t\tSym: 17.211843\t\tSpars: 964.730957\n",
      "\t TVw: -0.381674 | TVb: -2.043708 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1684 [4000/8000 (50%)]\tBatch Loss: 958.592020\tLearning Rate (w_theta): 0.001000\t TIME:2703.6s\n",
      "\t\t\t\tDisc: 0.953779\t\tSym: 16.558651\t\tSpars: 941.079590\n",
      "\t TVw: -0.381357 | TVb: -2.043708 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1684...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 987.4048351233359\n",
      "Average validation loss: 147.8838218127981\n",
      "Training epoch 1685...\n",
      "\n",
      "Train Epoch: 1685 [0/8000 (0%)]\tBatch Loss: 984.792203\tLearning Rate (w_theta): 0.001000\t TIME:2706.0s\n",
      "\t\t\t\tDisc: 1.044589\t\tSym: 16.974665\t\tSpars: 966.772949\n",
      "\t TVw: -0.381045 | TVb: -2.043708 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1685 [4000/8000 (50%)]\tBatch Loss: 978.262607\tLearning Rate (w_theta): 0.001000\t TIME:2707.6s\n",
      "\t\t\t\tDisc: 1.058841\t\tSym: 16.437286\t\tSpars: 960.766479\n",
      "\t TVw: -0.380732 | TVb: -2.043709 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1685...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 986.8797548446848\n",
      "Average validation loss: 147.4910094852718\n",
      "Training epoch 1686...\n",
      "\n",
      "Train Epoch: 1686 [0/8000 (0%)]\tBatch Loss: 964.379666\tLearning Rate (w_theta): 0.001000\t TIME:2709.9s\n",
      "\t\t\t\tDisc: 0.994664\t\tSym: 16.159233\t\tSpars: 947.225769\n",
      "\t TVw: -0.380420 | TVb: -2.043709 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1686 [4000/8000 (50%)]\tBatch Loss: 970.042472\tLearning Rate (w_theta): 0.001000\t TIME:2711.5s\n",
      "\t\t\t\tDisc: 0.958900\t\tSym: 16.374466\t\tSpars: 952.709106\n",
      "\t TVw: -0.380111 | TVb: -2.043710 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1686...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 984.6585848011982\n",
      "Average validation loss: 146.4456446332127\n",
      "Training epoch 1687...\n",
      "\n",
      "Train Epoch: 1687 [0/8000 (0%)]\tBatch Loss: 988.618770\tLearning Rate (w_theta): 0.001000\t TIME:2713.8s\n",
      "\t\t\t\tDisc: 1.063692\t\tSym: 17.388086\t\tSpars: 970.166992\n",
      "\t TVw: -0.379798 | TVb: -2.043710 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1687 [4000/8000 (50%)]\tBatch Loss: 990.476032\tLearning Rate (w_theta): 0.001000\t TIME:2715.3s\n",
      "\t\t\t\tDisc: 1.011047\t\tSym: 17.287678\t\tSpars: 972.177307\n",
      "\t TVw: -0.379480 | TVb: -2.043710 | GSw: -0.234959 | GSb: 0.065065 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1687...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 990.7421535560634\n",
      "Average validation loss: 150.24197280933117\n",
      "Training epoch 1688...\n",
      "\n",
      "Train Epoch: 1688 [0/8000 (0%)]\tBatch Loss: 974.123889\tLearning Rate (w_theta): 0.001000\t TIME:2717.7s\n",
      "\t\t\t\tDisc: 0.951737\t\tSym: 15.000887\t\tSpars: 958.171265\n",
      "\t TVw: -0.379163 | TVb: -2.043710 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1688 [4000/8000 (50%)]\tBatch Loss: 963.275018\tLearning Rate (w_theta): 0.001000\t TIME:2719.2s\n",
      "\t\t\t\tDisc: 1.117678\t\tSym: 15.486503\t\tSpars: 946.670837\n",
      "\t TVw: -0.378848 | TVb: -2.043710 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "Validating epoch 1688...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1001.6896188509454\n",
      "Average validation loss: 145.7938182662523\n",
      "Training epoch 1689...\n",
      "\n",
      "Train Epoch: 1689 [0/8000 (0%)]\tBatch Loss: 1009.376716\tLearning Rate (w_theta): 0.001000\t TIME:2721.9s\n",
      "\t\t\t\tDisc: 1.222068\t\tSym: 18.467941\t\tSpars: 989.686707\n",
      "\t TVw: -0.378543 | TVb: -2.043710 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034771\n",
      "\n",
      "Train Epoch: 1689 [4000/8000 (50%)]\tBatch Loss: 1000.669660\tLearning Rate (w_theta): 0.001000\t TIME:2723.4s\n",
      "\t\t\t\tDisc: 1.140398\t\tSym: 17.121120\t\tSpars: 982.408142\n",
      "\t TVw: -0.378248 | TVb: -2.043710 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1689...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1008.1921628548058\n",
      "Average validation loss: 145.8924821555771\n",
      "Training epoch 1690...\n",
      "\n",
      "Train Epoch: 1690 [0/8000 (0%)]\tBatch Loss: 980.440918\tLearning Rate (w_theta): 0.001000\t TIME:2725.8s\n",
      "\t\t\t\tDisc: 1.044854\t\tSym: 15.793647\t\tSpars: 963.602417\n",
      "\t TVw: -0.377954 | TVb: -2.043711 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1690 [4000/8000 (50%)]\tBatch Loss: 1026.741051\tLearning Rate (w_theta): 0.001000\t TIME:2727.3s\n",
      "\t\t\t\tDisc: 1.228861\t\tSym: 19.489058\t\tSpars: 1006.023132\n",
      "\t TVw: -0.377649 | TVb: -2.043711 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1690...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 995.1382688276428\n",
      "Average validation loss: 145.2517109289422\n",
      "Training epoch 1691...\n",
      "\n",
      "Train Epoch: 1691 [0/8000 (0%)]\tBatch Loss: 982.756552\tLearning Rate (w_theta): 0.001000\t TIME:2730.4s\n",
      "\t\t\t\tDisc: 0.996856\t\tSym: 16.729973\t\tSpars: 965.029724\n",
      "\t TVw: -0.377342 | TVb: -2.043712 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1691 [4000/8000 (50%)]\tBatch Loss: 997.035249\tLearning Rate (w_theta): 0.001000\t TIME:2731.9s\n",
      "\t\t\t\tDisc: 1.071357\t\tSym: 17.240564\t\tSpars: 978.723328\n",
      "\t TVw: -0.377032 | TVb: -2.043712 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1691...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 989.3362081632239\n",
      "Average validation loss: 146.54776061347806\n",
      "Training epoch 1692...\n",
      "\n",
      "Train Epoch: 1692 [0/8000 (0%)]\tBatch Loss: 995.158917\tLearning Rate (w_theta): 0.001000\t TIME:2734.3s\n",
      "\t\t\t\tDisc: 1.170939\t\tSym: 17.394289\t\tSpars: 976.593689\n",
      "\t TVw: -0.376717 | TVb: -2.043713 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1692 [4000/8000 (50%)]\tBatch Loss: 977.145794\tLearning Rate (w_theta): 0.001000\t TIME:2735.8s\n",
      "\t\t\t\tDisc: 1.101080\t\tSym: 16.696203\t\tSpars: 959.348511\n",
      "\t TVw: -0.376401 | TVb: -2.043714 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1692...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 988.4682732952907\n",
      "Average validation loss: 146.42336500952214\n",
      "Training epoch 1693...\n",
      "\n",
      "Train Epoch: 1693 [0/8000 (0%)]\tBatch Loss: 969.543763\tLearning Rate (w_theta): 0.001000\t TIME:2738.2s\n",
      "\t\t\t\tDisc: 1.036500\t\tSym: 15.415955\t\tSpars: 953.091309\n",
      "\t TVw: -0.376089 | TVb: -2.043715 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1693 [4000/8000 (50%)]\tBatch Loss: 994.244021\tLearning Rate (w_theta): 0.001000\t TIME:2739.8s\n",
      "\t\t\t\tDisc: 0.939270\t\tSym: 16.768740\t\tSpars: 976.536011\n",
      "\t TVw: -0.375779 | TVb: -2.043715 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1693...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 986.7677378862702\n",
      "Average validation loss: 145.07391611508623\n",
      "Training epoch 1694...\n",
      "\n",
      "Train Epoch: 1694 [0/8000 (0%)]\tBatch Loss: 1016.957412\tLearning Rate (w_theta): 0.001000\t TIME:2742.1s\n",
      "\t\t\t\tDisc: 1.183557\t\tSym: 17.566397\t\tSpars: 998.207458\n",
      "\t TVw: -0.375471 | TVb: -2.043716 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1694 [4000/8000 (50%)]\tBatch Loss: 973.668123\tLearning Rate (w_theta): 0.001000\t TIME:2743.7s\n",
      "\t\t\t\tDisc: 1.009273\t\tSym: 16.800207\t\tSpars: 955.858643\n",
      "\t TVw: -0.375155 | TVb: -2.043717 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1694...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 985.0796255526327\n",
      "Average validation loss: 146.08545777495223\n",
      "Training epoch 1695...\n",
      "\n",
      "Train Epoch: 1695 [0/8000 (0%)]\tBatch Loss: 992.028503\tLearning Rate (w_theta): 0.001000\t TIME:2746.0s\n",
      "\t\t\t\tDisc: 1.074342\t\tSym: 17.502562\t\tSpars: 973.451599\n",
      "\t TVw: -0.374839 | TVb: -2.043717 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1695 [4000/8000 (50%)]\tBatch Loss: 998.686085\tLearning Rate (w_theta): 0.001000\t TIME:2747.6s\n",
      "\t\t\t\tDisc: 1.041340\t\tSym: 16.896393\t\tSpars: 980.748352\n",
      "\t TVw: -0.374518 | TVb: -2.043717 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1695...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 982.5450735630556\n",
      "Average validation loss: 145.49959216222277\n",
      "Training epoch 1696...\n",
      "\n",
      "Train Epoch: 1696 [0/8000 (0%)]\tBatch Loss: 1036.051964\tLearning Rate (w_theta): 0.001000\t TIME:2750.1s\n",
      "\t\t\t\tDisc: 1.027033\t\tSym: 18.980314\t\tSpars: 1016.044617\n",
      "\t TVw: -0.374197 | TVb: -2.043718 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1696 [4000/8000 (50%)]\tBatch Loss: 942.261331\tLearning Rate (w_theta): 0.001000\t TIME:2751.7s\n",
      "\t\t\t\tDisc: 0.969395\t\tSym: 15.132817\t\tSpars: 926.159119\n",
      "\t TVw: -0.373877 | TVb: -2.043718 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1696...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 982.4401251962086\n",
      "Average validation loss: 145.2320198876822\n",
      "Training epoch 1697...\n",
      "\n",
      "Train Epoch: 1697 [0/8000 (0%)]\tBatch Loss: 959.897096\tLearning Rate (w_theta): 0.001000\t TIME:2754.1s\n",
      "\t\t\t\tDisc: 0.983769\t\tSym: 16.566952\t\tSpars: 942.346375\n",
      "\t TVw: -0.373554 | TVb: -2.043718 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1697 [4000/8000 (50%)]\tBatch Loss: 995.403911\tLearning Rate (w_theta): 0.001000\t TIME:2755.6s\n",
      "\t\t\t\tDisc: 1.120077\t\tSym: 17.209188\t\tSpars: 977.074646\n",
      "\t TVw: -0.373235 | TVb: -2.043719 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1697...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 980.006802553758\n",
      "Average validation loss: 145.72424633861482\n",
      "Training epoch 1698...\n",
      "\n",
      "Train Epoch: 1698 [0/8000 (0%)]\tBatch Loss: 970.719495\tLearning Rate (w_theta): 0.001000\t TIME:2758.0s\n",
      "\t\t\t\tDisc: 1.070823\t\tSym: 16.289419\t\tSpars: 953.359253\n",
      "\t TVw: -0.372914 | TVb: -2.043719 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1698 [4000/8000 (50%)]\tBatch Loss: 943.863998\tLearning Rate (w_theta): 0.001000\t TIME:2759.5s\n",
      "\t\t\t\tDisc: 0.962037\t\tSym: 15.447371\t\tSpars: 927.454590\n",
      "\t TVw: -0.372593 | TVb: -2.043719 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1698...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 979.1787085675776\n",
      "Average validation loss: 144.5184704357427\n",
      "Training epoch 1699...\n",
      "\n",
      "Train Epoch: 1699 [0/8000 (0%)]\tBatch Loss: 994.332814\tLearning Rate (w_theta): 0.001000\t TIME:2761.9s\n",
      "\t\t\t\tDisc: 0.989579\t\tSym: 17.710361\t\tSpars: 975.632874\n",
      "\t TVw: -0.372269 | TVb: -2.043720 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1699 [4000/8000 (50%)]\tBatch Loss: 973.105628\tLearning Rate (w_theta): 0.001000\t TIME:2763.4s\n",
      "\t\t\t\tDisc: 0.985027\t\tSym: 15.828242\t\tSpars: 956.292358\n",
      "\t TVw: -0.371944 | TVb: -2.043720 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1699...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 980.2312365940822\n",
      "Average validation loss: 145.4138622275022\n",
      "Training epoch 1700...\n",
      "\n",
      "Train Epoch: 1700 [0/8000 (0%)]\tBatch Loss: 975.307429\tLearning Rate (w_theta): 0.001000\t TIME:2765.8s\n",
      "\t\t\t\tDisc: 1.091893\t\tSym: 17.432211\t\tSpars: 956.783325\n",
      "\t TVw: -0.371620 | TVb: -2.043721 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1700 [4000/8000 (50%)]\tBatch Loss: 983.691774\tLearning Rate (w_theta): 0.001000\t TIME:2767.3s\n",
      "\t\t\t\tDisc: 1.053620\t\tSym: 16.821442\t\tSpars: 965.816711\n",
      "\t TVw: -0.371300 | TVb: -2.043721 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1700...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 979.5338558698764\n",
      "Average validation loss: 144.3439772831052\n",
      "Training epoch 1701...\n",
      "\n",
      "Train Epoch: 1701 [0/8000 (0%)]\tBatch Loss: 982.024381\tLearning Rate (w_theta): 0.001000\t TIME:2770.5s\n",
      "\t\t\t\tDisc: 0.973136\t\tSym: 17.086279\t\tSpars: 963.964966\n",
      "\t TVw: -0.370975 | TVb: -2.043722 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1701 [4000/8000 (50%)]\tBatch Loss: 996.155941\tLearning Rate (w_theta): 0.001000\t TIME:2772.0s\n",
      "\t\t\t\tDisc: 1.069336\t\tSym: 17.414791\t\tSpars: 977.671814\n",
      "\t TVw: -0.370650 | TVb: -2.043723 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1701...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 980.4566478109803\n",
      "Average validation loss: 146.42768880996738\n",
      "Training epoch 1702...\n",
      "\n",
      "Train Epoch: 1702 [0/8000 (0%)]\tBatch Loss: 983.777655\tLearning Rate (w_theta): 0.001000\t TIME:2774.4s\n",
      "\t\t\t\tDisc: 1.142742\t\tSym: 17.110620\t\tSpars: 965.524292\n",
      "\t TVw: -0.370330 | TVb: -2.043723 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1702 [4000/8000 (50%)]\tBatch Loss: 1002.094041\tLearning Rate (w_theta): 0.001000\t TIME:2775.9s\n",
      "\t\t\t\tDisc: 1.120436\t\tSym: 17.891390\t\tSpars: 983.082214\n",
      "\t TVw: -0.370011 | TVb: -2.043724 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1702...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 982.8765413288551\n",
      "Average validation loss: 143.67767322244416\n",
      "Training epoch 1703...\n",
      "\n",
      "Train Epoch: 1703 [0/8000 (0%)]\tBatch Loss: 977.894848\tLearning Rate (w_theta): 0.001000\t TIME:2778.5s\n",
      "\t\t\t\tDisc: 0.994556\t\tSym: 16.396629\t\tSpars: 960.503662\n",
      "\t TVw: -0.369691 | TVb: -2.043725 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1703 [4000/8000 (50%)]\tBatch Loss: 954.522187\tLearning Rate (w_theta): 0.001000\t TIME:2780.0s\n",
      "\t\t\t\tDisc: 1.014692\t\tSym: 15.617236\t\tSpars: 937.890259\n",
      "\t TVw: -0.369369 | TVb: -2.043725 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1703...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 981.5934185326126\n",
      "Average validation loss: 145.8544501114031\n",
      "Training epoch 1704...\n",
      "\n",
      "Train Epoch: 1704 [0/8000 (0%)]\tBatch Loss: 986.206447\tLearning Rate (w_theta): 0.001000\t TIME:2782.4s\n",
      "\t\t\t\tDisc: 1.148000\t\tSym: 17.355871\t\tSpars: 967.702576\n",
      "\t TVw: -0.369051 | TVb: -2.043725 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1704 [4000/8000 (50%)]\tBatch Loss: 949.547981\tLearning Rate (w_theta): 0.001000\t TIME:2783.9s\n",
      "\t\t\t\tDisc: 1.019841\t\tSym: 15.252078\t\tSpars: 933.276062\n",
      "\t TVw: -0.368736 | TVb: -2.043725 | GSw: -0.234959 | GSb: 0.065064 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1704...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 983.4428521109642\n",
      "Average validation loss: 142.96562971633503\n",
      "Training epoch 1705...\n",
      "\n",
      "Train Epoch: 1705 [0/8000 (0%)]\tBatch Loss: 994.779004\tLearning Rate (w_theta): 0.001000\t TIME:2786.3s\n",
      "\t\t\t\tDisc: 1.103067\t\tSym: 17.705784\t\tSpars: 975.970154\n",
      "\t TVw: -0.368416 | TVb: -2.043725 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1705 [4000/8000 (50%)]\tBatch Loss: 941.346031\tLearning Rate (w_theta): 0.001000\t TIME:2787.8s\n",
      "\t\t\t\tDisc: 0.938029\t\tSym: 14.543134\t\tSpars: 925.864868\n",
      "\t TVw: -0.368097 | TVb: -2.043726 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1705...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 981.5887250897661\n",
      "Average validation loss: 144.38199430293332\n",
      "Training epoch 1706...\n",
      "\n",
      "Train Epoch: 1706 [0/8000 (0%)]\tBatch Loss: 1008.657344\tLearning Rate (w_theta): 0.001000\t TIME:2790.2s\n",
      "\t\t\t\tDisc: 1.058294\t\tSym: 18.312796\t\tSpars: 989.286255\n",
      "\t TVw: -0.367779 | TVb: -2.043727 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1706 [4000/8000 (50%)]\tBatch Loss: 934.062466\tLearning Rate (w_theta): 0.001000\t TIME:2791.7s\n",
      "\t\t\t\tDisc: 0.937589\t\tSym: 15.620116\t\tSpars: 917.504761\n",
      "\t TVw: -0.367464 | TVb: -2.043727 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1706...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 975.7736052234632\n",
      "Average validation loss: 143.336738191225\n",
      "Training epoch 1707...\n",
      "\n",
      "Train Epoch: 1707 [0/8000 (0%)]\tBatch Loss: 978.886122\tLearning Rate (w_theta): 0.001000\t TIME:2794.1s\n",
      "\t\t\t\tDisc: 1.006943\t\tSym: 16.304045\t\tSpars: 961.575134\n",
      "\t TVw: -0.367137 | TVb: -2.043728 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1707 [4000/8000 (50%)]\tBatch Loss: 977.657277\tLearning Rate (w_theta): 0.001000\t TIME:2795.7s\n",
      "\t\t\t\tDisc: 1.015676\t\tSym: 17.625183\t\tSpars: 959.016418\n",
      "\t TVw: -0.366806 | TVb: -2.043729 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1707...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 975.1281530431633\n",
      "Average validation loss: 143.9749703045285\n",
      "Training epoch 1708...\n",
      "\n",
      "Train Epoch: 1708 [0/8000 (0%)]\tBatch Loss: 988.279745\tLearning Rate (w_theta): 0.001000\t TIME:2798.0s\n",
      "\t\t\t\tDisc: 1.000051\t\tSym: 16.380768\t\tSpars: 970.898926\n",
      "\t TVw: -0.366474 | TVb: -2.043730 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1708 [4000/8000 (50%)]\tBatch Loss: 961.485230\tLearning Rate (w_theta): 0.001000\t TIME:2799.6s\n",
      "\t\t\t\tDisc: 1.016911\t\tSym: 16.390072\t\tSpars: 944.078247\n",
      "\t TVw: -0.366146 | TVb: -2.043730 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1708...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 976.993760032663\n",
      "Average validation loss: 143.36542056403314\n",
      "Training epoch 1709...\n",
      "\n",
      "Train Epoch: 1709 [0/8000 (0%)]\tBatch Loss: 937.995691\tLearning Rate (w_theta): 0.001000\t TIME:2802.0s\n",
      "\t\t\t\tDisc: 0.863437\t\tSym: 14.949149\t\tSpars: 922.183105\n",
      "\t TVw: -0.365816 | TVb: -2.043730 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1709 [4000/8000 (50%)]\tBatch Loss: 972.215809\tLearning Rate (w_theta): 0.001000\t TIME:2803.5s\n",
      "\t\t\t\tDisc: 1.020727\t\tSym: 17.010450\t\tSpars: 954.184631\n",
      "\t TVw: -0.365482 | TVb: -2.043730 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1709...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 976.7858984829417\n",
      "Average validation loss: 144.08402795267054\n",
      "Training epoch 1710...\n",
      "\n",
      "Train Epoch: 1710 [0/8000 (0%)]\tBatch Loss: 978.123597\tLearning Rate (w_theta): 0.001000\t TIME:2805.9s\n",
      "\t\t\t\tDisc: 1.020190\t\tSym: 16.645338\t\tSpars: 960.458069\n",
      "\t TVw: -0.365145 | TVb: -2.043730 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1710 [4000/8000 (50%)]\tBatch Loss: 953.564187\tLearning Rate (w_theta): 0.001000\t TIME:2807.5s\n",
      "\t\t\t\tDisc: 0.976492\t\tSym: 15.794298\t\tSpars: 936.793396\n",
      "\t TVw: -0.364805 | TVb: -2.043730 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1710...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 974.6332628145593\n",
      "Average validation loss: 142.90679444905538\n",
      "Training epoch 1711...\n",
      "\n",
      "Train Epoch: 1711 [0/8000 (0%)]\tBatch Loss: 983.384805\tLearning Rate (w_theta): 0.001000\t TIME:2810.7s\n",
      "\t\t\t\tDisc: 1.056621\t\tSym: 16.335325\t\tSpars: 965.992859\n",
      "\t TVw: -0.364471 | TVb: -2.043730 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1711 [4000/8000 (50%)]\tBatch Loss: 957.743017\tLearning Rate (w_theta): 0.001000\t TIME:2812.3s\n",
      "\t\t\t\tDisc: 0.999169\t\tSym: 16.484327\t\tSpars: 940.259521\n",
      "\t TVw: -0.364139 | TVb: -2.043730 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1711...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 973.9716575254865\n",
      "Average validation loss: 143.25431056996342\n",
      "Training epoch 1712...\n",
      "\n",
      "Train Epoch: 1712 [0/8000 (0%)]\tBatch Loss: 959.923542\tLearning Rate (w_theta): 0.001000\t TIME:2814.6s\n",
      "\t\t\t\tDisc: 0.958549\t\tSym: 16.159145\t\tSpars: 942.805847\n",
      "\t TVw: -0.363806 | TVb: -2.043730 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1712 [4000/8000 (50%)]\tBatch Loss: 981.020352\tLearning Rate (w_theta): 0.001000\t TIME:2816.2s\n",
      "\t\t\t\tDisc: 1.043772\t\tSym: 16.918840\t\tSpars: 963.057739\n",
      "\t TVw: -0.363472 | TVb: -2.043731 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1712...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 973.6921943303203\n",
      "Average validation loss: 142.4922224865002\n",
      "Training epoch 1713...\n",
      "\n",
      "Train Epoch: 1713 [0/8000 (0%)]\tBatch Loss: 975.379135\tLearning Rate (w_theta): 0.001000\t TIME:2818.6s\n",
      "\t\t\t\tDisc: 0.927244\t\tSym: 16.991869\t\tSpars: 957.460022\n",
      "\t TVw: -0.363141 | TVb: -2.043732 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1713 [4000/8000 (50%)]\tBatch Loss: 1016.985329\tLearning Rate (w_theta): 0.001000\t TIME:2820.1s\n",
      "\t\t\t\tDisc: 1.136859\t\tSym: 18.371237\t\tSpars: 997.477234\n",
      "\t TVw: -0.362806 | TVb: -2.043733 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1713...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 984.2328365129895\n",
      "Average validation loss: 141.87949015110013\n",
      "Training epoch 1714...\n",
      "\n",
      "Train Epoch: 1714 [0/8000 (0%)]\tBatch Loss: 1000.917127\tLearning Rate (w_theta): 0.001000\t TIME:2822.5s\n",
      "\t\t\t\tDisc: 1.141020\t\tSym: 17.944382\t\tSpars: 981.831726\n",
      "\t TVw: -0.362472 | TVb: -2.043733 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1714 [4000/8000 (50%)]\tBatch Loss: 1019.304828\tLearning Rate (w_theta): 0.001000\t TIME:2824.1s\n",
      "\t\t\t\tDisc: 1.088970\t\tSym: 17.135414\t\tSpars: 1001.080444\n",
      "\t TVw: -0.362145 | TVb: -2.043733 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1714...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 985.5435394863297\n",
      "Average validation loss: 143.0362488723362\n",
      "Training epoch 1715...\n",
      "\n",
      "Train Epoch: 1715 [0/8000 (0%)]\tBatch Loss: 950.953262\tLearning Rate (w_theta): 0.001000\t TIME:2826.4s\n",
      "\t\t\t\tDisc: 0.913655\t\tSym: 15.336665\t\tSpars: 934.702942\n",
      "\t TVw: -0.361817 | TVb: -2.043734 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1715 [4000/8000 (50%)]\tBatch Loss: 950.810400\tLearning Rate (w_theta): 0.001000\t TIME:2828.0s\n",
      "\t\t\t\tDisc: 0.973781\t\tSym: 15.823801\t\tSpars: 934.012817\n",
      "\t TVw: -0.361482 | TVb: -2.043733 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1715...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 973.4225158888368\n",
      "Average validation loss: 142.4162022092509\n",
      "Training epoch 1716...\n",
      "\n",
      "Train Epoch: 1716 [0/8000 (0%)]\tBatch Loss: 916.946007\tLearning Rate (w_theta): 0.001000\t TIME:2830.4s\n",
      "\t\t\t\tDisc: 0.906043\t\tSym: 14.082750\t\tSpars: 901.957214\n",
      "\t TVw: -0.361144 | TVb: -2.043734 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1716 [4000/8000 (50%)]\tBatch Loss: 1001.666132\tLearning Rate (w_theta): 0.001000\t TIME:2831.9s\n",
      "\t\t\t\tDisc: 1.108410\t\tSym: 17.177046\t\tSpars: 983.380676\n",
      "\t TVw: -0.360806 | TVb: -2.043734 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1716...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 971.8024265261924\n",
      "Average validation loss: 142.10161866427939\n",
      "Training epoch 1717...\n",
      "\n",
      "Train Epoch: 1717 [0/8000 (0%)]\tBatch Loss: 952.980244\tLearning Rate (w_theta): 0.001000\t TIME:2834.3s\n",
      "\t\t\t\tDisc: 1.010187\t\tSym: 15.656214\t\tSpars: 936.313843\n",
      "\t TVw: -0.360470 | TVb: -2.043734 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1717 [4000/8000 (50%)]\tBatch Loss: 972.621265\tLearning Rate (w_theta): 0.001000\t TIME:2835.8s\n",
      "\t\t\t\tDisc: 0.969280\t\tSym: 17.521797\t\tSpars: 954.130188\n",
      "\t TVw: -0.360128 | TVb: -2.043734 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1717...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 972.5870940136174\n",
      "Average validation loss: 140.682853493577\n",
      "Training epoch 1718...\n",
      "\n",
      "Train Epoch: 1718 [0/8000 (0%)]\tBatch Loss: 991.300448\tLearning Rate (w_theta): 0.001000\t TIME:2838.2s\n",
      "\t\t\t\tDisc: 1.146413\t\tSym: 17.877729\t\tSpars: 972.276306\n",
      "\t TVw: -0.359790 | TVb: -2.043735 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1718 [4000/8000 (50%)]\tBatch Loss: 981.985322\tLearning Rate (w_theta): 0.001000\t TIME:2839.7s\n",
      "\t\t\t\tDisc: 1.046224\t\tSym: 16.497997\t\tSpars: 964.441101\n",
      "\t TVw: -0.359451 | TVb: -2.043735 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1718...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 980.4813985089324\n",
      "Average validation loss: 140.52720342538512\n",
      "Training epoch 1719...\n",
      "\n",
      "Train Epoch: 1719 [0/8000 (0%)]\tBatch Loss: 939.482263\tLearning Rate (w_theta): 0.001000\t TIME:2842.3s\n",
      "\t\t\t\tDisc: 0.938560\t\tSym: 15.070742\t\tSpars: 923.472961\n",
      "\t TVw: -0.359121 | TVb: -2.043736 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1719 [4000/8000 (50%)]\tBatch Loss: 1048.016742\tLearning Rate (w_theta): 0.001000\t TIME:2843.8s\n",
      "\t\t\t\tDisc: 1.072926\t\tSym: 18.968107\t\tSpars: 1027.975708\n",
      "\t TVw: -0.358805 | TVb: -2.043737 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1719...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 1009.6837026793717\n",
      "Average validation loss: 145.49853324838\n",
      "Training epoch 1720...\n",
      "\n",
      "Train Epoch: 1720 [0/8000 (0%)]\tBatch Loss: 967.249646\tLearning Rate (w_theta): 0.001000\t TIME:2846.2s\n",
      "\t\t\t\tDisc: 1.064162\t\tSym: 15.310790\t\tSpars: 950.874695\n",
      "\t TVw: -0.358487 | TVb: -2.043738 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1720 [4000/8000 (50%)]\tBatch Loss: 1021.384926\tLearning Rate (w_theta): 0.001000\t TIME:2847.8s\n",
      "\t\t\t\tDisc: 1.232927\t\tSym: 18.214865\t\tSpars: 1001.937134\n",
      "\t TVw: -0.358168 | TVb: -2.043738 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1720...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 982.074409843623\n",
      "Average validation loss: 143.90942875605995\n",
      "Training epoch 1721...\n",
      "\n",
      "Train Epoch: 1721 [0/8000 (0%)]\tBatch Loss: 985.111697\tLearning Rate (w_theta): 0.001000\t TIME:2850.8s\n",
      "\t\t\t\tDisc: 1.167614\t\tSym: 16.442434\t\tSpars: 967.501648\n",
      "\t TVw: -0.357840 | TVb: -2.043738 | GSw: -0.234959 | GSb: 0.065063 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1721 [4000/8000 (50%)]\tBatch Loss: 954.348254\tLearning Rate (w_theta): 0.001000\t TIME:2852.4s\n",
      "\t\t\t\tDisc: 1.040174\t\tSym: 15.469884\t\tSpars: 937.838196\n",
      "\t TVw: -0.357511 | TVb: -2.043738 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1721...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 976.3836864430583\n",
      "Average validation loss: 139.71640894682054\n",
      "Training epoch 1722...\n",
      "\n",
      "Train Epoch: 1722 [0/8000 (0%)]\tBatch Loss: 941.318086\tLearning Rate (w_theta): 0.001000\t TIME:2854.7s\n",
      "\t\t\t\tDisc: 0.884695\t\tSym: 14.518596\t\tSpars: 925.914795\n",
      "\t TVw: -0.357174 | TVb: -2.043737 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "\n",
      "Train Epoch: 1722 [4000/8000 (50%)]\tBatch Loss: 1019.625418\tLearning Rate (w_theta): 0.001000\t TIME:2856.3s\n",
      "\t\t\t\tDisc: 1.058998\t\tSym: 18.421156\t\tSpars: 1000.145264\n",
      "\t TVw: -0.356832 | TVb: -2.043738 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034772\n",
      "Validating epoch 1722...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 975.0715283591142\n",
      "Average validation loss: 140.15145024601574\n",
      "Training epoch 1723...\n",
      "\n",
      "Train Epoch: 1723 [0/8000 (0%)]\tBatch Loss: 983.208243\tLearning Rate (w_theta): 0.001000\t TIME:2858.6s\n",
      "\t\t\t\tDisc: 0.886756\t\tSym: 17.057144\t\tSpars: 965.264343\n",
      "\t TVw: -0.356479 | TVb: -2.043738 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1723 [4000/8000 (50%)]\tBatch Loss: 964.716109\tLearning Rate (w_theta): 0.001000\t TIME:2860.2s\n",
      "\t\t\t\tDisc: 0.943020\t\tSym: 15.490924\t\tSpars: 948.282166\n",
      "\t TVw: -0.356124 | TVb: -2.043738 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1723...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 970.8409128807345\n",
      "Average validation loss: 141.7786086426606\n",
      "Training epoch 1724...\n",
      "\n",
      "Train Epoch: 1724 [0/8000 (0%)]\tBatch Loss: 970.605892\tLearning Rate (w_theta): 0.001000\t TIME:2862.6s\n",
      "\t\t\t\tDisc: 1.084283\t\tSym: 17.203615\t\tSpars: 952.317993\n",
      "\t TVw: -0.355772 | TVb: -2.043738 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1724 [4000/8000 (50%)]\tBatch Loss: 966.340247\tLearning Rate (w_theta): 0.001000\t TIME:2864.1s\n",
      "\t\t\t\tDisc: 1.001050\t\tSym: 16.429224\t\tSpars: 948.909973\n",
      "\t TVw: -0.355419 | TVb: -2.043738 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1724...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 967.4414787581451\n",
      "Average validation loss: 141.51982941694243\n",
      "Training epoch 1725...\n",
      "\n",
      "Train Epoch: 1725 [0/8000 (0%)]\tBatch Loss: 965.523168\tLearning Rate (w_theta): 0.001000\t TIME:2866.5s\n",
      "\t\t\t\tDisc: 1.051424\t\tSym: 16.243961\t\tSpars: 948.227783\n",
      "\t TVw: -0.355063 | TVb: -2.043738 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1725 [4000/8000 (50%)]\tBatch Loss: 959.866216\tLearning Rate (w_theta): 0.001000\t TIME:2868.0s\n",
      "\t\t\t\tDisc: 0.997737\t\tSym: 16.266306\t\tSpars: 942.602173\n",
      "\t TVw: -0.354702 | TVb: -2.043738 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1725...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 970.6891338600013\n",
      "Average validation loss: 140.00937052545157\n",
      "Training epoch 1726...\n",
      "\n",
      "Train Epoch: 1726 [0/8000 (0%)]\tBatch Loss: 989.979850\tLearning Rate (w_theta): 0.001000\t TIME:2870.6s\n",
      "\t\t\t\tDisc: 1.036441\t\tSym: 16.785999\t\tSpars: 972.157410\n",
      "\t TVw: -0.354343 | TVb: -2.043738 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1726 [4000/8000 (50%)]\tBatch Loss: 955.091071\tLearning Rate (w_theta): 0.001000\t TIME:2872.2s\n",
      "\t\t\t\tDisc: 0.973134\t\tSym: 14.978594\t\tSpars: 939.139343\n",
      "\t TVw: -0.353983 | TVb: -2.043738 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1726...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 974.0686560850079\n",
      "Average validation loss: 138.5063813438461\n",
      "Training epoch 1727...\n",
      "\n",
      "Train Epoch: 1727 [0/8000 (0%)]\tBatch Loss: 961.463743\tLearning Rate (w_theta): 0.001000\t TIME:2874.5s\n",
      "\t\t\t\tDisc: 0.958614\t\tSym: 15.450870\t\tSpars: 945.054260\n",
      "\t TVw: -0.353632 | TVb: -2.043739 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1727 [4000/8000 (50%)]\tBatch Loss: 976.299437\tLearning Rate (w_theta): 0.001000\t TIME:2876.1s\n",
      "\t\t\t\tDisc: 1.002768\t\tSym: 17.055580\t\tSpars: 958.241089\n",
      "\t TVw: -0.353281 | TVb: -2.043739 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1727...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 977.4925771475209\n",
      "Average validation loss: 139.87590208239453\n",
      "Training epoch 1728...\n",
      "\n",
      "Train Epoch: 1728 [0/8000 (0%)]\tBatch Loss: 992.280773\tLearning Rate (w_theta): 0.001000\t TIME:2878.4s\n",
      "\t\t\t\tDisc: 0.970747\t\tSym: 17.763517\t\tSpars: 973.546509\n",
      "\t TVw: -0.352928 | TVb: -2.043739 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1728 [4000/8000 (50%)]\tBatch Loss: 985.934561\tLearning Rate (w_theta): 0.001000\t TIME:2880.0s\n",
      "\t\t\t\tDisc: 1.132206\t\tSym: 17.595385\t\tSpars: 967.206970\n",
      "\t TVw: -0.352581 | TVb: -2.043739 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1728...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 972.4417785653524\n",
      "Average validation loss: 140.82332941339573\n",
      "Training epoch 1729...\n",
      "\n",
      "Train Epoch: 1729 [0/8000 (0%)]\tBatch Loss: 994.949549\tLearning Rate (w_theta): 0.001000\t TIME:2882.4s\n",
      "\t\t\t\tDisc: 1.223628\t\tSym: 17.849884\t\tSpars: 975.876038\n",
      "\t TVw: -0.352234 | TVb: -2.043739 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1729 [4000/8000 (50%)]\tBatch Loss: 988.527254\tLearning Rate (w_theta): 0.001000\t TIME:2883.9s\n",
      "\t\t\t\tDisc: 1.094209\t\tSym: 17.577637\t\tSpars: 969.855408\n",
      "\t TVw: -0.351894 | TVb: -2.043740 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1729...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 968.8701432383393\n",
      "Average validation loss: 139.6042699249792\n",
      "Training epoch 1730...\n",
      "\n",
      "Train Epoch: 1730 [0/8000 (0%)]\tBatch Loss: 964.230789\tLearning Rate (w_theta): 0.001000\t TIME:2886.3s\n",
      "\t\t\t\tDisc: 0.975129\t\tSym: 17.066816\t\tSpars: 946.188843\n",
      "\t TVw: -0.351543 | TVb: -2.043740 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1730 [4000/8000 (50%)]\tBatch Loss: 987.969892\tLearning Rate (w_theta): 0.001000\t TIME:2887.8s\n",
      "\t\t\t\tDisc: 0.966148\t\tSym: 17.679037\t\tSpars: 969.324707\n",
      "\t TVw: -0.351188 | TVb: -2.043741 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1730...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 965.6805135002116\n",
      "Average validation loss: 138.7072388655318\n",
      "Training epoch 1731...\n",
      "\n",
      "Train Epoch: 1731 [0/8000 (0%)]\tBatch Loss: 960.071671\tLearning Rate (w_theta): 0.001000\t TIME:2890.9s\n",
      "\t\t\t\tDisc: 0.921564\t\tSym: 16.593893\t\tSpars: 942.556213\n",
      "\t TVw: -0.350832 | TVb: -2.043741 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1731 [4000/8000 (50%)]\tBatch Loss: 953.555067\tLearning Rate (w_theta): 0.001000\t TIME:2892.4s\n",
      "\t\t\t\tDisc: 0.927310\t\tSym: 15.454477\t\tSpars: 937.173279\n",
      "\t TVw: -0.350473 | TVb: -2.043742 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1731...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 965.5243157872289\n",
      "Average validation loss: 139.97104068585824\n",
      "Training epoch 1732...\n",
      "\n",
      "Train Epoch: 1732 [0/8000 (0%)]\tBatch Loss: 948.722957\tLearning Rate (w_theta): 0.001000\t TIME:2894.8s\n",
      "\t\t\t\tDisc: 0.990121\t\tSym: 15.016466\t\tSpars: 932.716370\n",
      "\t TVw: -0.350109 | TVb: -2.043743 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1732 [4000/8000 (50%)]\tBatch Loss: 969.400158\tLearning Rate (w_theta): 0.001000\t TIME:2896.3s\n",
      "\t\t\t\tDisc: 1.007780\t\tSym: 16.308210\t\tSpars: 952.084167\n",
      "\t TVw: -0.349744 | TVb: -2.043743 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1732...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 964.0078864841746\n",
      "Average validation loss: 140.1427076412105\n",
      "Training epoch 1733...\n",
      "\n",
      "Train Epoch: 1733 [0/8000 (0%)]\tBatch Loss: 958.782506\tLearning Rate (w_theta): 0.001000\t TIME:2899.0s\n",
      "\t\t\t\tDisc: 1.105079\t\tSym: 16.062498\t\tSpars: 941.614929\n",
      "\t TVw: -0.349384 | TVb: -2.043743 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1733 [4000/8000 (50%)]\tBatch Loss: 1003.863948\tLearning Rate (w_theta): 0.001000\t TIME:2900.5s\n",
      "\t\t\t\tDisc: 1.005872\t\tSym: 18.140303\t\tSpars: 984.717773\n",
      "\t TVw: -0.349022 | TVb: -2.043744 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1733...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 965.3776900702794\n",
      "Average validation loss: 137.82824918236176\n",
      "Training epoch 1734...\n",
      "\n",
      "Train Epoch: 1734 [0/8000 (0%)]\tBatch Loss: 943.997683\tLearning Rate (w_theta): 0.001000\t TIME:2902.9s\n",
      "\t\t\t\tDisc: 0.929493\t\tSym: 15.996596\t\tSpars: 927.071594\n",
      "\t TVw: -0.348666 | TVb: -2.043745 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1734 [4000/8000 (50%)]\tBatch Loss: 960.364854\tLearning Rate (w_theta): 0.001000\t TIME:2904.4s\n",
      "\t\t\t\tDisc: 0.972651\t\tSym: 17.096365\t\tSpars: 942.295837\n",
      "\t TVw: -0.348304 | TVb: -2.043745 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1734...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 966.1823536885544\n",
      "Average validation loss: 139.28570226954008\n",
      "Training epoch 1735...\n",
      "\n",
      "Train Epoch: 1735 [0/8000 (0%)]\tBatch Loss: 980.699576\tLearning Rate (w_theta): 0.001000\t TIME:2906.8s\n",
      "\t\t\t\tDisc: 1.073777\t\tSym: 16.977423\t\tSpars: 962.648376\n",
      "\t TVw: -0.347938 | TVb: -2.043745 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1735 [4000/8000 (50%)]\tBatch Loss: 957.042419\tLearning Rate (w_theta): 0.001000\t TIME:2908.3s\n",
      "\t\t\t\tDisc: 0.954607\t\tSym: 16.340559\t\tSpars: 939.747253\n",
      "\t TVw: -0.347578 | TVb: -2.043745 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1735...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 960.8278974898714\n",
      "Average validation loss: 138.22557480160765\n",
      "Training epoch 1736...\n",
      "\n",
      "Train Epoch: 1736 [0/8000 (0%)]\tBatch Loss: 973.776190\tLearning Rate (w_theta): 0.001000\t TIME:2910.7s\n",
      "\t\t\t\tDisc: 0.972075\t\tSym: 17.575478\t\tSpars: 955.228638\n",
      "\t TVw: -0.347221 | TVb: -2.043746 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1736 [4000/8000 (50%)]\tBatch Loss: 941.144860\tLearning Rate (w_theta): 0.001000\t TIME:2912.2s\n",
      "\t\t\t\tDisc: 0.910096\t\tSym: 14.338524\t\tSpars: 925.896240\n",
      "\t TVw: -0.346861 | TVb: -2.043747 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1736...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 960.2536200759678\n",
      "Average validation loss: 138.8917818321725\n",
      "Training epoch 1737...\n",
      "\n",
      "Train Epoch: 1737 [0/8000 (0%)]\tBatch Loss: 996.201841\tLearning Rate (w_theta): 0.001000\t TIME:2914.6s\n",
      "\t\t\t\tDisc: 1.037664\t\tSym: 17.733269\t\tSpars: 977.430908\n",
      "\t TVw: -0.346494 | TVb: -2.043747 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1737 [4000/8000 (50%)]\tBatch Loss: 960.868686\tLearning Rate (w_theta): 0.001000\t TIME:2916.2s\n",
      "\t\t\t\tDisc: 0.981479\t\tSym: 17.232483\t\tSpars: 942.654724\n",
      "\t TVw: -0.346128 | TVb: -2.043748 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1737...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 960.614426970024\n",
      "Average validation loss: 137.27461240015347\n",
      "Training epoch 1738...\n",
      "\n",
      "Train Epoch: 1738 [0/8000 (0%)]\tBatch Loss: 942.750298\tLearning Rate (w_theta): 0.001000\t TIME:2918.5s\n",
      "\t\t\t\tDisc: 0.893538\t\tSym: 15.411936\t\tSpars: 926.444824\n",
      "\t TVw: -0.345762 | TVb: -2.043749 | GSw: -0.234959 | GSb: 0.065062 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1738 [4000/8000 (50%)]\tBatch Loss: 953.287644\tLearning Rate (w_theta): 0.001000\t TIME:2920.1s\n",
      "\t\t\t\tDisc: 1.022352\t\tSym: 15.942416\t\tSpars: 936.322876\n",
      "\t TVw: -0.345398 | TVb: -2.043749 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1738...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 963.0995227153388\n",
      "Average validation loss: 139.91443292509865\n",
      "Training epoch 1739...\n",
      "\n",
      "Train Epoch: 1739 [0/8000 (0%)]\tBatch Loss: 943.181022\tLearning Rate (w_theta): 0.001000\t TIME:2922.4s\n",
      "\t\t\t\tDisc: 1.008008\t\tSym: 15.488443\t\tSpars: 926.684570\n",
      "\t TVw: -0.345026 | TVb: -2.043749 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1739 [4000/8000 (50%)]\tBatch Loss: 915.761491\tLearning Rate (w_theta): 0.001000\t TIME:2924.0s\n",
      "\t\t\t\tDisc: 0.839123\t\tSym: 14.079595\t\tSpars: 900.842773\n",
      "\t TVw: -0.344657 | TVb: -2.043749 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1739...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 965.8081766038218\n",
      "Average validation loss: 136.90018659554767\n",
      "Training epoch 1740...\n",
      "\n",
      "Train Epoch: 1740 [0/8000 (0%)]\tBatch Loss: 955.721007\tLearning Rate (w_theta): 0.001000\t TIME:2926.3s\n",
      "\t\t\t\tDisc: 1.007658\t\tSym: 16.088226\t\tSpars: 938.625122\n",
      "\t TVw: -0.344292 | TVb: -2.043749 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1740 [4000/8000 (50%)]\tBatch Loss: 953.902004\tLearning Rate (w_theta): 0.001000\t TIME:2927.9s\n",
      "\t\t\t\tDisc: 0.961946\t\tSym: 16.946772\t\tSpars: 935.993286\n",
      "\t TVw: -0.343931 | TVb: -2.043750 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1740...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 961.1586384794831\n",
      "Average validation loss: 138.29020226190673\n",
      "Training epoch 1741...\n",
      "\n",
      "Train Epoch: 1741 [0/8000 (0%)]\tBatch Loss: 973.028279\tLearning Rate (w_theta): 0.001000\t TIME:2931.2s\n",
      "\t\t\t\tDisc: 1.026093\t\tSym: 16.028553\t\tSpars: 955.973633\n",
      "\t TVw: -0.343559 | TVb: -2.043749 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1741 [4000/8000 (50%)]\tBatch Loss: 959.120598\tLearning Rate (w_theta): 0.001000\t TIME:2932.7s\n",
      "\t\t\t\tDisc: 1.104675\t\tSym: 16.453911\t\tSpars: 941.562012\n",
      "\t TVw: -0.343193 | TVb: -2.043748 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1741...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 959.4353596728251\n",
      "Average validation loss: 136.91858966340055\n",
      "Training epoch 1742...\n",
      "\n",
      "Train Epoch: 1742 [0/8000 (0%)]\tBatch Loss: 924.935180\tLearning Rate (w_theta): 0.001000\t TIME:2935.1s\n",
      "\t\t\t\tDisc: 0.913078\t\tSym: 14.949226\t\tSpars: 909.072876\n",
      "\t TVw: -0.342825 | TVb: -2.043749 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1742 [4000/8000 (50%)]\tBatch Loss: 918.817294\tLearning Rate (w_theta): 0.001000\t TIME:2936.6s\n",
      "\t\t\t\tDisc: 0.961041\t\tSym: 14.505240\t\tSpars: 903.351013\n",
      "\t TVw: -0.342460 | TVb: -2.043749 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1742...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 958.3752845632399\n",
      "Average validation loss: 137.15400543302238\n",
      "Training epoch 1743...\n",
      "\n",
      "Train Epoch: 1743 [0/8000 (0%)]\tBatch Loss: 939.959349\tLearning Rate (w_theta): 0.001000\t TIME:2939.0s\n",
      "\t\t\t\tDisc: 1.035768\t\tSym: 14.909604\t\tSpars: 924.013977\n",
      "\t TVw: -0.342093 | TVb: -2.043750 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1743 [4000/8000 (50%)]\tBatch Loss: 940.765111\tLearning Rate (w_theta): 0.001000\t TIME:2940.5s\n",
      "\t\t\t\tDisc: 0.979774\t\tSym: 15.283811\t\tSpars: 924.501526\n",
      "\t TVw: -0.341722 | TVb: -2.043751 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1743...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 958.5974157262883\n",
      "Average validation loss: 136.7357833309854\n",
      "Training epoch 1744...\n",
      "\n",
      "Train Epoch: 1744 [0/8000 (0%)]\tBatch Loss: 977.481801\tLearning Rate (w_theta): 0.001000\t TIME:2942.9s\n",
      "\t\t\t\tDisc: 1.021380\t\tSym: 17.126802\t\tSpars: 959.333618\n",
      "\t TVw: -0.341353 | TVb: -2.043751 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1744 [4000/8000 (50%)]\tBatch Loss: 970.389633\tLearning Rate (w_theta): 0.001000\t TIME:2944.4s\n",
      "\t\t\t\tDisc: 1.056249\t\tSym: 16.431894\t\tSpars: 952.901489\n",
      "\t TVw: -0.340982 | TVb: -2.043751 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1744...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 957.9831961598915\n",
      "Average validation loss: 136.30015175768426\n",
      "Training epoch 1745...\n",
      "\n",
      "Train Epoch: 1745 [0/8000 (0%)]\tBatch Loss: 953.734099\tLearning Rate (w_theta): 0.001000\t TIME:2946.8s\n",
      "\t\t\t\tDisc: 0.934120\t\tSym: 15.184134\t\tSpars: 937.615845\n",
      "\t TVw: -0.340616 | TVb: -2.043752 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1745 [4000/8000 (50%)]\tBatch Loss: 976.747998\tLearning Rate (w_theta): 0.001000\t TIME:2948.3s\n",
      "\t\t\t\tDisc: 1.099726\t\tSym: 16.877520\t\tSpars: 958.770752\n",
      "\t TVw: -0.340250 | TVb: -2.043753 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1745...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 961.612685674827\n",
      "Average validation loss: 137.42004462133852\n",
      "Training epoch 1746...\n",
      "\n",
      "Train Epoch: 1746 [0/8000 (0%)]\tBatch Loss: 964.527294\tLearning Rate (w_theta): 0.001000\t TIME:2950.7s\n",
      "\t\t\t\tDisc: 0.982632\t\tSym: 16.514694\t\tSpars: 947.029968\n",
      "\t TVw: -0.339881 | TVb: -2.043754 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1746 [4000/8000 (50%)]\tBatch Loss: 934.158783\tLearning Rate (w_theta): 0.001000\t TIME:2952.2s\n",
      "\t\t\t\tDisc: 0.996964\t\tSym: 15.207108\t\tSpars: 917.954712\n",
      "\t TVw: -0.339513 | TVb: -2.043754 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1746...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 959.7819292303907\n",
      "Average validation loss: 137.44657442929346\n",
      "Training epoch 1747...\n",
      "\n",
      "Train Epoch: 1747 [0/8000 (0%)]\tBatch Loss: 977.757798\tLearning Rate (w_theta): 0.001000\t TIME:2954.6s\n",
      "\t\t\t\tDisc: 1.124749\t\tSym: 17.061089\t\tSpars: 959.571960\n",
      "\t TVw: -0.339145 | TVb: -2.043755 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1747 [4000/8000 (50%)]\tBatch Loss: 974.303743\tLearning Rate (w_theta): 0.001000\t TIME:2956.1s\n",
      "\t\t\t\tDisc: 1.046566\t\tSym: 17.494482\t\tSpars: 955.762695\n",
      "\t TVw: -0.338778 | TVb: -2.043755 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1747...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 966.323968410451\n",
      "Average validation loss: 135.5436534766378\n",
      "Training epoch 1748...\n",
      "\n",
      "Train Epoch: 1748 [0/8000 (0%)]\tBatch Loss: 958.646582\tLearning Rate (w_theta): 0.001000\t TIME:2958.5s\n",
      "\t\t\t\tDisc: 1.021969\t\tSym: 15.685282\t\tSpars: 941.939331\n",
      "\t TVw: -0.338407 | TVb: -2.043756 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1748 [4000/8000 (50%)]\tBatch Loss: 938.473687\tLearning Rate (w_theta): 0.001000\t TIME:2960.0s\n",
      "\t\t\t\tDisc: 1.000374\t\tSym: 15.256149\t\tSpars: 922.217163\n",
      "\t TVw: -0.338030 | TVb: -2.043756 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1748...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 963.160073387846\n",
      "Average validation loss: 138.01173503874813\n",
      "Training epoch 1749...\n",
      "\n",
      "Train Epoch: 1749 [0/8000 (0%)]\tBatch Loss: 939.309041\tLearning Rate (w_theta): 0.001000\t TIME:2962.7s\n",
      "\t\t\t\tDisc: 1.010054\t\tSym: 15.342994\t\tSpars: 922.955994\n",
      "\t TVw: -0.337647 | TVb: -2.043755 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1749 [4000/8000 (50%)]\tBatch Loss: 939.615988\tLearning Rate (w_theta): 0.001000\t TIME:2964.2s\n",
      "\t\t\t\tDisc: 1.021583\t\tSym: 15.089767\t\tSpars: 923.504639\n",
      "\t TVw: -0.337264 | TVb: -2.043755 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1749...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 958.3031640772638\n",
      "Average validation loss: 135.82541263411318\n",
      "Training epoch 1750...\n",
      "\n",
      "Train Epoch: 1750 [0/8000 (0%)]\tBatch Loss: 916.798396\tLearning Rate (w_theta): 0.001000\t TIME:2966.6s\n",
      "\t\t\t\tDisc: 0.892505\t\tSym: 15.332832\t\tSpars: 900.573059\n",
      "\t TVw: -0.336886 | TVb: -2.043754 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1750 [4000/8000 (50%)]\tBatch Loss: 974.393781\tLearning Rate (w_theta): 0.001000\t TIME:2968.2s\n",
      "\t\t\t\tDisc: 0.911315\t\tSym: 16.517805\t\tSpars: 956.964661\n",
      "\t TVw: -0.336508 | TVb: -2.043754 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1750...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 957.4509217162268\n",
      "Average validation loss: 134.782776815971\n",
      "Training epoch 1751...\n",
      "\n",
      "Train Epoch: 1751 [0/8000 (0%)]\tBatch Loss: 956.364748\tLearning Rate (w_theta): 0.001000\t TIME:2971.2s\n",
      "\t\t\t\tDisc: 0.932308\t\tSym: 16.447943\t\tSpars: 938.984497\n",
      "\t TVw: -0.336129 | TVb: -2.043754 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1751 [4000/8000 (50%)]\tBatch Loss: 944.367049\tLearning Rate (w_theta): 0.001000\t TIME:2972.8s\n",
      "\t\t\t\tDisc: 0.934198\t\tSym: 15.485829\t\tSpars: 927.947021\n",
      "\t TVw: -0.335742 | TVb: -2.043754 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1751...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 956.2151287232482\n",
      "Average validation loss: 136.97976710033012\n",
      "Training epoch 1752...\n",
      "\n",
      "Train Epoch: 1752 [0/8000 (0%)]\tBatch Loss: 967.779030\tLearning Rate (w_theta): 0.001000\t TIME:2975.1s\n",
      "\t\t\t\tDisc: 1.004846\t\tSym: 16.276381\t\tSpars: 950.497803\n",
      "\t TVw: -0.335357 | TVb: -2.043754 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1752 [4000/8000 (50%)]\tBatch Loss: 968.597246\tLearning Rate (w_theta): 0.001000\t TIME:2976.7s\n",
      "\t\t\t\tDisc: 1.009565\t\tSym: 17.194736\t\tSpars: 950.392944\n",
      "\t TVw: -0.334981 | TVb: -2.043755 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1752...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 962.6521154071052\n",
      "Average validation loss: 134.8854836790916\n",
      "Training epoch 1753...\n",
      "\n",
      "Train Epoch: 1753 [0/8000 (0%)]\tBatch Loss: 934.244616\tLearning Rate (w_theta): 0.001000\t TIME:2979.1s\n",
      "\t\t\t\tDisc: 0.820512\t\tSym: 15.329500\t\tSpars: 918.094604\n",
      "\t TVw: -0.334602 | TVb: -2.043756 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1753 [4000/8000 (50%)]\tBatch Loss: 948.224418\tLearning Rate (w_theta): 0.001000\t TIME:2980.7s\n",
      "\t\t\t\tDisc: 1.035035\t\tSym: 15.588614\t\tSpars: 931.600769\n",
      "\t TVw: -0.334218 | TVb: -2.043756 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1753...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 960.1762076991406\n",
      "Average validation loss: 135.29896271477378\n",
      "Training epoch 1754...\n",
      "\n",
      "Train Epoch: 1754 [0/8000 (0%)]\tBatch Loss: 940.871739\tLearning Rate (w_theta): 0.001000\t TIME:2983.0s\n",
      "\t\t\t\tDisc: 0.851072\t\tSym: 15.768653\t\tSpars: 924.252014\n",
      "\t TVw: -0.333838 | TVb: -2.043757 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1754 [4000/8000 (50%)]\tBatch Loss: 948.966837\tLearning Rate (w_theta): 0.001000\t TIME:2984.6s\n",
      "\t\t\t\tDisc: 1.061436\t\tSym: 16.643866\t\tSpars: 931.261536\n",
      "\t TVw: -0.333452 | TVb: -2.043756 | GSw: -0.234959 | GSb: 0.065061 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1754...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 963.4448863113356\n",
      "Average validation loss: 136.71904117393402\n",
      "Training epoch 1755...\n",
      "\n",
      "Train Epoch: 1755 [0/8000 (0%)]\tBatch Loss: 972.022387\tLearning Rate (w_theta): 0.001000\t TIME:2986.9s\n",
      "\t\t\t\tDisc: 1.050448\t\tSym: 16.482925\t\tSpars: 954.489014\n",
      "\t TVw: -0.333063 | TVb: -2.043756 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1755 [4000/8000 (50%)]\tBatch Loss: 957.159476\tLearning Rate (w_theta): 0.001000\t TIME:2988.5s\n",
      "\t\t\t\tDisc: 1.075169\t\tSym: 17.054522\t\tSpars: 939.029785\n",
      "\t TVw: -0.332680 | TVb: -2.043756 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "Validating epoch 1755...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 960.2450081166753\n",
      "Average validation loss: 133.10766252950137\n",
      "Training epoch 1756...\n",
      "\n",
      "Train Epoch: 1756 [0/8000 (0%)]\tBatch Loss: 939.886068\tLearning Rate (w_theta): 0.001000\t TIME:2990.8s\n",
      "\t\t\t\tDisc: 0.906707\t\tSym: 15.213309\t\tSpars: 923.766052\n",
      "\t TVw: -0.332292 | TVb: -2.043756 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034773\n",
      "\n",
      "Train Epoch: 1756 [4000/8000 (50%)]\tBatch Loss: 937.548003\tLearning Rate (w_theta): 0.001000\t TIME:2992.4s\n",
      "\t\t\t\tDisc: 0.974154\t\tSym: 15.055905\t\tSpars: 921.517944\n",
      "\t TVw: -0.331910 | TVb: -2.043756 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1756...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 955.5591837811293\n",
      "Average validation loss: 133.9107371643976\n",
      "Training epoch 1757...\n",
      "\n",
      "Train Epoch: 1757 [0/8000 (0%)]\tBatch Loss: 911.640666\tLearning Rate (w_theta): 0.001000\t TIME:2995.0s\n",
      "\t\t\t\tDisc: 0.845897\t\tSym: 13.666472\t\tSpars: 897.128296\n",
      "\t TVw: -0.331534 | TVb: -2.043757 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1757 [4000/8000 (50%)]\tBatch Loss: 943.203791\tLearning Rate (w_theta): 0.001000\t TIME:2996.5s\n",
      "\t\t\t\tDisc: 0.907882\t\tSym: 15.963145\t\tSpars: 926.332764\n",
      "\t TVw: -0.331149 | TVb: -2.043758 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1757...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 949.6389902852659\n",
      "Average validation loss: 134.5870398619747\n",
      "Training epoch 1758...\n",
      "\n",
      "Train Epoch: 1758 [0/8000 (0%)]\tBatch Loss: 990.739217\tLearning Rate (w_theta): 0.001000\t TIME:2998.9s\n",
      "\t\t\t\tDisc: 0.998956\t\tSym: 17.250881\t\tSpars: 972.489380\n",
      "\t TVw: -0.330755 | TVb: -2.043759 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1758 [4000/8000 (50%)]\tBatch Loss: 926.173763\tLearning Rate (w_theta): 0.001000\t TIME:3000.5s\n",
      "\t\t\t\tDisc: 0.874997\t\tSym: 15.011291\t\tSpars: 910.287476\n",
      "\t TVw: -0.330357 | TVb: -2.043760 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1758...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 948.8987676946053\n",
      "Average validation loss: 133.75881661183507\n",
      "Training epoch 1759...\n",
      "\n",
      "Train Epoch: 1759 [0/8000 (0%)]\tBatch Loss: 947.557791\tLearning Rate (w_theta): 0.001000\t TIME:3002.8s\n",
      "\t\t\t\tDisc: 0.950077\t\tSym: 16.066759\t\tSpars: 930.540955\n",
      "\t TVw: -0.329967 | TVb: -2.043761 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1759 [4000/8000 (50%)]\tBatch Loss: 928.819640\tLearning Rate (w_theta): 0.001000\t TIME:3004.4s\n",
      "\t\t\t\tDisc: 0.886787\t\tSym: 15.138541\t\tSpars: 912.794312\n",
      "\t TVw: -0.329573 | TVb: -2.043761 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1759...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 949.5360665852769\n",
      "Average validation loss: 134.60841240791572\n",
      "Training epoch 1760...\n",
      "\n",
      "Train Epoch: 1760 [0/8000 (0%)]\tBatch Loss: 919.583667\tLearning Rate (w_theta): 0.001000\t TIME:3006.8s\n",
      "\t\t\t\tDisc: 0.966381\t\tSym: 14.257361\t\tSpars: 904.359924\n",
      "\t TVw: -0.329171 | TVb: -2.043762 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1760 [4000/8000 (50%)]\tBatch Loss: 970.883894\tLearning Rate (w_theta): 0.001000\t TIME:3008.3s\n",
      "\t\t\t\tDisc: 1.043892\t\tSym: 17.108801\t\tSpars: 952.731201\n",
      "\t TVw: -0.328771 | TVb: -2.043762 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1760...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 951.2731072676655\n",
      "Average validation loss: 134.1103384563138\n",
      "Training epoch 1761...\n",
      "\n",
      "Train Epoch: 1761 [0/8000 (0%)]\tBatch Loss: 919.142252\tLearning Rate (w_theta): 0.001000\t TIME:3011.4s\n",
      "\t\t\t\tDisc: 0.851280\t\tSym: 15.256182\t\tSpars: 903.034790\n",
      "\t TVw: -0.328372 | TVb: -2.043762 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1761 [4000/8000 (50%)]\tBatch Loss: 930.319930\tLearning Rate (w_theta): 0.001000\t TIME:3012.9s\n",
      "\t\t\t\tDisc: 0.983946\t\tSym: 14.842026\t\tSpars: 914.493958\n",
      "\t TVw: -0.327972 | TVb: -2.043763 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1761...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 947.4221334705701\n",
      "Average validation loss: 133.78682129621507\n",
      "Training epoch 1762...\n",
      "\n",
      "Train Epoch: 1762 [0/8000 (0%)]\tBatch Loss: 912.461476\tLearning Rate (w_theta): 0.001000\t TIME:3015.3s\n",
      "\t\t\t\tDisc: 0.810986\t\tSym: 14.414833\t\tSpars: 897.235657\n",
      "\t TVw: -0.327576 | TVb: -2.043763 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1762 [4000/8000 (50%)]\tBatch Loss: 927.352184\tLearning Rate (w_theta): 0.001000\t TIME:3016.8s\n",
      "\t\t\t\tDisc: 0.877902\t\tSym: 14.914955\t\tSpars: 911.559326\n",
      "\t TVw: -0.327174 | TVb: -2.043763 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1762...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 946.1924109925876\n",
      "Average validation loss: 133.27335078250152\n",
      "Training epoch 1763...\n",
      "\n",
      "Train Epoch: 1763 [0/8000 (0%)]\tBatch Loss: 974.984600\tLearning Rate (w_theta): 0.001000\t TIME:3019.2s\n",
      "\t\t\t\tDisc: 1.030538\t\tSym: 17.151876\t\tSpars: 956.802185\n",
      "\t TVw: -0.326772 | TVb: -2.043764 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1763 [4000/8000 (50%)]\tBatch Loss: 925.515663\tLearning Rate (w_theta): 0.001000\t TIME:3020.7s\n",
      "\t\t\t\tDisc: 0.919955\t\tSym: 14.579289\t\tSpars: 910.016418\n",
      "\t TVw: -0.326369 | TVb: -2.043764 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1763...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 946.2755849165499\n",
      "Average validation loss: 133.2467829800831\n",
      "Training epoch 1764...\n",
      "\n",
      "Train Epoch: 1764 [0/8000 (0%)]\tBatch Loss: 914.266929\tLearning Rate (w_theta): 0.001000\t TIME:3023.3s\n",
      "\t\t\t\tDisc: 0.889956\t\tSym: 14.743184\t\tSpars: 898.633789\n",
      "\t TVw: -0.325969 | TVb: -2.043765 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1764 [4000/8000 (50%)]\tBatch Loss: 1001.528528\tLearning Rate (w_theta): 0.001000\t TIME:3024.9s\n",
      "\t\t\t\tDisc: 0.955856\t\tSym: 17.671305\t\tSpars: 982.901367\n",
      "\t TVw: -0.325571 | TVb: -2.043766 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1764...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 947.1264450958904\n",
      "Average validation loss: 134.59551489918692\n",
      "Training epoch 1765...\n",
      "\n",
      "Train Epoch: 1765 [0/8000 (0%)]\tBatch Loss: 899.677393\tLearning Rate (w_theta): 0.001000\t TIME:3027.3s\n",
      "\t\t\t\tDisc: 0.906403\t\tSym: 13.776117\t\tSpars: 884.994873\n",
      "\t TVw: -0.325168 | TVb: -2.043766 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1765 [4000/8000 (50%)]\tBatch Loss: 950.459454\tLearning Rate (w_theta): 0.001000\t TIME:3028.8s\n",
      "\t\t\t\tDisc: 1.045714\t\tSym: 16.289656\t\tSpars: 933.124084\n",
      "\t TVw: -0.324767 | TVb: -2.043766 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1765...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 945.3506466479081\n",
      "Average validation loss: 132.2759017451304\n",
      "Training epoch 1766...\n",
      "\n",
      "Train Epoch: 1766 [0/8000 (0%)]\tBatch Loss: 933.584437\tLearning Rate (w_theta): 0.001000\t TIME:3031.2s\n",
      "\t\t\t\tDisc: 0.926272\t\tSym: 16.160362\t\tSpars: 916.497803\n",
      "\t TVw: -0.324367 | TVb: -2.043766 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1766 [4000/8000 (50%)]\tBatch Loss: 917.087405\tLearning Rate (w_theta): 0.001000\t TIME:3032.7s\n",
      "\t\t\t\tDisc: 0.915795\t\tSym: 15.123819\t\tSpars: 901.047791\n",
      "\t TVw: -0.323966 | TVb: -2.043766 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1766...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 944.7504311617705\n",
      "Average validation loss: 133.1815996414668\n",
      "Training epoch 1767...\n",
      "\n",
      "Train Epoch: 1767 [0/8000 (0%)]\tBatch Loss: 959.896561\tLearning Rate (w_theta): 0.001000\t TIME:3035.1s\n",
      "\t\t\t\tDisc: 1.021160\t\tSym: 17.202671\t\tSpars: 941.672729\n",
      "\t TVw: -0.323566 | TVb: -2.043766 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1767 [4000/8000 (50%)]\tBatch Loss: 943.471655\tLearning Rate (w_theta): 0.001000\t TIME:3036.6s\n",
      "\t\t\t\tDisc: 0.964892\t\tSym: 16.126026\t\tSpars: 926.380737\n",
      "\t TVw: -0.323166 | TVb: -2.043766 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1767...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 943.963500271508\n",
      "Average validation loss: 133.33374026807235\n",
      "Training epoch 1768...\n",
      "\n",
      "Train Epoch: 1768 [0/8000 (0%)]\tBatch Loss: 952.752953\tLearning Rate (w_theta): 0.001000\t TIME:3039.0s\n",
      "\t\t\t\tDisc: 0.952119\t\tSym: 16.772942\t\tSpars: 935.027893\n",
      "\t TVw: -0.322765 | TVb: -2.043767 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1768 [4000/8000 (50%)]\tBatch Loss: 916.013438\tLearning Rate (w_theta): 0.001000\t TIME:3040.6s\n",
      "\t\t\t\tDisc: 0.926199\t\tSym: 14.860677\t\tSpars: 900.226562\n",
      "\t TVw: -0.322357 | TVb: -2.043768 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1768...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 944.7833688446469\n",
      "Average validation loss: 132.56212174564996\n",
      "Training epoch 1769...\n",
      "\n",
      "Train Epoch: 1769 [0/8000 (0%)]\tBatch Loss: 965.601868\tLearning Rate (w_theta): 0.001000\t TIME:3043.0s\n",
      "\t\t\t\tDisc: 1.040742\t\tSym: 16.326385\t\tSpars: 948.234741\n",
      "\t TVw: -0.321949 | TVb: -2.043768 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1769 [4000/8000 (50%)]\tBatch Loss: 913.245582\tLearning Rate (w_theta): 0.001000\t TIME:3044.5s\n",
      "\t\t\t\tDisc: 0.942281\t\tSym: 14.058245\t\tSpars: 898.245056\n",
      "\t TVw: -0.321539 | TVb: -2.043768 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1769...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 946.5438006612616\n",
      "Average validation loss: 132.8359049624569\n",
      "Training epoch 1770...\n",
      "\n",
      "Train Epoch: 1770 [0/8000 (0%)]\tBatch Loss: 942.346260\tLearning Rate (w_theta): 0.001000\t TIME:3046.9s\n",
      "\t\t\t\tDisc: 1.013122\t\tSym: 15.917915\t\tSpars: 925.415222\n",
      "\t TVw: -0.321127 | TVb: -2.043768 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1770 [4000/8000 (50%)]\tBatch Loss: 943.722458\tLearning Rate (w_theta): 0.001000\t TIME:3048.5s\n",
      "\t\t\t\tDisc: 0.863831\t\tSym: 15.627060\t\tSpars: 927.231567\n",
      "\t TVw: -0.320719 | TVb: -2.043768 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1770...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 944.9114627426939\n",
      "Average validation loss: 131.1283424977018\n",
      "Training epoch 1771...\n",
      "\n",
      "Train Epoch: 1771 [0/8000 (0%)]\tBatch Loss: 941.301959\tLearning Rate (w_theta): 0.001000\t TIME:3051.5s\n",
      "\t\t\t\tDisc: 0.904536\t\tSym: 14.900475\t\tSpars: 925.496948\n",
      "\t TVw: -0.320315 | TVb: -2.043769 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1771 [4000/8000 (50%)]\tBatch Loss: 956.105799\tLearning Rate (w_theta): 0.001000\t TIME:3053.0s\n",
      "\t\t\t\tDisc: 0.999253\t\tSym: 16.984293\t\tSpars: 938.122253\n",
      "\t TVw: -0.319908 | TVb: -2.043769 | GSw: -0.234959 | GSb: 0.065060 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1771...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 942.9886601205133\n",
      "Average validation loss: 132.55944151303663\n",
      "Training epoch 1772...\n",
      "\n",
      "Train Epoch: 1772 [0/8000 (0%)]\tBatch Loss: 968.449189\tLearning Rate (w_theta): 0.001000\t TIME:3055.7s\n",
      "\t\t\t\tDisc: 1.080170\t\tSym: 16.175781\t\tSpars: 951.193237\n",
      "\t TVw: -0.319509 | TVb: -2.043769 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1772 [4000/8000 (50%)]\tBatch Loss: 906.071861\tLearning Rate (w_theta): 0.001000\t TIME:3057.2s\n",
      "\t\t\t\tDisc: 0.875921\t\tSym: 14.101946\t\tSpars: 891.093994\n",
      "\t TVw: -0.319102 | TVb: -2.043769 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1772...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 943.1528569160345\n",
      "Average validation loss: 130.92664246981317\n",
      "Training epoch 1773...\n",
      "\n",
      "Train Epoch: 1773 [0/8000 (0%)]\tBatch Loss: 958.107745\tLearning Rate (w_theta): 0.001000\t TIME:3059.6s\n",
      "\t\t\t\tDisc: 1.003541\t\tSym: 16.373552\t\tSpars: 940.730652\n",
      "\t TVw: -0.318692 | TVb: -2.043770 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1773 [4000/8000 (50%)]\tBatch Loss: 959.506330\tLearning Rate (w_theta): 0.001000\t TIME:3061.2s\n",
      "\t\t\t\tDisc: 0.908516\t\tSym: 17.567480\t\tSpars: 941.030334\n",
      "\t TVw: -0.318287 | TVb: -2.043770 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1773...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 942.8006796323831\n",
      "Average validation loss: 131.9512926397727\n",
      "Training epoch 1774...\n",
      "\n",
      "Train Epoch: 1774 [0/8000 (0%)]\tBatch Loss: 959.224393\tLearning Rate (w_theta): 0.001000\t TIME:3063.6s\n",
      "\t\t\t\tDisc: 1.063436\t\tSym: 15.694709\t\tSpars: 942.466248\n",
      "\t TVw: -0.317878 | TVb: -2.043770 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1774 [4000/8000 (50%)]\tBatch Loss: 897.033213\tLearning Rate (w_theta): 0.001000\t TIME:3065.1s\n",
      "\t\t\t\tDisc: 0.898809\t\tSym: 13.689824\t\tSpars: 882.444580\n",
      "\t TVw: -0.317474 | TVb: -2.043771 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1774...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 940.1298351771733\n",
      "Average validation loss: 130.89915623201443\n",
      "Training epoch 1775...\n",
      "\n",
      "Train Epoch: 1775 [0/8000 (0%)]\tBatch Loss: 945.814555\tLearning Rate (w_theta): 0.001000\t TIME:3067.5s\n",
      "\t\t\t\tDisc: 0.902867\t\tSym: 15.526008\t\tSpars: 929.385681\n",
      "\t TVw: -0.317064 | TVb: -2.043771 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1775 [4000/8000 (50%)]\tBatch Loss: 983.422938\tLearning Rate (w_theta): 0.001000\t TIME:3069.1s\n",
      "\t\t\t\tDisc: 0.960019\t\tSym: 18.098478\t\tSpars: 964.364441\n",
      "\t TVw: -0.316648 | TVb: -2.043772 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1775...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 941.8830714832811\n",
      "Average validation loss: 132.26157831078433\n",
      "Training epoch 1776...\n",
      "\n",
      "Train Epoch: 1776 [0/8000 (0%)]\tBatch Loss: 975.809238\tLearning Rate (w_theta): 0.001000\t TIME:3071.4s\n",
      "\t\t\t\tDisc: 1.120876\t\tSym: 17.326485\t\tSpars: 957.361877\n",
      "\t TVw: -0.316221 | TVb: -2.043771 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1776 [4000/8000 (50%)]\tBatch Loss: 991.980349\tLearning Rate (w_theta): 0.001000\t TIME:3073.0s\n",
      "\t\t\t\tDisc: 1.117007\t\tSym: 18.316406\t\tSpars: 972.546936\n",
      "\t TVw: -0.315800 | TVb: -2.043770 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1776...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 942.9943809217467\n",
      "Average validation loss: 130.1649302476818\n",
      "Training epoch 1777...\n",
      "\n",
      "Train Epoch: 1777 [0/8000 (0%)]\tBatch Loss: 973.599329\tLearning Rate (w_theta): 0.001000\t TIME:3075.4s\n",
      "\t\t\t\tDisc: 1.052616\t\tSym: 17.386923\t\tSpars: 955.159790\n",
      "\t TVw: -0.315393 | TVb: -2.043770 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1777 [4000/8000 (50%)]\tBatch Loss: 890.463699\tLearning Rate (w_theta): 0.001000\t TIME:3076.9s\n",
      "\t\t\t\tDisc: 0.831512\t\tSym: 13.762741\t\tSpars: 875.869446\n",
      "\t TVw: -0.314986 | TVb: -2.043770 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1777...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 941.508369038245\n",
      "Average validation loss: 130.26999379309328\n",
      "Training epoch 1778...\n",
      "\n",
      "Train Epoch: 1778 [0/8000 (0%)]\tBatch Loss: 927.181083\tLearning Rate (w_theta): 0.001000\t TIME:3079.3s\n",
      "\t\t\t\tDisc: 0.909541\t\tSym: 15.244199\t\tSpars: 911.027344\n",
      "\t TVw: -0.314572 | TVb: -2.043770 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1778 [4000/8000 (50%)]\tBatch Loss: 955.614937\tLearning Rate (w_theta): 0.001000\t TIME:3080.8s\n",
      "\t\t\t\tDisc: 0.967295\t\tSym: 16.500792\t\tSpars: 938.146851\n",
      "\t TVw: -0.314154 | TVb: -2.043771 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1778...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 938.997452814826\n",
      "Average validation loss: 130.24022243503097\n",
      "Training epoch 1779...\n",
      "\n",
      "Train Epoch: 1779 [0/8000 (0%)]\tBatch Loss: 940.811109\tLearning Rate (w_theta): 0.001000\t TIME:3083.2s\n",
      "\t\t\t\tDisc: 0.973661\t\tSym: 15.078842\t\tSpars: 924.758606\n",
      "\t TVw: -0.313731 | TVb: -2.043771 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1779 [4000/8000 (50%)]\tBatch Loss: 958.101305\tLearning Rate (w_theta): 0.001000\t TIME:3084.7s\n",
      "\t\t\t\tDisc: 1.066130\t\tSym: 17.036091\t\tSpars: 939.999084\n",
      "\t TVw: -0.313308 | TVb: -2.043772 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1779...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 941.1946798835058\n",
      "Average validation loss: 130.01793377617577\n",
      "Training epoch 1780...\n",
      "\n",
      "Train Epoch: 1780 [0/8000 (0%)]\tBatch Loss: 934.547596\tLearning Rate (w_theta): 0.001000\t TIME:3087.1s\n",
      "\t\t\t\tDisc: 0.898015\t\tSym: 16.026169\t\tSpars: 917.623413\n",
      "\t TVw: -0.312889 | TVb: -2.043772 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1780 [4000/8000 (50%)]\tBatch Loss: 932.313091\tLearning Rate (w_theta): 0.001000\t TIME:3088.6s\n",
      "\t\t\t\tDisc: 1.009667\t\tSym: 15.127887\t\tSpars: 916.175537\n",
      "\t TVw: -0.312469 | TVb: -2.043773 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1780...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 941.6197506995907\n",
      "Average validation loss: 129.6820719232952\n",
      "Training epoch 1781...\n",
      "\n",
      "Train Epoch: 1781 [0/8000 (0%)]\tBatch Loss: 1001.880383\tLearning Rate (w_theta): 0.001000\t TIME:3091.9s\n",
      "\t\t\t\tDisc: 0.953717\t\tSym: 19.284637\t\tSpars: 981.642029\n",
      "\t TVw: -0.312046 | TVb: -2.043773 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1781 [4000/8000 (50%)]\tBatch Loss: 954.773121\tLearning Rate (w_theta): 0.001000\t TIME:3093.5s\n",
      "\t\t\t\tDisc: 1.048929\t\tSym: 15.776621\t\tSpars: 937.947571\n",
      "\t TVw: -0.311625 | TVb: -2.043773 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "Validating epoch 1781...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 937.9706462672807\n",
      "Average validation loss: 129.5159758991732\n",
      "Training epoch 1782...\n",
      "\n",
      "Train Epoch: 1782 [0/8000 (0%)]\tBatch Loss: 936.700728\tLearning Rate (w_theta): 0.001000\t TIME:3095.8s\n",
      "\t\t\t\tDisc: 0.925052\t\tSym: 15.948955\t\tSpars: 919.826721\n",
      "\t TVw: -0.311205 | TVb: -2.043773 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034774\n",
      "\n",
      "Train Epoch: 1782 [4000/8000 (50%)]\tBatch Loss: 941.815240\tLearning Rate (w_theta): 0.001000\t TIME:3097.4s\n",
      "\t\t\t\tDisc: 0.967031\t\tSym: 16.579472\t\tSpars: 924.268738\n",
      "\t TVw: -0.310780 | TVb: -2.043773 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "Validating epoch 1782...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 935.7031292594062\n",
      "Average validation loss: 128.97622870984742\n",
      "Training epoch 1783...\n",
      "\n",
      "Train Epoch: 1783 [0/8000 (0%)]\tBatch Loss: 939.709014\tLearning Rate (w_theta): 0.001000\t TIME:3099.7s\n",
      "\t\t\t\tDisc: 0.931950\t\tSym: 15.175746\t\tSpars: 923.601318\n",
      "\t TVw: -0.310355 | TVb: -2.043774 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "\n",
      "Train Epoch: 1783 [4000/8000 (50%)]\tBatch Loss: 961.521280\tLearning Rate (w_theta): 0.001000\t TIME:3101.3s\n",
      "\t\t\t\tDisc: 0.921613\t\tSym: 16.741512\t\tSpars: 943.858154\n",
      "\t TVw: -0.309933 | TVb: -2.043775 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "Validating epoch 1783...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 935.0648430422177\n",
      "Average validation loss: 129.7871174324523\n",
      "Training epoch 1784...\n",
      "\n",
      "Train Epoch: 1784 [0/8000 (0%)]\tBatch Loss: 923.751004\tLearning Rate (w_theta): 0.001000\t TIME:3103.7s\n",
      "\t\t\t\tDisc: 0.874243\t\tSym: 15.111747\t\tSpars: 907.765015\n",
      "\t TVw: -0.309505 | TVb: -2.043775 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "\n",
      "Train Epoch: 1784 [4000/8000 (50%)]\tBatch Loss: 965.448597\tLearning Rate (w_theta): 0.001000\t TIME:3105.3s\n",
      "\t\t\t\tDisc: 1.024816\t\tSym: 16.601698\t\tSpars: 947.822083\n",
      "\t TVw: -0.309076 | TVb: -2.043776 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "Validating epoch 1784...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 935.6908136587659\n",
      "Average validation loss: 129.81551590004918\n",
      "Training epoch 1785...\n",
      "\n",
      "Train Epoch: 1785 [0/8000 (0%)]\tBatch Loss: 927.390925\tLearning Rate (w_theta): 0.001000\t TIME:3107.7s\n",
      "\t\t\t\tDisc: 1.041120\t\tSym: 15.617261\t\tSpars: 910.732544\n",
      "\t TVw: -0.308642 | TVb: -2.043776 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "\n",
      "Train Epoch: 1785 [4000/8000 (50%)]\tBatch Loss: 899.475610\tLearning Rate (w_theta): 0.001000\t TIME:3109.2s\n",
      "\t\t\t\tDisc: 0.832959\t\tSym: 14.195081\t\tSpars: 884.447571\n",
      "\t TVw: -0.308212 | TVb: -2.043777 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "Validating epoch 1785...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 935.3532517340055\n",
      "Average validation loss: 130.7399921112306\n",
      "Training epoch 1786...\n",
      "\n",
      "Train Epoch: 1786 [0/8000 (0%)]\tBatch Loss: 959.020131\tLearning Rate (w_theta): 0.001000\t TIME:3111.6s\n",
      "\t\t\t\tDisc: 1.005641\t\tSym: 16.771143\t\tSpars: 941.243347\n",
      "\t TVw: -0.307776 | TVb: -2.043778 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "\n",
      "Train Epoch: 1786 [4000/8000 (50%)]\tBatch Loss: 938.906790\tLearning Rate (w_theta): 0.001000\t TIME:3113.1s\n",
      "\t\t\t\tDisc: 0.955837\t\tSym: 15.373317\t\tSpars: 922.577637\n",
      "\t TVw: -0.307332 | TVb: -2.043777 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "Validating epoch 1786...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 938.9609971529568\n",
      "Average validation loss: 128.2571135320219\n",
      "Training epoch 1787...\n",
      "\n",
      "Train Epoch: 1787 [0/8000 (0%)]\tBatch Loss: 927.152508\tLearning Rate (w_theta): 0.001000\t TIME:3115.5s\n",
      "\t\t\t\tDisc: 0.960758\t\tSym: 15.107643\t\tSpars: 911.084106\n",
      "\t TVw: -0.306901 | TVb: -2.043776 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "\n",
      "Train Epoch: 1787 [4000/8000 (50%)]\tBatch Loss: 931.350736\tLearning Rate (w_theta): 0.001000\t TIME:3117.1s\n",
      "\t\t\t\tDisc: 1.006540\t\tSym: 15.552997\t\tSpars: 914.791199\n",
      "\t TVw: -0.306465 | TVb: -2.043775 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "Validating epoch 1787...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 936.412471313889\n",
      "Average validation loss: 127.75681659598219\n",
      "Training epoch 1788...\n",
      "\n",
      "Train Epoch: 1788 [0/8000 (0%)]\tBatch Loss: 936.175203\tLearning Rate (w_theta): 0.001000\t TIME:3119.5s\n",
      "\t\t\t\tDisc: 0.837169\t\tSym: 16.019430\t\tSpars: 919.318604\n",
      "\t TVw: -0.306032 | TVb: -2.043775 | GSw: -0.234959 | GSb: 0.065059 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "\n",
      "Train Epoch: 1788 [4000/8000 (50%)]\tBatch Loss: 930.166939\tLearning Rate (w_theta): 0.001000\t TIME:3121.1s\n",
      "\t\t\t\tDisc: 0.943495\t\tSym: 15.822138\t\tSpars: 913.401306\n",
      "\t TVw: -0.305599 | TVb: -2.043774 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "Validating epoch 1788...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 940.6818541317948\n",
      "Average validation loss: 130.7378462796394\n",
      "Training epoch 1789...\n",
      "\n",
      "Train Epoch: 1789 [0/8000 (0%)]\tBatch Loss: 971.923899\tLearning Rate (w_theta): 0.001000\t TIME:3123.8s\n",
      "\t\t\t\tDisc: 0.929080\t\tSym: 16.525398\t\tSpars: 954.469421\n",
      "\t TVw: -0.305169 | TVb: -2.043773 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "\n",
      "Train Epoch: 1789 [4000/8000 (50%)]\tBatch Loss: 961.655606\tLearning Rate (w_theta): 0.001000\t TIME:3125.3s\n",
      "\t\t\t\tDisc: 0.979140\t\tSym: 16.660658\t\tSpars: 944.015808\n",
      "\t TVw: -0.304758 | TVb: -2.043772 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "Validating epoch 1789...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 964.7413409864563\n",
      "Average validation loss: 126.90335193717337\n",
      "Training epoch 1790...\n",
      "\n",
      "Train Epoch: 1790 [0/8000 (0%)]\tBatch Loss: 967.352367\tLearning Rate (w_theta): 0.001000\t TIME:3127.7s\n",
      "\t\t\t\tDisc: 0.975526\t\tSym: 16.584055\t\tSpars: 949.792786\n",
      "\t TVw: -0.304352 | TVb: -2.043773 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "\n",
      "Train Epoch: 1790 [4000/8000 (50%)]\tBatch Loss: 949.961750\tLearning Rate (w_theta): 0.001000\t TIME:3129.3s\n",
      "\t\t\t\tDisc: 0.878440\t\tSym: 15.358518\t\tSpars: 933.724792\n",
      "\t TVw: -0.303928 | TVb: -2.043772 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "Validating epoch 1790...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 955.285992200218\n",
      "Average validation loss: 127.01302246272863\n",
      "Training epoch 1791...\n",
      "\n",
      "Train Epoch: 1791 [0/8000 (0%)]\tBatch Loss: 980.299604\tLearning Rate (w_theta): 0.001000\t TIME:3132.3s\n",
      "\t\t\t\tDisc: 0.930008\t\tSym: 16.690947\t\tSpars: 962.678650\n",
      "\t TVw: -0.303515 | TVb: -2.043773 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "\n",
      "Train Epoch: 1791 [4000/8000 (50%)]\tBatch Loss: 896.639912\tLearning Rate (w_theta): 0.001000\t TIME:3133.8s\n",
      "\t\t\t\tDisc: 0.879163\t\tSym: 14.118599\t\tSpars: 881.642151\n",
      "\t TVw: -0.303102 | TVb: -2.043774 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "Validating epoch 1791...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 954.7020449120539\n",
      "Average validation loss: 130.08749449647343\n",
      "Training epoch 1792...\n",
      "\n",
      "Train Epoch: 1792 [0/8000 (0%)]\tBatch Loss: 885.094431\tLearning Rate (w_theta): 0.001000\t TIME:3136.2s\n",
      "\t\t\t\tDisc: 0.919565\t\tSym: 13.389709\t\tSpars: 870.785156\n",
      "\t TVw: -0.302695 | TVb: -2.043775 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "\n",
      "Train Epoch: 1792 [4000/8000 (50%)]\tBatch Loss: 997.350660\tLearning Rate (w_theta): 0.001000\t TIME:3137.8s\n",
      "\t\t\t\tDisc: 1.142088\t\tSym: 18.699539\t\tSpars: 977.509033\n",
      "\t TVw: -0.302277 | TVb: -2.043774 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "Validating epoch 1792...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 941.3871729443089\n",
      "Average validation loss: 129.78852531954107\n",
      "Training epoch 1793...\n",
      "\n",
      "Train Epoch: 1793 [0/8000 (0%)]\tBatch Loss: 923.254776\tLearning Rate (w_theta): 0.001000\t TIME:3140.2s\n",
      "\t\t\t\tDisc: 1.057523\t\tSym: 15.813464\t\tSpars: 906.383789\n",
      "\t TVw: -0.301844 | TVb: -2.043773 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "\n",
      "Train Epoch: 1793 [4000/8000 (50%)]\tBatch Loss: 1016.303645\tLearning Rate (w_theta): 0.001000\t TIME:3141.7s\n",
      "\t\t\t\tDisc: 1.124242\t\tSym: 18.819113\t\tSpars: 996.360291\n",
      "\t TVw: -0.301405 | TVb: -2.043772 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "Validating epoch 1793...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 933.3627716477188\n",
      "Average validation loss: 128.57709864233192\n",
      "Training epoch 1794...\n",
      "\n",
      "Train Epoch: 1794 [0/8000 (0%)]\tBatch Loss: 945.548952\tLearning Rate (w_theta): 0.001000\t TIME:3144.1s\n",
      "\t\t\t\tDisc: 0.962181\t\tSym: 16.148478\t\tSpars: 928.438293\n",
      "\t TVw: -0.300966 | TVb: -2.043772 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "\n",
      "Train Epoch: 1794 [4000/8000 (50%)]\tBatch Loss: 930.669507\tLearning Rate (w_theta): 0.001000\t TIME:3145.6s\n",
      "\t\t\t\tDisc: 0.915267\t\tSym: 16.462187\t\tSpars: 913.292053\n",
      "\t TVw: -0.300513 | TVb: -2.043772 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "Validating epoch 1794...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 932.1645150700455\n",
      "Average validation loss: 126.93251229287937\n",
      "Training epoch 1795...\n",
      "\n",
      "Train Epoch: 1795 [0/8000 (0%)]\tBatch Loss: 932.673849\tLearning Rate (w_theta): 0.001000\t TIME:3148.0s\n",
      "\t\t\t\tDisc: 0.920123\t\tSym: 15.565982\t\tSpars: 916.187744\n",
      "\t TVw: -0.300052 | TVb: -2.043771 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "\n",
      "Train Epoch: 1795 [4000/8000 (50%)]\tBatch Loss: 962.256504\tLearning Rate (w_theta): 0.001000\t TIME:3149.5s\n",
      "\t\t\t\tDisc: 0.971314\t\tSym: 17.307041\t\tSpars: 943.978149\n",
      "\t TVw: -0.299587 | TVb: -2.043771 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "Validating epoch 1795...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 930.0757722170212\n",
      "Average validation loss: 127.64480304603002\n",
      "Training epoch 1796...\n",
      "\n",
      "Train Epoch: 1796 [0/8000 (0%)]\tBatch Loss: 914.297199\tLearning Rate (w_theta): 0.001000\t TIME:3151.9s\n",
      "\t\t\t\tDisc: 0.952033\t\tSym: 14.691968\t\tSpars: 898.653198\n",
      "\t TVw: -0.299122 | TVb: -2.043770 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "\n",
      "Train Epoch: 1796 [4000/8000 (50%)]\tBatch Loss: 960.942082\tLearning Rate (w_theta): 0.001000\t TIME:3153.5s\n",
      "\t\t\t\tDisc: 0.974679\t\tSym: 16.656185\t\tSpars: 943.311218\n",
      "\t TVw: -0.298658 | TVb: -2.043770 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "Validating epoch 1796...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 929.4200960007403\n",
      "Average validation loss: 127.24836937096315\n",
      "Training epoch 1797...\n",
      "\n",
      "Train Epoch: 1797 [0/8000 (0%)]\tBatch Loss: 897.280482\tLearning Rate (w_theta): 0.001000\t TIME:3156.1s\n",
      "\t\t\t\tDisc: 0.866104\t\tSym: 14.095958\t\tSpars: 882.318420\n",
      "\t TVw: -0.298200 | TVb: -2.043771 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "\n",
      "Train Epoch: 1797 [4000/8000 (50%)]\tBatch Loss: 915.769835\tLearning Rate (w_theta): 0.001000\t TIME:3157.6s\n",
      "\t\t\t\tDisc: 0.896442\t\tSym: 15.057170\t\tSpars: 899.816223\n",
      "\t TVw: -0.297738 | TVb: -2.043771 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "Validating epoch 1797...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 928.6668191927337\n",
      "Average validation loss: 126.6965039849727\n",
      "Training epoch 1798...\n",
      "\n",
      "Train Epoch: 1798 [0/8000 (0%)]\tBatch Loss: 921.186072\tLearning Rate (w_theta): 0.001000\t TIME:3160.0s\n",
      "\t\t\t\tDisc: 0.835237\t\tSym: 15.189275\t\tSpars: 905.161560\n",
      "\t TVw: -0.297275 | TVb: -2.043771 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "\n",
      "Train Epoch: 1798 [4000/8000 (50%)]\tBatch Loss: 945.108302\tLearning Rate (w_theta): 0.001000\t TIME:3161.5s\n",
      "\t\t\t\tDisc: 0.974859\t\tSym: 16.978170\t\tSpars: 927.155273\n",
      "\t TVw: -0.296807 | TVb: -2.043770 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "Validating epoch 1798...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 927.9844935154755\n",
      "Average validation loss: 126.26883307910323\n",
      "Training epoch 1799...\n",
      "\n",
      "Train Epoch: 1799 [0/8000 (0%)]\tBatch Loss: 922.764632\tLearning Rate (w_theta): 0.001000\t TIME:3163.9s\n",
      "\t\t\t\tDisc: 0.901142\t\tSym: 15.282191\t\tSpars: 906.581299\n",
      "\t TVw: -0.296345 | TVb: -2.043769 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034775\n",
      "\n",
      "Train Epoch: 1799 [4000/8000 (50%)]\tBatch Loss: 946.618088\tLearning Rate (w_theta): 0.001000\t TIME:3165.5s\n",
      "\t\t\t\tDisc: 0.883074\t\tSym: 16.822111\t\tSpars: 928.912903\n",
      "\t TVw: -0.295882 | TVb: -2.043769 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "Validating epoch 1799...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 927.11101790547\n",
      "Average validation loss: 125.33577959625354\n",
      "Training epoch 1800...\n",
      "\n",
      "Train Epoch: 1800 [0/8000 (0%)]\tBatch Loss: 965.371062\tLearning Rate (w_theta): 0.001000\t TIME:3167.8s\n",
      "\t\t\t\tDisc: 0.957850\t\tSym: 16.782902\t\tSpars: 947.630310\n",
      "\t TVw: -0.295427 | TVb: -2.043770 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "\n",
      "Train Epoch: 1800 [4000/8000 (50%)]\tBatch Loss: 936.082440\tLearning Rate (w_theta): 0.001000\t TIME:3169.4s\n",
      "\t\t\t\tDisc: 0.922926\t\tSym: 16.019255\t\tSpars: 919.140259\n",
      "\t TVw: -0.294966 | TVb: -2.043770 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "Validating epoch 1800...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 928.025055401777\n",
      "Average validation loss: 126.39682860622352\n",
      "Training epoch 1801...\n",
      "\n",
      "Train Epoch: 1801 [0/8000 (0%)]\tBatch Loss: 924.293693\tLearning Rate (w_theta): 0.001000\t TIME:3172.5s\n",
      "\t\t\t\tDisc: 0.874062\t\tSym: 15.441298\t\tSpars: 907.978333\n",
      "\t TVw: -0.294507 | TVb: -2.043769 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "\n",
      "Train Epoch: 1801 [4000/8000 (50%)]\tBatch Loss: 918.818211\tLearning Rate (w_theta): 0.001000\t TIME:3174.0s\n",
      "\t\t\t\tDisc: 0.917325\t\tSym: 15.224861\t\tSpars: 902.676025\n",
      "\t TVw: -0.294051 | TVb: -2.043770 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "Validating epoch 1801...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 929.9416540740946\n",
      "Average validation loss: 124.96549581554108\n",
      "Training epoch 1802...\n",
      "\n",
      "Train Epoch: 1802 [0/8000 (0%)]\tBatch Loss: 911.359203\tLearning Rate (w_theta): 0.001000\t TIME:3176.4s\n",
      "\t\t\t\tDisc: 0.855712\t\tSym: 14.133435\t\tSpars: 896.370056\n",
      "\t TVw: -0.293596 | TVb: -2.043769 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "\n",
      "Train Epoch: 1802 [4000/8000 (50%)]\tBatch Loss: 952.889911\tLearning Rate (w_theta): 0.001000\t TIME:3177.9s\n",
      "\t\t\t\tDisc: 0.985748\t\tSym: 16.247303\t\tSpars: 935.656860\n",
      "\t TVw: -0.293143 | TVb: -2.043769 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "Validating epoch 1802...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 929.1507004904977\n",
      "Average validation loss: 125.86571949200322\n",
      "Training epoch 1803...\n",
      "\n",
      "Train Epoch: 1803 [0/8000 (0%)]\tBatch Loss: 900.009061\tLearning Rate (w_theta): 0.001000\t TIME:3180.3s\n",
      "\t\t\t\tDisc: 0.898831\t\tSym: 13.848999\t\tSpars: 885.261230\n",
      "\t TVw: -0.292689 | TVb: -2.043768 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "\n",
      "Train Epoch: 1803 [4000/8000 (50%)]\tBatch Loss: 963.877693\tLearning Rate (w_theta): 0.001000\t TIME:3181.8s\n",
      "\t\t\t\tDisc: 1.045017\t\tSym: 16.381870\t\tSpars: 946.450806\n",
      "\t TVw: -0.292241 | TVb: -2.043767 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "Validating epoch 1803...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 937.3210357024573\n",
      "Average validation loss: 124.48892607550849\n",
      "Training epoch 1804...\n",
      "\n",
      "Train Epoch: 1804 [0/8000 (0%)]\tBatch Loss: 948.321556\tLearning Rate (w_theta): 0.001000\t TIME:3184.5s\n",
      "\t\t\t\tDisc: 0.882400\t\tSym: 15.468208\t\tSpars: 931.970947\n",
      "\t TVw: -0.291804 | TVb: -2.043768 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "\n",
      "Train Epoch: 1804 [4000/8000 (50%)]\tBatch Loss: 954.528882\tLearning Rate (w_theta): 0.001000\t TIME:3186.1s\n",
      "\t\t\t\tDisc: 1.076575\t\tSym: 16.922033\t\tSpars: 936.530273\n",
      "\t TVw: -0.291368 | TVb: -2.043767 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "Validating epoch 1804...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 929.5817689703346\n",
      "Average validation loss: 125.70998363669045\n",
      "Training epoch 1805...\n",
      "\n",
      "Train Epoch: 1805 [0/8000 (0%)]\tBatch Loss: 938.304408\tLearning Rate (w_theta): 0.001000\t TIME:3188.5s\n",
      "\t\t\t\tDisc: 1.017365\t\tSym: 16.324335\t\tSpars: 920.962708\n",
      "\t TVw: -0.290922 | TVb: -2.043767 | GSw: -0.234959 | GSb: 0.065058 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "\n",
      "Train Epoch: 1805 [4000/8000 (50%)]\tBatch Loss: 881.324573\tLearning Rate (w_theta): 0.001000\t TIME:3190.0s\n",
      "\t\t\t\tDisc: 0.840117\t\tSym: 14.201619\t\tSpars: 866.282837\n",
      "\t TVw: -0.290474 | TVb: -2.043767 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "Validating epoch 1805...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 927.0128004339055\n",
      "Average validation loss: 123.97183550626133\n",
      "Training epoch 1806...\n",
      "\n",
      "Train Epoch: 1806 [0/8000 (0%)]\tBatch Loss: 919.285264\tLearning Rate (w_theta): 0.001000\t TIME:3192.4s\n",
      "\t\t\t\tDisc: 0.871100\t\tSym: 14.802713\t\tSpars: 903.611450\n",
      "\t TVw: -0.290028 | TVb: -2.043768 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "\n",
      "Train Epoch: 1806 [4000/8000 (50%)]\tBatch Loss: 901.853323\tLearning Rate (w_theta): 0.001000\t TIME:3193.9s\n",
      "\t\t\t\tDisc: 0.867650\t\tSym: 14.848162\t\tSpars: 886.137512\n",
      "\t TVw: -0.289581 | TVb: -2.043768 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "Validating epoch 1806...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 925.3587634548143\n",
      "Average validation loss: 126.45768651909461\n",
      "Training epoch 1807...\n",
      "\n",
      "Train Epoch: 1807 [0/8000 (0%)]\tBatch Loss: 911.448597\tLearning Rate (w_theta): 0.001000\t TIME:3196.3s\n",
      "\t\t\t\tDisc: 0.928135\t\tSym: 14.627762\t\tSpars: 895.892700\n",
      "\t TVw: -0.289126 | TVb: -2.043768 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "\n",
      "Train Epoch: 1807 [4000/8000 (50%)]\tBatch Loss: 907.392077\tLearning Rate (w_theta): 0.001000\t TIME:3197.8s\n",
      "\t\t\t\tDisc: 0.915781\t\tSym: 14.529701\t\tSpars: 891.946594\n",
      "\t TVw: -0.288669 | TVb: -2.043768 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "Validating epoch 1807...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 931.3342226456875\n",
      "Average validation loss: 124.54802351656352\n",
      "Training epoch 1808...\n",
      "\n",
      "Train Epoch: 1808 [0/8000 (0%)]\tBatch Loss: 929.728075\tLearning Rate (w_theta): 0.001000\t TIME:3200.2s\n",
      "\t\t\t\tDisc: 0.904843\t\tSym: 15.423451\t\tSpars: 913.399780\n",
      "\t TVw: -0.288214 | TVb: -2.043768 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "\n",
      "Train Epoch: 1808 [4000/8000 (50%)]\tBatch Loss: 954.040107\tLearning Rate (w_theta): 0.001000\t TIME:3201.8s\n",
      "\t\t\t\tDisc: 1.038438\t\tSym: 16.503622\t\tSpars: 936.498047\n",
      "\t TVw: -0.287750 | TVb: -2.043767 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "Validating epoch 1808...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 926.5650137536961\n",
      "Average validation loss: 125.98701820590907\n",
      "Training epoch 1809...\n",
      "\n",
      "Train Epoch: 1809 [0/8000 (0%)]\tBatch Loss: 886.553096\tLearning Rate (w_theta): 0.001000\t TIME:3204.2s\n",
      "\t\t\t\tDisc: 0.863055\t\tSym: 14.430275\t\tSpars: 871.259766\n",
      "\t TVw: -0.287288 | TVb: -2.043767 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "\n",
      "Train Epoch: 1809 [4000/8000 (50%)]\tBatch Loss: 938.540283\tLearning Rate (w_theta): 0.001000\t TIME:3205.7s\n",
      "\t\t\t\tDisc: 0.931104\t\tSym: 16.596300\t\tSpars: 921.012878\n",
      "\t TVw: -0.286829 | TVb: -2.043767 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "Validating epoch 1809...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 921.905422792236\n",
      "Average validation loss: 124.47233957998435\n",
      "Training epoch 1810...\n",
      "\n",
      "Train Epoch: 1810 [0/8000 (0%)]\tBatch Loss: 901.412932\tLearning Rate (w_theta): 0.001000\t TIME:3208.1s\n",
      "\t\t\t\tDisc: 0.796699\t\tSym: 15.275352\t\tSpars: 885.340881\n",
      "\t TVw: -0.286364 | TVb: -2.043767 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "\n",
      "Train Epoch: 1810 [4000/8000 (50%)]\tBatch Loss: 924.591907\tLearning Rate (w_theta): 0.001000\t TIME:3209.7s\n",
      "\t\t\t\tDisc: 0.982523\t\tSym: 16.263620\t\tSpars: 907.345764\n",
      "\t TVw: -0.285895 | TVb: -2.043767 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "Validating epoch 1810...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 920.4668056456287\n",
      "Average validation loss: 124.29732977660613\n",
      "Training epoch 1811...\n",
      "\n",
      "Train Epoch: 1811 [0/8000 (0%)]\tBatch Loss: 871.445183\tLearning Rate (w_theta): 0.001000\t TIME:3212.7s\n",
      "\t\t\t\tDisc: 0.706947\t\tSym: 13.014420\t\tSpars: 857.723816\n",
      "\t TVw: -0.285424 | TVb: -2.043767 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "\n",
      "Train Epoch: 1811 [4000/8000 (50%)]\tBatch Loss: 923.029511\tLearning Rate (w_theta): 0.001000\t TIME:3214.3s\n",
      "\t\t\t\tDisc: 0.921568\t\tSym: 16.017000\t\tSpars: 906.090942\n",
      "\t TVw: -0.284952 | TVb: -2.043768 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "Validating epoch 1811...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 919.7871510445386\n",
      "Average validation loss: 124.4145726877067\n",
      "Training epoch 1812...\n",
      "\n",
      "Train Epoch: 1812 [0/8000 (0%)]\tBatch Loss: 889.030641\tLearning Rate (w_theta): 0.001000\t TIME:3216.9s\n",
      "\t\t\t\tDisc: 0.876982\t\tSym: 14.263095\t\tSpars: 873.890564\n",
      "\t TVw: -0.284475 | TVb: -2.043767 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "\n",
      "Train Epoch: 1812 [4000/8000 (50%)]\tBatch Loss: 927.867680\tLearning Rate (w_theta): 0.001000\t TIME:3218.5s\n",
      "\t\t\t\tDisc: 0.934325\t\tSym: 16.064215\t\tSpars: 910.869141\n",
      "\t TVw: -0.283996 | TVb: -2.043767 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "Validating epoch 1812...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 919.4692991385433\n",
      "Average validation loss: 124.68448528888729\n",
      "Training epoch 1813...\n",
      "\n",
      "Train Epoch: 1813 [0/8000 (0%)]\tBatch Loss: 909.906954\tLearning Rate (w_theta): 0.001000\t TIME:3220.9s\n",
      "\t\t\t\tDisc: 0.874752\t\tSym: 13.957740\t\tSpars: 895.074463\n",
      "\t TVw: -0.283513 | TVb: -2.043767 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "\n",
      "Train Epoch: 1813 [4000/8000 (50%)]\tBatch Loss: 930.640063\tLearning Rate (w_theta): 0.001000\t TIME:3222.4s\n",
      "\t\t\t\tDisc: 1.034556\t\tSym: 16.401222\t\tSpars: 913.204285\n",
      "\t TVw: -0.283032 | TVb: -2.043766 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "Validating epoch 1813...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 922.4911864723002\n",
      "Average validation loss: 123.46724835479408\n",
      "Training epoch 1814...\n",
      "\n",
      "Train Epoch: 1814 [0/8000 (0%)]\tBatch Loss: 945.806497\tLearning Rate (w_theta): 0.001000\t TIME:3224.8s\n",
      "\t\t\t\tDisc: 0.885366\t\tSym: 17.252918\t\tSpars: 927.668213\n",
      "\t TVw: -0.282553 | TVb: -2.043765 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "\n",
      "Train Epoch: 1814 [4000/8000 (50%)]\tBatch Loss: 944.516168\tLearning Rate (w_theta): 0.001000\t TIME:3226.4s\n",
      "\t\t\t\tDisc: 0.935705\t\tSym: 15.982013\t\tSpars: 927.598450\n",
      "\t TVw: -0.282085 | TVb: -2.043764 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "Validating epoch 1814...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 926.063826268844\n",
      "Average validation loss: 122.6767531747158\n",
      "Training epoch 1815...\n",
      "\n",
      "Train Epoch: 1815 [0/8000 (0%)]\tBatch Loss: 937.387392\tLearning Rate (w_theta): 0.001000\t TIME:3228.7s\n",
      "\t\t\t\tDisc: 0.973594\t\tSym: 16.680765\t\tSpars: 919.733032\n",
      "\t TVw: -0.281621 | TVb: -2.043763 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "\n",
      "Train Epoch: 1815 [4000/8000 (50%)]\tBatch Loss: 944.956823\tLearning Rate (w_theta): 0.001000\t TIME:3230.3s\n",
      "\t\t\t\tDisc: 0.693966\t\tSym: 15.346109\t\tSpars: 928.916748\n",
      "\t TVw: -0.281176 | TVb: -2.043762 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034776\n",
      "Validating epoch 1815...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 940.9332492184437\n",
      "Average validation loss: 125.29810779467167\n",
      "Training epoch 1816...\n",
      "\n",
      "Train Epoch: 1816 [0/8000 (0%)]\tBatch Loss: 924.229299\tLearning Rate (w_theta): 0.001000\t TIME:3232.7s\n",
      "\t\t\t\tDisc: 1.011740\t\tSym: 16.278595\t\tSpars: 906.938965\n",
      "\t TVw: -0.280731 | TVb: -2.043762 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "\n",
      "Train Epoch: 1816 [4000/8000 (50%)]\tBatch Loss: 941.488258\tLearning Rate (w_theta): 0.001000\t TIME:3234.3s\n",
      "\t\t\t\tDisc: 0.982775\t\tSym: 17.107534\t\tSpars: 923.397949\n",
      "\t TVw: -0.280271 | TVb: -2.043762 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "Validating epoch 1816...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 933.5898095176631\n",
      "Average validation loss: 121.33699491366343\n",
      "Training epoch 1817...\n",
      "\n",
      "Train Epoch: 1817 [0/8000 (0%)]\tBatch Loss: 962.938264\tLearning Rate (w_theta): 0.001000\t TIME:3236.7s\n",
      "\t\t\t\tDisc: 0.943646\t\tSym: 15.601613\t\tSpars: 946.393005\n",
      "\t TVw: -0.279817 | TVb: -2.043761 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "\n",
      "Train Epoch: 1817 [4000/8000 (50%)]\tBatch Loss: 965.114845\tLearning Rate (w_theta): 0.001000\t TIME:3238.2s\n",
      "\t\t\t\tDisc: 0.960330\t\tSym: 16.954685\t\tSpars: 947.199829\n",
      "\t TVw: -0.279371 | TVb: -2.043761 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "Validating epoch 1817...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 934.4088738962384\n",
      "Average validation loss: 122.93566763586588\n",
      "Training epoch 1818...\n",
      "\n",
      "Train Epoch: 1818 [0/8000 (0%)]\tBatch Loss: 946.986858\tLearning Rate (w_theta): 0.001000\t TIME:3240.6s\n",
      "\t\t\t\tDisc: 0.843765\t\tSym: 16.148220\t\tSpars: 929.994873\n",
      "\t TVw: -0.278905 | TVb: -2.043761 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "\n",
      "Train Epoch: 1818 [4000/8000 (50%)]\tBatch Loss: 917.789900\tLearning Rate (w_theta): 0.001000\t TIME:3242.1s\n",
      "\t\t\t\tDisc: 0.923015\t\tSym: 15.385379\t\tSpars: 901.481506\n",
      "\t TVw: -0.278428 | TVb: -2.043760 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "Validating epoch 1818...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 922.6535010691862\n",
      "Average validation loss: 122.127397299089\n",
      "Training epoch 1819...\n",
      "\n",
      "Train Epoch: 1819 [0/8000 (0%)]\tBatch Loss: 894.368689\tLearning Rate (w_theta): 0.001000\t TIME:3244.5s\n",
      "\t\t\t\tDisc: 0.781234\t\tSym: 15.828788\t\tSpars: 877.758667\n",
      "\t TVw: -0.277936 | TVb: -2.043758 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "\n",
      "Train Epoch: 1819 [4000/8000 (50%)]\tBatch Loss: 933.410394\tLearning Rate (w_theta): 0.001000\t TIME:3246.0s\n",
      "\t\t\t\tDisc: 0.946960\t\tSym: 16.394403\t\tSpars: 916.069031\n",
      "\t TVw: -0.277439 | TVb: -2.043756 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "Validating epoch 1819...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 926.0346296049914\n",
      "Average validation loss: 124.90546651185419\n",
      "Training epoch 1820...\n",
      "\n",
      "Train Epoch: 1820 [0/8000 (0%)]\tBatch Loss: 941.130357\tLearning Rate (w_theta): 0.001000\t TIME:3248.4s\n",
      "\t\t\t\tDisc: 0.941008\t\tSym: 16.486895\t\tSpars: 923.702454\n",
      "\t TVw: -0.276953 | TVb: -2.043754 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "\n",
      "Train Epoch: 1820 [4000/8000 (50%)]\tBatch Loss: 908.125497\tLearning Rate (w_theta): 0.001000\t TIME:3250.0s\n",
      "\t\t\t\tDisc: 0.910941\t\tSym: 15.217913\t\tSpars: 891.996643\n",
      "\t TVw: -0.276486 | TVb: -2.043754 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "Validating epoch 1820...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 926.6930086044999\n",
      "Average validation loss: 122.52354819867438\n",
      "Training epoch 1821...\n",
      "\n",
      "Train Epoch: 1821 [0/8000 (0%)]\tBatch Loss: 909.252554\tLearning Rate (w_theta): 0.001000\t TIME:3253.3s\n",
      "\t\t\t\tDisc: 0.883555\t\tSym: 15.319011\t\tSpars: 893.049988\n",
      "\t TVw: -0.276012 | TVb: -2.043754 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "\n",
      "Train Epoch: 1821 [4000/8000 (50%)]\tBatch Loss: 906.629585\tLearning Rate (w_theta): 0.001000\t TIME:3254.8s\n",
      "\t\t\t\tDisc: 0.838532\t\tSym: 14.783607\t\tSpars: 891.007446\n",
      "\t TVw: -0.275537 | TVb: -2.043754 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "Validating epoch 1821...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 917.7375166252316\n",
      "Average validation loss: 121.23061046683597\n",
      "Training epoch 1822...\n",
      "\n",
      "Train Epoch: 1822 [0/8000 (0%)]\tBatch Loss: 911.148929\tLearning Rate (w_theta): 0.001000\t TIME:3257.2s\n",
      "\t\t\t\tDisc: 0.833942\t\tSym: 15.240341\t\tSpars: 895.074646\n",
      "\t TVw: -0.275052 | TVb: -2.043753 | GSw: -0.234959 | GSb: 0.065057 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "\n",
      "Train Epoch: 1822 [4000/8000 (50%)]\tBatch Loss: 915.483691\tLearning Rate (w_theta): 0.001000\t TIME:3258.7s\n",
      "\t\t\t\tDisc: 0.876535\t\tSym: 15.610209\t\tSpars: 898.996948\n",
      "\t TVw: -0.274563 | TVb: -2.043752 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "Validating epoch 1822...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 916.7832923548224\n",
      "Average validation loss: 120.5595643592316\n",
      "Training epoch 1823...\n",
      "\n",
      "Train Epoch: 1823 [0/8000 (0%)]\tBatch Loss: 880.714319\tLearning Rate (w_theta): 0.001000\t TIME:3261.1s\n",
      "\t\t\t\tDisc: 0.808768\t\tSym: 13.610507\t\tSpars: 866.295044\n",
      "\t TVw: -0.274078 | TVb: -2.043752 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "\n",
      "Train Epoch: 1823 [4000/8000 (50%)]\tBatch Loss: 920.476451\tLearning Rate (w_theta): 0.001000\t TIME:3262.6s\n",
      "\t\t\t\tDisc: 0.893276\t\tSym: 15.679611\t\tSpars: 903.903564\n",
      "\t TVw: -0.273593 | TVb: -2.043751 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "Validating epoch 1823...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 915.5415225966046\n",
      "Average validation loss: 121.67841913588171\n",
      "Training epoch 1824...\n",
      "\n",
      "Train Epoch: 1824 [0/8000 (0%)]\tBatch Loss: 934.725007\tLearning Rate (w_theta): 0.001000\t TIME:3265.0s\n",
      "\t\t\t\tDisc: 0.968730\t\tSym: 16.701712\t\tSpars: 917.054565\n",
      "\t TVw: -0.273104 | TVb: -2.043750 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "\n",
      "Train Epoch: 1824 [4000/8000 (50%)]\tBatch Loss: 911.590201\tLearning Rate (w_theta): 0.001000\t TIME:3266.6s\n",
      "\t\t\t\tDisc: 0.952768\t\tSym: 15.529950\t\tSpars: 895.107483\n",
      "\t TVw: -0.272612 | TVb: -2.043749 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "Validating epoch 1824...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 913.2717609402505\n",
      "Average validation loss: 121.49836456408015\n",
      "Training epoch 1825...\n",
      "\n",
      "Train Epoch: 1825 [0/8000 (0%)]\tBatch Loss: 895.869394\tLearning Rate (w_theta): 0.001000\t TIME:3268.9s\n",
      "\t\t\t\tDisc: 0.910575\t\tSym: 14.971271\t\tSpars: 879.987549\n",
      "\t TVw: -0.272125 | TVb: -2.043749 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "\n",
      "Train Epoch: 1825 [4000/8000 (50%)]\tBatch Loss: 925.634978\tLearning Rate (w_theta): 0.001000\t TIME:3270.5s\n",
      "\t\t\t\tDisc: 0.923002\t\tSym: 15.756104\t\tSpars: 908.955872\n",
      "\t TVw: -0.271638 | TVb: -2.043749 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "Validating epoch 1825...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 912.6965337246497\n",
      "Average validation loss: 120.85368696485637\n",
      "Training epoch 1826...\n",
      "\n",
      "Train Epoch: 1826 [0/8000 (0%)]\tBatch Loss: 962.712072\tLearning Rate (w_theta): 0.001000\t TIME:3272.9s\n",
      "\t\t\t\tDisc: 0.955025\t\tSym: 18.077543\t\tSpars: 943.679504\n",
      "\t TVw: -0.271150 | TVb: -2.043749 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "\n",
      "Train Epoch: 1826 [4000/8000 (50%)]\tBatch Loss: 932.918373\tLearning Rate (w_theta): 0.001000\t TIME:3274.4s\n",
      "\t\t\t\tDisc: 0.955316\t\tSym: 16.373518\t\tSpars: 915.589539\n",
      "\t TVw: -0.270662 | TVb: -2.043749 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "Validating epoch 1826...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 910.918317830955\n",
      "Average validation loss: 120.99096611064543\n",
      "Training epoch 1827...\n",
      "\n",
      "Train Epoch: 1827 [0/8000 (0%)]\tBatch Loss: 880.600798\tLearning Rate (w_theta): 0.001000\t TIME:3276.8s\n",
      "\t\t\t\tDisc: 0.813107\t\tSym: 13.455538\t\tSpars: 866.332153\n",
      "\t TVw: -0.270165 | TVb: -2.043748 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "\n",
      "Train Epoch: 1827 [4000/8000 (50%)]\tBatch Loss: 924.587550\tLearning Rate (w_theta): 0.001000\t TIME:3278.4s\n",
      "\t\t\t\tDisc: 0.973583\t\tSym: 15.710219\t\tSpars: 907.903748\n",
      "\t TVw: -0.269669 | TVb: -2.043748 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "Validating epoch 1827...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 910.9117234152847\n",
      "Average validation loss: 120.61860425714707\n",
      "Training epoch 1828...\n",
      "\n",
      "Train Epoch: 1828 [0/8000 (0%)]\tBatch Loss: 920.617722\tLearning Rate (w_theta): 0.001000\t TIME:3280.7s\n",
      "\t\t\t\tDisc: 0.846617\t\tSym: 14.969042\t\tSpars: 904.802063\n",
      "\t TVw: -0.269171 | TVb: -2.043749 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "\n",
      "Train Epoch: 1828 [4000/8000 (50%)]\tBatch Loss: 936.595825\tLearning Rate (w_theta): 0.001000\t TIME:3282.3s\n",
      "\t\t\t\tDisc: 0.993763\t\tSym: 15.973033\t\tSpars: 919.629028\n",
      "\t TVw: -0.268663 | TVb: -2.043748 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "Validating epoch 1828...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 910.99098181465\n",
      "Average validation loss: 121.24396022389874\n",
      "Training epoch 1829...\n",
      "\n",
      "Train Epoch: 1829 [0/8000 (0%)]\tBatch Loss: 926.506439\tLearning Rate (w_theta): 0.001000\t TIME:3284.7s\n",
      "\t\t\t\tDisc: 0.915591\t\tSym: 16.932829\t\tSpars: 908.658020\n",
      "\t TVw: -0.268170 | TVb: -2.043747 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "\n",
      "Train Epoch: 1829 [4000/8000 (50%)]\tBatch Loss: 894.953993\tLearning Rate (w_theta): 0.001000\t TIME:3286.2s\n",
      "\t\t\t\tDisc: 0.795295\t\tSym: 13.756110\t\tSpars: 880.402588\n",
      "\t TVw: -0.267689 | TVb: -2.043747 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "Validating epoch 1829...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 911.5082636486371\n",
      "Average validation loss: 120.16245362147085\n",
      "Training epoch 1830...\n",
      "\n",
      "Train Epoch: 1830 [0/8000 (0%)]\tBatch Loss: 895.616069\tLearning Rate (w_theta): 0.001000\t TIME:3288.8s\n",
      "\t\t\t\tDisc: 0.716887\t\tSym: 15.120252\t\tSpars: 879.778931\n",
      "\t TVw: -0.267206 | TVb: -2.043748 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "\n",
      "Train Epoch: 1830 [4000/8000 (50%)]\tBatch Loss: 962.362043\tLearning Rate (w_theta): 0.001000\t TIME:3290.4s\n",
      "\t\t\t\tDisc: 1.090157\t\tSym: 18.288061\t\tSpars: 942.983826\n",
      "\t TVw: -0.266726 | TVb: -2.043748 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "Validating epoch 1830...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 909.9944125830112\n",
      "Average validation loss: 120.93054092549659\n",
      "Training epoch 1831...\n",
      "\n",
      "Train Epoch: 1831 [0/8000 (0%)]\tBatch Loss: 896.837643\tLearning Rate (w_theta): 0.001000\t TIME:3293.4s\n",
      "\t\t\t\tDisc: 0.840192\t\tSym: 15.521926\t\tSpars: 880.475525\n",
      "\t TVw: -0.266243 | TVb: -2.043748 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "\n",
      "Train Epoch: 1831 [4000/8000 (50%)]\tBatch Loss: 913.952868\tLearning Rate (w_theta): 0.001000\t TIME:3294.9s\n",
      "\t\t\t\tDisc: 0.966461\t\tSym: 15.692279\t\tSpars: 897.294128\n",
      "\t TVw: -0.265753 | TVb: -2.043748 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "Validating epoch 1831...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 908.0813330771592\n",
      "Average validation loss: 121.45520032299534\n",
      "Training epoch 1832...\n",
      "\n",
      "Train Epoch: 1832 [0/8000 (0%)]\tBatch Loss: 932.139110\tLearning Rate (w_theta): 0.001000\t TIME:3297.4s\n",
      "\t\t\t\tDisc: 0.950252\t\tSym: 16.002579\t\tSpars: 915.186279\n",
      "\t TVw: -0.265264 | TVb: -2.043748 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "\n",
      "Train Epoch: 1832 [4000/8000 (50%)]\tBatch Loss: 938.886556\tLearning Rate (w_theta): 0.001000\t TIME:3298.9s\n",
      "\t\t\t\tDisc: 0.943152\t\tSym: 16.069258\t\tSpars: 921.874146\n",
      "\t TVw: -0.264767 | TVb: -2.043747 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034777\n",
      "Validating epoch 1832...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 912.1330782365421\n",
      "Average validation loss: 119.50789873298574\n",
      "Training epoch 1833...\n",
      "\n",
      "Train Epoch: 1833 [0/8000 (0%)]\tBatch Loss: 909.119307\tLearning Rate (w_theta): 0.001000\t TIME:3301.3s\n",
      "\t\t\t\tDisc: 0.880637\t\tSym: 15.278403\t\tSpars: 892.960266\n",
      "\t TVw: -0.264269 | TVb: -2.043746 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "\n",
      "Train Epoch: 1833 [4000/8000 (50%)]\tBatch Loss: 940.710187\tLearning Rate (w_theta): 0.001000\t TIME:3302.8s\n",
      "\t\t\t\tDisc: 1.048774\t\tSym: 16.558630\t\tSpars: 923.102783\n",
      "\t TVw: -0.263779 | TVb: -2.043744 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "Validating epoch 1833...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 921.818733218001\n",
      "Average validation loss: 120.20316602330708\n",
      "Training epoch 1834...\n",
      "\n",
      "Train Epoch: 1834 [0/8000 (0%)]\tBatch Loss: 898.579935\tLearning Rate (w_theta): 0.001000\t TIME:3305.2s\n",
      "\t\t\t\tDisc: 0.845926\t\tSym: 14.764038\t\tSpars: 882.969971\n",
      "\t TVw: -0.263305 | TVb: -2.043744 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "\n",
      "Train Epoch: 1834 [4000/8000 (50%)]\tBatch Loss: 971.418373\tLearning Rate (w_theta): 0.001000\t TIME:3306.7s\n",
      "\t\t\t\tDisc: 0.978195\t\tSym: 17.283257\t\tSpars: 953.156921\n",
      "\t TVw: -0.262824 | TVb: -2.043743 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "Validating epoch 1834...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 915.4377401957863\n",
      "Average validation loss: 119.88191172809945\n",
      "Training epoch 1835...\n",
      "\n",
      "Train Epoch: 1835 [0/8000 (0%)]\tBatch Loss: 890.085114\tLearning Rate (w_theta): 0.001000\t TIME:3309.1s\n",
      "\t\t\t\tDisc: 0.893111\t\tSym: 14.452440\t\tSpars: 874.739563\n",
      "\t TVw: -0.262341 | TVb: -2.043742 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "\n",
      "Train Epoch: 1835 [4000/8000 (50%)]\tBatch Loss: 901.734763\tLearning Rate (w_theta): 0.001000\t TIME:3310.7s\n",
      "\t\t\t\tDisc: 0.824404\t\tSym: 15.574422\t\tSpars: 885.335938\n",
      "\t TVw: -0.261849 | TVb: -2.043741 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "Validating epoch 1835...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 907.498532849127\n",
      "Average validation loss: 120.98246683910068\n",
      "Training epoch 1836...\n",
      "\n",
      "Train Epoch: 1836 [0/8000 (0%)]\tBatch Loss: 967.642059\tLearning Rate (w_theta): 0.001000\t TIME:3313.1s\n",
      "\t\t\t\tDisc: 0.951780\t\tSym: 16.918673\t\tSpars: 949.771606\n",
      "\t TVw: -0.261354 | TVb: -2.043740 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "\n",
      "Train Epoch: 1836 [4000/8000 (50%)]\tBatch Loss: 857.929644\tLearning Rate (w_theta): 0.001000\t TIME:3314.6s\n",
      "\t\t\t\tDisc: 0.822174\t\tSym: 13.670581\t\tSpars: 843.436890\n",
      "\t TVw: -0.260853 | TVb: -2.043739 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "Validating epoch 1836...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 909.3868541392796\n",
      "Average validation loss: 118.57498138308078\n",
      "Training epoch 1837...\n",
      "\n",
      "Train Epoch: 1837 [0/8000 (0%)]\tBatch Loss: 944.871817\tLearning Rate (w_theta): 0.001000\t TIME:3317.0s\n",
      "\t\t\t\tDisc: 0.906077\t\tSym: 16.620098\t\tSpars: 927.345642\n",
      "\t TVw: -0.260349 | TVb: -2.043739 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "\n",
      "Train Epoch: 1837 [4000/8000 (50%)]\tBatch Loss: 885.208209\tLearning Rate (w_theta): 0.001000\t TIME:3318.6s\n",
      "\t\t\t\tDisc: 0.892138\t\tSym: 14.826141\t\tSpars: 869.489929\n",
      "\t TVw: -0.259838 | TVb: -2.043738 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "Validating epoch 1837...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 909.5249380569749\n",
      "Average validation loss: 120.44987714809535\n",
      "Training epoch 1838...\n",
      "\n",
      "Train Epoch: 1838 [0/8000 (0%)]\tBatch Loss: 910.950259\tLearning Rate (w_theta): 0.001000\t TIME:3320.9s\n",
      "\t\t\t\tDisc: 0.942877\t\tSym: 15.492368\t\tSpars: 894.515015\n",
      "\t TVw: -0.259325 | TVb: -2.043736 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "\n",
      "Train Epoch: 1838 [4000/8000 (50%)]\tBatch Loss: 850.505965\tLearning Rate (w_theta): 0.001000\t TIME:3322.5s\n",
      "\t\t\t\tDisc: 0.797890\t\tSym: 13.292670\t\tSpars: 836.415405\n",
      "\t TVw: -0.258818 | TVb: -2.043736 | GSw: -0.234959 | GSb: 0.065056 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "Validating epoch 1838...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 906.2590247646461\n",
      "Average validation loss: 119.58989711296002\n",
      "Training epoch 1839...\n",
      "\n",
      "Train Epoch: 1839 [0/8000 (0%)]\tBatch Loss: 897.406157\tLearning Rate (w_theta): 0.001000\t TIME:3325.1s\n",
      "\t\t\t\tDisc: 0.909481\t\tSym: 14.288791\t\tSpars: 882.207886\n",
      "\t TVw: -0.258311 | TVb: -2.043736 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "\n",
      "Train Epoch: 1839 [4000/8000 (50%)]\tBatch Loss: 894.977387\tLearning Rate (w_theta): 0.001000\t TIME:3326.7s\n",
      "\t\t\t\tDisc: 0.809647\t\tSym: 14.973587\t\tSpars: 879.194153\n",
      "\t TVw: -0.257804 | TVb: -2.043735 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "Validating epoch 1839...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 909.2682495711617\n",
      "Average validation loss: 118.6136189560917\n",
      "Training epoch 1840...\n",
      "\n",
      "Train Epoch: 1840 [0/8000 (0%)]\tBatch Loss: 876.463301\tLearning Rate (w_theta): 0.001000\t TIME:3329.1s\n",
      "\t\t\t\tDisc: 0.767226\t\tSym: 14.524932\t\tSpars: 861.171143\n",
      "\t TVw: -0.257301 | TVb: -2.043735 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "\n",
      "Train Epoch: 1840 [4000/8000 (50%)]\tBatch Loss: 999.033112\tLearning Rate (w_theta): 0.001000\t TIME:3330.6s\n",
      "\t\t\t\tDisc: 0.881184\t\tSym: 18.537792\t\tSpars: 979.614136\n",
      "\t TVw: -0.256803 | TVb: -2.043733 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "Validating epoch 1840...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 924.9201275939032\n",
      "Average validation loss: 121.49430704129088\n",
      "Training epoch 1841...\n",
      "\n",
      "Train Epoch: 1841 [0/8000 (0%)]\tBatch Loss: 916.066259\tLearning Rate (w_theta): 0.001000\t TIME:3333.7s\n",
      "\t\t\t\tDisc: 0.968939\t\tSym: 14.599395\t\tSpars: 900.497925\n",
      "\t TVw: -0.256315 | TVb: -2.043733 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "\n",
      "Train Epoch: 1841 [4000/8000 (50%)]\tBatch Loss: 861.800229\tLearning Rate (w_theta): 0.001000\t TIME:3335.3s\n",
      "\t\t\t\tDisc: 0.826546\t\tSym: 12.700612\t\tSpars: 848.273071\n",
      "\t TVw: -0.255832 | TVb: -2.043734 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "Validating epoch 1841...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 919.0174077883248\n",
      "Average validation loss: 118.44796611590012\n",
      "Training epoch 1842...\n",
      "\n",
      "Train Epoch: 1842 [0/8000 (0%)]\tBatch Loss: 938.219706\tLearning Rate (w_theta): 0.001000\t TIME:3337.7s\n",
      "\t\t\t\tDisc: 0.869389\t\tSym: 16.127661\t\tSpars: 921.222656\n",
      "\t TVw: -0.255344 | TVb: -2.043734 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "\n",
      "Train Epoch: 1842 [4000/8000 (50%)]\tBatch Loss: 903.928911\tLearning Rate (w_theta): 0.001000\t TIME:3339.2s\n",
      "\t\t\t\tDisc: 0.897334\t\tSym: 15.743308\t\tSpars: 887.288269\n",
      "\t TVw: -0.254847 | TVb: -2.043733 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "Validating epoch 1842...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 908.7927205424692\n",
      "Average validation loss: 118.59524148774338\n",
      "Training epoch 1843...\n",
      "\n",
      "Train Epoch: 1843 [0/8000 (0%)]\tBatch Loss: 902.933026\tLearning Rate (w_theta): 0.001000\t TIME:3341.6s\n",
      "\t\t\t\tDisc: 0.832369\t\tSym: 14.439036\t\tSpars: 887.661621\n",
      "\t TVw: -0.254322 | TVb: -2.043731 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "\n",
      "Train Epoch: 1843 [4000/8000 (50%)]\tBatch Loss: 881.249491\tLearning Rate (w_theta): 0.001000\t TIME:3343.2s\n",
      "\t\t\t\tDisc: 0.924579\t\tSym: 14.562217\t\tSpars: 865.762695\n",
      "\t TVw: -0.253790 | TVb: -2.043729 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "Validating epoch 1843...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 905.8422222342041\n",
      "Average validation loss: 119.83579996720687\n",
      "Training epoch 1844...\n",
      "\n",
      "Train Epoch: 1844 [0/8000 (0%)]\tBatch Loss: 923.884065\tLearning Rate (w_theta): 0.001000\t TIME:3345.6s\n",
      "\t\t\t\tDisc: 0.943596\t\tSym: 16.197306\t\tSpars: 906.743164\n",
      "\t TVw: -0.253241 | TVb: -2.043725 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "\n",
      "Train Epoch: 1844 [4000/8000 (50%)]\tBatch Loss: 887.295356\tLearning Rate (w_theta): 0.001000\t TIME:3347.2s\n",
      "\t\t\t\tDisc: 0.941240\t\tSym: 14.103078\t\tSpars: 872.251038\n",
      "\t TVw: -0.252695 | TVb: -2.043722 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "Validating epoch 1844...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 906.656071319538\n",
      "Average validation loss: 117.08566376467155\n",
      "Training epoch 1845...\n",
      "\n",
      "Train Epoch: 1845 [0/8000 (0%)]\tBatch Loss: 903.533011\tLearning Rate (w_theta): 0.001000\t TIME:3349.5s\n",
      "\t\t\t\tDisc: 0.869897\t\tSym: 15.238187\t\tSpars: 887.424927\n",
      "\t TVw: -0.252162 | TVb: -2.043720 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "\n",
      "Train Epoch: 1845 [4000/8000 (50%)]\tBatch Loss: 934.737514\tLearning Rate (w_theta): 0.001000\t TIME:3351.1s\n",
      "\t\t\t\tDisc: 0.910429\t\tSym: 16.359007\t\tSpars: 917.468079\n",
      "\t TVw: -0.251628 | TVb: -2.043718 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "Validating epoch 1845...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 903.3328394717603\n",
      "Average validation loss: 115.64657516983355\n",
      "Training epoch 1846...\n",
      "\n",
      "Train Epoch: 1846 [0/8000 (0%)]\tBatch Loss: 882.080391\tLearning Rate (w_theta): 0.001000\t TIME:3353.4s\n",
      "\t\t\t\tDisc: 0.770560\t\tSym: 14.779314\t\tSpars: 866.530518\n",
      "\t TVw: -0.251091 | TVb: -2.043716 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "\n",
      "Train Epoch: 1846 [4000/8000 (50%)]\tBatch Loss: 910.028999\tLearning Rate (w_theta): 0.001000\t TIME:3355.0s\n",
      "\t\t\t\tDisc: 0.928936\t\tSym: 16.015652\t\tSpars: 893.084412\n",
      "\t TVw: -0.250570 | TVb: -2.043714 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "Validating epoch 1846...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 901.5523976468963\n",
      "Average validation loss: 117.19087560168865\n",
      "Training epoch 1847...\n",
      "\n",
      "Train Epoch: 1847 [0/8000 (0%)]\tBatch Loss: 898.644467\tLearning Rate (w_theta): 0.001000\t TIME:3357.6s\n",
      "\t\t\t\tDisc: 0.934916\t\tSym: 15.308855\t\tSpars: 882.400696\n",
      "\t TVw: -0.250056 | TVb: -2.043713 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "\n",
      "Train Epoch: 1847 [4000/8000 (50%)]\tBatch Loss: 912.013825\tLearning Rate (w_theta): 0.001000\t TIME:3359.2s\n",
      "\t\t\t\tDisc: 0.880806\t\tSym: 15.438377\t\tSpars: 895.694641\n",
      "\t TVw: -0.249533 | TVb: -2.043712 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "Validating epoch 1847...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 903.8758363746413\n",
      "Average validation loss: 117.90836121744887\n",
      "Training epoch 1848...\n",
      "\n",
      "Train Epoch: 1848 [0/8000 (0%)]\tBatch Loss: 883.308516\tLearning Rate (w_theta): 0.001000\t TIME:3361.6s\n",
      "\t\t\t\tDisc: 0.855557\t\tSym: 14.236528\t\tSpars: 868.216431\n",
      "\t TVw: -0.249011 | TVb: -2.043711 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "\n",
      "Train Epoch: 1848 [4000/8000 (50%)]\tBatch Loss: 921.569997\tLearning Rate (w_theta): 0.001000\t TIME:3363.1s\n",
      "\t\t\t\tDisc: 0.817971\t\tSym: 14.857251\t\tSpars: 905.894775\n",
      "\t TVw: -0.248495 | TVb: -2.043710 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "Validating epoch 1848...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 920.125701415579\n",
      "Average validation loss: 114.41772367513157\n",
      "Training epoch 1849...\n",
      "\n",
      "Train Epoch: 1849 [0/8000 (0%)]\tBatch Loss: 980.711135\tLearning Rate (w_theta): 0.001000\t TIME:3365.5s\n",
      "\t\t\t\tDisc: 0.931619\t\tSym: 17.525366\t\tSpars: 962.254150\n",
      "\t TVw: -0.248001 | TVb: -2.043710 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "\n",
      "Train Epoch: 1849 [4000/8000 (50%)]\tBatch Loss: 901.904939\tLearning Rate (w_theta): 0.001000\t TIME:3367.1s\n",
      "\t\t\t\tDisc: 0.856752\t\tSym: 14.419159\t\tSpars: 886.629028\n",
      "\t TVw: -0.247513 | TVb: -2.043711 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034778\n",
      "Validating epoch 1849...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 917.0416678179088\n",
      "Average validation loss: 115.37335648778749\n",
      "Training epoch 1850...\n",
      "\n",
      "Train Epoch: 1850 [0/8000 (0%)]\tBatch Loss: 903.159121\tLearning Rate (w_theta): 0.001000\t TIME:3369.4s\n",
      "\t\t\t\tDisc: 0.876457\t\tSym: 15.274302\t\tSpars: 887.008362\n",
      "\t TVw: -0.247022 | TVb: -2.043711 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "\n",
      "Train Epoch: 1850 [4000/8000 (50%)]\tBatch Loss: 892.056406\tLearning Rate (w_theta): 0.001000\t TIME:3371.0s\n",
      "\t\t\t\tDisc: 0.821617\t\tSym: 15.021044\t\tSpars: 876.213745\n",
      "\t TVw: -0.246535 | TVb: -2.043710 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "Validating epoch 1850...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 906.1578013838192\n",
      "Average validation loss: 118.3409203192826\n",
      "Training epoch 1851...\n",
      "\n",
      "Train Epoch: 1851 [0/8000 (0%)]\tBatch Loss: 935.383686\tLearning Rate (w_theta): 0.001000\t TIME:3374.0s\n",
      "\t\t\t\tDisc: 0.990801\t\tSym: 16.771486\t\tSpars: 917.621399\n",
      "\t TVw: -0.246031 | TVb: -2.043709 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "\n",
      "Train Epoch: 1851 [4000/8000 (50%)]\tBatch Loss: 925.541111\tLearning Rate (w_theta): 0.001000\t TIME:3375.6s\n",
      "\t\t\t\tDisc: 0.943993\t\tSym: 16.043041\t\tSpars: 908.554077\n",
      "\t TVw: -0.245511 | TVb: -2.043707 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "Validating epoch 1851...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 899.7816197016635\n",
      "Average validation loss: 117.56733865100372\n",
      "Training epoch 1852...\n",
      "\n",
      "Train Epoch: 1852 [0/8000 (0%)]\tBatch Loss: 937.461199\tLearning Rate (w_theta): 0.001000\t TIME:3378.1s\n",
      "\t\t\t\tDisc: 0.975336\t\tSym: 16.387352\t\tSpars: 920.098511\n",
      "\t TVw: -0.244977 | TVb: -2.043704 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "\n",
      "Train Epoch: 1852 [4000/8000 (50%)]\tBatch Loss: 884.026979\tLearning Rate (w_theta): 0.001000\t TIME:3379.6s\n",
      "\t\t\t\tDisc: 0.874132\t\tSym: 14.493240\t\tSpars: 868.659607\n",
      "\t TVw: -0.244442 | TVb: -2.043702 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "Validating epoch 1852...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 898.8536114130743\n",
      "Average validation loss: 116.05509227769636\n",
      "Training epoch 1853...\n",
      "\n",
      "Train Epoch: 1853 [0/8000 (0%)]\tBatch Loss: 891.640402\tLearning Rate (w_theta): 0.001000\t TIME:3382.0s\n",
      "\t\t\t\tDisc: 0.892946\t\tSym: 14.616475\t\tSpars: 876.130981\n",
      "\t TVw: -0.243895 | TVb: -2.043701 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "\n",
      "Train Epoch: 1853 [4000/8000 (50%)]\tBatch Loss: 887.855093\tLearning Rate (w_theta): 0.001000\t TIME:3383.6s\n",
      "\t\t\t\tDisc: 0.850871\t\tSym: 14.676158\t\tSpars: 872.328064\n",
      "\t TVw: -0.243330 | TVb: -2.043700 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "Validating epoch 1853...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 895.2584941084485\n",
      "Average validation loss: 115.79210192243784\n",
      "Training epoch 1854...\n",
      "\n",
      "Train Epoch: 1854 [0/8000 (0%)]\tBatch Loss: 892.072793\tLearning Rate (w_theta): 0.001000\t TIME:3386.0s\n",
      "\t\t\t\tDisc: 0.878831\t\tSym: 15.355766\t\tSpars: 875.838196\n",
      "\t TVw: -0.242782 | TVb: -2.043700 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "\n",
      "Train Epoch: 1854 [4000/8000 (50%)]\tBatch Loss: 920.640215\tLearning Rate (w_theta): 0.001000\t TIME:3387.5s\n",
      "\t\t\t\tDisc: 0.839208\t\tSym: 15.076154\t\tSpars: 904.724854\n",
      "\t TVw: -0.242226 | TVb: -2.043699 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "Validating epoch 1854...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 894.4126190125266\n",
      "Average validation loss: 115.32714949414182\n",
      "Training epoch 1855...\n",
      "\n",
      "Train Epoch: 1855 [0/8000 (0%)]\tBatch Loss: 933.789175\tLearning Rate (w_theta): 0.001000\t TIME:3390.1s\n",
      "\t\t\t\tDisc: 0.904221\t\tSym: 16.916937\t\tSpars: 915.968018\n",
      "\t TVw: -0.241681 | TVb: -2.043699 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "\n",
      "Train Epoch: 1855 [4000/8000 (50%)]\tBatch Loss: 866.725243\tLearning Rate (w_theta): 0.001000\t TIME:3391.7s\n",
      "\t\t\t\tDisc: 0.729941\t\tSym: 14.270021\t\tSpars: 851.725281\n",
      "\t TVw: -0.241140 | TVb: -2.043699 | GSw: -0.234959 | GSb: 0.065055 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "Validating epoch 1855...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 894.2670715298055\n",
      "Average validation loss: 115.47315566508915\n",
      "Training epoch 1856...\n",
      "\n",
      "Train Epoch: 1856 [0/8000 (0%)]\tBatch Loss: 875.839618\tLearning Rate (w_theta): 0.001000\t TIME:3394.1s\n",
      "\t\t\t\tDisc: 0.849179\t\tSym: 14.393882\t\tSpars: 860.596558\n",
      "\t TVw: -0.240596 | TVb: -2.043700 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "\n",
      "Train Epoch: 1856 [4000/8000 (50%)]\tBatch Loss: 857.222672\tLearning Rate (w_theta): 0.001000\t TIME:3395.6s\n",
      "\t\t\t\tDisc: 0.776590\t\tSym: 13.469520\t\tSpars: 842.976562\n",
      "\t TVw: -0.240052 | TVb: -2.043700 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "Validating epoch 1856...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 892.8560432217217\n",
      "Average validation loss: 115.86421751155127\n",
      "Training epoch 1857...\n",
      "\n",
      "Train Epoch: 1857 [0/8000 (0%)]\tBatch Loss: 864.026539\tLearning Rate (w_theta): 0.001000\t TIME:3398.0s\n",
      "\t\t\t\tDisc: 0.845132\t\tSym: 13.880565\t\tSpars: 849.300842\n",
      "\t TVw: -0.239506 | TVb: -2.043701 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "\n",
      "Train Epoch: 1857 [4000/8000 (50%)]\tBatch Loss: 905.734892\tLearning Rate (w_theta): 0.001000\t TIME:3399.5s\n",
      "\t\t\t\tDisc: 0.969337\t\tSym: 14.838675\t\tSpars: 889.926880\n",
      "\t TVw: -0.238953 | TVb: -2.043700 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "Validating epoch 1857...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 894.6852662797133\n",
      "Average validation loss: 116.46882428297948\n",
      "Training epoch 1858...\n",
      "\n",
      "Train Epoch: 1858 [0/8000 (0%)]\tBatch Loss: 934.946952\tLearning Rate (w_theta): 0.001000\t TIME:3401.9s\n",
      "\t\t\t\tDisc: 0.910821\t\tSym: 17.540709\t\tSpars: 916.495422\n",
      "\t TVw: -0.238403 | TVb: -2.043699 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "\n",
      "Train Epoch: 1858 [4000/8000 (50%)]\tBatch Loss: 904.887111\tLearning Rate (w_theta): 0.001000\t TIME:3403.5s\n",
      "\t\t\t\tDisc: 0.928204\t\tSym: 15.379256\t\tSpars: 888.579651\n",
      "\t TVw: -0.237849 | TVb: -2.043697 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "Validating epoch 1858...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 897.9863176009269\n",
      "Average validation loss: 114.78362705614724\n",
      "Training epoch 1859...\n",
      "\n",
      "Train Epoch: 1859 [0/8000 (0%)]\tBatch Loss: 894.592451\tLearning Rate (w_theta): 0.001000\t TIME:3405.8s\n",
      "\t\t\t\tDisc: 0.863511\t\tSym: 14.516538\t\tSpars: 879.212402\n",
      "\t TVw: -0.237319 | TVb: -2.043696 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "\n",
      "Train Epoch: 1859 [4000/8000 (50%)]\tBatch Loss: 873.813684\tLearning Rate (w_theta): 0.001000\t TIME:3407.4s\n",
      "\t\t\t\tDisc: 0.864170\t\tSym: 13.805409\t\tSpars: 859.144104\n",
      "\t TVw: -0.236795 | TVb: -2.043695 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "Validating epoch 1859...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 899.257918134176\n",
      "Average validation loss: 113.73297598137027\n",
      "Training epoch 1860...\n",
      "\n",
      "Train Epoch: 1860 [0/8000 (0%)]\tBatch Loss: 904.858712\tLearning Rate (w_theta): 0.001000\t TIME:3410.0s\n",
      "\t\t\t\tDisc: 0.910527\t\tSym: 16.043644\t\tSpars: 887.904541\n",
      "\t TVw: -0.236268 | TVb: -2.043695 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "\n",
      "Train Epoch: 1860 [4000/8000 (50%)]\tBatch Loss: 898.061927\tLearning Rate (w_theta): 0.001000\t TIME:3411.6s\n",
      "\t\t\t\tDisc: 0.903325\t\tSym: 15.684847\t\tSpars: 881.473755\n",
      "\t TVw: -0.235736 | TVb: -2.043693 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "Validating epoch 1860...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 900.5404792183225\n",
      "Average validation loss: 117.89691314712809\n",
      "Training epoch 1861...\n",
      "\n",
      "Train Epoch: 1861 [0/8000 (0%)]\tBatch Loss: 913.066021\tLearning Rate (w_theta): 0.001000\t TIME:3414.5s\n",
      "\t\t\t\tDisc: 0.750047\t\tSym: 15.429317\t\tSpars: 896.886658\n",
      "\t TVw: -0.235222 | TVb: -2.043691 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "\n",
      "Train Epoch: 1861 [4000/8000 (50%)]\tBatch Loss: 922.942978\tLearning Rate (w_theta): 0.001000\t TIME:3416.1s\n",
      "\t\t\t\tDisc: 0.885121\t\tSym: 15.911067\t\tSpars: 906.146790\n",
      "\t TVw: -0.234731 | TVb: -2.043691 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "Validating epoch 1861...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 914.7614865035275\n",
      "Average validation loss: 114.23224038238881\n",
      "Training epoch 1862...\n",
      "\n",
      "Train Epoch: 1862 [0/8000 (0%)]\tBatch Loss: 890.539562\tLearning Rate (w_theta): 0.001000\t TIME:3418.4s\n",
      "\t\t\t\tDisc: 0.801694\t\tSym: 15.253493\t\tSpars: 874.484375\n",
      "\t TVw: -0.234249 | TVb: -2.043692 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "\n",
      "Train Epoch: 1862 [4000/8000 (50%)]\tBatch Loss: 883.006448\tLearning Rate (w_theta): 0.001000\t TIME:3420.0s\n",
      "\t\t\t\tDisc: 0.774306\t\tSym: 14.523645\t\tSpars: 867.708496\n",
      "\t TVw: -0.233754 | TVb: -2.043693 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "Validating epoch 1862...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 897.350498138921\n",
      "Average validation loss: 114.98500933823644\n",
      "Training epoch 1863...\n",
      "\n",
      "Train Epoch: 1863 [0/8000 (0%)]\tBatch Loss: 934.158207\tLearning Rate (w_theta): 0.001000\t TIME:3422.5s\n",
      "\t\t\t\tDisc: 0.872107\t\tSym: 16.471952\t\tSpars: 916.814148\n",
      "\t TVw: -0.233226 | TVb: -2.043692 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "\n",
      "Train Epoch: 1863 [4000/8000 (50%)]\tBatch Loss: 891.210062\tLearning Rate (w_theta): 0.001000\t TIME:3424.1s\n",
      "\t\t\t\tDisc: 0.926605\t\tSym: 14.654674\t\tSpars: 875.628784\n",
      "\t TVw: -0.232673 | TVb: -2.043690 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "Validating epoch 1863...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 892.9288243809609\n",
      "Average validation loss: 114.9645911842733\n",
      "Training epoch 1864...\n",
      "\n",
      "Train Epoch: 1864 [0/8000 (0%)]\tBatch Loss: 887.900921\tLearning Rate (w_theta): 0.001000\t TIME:3426.5s\n",
      "\t\t\t\tDisc: 0.871812\t\tSym: 15.030879\t\tSpars: 871.998230\n",
      "\t TVw: -0.232104 | TVb: -2.043688 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "\n",
      "Train Epoch: 1864 [4000/8000 (50%)]\tBatch Loss: 925.315277\tLearning Rate (w_theta): 0.001000\t TIME:3428.0s\n",
      "\t\t\t\tDisc: 0.898060\t\tSym: 15.935405\t\tSpars: 908.481812\n",
      "\t TVw: -0.231523 | TVb: -2.043686 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "Validating epoch 1864...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 890.0419877793643\n",
      "Average validation loss: 114.52360439878093\n",
      "Training epoch 1865...\n",
      "\n",
      "Train Epoch: 1865 [0/8000 (0%)]\tBatch Loss: 905.128820\tLearning Rate (w_theta): 0.001000\t TIME:3430.3s\n",
      "\t\t\t\tDisc: 0.904647\t\tSym: 16.048208\t\tSpars: 888.175964\n",
      "\t TVw: -0.230932 | TVb: -2.043683 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "\n",
      "Train Epoch: 1865 [4000/8000 (50%)]\tBatch Loss: 921.549610\tLearning Rate (w_theta): 0.001000\t TIME:3431.9s\n",
      "\t\t\t\tDisc: 0.843982\t\tSym: 16.033691\t\tSpars: 904.671936\n",
      "\t TVw: -0.230347 | TVb: -2.043681 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "Validating epoch 1865...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 887.8315978687531\n",
      "Average validation loss: 113.52141465803042\n",
      "Training epoch 1866...\n",
      "\n",
      "Train Epoch: 1866 [0/8000 (0%)]\tBatch Loss: 887.279805\tLearning Rate (w_theta): 0.001000\t TIME:3434.2s\n",
      "\t\t\t\tDisc: 0.802035\t\tSym: 16.142931\t\tSpars: 870.334839\n",
      "\t TVw: -0.229775 | TVb: -2.043679 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034779\n",
      "\n",
      "Train Epoch: 1866 [4000/8000 (50%)]\tBatch Loss: 874.533796\tLearning Rate (w_theta): 0.001000\t TIME:3435.7s\n",
      "\t\t\t\tDisc: 0.854440\t\tSym: 14.021520\t\tSpars: 859.657837\n",
      "\t TVw: -0.229196 | TVb: -2.043679 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "Validating epoch 1866...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 887.7969845129511\n",
      "Average validation loss: 112.81995462935744\n",
      "Training epoch 1867...\n",
      "\n",
      "Train Epoch: 1867 [0/8000 (0%)]\tBatch Loss: 888.961017\tLearning Rate (w_theta): 0.001000\t TIME:3438.1s\n",
      "\t\t\t\tDisc: 0.856686\t\tSym: 15.448081\t\tSpars: 872.656250\n",
      "\t TVw: -0.228619 | TVb: -2.043677 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "\n",
      "Train Epoch: 1867 [4000/8000 (50%)]\tBatch Loss: 873.683112\tLearning Rate (w_theta): 0.001000\t TIME:3439.6s\n",
      "\t\t\t\tDisc: 0.816031\t\tSym: 14.525467\t\tSpars: 858.341614\n",
      "\t TVw: -0.228052 | TVb: -2.043676 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "Validating epoch 1867...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 887.3000171505627\n",
      "Average validation loss: 113.08722420770734\n",
      "Training epoch 1868...\n",
      "\n",
      "Train Epoch: 1868 [0/8000 (0%)]\tBatch Loss: 849.080068\tLearning Rate (w_theta): 0.001000\t TIME:3442.0s\n",
      "\t\t\t\tDisc: 0.745146\t\tSym: 12.901328\t\tSpars: 835.433594\n",
      "\t TVw: -0.227491 | TVb: -2.043676 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "\n",
      "Train Epoch: 1868 [4000/8000 (50%)]\tBatch Loss: 855.880389\tLearning Rate (w_theta): 0.001000\t TIME:3443.6s\n",
      "\t\t\t\tDisc: 0.796654\t\tSym: 14.601130\t\tSpars: 840.482605\n",
      "\t TVw: -0.226928 | TVb: -2.043674 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "Validating epoch 1868...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 886.611063786786\n",
      "Average validation loss: 112.88931001302737\n",
      "Training epoch 1869...\n",
      "\n",
      "Train Epoch: 1869 [0/8000 (0%)]\tBatch Loss: 904.839115\tLearning Rate (w_theta): 0.001000\t TIME:3445.9s\n",
      "\t\t\t\tDisc: 0.918555\t\tSym: 16.233915\t\tSpars: 887.686646\n",
      "\t TVw: -0.226359 | TVb: -2.043672 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "\n",
      "Train Epoch: 1869 [4000/8000 (50%)]\tBatch Loss: 919.300250\tLearning Rate (w_theta): 0.001000\t TIME:3447.5s\n",
      "\t\t\t\tDisc: 0.848149\t\tSym: 16.524611\t\tSpars: 901.927490\n",
      "\t TVw: -0.225793 | TVb: -2.043670 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "Validating epoch 1869...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 885.0709984879061\n",
      "Average validation loss: 112.89542108342334\n",
      "Training epoch 1870...\n",
      "\n",
      "Train Epoch: 1870 [0/8000 (0%)]\tBatch Loss: 908.570852\tLearning Rate (w_theta): 0.001000\t TIME:3449.8s\n",
      "\t\t\t\tDisc: 0.892228\t\tSym: 15.705968\t\tSpars: 891.972656\n",
      "\t TVw: -0.225231 | TVb: -2.043669 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "\n",
      "Train Epoch: 1870 [4000/8000 (50%)]\tBatch Loss: 873.401370\tLearning Rate (w_theta): 0.001000\t TIME:3451.4s\n",
      "\t\t\t\tDisc: 0.872076\t\tSym: 14.717649\t\tSpars: 857.811646\n",
      "\t TVw: -0.224676 | TVb: -2.043669 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "Validating epoch 1870...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 884.2045777344103\n",
      "Average validation loss: 111.96489277336514\n",
      "Training epoch 1871...\n",
      "\n",
      "Train Epoch: 1871 [0/8000 (0%)]\tBatch Loss: 896.027215\tLearning Rate (w_theta): 0.001000\t TIME:3454.7s\n",
      "\t\t\t\tDisc: 0.852785\t\tSym: 14.679618\t\tSpars: 880.494812\n",
      "\t TVw: -0.224108 | TVb: -2.043668 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "\n",
      "Train Epoch: 1871 [4000/8000 (50%)]\tBatch Loss: 861.682274\tLearning Rate (w_theta): 0.001000\t TIME:3456.2s\n",
      "\t\t\t\tDisc: 0.799927\t\tSym: 14.040550\t\tSpars: 846.841797\n",
      "\t TVw: -0.223533 | TVb: -2.043667 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "Validating epoch 1871...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 883.5553983704078\n",
      "Average validation loss: 112.46334823291373\n",
      "Training epoch 1872...\n",
      "\n",
      "Train Epoch: 1872 [0/8000 (0%)]\tBatch Loss: 866.109440\tLearning Rate (w_theta): 0.001000\t TIME:3458.6s\n",
      "\t\t\t\tDisc: 0.788281\t\tSym: 13.528618\t\tSpars: 851.792542\n",
      "\t TVw: -0.222962 | TVb: -2.043665 | GSw: -0.234959 | GSb: 0.065054 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "\n",
      "Train Epoch: 1872 [4000/8000 (50%)]\tBatch Loss: 910.298490\tLearning Rate (w_theta): 0.001000\t TIME:3460.2s\n",
      "\t\t\t\tDisc: 0.792520\t\tSym: 16.115101\t\tSpars: 893.390869\n",
      "\t TVw: -0.222389 | TVb: -2.043663 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "Validating epoch 1872...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 885.4423474101154\n",
      "Average validation loss: 111.56825865068058\n",
      "Training epoch 1873...\n",
      "\n",
      "Train Epoch: 1873 [0/8000 (0%)]\tBatch Loss: 860.766806\tLearning Rate (w_theta): 0.001000\t TIME:3462.5s\n",
      "\t\t\t\tDisc: 0.825214\t\tSym: 14.262332\t\tSpars: 845.679260\n",
      "\t TVw: -0.221819 | TVb: -2.043661 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "\n",
      "Train Epoch: 1873 [4000/8000 (50%)]\tBatch Loss: 891.676719\tLearning Rate (w_theta): 0.001000\t TIME:3464.1s\n",
      "\t\t\t\tDisc: 0.909607\t\tSym: 15.949363\t\tSpars: 874.817749\n",
      "\t TVw: -0.221250 | TVb: -2.043658 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "Validating epoch 1873...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 884.9086816029098\n",
      "Average validation loss: 110.88594870725161\n",
      "Training epoch 1874...\n",
      "\n",
      "Train Epoch: 1874 [0/8000 (0%)]\tBatch Loss: 888.083789\tLearning Rate (w_theta): 0.001000\t TIME:3466.4s\n",
      "\t\t\t\tDisc: 0.866852\t\tSym: 15.234637\t\tSpars: 871.982300\n",
      "\t TVw: -0.220695 | TVb: -2.043656 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "\n",
      "Train Epoch: 1874 [4000/8000 (50%)]\tBatch Loss: 896.731020\tLearning Rate (w_theta): 0.001000\t TIME:3468.0s\n",
      "\t\t\t\tDisc: 0.847936\t\tSym: 15.430936\t\tSpars: 880.452148\n",
      "\t TVw: -0.220138 | TVb: -2.043655 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "Validating epoch 1874...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 883.062237485656\n",
      "Average validation loss: 110.58751154670215\n",
      "Training epoch 1875...\n",
      "\n",
      "Train Epoch: 1875 [0/8000 (0%)]\tBatch Loss: 858.376458\tLearning Rate (w_theta): 0.001000\t TIME:3470.3s\n",
      "\t\t\t\tDisc: 0.720859\t\tSym: 12.933125\t\tSpars: 844.722473\n",
      "\t TVw: -0.219586 | TVb: -2.043654 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "\n",
      "Train Epoch: 1875 [4000/8000 (50%)]\tBatch Loss: 929.086873\tLearning Rate (w_theta): 0.001000\t TIME:3471.9s\n",
      "\t\t\t\tDisc: 0.967528\t\tSym: 16.930441\t\tSpars: 911.188904\n",
      "\t TVw: -0.219026 | TVb: -2.043652 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "Validating epoch 1875...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 885.2994923660438\n",
      "Average validation loss: 111.4754784191243\n",
      "Training epoch 1876...\n",
      "\n",
      "Train Epoch: 1876 [0/8000 (0%)]\tBatch Loss: 859.977774\tLearning Rate (w_theta): 0.001000\t TIME:3474.3s\n",
      "\t\t\t\tDisc: 0.828350\t\tSym: 14.609201\t\tSpars: 844.540222\n",
      "\t TVw: -0.218469 | TVb: -2.043650 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "\n",
      "Train Epoch: 1876 [4000/8000 (50%)]\tBatch Loss: 900.325722\tLearning Rate (w_theta): 0.001000\t TIME:3475.8s\n",
      "\t\t\t\tDisc: 0.800603\t\tSym: 15.579074\t\tSpars: 883.946045\n",
      "\t TVw: -0.217920 | TVb: -2.043649 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "Validating epoch 1876...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 884.9941899198476\n",
      "Average validation loss: 109.03826271164841\n",
      "Training epoch 1877...\n",
      "\n",
      "Train Epoch: 1877 [0/8000 (0%)]\tBatch Loss: 917.392508\tLearning Rate (w_theta): 0.001000\t TIME:3478.2s\n",
      "\t\t\t\tDisc: 0.890115\t\tSym: 15.478345\t\tSpars: 901.024048\n",
      "\t TVw: -0.217369 | TVb: -2.043647 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "\n",
      "Train Epoch: 1877 [4000/8000 (50%)]\tBatch Loss: 884.713563\tLearning Rate (w_theta): 0.001000\t TIME:3479.7s\n",
      "\t\t\t\tDisc: 0.855308\t\tSym: 14.442972\t\tSpars: 869.415283\n",
      "\t TVw: -0.216815 | TVb: -2.043644 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "Validating epoch 1877...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 885.0369292269186\n",
      "Average validation loss: 110.78947902472535\n",
      "Training epoch 1878...\n",
      "\n",
      "Train Epoch: 1878 [0/8000 (0%)]\tBatch Loss: 884.304632\tLearning Rate (w_theta): 0.001000\t TIME:3482.1s\n",
      "\t\t\t\tDisc: 0.882458\t\tSym: 13.949640\t\tSpars: 869.472534\n",
      "\t TVw: -0.216257 | TVb: -2.043642 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "\n",
      "Train Epoch: 1878 [4000/8000 (50%)]\tBatch Loss: 860.246143\tLearning Rate (w_theta): 0.001000\t TIME:3483.6s\n",
      "\t\t\t\tDisc: 0.734300\t\tSym: 14.351077\t\tSpars: 845.160767\n",
      "\t TVw: -0.215718 | TVb: -2.043641 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "Validating epoch 1878...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 880.1699851558469\n",
      "Average validation loss: 110.30023838971198\n",
      "Training epoch 1879...\n",
      "\n",
      "Train Epoch: 1879 [0/8000 (0%)]\tBatch Loss: 854.435721\tLearning Rate (w_theta): 0.001000\t TIME:3486.0s\n",
      "\t\t\t\tDisc: 0.765863\t\tSym: 13.266232\t\tSpars: 840.403625\n",
      "\t TVw: -0.215156 | TVb: -2.043640 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "\n",
      "Train Epoch: 1879 [4000/8000 (50%)]\tBatch Loss: 918.533481\tLearning Rate (w_theta): 0.001000\t TIME:3487.5s\n",
      "\t\t\t\tDisc: 0.871357\t\tSym: 15.579970\t\tSpars: 902.082153\n",
      "\t TVw: -0.214591 | TVb: -2.043638 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "Validating epoch 1879...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 882.2326800889339\n",
      "Average validation loss: 109.2936534927539\n",
      "Training epoch 1880...\n",
      "\n",
      "Train Epoch: 1880 [0/8000 (0%)]\tBatch Loss: 914.009364\tLearning Rate (w_theta): 0.001000\t TIME:3489.9s\n",
      "\t\t\t\tDisc: 0.887734\t\tSym: 16.845446\t\tSpars: 896.276184\n",
      "\t TVw: -0.214028 | TVb: -2.043636 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "\n",
      "Train Epoch: 1880 [4000/8000 (50%)]\tBatch Loss: 893.492722\tLearning Rate (w_theta): 0.001000\t TIME:3491.5s\n",
      "\t\t\t\tDisc: 0.845404\t\tSym: 15.791178\t\tSpars: 876.856140\n",
      "\t TVw: -0.213463 | TVb: -2.043635 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "Validating epoch 1880...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 880.0063758369174\n",
      "Average validation loss: 110.94869677905594\n",
      "Training epoch 1881...\n",
      "\n",
      "Train Epoch: 1881 [0/8000 (0%)]\tBatch Loss: 909.428276\tLearning Rate (w_theta): 0.001000\t TIME:3494.7s\n",
      "\t\t\t\tDisc: 1.017344\t\tSym: 17.342024\t\tSpars: 891.068909\n",
      "\t TVw: -0.212893 | TVb: -2.043634 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "\n",
      "Train Epoch: 1881 [4000/8000 (50%)]\tBatch Loss: 882.895150\tLearning Rate (w_theta): 0.001000\t TIME:3496.3s\n",
      "\t\t\t\tDisc: 0.839460\t\tSym: 15.356471\t\tSpars: 866.699219\n",
      "\t TVw: -0.212314 | TVb: -2.043632 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "Validating epoch 1881...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 882.4036853585297\n",
      "Average validation loss: 109.68572582096807\n",
      "Training epoch 1882...\n",
      "\n",
      "Train Epoch: 1882 [0/8000 (0%)]\tBatch Loss: 893.911612\tLearning Rate (w_theta): 0.001000\t TIME:3498.6s\n",
      "\t\t\t\tDisc: 0.835944\t\tSym: 15.365891\t\tSpars: 877.709778\n",
      "\t TVw: -0.211741 | TVb: -2.043631 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "\n",
      "Train Epoch: 1882 [4000/8000 (50%)]\tBatch Loss: 888.801724\tLearning Rate (w_theta): 0.001000\t TIME:3500.2s\n",
      "\t\t\t\tDisc: 0.888732\t\tSym: 14.273709\t\tSpars: 873.639282\n",
      "\t TVw: -0.211156 | TVb: -2.043629 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "Validating epoch 1882...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 879.6109109049161\n",
      "Average validation loss: 108.24665796610513\n",
      "Training epoch 1883...\n",
      "\n",
      "Train Epoch: 1883 [0/8000 (0%)]\tBatch Loss: 919.590216\tLearning Rate (w_theta): 0.001000\t TIME:3502.5s\n",
      "\t\t\t\tDisc: 0.887103\t\tSym: 16.975330\t\tSpars: 901.727783\n",
      "\t TVw: -0.210555 | TVb: -2.043626 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034780\n",
      "\n",
      "Train Epoch: 1883 [4000/8000 (50%)]\tBatch Loss: 847.699345\tLearning Rate (w_theta): 0.001000\t TIME:3504.1s\n",
      "\t\t\t\tDisc: 0.815608\t\tSym: 13.349314\t\tSpars: 833.534424\n",
      "\t TVw: -0.209956 | TVb: -2.043624 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "Validating epoch 1883...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 879.0743014549421\n",
      "Average validation loss: 109.33567249806184\n",
      "Training epoch 1884...\n",
      "\n",
      "Train Epoch: 1884 [0/8000 (0%)]\tBatch Loss: 882.713008\tLearning Rate (w_theta): 0.001000\t TIME:3506.5s\n",
      "\t\t\t\tDisc: 0.865407\t\tSym: 16.069281\t\tSpars: 865.778320\n",
      "\t TVw: -0.209380 | TVb: -2.043623 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "\n",
      "Train Epoch: 1884 [4000/8000 (50%)]\tBatch Loss: 868.696248\tLearning Rate (w_theta): 0.001000\t TIME:3508.0s\n",
      "\t\t\t\tDisc: 0.838927\t\tSym: 13.757407\t\tSpars: 854.099915\n",
      "\t TVw: -0.208805 | TVb: -2.043622 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "Validating epoch 1884...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 877.2243598490699\n",
      "Average validation loss: 107.5645789013712\n",
      "Training epoch 1885...\n",
      "\n",
      "Train Epoch: 1885 [0/8000 (0%)]\tBatch Loss: 893.633093\tLearning Rate (w_theta): 0.001000\t TIME:3510.4s\n",
      "\t\t\t\tDisc: 0.848163\t\tSym: 15.972003\t\tSpars: 876.812927\n",
      "\t TVw: -0.208231 | TVb: -2.043622 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "\n",
      "Train Epoch: 1885 [4000/8000 (50%)]\tBatch Loss: 892.127944\tLearning Rate (w_theta): 0.001000\t TIME:3511.9s\n",
      "\t\t\t\tDisc: 0.931411\t\tSym: 14.556396\t\tSpars: 876.640137\n",
      "\t TVw: -0.207642 | TVb: -2.043619 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "Validating epoch 1885...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 879.8208076046267\n",
      "Average validation loss: 108.31422560114558\n",
      "Training epoch 1886...\n",
      "\n",
      "Train Epoch: 1886 [0/8000 (0%)]\tBatch Loss: 903.981797\tLearning Rate (w_theta): 0.001000\t TIME:3514.3s\n",
      "\t\t\t\tDisc: 0.854064\t\tSym: 16.201342\t\tSpars: 886.926392\n",
      "\t TVw: -0.207062 | TVb: -2.043616 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "\n",
      "Train Epoch: 1886 [4000/8000 (50%)]\tBatch Loss: 874.914768\tLearning Rate (w_theta): 0.001000\t TIME:3515.8s\n",
      "\t\t\t\tDisc: 0.870862\t\tSym: 14.811301\t\tSpars: 859.232605\n",
      "\t TVw: -0.206482 | TVb: -2.043614 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "Validating epoch 1886...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 876.1987459692918\n",
      "Average validation loss: 107.56318319807745\n",
      "Training epoch 1887...\n",
      "\n",
      "Train Epoch: 1887 [0/8000 (0%)]\tBatch Loss: 865.965647\tLearning Rate (w_theta): 0.001000\t TIME:3518.2s\n",
      "\t\t\t\tDisc: 0.825571\t\tSym: 14.800110\t\tSpars: 850.339966\n",
      "\t TVw: -0.205894 | TVb: -2.043612 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "\n",
      "Train Epoch: 1887 [4000/8000 (50%)]\tBatch Loss: 873.933550\tLearning Rate (w_theta): 0.001000\t TIME:3519.7s\n",
      "\t\t\t\tDisc: 0.835994\t\tSym: 15.257468\t\tSpars: 857.840088\n",
      "\t TVw: -0.205313 | TVb: -2.043611 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "Validating epoch 1887...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 873.315798220451\n",
      "Average validation loss: 108.05565079089983\n",
      "Training epoch 1888...\n",
      "\n",
      "Train Epoch: 1888 [0/8000 (0%)]\tBatch Loss: 916.857734\tLearning Rate (w_theta): 0.001000\t TIME:3522.2s\n",
      "\t\t\t\tDisc: 0.917104\t\tSym: 17.951555\t\tSpars: 897.989075\n",
      "\t TVw: -0.204729 | TVb: -2.043609 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "\n",
      "Train Epoch: 1888 [4000/8000 (50%)]\tBatch Loss: 886.057230\tLearning Rate (w_theta): 0.001000\t TIME:3523.7s\n",
      "\t\t\t\tDisc: 0.869578\t\tSym: 15.854950\t\tSpars: 869.332703\n",
      "\t TVw: -0.204142 | TVb: -2.043608 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "Validating epoch 1888...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 874.076021134704\n",
      "Average validation loss: 106.69995447046793\n",
      "Training epoch 1889...\n",
      "\n",
      "Train Epoch: 1889 [0/8000 (0%)]\tBatch Loss: 889.889393\tLearning Rate (w_theta): 0.001000\t TIME:3526.1s\n",
      "\t\t\t\tDisc: 0.806681\t\tSym: 15.981882\t\tSpars: 873.100830\n",
      "\t TVw: -0.203554 | TVb: -2.043608 | GSw: -0.234959 | GSb: 0.065053 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "\n",
      "Train Epoch: 1889 [4000/8000 (50%)]\tBatch Loss: 841.810193\tLearning Rate (w_theta): 0.001000\t TIME:3527.6s\n",
      "\t\t\t\tDisc: 0.802393\t\tSym: 13.950610\t\tSpars: 827.057190\n",
      "\t TVw: -0.202969 | TVb: -2.043607 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "Validating epoch 1889...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 876.6296280455042\n",
      "Average validation loss: 107.92091445841262\n",
      "Training epoch 1890...\n",
      "\n",
      "Train Epoch: 1890 [0/8000 (0%)]\tBatch Loss: 854.378115\tLearning Rate (w_theta): 0.001000\t TIME:3530.2s\n",
      "\t\t\t\tDisc: 0.829043\t\tSym: 13.887694\t\tSpars: 839.661377\n",
      "\t TVw: -0.202379 | TVb: -2.043604 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "\n",
      "Train Epoch: 1890 [4000/8000 (50%)]\tBatch Loss: 821.095978\tLearning Rate (w_theta): 0.001000\t TIME:3531.8s\n",
      "\t\t\t\tDisc: 0.743388\t\tSym: 12.878285\t\tSpars: 807.474304\n",
      "\t TVw: -0.201790 | TVb: -2.043603 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "Validating epoch 1890...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 871.4478460181313\n",
      "Average validation loss: 106.61871910033014\n",
      "Training epoch 1891...\n",
      "\n",
      "Train Epoch: 1891 [0/8000 (0%)]\tBatch Loss: 848.300296\tLearning Rate (w_theta): 0.001000\t TIME:3534.8s\n",
      "\t\t\t\tDisc: 0.790393\t\tSym: 14.480423\t\tSpars: 833.029480\n",
      "\t TVw: -0.201206 | TVb: -2.043602 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "\n",
      "Train Epoch: 1891 [4000/8000 (50%)]\tBatch Loss: 895.073466\tLearning Rate (w_theta): 0.001000\t TIME:3536.3s\n",
      "\t\t\t\tDisc: 0.892591\t\tSym: 15.563199\t\tSpars: 878.617676\n",
      "\t TVw: -0.200612 | TVb: -2.043601 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "Validating epoch 1891...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 874.9088558988947\n",
      "Average validation loss: 107.54156430185573\n",
      "Training epoch 1892...\n",
      "\n",
      "Train Epoch: 1892 [0/8000 (0%)]\tBatch Loss: 877.361640\tLearning Rate (w_theta): 0.001000\t TIME:3538.7s\n",
      "\t\t\t\tDisc: 0.904530\t\tSym: 14.842974\t\tSpars: 861.614136\n",
      "\t TVw: -0.200011 | TVb: -2.043598 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "\n",
      "Train Epoch: 1892 [4000/8000 (50%)]\tBatch Loss: 869.469534\tLearning Rate (w_theta): 0.001000\t TIME:3540.3s\n",
      "\t\t\t\tDisc: 0.735130\t\tSym: 13.820220\t\tSpars: 854.914185\n",
      "\t TVw: -0.199429 | TVb: -2.043596 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "Validating epoch 1892...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 879.7541188525707\n",
      "Average validation loss: 105.82957958218019\n",
      "Training epoch 1893...\n",
      "\n",
      "Train Epoch: 1893 [0/8000 (0%)]\tBatch Loss: 895.388095\tLearning Rate (w_theta): 0.001000\t TIME:3542.6s\n",
      "\t\t\t\tDisc: 0.892213\t\tSym: 15.367891\t\tSpars: 879.127991\n",
      "\t TVw: -0.198870 | TVb: -2.043595 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "\n",
      "Train Epoch: 1893 [4000/8000 (50%)]\tBatch Loss: 875.018242\tLearning Rate (w_theta): 0.001000\t TIME:3544.2s\n",
      "\t\t\t\tDisc: 0.873879\t\tSym: 14.674942\t\tSpars: 859.469421\n",
      "\t TVw: -0.198295 | TVb: -2.043592 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "Validating epoch 1893...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 878.7738036824956\n",
      "Average validation loss: 106.85809289741692\n",
      "Training epoch 1894...\n",
      "\n",
      "Train Epoch: 1894 [0/8000 (0%)]\tBatch Loss: 844.946712\tLearning Rate (w_theta): 0.001000\t TIME:3546.5s\n",
      "\t\t\t\tDisc: 0.745465\t\tSym: 13.993545\t\tSpars: 830.207703\n",
      "\t TVw: -0.197729 | TVb: -2.043589 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "\n",
      "Train Epoch: 1894 [4000/8000 (50%)]\tBatch Loss: 864.454201\tLearning Rate (w_theta): 0.001000\t TIME:3548.1s\n",
      "\t\t\t\tDisc: 0.888311\t\tSym: 14.431247\t\tSpars: 849.134644\n",
      "\t TVw: -0.197171 | TVb: -2.043587 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "Validating epoch 1894...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 870.5457908037905\n",
      "Average validation loss: 105.26851322096702\n",
      "Training epoch 1895...\n",
      "\n",
      "Train Epoch: 1895 [0/8000 (0%)]\tBatch Loss: 876.573181\tLearning Rate (w_theta): 0.001000\t TIME:3550.4s\n",
      "\t\t\t\tDisc: 0.860883\t\tSym: 15.204363\t\tSpars: 860.507935\n",
      "\t TVw: -0.196604 | TVb: -2.043586 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "\n",
      "Train Epoch: 1895 [4000/8000 (50%)]\tBatch Loss: 870.074874\tLearning Rate (w_theta): 0.001000\t TIME:3552.0s\n",
      "\t\t\t\tDisc: 0.773912\t\tSym: 14.739804\t\tSpars: 854.561157\n",
      "\t TVw: -0.196014 | TVb: -2.043584 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "Validating epoch 1895...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 868.5254247163169\n",
      "Average validation loss: 106.47129742484124\n",
      "Training epoch 1896...\n",
      "\n",
      "Train Epoch: 1896 [0/8000 (0%)]\tBatch Loss: 916.860442\tLearning Rate (w_theta): 0.001000\t TIME:3554.3s\n",
      "\t\t\t\tDisc: 0.880237\t\tSym: 17.074078\t\tSpars: 898.906128\n",
      "\t TVw: -0.195417 | TVb: -2.043583 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "\n",
      "Train Epoch: 1896 [4000/8000 (50%)]\tBatch Loss: 897.481239\tLearning Rate (w_theta): 0.001000\t TIME:3555.9s\n",
      "\t\t\t\tDisc: 0.876295\t\tSym: 15.625147\t\tSpars: 880.979797\n",
      "\t TVw: -0.194813 | TVb: -2.043582 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "Validating epoch 1896...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 867.4094717631586\n",
      "Average validation loss: 106.42574433250405\n",
      "Training epoch 1897...\n",
      "\n",
      "Train Epoch: 1897 [0/8000 (0%)]\tBatch Loss: 851.140845\tLearning Rate (w_theta): 0.001000\t TIME:3558.2s\n",
      "\t\t\t\tDisc: 0.814800\t\tSym: 13.654780\t\tSpars: 836.671265\n",
      "\t TVw: -0.194206 | TVb: -2.043581 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "\n",
      "Train Epoch: 1897 [4000/8000 (50%)]\tBatch Loss: 838.544864\tLearning Rate (w_theta): 0.001000\t TIME:3559.8s\n",
      "\t\t\t\tDisc: 0.668895\t\tSym: 12.985283\t\tSpars: 824.890686\n",
      "\t TVw: -0.193583 | TVb: -2.043579 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "Validating epoch 1897...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 867.4147214847003\n",
      "Average validation loss: 104.8380785867356\n",
      "Training epoch 1898...\n",
      "\n",
      "Train Epoch: 1898 [0/8000 (0%)]\tBatch Loss: 916.171609\tLearning Rate (w_theta): 0.001000\t TIME:3562.4s\n",
      "\t\t\t\tDisc: 0.956510\t\tSym: 16.773388\t\tSpars: 898.441711\n",
      "\t TVw: -0.192959 | TVb: -2.043577 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "\n",
      "Train Epoch: 1898 [4000/8000 (50%)]\tBatch Loss: 922.232280\tLearning Rate (w_theta): 0.001000\t TIME:3563.9s\n",
      "\t\t\t\tDisc: 1.027739\t\tSym: 16.923901\t\tSpars: 904.280640\n",
      "\t TVw: -0.192339 | TVb: -2.043573 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "Validating epoch 1898...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 871.3703252037062\n",
      "Average validation loss: 105.76124136330459\n",
      "Training epoch 1899...\n",
      "\n",
      "Train Epoch: 1899 [0/8000 (0%)]\tBatch Loss: 875.663618\tLearning Rate (w_theta): 0.001000\t TIME:3566.3s\n",
      "\t\t\t\tDisc: 0.856724\t\tSym: 15.150156\t\tSpars: 859.656738\n",
      "\t TVw: -0.191724 | TVb: -2.043569 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "\n",
      "Train Epoch: 1899 [4000/8000 (50%)]\tBatch Loss: 889.871625\tLearning Rate (w_theta): 0.001000\t TIME:3567.8s\n",
      "\t\t\t\tDisc: 0.819389\t\tSym: 14.996388\t\tSpars: 874.055847\n",
      "\t TVw: -0.191152 | TVb: -2.043567 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034781\n",
      "Validating epoch 1899...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 883.0809007267073\n",
      "Average validation loss: 103.80394064085577\n",
      "Training epoch 1900...\n",
      "\n",
      "Train Epoch: 1900 [0/8000 (0%)]\tBatch Loss: 890.491941\tLearning Rate (w_theta): 0.001000\t TIME:3570.2s\n",
      "\t\t\t\tDisc: 0.804129\t\tSym: 15.105353\t\tSpars: 874.582458\n",
      "\t TVw: -0.190616 | TVb: -2.043567 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "\n",
      "Train Epoch: 1900 [4000/8000 (50%)]\tBatch Loss: 890.582992\tLearning Rate (w_theta): 0.001000\t TIME:3571.8s\n",
      "\t\t\t\tDisc: 0.872521\t\tSym: 15.957419\t\tSpars: 873.753052\n",
      "\t TVw: -0.190056 | TVb: -2.043565 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "Validating epoch 1900...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 882.891680581461\n",
      "Average validation loss: 105.98173257990999\n",
      "Training epoch 1901...\n",
      "\n",
      "Train Epoch: 1901 [0/8000 (0%)]\tBatch Loss: 853.656813\tLearning Rate (w_theta): 0.001000\t TIME:3574.7s\n",
      "\t\t\t\tDisc: 0.859500\t\tSym: 13.893992\t\tSpars: 838.903320\n",
      "\t TVw: -0.189497 | TVb: -2.043564 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "\n",
      "Train Epoch: 1901 [4000/8000 (50%)]\tBatch Loss: 896.110529\tLearning Rate (w_theta): 0.001000\t TIME:3576.3s\n",
      "\t\t\t\tDisc: 0.765719\t\tSym: 15.217002\t\tSpars: 880.127808\n",
      "\t TVw: -0.188922 | TVb: -2.043563 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "Validating epoch 1901...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 878.327568219517\n",
      "Average validation loss: 106.66737574342102\n",
      "Training epoch 1902...\n",
      "\n",
      "Train Epoch: 1902 [0/8000 (0%)]\tBatch Loss: 893.232140\tLearning Rate (w_theta): 0.001000\t TIME:3578.7s\n",
      "\t\t\t\tDisc: 0.866242\t\tSym: 15.252739\t\tSpars: 877.113159\n",
      "\t TVw: -0.188328 | TVb: -2.043561 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "\n",
      "Train Epoch: 1902 [4000/8000 (50%)]\tBatch Loss: 899.321752\tLearning Rate (w_theta): 0.001000\t TIME:3580.2s\n",
      "\t\t\t\tDisc: 0.892615\t\tSym: 16.357664\t\tSpars: 882.071472\n",
      "\t TVw: -0.187713 | TVb: -2.043558 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "Validating epoch 1902...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 871.9185429063417\n",
      "Average validation loss: 104.54673974388962\n",
      "Training epoch 1903...\n",
      "\n",
      "Train Epoch: 1903 [0/8000 (0%)]\tBatch Loss: 857.255526\tLearning Rate (w_theta): 0.001000\t TIME:3582.6s\n",
      "\t\t\t\tDisc: 0.748614\t\tSym: 14.028518\t\tSpars: 842.478394\n",
      "\t TVw: -0.187100 | TVb: -2.043555 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "\n",
      "Train Epoch: 1903 [4000/8000 (50%)]\tBatch Loss: 858.314199\tLearning Rate (w_theta): 0.001000\t TIME:3584.1s\n",
      "\t\t\t\tDisc: 0.828807\t\tSym: 13.577250\t\tSpars: 843.908142\n",
      "\t TVw: -0.186487 | TVb: -2.043552 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "Validating epoch 1903...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 866.0150814134115\n",
      "Average validation loss: 103.97629377675334\n",
      "Training epoch 1904...\n",
      "\n",
      "Train Epoch: 1904 [0/8000 (0%)]\tBatch Loss: 852.455173\tLearning Rate (w_theta): 0.001000\t TIME:3586.5s\n",
      "\t\t\t\tDisc: 0.757651\t\tSym: 14.118909\t\tSpars: 837.578613\n",
      "\t TVw: -0.185859 | TVb: -2.043550 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "\n",
      "Train Epoch: 1904 [4000/8000 (50%)]\tBatch Loss: 853.658896\tLearning Rate (w_theta): 0.001000\t TIME:3588.0s\n",
      "\t\t\t\tDisc: 0.790799\t\tSym: 13.958918\t\tSpars: 838.909180\n",
      "\t TVw: -0.185224 | TVb: -2.043547 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "Validating epoch 1904...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 862.5221991156575\n",
      "Average validation loss: 103.8382474177832\n",
      "Training epoch 1905...\n",
      "\n",
      "Train Epoch: 1905 [0/8000 (0%)]\tBatch Loss: 822.246685\tLearning Rate (w_theta): 0.001000\t TIME:3590.4s\n",
      "\t\t\t\tDisc: 0.687974\t\tSym: 13.416438\t\tSpars: 808.142273\n",
      "\t TVw: -0.184585 | TVb: -2.043544 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "\n",
      "Train Epoch: 1905 [4000/8000 (50%)]\tBatch Loss: 851.414289\tLearning Rate (w_theta): 0.001000\t TIME:3591.9s\n",
      "\t\t\t\tDisc: 0.786095\t\tSym: 13.811116\t\tSpars: 836.817078\n",
      "\t TVw: -0.183942 | TVb: -2.043542 | GSw: -0.234959 | GSb: 0.065052 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "Validating epoch 1905...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 862.6852557026081\n",
      "Average validation loss: 104.17890990720826\n",
      "Training epoch 1906...\n",
      "\n",
      "Train Epoch: 1906 [0/8000 (0%)]\tBatch Loss: 896.840963\tLearning Rate (w_theta): 0.001000\t TIME:3594.3s\n",
      "\t\t\t\tDisc: 0.895111\t\tSym: 17.200186\t\tSpars: 878.745667\n",
      "\t TVw: -0.183298 | TVb: -2.043539 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "\n",
      "Train Epoch: 1906 [4000/8000 (50%)]\tBatch Loss: 872.246475\tLearning Rate (w_theta): 0.001000\t TIME:3595.8s\n",
      "\t\t\t\tDisc: 0.799329\t\tSym: 15.354189\t\tSpars: 856.092957\n",
      "\t TVw: -0.182669 | TVb: -2.043537 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "Validating epoch 1906...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 861.046849575804\n",
      "Average validation loss: 103.10015871075281\n",
      "Training epoch 1907...\n",
      "\n",
      "Train Epoch: 1907 [0/8000 (0%)]\tBatch Loss: 840.637549\tLearning Rate (w_theta): 0.001000\t TIME:3598.5s\n",
      "\t\t\t\tDisc: 0.790312\t\tSym: 14.847542\t\tSpars: 824.999695\n",
      "\t TVw: -0.182042 | TVb: -2.043535 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "\n",
      "Train Epoch: 1907 [4000/8000 (50%)]\tBatch Loss: 865.878826\tLearning Rate (w_theta): 0.001000\t TIME:3600.0s\n",
      "\t\t\t\tDisc: 0.859170\t\tSym: 14.717226\t\tSpars: 850.302429\n",
      "\t TVw: -0.181424 | TVb: -2.043533 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "Validating epoch 1907...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 862.4191536487536\n",
      "Average validation loss: 103.05998054073832\n",
      "Training epoch 1908...\n",
      "\n",
      "Train Epoch: 1908 [0/8000 (0%)]\tBatch Loss: 857.801631\tLearning Rate (w_theta): 0.001000\t TIME:3602.4s\n",
      "\t\t\t\tDisc: 0.859643\t\tSym: 14.708162\t\tSpars: 842.233826\n",
      "\t TVw: -0.180807 | TVb: -2.043530 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "\n",
      "Train Epoch: 1908 [4000/8000 (50%)]\tBatch Loss: 859.738031\tLearning Rate (w_theta): 0.001000\t TIME:3603.9s\n",
      "\t\t\t\tDisc: 0.805101\t\tSym: 15.279182\t\tSpars: 843.653748\n",
      "\t TVw: -0.180193 | TVb: -2.043528 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "Validating epoch 1908...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 859.9468521450685\n",
      "Average validation loss: 102.05907898641951\n",
      "Training epoch 1909...\n",
      "\n",
      "Train Epoch: 1909 [0/8000 (0%)]\tBatch Loss: 874.059328\tLearning Rate (w_theta): 0.001000\t TIME:3606.3s\n",
      "\t\t\t\tDisc: 0.809497\t\tSym: 15.536880\t\tSpars: 857.712952\n",
      "\t TVw: -0.179581 | TVb: -2.043525 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "\n",
      "Train Epoch: 1909 [4000/8000 (50%)]\tBatch Loss: 845.256411\tLearning Rate (w_theta): 0.001000\t TIME:3607.8s\n",
      "\t\t\t\tDisc: 0.758331\t\tSym: 14.355380\t\tSpars: 830.142700\n",
      "\t TVw: -0.178972 | TVb: -2.043523 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "Validating epoch 1909...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 860.2973601437625\n",
      "Average validation loss: 102.02830671699412\n",
      "Training epoch 1910...\n",
      "\n",
      "Train Epoch: 1910 [0/8000 (0%)]\tBatch Loss: 851.696565\tLearning Rate (w_theta): 0.001000\t TIME:3610.2s\n",
      "\t\t\t\tDisc: 0.780379\t\tSym: 13.588305\t\tSpars: 837.327881\n",
      "\t TVw: -0.178350 | TVb: -2.043520 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "\n",
      "Train Epoch: 1910 [4000/8000 (50%)]\tBatch Loss: 857.123902\tLearning Rate (w_theta): 0.001000\t TIME:3611.7s\n",
      "\t\t\t\tDisc: 0.745919\t\tSym: 14.805412\t\tSpars: 841.572571\n",
      "\t TVw: -0.177727 | TVb: -2.043517 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "Validating epoch 1910...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 860.3281244454425\n",
      "Average validation loss: 100.99449518284746\n",
      "Training epoch 1911...\n",
      "\n",
      "Train Epoch: 1911 [0/8000 (0%)]\tBatch Loss: 904.353494\tLearning Rate (w_theta): 0.001000\t TIME:3614.7s\n",
      "\t\t\t\tDisc: 0.817958\t\tSym: 16.580458\t\tSpars: 886.955078\n",
      "\t TVw: -0.177126 | TVb: -2.043515 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "\n",
      "Train Epoch: 1911 [4000/8000 (50%)]\tBatch Loss: 853.842590\tLearning Rate (w_theta): 0.001000\t TIME:3616.3s\n",
      "\t\t\t\tDisc: 0.777861\t\tSym: 14.838045\t\tSpars: 838.226685\n",
      "\t TVw: -0.176524 | TVb: -2.043512 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "Validating epoch 1911...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 860.3253093574173\n",
      "Average validation loss: 101.26896489089172\n",
      "Training epoch 1912...\n",
      "\n",
      "Train Epoch: 1912 [0/8000 (0%)]\tBatch Loss: 843.883863\tLearning Rate (w_theta): 0.001000\t TIME:3618.7s\n",
      "\t\t\t\tDisc: 0.735350\t\tSym: 14.550185\t\tSpars: 828.598328\n",
      "\t TVw: -0.175920 | TVb: -2.043510 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "\n",
      "Train Epoch: 1912 [4000/8000 (50%)]\tBatch Loss: 838.576971\tLearning Rate (w_theta): 0.001000\t TIME:3620.2s\n",
      "\t\t\t\tDisc: 0.798336\t\tSym: 13.879099\t\tSpars: 823.899536\n",
      "\t TVw: -0.175326 | TVb: -2.043508 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "Validating epoch 1912...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 856.939119557695\n",
      "Average validation loss: 101.36664501612066\n",
      "Training epoch 1913...\n",
      "\n",
      "Train Epoch: 1913 [0/8000 (0%)]\tBatch Loss: 903.281110\tLearning Rate (w_theta): 0.001000\t TIME:3622.6s\n",
      "\t\t\t\tDisc: 0.997450\t\tSym: 16.567413\t\tSpars: 885.716248\n",
      "\t TVw: -0.174731 | TVb: -2.043507 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "\n",
      "Train Epoch: 1913 [4000/8000 (50%)]\tBatch Loss: 834.998397\tLearning Rate (w_theta): 0.001000\t TIME:3624.1s\n",
      "\t\t\t\tDisc: 0.740770\t\tSym: 13.485959\t\tSpars: 820.771667\n",
      "\t TVw: -0.174122 | TVb: -2.043505 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "Validating epoch 1913...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 858.9094667969136\n",
      "Average validation loss: 100.32816391760184\n",
      "Training epoch 1914...\n",
      "\n",
      "Train Epoch: 1914 [0/8000 (0%)]\tBatch Loss: 883.897532\tLearning Rate (w_theta): 0.001000\t TIME:3626.4s\n",
      "\t\t\t\tDisc: 0.801951\t\tSym: 15.510619\t\tSpars: 867.584961\n",
      "\t TVw: -0.173516 | TVb: -2.043504 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "\n",
      "Train Epoch: 1914 [4000/8000 (50%)]\tBatch Loss: 856.644840\tLearning Rate (w_theta): 0.001000\t TIME:3628.0s\n",
      "\t\t\t\tDisc: 0.769929\t\tSym: 14.188387\t\tSpars: 841.686523\n",
      "\t TVw: -0.172909 | TVb: -2.043501 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "Validating epoch 1914...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 860.2151216357954\n",
      "Average validation loss: 101.03379316060835\n",
      "Training epoch 1915...\n",
      "\n",
      "Train Epoch: 1915 [0/8000 (0%)]\tBatch Loss: 822.087617\tLearning Rate (w_theta): 0.001000\t TIME:3630.4s\n",
      "\t\t\t\tDisc: 0.750872\t\tSym: 13.021682\t\tSpars: 808.315063\n",
      "\t TVw: -0.172288 | TVb: -2.043498 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "\n",
      "Train Epoch: 1915 [4000/8000 (50%)]\tBatch Loss: 879.098380\tLearning Rate (w_theta): 0.001000\t TIME:3631.9s\n",
      "\t\t\t\tDisc: 0.836024\t\tSym: 15.384061\t\tSpars: 862.878296\n",
      "\t TVw: -0.171678 | TVb: -2.043495 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "Validating epoch 1915...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 861.7828357814042\n",
      "Average validation loss: 99.97223840076028\n",
      "Training epoch 1916...\n",
      "\n",
      "Train Epoch: 1916 [0/8000 (0%)]\tBatch Loss: 879.014550\tLearning Rate (w_theta): 0.001000\t TIME:3634.6s\n",
      "\t\t\t\tDisc: 0.842007\t\tSym: 15.564878\t\tSpars: 862.607666\n",
      "\t TVw: -0.171066 | TVb: -2.043491 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "\n",
      "Train Epoch: 1916 [4000/8000 (50%)]\tBatch Loss: 835.797628\tLearning Rate (w_theta): 0.001000\t TIME:3636.1s\n",
      "\t\t\t\tDisc: 0.717152\t\tSym: 13.198214\t\tSpars: 821.882263\n",
      "\t TVw: -0.170463 | TVb: -2.043489 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034782\n",
      "Validating epoch 1916...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 855.400286945823\n",
      "Average validation loss: 99.62541072609751\n",
      "Training epoch 1917...\n",
      "\n",
      "Train Epoch: 1917 [0/8000 (0%)]\tBatch Loss: 841.124912\tLearning Rate (w_theta): 0.001000\t TIME:3638.5s\n",
      "\t\t\t\tDisc: 0.737389\t\tSym: 14.219066\t\tSpars: 826.168457\n",
      "\t TVw: -0.169861 | TVb: -2.043486 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "\n",
      "Train Epoch: 1917 [4000/8000 (50%)]\tBatch Loss: 870.270013\tLearning Rate (w_theta): 0.001000\t TIME:3640.0s\n",
      "\t\t\t\tDisc: 0.819585\t\tSym: 15.378894\t\tSpars: 854.071533\n",
      "\t TVw: -0.169247 | TVb: -2.043484 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "Validating epoch 1917...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 858.8455192720432\n",
      "Average validation loss: 99.5075962994889\n",
      "Training epoch 1918...\n",
      "\n",
      "Train Epoch: 1918 [0/8000 (0%)]\tBatch Loss: 848.498836\tLearning Rate (w_theta): 0.001000\t TIME:3642.4s\n",
      "\t\t\t\tDisc: 0.733316\t\tSym: 13.975115\t\tSpars: 833.790405\n",
      "\t TVw: -0.168631 | TVb: -2.043482 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "\n",
      "Train Epoch: 1918 [4000/8000 (50%)]\tBatch Loss: 902.491860\tLearning Rate (w_theta): 0.001000\t TIME:3643.9s\n",
      "\t\t\t\tDisc: 0.956303\t\tSym: 16.604588\t\tSpars: 884.930969\n",
      "\t TVw: -0.168045 | TVb: -2.043480 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "Validating epoch 1918...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 861.7184720257111\n",
      "Average validation loss: 99.08607968218153\n",
      "Training epoch 1919...\n",
      "\n",
      "Train Epoch: 1919 [0/8000 (0%)]\tBatch Loss: 864.727333\tLearning Rate (w_theta): 0.001000\t TIME:3646.3s\n",
      "\t\t\t\tDisc: 0.784276\t\tSym: 14.290591\t\tSpars: 849.652466\n",
      "\t TVw: -0.167451 | TVb: -2.043478 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "\n",
      "Train Epoch: 1919 [4000/8000 (50%)]\tBatch Loss: 835.947310\tLearning Rate (w_theta): 0.001000\t TIME:3647.8s\n",
      "\t\t\t\tDisc: 0.704452\t\tSym: 14.831481\t\tSpars: 820.411377\n",
      "\t TVw: -0.166848 | TVb: -2.043476 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "Validating epoch 1919...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 854.6522239878709\n",
      "Average validation loss: 99.51483017937109\n",
      "Training epoch 1920...\n",
      "\n",
      "Train Epoch: 1920 [0/8000 (0%)]\tBatch Loss: 901.554529\tLearning Rate (w_theta): 0.001000\t TIME:3650.2s\n",
      "\t\t\t\tDisc: 0.934078\t\tSym: 16.258024\t\tSpars: 884.362427\n",
      "\t TVw: -0.166240 | TVb: -2.043473 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "\n",
      "Train Epoch: 1920 [4000/8000 (50%)]\tBatch Loss: 817.932647\tLearning Rate (w_theta): 0.001000\t TIME:3651.8s\n",
      "\t\t\t\tDisc: 0.693131\t\tSym: 12.489455\t\tSpars: 804.750061\n",
      "\t TVw: -0.165648 | TVb: -2.043471 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "Validating epoch 1920...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 852.6725992412212\n",
      "Average validation loss: 98.99372454633938\n",
      "Training epoch 1921...\n",
      "\n",
      "Train Epoch: 1921 [0/8000 (0%)]\tBatch Loss: 860.609872\tLearning Rate (w_theta): 0.001000\t TIME:3654.8s\n",
      "\t\t\t\tDisc: 0.847857\t\tSym: 14.889152\t\tSpars: 844.872864\n",
      "\t TVw: -0.165063 | TVb: -2.043470 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "\n",
      "Train Epoch: 1921 [4000/8000 (50%)]\tBatch Loss: 812.739706\tLearning Rate (w_theta): 0.001000\t TIME:3656.4s\n",
      "\t\t\t\tDisc: 0.777976\t\tSym: 12.934020\t\tSpars: 799.027710\n",
      "\t TVw: -0.164462 | TVb: -2.043467 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "Validating epoch 1921...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 850.6668433351342\n",
      "Average validation loss: 99.31731876959105\n",
      "Training epoch 1922...\n",
      "\n",
      "Train Epoch: 1922 [0/8000 (0%)]\tBatch Loss: 835.876973\tLearning Rate (w_theta): 0.001000\t TIME:3658.8s\n",
      "\t\t\t\tDisc: 0.824999\t\tSym: 14.433626\t\tSpars: 820.618347\n",
      "\t TVw: -0.163843 | TVb: -2.043464 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "\n",
      "Train Epoch: 1922 [4000/8000 (50%)]\tBatch Loss: 901.219309\tLearning Rate (w_theta): 0.001000\t TIME:3660.3s\n",
      "\t\t\t\tDisc: 0.827936\t\tSym: 16.439529\t\tSpars: 883.951843\n",
      "\t TVw: -0.163221 | TVb: -2.043462 | GSw: -0.234959 | GSb: 0.065051 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "Validating epoch 1922...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 851.9478140806157\n",
      "Average validation loss: 98.69608663752923\n",
      "Training epoch 1923...\n",
      "\n",
      "Train Epoch: 1923 [0/8000 (0%)]\tBatch Loss: 848.217977\tLearning Rate (w_theta): 0.001000\t TIME:3662.7s\n",
      "\t\t\t\tDisc: 0.788767\t\tSym: 14.665050\t\tSpars: 832.764160\n",
      "\t TVw: -0.162601 | TVb: -2.043458 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "\n",
      "Train Epoch: 1923 [4000/8000 (50%)]\tBatch Loss: 846.608203\tLearning Rate (w_theta): 0.001000\t TIME:3664.2s\n",
      "\t\t\t\tDisc: 0.860240\t\tSym: 14.425270\t\tSpars: 831.322693\n",
      "\t TVw: -0.161976 | TVb: -2.043454 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "Validating epoch 1923...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 854.4886130838505\n",
      "Average validation loss: 97.50370678534706\n",
      "Training epoch 1924...\n",
      "\n",
      "Train Epoch: 1924 [0/8000 (0%)]\tBatch Loss: 820.350370\tLearning Rate (w_theta): 0.001000\t TIME:3666.9s\n",
      "\t\t\t\tDisc: 0.746689\t\tSym: 13.161725\t\tSpars: 806.441956\n",
      "\t TVw: -0.161370 | TVb: -2.043452 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "\n",
      "Train Epoch: 1924 [4000/8000 (50%)]\tBatch Loss: 878.419596\tLearning Rate (w_theta): 0.001000\t TIME:3668.4s\n",
      "\t\t\t\tDisc: 0.858800\t\tSym: 15.977056\t\tSpars: 861.583740\n",
      "\t TVw: -0.160768 | TVb: -2.043449 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "Validating epoch 1924...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 854.1282291438903\n",
      "Average validation loss: 97.69493306870444\n",
      "Training epoch 1925...\n",
      "\n",
      "Train Epoch: 1925 [0/8000 (0%)]\tBatch Loss: 821.632430\tLearning Rate (w_theta): 0.001000\t TIME:3670.8s\n",
      "\t\t\t\tDisc: 0.712181\t\tSym: 13.992942\t\tSpars: 806.927307\n",
      "\t TVw: -0.160176 | TVb: -2.043446 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "\n",
      "Train Epoch: 1925 [4000/8000 (50%)]\tBatch Loss: 859.380084\tLearning Rate (w_theta): 0.001000\t TIME:3672.3s\n",
      "\t\t\t\tDisc: 0.811310\t\tSym: 14.553271\t\tSpars: 844.015503\n",
      "\t TVw: -0.159591 | TVb: -2.043443 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "Validating epoch 1925...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 848.3645444856285\n",
      "Average validation loss: 97.48294015831277\n",
      "Training epoch 1926...\n",
      "\n",
      "Train Epoch: 1926 [0/8000 (0%)]\tBatch Loss: 839.609645\tLearning Rate (w_theta): 0.001000\t TIME:3674.7s\n",
      "\t\t\t\tDisc: 0.747384\t\tSym: 13.992815\t\tSpars: 824.869446\n",
      "\t TVw: -0.158984 | TVb: -2.043441 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "\n",
      "Train Epoch: 1926 [4000/8000 (50%)]\tBatch Loss: 853.799351\tLearning Rate (w_theta): 0.001000\t TIME:3676.2s\n",
      "\t\t\t\tDisc: 0.730954\t\tSym: 13.923805\t\tSpars: 839.144592\n",
      "\t TVw: -0.158358 | TVb: -2.043438 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "Validating epoch 1926...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 847.3868513518223\n",
      "Average validation loss: 96.87926676827772\n",
      "Training epoch 1927...\n",
      "\n",
      "Train Epoch: 1927 [0/8000 (0%)]\tBatch Loss: 826.695798\tLearning Rate (w_theta): 0.001000\t TIME:3678.6s\n",
      "\t\t\t\tDisc: 0.791058\t\tSym: 12.691361\t\tSpars: 813.213379\n",
      "\t TVw: -0.157725 | TVb: -2.043436 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "\n",
      "Train Epoch: 1927 [4000/8000 (50%)]\tBatch Loss: 832.670265\tLearning Rate (w_theta): 0.001000\t TIME:3680.1s\n",
      "\t\t\t\tDisc: 0.741580\t\tSym: 14.105016\t\tSpars: 817.823669\n",
      "\t TVw: -0.157094 | TVb: -2.043433 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "Validating epoch 1927...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 845.966280140377\n",
      "Average validation loss: 96.90510129564741\n",
      "Training epoch 1928...\n",
      "\n",
      "Train Epoch: 1928 [0/8000 (0%)]\tBatch Loss: 832.631749\tLearning Rate (w_theta): 0.001000\t TIME:3682.5s\n",
      "\t\t\t\tDisc: 0.691205\t\tSym: 13.539848\t\tSpars: 818.400696\n",
      "\t TVw: -0.156452 | TVb: -2.043430 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "\n",
      "Train Epoch: 1928 [4000/8000 (50%)]\tBatch Loss: 849.040471\tLearning Rate (w_theta): 0.001000\t TIME:3684.1s\n",
      "\t\t\t\tDisc: 0.801805\t\tSym: 15.248675\t\tSpars: 832.989990\n",
      "\t TVw: -0.155824 | TVb: -2.043428 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "Validating epoch 1928...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 845.0315370268655\n",
      "Average validation loss: 96.529402989148\n",
      "Training epoch 1929...\n",
      "\n",
      "Train Epoch: 1929 [0/8000 (0%)]\tBatch Loss: 862.960365\tLearning Rate (w_theta): 0.001000\t TIME:3686.4s\n",
      "\t\t\t\tDisc: 0.823819\t\tSym: 14.427073\t\tSpars: 847.709473\n",
      "\t TVw: -0.155191 | TVb: -2.043425 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "\n",
      "Train Epoch: 1929 [4000/8000 (50%)]\tBatch Loss: 847.010660\tLearning Rate (w_theta): 0.001000\t TIME:3688.0s\n",
      "\t\t\t\tDisc: 0.799719\t\tSym: 14.319095\t\tSpars: 831.891846\n",
      "\t TVw: -0.154553 | TVb: -2.043422 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "Validating epoch 1929...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 843.7857844937546\n",
      "Average validation loss: 96.24895792537419\n",
      "Training epoch 1930...\n",
      "\n",
      "Train Epoch: 1930 [0/8000 (0%)]\tBatch Loss: 840.735331\tLearning Rate (w_theta): 0.001000\t TIME:3690.3s\n",
      "\t\t\t\tDisc: 0.808098\t\tSym: 14.528796\t\tSpars: 825.398438\n",
      "\t TVw: -0.153914 | TVb: -2.043418 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "\n",
      "Train Epoch: 1930 [4000/8000 (50%)]\tBatch Loss: 828.275287\tLearning Rate (w_theta): 0.001000\t TIME:3691.9s\n",
      "\t\t\t\tDisc: 0.734757\t\tSym: 13.681276\t\tSpars: 813.859253\n",
      "\t TVw: -0.153271 | TVb: -2.043415 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "Validating epoch 1930...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 843.2181020990536\n",
      "Average validation loss: 96.34410822005532\n",
      "Training epoch 1931...\n",
      "\n",
      "Train Epoch: 1931 [0/8000 (0%)]\tBatch Loss: 858.427892\tLearning Rate (w_theta): 0.001000\t TIME:3694.9s\n",
      "\t\t\t\tDisc: 0.834590\t\tSym: 14.234903\t\tSpars: 843.358398\n",
      "\t TVw: -0.152640 | TVb: -2.043412 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "\n",
      "Train Epoch: 1931 [4000/8000 (50%)]\tBatch Loss: 861.818522\tLearning Rate (w_theta): 0.001000\t TIME:3696.5s\n",
      "\t\t\t\tDisc: 0.666956\t\tSym: 15.014908\t\tSpars: 846.136658\n",
      "\t TVw: -0.152030 | TVb: -2.043410 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "Validating epoch 1931...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 844.9557956972326\n",
      "Average validation loss: 96.43822586247346\n",
      "Training epoch 1932...\n",
      "\n",
      "Train Epoch: 1932 [0/8000 (0%)]\tBatch Loss: 865.333057\tLearning Rate (w_theta): 0.001000\t TIME:3698.9s\n",
      "\t\t\t\tDisc: 0.829991\t\tSym: 15.667312\t\tSpars: 848.835754\n",
      "\t TVw: -0.151400 | TVb: -2.043406 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "\n",
      "Train Epoch: 1932 [4000/8000 (50%)]\tBatch Loss: 834.519692\tLearning Rate (w_theta): 0.001000\t TIME:3700.5s\n",
      "\t\t\t\tDisc: 0.741716\t\tSym: 14.106040\t\tSpars: 819.671936\n",
      "\t TVw: -0.150767 | TVb: -2.043402 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034783\n",
      "Validating epoch 1932...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 846.3047948952759\n",
      "Average validation loss: 94.05263358627376\n",
      "Training epoch 1933...\n",
      "\n",
      "Train Epoch: 1933 [0/8000 (0%)]\tBatch Loss: 846.567134\tLearning Rate (w_theta): 0.001000\t TIME:3703.1s\n",
      "\t\t\t\tDisc: 0.744343\t\tSym: 14.140784\t\tSpars: 831.682007\n",
      "\t TVw: -0.150153 | TVb: -2.043400 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034784\n",
      "\n",
      "Train Epoch: 1933 [4000/8000 (50%)]\tBatch Loss: 868.601572\tLearning Rate (w_theta): 0.001000\t TIME:3704.6s\n",
      "\t\t\t\tDisc: 0.757544\t\tSym: 14.481174\t\tSpars: 853.362854\n",
      "\t TVw: -0.149534 | TVb: -2.043396 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034784\n",
      "Validating epoch 1933...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 849.8152571740787\n",
      "Average validation loss: 95.81341983676027\n",
      "Training epoch 1934...\n",
      "\n",
      "Train Epoch: 1934 [0/8000 (0%)]\tBatch Loss: 839.615672\tLearning Rate (w_theta): 0.001000\t TIME:3707.0s\n",
      "\t\t\t\tDisc: 0.752061\t\tSym: 14.901758\t\tSpars: 823.961853\n",
      "\t TVw: -0.148913 | TVb: -2.043391 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034784\n",
      "\n",
      "Train Epoch: 1934 [4000/8000 (50%)]\tBatch Loss: 816.213738\tLearning Rate (w_theta): 0.001000\t TIME:3708.5s\n",
      "\t\t\t\tDisc: 0.678838\t\tSym: 13.004443\t\tSpars: 802.530457\n",
      "\t TVw: -0.148305 | TVb: -2.043386 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034784\n",
      "Validating epoch 1934...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 845.9463920818918\n",
      "Average validation loss: 94.1207798229564\n",
      "Training epoch 1935...\n",
      "\n",
      "Train Epoch: 1935 [0/8000 (0%)]\tBatch Loss: 830.808981\tLearning Rate (w_theta): 0.001000\t TIME:3710.9s\n",
      "\t\t\t\tDisc: 0.753406\t\tSym: 13.628818\t\tSpars: 816.426758\n",
      "\t TVw: -0.147681 | TVb: -2.043382 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034784\n",
      "\n",
      "Train Epoch: 1935 [4000/8000 (50%)]\tBatch Loss: 860.730033\tLearning Rate (w_theta): 0.001000\t TIME:3712.5s\n",
      "\t\t\t\tDisc: 0.779565\t\tSym: 15.051847\t\tSpars: 844.898621\n",
      "\t TVw: -0.147049 | TVb: -2.043377 | GSw: -0.234959 | GSb: 0.065050 | TSUw: 0.464946 | TSUb: 0.034784\n",
      "Validating epoch 1935...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 841.0994941054938\n",
      "Average validation loss: 92.87586265979914\n",
      "Training epoch 1936...\n",
      "\n",
      "Train Epoch: 1936 [0/8000 (0%)]\tBatch Loss: 828.834384\tLearning Rate (w_theta): 0.001000\t TIME:3714.8s\n",
      "\t\t\t\tDisc: 0.697213\t\tSym: 13.208338\t\tSpars: 814.928833\n",
      "\t TVw: -0.146430 | TVb: -2.043374 | GSw: -0.234959 | GSb: 0.065049 | TSUw: 0.464946 | TSUb: 0.034784\n",
      "\n",
      "Train Epoch: 1936 [4000/8000 (50%)]\tBatch Loss: 844.227545\tLearning Rate (w_theta): 0.001000\t TIME:3716.4s\n",
      "\t\t\t\tDisc: 0.793151\t\tSym: 14.612556\t\tSpars: 828.821838\n",
      "\t TVw: -0.145815 | TVb: -2.043371 | GSw: -0.234959 | GSb: 0.065049 | TSUw: 0.464946 | TSUb: 0.034784\n",
      "Validating epoch 1936...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 843.7181462494292\n",
      "Average validation loss: 94.92242865175096\n",
      "Training epoch 1937...\n",
      "\n",
      "Train Epoch: 1937 [0/8000 (0%)]\tBatch Loss: 879.187092\tLearning Rate (w_theta): 0.001000\t TIME:3718.8s\n",
      "\t\t\t\tDisc: 0.803792\t\tSym: 15.804320\t\tSpars: 862.578979\n",
      "\t TVw: -0.145194 | TVb: -2.043369 | GSw: -0.234959 | GSb: 0.065049 | TSUw: 0.464946 | TSUb: 0.034784\n",
      "\n",
      "Train Epoch: 1937 [4000/8000 (50%)]\tBatch Loss: 787.847425\tLearning Rate (w_theta): 0.001000\t TIME:3720.3s\n",
      "\t\t\t\tDisc: 0.676314\t\tSym: 11.906402\t\tSpars: 775.264709\n",
      "\t TVw: -0.144582 | TVb: -2.043366 | GSw: -0.234959 | GSb: 0.065049 | TSUw: 0.464946 | TSUb: 0.034784\n",
      "Validating epoch 1937...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 847.6380528377487\n",
      "Average validation loss: 93.04596125049284\n",
      "Training epoch 1938...\n",
      "\n",
      "Train Epoch: 1938 [0/8000 (0%)]\tBatch Loss: 873.245607\tLearning Rate (w_theta): 0.001000\t TIME:3722.7s\n",
      "\t\t\t\tDisc: 0.701790\t\tSym: 15.682489\t\tSpars: 856.861328\n",
      "\t TVw: -0.144000 | TVb: -2.043365 | GSw: -0.234959 | GSb: 0.065049 | TSUw: 0.464946 | TSUb: 0.034784\n",
      "\n",
      "Train Epoch: 1938 [4000/8000 (50%)]\tBatch Loss: 830.901233\tLearning Rate (w_theta): 0.001000\t TIME:3724.2s\n",
      "\t\t\t\tDisc: 0.686610\t\tSym: 13.236656\t\tSpars: 816.977966\n",
      "\t TVw: -0.143412 | TVb: -2.043363 | GSw: -0.234959 | GSb: 0.065049 | TSUw: 0.464946 | TSUb: 0.034784\n",
      "Validating epoch 1938...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 843.2953344143989\n",
      "Average validation loss: 94.03702415391447\n",
      "Training epoch 1939...\n",
      "\n",
      "Train Epoch: 1939 [0/8000 (0%)]\tBatch Loss: 800.736437\tLearning Rate (w_theta): 0.001000\t TIME:3726.6s\n",
      "\t\t\t\tDisc: 0.687687\t\tSym: 12.637923\t\tSpars: 787.410828\n",
      "\t TVw: -0.142801 | TVb: -2.043359 | GSw: -0.234959 | GSb: 0.065049 | TSUw: 0.464946 | TSUb: 0.034784\n",
      "\n",
      "Train Epoch: 1939 [4000/8000 (50%)]\tBatch Loss: 831.624930\tLearning Rate (w_theta): 0.001000\t TIME:3728.1s\n",
      "\t\t\t\tDisc: 0.844329\t\tSym: 13.933922\t\tSpars: 816.846680\n",
      "\t TVw: -0.142181 | TVb: -2.043355 | GSw: -0.234959 | GSb: 0.065049 | TSUw: 0.464946 | TSUb: 0.034784\n",
      "Validating epoch 1939...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 839.5605075726762\n",
      "Average validation loss: 92.66591441785333\n",
      "Training epoch 1940...\n",
      "\n",
      "Train Epoch: 1940 [0/8000 (0%)]\tBatch Loss: 846.535506\tLearning Rate (w_theta): 0.001000\t TIME:3730.5s\n",
      "\t\t\t\tDisc: 0.692885\t\tSym: 14.566315\t\tSpars: 831.276306\n",
      "\t TVw: -0.141557 | TVb: -2.043351 | GSw: -0.234959 | GSb: 0.065049 | TSUw: 0.464946 | TSUb: 0.034784\n",
      "\n",
      "Train Epoch: 1940 [4000/8000 (50%)]\tBatch Loss: 837.633872\tLearning Rate (w_theta): 0.001000\t TIME:3732.1s\n",
      "\t\t\t\tDisc: 0.793391\t\tSym: 14.593656\t\tSpars: 822.246826\n",
      "\t TVw: -0.140930 | TVb: -2.043347 | GSw: -0.234959 | GSb: 0.065049 | TSUw: 0.464946 | TSUb: 0.034784\n",
      "Validating epoch 1940...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 839.101431688063\n",
      "Average validation loss: 93.15113846876936\n",
      "Training epoch 1941...\n",
      "\n",
      "Train Epoch: 1941 [0/8000 (0%)]\tBatch Loss: 815.446658\tLearning Rate (w_theta): 0.001000\t TIME:3735.1s\n",
      "\t\t\t\tDisc: 0.733127\t\tSym: 13.086273\t\tSpars: 801.627258\n",
      "\t TVw: -0.140304 | TVb: -2.043343 | GSw: -0.234959 | GSb: 0.065049 | TSUw: 0.464946 | TSUb: 0.034784\n",
      "\n",
      "Train Epoch: 1941 [4000/8000 (50%)]\tBatch Loss: 854.855208\tLearning Rate (w_theta): 0.001000\t TIME:3736.6s\n",
      "\t\t\t\tDisc: 0.806894\t\tSym: 14.723180\t\tSpars: 839.325134\n",
      "\t TVw: -0.139683 | TVb: -2.043339 | GSw: -0.234959 | GSb: 0.065049 | TSUw: 0.464946 | TSUb: 0.034784\n",
      "Validating epoch 1941...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 836.5182606301366\n",
      "Average validation loss: 92.79033561193894\n",
      "Training epoch 1942...\n",
      "\n",
      "Train Epoch: 1942 [0/8000 (0%)]\tBatch Loss: 873.110485\tLearning Rate (w_theta): 0.001000\t TIME:3739.3s\n",
      "\t\t\t\tDisc: 0.850835\t\tSym: 15.909431\t\tSpars: 856.350220\n",
      "\t TVw: -0.139052 | TVb: -2.043336 | GSw: -0.234959 | GSb: 0.065049 | TSUw: 0.464946 | TSUb: 0.034784\n",
      "\n",
      "Train Epoch: 1942 [4000/8000 (50%)]\tBatch Loss: 854.182536\tLearning Rate (w_theta): 0.001000\t TIME:3740.8s\n",
      "\t\t\t\tDisc: 0.841960\t\tSym: 15.508972\t\tSpars: 837.831604\n",
      "\t TVw: -0.138431 | TVb: -2.043334 | GSw: -0.234959 | GSb: 0.065049 | TSUw: 0.464946 | TSUb: 0.034784\n",
      "Validating epoch 1942...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 837.3225829747754\n",
      "Average validation loss: 92.09718785088843\n",
      "Training epoch 1943...\n",
      "\n",
      "Train Epoch: 1943 [0/8000 (0%)]\tBatch Loss: 800.504266\tLearning Rate (w_theta): 0.001000\t TIME:3743.2s\n",
      "\t\t\t\tDisc: 0.708766\t\tSym: 12.370208\t\tSpars: 787.425293\n",
      "\t TVw: -0.137811 | TVb: -2.043332 | GSw: -0.234959 | GSb: 0.065049 | TSUw: 0.464946 | TSUb: 0.034784\n",
      "\n",
      "Train Epoch: 1943 [4000/8000 (50%)]\tBatch Loss: 821.105937\tLearning Rate (w_theta): 0.001000\t TIME:3744.7s\n",
      "\t\t\t\tDisc: 0.722730\t\tSym: 14.084195\t\tSpars: 806.299011\n",
      "\t TVw: -0.137181 | TVb: -2.043329 | GSw: -0.234959 | GSb: 0.065049 | TSUw: 0.464946 | TSUb: 0.034784\n",
      "Validating epoch 1943...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 836.2309471867818\n",
      "Average validation loss: 91.87013664025002\n",
      "Training epoch 1944...\n",
      "\n",
      "Train Epoch: 1944 [0/8000 (0%)]\tBatch Loss: 815.041181\tLearning Rate (w_theta): 0.001000\t TIME:3747.1s\n",
      "\t\t\t\tDisc: 0.646961\t\tSym: 12.877008\t\tSpars: 801.517212\n",
      "\t TVw: -0.136537 | TVb: -2.043326 | GSw: -0.234959 | GSb: 0.065048 | TSUw: 0.464946 | TSUb: 0.034784\n",
      "\n",
      "Train Epoch: 1944 [4000/8000 (50%)]\tBatch Loss: 850.666361\tLearning Rate (w_theta): 0.001000\t TIME:3748.7s\n",
      "\t\t\t\tDisc: 0.790578\t\tSym: 14.958547\t\tSpars: 834.917236\n",
      "\t TVw: -0.135895 | TVb: -2.043323 | GSw: -0.234959 | GSb: 0.065048 | TSUw: 0.464946 | TSUb: 0.034785\n",
      "Validating epoch 1944...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 836.1250267090171\n",
      "Average validation loss: 91.18051506244657\n",
      "Training epoch 1945...\n",
      "\n",
      "Train Epoch: 1945 [0/8000 (0%)]\tBatch Loss: 887.832702\tLearning Rate (w_theta): 0.001000\t TIME:3751.0s\n",
      "\t\t\t\tDisc: 0.780050\t\tSym: 16.424601\t\tSpars: 870.628052\n",
      "\t TVw: -0.135275 | TVb: -2.043319 | GSw: -0.234959 | GSb: 0.065048 | TSUw: 0.464946 | TSUb: 0.034785\n",
      "\n",
      "Train Epoch: 1945 [4000/8000 (50%)]\tBatch Loss: 892.049902\tLearning Rate (w_theta): 0.001000\t TIME:3752.6s\n",
      "\t\t\t\tDisc: 0.844194\t\tSym: 16.529316\t\tSpars: 874.676392\n",
      "\t TVw: -0.134644 | TVb: -2.043314 | GSw: -0.234959 | GSb: 0.065048 | TSUw: 0.464946 | TSUb: 0.034785\n",
      "Validating epoch 1945...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 836.3900450320423\n",
      "Average validation loss: 92.07727461837112\n",
      "Training epoch 1946...\n",
      "\n",
      "Train Epoch: 1946 [0/8000 (0%)]\tBatch Loss: 818.515223\tLearning Rate (w_theta): 0.001000\t TIME:3755.0s\n",
      "\t\t\t\tDisc: 0.694146\t\tSym: 12.905245\t\tSpars: 804.915833\n",
      "\t TVw: -0.134026 | TVb: -2.043309 | GSw: -0.234959 | GSb: 0.065048 | TSUw: 0.464946 | TSUb: 0.034785\n",
      "\n",
      "Train Epoch: 1946 [4000/8000 (50%)]\tBatch Loss: 843.304550\tLearning Rate (w_theta): 0.001000\t TIME:3756.5s\n",
      "\t\t\t\tDisc: 0.735357\t\tSym: 14.646281\t\tSpars: 827.922913\n",
      "\t TVw: -0.133427 | TVb: -2.043306 | GSw: -0.234959 | GSb: 0.065048 | TSUw: 0.464946 | TSUb: 0.034785\n",
      "Validating epoch 1946...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 836.6951083737595\n",
      "Average validation loss: 90.40474841939309\n",
      "Training epoch 1947...\n",
      "\n",
      "Train Epoch: 1947 [0/8000 (0%)]\tBatch Loss: 824.015781\tLearning Rate (w_theta): 0.001000\t TIME:3758.9s\n",
      "\t\t\t\tDisc: 0.693081\t\tSym: 13.104378\t\tSpars: 810.218323\n",
      "\t TVw: -0.132835 | TVb: -2.043303 | GSw: -0.234959 | GSb: 0.065048 | TSUw: 0.464946 | TSUb: 0.034785\n",
      "\n",
      "Train Epoch: 1947 [4000/8000 (50%)]\tBatch Loss: 826.684832\tLearning Rate (w_theta): 0.001000\t TIME:3760.5s\n",
      "\t\t\t\tDisc: 0.746852\t\tSym: 13.876396\t\tSpars: 812.061584\n",
      "\t TVw: -0.132223 | TVb: -2.043299 | GSw: -0.234959 | GSb: 0.065048 | TSUw: 0.464946 | TSUb: 0.034785\n",
      "Validating epoch 1947...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 834.8955809660624\n",
      "Average validation loss: 91.45893971123452\n",
      "Training epoch 1948...\n",
      "\n",
      "Train Epoch: 1948 [0/8000 (0%)]\tBatch Loss: 823.430076\tLearning Rate (w_theta): 0.001000\t TIME:3762.9s\n",
      "\t\t\t\tDisc: 0.742757\t\tSym: 13.841127\t\tSpars: 808.846191\n",
      "\t TVw: -0.131581 | TVb: -2.043294 | GSw: -0.234959 | GSb: 0.065048 | TSUw: 0.464946 | TSUb: 0.034785\n",
      "\n",
      "Train Epoch: 1948 [4000/8000 (50%)]\tBatch Loss: 818.620490\tLearning Rate (w_theta): 0.001000\t TIME:3764.4s\n",
      "\t\t\t\tDisc: 0.687672\t\tSym: 13.774432\t\tSpars: 804.158386\n",
      "\t TVw: -0.130933 | TVb: -2.043290 | GSw: -0.234959 | GSb: 0.065048 | TSUw: 0.464946 | TSUb: 0.034785\n",
      "Validating epoch 1948...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 831.8912207878956\n",
      "Average validation loss: 90.3936488596729\n",
      "Training epoch 1949...\n",
      "\n",
      "Train Epoch: 1949 [0/8000 (0%)]\tBatch Loss: 829.928119\tLearning Rate (w_theta): 0.001000\t TIME:3766.8s\n",
      "\t\t\t\tDisc: 0.749390\t\tSym: 14.422259\t\tSpars: 814.756470\n",
      "\t TVw: -0.130292 | TVb: -2.043286 | GSw: -0.234959 | GSb: 0.065048 | TSUw: 0.464946 | TSUb: 0.034785\n",
      "\n",
      "Train Epoch: 1949 [4000/8000 (50%)]\tBatch Loss: 827.948119\tLearning Rate (w_theta): 0.001000\t TIME:3768.3s\n",
      "\t\t\t\tDisc: 0.688959\t\tSym: 13.518987\t\tSpars: 813.740173\n",
      "\t TVw: -0.129664 | TVb: -2.043283 | GSw: -0.234959 | GSb: 0.065048 | TSUw: 0.464946 | TSUb: 0.034785\n",
      "Validating epoch 1949...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 829.7178571440205\n",
      "Average validation loss: 90.05355456118888\n",
      "Training epoch 1950...\n",
      "\n",
      "Train Epoch: 1950 [0/8000 (0%)]\tBatch Loss: 824.826063\tLearning Rate (w_theta): 0.001000\t TIME:3770.7s\n",
      "\t\t\t\tDisc: 0.683834\t\tSym: 13.519182\t\tSpars: 810.623047\n",
      "\t TVw: -0.129034 | TVb: -2.043279 | GSw: -0.234959 | GSb: 0.065048 | TSUw: 0.464946 | TSUb: 0.034785\n",
      "\n",
      "Train Epoch: 1950 [4000/8000 (50%)]\tBatch Loss: 845.643817\tLearning Rate (w_theta): 0.001000\t TIME:3772.2s\n",
      "\t\t\t\tDisc: 0.766651\t\tSym: 15.379607\t\tSpars: 829.497559\n",
      "\t TVw: -0.128414 | TVb: -2.043276 | GSw: -0.234959 | GSb: 0.065048 | TSUw: 0.464946 | TSUb: 0.034785\n",
      "Validating epoch 1950...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 829.6297453182938\n",
      "Average validation loss: 90.15722189727236\n",
      "Training epoch 1951...\n",
      "\n",
      "Train Epoch: 1951 [0/8000 (0%)]\tBatch Loss: 816.532149\tLearning Rate (w_theta): 0.001000\t TIME:3775.5s\n",
      "\t\t\t\tDisc: 0.703554\t\tSym: 13.158612\t\tSpars: 802.669983\n",
      "\t TVw: -0.127784 | TVb: -2.043271 | GSw: -0.234959 | GSb: 0.065048 | TSUw: 0.464946 | TSUb: 0.034785\n",
      "\n",
      "Train Epoch: 1951 [4000/8000 (50%)]\tBatch Loss: 854.897775\tLearning Rate (w_theta): 0.001000\t TIME:3777.1s\n",
      "\t\t\t\tDisc: 0.810848\t\tSym: 15.280591\t\tSpars: 838.806335\n",
      "\t TVw: -0.127149 | TVb: -2.043267 | GSw: -0.234959 | GSb: 0.065048 | TSUw: 0.464946 | TSUb: 0.034785\n",
      "Validating epoch 1951...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 829.4992130231946\n",
      "Average validation loss: 88.89661574946322\n",
      "Training epoch 1952...\n",
      "\n",
      "Train Epoch: 1952 [0/8000 (0%)]\tBatch Loss: 826.208447\tLearning Rate (w_theta): 0.001000\t TIME:3779.4s\n",
      "\t\t\t\tDisc: 0.733840\t\tSym: 13.473264\t\tSpars: 812.001343\n",
      "\t TVw: -0.126525 | TVb: -2.043264 | GSw: -0.234959 | GSb: 0.065048 | TSUw: 0.464946 | TSUb: 0.034785\n",
      "\n",
      "Train Epoch: 1952 [4000/8000 (50%)]\tBatch Loss: 846.872683\tLearning Rate (w_theta): 0.001000\t TIME:3781.0s\n",
      "\t\t\t\tDisc: 0.761839\t\tSym: 14.404119\t\tSpars: 831.706726\n",
      "\t TVw: -0.125904 | TVb: -2.043260 | GSw: -0.234959 | GSb: 0.065047 | TSUw: 0.464946 | TSUb: 0.034785\n",
      "Validating epoch 1952...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 830.9922383216604\n",
      "Average validation loss: 89.35629352586834\n",
      "Training epoch 1953...\n",
      "\n",
      "Train Epoch: 1953 [0/8000 (0%)]\tBatch Loss: 794.116233\tLearning Rate (w_theta): 0.001000\t TIME:3783.4s\n",
      "\t\t\t\tDisc: 0.680998\t\tSym: 12.705438\t\tSpars: 780.729797\n",
      "\t TVw: -0.125291 | TVb: -2.043257 | GSw: -0.234959 | GSb: 0.065047 | TSUw: 0.464946 | TSUb: 0.034785\n",
      "\n",
      "Train Epoch: 1953 [4000/8000 (50%)]\tBatch Loss: 830.084933\tLearning Rate (w_theta): 0.001000\t TIME:3784.9s\n",
      "\t\t\t\tDisc: 0.777467\t\tSym: 14.907930\t\tSpars: 814.399536\n",
      "\t TVw: -0.124681 | TVb: -2.043253 | GSw: -0.234959 | GSb: 0.065047 | TSUw: 0.464946 | TSUb: 0.034785\n",
      "Validating epoch 1953...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 827.7329701282891\n",
      "Average validation loss: 88.55599546650456\n",
      "Training epoch 1954...\n",
      "\n",
      "Train Epoch: 1954 [0/8000 (0%)]\tBatch Loss: 845.200645\tLearning Rate (w_theta): 0.001000\t TIME:3787.3s\n",
      "\t\t\t\tDisc: 0.769643\t\tSym: 15.160555\t\tSpars: 829.270447\n",
      "\t TVw: -0.124066 | TVb: -2.043250 | GSw: -0.234959 | GSb: 0.065047 | TSUw: 0.464946 | TSUb: 0.034785\n",
      "\n",
      "Train Epoch: 1954 [4000/8000 (50%)]\tBatch Loss: 824.747419\tLearning Rate (w_theta): 0.001000\t TIME:3788.9s\n",
      "\t\t\t\tDisc: 0.743701\t\tSym: 14.135554\t\tSpars: 809.868164\n",
      "\t TVw: -0.123445 | TVb: -2.043246 | GSw: -0.234959 | GSb: 0.065047 | TSUw: 0.464946 | TSUb: 0.034785\n",
      "Validating epoch 1954...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 828.318108986319\n",
      "Average validation loss: 88.98399382209598\n",
      "Training epoch 1955...\n",
      "\n",
      "Train Epoch: 1955 [0/8000 (0%)]\tBatch Loss: 800.027658\tLearning Rate (w_theta): 0.001000\t TIME:3791.2s\n",
      "\t\t\t\tDisc: 0.706241\t\tSym: 12.746038\t\tSpars: 786.575378\n",
      "\t TVw: -0.122851 | TVb: -2.043244 | GSw: -0.234959 | GSb: 0.065047 | TSUw: 0.464946 | TSUb: 0.034785\n",
      "\n",
      "Train Epoch: 1955 [4000/8000 (50%)]\tBatch Loss: 846.249613\tLearning Rate (w_theta): 0.001000\t TIME:3792.8s\n",
      "\t\t\t\tDisc: 0.719439\t\tSym: 13.851097\t\tSpars: 831.679077\n",
      "\t TVw: -0.122245 | TVb: -2.043241 | GSw: -0.234959 | GSb: 0.065047 | TSUw: 0.464946 | TSUb: 0.034786\n",
      "Validating epoch 1955...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 826.729276936396\n",
      "Average validation loss: 88.1038023089418\n",
      "Training epoch 1956...\n",
      "\n",
      "Train Epoch: 1956 [0/8000 (0%)]\tBatch Loss: 843.775555\tLearning Rate (w_theta): 0.001000\t TIME:3795.2s\n",
      "\t\t\t\tDisc: 0.711787\t\tSym: 14.359606\t\tSpars: 828.704163\n",
      "\t TVw: -0.121626 | TVb: -2.043237 | GSw: -0.234959 | GSb: 0.065047 | TSUw: 0.464946 | TSUb: 0.034786\n",
      "\n",
      "Train Epoch: 1956 [4000/8000 (50%)]\tBatch Loss: 837.316356\tLearning Rate (w_theta): 0.001000\t TIME:3796.7s\n",
      "\t\t\t\tDisc: 0.768372\t\tSym: 14.927501\t\tSpars: 821.620483\n",
      "\t TVw: -0.121001 | TVb: -2.043234 | GSw: -0.234959 | GSb: 0.065047 | TSUw: 0.464946 | TSUb: 0.034786\n",
      "Validating epoch 1956...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 825.4825909090694\n",
      "Average validation loss: 88.25746051854075\n",
      "Training epoch 1957...\n",
      "\n",
      "Train Epoch: 1957 [0/8000 (0%)]\tBatch Loss: 859.009289\tLearning Rate (w_theta): 0.001000\t TIME:3799.1s\n",
      "\t\t\t\tDisc: 0.760514\t\tSym: 16.493649\t\tSpars: 841.755127\n",
      "\t TVw: -0.120367 | TVb: -2.043230 | GSw: -0.234959 | GSb: 0.065047 | TSUw: 0.464946 | TSUb: 0.034786\n",
      "\n",
      "Train Epoch: 1957 [4000/8000 (50%)]\tBatch Loss: 823.494787\tLearning Rate (w_theta): 0.001000\t TIME:3800.6s\n",
      "\t\t\t\tDisc: 0.719931\t\tSym: 13.786942\t\tSpars: 808.987915\n",
      "\t TVw: -0.119761 | TVb: -2.043227 | GSw: -0.234959 | GSb: 0.065047 | TSUw: 0.464946 | TSUb: 0.034786\n",
      "Validating epoch 1957...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 827.3227115273556\n",
      "Average validation loss: 88.14806762709534\n",
      "Training epoch 1958...\n",
      "\n",
      "Train Epoch: 1958 [0/8000 (0%)]\tBatch Loss: 833.288495\tLearning Rate (w_theta): 0.001000\t TIME:3803.0s\n",
      "\t\t\t\tDisc: 0.706479\t\tSym: 14.376938\t\tSpars: 818.205078\n",
      "\t TVw: -0.119155 | TVb: -2.043224 | GSw: -0.234959 | GSb: 0.065047 | TSUw: 0.464946 | TSUb: 0.034786\n",
      "\n",
      "Train Epoch: 1958 [4000/8000 (50%)]\tBatch Loss: 846.902483\tLearning Rate (w_theta): 0.001000\t TIME:3804.5s\n",
      "\t\t\t\tDisc: 0.880076\t\tSym: 14.670356\t\tSpars: 831.352051\n",
      "\t TVw: -0.118535 | TVb: -2.043220 | GSw: -0.234959 | GSb: 0.065047 | TSUw: 0.464946 | TSUb: 0.034786\n",
      "Validating epoch 1958...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 824.6501712745961\n",
      "Average validation loss: 88.52268645693547\n",
      "Training epoch 1959...\n",
      "\n",
      "Train Epoch: 1959 [0/8000 (0%)]\tBatch Loss: 859.911303\tLearning Rate (w_theta): 0.001000\t TIME:3806.9s\n",
      "\t\t\t\tDisc: 0.801873\t\tSym: 16.182550\t\tSpars: 842.926880\n",
      "\t TVw: -0.117906 | TVb: -2.043215 | GSw: -0.234959 | GSb: 0.065047 | TSUw: 0.464946 | TSUb: 0.034786\n",
      "\n",
      "Train Epoch: 1959 [4000/8000 (50%)]\tBatch Loss: 842.763460\tLearning Rate (w_theta): 0.001000\t TIME:3808.5s\n",
      "\t\t\t\tDisc: 0.721972\t\tSym: 14.900864\t\tSpars: 827.140625\n",
      "\t TVw: -0.117267 | TVb: -2.043211 | GSw: -0.234959 | GSb: 0.065047 | TSUw: 0.464946 | TSUb: 0.034786\n",
      "Validating epoch 1959...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 823.62563062398\n",
      "Average validation loss: 86.82710926460533\n",
      "Training epoch 1960...\n",
      "\n",
      "Train Epoch: 1960 [0/8000 (0%)]\tBatch Loss: 842.084657\tLearning Rate (w_theta): 0.001000\t TIME:3810.9s\n",
      "\t\t\t\tDisc: 0.754199\t\tSym: 15.739760\t\tSpars: 825.590698\n",
      "\t TVw: -0.116634 | TVb: -2.043206 | GSw: -0.234959 | GSb: 0.065047 | TSUw: 0.464946 | TSUb: 0.034786\n",
      "\n",
      "Train Epoch: 1960 [4000/8000 (50%)]\tBatch Loss: 837.436336\tLearning Rate (w_theta): 0.001000\t TIME:3812.4s\n",
      "\t\t\t\tDisc: 0.725150\t\tSym: 14.563054\t\tSpars: 822.148132\n",
      "\t TVw: -0.116015 | TVb: -2.043202 | GSw: -0.234959 | GSb: 0.065047 | TSUw: 0.464946 | TSUb: 0.034786\n",
      "Validating epoch 1960...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 821.5821201169712\n",
      "Average validation loss: 86.91132254473494\n",
      "Training epoch 1961...\n",
      "\n",
      "Train Epoch: 1961 [0/8000 (0%)]\tBatch Loss: 811.108140\tLearning Rate (w_theta): 0.001000\t TIME:3815.7s\n",
      "\t\t\t\tDisc: 0.718543\t\tSym: 13.485727\t\tSpars: 796.903870\n",
      "\t TVw: -0.115394 | TVb: -2.043198 | GSw: -0.234959 | GSb: 0.065046 | TSUw: 0.464946 | TSUb: 0.034786\n",
      "\n",
      "Train Epoch: 1961 [4000/8000 (50%)]\tBatch Loss: 811.775315\tLearning Rate (w_theta): 0.001000\t TIME:3817.2s\n",
      "\t\t\t\tDisc: 0.652307\t\tSym: 13.557334\t\tSpars: 797.565674\n",
      "\t TVw: -0.114784 | TVb: -2.043194 | GSw: -0.234959 | GSb: 0.065046 | TSUw: 0.464946 | TSUb: 0.034786\n",
      "Validating epoch 1961...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 823.2714044697161\n",
      "Average validation loss: 86.99521212278417\n",
      "Training epoch 1962...\n",
      "\n",
      "Train Epoch: 1962 [0/8000 (0%)]\tBatch Loss: 794.900056\tLearning Rate (w_theta): 0.001000\t TIME:3819.6s\n",
      "\t\t\t\tDisc: 0.726465\t\tSym: 12.817574\t\tSpars: 781.356018\n",
      "\t TVw: -0.114170 | TVb: -2.043190 | GSw: -0.234959 | GSb: 0.065046 | TSUw: 0.464946 | TSUb: 0.034786\n",
      "\n",
      "Train Epoch: 1962 [4000/8000 (50%)]\tBatch Loss: 809.194042\tLearning Rate (w_theta): 0.001000\t TIME:3821.2s\n",
      "\t\t\t\tDisc: 0.650540\t\tSym: 12.954268\t\tSpars: 795.589233\n",
      "\t TVw: -0.113548 | TVb: -2.043186 | GSw: -0.234959 | GSb: 0.065046 | TSUw: 0.464946 | TSUb: 0.034786\n",
      "Validating epoch 1962...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 822.4463616168664\n",
      "Average validation loss: 85.98112248162776\n",
      "Training epoch 1963...\n",
      "\n",
      "Train Epoch: 1963 [0/8000 (0%)]\tBatch Loss: 788.616707\tLearning Rate (w_theta): 0.001000\t TIME:3823.5s\n",
      "\t\t\t\tDisc: 0.618893\t\tSym: 12.275707\t\tSpars: 775.722107\n",
      "\t TVw: -0.112929 | TVb: -2.043183 | GSw: -0.234959 | GSb: 0.065046 | TSUw: 0.464946 | TSUb: 0.034786\n",
      "\n",
      "Train Epoch: 1963 [4000/8000 (50%)]\tBatch Loss: 839.575838\tLearning Rate (w_theta): 0.001000\t TIME:3825.1s\n",
      "\t\t\t\tDisc: 0.781488\t\tSym: 15.230202\t\tSpars: 823.564148\n",
      "\t TVw: -0.112308 | TVb: -2.043180 | GSw: -0.234959 | GSb: 0.065046 | TSUw: 0.464946 | TSUb: 0.034786\n",
      "Validating epoch 1963...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 825.435398597843\n",
      "Average validation loss: 87.41040236654334\n",
      "Training epoch 1964...\n",
      "\n",
      "Train Epoch: 1964 [0/8000 (0%)]\tBatch Loss: 837.440702\tLearning Rate (w_theta): 0.001000\t TIME:3827.5s\n",
      "\t\t\t\tDisc: 0.765399\t\tSym: 15.211252\t\tSpars: 821.464050\n",
      "\t TVw: -0.111679 | TVb: -2.043176 | GSw: -0.234959 | GSb: 0.065046 | TSUw: 0.464946 | TSUb: 0.034786\n",
      "\n",
      "Train Epoch: 1964 [4000/8000 (50%)]\tBatch Loss: 809.084888\tLearning Rate (w_theta): 0.001000\t TIME:3829.1s\n",
      "\t\t\t\tDisc: 0.693239\t\tSym: 13.763048\t\tSpars: 794.628601\n",
      "\t TVw: -0.111041 | TVb: -2.043171 | GSw: -0.234959 | GSb: 0.065046 | TSUw: 0.464946 | TSUb: 0.034786\n",
      "Validating epoch 1964...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 820.7813351897578\n",
      "Average validation loss: 85.6538361954772\n",
      "Training epoch 1965...\n",
      "\n",
      "Train Epoch: 1965 [0/8000 (0%)]\tBatch Loss: 830.774188\tLearning Rate (w_theta): 0.001000\t TIME:3831.5s\n",
      "\t\t\t\tDisc: 0.683249\t\tSym: 13.576474\t\tSpars: 816.514465\n",
      "\t TVw: -0.110416 | TVb: -2.043167 | GSw: -0.234959 | GSb: 0.065046 | TSUw: 0.464946 | TSUb: 0.034786\n",
      "\n",
      "Train Epoch: 1965 [4000/8000 (50%)]\tBatch Loss: 810.686355\tLearning Rate (w_theta): 0.001000\t TIME:3833.0s\n",
      "\t\t\t\tDisc: 0.745551\t\tSym: 13.402901\t\tSpars: 796.537903\n",
      "\t TVw: -0.109788 | TVb: -2.043163 | GSw: -0.234959 | GSb: 0.065046 | TSUw: 0.464946 | TSUb: 0.034786\n",
      "Validating epoch 1965...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 819.7023955607137\n",
      "Average validation loss: 86.24066775430346\n",
      "Training epoch 1966...\n",
      "\n",
      "Train Epoch: 1966 [0/8000 (0%)]\tBatch Loss: 859.080688\tLearning Rate (w_theta): 0.001000\t TIME:3835.4s\n",
      "\t\t\t\tDisc: 0.772247\t\tSym: 15.072967\t\tSpars: 843.235474\n",
      "\t TVw: -0.109142 | TVb: -2.043159 | GSw: -0.234959 | GSb: 0.065046 | TSUw: 0.464946 | TSUb: 0.034786\n",
      "\n",
      "Train Epoch: 1966 [4000/8000 (50%)]\tBatch Loss: 817.378245\tLearning Rate (w_theta): 0.001000\t TIME:3836.9s\n",
      "\t\t\t\tDisc: 0.745685\t\tSym: 14.296439\t\tSpars: 802.336121\n",
      "\t TVw: -0.108509 | TVb: -2.043155 | GSw: -0.234959 | GSb: 0.065046 | TSUw: 0.464946 | TSUb: 0.034787\n",
      "Validating epoch 1966...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 817.7937121362522\n",
      "Average validation loss: 85.29735223449843\n",
      "Training epoch 1967...\n",
      "\n",
      "Train Epoch: 1967 [0/8000 (0%)]\tBatch Loss: 778.286813\tLearning Rate (w_theta): 0.001000\t TIME:3839.3s\n",
      "\t\t\t\tDisc: 0.598059\t\tSym: 12.037509\t\tSpars: 765.651245\n",
      "\t TVw: -0.107865 | TVb: -2.043152 | GSw: -0.234959 | GSb: 0.065046 | TSUw: 0.464946 | TSUb: 0.034787\n",
      "\n",
      "Train Epoch: 1967 [4000/8000 (50%)]\tBatch Loss: 849.760248\tLearning Rate (w_theta): 0.001000\t TIME:3840.9s\n",
      "\t\t\t\tDisc: 0.763550\t\tSym: 14.917536\t\tSpars: 834.079163\n",
      "\t TVw: -0.107229 | TVb: -2.043148 | GSw: -0.234959 | GSb: 0.065046 | TSUw: 0.464946 | TSUb: 0.034787\n",
      "Validating epoch 1967...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 817.5561130314921\n",
      "Average validation loss: 85.3692237192496\n",
      "Training epoch 1968...\n",
      "\n",
      "Train Epoch: 1968 [0/8000 (0%)]\tBatch Loss: 815.479110\tLearning Rate (w_theta): 0.001000\t TIME:3843.3s\n",
      "\t\t\t\tDisc: 0.744985\t\tSym: 14.222406\t\tSpars: 800.511719\n",
      "\t TVw: -0.106595 | TVb: -2.043143 | GSw: -0.234959 | GSb: 0.065046 | TSUw: 0.464946 | TSUb: 0.034787\n",
      "\n",
      "Train Epoch: 1968 [4000/8000 (50%)]\tBatch Loss: 819.228257\tLearning Rate (w_theta): 0.001000\t TIME:3844.8s\n",
      "\t\t\t\tDisc: 0.679325\t\tSym: 13.873639\t\tSpars: 804.675293\n",
      "\t TVw: -0.105964 | TVb: -2.043139 | GSw: -0.234959 | GSb: 0.065046 | TSUw: 0.464946 | TSUb: 0.034787\n",
      "Validating epoch 1968...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 815.8699295491236\n",
      "Average validation loss: 85.02442027672373\n",
      "Training epoch 1969...\n",
      "\n",
      "Train Epoch: 1969 [0/8000 (0%)]\tBatch Loss: 862.150131\tLearning Rate (w_theta): 0.001000\t TIME:3847.2s\n",
      "\t\t\t\tDisc: 0.794825\t\tSym: 15.722493\t\tSpars: 845.632812\n",
      "\t TVw: -0.105322 | TVb: -2.043134 | GSw: -0.234959 | GSb: 0.065046 | TSUw: 0.464946 | TSUb: 0.034787\n",
      "\n",
      "Train Epoch: 1969 [4000/8000 (50%)]\tBatch Loss: 800.411984\tLearning Rate (w_theta): 0.001000\t TIME:3848.7s\n",
      "\t\t\t\tDisc: 0.640647\t\tSym: 13.552953\t\tSpars: 786.218384\n",
      "\t TVw: -0.104713 | TVb: -2.043131 | GSw: -0.234959 | GSb: 0.065045 | TSUw: 0.464946 | TSUb: 0.034787\n",
      "Validating epoch 1969...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 817.8466135406652\n",
      "Average validation loss: 84.86475458355761\n",
      "Training epoch 1970...\n",
      "\n",
      "Train Epoch: 1970 [0/8000 (0%)]\tBatch Loss: 832.039653\tLearning Rate (w_theta): 0.001000\t TIME:3851.1s\n",
      "\t\t\t\tDisc: 0.698558\t\tSym: 14.659515\t\tSpars: 816.681580\n",
      "\t TVw: -0.104104 | TVb: -2.043127 | GSw: -0.234959 | GSb: 0.065045 | TSUw: 0.464946 | TSUb: 0.034787\n",
      "\n",
      "Train Epoch: 1970 [4000/8000 (50%)]\tBatch Loss: 861.775102\tLearning Rate (w_theta): 0.001000\t TIME:3852.7s\n",
      "\t\t\t\tDisc: 0.766255\t\tSym: 15.358579\t\tSpars: 845.650269\n",
      "\t TVw: -0.103488 | TVb: -2.043123 | GSw: -0.234959 | GSb: 0.065045 | TSUw: 0.464946 | TSUb: 0.034787\n",
      "Validating epoch 1970...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 814.3981594379202\n",
      "Average validation loss: 84.22717555492032\n",
      "Training epoch 1971...\n",
      "\n",
      "Train Epoch: 1971 [0/8000 (0%)]\tBatch Loss: 806.696919\tLearning Rate (w_theta): 0.001000\t TIME:3856.0s\n",
      "\t\t\t\tDisc: 0.599148\t\tSym: 13.638542\t\tSpars: 792.459229\n",
      "\t TVw: -0.102873 | TVb: -2.043121 | GSw: -0.234959 | GSb: 0.065045 | TSUw: 0.464946 | TSUb: 0.034787\n",
      "\n",
      "Train Epoch: 1971 [4000/8000 (50%)]\tBatch Loss: 846.887442\tLearning Rate (w_theta): 0.001000\t TIME:3857.6s\n",
      "\t\t\t\tDisc: 0.798575\t\tSym: 15.724182\t\tSpars: 830.364685\n",
      "\t TVw: -0.102224 | TVb: -2.043116 | GSw: -0.234959 | GSb: 0.065045 | TSUw: 0.464946 | TSUb: 0.034787\n",
      "Validating epoch 1971...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 813.7778059439893\n",
      "Average validation loss: 84.3834371698284\n",
      "Training epoch 1972...\n",
      "\n",
      "Train Epoch: 1972 [0/8000 (0%)]\tBatch Loss: 838.211903\tLearning Rate (w_theta): 0.001000\t TIME:3860.0s\n",
      "\t\t\t\tDisc: 0.730033\t\tSym: 14.901059\t\tSpars: 822.580811\n",
      "\t TVw: -0.101571 | TVb: -2.043112 | GSw: -0.234959 | GSb: 0.065045 | TSUw: 0.464946 | TSUb: 0.034787\n",
      "\n",
      "Train Epoch: 1972 [4000/8000 (50%)]\tBatch Loss: 856.636973\tLearning Rate (w_theta): 0.001000\t TIME:3861.5s\n",
      "\t\t\t\tDisc: 0.742192\t\tSym: 16.377874\t\tSpars: 839.516907\n",
      "\t TVw: -0.100948 | TVb: -2.043108 | GSw: -0.234959 | GSb: 0.065045 | TSUw: 0.464946 | TSUb: 0.034787\n",
      "Validating epoch 1972...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 812.9288534377664\n",
      "Average validation loss: 83.6690020310625\n",
      "Training epoch 1973...\n",
      "\n",
      "Train Epoch: 1973 [0/8000 (0%)]\tBatch Loss: 805.192493\tLearning Rate (w_theta): 0.001000\t TIME:3863.9s\n",
      "\t\t\t\tDisc: 0.669422\t\tSym: 13.863281\t\tSpars: 790.659790\n",
      "\t TVw: -0.100327 | TVb: -2.043104 | GSw: -0.234959 | GSb: 0.065045 | TSUw: 0.464946 | TSUb: 0.034787\n",
      "\n",
      "Train Epoch: 1973 [4000/8000 (50%)]\tBatch Loss: 811.559802\tLearning Rate (w_theta): 0.001000\t TIME:3865.4s\n",
      "\t\t\t\tDisc: 0.765004\t\tSym: 14.479674\t\tSpars: 796.315125\n",
      "\t TVw: -0.099698 | TVb: -2.043100 | GSw: -0.234959 | GSb: 0.065045 | TSUw: 0.464946 | TSUb: 0.034787\n",
      "Validating epoch 1973...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 814.081702954899\n",
      "Average validation loss: 83.64920576363824\n",
      "Training epoch 1974...\n",
      "\n",
      "Train Epoch: 1974 [0/8000 (0%)]\tBatch Loss: 800.239638\tLearning Rate (w_theta): 0.001000\t TIME:3867.8s\n",
      "\t\t\t\tDisc: 0.708861\t\tSym: 13.070450\t\tSpars: 786.460327\n",
      "\t TVw: -0.099081 | TVb: -2.043097 | GSw: -0.234959 | GSb: 0.065045 | TSUw: 0.464946 | TSUb: 0.034787\n",
      "\n",
      "Train Epoch: 1974 [4000/8000 (50%)]\tBatch Loss: 789.983251\tLearning Rate (w_theta): 0.001000\t TIME:3869.4s\n",
      "\t\t\t\tDisc: 0.620551\t\tSym: 12.920074\t\tSpars: 776.442627\n",
      "\t TVw: -0.098472 | TVb: -2.043094 | GSw: -0.234959 | GSb: 0.065045 | TSUw: 0.464946 | TSUb: 0.034787\n",
      "Validating epoch 1974...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 811.4781747669662\n",
      "Average validation loss: 83.00752383260291\n",
      "Training epoch 1975...\n",
      "\n",
      "Train Epoch: 1975 [0/8000 (0%)]\tBatch Loss: 811.299454\tLearning Rate (w_theta): 0.001000\t TIME:3871.8s\n",
      "\t\t\t\tDisc: 0.690074\t\tSym: 13.331182\t\tSpars: 797.278198\n",
      "\t TVw: -0.097851 | TVb: -2.043090 | GSw: -0.234959 | GSb: 0.065045 | TSUw: 0.464946 | TSUb: 0.034787\n",
      "\n",
      "Train Epoch: 1975 [4000/8000 (50%)]\tBatch Loss: 817.297959\tLearning Rate (w_theta): 0.001000\t TIME:3873.4s\n",
      "\t\t\t\tDisc: 0.722126\t\tSym: 14.556729\t\tSpars: 802.019104\n",
      "\t TVw: -0.097230 | TVb: -2.043085 | GSw: -0.234959 | GSb: 0.065045 | TSUw: 0.464946 | TSUb: 0.034787\n",
      "Validating epoch 1975...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 815.3521715294319\n",
      "Average validation loss: 82.56190661332559\n",
      "Training epoch 1976...\n",
      "\n",
      "Train Epoch: 1976 [0/8000 (0%)]\tBatch Loss: 811.812291\tLearning Rate (w_theta): 0.001000\t TIME:3875.7s\n",
      "\t\t\t\tDisc: 0.688522\t\tSym: 14.312062\t\tSpars: 796.811707\n",
      "\t TVw: -0.096632 | TVb: -2.043081 | GSw: -0.234959 | GSb: 0.065045 | TSUw: 0.464946 | TSUb: 0.034787\n",
      "\n",
      "Train Epoch: 1976 [4000/8000 (50%)]\tBatch Loss: 801.033664\tLearning Rate (w_theta): 0.001000\t TIME:3877.3s\n",
      "\t\t\t\tDisc: 0.712105\t\tSym: 13.374171\t\tSpars: 786.947388\n",
      "\t TVw: -0.096028 | TVb: -2.043074 | GSw: -0.234959 | GSb: 0.065045 | TSUw: 0.464946 | TSUb: 0.034787\n",
      "Validating epoch 1976...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 817.6253369763555\n",
      "Average validation loss: 83.34167566274499\n",
      "Training epoch 1977...\n",
      "\n",
      "Train Epoch: 1977 [0/8000 (0%)]\tBatch Loss: 807.614561\tLearning Rate (w_theta): 0.001000\t TIME:3879.7s\n",
      "\t\t\t\tDisc: 0.721284\t\tSym: 13.108914\t\tSpars: 793.784363\n",
      "\t TVw: -0.095431 | TVb: -2.043066 | GSw: -0.234959 | GSb: 0.065045 | TSUw: 0.464946 | TSUb: 0.034787\n",
      "\n",
      "Train Epoch: 1977 [4000/8000 (50%)]\tBatch Loss: 831.417578\tLearning Rate (w_theta): 0.001000\t TIME:3881.2s\n",
      "\t\t\t\tDisc: 0.683471\t\tSym: 15.749305\t\tSpars: 814.984802\n",
      "\t TVw: -0.094875 | TVb: -2.043062 | GSw: -0.234959 | GSb: 0.065044 | TSUw: 0.464946 | TSUb: 0.034787\n",
      "Validating epoch 1977...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 816.775169257199\n",
      "Average validation loss: 82.52933728725286\n",
      "Training epoch 1978...\n",
      "\n",
      "Train Epoch: 1978 [0/8000 (0%)]\tBatch Loss: 805.964039\tLearning Rate (w_theta): 0.001000\t TIME:3883.6s\n",
      "\t\t\t\tDisc: 0.726940\t\tSym: 13.914040\t\tSpars: 791.323059\n",
      "\t TVw: -0.094320 | TVb: -2.043058 | GSw: -0.234959 | GSb: 0.065044 | TSUw: 0.464946 | TSUb: 0.034788\n",
      "\n",
      "Train Epoch: 1978 [4000/8000 (50%)]\tBatch Loss: 844.414691\tLearning Rate (w_theta): 0.001000\t TIME:3885.2s\n",
      "\t\t\t\tDisc: 0.652996\t\tSym: 14.975440\t\tSpars: 828.786255\n",
      "\t TVw: -0.093770 | TVb: -2.043055 | GSw: -0.234959 | GSb: 0.065044 | TSUw: 0.464946 | TSUb: 0.034788\n",
      "Validating epoch 1978...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 821.7741841040355\n",
      "Average validation loss: 82.46646716716468\n",
      "Training epoch 1979...\n",
      "\n",
      "Train Epoch: 1979 [0/8000 (0%)]\tBatch Loss: 822.460865\tLearning Rate (w_theta): 0.001000\t TIME:3887.6s\n",
      "\t\t\t\tDisc: 0.589502\t\tSym: 14.506311\t\tSpars: 807.365051\n",
      "\t TVw: -0.093255 | TVb: -2.043055 | GSw: -0.234959 | GSb: 0.065044 | TSUw: 0.464946 | TSUb: 0.034788\n",
      "\n",
      "Train Epoch: 1979 [4000/8000 (50%)]\tBatch Loss: 826.798831\tLearning Rate (w_theta): 0.001000\t TIME:3889.1s\n",
      "\t\t\t\tDisc: 0.620360\t\tSym: 13.480107\t\tSpars: 812.698364\n",
      "\t TVw: -0.092726 | TVb: -2.043054 | GSw: -0.234959 | GSb: 0.065044 | TSUw: 0.464946 | TSUb: 0.034788\n",
      "Validating epoch 1979...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 821.694198265208\n",
      "Average validation loss: 83.35087146048465\n",
      "Training epoch 1980...\n",
      "\n",
      "Train Epoch: 1980 [0/8000 (0%)]\tBatch Loss: 809.597806\tLearning Rate (w_theta): 0.001000\t TIME:3891.5s\n",
      "\t\t\t\tDisc: 0.666960\t\tSym: 13.645934\t\tSpars: 795.284912\n",
      "\t TVw: -0.092165 | TVb: -2.043051 | GSw: -0.234959 | GSb: 0.065044 | TSUw: 0.464946 | TSUb: 0.034788\n",
      "\n",
      "Train Epoch: 1980 [4000/8000 (50%)]\tBatch Loss: 834.801536\tLearning Rate (w_theta): 0.001000\t TIME:3893.1s\n",
      "\t\t\t\tDisc: 0.727348\t\tSym: 14.829437\t\tSpars: 819.244751\n",
      "\t TVw: -0.091553 | TVb: -2.043046 | GSw: -0.234959 | GSb: 0.065044 | TSUw: 0.464946 | TSUb: 0.034788\n",
      "Validating epoch 1980...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 813.7158417918031\n",
      "Average validation loss: 84.9697815445771\n",
      "Training epoch 1981...\n",
      "\n",
      "Train Epoch: 1981 [0/8000 (0%)]\tBatch Loss: 822.989019\tLearning Rate (w_theta): 0.001000\t TIME:3896.4s\n",
      "\t\t\t\tDisc: 0.677585\t\tSym: 14.122530\t\tSpars: 808.188904\n",
      "\t TVw: -0.090909 | TVb: -2.043038 | GSw: -0.234959 | GSb: 0.065044 | TSUw: 0.464946 | TSUb: 0.034788\n",
      "\n",
      "Train Epoch: 1981 [4000/8000 (50%)]\tBatch Loss: 810.567910\tLearning Rate (w_theta): 0.001000\t TIME:3897.9s\n",
      "\t\t\t\tDisc: 0.629915\t\tSym: 13.387641\t\tSpars: 796.550354\n",
      "\t TVw: -0.090286 | TVb: -2.043032 | GSw: -0.234959 | GSb: 0.065044 | TSUw: 0.464946 | TSUb: 0.034788\n",
      "Validating epoch 1981...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 816.6890952129606\n",
      "Average validation loss: 81.998291148976\n",
      "Training epoch 1982...\n",
      "\n",
      "Train Epoch: 1982 [0/8000 (0%)]\tBatch Loss: 820.847862\tLearning Rate (w_theta): 0.001000\t TIME:3900.3s\n",
      "\t\t\t\tDisc: 0.602299\t\tSym: 13.429095\t\tSpars: 806.816467\n",
      "\t TVw: -0.089627 | TVb: -2.043025 | GSw: -0.234959 | GSb: 0.065044 | TSUw: 0.464946 | TSUb: 0.034788\n",
      "\n",
      "Train Epoch: 1982 [4000/8000 (50%)]\tBatch Loss: 811.486274\tLearning Rate (w_theta): 0.001000\t TIME:3901.9s\n",
      "\t\t\t\tDisc: 0.613242\t\tSym: 14.656906\t\tSpars: 796.216125\n",
      "\t TVw: -0.088941 | TVb: -2.043018 | GSw: -0.234959 | GSb: 0.065044 | TSUw: 0.464946 | TSUb: 0.034788\n",
      "Validating epoch 1982...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 807.423297238437\n",
      "Average validation loss: 81.78185694005819\n",
      "Training epoch 1983...\n",
      "\n",
      "Train Epoch: 1983 [0/8000 (0%)]\tBatch Loss: 778.490960\tLearning Rate (w_theta): 0.001000\t TIME:3904.2s\n",
      "\t\t\t\tDisc: 0.609023\t\tSym: 12.647562\t\tSpars: 765.234375\n",
      "\t TVw: -0.088264 | TVb: -2.043011 | GSw: -0.234959 | GSb: 0.065044 | TSUw: 0.464946 | TSUb: 0.034788\n",
      "\n",
      "Train Epoch: 1983 [4000/8000 (50%)]\tBatch Loss: 863.304805\tLearning Rate (w_theta): 0.001000\t TIME:3905.8s\n",
      "\t\t\t\tDisc: 0.714285\t\tSym: 15.893010\t\tSpars: 846.697510\n",
      "\t TVw: -0.087604 | TVb: -2.043006 | GSw: -0.234959 | GSb: 0.065044 | TSUw: 0.464946 | TSUb: 0.034788\n",
      "Validating epoch 1983...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 806.3561636160971\n",
      "Average validation loss: 81.79183642154524\n",
      "Training epoch 1984...\n",
      "\n",
      "Train Epoch: 1984 [0/8000 (0%)]\tBatch Loss: 821.930365\tLearning Rate (w_theta): 0.001000\t TIME:3908.2s\n",
      "\t\t\t\tDisc: 0.691534\t\tSym: 15.040894\t\tSpars: 806.197937\n",
      "\t TVw: -0.086939 | TVb: -2.043001 | GSw: -0.234959 | GSb: 0.065044 | TSUw: 0.464946 | TSUb: 0.034788\n",
      "\n",
      "Train Epoch: 1984 [4000/8000 (50%)]\tBatch Loss: 815.072573\tLearning Rate (w_theta): 0.001000\t TIME:3909.8s\n",
      "\t\t\t\tDisc: 0.683716\t\tSym: 14.511232\t\tSpars: 799.877625\n",
      "\t TVw: -0.086278 | TVb: -2.042995 | GSw: -0.234959 | GSb: 0.065044 | TSUw: 0.464946 | TSUb: 0.034788\n",
      "Validating epoch 1984...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 805.6163095398066\n",
      "Average validation loss: 80.83234728092214\n",
      "Training epoch 1985...\n",
      "\n",
      "Train Epoch: 1985 [0/8000 (0%)]\tBatch Loss: 804.100077\tLearning Rate (w_theta): 0.001000\t TIME:3912.2s\n",
      "\t\t\t\tDisc: 0.693824\t\tSym: 14.179996\t\tSpars: 789.226257\n",
      "\t TVw: -0.085651 | TVb: -2.042992 | GSw: -0.234959 | GSb: 0.065044 | TSUw: 0.464946 | TSUb: 0.034788\n",
      "\n",
      "Train Epoch: 1985 [4000/8000 (50%)]\tBatch Loss: 841.535961\tLearning Rate (w_theta): 0.001000\t TIME:3913.7s\n",
      "\t\t\t\tDisc: 0.707650\t\tSym: 15.020816\t\tSpars: 825.807495\n",
      "\t TVw: -0.085011 | TVb: -2.042989 | GSw: -0.234959 | GSb: 0.065044 | TSUw: 0.464946 | TSUb: 0.034788\n",
      "Validating epoch 1985...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 803.80332289238\n",
      "Average validation loss: 80.54544211772414\n",
      "Training epoch 1986...\n",
      "\n",
      "Train Epoch: 1986 [0/8000 (0%)]\tBatch Loss: 813.172355\tLearning Rate (w_theta): 0.001000\t TIME:3916.1s\n",
      "\t\t\t\tDisc: 0.677270\t\tSym: 14.390227\t\tSpars: 798.104858\n",
      "\t TVw: -0.084351 | TVb: -2.042985 | GSw: -0.234959 | GSb: 0.065043 | TSUw: 0.464946 | TSUb: 0.034788\n",
      "\n",
      "Train Epoch: 1986 [4000/8000 (50%)]\tBatch Loss: 822.457205\tLearning Rate (w_theta): 0.001000\t TIME:3917.7s\n",
      "\t\t\t\tDisc: 0.706292\t\tSym: 14.674741\t\tSpars: 807.076172\n",
      "\t TVw: -0.083687 | TVb: -2.042980 | GSw: -0.234959 | GSb: 0.065043 | TSUw: 0.464946 | TSUb: 0.034788\n",
      "Validating epoch 1986...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 803.9257877024027\n",
      "Average validation loss: 80.76858079371684\n",
      "Training epoch 1987...\n",
      "\n",
      "Train Epoch: 1987 [0/8000 (0%)]\tBatch Loss: 865.848425\tLearning Rate (w_theta): 0.001000\t TIME:3920.0s\n",
      "\t\t\t\tDisc: 0.745144\t\tSym: 16.210703\t\tSpars: 848.892578\n",
      "\t TVw: -0.083045 | TVb: -2.042977 | GSw: -0.234959 | GSb: 0.065043 | TSUw: 0.464946 | TSUb: 0.034788\n",
      "\n",
      "Train Epoch: 1987 [4000/8000 (50%)]\tBatch Loss: 792.431283\tLearning Rate (w_theta): 0.001000\t TIME:3921.6s\n",
      "\t\t\t\tDisc: 0.567681\t\tSym: 12.981155\t\tSpars: 778.882446\n",
      "\t TVw: -0.082394 | TVb: -2.042973 | GSw: -0.234959 | GSb: 0.065043 | TSUw: 0.464946 | TSUb: 0.034788\n",
      "Validating epoch 1987...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 803.6999660584701\n",
      "Average validation loss: 80.84904155042133\n",
      "Training epoch 1988...\n",
      "\n",
      "Train Epoch: 1988 [0/8000 (0%)]\tBatch Loss: 827.932459\tLearning Rate (w_theta): 0.001000\t TIME:3924.0s\n",
      "\t\t\t\tDisc: 0.697708\t\tSym: 14.300913\t\tSpars: 812.933838\n",
      "\t TVw: -0.081760 | TVb: -2.042970 | GSw: -0.234959 | GSb: 0.065043 | TSUw: 0.464946 | TSUb: 0.034788\n",
      "\n",
      "Train Epoch: 1988 [4000/8000 (50%)]\tBatch Loss: 790.755324\tLearning Rate (w_theta): 0.001000\t TIME:3925.5s\n",
      "\t\t\t\tDisc: 0.739694\t\tSym: 13.751225\t\tSpars: 776.264404\n",
      "\t TVw: -0.081134 | TVb: -2.042966 | GSw: -0.234959 | GSb: 0.065043 | TSUw: 0.464946 | TSUb: 0.034788\n",
      "Validating epoch 1988...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 801.4415808577899\n",
      "Average validation loss: 80.31005535685988\n",
      "Training epoch 1989...\n",
      "\n",
      "Train Epoch: 1989 [0/8000 (0%)]\tBatch Loss: 820.928869\tLearning Rate (w_theta): 0.001000\t TIME:3927.9s\n",
      "\t\t\t\tDisc: 0.767619\t\tSym: 14.136043\t\tSpars: 806.025208\n",
      "\t TVw: -0.080501 | TVb: -2.042963 | GSw: -0.234959 | GSb: 0.065043 | TSUw: 0.464946 | TSUb: 0.034789\n",
      "\n",
      "Train Epoch: 1989 [4000/8000 (50%)]\tBatch Loss: 796.661499\tLearning Rate (w_theta): 0.001000\t TIME:3929.5s\n",
      "\t\t\t\tDisc: 0.656083\t\tSym: 12.882370\t\tSpars: 783.123047\n",
      "\t TVw: -0.079849 | TVb: -2.042959 | GSw: -0.234959 | GSb: 0.065043 | TSUw: 0.464946 | TSUb: 0.034789\n",
      "Validating epoch 1989...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 800.7484904491301\n",
      "Average validation loss: 81.12178739757891\n",
      "Training epoch 1990...\n",
      "\n",
      "Train Epoch: 1990 [0/8000 (0%)]\tBatch Loss: 832.180512\tLearning Rate (w_theta): 0.001000\t TIME:3932.1s\n",
      "\t\t\t\tDisc: 0.741947\t\tSym: 15.278165\t\tSpars: 816.160400\n",
      "\t TVw: -0.079201 | TVb: -2.042955 | GSw: -0.234959 | GSb: 0.065043 | TSUw: 0.464946 | TSUb: 0.034789\n",
      "\n",
      "Train Epoch: 1990 [4000/8000 (50%)]\tBatch Loss: 812.808680\tLearning Rate (w_theta): 0.001000\t TIME:3933.7s\n",
      "\t\t\t\tDisc: 0.662728\t\tSym: 14.174517\t\tSpars: 797.971436\n",
      "\t TVw: -0.078568 | TVb: -2.042951 | GSw: -0.234959 | GSb: 0.065043 | TSUw: 0.464946 | TSUb: 0.034789\n",
      "Validating epoch 1990...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 802.3522128149583\n",
      "Average validation loss: 80.0662625953841\n",
      "Training epoch 1991...\n",
      "\n",
      "Train Epoch: 1991 [0/8000 (0%)]\tBatch Loss: 789.137098\tLearning Rate (w_theta): 0.001000\t TIME:3936.8s\n",
      "\t\t\t\tDisc: 0.660263\t\tSym: 12.954740\t\tSpars: 775.522095\n",
      "\t TVw: -0.077932 | TVb: -2.042947 | GSw: -0.234959 | GSb: 0.065043 | TSUw: 0.464946 | TSUb: 0.034789\n",
      "\n",
      "Train Epoch: 1991 [4000/8000 (50%)]\tBatch Loss: 782.245221\tLearning Rate (w_theta): 0.001000\t TIME:3938.3s\n",
      "\t\t\t\tDisc: 0.629184\t\tSym: 12.905527\t\tSpars: 768.710510\n",
      "\t TVw: -0.077296 | TVb: -2.042944 | GSw: -0.234959 | GSb: 0.065043 | TSUw: 0.464946 | TSUb: 0.034789\n",
      "Validating epoch 1991...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 802.2451879779462\n",
      "Average validation loss: 80.52266316195355\n",
      "Training epoch 1992...\n",
      "\n",
      "Train Epoch: 1992 [0/8000 (0%)]\tBatch Loss: 830.841523\tLearning Rate (w_theta): 0.001000\t TIME:3940.7s\n",
      "\t\t\t\tDisc: 0.755762\t\tSym: 14.732368\t\tSpars: 815.353394\n",
      "\t TVw: -0.076652 | TVb: -2.042938 | GSw: -0.234959 | GSb: 0.065043 | TSUw: 0.464946 | TSUb: 0.034789\n",
      "\n",
      "Train Epoch: 1992 [4000/8000 (50%)]\tBatch Loss: 822.689356\tLearning Rate (w_theta): 0.001000\t TIME:3942.3s\n",
      "\t\t\t\tDisc: 0.649095\t\tSym: 15.413918\t\tSpars: 806.626343\n",
      "\t TVw: -0.076006 | TVb: -2.042932 | GSw: -0.234959 | GSb: 0.065043 | TSUw: 0.464946 | TSUb: 0.034789\n",
      "Validating epoch 1992...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 801.5091220265017\n",
      "Average validation loss: 80.01368405520338\n",
      "Training epoch 1993...\n",
      "\n",
      "Train Epoch: 1993 [0/8000 (0%)]\tBatch Loss: 820.530093\tLearning Rate (w_theta): 0.001000\t TIME:3944.7s\n",
      "\t\t\t\tDisc: 0.628678\t\tSym: 15.010668\t\tSpars: 804.890747\n",
      "\t TVw: -0.075346 | TVb: -2.042925 | GSw: -0.234959 | GSb: 0.065043 | TSUw: 0.464946 | TSUb: 0.034789\n",
      "\n",
      "Train Epoch: 1993 [4000/8000 (50%)]\tBatch Loss: 783.908022\tLearning Rate (w_theta): 0.001000\t TIME:3946.2s\n",
      "\t\t\t\tDisc: 0.679390\t\tSym: 13.539423\t\tSpars: 769.689209\n",
      "\t TVw: -0.074705 | TVb: -2.042919 | GSw: -0.234959 | GSb: 0.065043 | TSUw: 0.464946 | TSUb: 0.034789\n",
      "Validating epoch 1993...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 800.2170084066413\n",
      "Average validation loss: 78.65074849007291\n",
      "Training epoch 1994...\n",
      "\n",
      "Train Epoch: 1994 [0/8000 (0%)]\tBatch Loss: 768.074432\tLearning Rate (w_theta): 0.001000\t TIME:3948.6s\n",
      "\t\t\t\tDisc: 0.604854\t\tSym: 12.114841\t\tSpars: 755.354736\n",
      "\t TVw: -0.074082 | TVb: -2.042915 | GSw: -0.234959 | GSb: 0.065043 | TSUw: 0.464946 | TSUb: 0.034789\n",
      "\n",
      "Train Epoch: 1994 [4000/8000 (50%)]\tBatch Loss: 836.466174\tLearning Rate (w_theta): 0.001000\t TIME:3950.2s\n",
      "\t\t\t\tDisc: 0.732281\t\tSym: 16.079168\t\tSpars: 819.654724\n",
      "\t TVw: -0.073477 | TVb: -2.042911 | GSw: -0.234959 | GSb: 0.065042 | TSUw: 0.464946 | TSUb: 0.034789\n",
      "Validating epoch 1994...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 802.2600523820831\n",
      "Average validation loss: 80.62559751052778\n",
      "Training epoch 1995...\n",
      "\n",
      "Train Epoch: 1995 [0/8000 (0%)]\tBatch Loss: 846.669752\tLearning Rate (w_theta): 0.001000\t TIME:3952.5s\n",
      "\t\t\t\tDisc: 0.750085\t\tSym: 15.528554\t\tSpars: 830.391113\n",
      "\t TVw: -0.072858 | TVb: -2.042906 | GSw: -0.234959 | GSb: 0.065042 | TSUw: 0.464946 | TSUb: 0.034789\n",
      "\n",
      "Train Epoch: 1995 [4000/8000 (50%)]\tBatch Loss: 803.225574\tLearning Rate (w_theta): 0.001000\t TIME:3954.1s\n",
      "\t\t\t\tDisc: 0.544333\t\tSym: 13.417630\t\tSpars: 789.263611\n",
      "\t TVw: -0.072270 | TVb: -2.042904 | GSw: -0.234959 | GSb: 0.065042 | TSUw: 0.464946 | TSUb: 0.034789\n",
      "Validating epoch 1995...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 805.4958443381812\n",
      "Average validation loss: 78.81397741977592\n",
      "Training epoch 1996...\n",
      "\n",
      "Train Epoch: 1996 [0/8000 (0%)]\tBatch Loss: 796.479618\tLearning Rate (w_theta): 0.001000\t TIME:3956.5s\n",
      "\t\t\t\tDisc: 0.709461\t\tSym: 14.253677\t\tSpars: 781.516479\n",
      "\t TVw: -0.071707 | TVb: -2.042902 | GSw: -0.234959 | GSb: 0.065042 | TSUw: 0.464946 | TSUb: 0.034789\n",
      "\n",
      "Train Epoch: 1996 [4000/8000 (50%)]\tBatch Loss: 796.188989\tLearning Rate (w_theta): 0.001000\t TIME:3958.1s\n",
      "\t\t\t\tDisc: 0.628417\t\tSym: 14.076258\t\tSpars: 781.484314\n",
      "\t TVw: -0.071112 | TVb: -2.042898 | GSw: -0.234959 | GSb: 0.065042 | TSUw: 0.464946 | TSUb: 0.034789\n",
      "Validating epoch 1996...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 796.7035279986276\n",
      "Average validation loss: 78.69418706261027\n",
      "Training epoch 1997...\n",
      "\n",
      "Train Epoch: 1997 [0/8000 (0%)]\tBatch Loss: 780.158225\tLearning Rate (w_theta): 0.001000\t TIME:3960.5s\n",
      "\t\t\t\tDisc: 0.618500\t\tSym: 13.675895\t\tSpars: 765.863831\n",
      "\t TVw: -0.070498 | TVb: -2.042894 | GSw: -0.234959 | GSb: 0.065042 | TSUw: 0.464946 | TSUb: 0.034789\n",
      "\n",
      "Train Epoch: 1997 [4000/8000 (50%)]\tBatch Loss: 778.562411\tLearning Rate (w_theta): 0.001000\t TIME:3962.0s\n",
      "\t\t\t\tDisc: 0.592478\t\tSym: 12.921776\t\tSpars: 765.048157\n",
      "\t TVw: -0.069866 | TVb: -2.042890 | GSw: -0.234959 | GSb: 0.065042 | TSUw: 0.464946 | TSUb: 0.034789\n",
      "Validating epoch 1997...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 795.9575501493789\n",
      "Average validation loss: 79.73642448383318\n",
      "Training epoch 1998...\n",
      "\n",
      "Train Epoch: 1998 [0/8000 (0%)]\tBatch Loss: 820.886091\tLearning Rate (w_theta): 0.001000\t TIME:3964.4s\n",
      "\t\t\t\tDisc: 0.688053\t\tSym: 15.021280\t\tSpars: 805.176758\n",
      "\t TVw: -0.069219 | TVb: -2.042885 | GSw: -0.234959 | GSb: 0.065042 | TSUw: 0.464946 | TSUb: 0.034789\n",
      "\n",
      "Train Epoch: 1998 [4000/8000 (50%)]\tBatch Loss: 796.825185\tLearning Rate (w_theta): 0.001000\t TIME:3965.9s\n",
      "\t\t\t\tDisc: 0.659760\t\tSym: 13.561727\t\tSpars: 782.603699\n",
      "\t TVw: -0.068560 | TVb: -2.042880 | GSw: -0.234959 | GSb: 0.065042 | TSUw: 0.464946 | TSUb: 0.034789\n",
      "Validating epoch 1998...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 796.5611693381085\n",
      "Average validation loss: 78.39503470568725\n",
      "Training epoch 1999...\n",
      "\n",
      "Train Epoch: 1999 [0/8000 (0%)]\tBatch Loss: 772.201326\tLearning Rate (w_theta): 0.001000\t TIME:3968.6s\n",
      "\t\t\t\tDisc: 0.570586\t\tSym: 12.754519\t\tSpars: 758.876221\n",
      "\t TVw: -0.067904 | TVb: -2.042875 | GSw: -0.234959 | GSb: 0.065042 | TSUw: 0.464946 | TSUb: 0.034789\n",
      "\n",
      "Train Epoch: 1999 [4000/8000 (50%)]\tBatch Loss: 836.246594\tLearning Rate (w_theta): 0.001000\t TIME:3970.2s\n",
      "\t\t\t\tDisc: 0.701534\t\tSym: 14.345840\t\tSpars: 821.199219\n",
      "\t TVw: -0.067270 | TVb: -2.042872 | GSw: -0.234959 | GSb: 0.065042 | TSUw: 0.464946 | TSUb: 0.034789\n",
      "Validating epoch 1999...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 800.1629434789312\n",
      "Average validation loss: 79.83273441073285\n",
      "Training epoch 2000...\n",
      "\n",
      "Train Epoch: 2000 [0/8000 (0%)]\tBatch Loss: 780.294636\tLearning Rate (w_theta): 0.001000\t TIME:3972.6s\n",
      "\t\t\t\tDisc: 0.636606\t\tSym: 13.400767\t\tSpars: 766.257263\n",
      "\t TVw: -0.066635 | TVb: -2.042868 | GSw: -0.234959 | GSb: 0.065042 | TSUw: 0.464946 | TSUb: 0.034790\n",
      "\n",
      "Train Epoch: 2000 [4000/8000 (50%)]\tBatch Loss: 828.325051\tLearning Rate (w_theta): 0.001000\t TIME:3974.1s\n",
      "\t\t\t\tDisc: 0.582258\t\tSym: 13.978023\t\tSpars: 813.764771\n",
      "\t TVw: -0.066001 | TVb: -2.042861 | GSw: -0.234959 | GSb: 0.065042 | TSUw: 0.464946 | TSUb: 0.034790\n",
      "Validating epoch 2000...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 803.3165525103269\n",
      "Average validation loss: 77.45487127001809\n",
      "Training epoch 2001...\n",
      "\n",
      "Train Epoch: 2001 [0/8000 (0%)]\tBatch Loss: 802.286955\tLearning Rate (w_theta): 0.001000\t TIME:3977.1s\n",
      "\t\t\t\tDisc: 0.636127\t\tSym: 13.146373\t\tSpars: 788.504456\n",
      "\t TVw: -0.065409 | TVb: -2.042856 | GSw: -0.234959 | GSb: 0.065042 | TSUw: 0.464946 | TSUb: 0.034790\n",
      "\n",
      "Train Epoch: 2001 [4000/8000 (50%)]\tBatch Loss: 787.502447\tLearning Rate (w_theta): 0.001000\t TIME:3978.7s\n",
      "\t\t\t\tDisc: 0.673254\t\tSym: 13.094452\t\tSpars: 773.734741\n",
      "\t TVw: -0.064811 | TVb: -2.042851 | GSw: -0.234959 | GSb: 0.065042 | TSUw: 0.464946 | TSUb: 0.034790\n",
      "Validating epoch 2001...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 799.2362593520946\n",
      "Average validation loss: 79.75063374878282\n",
      "Training epoch 2002...\n",
      "\n",
      "Train Epoch: 2002 [0/8000 (0%)]\tBatch Loss: 780.301433\tLearning Rate (w_theta): 0.001000\t TIME:3981.1s\n",
      "\t\t\t\tDisc: 0.637094\t\tSym: 13.554842\t\tSpars: 766.109497\n",
      "\t TVw: -0.064187 | TVb: -2.042844 | GSw: -0.234959 | GSb: 0.065042 | TSUw: 0.464946 | TSUb: 0.034790\n",
      "\n",
      "Train Epoch: 2002 [4000/8000 (50%)]\tBatch Loss: 773.818903\tLearning Rate (w_theta): 0.001000\t TIME:3982.7s\n",
      "\t\t\t\tDisc: 0.604708\t\tSym: 12.754906\t\tSpars: 760.459290\n",
      "\t TVw: -0.063561 | TVb: -2.042836 | GSw: -0.234959 | GSb: 0.065042 | TSUw: 0.464946 | TSUb: 0.034790\n",
      "Validating epoch 2002...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 801.8360286943262\n",
      "Average validation loss: 76.37211353101236\n",
      "Training epoch 2003...\n",
      "\n",
      "Train Epoch: 2003 [0/8000 (0%)]\tBatch Loss: 807.828360\tLearning Rate (w_theta): 0.001000\t TIME:3985.1s\n",
      "\t\t\t\tDisc: 0.584777\t\tSym: 14.853020\t\tSpars: 792.390564\n",
      "\t TVw: -0.062968 | TVb: -2.042830 | GSw: -0.234959 | GSb: 0.065041 | TSUw: 0.464946 | TSUb: 0.034790\n",
      "\n",
      "Train Epoch: 2003 [4000/8000 (50%)]\tBatch Loss: 791.600597\tLearning Rate (w_theta): 0.001000\t TIME:3986.6s\n",
      "\t\t\t\tDisc: 0.601811\t\tSym: 13.748908\t\tSpars: 777.249878\n",
      "\t TVw: -0.062399 | TVb: -2.042826 | GSw: -0.234959 | GSb: 0.065041 | TSUw: 0.464946 | TSUb: 0.034790\n",
      "Validating epoch 2003...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 798.2176886008582\n",
      "Average validation loss: 78.32345206671488\n",
      "Training epoch 2004...\n",
      "\n",
      "Train Epoch: 2004 [0/8000 (0%)]\tBatch Loss: 779.011747\tLearning Rate (w_theta): 0.001000\t TIME:3989.1s\n",
      "\t\t\t\tDisc: 0.648795\t\tSym: 12.549964\t\tSpars: 765.812988\n",
      "\t TVw: -0.061831 | TVb: -2.042822 | GSw: -0.234959 | GSb: 0.065041 | TSUw: 0.464946 | TSUb: 0.034790\n",
      "\n",
      "Train Epoch: 2004 [4000/8000 (50%)]\tBatch Loss: 778.099356\tLearning Rate (w_theta): 0.001000\t TIME:3990.6s\n",
      "\t\t\t\tDisc: 0.616309\t\tSym: 12.544693\t\tSpars: 764.938354\n",
      "\t TVw: -0.061238 | TVb: -2.042817 | GSw: -0.234959 | GSb: 0.065041 | TSUw: 0.464946 | TSUb: 0.034790\n",
      "Validating epoch 2004...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 794.5973955339985\n",
      "Average validation loss: 77.82654728437859\n",
      "Training epoch 2005...\n",
      "\n",
      "Train Epoch: 2005 [0/8000 (0%)]\tBatch Loss: 771.742536\tLearning Rate (w_theta): 0.001000\t TIME:3993.0s\n",
      "\t\t\t\tDisc: 0.635951\t\tSym: 12.928545\t\tSpars: 758.178040\n",
      "\t TVw: -0.060630 | TVb: -2.042811 | GSw: -0.234959 | GSb: 0.065041 | TSUw: 0.464946 | TSUb: 0.034790\n",
      "\n",
      "Train Epoch: 2005 [4000/8000 (50%)]\tBatch Loss: 789.171499\tLearning Rate (w_theta): 0.001000\t TIME:3994.5s\n",
      "\t\t\t\tDisc: 0.571106\t\tSym: 13.050221\t\tSpars: 775.550171\n",
      "\t TVw: -0.060029 | TVb: -2.042807 | GSw: -0.234959 | GSb: 0.065041 | TSUw: 0.464946 | TSUb: 0.034790\n",
      "Validating epoch 2005...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 791.7416101956879\n",
      "Average validation loss: 76.40250214427876\n",
      "Training epoch 2006...\n",
      "\n",
      "Train Epoch: 2006 [0/8000 (0%)]\tBatch Loss: 776.321115\tLearning Rate (w_theta): 0.001000\t TIME:3996.9s\n",
      "\t\t\t\tDisc: 0.605689\t\tSym: 13.101473\t\tSpars: 762.613953\n",
      "\t TVw: -0.059381 | TVb: -2.042803 | GSw: -0.234959 | GSb: 0.065041 | TSUw: 0.464946 | TSUb: 0.034790\n",
      "\n",
      "Train Epoch: 2006 [4000/8000 (50%)]\tBatch Loss: 827.667906\tLearning Rate (w_theta): 0.001000\t TIME:3998.5s\n",
      "\t\t\t\tDisc: 0.681118\t\tSym: 14.961336\t\tSpars: 812.025452\n",
      "\t TVw: -0.058741 | TVb: -2.042799 | GSw: -0.234959 | GSb: 0.065041 | TSUw: 0.464946 | TSUb: 0.034790\n",
      "Validating epoch 2006...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 792.5685762377668\n",
      "Average validation loss: 76.97805998176803\n",
      "Training epoch 2007...\n",
      "\n",
      "Train Epoch: 2007 [0/8000 (0%)]\tBatch Loss: 829.163178\tLearning Rate (w_theta): 0.001000\t TIME:4000.9s\n",
      "\t\t\t\tDisc: 0.620019\t\tSym: 15.383858\t\tSpars: 813.159302\n",
      "\t TVw: -0.058063 | TVb: -2.042794 | GSw: -0.234959 | GSb: 0.065041 | TSUw: 0.464946 | TSUb: 0.034790\n",
      "\n",
      "Train Epoch: 2007 [4000/8000 (50%)]\tBatch Loss: 775.319470\tLearning Rate (w_theta): 0.001000\t TIME:4002.5s\n",
      "\t\t\t\tDisc: 0.646993\t\tSym: 12.885490\t\tSpars: 761.786987\n",
      "\t TVw: -0.057352 | TVb: -2.042788 | GSw: -0.234959 | GSb: 0.065041 | TSUw: 0.464946 | TSUb: 0.034790\n",
      "Validating epoch 2007...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 787.8491415444075\n",
      "Average validation loss: 76.6050184283934\n",
      "Training epoch 2008...\n",
      "\n",
      "Train Epoch: 2008 [0/8000 (0%)]\tBatch Loss: 766.674617\tLearning Rate (w_theta): 0.001000\t TIME:4005.1s\n",
      "\t\t\t\tDisc: 0.592019\t\tSym: 12.889789\t\tSpars: 753.192810\n",
      "\t TVw: -0.056657 | TVb: -2.042784 | GSw: -0.234959 | GSb: 0.065041 | TSUw: 0.464946 | TSUb: 0.034790\n",
      "\n",
      "Train Epoch: 2008 [4000/8000 (50%)]\tBatch Loss: 800.078499\tLearning Rate (w_theta): 0.001000\t TIME:4006.7s\n",
      "\t\t\t\tDisc: 0.685494\t\tSym: 14.017761\t\tSpars: 785.375244\n",
      "\t TVw: -0.055985 | TVb: -2.042781 | GSw: -0.234959 | GSb: 0.065041 | TSUw: 0.464946 | TSUb: 0.034790\n",
      "Validating epoch 2008...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 787.496716887338\n",
      "Average validation loss: 76.71389157414517\n",
      "Training epoch 2009...\n",
      "\n",
      "Train Epoch: 2009 [0/8000 (0%)]\tBatch Loss: 763.500986\tLearning Rate (w_theta): 0.001000\t TIME:4009.1s\n",
      "\t\t\t\tDisc: 0.629478\t\tSym: 12.559009\t\tSpars: 750.312500\n",
      "\t TVw: -0.055309 | TVb: -2.042777 | GSw: -0.234959 | GSb: 0.065041 | TSUw: 0.464946 | TSUb: 0.034790\n",
      "\n",
      "Train Epoch: 2009 [4000/8000 (50%)]\tBatch Loss: 810.893717\tLearning Rate (w_theta): 0.001000\t TIME:4010.6s\n",
      "\t\t\t\tDisc: 0.628947\t\tSym: 14.546142\t\tSpars: 795.718628\n",
      "\t TVw: -0.054619 | TVb: -2.042771 | GSw: -0.234959 | GSb: 0.065041 | TSUw: 0.464946 | TSUb: 0.034790\n",
      "Validating epoch 2009...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 787.4302586011286\n",
      "Average validation loss: 76.54411029159218\n",
      "Training epoch 2010...\n",
      "\n",
      "Train Epoch: 2010 [0/8000 (0%)]\tBatch Loss: 751.651094\tLearning Rate (w_theta): 0.001000\t TIME:4013.0s\n",
      "\t\t\t\tDisc: 0.594436\t\tSym: 12.240435\t\tSpars: 738.816223\n",
      "\t TVw: -0.053939 | TVb: -2.042765 | GSw: -0.234959 | GSb: 0.065041 | TSUw: 0.464946 | TSUb: 0.034790\n",
      "\n",
      "Train Epoch: 2010 [4000/8000 (50%)]\tBatch Loss: 792.819786\tLearning Rate (w_theta): 0.001000\t TIME:4014.6s\n",
      "\t\t\t\tDisc: 0.660543\t\tSym: 13.548586\t\tSpars: 778.610657\n",
      "\t TVw: -0.053278 | TVb: -2.042759 | GSw: -0.234959 | GSb: 0.065041 | TSUw: 0.464946 | TSUb: 0.034790\n",
      "Validating epoch 2010...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 788.2721306764902\n",
      "Average validation loss: 75.38429132662897\n",
      "Training epoch 2011...\n",
      "\n",
      "Train Epoch: 2011 [0/8000 (0%)]\tBatch Loss: 786.211184\tLearning Rate (w_theta): 0.001000\t TIME:4017.8s\n",
      "\t\t\t\tDisc: 0.562649\t\tSym: 13.466712\t\tSpars: 772.181824\n",
      "\t TVw: -0.052629 | TVb: -2.042754 | GSw: -0.234959 | GSb: 0.065041 | TSUw: 0.464946 | TSUb: 0.034790\n",
      "\n",
      "Train Epoch: 2011 [4000/8000 (50%)]\tBatch Loss: 781.415729\tLearning Rate (w_theta): 0.001000\t TIME:4019.3s\n",
      "\t\t\t\tDisc: 0.633075\t\tSym: 13.257568\t\tSpars: 767.525085\n",
      "\t TVw: -0.052000 | TVb: -2.042747 | GSw: -0.234959 | GSb: 0.065040 | TSUw: 0.464946 | TSUb: 0.034791\n",
      "Validating epoch 2011...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 787.81324228773\n",
      "Average validation loss: 75.9175287786454\n",
      "Training epoch 2012...\n",
      "\n",
      "Train Epoch: 2012 [0/8000 (0%)]\tBatch Loss: 802.590575\tLearning Rate (w_theta): 0.001000\t TIME:4021.8s\n",
      "\t\t\t\tDisc: 0.701087\t\tSym: 14.110251\t\tSpars: 787.779236\n",
      "\t TVw: -0.051395 | TVb: -2.042742 | GSw: -0.234959 | GSb: 0.065040 | TSUw: 0.464946 | TSUb: 0.034791\n",
      "\n",
      "Train Epoch: 2012 [4000/8000 (50%)]\tBatch Loss: 803.455546\tLearning Rate (w_theta): 0.001000\t TIME:4023.3s\n",
      "\t\t\t\tDisc: 0.652870\t\tSym: 14.571231\t\tSpars: 788.231445\n",
      "\t TVw: -0.050789 | TVb: -2.042738 | GSw: -0.234959 | GSb: 0.065040 | TSUw: 0.464946 | TSUb: 0.034791\n",
      "Validating epoch 2012...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 783.7948165859019\n",
      "Average validation loss: 76.09460819438215\n",
      "Training epoch 2013...\n",
      "\n",
      "Train Epoch: 2013 [0/8000 (0%)]\tBatch Loss: 774.674151\tLearning Rate (w_theta): 0.001000\t TIME:4025.7s\n",
      "\t\t\t\tDisc: 0.631254\t\tSym: 13.224843\t\tSpars: 760.818054\n",
      "\t TVw: -0.050164 | TVb: -2.042732 | GSw: -0.234959 | GSb: 0.065040 | TSUw: 0.464946 | TSUb: 0.034791\n",
      "\n",
      "Train Epoch: 2013 [4000/8000 (50%)]\tBatch Loss: 787.374046\tLearning Rate (w_theta): 0.001000\t TIME:4027.3s\n",
      "\t\t\t\tDisc: 0.589013\t\tSym: 14.279479\t\tSpars: 772.505554\n",
      "\t TVw: -0.049549 | TVb: -2.042727 | GSw: -0.234959 | GSb: 0.065040 | TSUw: 0.464946 | TSUb: 0.034791\n",
      "Validating epoch 2013...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 785.9889727120798\n",
      "Average validation loss: 74.72857115386203\n",
      "Training epoch 2014...\n",
      "\n",
      "Train Epoch: 2014 [0/8000 (0%)]\tBatch Loss: 777.739224\tLearning Rate (w_theta): 0.001000\t TIME:4029.7s\n",
      "\t\t\t\tDisc: 0.631216\t\tSym: 13.598548\t\tSpars: 763.509460\n",
      "\t TVw: -0.048937 | TVb: -2.042723 | GSw: -0.234959 | GSb: 0.065040 | TSUw: 0.464946 | TSUb: 0.034791\n",
      "\n",
      "Train Epoch: 2014 [4000/8000 (50%)]\tBatch Loss: 812.077026\tLearning Rate (w_theta): 0.001000\t TIME:4031.2s\n",
      "\t\t\t\tDisc: 0.641846\t\tSym: 14.562926\t\tSpars: 796.872253\n",
      "\t TVw: -0.048290 | TVb: -2.042716 | GSw: -0.234959 | GSb: 0.065040 | TSUw: 0.464946 | TSUb: 0.034791\n",
      "Validating epoch 2014...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 791.6016067266402\n",
      "Average validation loss: 76.46490436253478\n",
      "Training epoch 2015...\n",
      "\n",
      "Train Epoch: 2015 [0/8000 (0%)]\tBatch Loss: 777.357122\tLearning Rate (w_theta): 0.001000\t TIME:4033.7s\n",
      "\t\t\t\tDisc: 0.553503\t\tSym: 13.430267\t\tSpars: 763.373352\n",
      "\t TVw: -0.047648 | TVb: -2.042707 | GSw: -0.234959 | GSb: 0.065040 | TSUw: 0.464946 | TSUb: 0.034791\n",
      "\n",
      "Train Epoch: 2015 [4000/8000 (50%)]\tBatch Loss: 808.619271\tLearning Rate (w_theta): 0.001000\t TIME:4035.3s\n",
      "\t\t\t\tDisc: 0.665915\t\tSym: 14.620714\t\tSpars: 793.332642\n",
      "\t TVw: -0.047022 | TVb: -2.042700 | GSw: -0.234959 | GSb: 0.065040 | TSUw: 0.464946 | TSUb: 0.034791\n",
      "Validating epoch 2015...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 791.8496929110196\n",
      "Average validation loss: 73.82600873695075\n",
      "Training epoch 2016...\n",
      "\n",
      "Train Epoch: 2016 [0/8000 (0%)]\tBatch Loss: 773.766501\tLearning Rate (w_theta): 0.001000\t TIME:4037.6s\n",
      "\t\t\t\tDisc: 0.578496\t\tSym: 12.131181\t\tSpars: 761.056824\n",
      "\t TVw: -0.046407 | TVb: -2.042692 | GSw: -0.234959 | GSb: 0.065040 | TSUw: 0.464946 | TSUb: 0.034791\n",
      "\n",
      "Train Epoch: 2016 [4000/8000 (50%)]\tBatch Loss: 812.813758\tLearning Rate (w_theta): 0.001000\t TIME:4039.2s\n",
      "\t\t\t\tDisc: 0.614961\t\tSym: 14.417607\t\tSpars: 797.781189\n",
      "\t TVw: -0.045827 | TVb: -2.042688 | GSw: -0.234959 | GSb: 0.065040 | TSUw: 0.464946 | TSUb: 0.034791\n",
      "Validating epoch 2016...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 786.1685601095124\n",
      "Average validation loss: 74.62890181379755\n",
      "Training epoch 2017...\n",
      "\n",
      "Train Epoch: 2017 [0/8000 (0%)]\tBatch Loss: 760.653910\tLearning Rate (w_theta): 0.001000\t TIME:4041.6s\n",
      "\t\t\t\tDisc: 0.648237\t\tSym: 12.802976\t\tSpars: 747.202698\n",
      "\t TVw: -0.045243 | TVb: -2.042684 | GSw: -0.234959 | GSb: 0.065040 | TSUw: 0.464946 | TSUb: 0.034791\n",
      "\n",
      "Train Epoch: 2017 [4000/8000 (50%)]\tBatch Loss: 797.317551\tLearning Rate (w_theta): 0.001000\t TIME:4043.2s\n",
      "\t\t\t\tDisc: 0.626951\t\tSym: 13.863818\t\tSpars: 782.826782\n",
      "\t TVw: -0.044645 | TVb: -2.042680 | GSw: -0.234959 | GSb: 0.065040 | TSUw: 0.464946 | TSUb: 0.034791\n",
      "Validating epoch 2017...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 783.8280203314692\n",
      "Average validation loss: 75.70705582898425\n",
      "Training epoch 2018...\n",
      "\n",
      "Train Epoch: 2018 [0/8000 (0%)]\tBatch Loss: 768.959475\tLearning Rate (w_theta): 0.001000\t TIME:4045.9s\n",
      "\t\t\t\tDisc: 0.554185\t\tSym: 13.041033\t\tSpars: 755.364258\n",
      "\t TVw: -0.044017 | TVb: -2.042675 | GSw: -0.234959 | GSb: 0.065040 | TSUw: 0.464946 | TSUb: 0.034791\n",
      "\n",
      "Train Epoch: 2018 [4000/8000 (50%)]\tBatch Loss: 752.118255\tLearning Rate (w_theta): 0.001000\t TIME:4047.5s\n",
      "\t\t\t\tDisc: 0.572475\t\tSym: 12.526066\t\tSpars: 739.019714\n",
      "\t TVw: -0.043345 | TVb: -2.042669 | GSw: -0.234959 | GSb: 0.065040 | TSUw: 0.464946 | TSUb: 0.034791\n",
      "Validating epoch 2018...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 782.7585320635056\n",
      "Average validation loss: 74.50514279824714\n",
      "Training epoch 2019...\n",
      "\n",
      "Train Epoch: 2019 [0/8000 (0%)]\tBatch Loss: 787.043740\tLearning Rate (w_theta): 0.001000\t TIME:4049.9s\n",
      "\t\t\t\tDisc: 0.622044\t\tSym: 13.320012\t\tSpars: 773.101685\n",
      "\t TVw: -0.042704 | TVb: -2.042663 | GSw: -0.234959 | GSb: 0.065040 | TSUw: 0.464946 | TSUb: 0.034791\n",
      "\n",
      "Train Epoch: 2019 [4000/8000 (50%)]\tBatch Loss: 773.042509\tLearning Rate (w_theta): 0.001000\t TIME:4051.5s\n",
      "\t\t\t\tDisc: 0.514001\t\tSym: 13.944646\t\tSpars: 758.583862\n",
      "\t TVw: -0.042072 | TVb: -2.042658 | GSw: -0.234959 | GSb: 0.065039 | TSUw: 0.464946 | TSUb: 0.034791\n",
      "Validating epoch 2019...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 781.2345986894198\n",
      "Average validation loss: 73.5932162579129\n",
      "Training epoch 2020...\n",
      "\n",
      "Train Epoch: 2020 [0/8000 (0%)]\tBatch Loss: 778.887906\tLearning Rate (w_theta): 0.001000\t TIME:4053.9s\n",
      "\t\t\t\tDisc: 0.518713\t\tSym: 12.872489\t\tSpars: 765.496704\n",
      "\t TVw: -0.041460 | TVb: -2.042654 | GSw: -0.234959 | GSb: 0.065039 | TSUw: 0.464946 | TSUb: 0.034791\n",
      "\n",
      "Train Epoch: 2020 [4000/8000 (50%)]\tBatch Loss: 740.920528\tLearning Rate (w_theta): 0.001000\t TIME:4055.4s\n",
      "\t\t\t\tDisc: 0.607243\t\tSym: 12.843925\t\tSpars: 727.469360\n",
      "\t TVw: -0.040833 | TVb: -2.042651 | GSw: -0.234959 | GSb: 0.065039 | TSUw: 0.464946 | TSUb: 0.034791\n",
      "Validating epoch 2020...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 781.8469106172138\n",
      "Average validation loss: 74.98892601894724\n",
      "Training epoch 2021...\n",
      "\n",
      "Train Epoch: 2021 [0/8000 (0%)]\tBatch Loss: 789.280704\tLearning Rate (w_theta): 0.001000\t TIME:4058.5s\n",
      "\t\t\t\tDisc: 0.685481\t\tSym: 14.279060\t\tSpars: 774.316162\n",
      "\t TVw: -0.040209 | TVb: -2.042647 | GSw: -0.234959 | GSb: 0.065039 | TSUw: 0.464946 | TSUb: 0.034791\n",
      "\n",
      "Train Epoch: 2021 [4000/8000 (50%)]\tBatch Loss: 778.355944\tLearning Rate (w_theta): 0.001000\t TIME:4060.1s\n",
      "\t\t\t\tDisc: 0.508356\t\tSym: 13.171318\t\tSpars: 764.676270\n",
      "\t TVw: -0.039581 | TVb: -2.042642 | GSw: -0.234959 | GSb: 0.065039 | TSUw: 0.464946 | TSUb: 0.034791\n",
      "Validating epoch 2021...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 778.0332419996504\n",
      "Average validation loss: 74.05113714545517\n",
      "Training epoch 2022...\n",
      "\n",
      "Train Epoch: 2022 [0/8000 (0%)]\tBatch Loss: 756.451661\tLearning Rate (w_theta): 0.001000\t TIME:4062.5s\n",
      "\t\t\t\tDisc: 0.551622\t\tSym: 12.700027\t\tSpars: 743.200012\n",
      "\t TVw: -0.038933 | TVb: -2.042637 | GSw: -0.234959 | GSb: 0.065039 | TSUw: 0.464946 | TSUb: 0.034791\n",
      "\n",
      "Train Epoch: 2022 [4000/8000 (50%)]\tBatch Loss: 792.005639\tLearning Rate (w_theta): 0.001000\t TIME:4064.0s\n",
      "\t\t\t\tDisc: 0.579926\t\tSym: 13.551750\t\tSpars: 777.873962\n",
      "\t TVw: -0.038281 | TVb: -2.042633 | GSw: -0.234959 | GSb: 0.065039 | TSUw: 0.464946 | TSUb: 0.034792\n",
      "Validating epoch 2022...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 775.8291819941743\n",
      "Average validation loss: 74.2758663510737\n",
      "Training epoch 2023...\n",
      "\n",
      "Train Epoch: 2023 [0/8000 (0%)]\tBatch Loss: 774.595080\tLearning Rate (w_theta): 0.001000\t TIME:4066.5s\n",
      "\t\t\t\tDisc: 0.644820\t\tSym: 12.954532\t\tSpars: 760.995728\n",
      "\t TVw: -0.037626 | TVb: -2.042629 | GSw: -0.234959 | GSb: 0.065039 | TSUw: 0.464946 | TSUb: 0.034792\n",
      "\n",
      "Train Epoch: 2023 [4000/8000 (50%)]\tBatch Loss: 780.836687\tLearning Rate (w_theta): 0.001000\t TIME:4068.0s\n",
      "\t\t\t\tDisc: 0.576398\t\tSym: 13.832372\t\tSpars: 766.427917\n",
      "\t TVw: -0.036961 | TVb: -2.042623 | GSw: -0.234959 | GSb: 0.065039 | TSUw: 0.464946 | TSUb: 0.034792\n",
      "Validating epoch 2023...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 774.8675594400277\n",
      "Average validation loss: 73.71497650712735\n",
      "Training epoch 2024...\n",
      "\n",
      "Train Epoch: 2024 [0/8000 (0%)]\tBatch Loss: 780.465703\tLearning Rate (w_theta): 0.001000\t TIME:4070.4s\n",
      "\t\t\t\tDisc: 0.616158\t\tSym: 13.768186\t\tSpars: 766.081360\n",
      "\t TVw: -0.036301 | TVb: -2.042619 | GSw: -0.234959 | GSb: 0.065039 | TSUw: 0.464946 | TSUb: 0.034792\n",
      "\n",
      "Train Epoch: 2024 [4000/8000 (50%)]\tBatch Loss: 738.788476\tLearning Rate (w_theta): 0.001000\t TIME:4072.0s\n",
      "\t\t\t\tDisc: 0.585639\t\tSym: 12.412737\t\tSpars: 725.790100\n",
      "\t TVw: -0.035619 | TVb: -2.042613 | GSw: -0.234959 | GSb: 0.065039 | TSUw: 0.464946 | TSUb: 0.034792\n",
      "Validating epoch 2024...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 773.7404054512465\n",
      "Average validation loss: 73.48283077997694\n",
      "Training epoch 2025...\n",
      "\n",
      "Train Epoch: 2025 [0/8000 (0%)]\tBatch Loss: 790.229904\tLearning Rate (w_theta): 0.001000\t TIME:4074.4s\n",
      "\t\t\t\tDisc: 0.618321\t\tSym: 14.410289\t\tSpars: 775.201294\n",
      "\t TVw: -0.034931 | TVb: -2.042606 | GSw: -0.234959 | GSb: 0.065039 | TSUw: 0.464946 | TSUb: 0.034792\n",
      "\n",
      "Train Epoch: 2025 [4000/8000 (50%)]\tBatch Loss: 779.273693\tLearning Rate (w_theta): 0.001000\t TIME:4076.0s\n",
      "\t\t\t\tDisc: 0.590146\t\tSym: 14.004897\t\tSpars: 764.678650\n",
      "\t TVw: -0.034246 | TVb: -2.042601 | GSw: -0.234959 | GSb: 0.065039 | TSUw: 0.464946 | TSUb: 0.034792\n",
      "Validating epoch 2025...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 772.8792256965555\n",
      "Average validation loss: 74.06743592026885\n",
      "Training epoch 2026...\n",
      "\n",
      "Train Epoch: 2026 [0/8000 (0%)]\tBatch Loss: 774.929454\tLearning Rate (w_theta): 0.001000\t TIME:4078.4s\n",
      "\t\t\t\tDisc: 0.671120\t\tSym: 13.755465\t\tSpars: 760.502869\n",
      "\t TVw: -0.033568 | TVb: -2.042594 | GSw: -0.234959 | GSb: 0.065039 | TSUw: 0.464946 | TSUb: 0.034792\n",
      "\n",
      "Train Epoch: 2026 [4000/8000 (50%)]\tBatch Loss: 777.106937\tLearning Rate (w_theta): 0.001000\t TIME:4079.9s\n",
      "\t\t\t\tDisc: 0.547802\t\tSym: 13.224051\t\tSpars: 763.335083\n",
      "\t TVw: -0.032893 | TVb: -2.042590 | GSw: -0.234959 | GSb: 0.065039 | TSUw: 0.464946 | TSUb: 0.034792\n",
      "Validating epoch 2026...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 772.3257799353679\n",
      "Average validation loss: 73.13478614575473\n",
      "Training epoch 2027...\n",
      "\n",
      "Train Epoch: 2027 [0/8000 (0%)]\tBatch Loss: 805.368978\tLearning Rate (w_theta): 0.001000\t TIME:4082.6s\n",
      "\t\t\t\tDisc: 0.699448\t\tSym: 15.352818\t\tSpars: 789.316711\n",
      "\t TVw: -0.032224 | TVb: -2.042585 | GSw: -0.234959 | GSb: 0.065039 | TSUw: 0.464946 | TSUb: 0.034792\n",
      "\n",
      "Train Epoch: 2027 [4000/8000 (50%)]\tBatch Loss: 766.166262\tLearning Rate (w_theta): 0.001000\t TIME:4084.2s\n",
      "\t\t\t\tDisc: 0.601771\t\tSym: 13.502968\t\tSpars: 752.061523\n",
      "\t TVw: -0.031562 | TVb: -2.042580 | GSw: -0.234959 | GSb: 0.065039 | TSUw: 0.464946 | TSUb: 0.034792\n",
      "Validating epoch 2027...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 771.2830037618486\n",
      "Average validation loss: 72.73456118265673\n",
      "Training epoch 2028...\n",
      "\n",
      "Train Epoch: 2028 [0/8000 (0%)]\tBatch Loss: 774.228041\tLearning Rate (w_theta): 0.001000\t TIME:4086.6s\n",
      "\t\t\t\tDisc: 0.572809\t\tSym: 13.396749\t\tSpars: 760.258484\n",
      "\t TVw: -0.030879 | TVb: -2.042574 | GSw: -0.234959 | GSb: 0.065038 | TSUw: 0.464946 | TSUb: 0.034792\n",
      "\n",
      "Train Epoch: 2028 [4000/8000 (50%)]\tBatch Loss: 785.593059\tLearning Rate (w_theta): 0.001000\t TIME:4088.1s\n",
      "\t\t\t\tDisc: 0.611025\t\tSym: 13.893351\t\tSpars: 771.088684\n",
      "\t TVw: -0.030175 | TVb: -2.042567 | GSw: -0.234959 | GSb: 0.065038 | TSUw: 0.464946 | TSUb: 0.034792\n",
      "Validating epoch 2028...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 770.3951354635097\n",
      "Average validation loss: 73.13065263511028\n",
      "Training epoch 2029...\n",
      "\n",
      "Train Epoch: 2029 [0/8000 (0%)]\tBatch Loss: 741.839152\tLearning Rate (w_theta): 0.001000\t TIME:4090.5s\n",
      "\t\t\t\tDisc: 0.591162\t\tSym: 12.148930\t\tSpars: 729.099060\n",
      "\t TVw: -0.029503 | TVb: -2.042561 | GSw: -0.234959 | GSb: 0.065038 | TSUw: 0.464946 | TSUb: 0.034792\n",
      "\n",
      "Train Epoch: 2029 [4000/8000 (50%)]\tBatch Loss: 779.166256\tLearning Rate (w_theta): 0.001000\t TIME:4092.1s\n",
      "\t\t\t\tDisc: 0.609931\t\tSym: 13.368093\t\tSpars: 765.188232\n",
      "\t TVw: -0.028854 | TVb: -2.042555 | GSw: -0.234959 | GSb: 0.065038 | TSUw: 0.464946 | TSUb: 0.034792\n",
      "Validating epoch 2029...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 770.9367652882343\n",
      "Average validation loss: 72.15163473511676\n",
      "Training epoch 2030...\n",
      "\n",
      "Train Epoch: 2030 [0/8000 (0%)]\tBatch Loss: 790.006173\tLearning Rate (w_theta): 0.001000\t TIME:4094.5s\n",
      "\t\t\t\tDisc: 0.566778\t\tSym: 14.410953\t\tSpars: 775.028442\n",
      "\t TVw: -0.028203 | TVb: -2.042551 | GSw: -0.234959 | GSb: 0.065038 | TSUw: 0.464946 | TSUb: 0.034792\n",
      "\n",
      "Train Epoch: 2030 [4000/8000 (50%)]\tBatch Loss: 755.352133\tLearning Rate (w_theta): 0.001000\t TIME:4096.0s\n",
      "\t\t\t\tDisc: 0.621213\t\tSym: 12.160302\t\tSpars: 742.570618\n",
      "\t TVw: -0.027544 | TVb: -2.042544 | GSw: -0.234959 | GSb: 0.065038 | TSUw: 0.464946 | TSUb: 0.034792\n",
      "Validating epoch 2030...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 775.5070774655503\n",
      "Average validation loss: 71.50700059144489\n",
      "Training epoch 2031...\n",
      "\n",
      "Train Epoch: 2031 [0/8000 (0%)]\tBatch Loss: 808.732502\tLearning Rate (w_theta): 0.001000\t TIME:4099.1s\n",
      "\t\t\t\tDisc: 0.613720\t\tSym: 14.048714\t\tSpars: 794.070068\n",
      "\t TVw: -0.026954 | TVb: -2.042540 | GSw: -0.234959 | GSb: 0.065038 | TSUw: 0.464946 | TSUb: 0.034792\n",
      "\n",
      "Train Epoch: 2031 [4000/8000 (50%)]\tBatch Loss: 784.801084\tLearning Rate (w_theta): 0.001000\t TIME:4100.7s\n",
      "\t\t\t\tDisc: 0.613216\t\tSym: 13.861574\t\tSpars: 770.326294\n",
      "\t TVw: -0.026377 | TVb: -2.042535 | GSw: -0.234959 | GSb: 0.065038 | TSUw: 0.464946 | TSUb: 0.034792\n",
      "Validating epoch 2031...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 776.0052805478267\n",
      "Average validation loss: 73.00092963625762\n",
      "Training epoch 2032...\n",
      "\n",
      "Train Epoch: 2032 [0/8000 (0%)]\tBatch Loss: 757.026905\tLearning Rate (w_theta): 0.001000\t TIME:4103.1s\n",
      "\t\t\t\tDisc: 0.595849\t\tSym: 12.503078\t\tSpars: 743.927979\n",
      "\t TVw: -0.025775 | TVb: -2.042528 | GSw: -0.234959 | GSb: 0.065038 | TSUw: 0.464946 | TSUb: 0.034792\n",
      "\n",
      "Train Epoch: 2032 [4000/8000 (50%)]\tBatch Loss: 786.347390\tLearning Rate (w_theta): 0.001000\t TIME:4104.6s\n",
      "\t\t\t\tDisc: 0.630565\t\tSym: 14.545560\t\tSpars: 771.171265\n",
      "\t TVw: -0.025201 | TVb: -2.042523 | GSw: -0.234959 | GSb: 0.065038 | TSUw: 0.464946 | TSUb: 0.034792\n",
      "Validating epoch 2032...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 772.2674004235951\n",
      "Average validation loss: 71.89956469653931\n",
      "Training epoch 2033...\n",
      "\n",
      "Train Epoch: 2033 [0/8000 (0%)]\tBatch Loss: 774.077193\tLearning Rate (w_theta): 0.001000\t TIME:4107.0s\n",
      "\t\t\t\tDisc: 0.536597\t\tSym: 13.934517\t\tSpars: 759.606079\n",
      "\t TVw: -0.024632 | TVb: -2.042521 | GSw: -0.234959 | GSb: 0.065038 | TSUw: 0.464946 | TSUb: 0.034792\n",
      "\n",
      "Train Epoch: 2033 [4000/8000 (50%)]\tBatch Loss: 756.141000\tLearning Rate (w_theta): 0.001000\t TIME:4108.6s\n",
      "\t\t\t\tDisc: 0.549966\t\tSym: 12.674347\t\tSpars: 742.916687\n",
      "\t TVw: -0.024042 | TVb: -2.042516 | GSw: -0.234959 | GSb: 0.065038 | TSUw: 0.464946 | TSUb: 0.034793\n",
      "Validating epoch 2033...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 769.6862809576746\n",
      "Average validation loss: 73.32515656362577\n",
      "Training epoch 2034...\n",
      "\n",
      "Train Epoch: 2034 [0/8000 (0%)]\tBatch Loss: 772.706228\tLearning Rate (w_theta): 0.001000\t TIME:4111.0s\n",
      "\t\t\t\tDisc: 0.599095\t\tSym: 12.685319\t\tSpars: 759.421814\n",
      "\t TVw: -0.023408 | TVb: -2.042510 | GSw: -0.234959 | GSb: 0.065038 | TSUw: 0.464946 | TSUb: 0.034793\n",
      "\n",
      "Train Epoch: 2034 [4000/8000 (50%)]\tBatch Loss: 739.309822\tLearning Rate (w_theta): 0.001000\t TIME:4112.6s\n",
      "\t\t\t\tDisc: 0.532395\t\tSym: 12.346091\t\tSpars: 726.431335\n",
      "\t TVw: -0.022758 | TVb: -2.042504 | GSw: -0.234959 | GSb: 0.065038 | TSUw: 0.464946 | TSUb: 0.034793\n",
      "Validating epoch 2034...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 773.8886425045539\n",
      "Average validation loss: 71.46129047450538\n",
      "Training epoch 2035...\n",
      "\n",
      "Train Epoch: 2035 [0/8000 (0%)]\tBatch Loss: 783.150518\tLearning Rate (w_theta): 0.001000\t TIME:4115.0s\n",
      "\t\t\t\tDisc: 0.581916\t\tSym: 14.059142\t\tSpars: 768.509460\n",
      "\t TVw: -0.022180 | TVb: -2.042500 | GSw: -0.234959 | GSb: 0.065038 | TSUw: 0.464946 | TSUb: 0.034793\n",
      "\n",
      "Train Epoch: 2035 [4000/8000 (50%)]\tBatch Loss: 771.823612\tLearning Rate (w_theta): 0.001000\t TIME:4116.5s\n",
      "\t\t\t\tDisc: 0.567064\t\tSym: 13.748674\t\tSpars: 757.507874\n",
      "\t TVw: -0.021569 | TVb: -2.042493 | GSw: -0.234959 | GSb: 0.065038 | TSUw: 0.464946 | TSUb: 0.034793\n",
      "Validating epoch 2035...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 767.2411458938573\n",
      "Average validation loss: 72.39613530226838\n",
      "Training epoch 2036...\n",
      "\n",
      "Train Epoch: 2036 [0/8000 (0%)]\tBatch Loss: 741.506508\tLearning Rate (w_theta): 0.001000\t TIME:4118.9s\n",
      "\t\t\t\tDisc: 0.593538\t\tSym: 12.574836\t\tSpars: 728.338135\n",
      "\t TVw: -0.020929 | TVb: -2.042486 | GSw: -0.234959 | GSb: 0.065038 | TSUw: 0.464946 | TSUb: 0.034793\n",
      "\n",
      "Train Epoch: 2036 [4000/8000 (50%)]\tBatch Loss: 781.519648\tLearning Rate (w_theta): 0.001000\t TIME:4120.5s\n",
      "\t\t\t\tDisc: 0.643877\t\tSym: 14.801613\t\tSpars: 766.074158\n",
      "\t TVw: -0.020288 | TVb: -2.042480 | GSw: -0.234959 | GSb: 0.065037 | TSUw: 0.464946 | TSUb: 0.034793\n",
      "Validating epoch 2036...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 765.7866000176384\n",
      "Average validation loss: 70.95429639932904\n",
      "Training epoch 2037...\n",
      "\n",
      "Train Epoch: 2037 [0/8000 (0%)]\tBatch Loss: 776.361234\tLearning Rate (w_theta): 0.001000\t TIME:4123.2s\n",
      "\t\t\t\tDisc: 0.546198\t\tSym: 13.935519\t\tSpars: 761.879517\n",
      "\t TVw: -0.019666 | TVb: -2.042475 | GSw: -0.234959 | GSb: 0.065037 | TSUw: 0.464946 | TSUb: 0.034793\n",
      "\n",
      "Train Epoch: 2037 [4000/8000 (50%)]\tBatch Loss: 774.538025\tLearning Rate (w_theta): 0.001000\t TIME:4124.8s\n",
      "\t\t\t\tDisc: 0.574082\t\tSym: 14.224258\t\tSpars: 759.739685\n",
      "\t TVw: -0.019047 | TVb: -2.042469 | GSw: -0.234959 | GSb: 0.065037 | TSUw: 0.464946 | TSUb: 0.034793\n",
      "Validating epoch 2037...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 766.984136550933\n",
      "Average validation loss: 71.92577534989265\n",
      "Training epoch 2038...\n",
      "\n",
      "Train Epoch: 2038 [0/8000 (0%)]\tBatch Loss: 810.141794\tLearning Rate (w_theta): 0.001000\t TIME:4127.2s\n",
      "\t\t\t\tDisc: 0.613952\t\tSym: 15.559763\t\tSpars: 793.968079\n",
      "\t TVw: -0.018435 | TVb: -2.042461 | GSw: -0.234959 | GSb: 0.065037 | TSUw: 0.464946 | TSUb: 0.034793\n",
      "\n",
      "Train Epoch: 2038 [4000/8000 (50%)]\tBatch Loss: 797.040420\tLearning Rate (w_theta): 0.001000\t TIME:4128.8s\n",
      "\t\t\t\tDisc: 0.592947\t\tSym: 14.439722\t\tSpars: 782.007751\n",
      "\t TVw: -0.017837 | TVb: -2.042454 | GSw: -0.234959 | GSb: 0.065037 | TSUw: 0.464946 | TSUb: 0.034793\n",
      "Validating epoch 2038...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 766.0114706672584\n",
      "Average validation loss: 70.7743491977782\n",
      "Training epoch 2039...\n",
      "\n",
      "Train Epoch: 2039 [0/8000 (0%)]\tBatch Loss: 771.193199\tLearning Rate (w_theta): 0.001000\t TIME:4131.2s\n",
      "\t\t\t\tDisc: 0.548936\t\tSym: 13.170386\t\tSpars: 757.473877\n",
      "\t TVw: -0.017234 | TVb: -2.042449 | GSw: -0.234959 | GSb: 0.065037 | TSUw: 0.464946 | TSUb: 0.034793\n",
      "\n",
      "Train Epoch: 2039 [4000/8000 (50%)]\tBatch Loss: 749.295147\tLearning Rate (w_theta): 0.001000\t TIME:4132.8s\n",
      "\t\t\t\tDisc: 0.545144\t\tSym: 12.224490\t\tSpars: 736.525513\n",
      "\t TVw: -0.016607 | TVb: -2.042443 | GSw: -0.234959 | GSb: 0.065037 | TSUw: 0.464946 | TSUb: 0.034793\n",
      "Validating epoch 2039...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 764.3600651392098\n",
      "Average validation loss: 71.47100740485014\n",
      "Training epoch 2040...\n",
      "\n",
      "Train Epoch: 2040 [0/8000 (0%)]\tBatch Loss: 761.796814\tLearning Rate (w_theta): 0.001000\t TIME:4135.1s\n",
      "\t\t\t\tDisc: 0.555311\t\tSym: 13.663989\t\tSpars: 747.577515\n",
      "\t TVw: -0.015998 | TVb: -2.042438 | GSw: -0.234959 | GSb: 0.065037 | TSUw: 0.464946 | TSUb: 0.034793\n",
      "\n",
      "Train Epoch: 2040 [4000/8000 (50%)]\tBatch Loss: 765.413983\tLearning Rate (w_theta): 0.001000\t TIME:4136.7s\n",
      "\t\t\t\tDisc: 0.525571\t\tSym: 13.116988\t\tSpars: 751.771423\n",
      "\t TVw: -0.015405 | TVb: -2.042433 | GSw: -0.234959 | GSb: 0.065037 | TSUw: 0.464946 | TSUb: 0.034793\n",
      "Validating epoch 2040...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 763.3390919943812\n",
      "Average validation loss: 70.59495294059606\n",
      "Training epoch 2041...\n",
      "\n",
      "Train Epoch: 2041 [0/8000 (0%)]\tBatch Loss: 731.568657\tLearning Rate (w_theta): 0.001000\t TIME:4139.7s\n",
      "\t\t\t\tDisc: 0.482842\t\tSym: 12.194152\t\tSpars: 718.891663\n",
      "\t TVw: -0.014824 | TVb: -2.042429 | GSw: -0.234959 | GSb: 0.065037 | TSUw: 0.464946 | TSUb: 0.034793\n",
      "\n",
      "Train Epoch: 2041 [4000/8000 (50%)]\tBatch Loss: 794.725152\tLearning Rate (w_theta): 0.001000\t TIME:4141.3s\n",
      "\t\t\t\tDisc: 0.627611\t\tSym: 14.589118\t\tSpars: 779.508423\n",
      "\t TVw: -0.014216 | TVb: -2.042424 | GSw: -0.234959 | GSb: 0.065037 | TSUw: 0.464946 | TSUb: 0.034793\n",
      "Validating epoch 2041...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 761.9540837980492\n",
      "Average validation loss: 71.1789726788349\n",
      "Training epoch 2042...\n",
      "\n",
      "Train Epoch: 2042 [0/8000 (0%)]\tBatch Loss: 760.051674\tLearning Rate (w_theta): 0.001000\t TIME:4143.7s\n",
      "\t\t\t\tDisc: 0.574131\t\tSym: 13.120122\t\tSpars: 746.357422\n",
      "\t TVw: -0.013593 | TVb: -2.042419 | GSw: -0.234959 | GSb: 0.065037 | TSUw: 0.464946 | TSUb: 0.034793\n",
      "\n",
      "Train Epoch: 2042 [4000/8000 (50%)]\tBatch Loss: 728.760077\tLearning Rate (w_theta): 0.001000\t TIME:4145.3s\n",
      "\t\t\t\tDisc: 0.514077\t\tSym: 11.935148\t\tSpars: 716.310852\n",
      "\t TVw: -0.013012 | TVb: -2.042417 | GSw: -0.234959 | GSb: 0.065037 | TSUw: 0.464946 | TSUb: 0.034793\n",
      "Validating epoch 2042...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 760.0910280120798\n",
      "Average validation loss: 70.70883069109712\n",
      "Training epoch 2043...\n",
      "\n",
      "Train Epoch: 2043 [0/8000 (0%)]\tBatch Loss: 735.322729\tLearning Rate (w_theta): 0.001000\t TIME:4147.7s\n",
      "\t\t\t\tDisc: 0.514335\t\tSym: 12.463546\t\tSpars: 722.344849\n",
      "\t TVw: -0.012385 | TVb: -2.042413 | GSw: -0.234959 | GSb: 0.065037 | TSUw: 0.464946 | TSUb: 0.034793\n",
      "\n",
      "Train Epoch: 2043 [4000/8000 (50%)]\tBatch Loss: 760.410635\tLearning Rate (w_theta): 0.001000\t TIME:4149.3s\n",
      "\t\t\t\tDisc: 0.573436\t\tSym: 12.716350\t\tSpars: 747.120850\n",
      "\t TVw: -0.011735 | TVb: -2.042408 | GSw: -0.234959 | GSb: 0.065037 | TSUw: 0.464946 | TSUb: 0.034793\n",
      "Validating epoch 2043...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 766.3650329173358\n",
      "Average validation loss: 71.99846945232842\n",
      "Training epoch 2044...\n",
      "\n",
      "Train Epoch: 2044 [0/8000 (0%)]\tBatch Loss: 772.682818\tLearning Rate (w_theta): 0.001000\t TIME:4151.6s\n",
      "\t\t\t\tDisc: 0.618263\t\tSym: 13.009685\t\tSpars: 759.054871\n",
      "\t TVw: -0.011084 | TVb: -2.042400 | GSw: -0.234959 | GSb: 0.065037 | TSUw: 0.464946 | TSUb: 0.034794\n",
      "\n",
      "Train Epoch: 2044 [4000/8000 (50%)]\tBatch Loss: 776.070905\tLearning Rate (w_theta): 0.001000\t TIME:4153.2s\n",
      "\t\t\t\tDisc: 0.550110\t\tSym: 13.710797\t\tSpars: 761.809998\n",
      "\t TVw: -0.010500 | TVb: -2.042394 | GSw: -0.234959 | GSb: 0.065037 | TSUw: 0.464946 | TSUb: 0.034794\n",
      "Validating epoch 2044...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 766.5938254056313\n",
      "Average validation loss: 69.7404722383199\n",
      "Training epoch 2045...\n",
      "\n",
      "Train Epoch: 2045 [0/8000 (0%)]\tBatch Loss: 763.524588\tLearning Rate (w_theta): 0.001000\t TIME:4155.6s\n",
      "\t\t\t\tDisc: 0.520730\t\tSym: 13.427014\t\tSpars: 749.576843\n",
      "\t TVw: -0.009921 | TVb: -2.042388 | GSw: -0.234959 | GSb: 0.065036 | TSUw: 0.464946 | TSUb: 0.034794\n",
      "\n",
      "Train Epoch: 2045 [4000/8000 (50%)]\tBatch Loss: 742.649181\tLearning Rate (w_theta): 0.001000\t TIME:4157.2s\n",
      "\t\t\t\tDisc: 0.558133\t\tSym: 12.643783\t\tSpars: 729.447266\n",
      "\t TVw: -0.009357 | TVb: -2.042382 | GSw: -0.234959 | GSb: 0.065036 | TSUw: 0.464946 | TSUb: 0.034794\n",
      "Validating epoch 2045...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 765.4697495739471\n",
      "Average validation loss: 71.21360639820661\n",
      "Training epoch 2046...\n",
      "\n",
      "Train Epoch: 2046 [0/8000 (0%)]\tBatch Loss: 737.692921\tLearning Rate (w_theta): 0.001000\t TIME:4159.5s\n",
      "\t\t\t\tDisc: 0.551847\t\tSym: 11.905601\t\tSpars: 725.235474\n",
      "\t TVw: -0.008781 | TVb: -2.042376 | GSw: -0.234959 | GSb: 0.065036 | TSUw: 0.464946 | TSUb: 0.034794\n",
      "\n",
      "Train Epoch: 2046 [4000/8000 (50%)]\tBatch Loss: 761.518375\tLearning Rate (w_theta): 0.001000\t TIME:4161.1s\n",
      "\t\t\t\tDisc: 0.575555\t\tSym: 13.150584\t\tSpars: 747.792236\n",
      "\t TVw: -0.008210 | TVb: -2.042371 | GSw: -0.234959 | GSb: 0.065036 | TSUw: 0.464946 | TSUb: 0.034794\n",
      "Validating epoch 2046...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 758.476473523676\n",
      "Average validation loss: 70.51162375738194\n",
      "Training epoch 2047...\n",
      "\n",
      "Train Epoch: 2047 [0/8000 (0%)]\tBatch Loss: 778.966049\tLearning Rate (w_theta): 0.001000\t TIME:4163.8s\n",
      "\t\t\t\tDisc: 0.576098\t\tSym: 14.313413\t\tSpars: 764.076538\n",
      "\t TVw: -0.007609 | TVb: -2.042366 | GSw: -0.234959 | GSb: 0.065036 | TSUw: 0.464946 | TSUb: 0.034794\n",
      "\n",
      "Train Epoch: 2047 [4000/8000 (50%)]\tBatch Loss: 749.864293\tLearning Rate (w_theta): 0.001000\t TIME:4165.4s\n",
      "\t\t\t\tDisc: 0.515832\t\tSym: 12.472424\t\tSpars: 736.876038\n",
      "\t TVw: -0.006994 | TVb: -2.042360 | GSw: -0.234959 | GSb: 0.065036 | TSUw: 0.464946 | TSUb: 0.034794\n",
      "Validating epoch 2047...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 758.3343724223854\n",
      "Average validation loss: 71.04616797989847\n",
      "Training epoch 2048...\n",
      "\n",
      "Train Epoch: 2048 [0/8000 (0%)]\tBatch Loss: 734.509723\tLearning Rate (w_theta): 0.001000\t TIME:4167.8s\n",
      "\t\t\t\tDisc: 0.480427\t\tSym: 12.547851\t\tSpars: 721.481445\n",
      "\t TVw: -0.006364 | TVb: -2.042354 | GSw: -0.234959 | GSb: 0.065036 | TSUw: 0.464946 | TSUb: 0.034794\n",
      "\n",
      "Train Epoch: 2048 [4000/8000 (50%)]\tBatch Loss: 772.954952\tLearning Rate (w_theta): 0.001000\t TIME:4169.4s\n",
      "\t\t\t\tDisc: 0.575573\t\tSym: 14.073715\t\tSpars: 758.305664\n",
      "\t TVw: -0.005736 | TVb: -2.042349 | GSw: -0.234959 | GSb: 0.065036 | TSUw: 0.464946 | TSUb: 0.034794\n",
      "Validating epoch 2048...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 756.5592122651983\n",
      "Average validation loss: 69.88130314019989\n",
      "Training epoch 2049...\n",
      "\n",
      "Train Epoch: 2049 [0/8000 (0%)]\tBatch Loss: 742.497101\tLearning Rate (w_theta): 0.001000\t TIME:4171.8s\n",
      "\t\t\t\tDisc: 0.522060\t\tSym: 12.962041\t\tSpars: 729.013000\n",
      "\t TVw: -0.005103 | TVb: -2.042343 | GSw: -0.234959 | GSb: 0.065036 | TSUw: 0.464946 | TSUb: 0.034794\n",
      "\n",
      "Train Epoch: 2049 [4000/8000 (50%)]\tBatch Loss: 746.772966\tLearning Rate (w_theta): 0.001000\t TIME:4173.3s\n",
      "\t\t\t\tDisc: 0.552270\t\tSym: 13.697380\t\tSpars: 732.523315\n",
      "\t TVw: -0.004494 | TVb: -2.042338 | GSw: -0.234959 | GSb: 0.065036 | TSUw: 0.464946 | TSUb: 0.034794\n",
      "Validating epoch 2049...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 754.7931913189831\n",
      "Average validation loss: 69.80504542765956\n",
      "Training epoch 2050...\n",
      "\n",
      "Train Epoch: 2050 [0/8000 (0%)]\tBatch Loss: 732.825442\tLearning Rate (w_theta): 0.001000\t TIME:4175.7s\n",
      "\t\t\t\tDisc: 0.511449\t\tSym: 12.494963\t\tSpars: 719.819031\n",
      "\t TVw: -0.003866 | TVb: -2.042333 | GSw: -0.234959 | GSb: 0.065036 | TSUw: 0.464946 | TSUb: 0.034794\n",
      "\n",
      "Train Epoch: 2050 [4000/8000 (50%)]\tBatch Loss: 764.614921\tLearning Rate (w_theta): 0.001000\t TIME:4177.3s\n",
      "\t\t\t\tDisc: 0.569526\t\tSym: 13.542221\t\tSpars: 750.503174\n",
      "\t TVw: -0.003232 | TVb: -2.042328 | GSw: -0.234959 | GSb: 0.065036 | TSUw: 0.464946 | TSUb: 0.034794\n",
      "Validating epoch 2050...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 753.0987371229684\n",
      "Average validation loss: 69.76169140780347\n",
      "Training epoch 2051...\n",
      "\n",
      "Train Epoch: 2051 [0/8000 (0%)]\tBatch Loss: 746.900075\tLearning Rate (w_theta): 0.001000\t TIME:4180.4s\n",
      "\t\t\t\tDisc: 0.475212\t\tSym: 13.367612\t\tSpars: 733.057251\n",
      "\t TVw: -0.002616 | TVb: -2.042324 | GSw: -0.234959 | GSb: 0.065036 | TSUw: 0.464946 | TSUb: 0.034794\n",
      "\n",
      "Train Epoch: 2051 [4000/8000 (50%)]\tBatch Loss: 733.167758\tLearning Rate (w_theta): 0.001000\t TIME:4182.0s\n",
      "\t\t\t\tDisc: 0.520045\t\tSym: 11.804207\t\tSpars: 720.843506\n",
      "\t TVw: -0.001963 | TVb: -2.042318 | GSw: -0.234959 | GSb: 0.065036 | TSUw: 0.464946 | TSUb: 0.034794\n",
      "Validating epoch 2051...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 758.2837451946031\n",
      "Average validation loss: 69.64390512083808\n",
      "Training epoch 2052...\n",
      "\n",
      "Train Epoch: 2052 [0/8000 (0%)]\tBatch Loss: 774.142029\tLearning Rate (w_theta): 0.001000\t TIME:4184.4s\n",
      "\t\t\t\tDisc: 0.526282\t\tSym: 14.071680\t\tSpars: 759.544067\n",
      "\t TVw: -0.001321 | TVb: -2.042311 | GSw: -0.234959 | GSb: 0.065036 | TSUw: 0.464946 | TSUb: 0.034794\n",
      "\n",
      "Train Epoch: 2052 [4000/8000 (50%)]\tBatch Loss: 746.171852\tLearning Rate (w_theta): 0.001000\t TIME:4186.0s\n",
      "\t\t\t\tDisc: 0.528931\t\tSym: 12.976418\t\tSpars: 732.666504\n",
      "\t TVw: -0.000730 | TVb: -2.042308 | GSw: -0.234959 | GSb: 0.065036 | TSUw: 0.464946 | TSUb: 0.034794\n",
      "Validating epoch 2052...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 755.6726904250269\n",
      "Average validation loss: 69.38866861413658\n",
      "Training epoch 2053...\n",
      "\n",
      "Train Epoch: 2053 [0/8000 (0%)]\tBatch Loss: 781.105550\tLearning Rate (w_theta): 0.001000\t TIME:4188.4s\n",
      "\t\t\t\tDisc: 0.521634\t\tSym: 13.441460\t\tSpars: 767.142456\n",
      "\t TVw: -0.000185 | TVb: -2.042307 | GSw: -0.234959 | GSb: 0.065035 | TSUw: 0.464946 | TSUb: 0.034795\n",
      "\n",
      "Train Epoch: 2053 [4000/8000 (50%)]\tBatch Loss: 774.090563\tLearning Rate (w_theta): 0.001000\t TIME:4189.9s\n",
      "\t\t\t\tDisc: 0.634490\t\tSym: 14.014667\t\tSpars: 759.441406\n",
      "\t TVw: 0.000410 | TVb: -2.042300 | GSw: -0.234959 | GSb: 0.065035 | TSUw: 0.464946 | TSUb: 0.034795\n",
      "Validating epoch 2053...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 754.4240655071998\n",
      "Average validation loss: 70.23924332012798\n",
      "Training epoch 2054...\n",
      "\n",
      "Train Epoch: 2054 [0/8000 (0%)]\tBatch Loss: 755.986444\tLearning Rate (w_theta): 0.001000\t TIME:4192.3s\n",
      "\t\t\t\tDisc: 0.541933\t\tSym: 12.783501\t\tSpars: 742.661011\n",
      "\t TVw: 0.001014 | TVb: -2.042293 | GSw: -0.234959 | GSb: 0.065035 | TSUw: 0.464946 | TSUb: 0.034795\n",
      "\n",
      "Train Epoch: 2054 [4000/8000 (50%)]\tBatch Loss: 744.060533\tLearning Rate (w_theta): 0.001000\t TIME:4193.9s\n",
      "\t\t\t\tDisc: 0.546820\t\tSym: 12.790935\t\tSpars: 730.722778\n",
      "\t TVw: 0.001616 | TVb: -2.042286 | GSw: -0.234959 | GSb: 0.065035 | TSUw: 0.464946 | TSUb: 0.034795\n",
      "Validating epoch 2054...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 752.4014249474264\n",
      "Average validation loss: 69.25111924398021\n",
      "Training epoch 2055...\n",
      "\n",
      "Train Epoch: 2055 [0/8000 (0%)]\tBatch Loss: 758.881560\tLearning Rate (w_theta): 0.001000\t TIME:4196.3s\n",
      "\t\t\t\tDisc: 0.605683\t\tSym: 13.564084\t\tSpars: 744.711792\n",
      "\t TVw: 0.002233 | TVb: -2.042279 | GSw: -0.234959 | GSb: 0.065035 | TSUw: 0.464946 | TSUb: 0.034795\n",
      "\n",
      "Train Epoch: 2055 [4000/8000 (50%)]\tBatch Loss: 775.385839\tLearning Rate (w_theta): 0.001000\t TIME:4197.9s\n",
      "\t\t\t\tDisc: 0.566691\t\tSym: 13.920465\t\tSpars: 760.898682\n",
      "\t TVw: 0.002819 | TVb: -2.042273 | GSw: -0.234959 | GSb: 0.065035 | TSUw: 0.464946 | TSUb: 0.034795\n",
      "Validating epoch 2055...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 753.8991985244054\n",
      "Average validation loss: 68.99584275977034\n",
      "Training epoch 2056...\n",
      "\n",
      "Train Epoch: 2056 [0/8000 (0%)]\tBatch Loss: 722.179553\tLearning Rate (w_theta): 0.001000\t TIME:4200.6s\n",
      "\t\t\t\tDisc: 0.451579\t\tSym: 11.491890\t\tSpars: 710.236084\n",
      "\t TVw: 0.003423 | TVb: -2.042267 | GSw: -0.234959 | GSb: 0.065035 | TSUw: 0.464946 | TSUb: 0.034795\n",
      "\n",
      "Train Epoch: 2056 [4000/8000 (50%)]\tBatch Loss: 755.741801\tLearning Rate (w_theta): 0.001000\t TIME:4202.1s\n",
      "\t\t\t\tDisc: 0.573661\t\tSym: 14.006640\t\tSpars: 741.161499\n",
      "\t TVw: 0.004037 | TVb: -2.042261 | GSw: -0.234959 | GSb: 0.065035 | TSUw: 0.464946 | TSUb: 0.034795\n",
      "Validating epoch 2056...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 749.8640544960228\n",
      "Average validation loss: 69.82630721217778\n",
      "Training epoch 2057...\n",
      "\n",
      "Train Epoch: 2057 [0/8000 (0%)]\tBatch Loss: 777.260652\tLearning Rate (w_theta): 0.001000\t TIME:4204.5s\n",
      "\t\t\t\tDisc: 0.554819\t\tSym: 14.220359\t\tSpars: 762.485474\n",
      "\t TVw: 0.004651 | TVb: -2.042255 | GSw: -0.234959 | GSb: 0.065035 | TSUw: 0.464946 | TSUb: 0.034795\n",
      "\n",
      "Train Epoch: 2057 [4000/8000 (50%)]\tBatch Loss: 743.423138\tLearning Rate (w_theta): 0.001000\t TIME:4206.1s\n",
      "\t\t\t\tDisc: 0.566354\t\tSym: 12.778232\t\tSpars: 730.078552\n",
      "\t TVw: 0.005286 | TVb: -2.042249 | GSw: -0.234959 | GSb: 0.065035 | TSUw: 0.464946 | TSUb: 0.034795\n",
      "Validating epoch 2057...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 751.3748183451464\n",
      "Average validation loss: 68.75737827190227\n",
      "Training epoch 2058...\n",
      "\n",
      "Train Epoch: 2058 [0/8000 (0%)]\tBatch Loss: 756.978728\tLearning Rate (w_theta): 0.001000\t TIME:4208.4s\n",
      "\t\t\t\tDisc: 0.551067\t\tSym: 13.303882\t\tSpars: 743.123779\n",
      "\t TVw: 0.005891 | TVb: -2.042244 | GSw: -0.234959 | GSb: 0.065035 | TSUw: 0.464946 | TSUb: 0.034795\n",
      "\n",
      "Train Epoch: 2058 [4000/8000 (50%)]\tBatch Loss: 728.560454\tLearning Rate (w_theta): 0.001000\t TIME:4210.0s\n",
      "\t\t\t\tDisc: 0.525184\t\tSym: 11.779105\t\tSpars: 716.256165\n",
      "\t TVw: 0.006524 | TVb: -2.042238 | GSw: -0.234959 | GSb: 0.065035 | TSUw: 0.464946 | TSUb: 0.034795\n",
      "Validating epoch 2058...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 749.2851788204298\n",
      "Average validation loss: 69.56867578389848\n",
      "Training epoch 2059...\n",
      "\n",
      "Train Epoch: 2059 [0/8000 (0%)]\tBatch Loss: 757.355864\tLearning Rate (w_theta): 0.001000\t TIME:4212.4s\n",
      "\t\t\t\tDisc: 0.602571\t\tSym: 12.630124\t\tSpars: 744.123169\n",
      "\t TVw: 0.007148 | TVb: -2.042232 | GSw: -0.234959 | GSb: 0.065035 | TSUw: 0.464946 | TSUb: 0.034795\n",
      "\n",
      "Train Epoch: 2059 [4000/8000 (50%)]\tBatch Loss: 759.106883\tLearning Rate (w_theta): 0.001000\t TIME:4214.0s\n",
      "\t\t\t\tDisc: 0.523165\t\tSym: 12.920509\t\tSpars: 745.663208\n",
      "\t TVw: 0.007770 | TVb: -2.042225 | GSw: -0.234959 | GSb: 0.065035 | TSUw: 0.464946 | TSUb: 0.034795\n",
      "Validating epoch 2059...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 748.9277016239117\n",
      "Average validation loss: 69.04520572556743\n",
      "Training epoch 2060...\n",
      "\n",
      "Train Epoch: 2060 [0/8000 (0%)]\tBatch Loss: 732.029857\tLearning Rate (w_theta): 0.001000\t TIME:4216.4s\n",
      "\t\t\t\tDisc: 0.527006\t\tSym: 12.734662\t\tSpars: 718.768188\n",
      "\t TVw: 0.008399 | TVb: -2.042219 | GSw: -0.234959 | GSb: 0.065035 | TSUw: 0.464946 | TSUb: 0.034795\n",
      "\n",
      "Train Epoch: 2060 [4000/8000 (50%)]\tBatch Loss: 730.619274\tLearning Rate (w_theta): 0.001000\t TIME:4217.9s\n",
      "\t\t\t\tDisc: 0.519514\t\tSym: 12.713957\t\tSpars: 717.385803\n",
      "\t TVw: 0.009029 | TVb: -2.042213 | GSw: -0.234959 | GSb: 0.065035 | TSUw: 0.464946 | TSUb: 0.034795\n",
      "Validating epoch 2060...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 745.8217157576587\n",
      "Average validation loss: 69.02261030508926\n",
      "Training epoch 2061...\n",
      "\n",
      "Train Epoch: 2061 [0/8000 (0%)]\tBatch Loss: 729.983199\tLearning Rate (w_theta): 0.001000\t TIME:4221.0s\n",
      "\t\t\t\tDisc: 0.591510\t\tSym: 12.620692\t\tSpars: 716.770996\n",
      "\t TVw: 0.009639 | TVb: -2.042208 | GSw: -0.234959 | GSb: 0.065035 | TSUw: 0.464946 | TSUb: 0.034795\n",
      "\n",
      "Train Epoch: 2061 [4000/8000 (50%)]\tBatch Loss: 714.702209\tLearning Rate (w_theta): 0.001000\t TIME:4222.6s\n",
      "\t\t\t\tDisc: 0.461396\t\tSym: 11.832000\t\tSpars: 702.408813\n",
      "\t TVw: 0.010256 | TVb: -2.042203 | GSw: -0.234959 | GSb: 0.065034 | TSUw: 0.464946 | TSUb: 0.034796\n",
      "Validating epoch 2061...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 744.5040777919467\n",
      "Average validation loss: 69.44528445530166\n",
      "Training epoch 2062...\n",
      "\n",
      "Train Epoch: 2062 [0/8000 (0%)]\tBatch Loss: 736.981551\tLearning Rate (w_theta): 0.001000\t TIME:4225.0s\n",
      "\t\t\t\tDisc: 0.514690\t\tSym: 12.308414\t\tSpars: 724.158447\n",
      "\t TVw: 0.010892 | TVb: -2.042198 | GSw: -0.234959 | GSb: 0.065034 | TSUw: 0.464946 | TSUb: 0.034796\n",
      "\n",
      "Train Epoch: 2062 [4000/8000 (50%)]\tBatch Loss: 777.195052\tLearning Rate (w_theta): 0.001000\t TIME:4226.6s\n",
      "\t\t\t\tDisc: 0.552921\t\tSym: 14.214641\t\tSpars: 762.427490\n",
      "\t TVw: 0.011493 | TVb: -2.042194 | GSw: -0.234959 | GSb: 0.065034 | TSUw: 0.464946 | TSUb: 0.034796\n",
      "Validating epoch 2062...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 744.4944569817701\n",
      "Average validation loss: 68.88536164198426\n",
      "Training epoch 2063...\n",
      "\n",
      "Train Epoch: 2063 [0/8000 (0%)]\tBatch Loss: 712.125797\tLearning Rate (w_theta): 0.001000\t TIME:4229.0s\n",
      "\t\t\t\tDisc: 0.518317\t\tSym: 11.705441\t\tSpars: 699.902039\n",
      "\t TVw: 0.012115 | TVb: -2.042188 | GSw: -0.234959 | GSb: 0.065034 | TSUw: 0.464946 | TSUb: 0.034796\n",
      "\n",
      "Train Epoch: 2063 [4000/8000 (50%)]\tBatch Loss: 749.901378\tLearning Rate (w_theta): 0.001000\t TIME:4230.6s\n",
      "\t\t\t\tDisc: 0.471728\t\tSym: 12.511497\t\tSpars: 736.918152\n",
      "\t TVw: 0.012805 | TVb: -2.042181 | GSw: -0.234959 | GSb: 0.065034 | TSUw: 0.464946 | TSUb: 0.034796\n",
      "Validating epoch 2063...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 742.7347661043673\n",
      "Average validation loss: 68.82603532064824\n",
      "Training epoch 2064...\n",
      "\n",
      "Train Epoch: 2064 [0/8000 (0%)]\tBatch Loss: 749.460436\tLearning Rate (w_theta): 0.001000\t TIME:4233.0s\n",
      "\t\t\t\tDisc: 0.528216\t\tSym: 13.685576\t\tSpars: 735.246643\n",
      "\t TVw: 0.013454 | TVb: -2.042175 | GSw: -0.234959 | GSb: 0.065034 | TSUw: 0.464946 | TSUb: 0.034796\n",
      "\n",
      "Train Epoch: 2064 [4000/8000 (50%)]\tBatch Loss: 760.280107\tLearning Rate (w_theta): 0.001000\t TIME:4234.5s\n",
      "\t\t\t\tDisc: 0.592860\t\tSym: 14.266471\t\tSpars: 745.420776\n",
      "\t TVw: 0.014110 | TVb: -2.042169 | GSw: -0.234959 | GSb: 0.065034 | TSUw: 0.464946 | TSUb: 0.034796\n",
      "Validating epoch 2064...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 742.4477043254178\n",
      "Average validation loss: 68.54533207945016\n",
      "Training epoch 2065...\n",
      "\n",
      "Train Epoch: 2065 [0/8000 (0%)]\tBatch Loss: 772.562458\tLearning Rate (w_theta): 0.001000\t TIME:4236.9s\n",
      "\t\t\t\tDisc: 0.542485\t\tSym: 14.090529\t\tSpars: 757.929443\n",
      "\t TVw: 0.014750 | TVb: -2.042163 | GSw: -0.234959 | GSb: 0.065034 | TSUw: 0.464946 | TSUb: 0.034796\n",
      "\n",
      "Train Epoch: 2065 [4000/8000 (50%)]\tBatch Loss: 747.689162\tLearning Rate (w_theta): 0.001000\t TIME:4238.5s\n",
      "\t\t\t\tDisc: 0.534092\t\tSym: 12.916179\t\tSpars: 734.238892\n",
      "\t TVw: 0.015391 | TVb: -2.042156 | GSw: -0.234959 | GSb: 0.065034 | TSUw: 0.464946 | TSUb: 0.034796\n",
      "Validating epoch 2065...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 742.315910090401\n",
      "Average validation loss: 67.98021125136435\n",
      "Training epoch 2066...\n",
      "\n",
      "Train Epoch: 2066 [0/8000 (0%)]\tBatch Loss: 707.919052\tLearning Rate (w_theta): 0.001000\t TIME:4241.3s\n",
      "\t\t\t\tDisc: 0.488026\t\tSym: 11.673274\t\tSpars: 695.757751\n",
      "\t TVw: 0.016040 | TVb: -2.042150 | GSw: -0.234959 | GSb: 0.065034 | TSUw: 0.464946 | TSUb: 0.034796\n",
      "\n",
      "Train Epoch: 2066 [4000/8000 (50%)]\tBatch Loss: 744.113377\tLearning Rate (w_theta): 0.001000\t TIME:4242.8s\n",
      "\t\t\t\tDisc: 0.501838\t\tSym: 13.188809\t\tSpars: 730.422729\n",
      "\t TVw: 0.016688 | TVb: -2.042143 | GSw: -0.234959 | GSb: 0.065034 | TSUw: 0.464946 | TSUb: 0.034796\n",
      "Validating epoch 2066...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 742.8890849926348\n",
      "Average validation loss: 68.78681377894111\n",
      "Training epoch 2067...\n",
      "\n",
      "Train Epoch: 2067 [0/8000 (0%)]\tBatch Loss: 729.143544\tLearning Rate (w_theta): 0.001000\t TIME:4245.2s\n",
      "\t\t\t\tDisc: 0.503117\t\tSym: 13.283920\t\tSpars: 715.356506\n",
      "\t TVw: 0.017330 | TVb: -2.042137 | GSw: -0.234959 | GSb: 0.065034 | TSUw: 0.464946 | TSUb: 0.034796\n",
      "\n",
      "Train Epoch: 2067 [4000/8000 (50%)]\tBatch Loss: 739.006314\tLearning Rate (w_theta): 0.001000\t TIME:4246.8s\n",
      "\t\t\t\tDisc: 0.548642\t\tSym: 12.634246\t\tSpars: 725.823425\n",
      "\t TVw: 0.017958 | TVb: -2.042131 | GSw: -0.234959 | GSb: 0.065034 | TSUw: 0.464946 | TSUb: 0.034796\n",
      "Validating epoch 2067...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 740.1008675293544\n",
      "Average validation loss: 68.79133274490285\n",
      "Training epoch 2068...\n",
      "\n",
      "Train Epoch: 2068 [0/8000 (0%)]\tBatch Loss: 773.407793\tLearning Rate (w_theta): 0.001000\t TIME:4249.2s\n",
      "\t\t\t\tDisc: 0.586860\t\tSym: 14.601999\t\tSpars: 758.218933\n",
      "\t TVw: 0.018573 | TVb: -2.042125 | GSw: -0.234959 | GSb: 0.065034 | TSUw: 0.464946 | TSUb: 0.034796\n",
      "\n",
      "Train Epoch: 2068 [4000/8000 (50%)]\tBatch Loss: 720.852923\tLearning Rate (w_theta): 0.001000\t TIME:4250.8s\n",
      "\t\t\t\tDisc: 0.514256\t\tSym: 11.920332\t\tSpars: 708.418335\n",
      "\t TVw: 0.019186 | TVb: -2.042119 | GSw: -0.234959 | GSb: 0.065034 | TSUw: 0.464946 | TSUb: 0.034796\n",
      "Validating epoch 2068...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 740.6456571555137\n",
      "Average validation loss: 68.02602562874382\n",
      "Training epoch 2069...\n",
      "\n",
      "Train Epoch: 2069 [0/8000 (0%)]\tBatch Loss: 730.762432\tLearning Rate (w_theta): 0.001000\t TIME:4253.2s\n",
      "\t\t\t\tDisc: 0.554461\t\tSym: 12.415674\t\tSpars: 717.792297\n",
      "\t TVw: 0.019752 | TVb: -2.042115 | GSw: -0.234959 | GSb: 0.065034 | TSUw: 0.464946 | TSUb: 0.034796\n",
      "\n",
      "Train Epoch: 2069 [4000/8000 (50%)]\tBatch Loss: 752.007293\tLearning Rate (w_theta): 0.001000\t TIME:4254.7s\n",
      "\t\t\t\tDisc: 0.530730\t\tSym: 13.877502\t\tSpars: 737.599060\n",
      "\t TVw: 0.020359 | TVb: -2.042108 | GSw: -0.234959 | GSb: 0.065034 | TSUw: 0.464946 | TSUb: 0.034797\n",
      "Validating epoch 2069...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 738.6579130978017\n",
      "Average validation loss: 68.28342108595741\n",
      "Training epoch 2070...\n",
      "\n",
      "Train Epoch: 2070 [0/8000 (0%)]\tBatch Loss: 769.868191\tLearning Rate (w_theta): 0.001000\t TIME:4257.2s\n",
      "\t\t\t\tDisc: 0.572366\t\tSym: 14.665027\t\tSpars: 754.630798\n",
      "\t TVw: 0.020941 | TVb: -2.042102 | GSw: -0.234959 | GSb: 0.065033 | TSUw: 0.464946 | TSUb: 0.034797\n",
      "\n",
      "Train Epoch: 2070 [4000/8000 (50%)]\tBatch Loss: 741.551285\tLearning Rate (w_theta): 0.001000\t TIME:4258.8s\n",
      "\t\t\t\tDisc: 0.523657\t\tSym: 13.135782\t\tSpars: 727.891846\n",
      "\t TVw: 0.021504 | TVb: -2.042098 | GSw: -0.234959 | GSb: 0.065033 | TSUw: 0.464946 | TSUb: 0.034797\n",
      "Validating epoch 2070...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 739.2822848798585\n",
      "Average validation loss: 69.1591174256333\n",
      "Training epoch 2071...\n",
      "\n",
      "Train Epoch: 2071 [0/8000 (0%)]\tBatch Loss: 738.605868\tLearning Rate (w_theta): 0.001000\t TIME:4261.8s\n",
      "\t\t\t\tDisc: 0.565041\t\tSym: 13.790094\t\tSpars: 724.250732\n",
      "\t TVw: 0.022113 | TVb: -2.042093 | GSw: -0.234959 | GSb: 0.065033 | TSUw: 0.464946 | TSUb: 0.034797\n",
      "\n",
      "Train Epoch: 2071 [4000/8000 (50%)]\tBatch Loss: 706.810189\tLearning Rate (w_theta): 0.001000\t TIME:4263.4s\n",
      "\t\t\t\tDisc: 0.436701\t\tSym: 11.003860\t\tSpars: 695.369629\n",
      "\t TVw: 0.022737 | TVb: -2.042088 | GSw: -0.234959 | GSb: 0.065033 | TSUw: 0.464946 | TSUb: 0.034797\n",
      "Validating epoch 2071...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 740.8593151060386\n",
      "Average validation loss: 68.24505164594275\n",
      "Training epoch 2072...\n",
      "\n",
      "Train Epoch: 2072 [0/8000 (0%)]\tBatch Loss: 737.986841\tLearning Rate (w_theta): 0.001000\t TIME:4265.8s\n",
      "\t\t\t\tDisc: 0.553527\t\tSym: 12.916224\t\tSpars: 724.517090\n",
      "\t TVw: 0.023339 | TVb: -2.042083 | GSw: -0.234959 | GSb: 0.065033 | TSUw: 0.464946 | TSUb: 0.034797\n",
      "\n",
      "Train Epoch: 2072 [4000/8000 (50%)]\tBatch Loss: 744.450007\tLearning Rate (w_theta): 0.001000\t TIME:4267.4s\n",
      "\t\t\t\tDisc: 0.482051\t\tSym: 13.516846\t\tSpars: 730.451111\n",
      "\t TVw: 0.023963 | TVb: -2.042075 | GSw: -0.234959 | GSb: 0.065033 | TSUw: 0.464946 | TSUb: 0.034797\n",
      "Validating epoch 2072...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 736.4728969724742\n",
      "Average validation loss: 67.60954997612049\n",
      "Training epoch 2073...\n",
      "\n",
      "Train Epoch: 2073 [0/8000 (0%)]\tBatch Loss: 724.049492\tLearning Rate (w_theta): 0.001000\t TIME:4269.8s\n",
      "\t\t\t\tDisc: 0.505599\t\tSym: 12.700754\t\tSpars: 710.843140\n",
      "\t TVw: 0.024572 | TVb: -2.042068 | GSw: -0.234959 | GSb: 0.065033 | TSUw: 0.464946 | TSUb: 0.034797\n",
      "\n",
      "Train Epoch: 2073 [4000/8000 (50%)]\tBatch Loss: 757.978014\tLearning Rate (w_theta): 0.001000\t TIME:4271.4s\n",
      "\t\t\t\tDisc: 0.466210\t\tSym: 14.678247\t\tSpars: 742.833557\n",
      "\t TVw: 0.025177 | TVb: -2.042061 | GSw: -0.234959 | GSb: 0.065033 | TSUw: 0.464946 | TSUb: 0.034797\n",
      "Validating epoch 2073...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 734.2944693440044\n",
      "Average validation loss: 68.25789455588824\n",
      "Training epoch 2074...\n",
      "\n",
      "Train Epoch: 2074 [0/8000 (0%)]\tBatch Loss: 737.802538\tLearning Rate (w_theta): 0.001000\t TIME:4273.9s\n",
      "\t\t\t\tDisc: 0.508957\t\tSym: 13.996768\t\tSpars: 723.296814\n",
      "\t TVw: 0.025807 | TVb: -2.042054 | GSw: -0.234959 | GSb: 0.065033 | TSUw: 0.464946 | TSUb: 0.034797\n",
      "\n",
      "Train Epoch: 2074 [4000/8000 (50%)]\tBatch Loss: 737.172949\tLearning Rate (w_theta): 0.001000\t TIME:4275.4s\n",
      "\t\t\t\tDisc: 0.574374\t\tSym: 12.796573\t\tSpars: 723.802002\n",
      "\t TVw: 0.026384 | TVb: -2.042049 | GSw: -0.234959 | GSb: 0.065033 | TSUw: 0.464946 | TSUb: 0.034797\n",
      "Validating epoch 2074...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 734.8652374787706\n",
      "Average validation loss: 68.1901626866784\n",
      "Training epoch 2075...\n",
      "\n",
      "Train Epoch: 2075 [0/8000 (0%)]\tBatch Loss: 715.522373\tLearning Rate (w_theta): 0.001000\t TIME:4277.8s\n",
      "\t\t\t\tDisc: 0.468418\t\tSym: 11.559448\t\tSpars: 703.494507\n",
      "\t TVw: 0.026991 | TVb: -2.042043 | GSw: -0.234959 | GSb: 0.065033 | TSUw: 0.464946 | TSUb: 0.034797\n",
      "\n",
      "Train Epoch: 2075 [4000/8000 (50%)]\tBatch Loss: 736.407468\tLearning Rate (w_theta): 0.001000\t TIME:4279.4s\n",
      "\t\t\t\tDisc: 0.560253\t\tSym: 13.429247\t\tSpars: 722.417969\n",
      "\t TVw: 0.027645 | TVb: -2.042034 | GSw: -0.234959 | GSb: 0.065033 | TSUw: 0.464946 | TSUb: 0.034797\n",
      "Validating epoch 2075...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 734.58528787208\n",
      "Average validation loss: 67.67391315962593\n",
      "Training epoch 2076...\n",
      "\n",
      "Train Epoch: 2076 [0/8000 (0%)]\tBatch Loss: 693.752188\tLearning Rate (w_theta): 0.001000\t TIME:4282.1s\n",
      "\t\t\t\tDisc: 0.412638\t\tSym: 10.796398\t\tSpars: 682.543152\n",
      "\t TVw: 0.028287 | TVb: -2.042028 | GSw: -0.234959 | GSb: 0.065033 | TSUw: 0.464946 | TSUb: 0.034797\n",
      "\n",
      "Train Epoch: 2076 [4000/8000 (50%)]\tBatch Loss: 749.020803\tLearning Rate (w_theta): 0.001000\t TIME:4283.7s\n",
      "\t\t\t\tDisc: 0.510712\t\tSym: 13.838887\t\tSpars: 734.671204\n",
      "\t TVw: 0.028918 | TVb: -2.042020 | GSw: -0.234959 | GSb: 0.065033 | TSUw: 0.464946 | TSUb: 0.034797\n",
      "Validating epoch 2076...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 735.1341734935476\n",
      "Average validation loss: 67.14724549230267\n",
      "Training epoch 2077...\n",
      "\n",
      "Train Epoch: 2077 [0/8000 (0%)]\tBatch Loss: 730.672450\tLearning Rate (w_theta): 0.001000\t TIME:4286.1s\n",
      "\t\t\t\tDisc: 0.488224\t\tSym: 12.349387\t\tSpars: 717.834839\n",
      "\t TVw: 0.029564 | TVb: -2.042016 | GSw: -0.234959 | GSb: 0.065033 | TSUw: 0.464946 | TSUb: 0.034797\n",
      "\n",
      "Train Epoch: 2077 [4000/8000 (50%)]\tBatch Loss: 750.597161\tLearning Rate (w_theta): 0.001000\t TIME:4287.6s\n",
      "\t\t\t\tDisc: 0.540266\t\tSym: 14.347362\t\tSpars: 735.709534\n",
      "\t TVw: 0.030203 | TVb: -2.042009 | GSw: -0.234959 | GSb: 0.065033 | TSUw: 0.464945 | TSUb: 0.034797\n",
      "Validating epoch 2077...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 739.4850455292928\n",
      "Average validation loss: 68.26793932883511\n",
      "Training epoch 2078...\n",
      "\n",
      "Train Epoch: 2078 [0/8000 (0%)]\tBatch Loss: 753.873704\tLearning Rate (w_theta): 0.001000\t TIME:4290.1s\n",
      "\t\t\t\tDisc: 0.560215\t\tSym: 13.652966\t\tSpars: 739.660522\n",
      "\t TVw: 0.030795 | TVb: -2.042002 | GSw: -0.234959 | GSb: 0.065033 | TSUw: 0.464945 | TSUb: 0.034798\n",
      "\n",
      "Train Epoch: 2078 [4000/8000 (50%)]\tBatch Loss: 723.809027\tLearning Rate (w_theta): 0.001000\t TIME:4291.7s\n",
      "\t\t\t\tDisc: 0.490738\t\tSym: 12.577323\t\tSpars: 710.740967\n",
      "\t TVw: 0.031369 | TVb: -2.041996 | GSw: -0.234959 | GSb: 0.065032 | TSUw: 0.464945 | TSUb: 0.034798\n",
      "Validating epoch 2078...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 735.7301685986764\n",
      "Average validation loss: 67.35715298816915\n",
      "Training epoch 2079...\n",
      "\n",
      "Train Epoch: 2079 [0/8000 (0%)]\tBatch Loss: 733.956060\tLearning Rate (w_theta): 0.001000\t TIME:4294.1s\n",
      "\t\t\t\tDisc: 0.441338\t\tSym: 13.226331\t\tSpars: 720.288391\n",
      "\t TVw: 0.031921 | TVb: -2.041994 | GSw: -0.234959 | GSb: 0.065032 | TSUw: 0.464945 | TSUb: 0.034798\n",
      "\n",
      "Train Epoch: 2079 [4000/8000 (50%)]\tBatch Loss: 685.080049\tLearning Rate (w_theta): 0.001000\t TIME:4295.6s\n",
      "\t\t\t\tDisc: 0.449237\t\tSym: 10.726088\t\tSpars: 673.904724\n",
      "\t TVw: 0.032519 | TVb: -2.041988 | GSw: -0.234959 | GSb: 0.065032 | TSUw: 0.464945 | TSUb: 0.034798\n",
      "Validating epoch 2079...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 732.9403850039223\n",
      "Average validation loss: 67.44553141200944\n",
      "Training epoch 2080...\n",
      "\n",
      "Train Epoch: 2080 [0/8000 (0%)]\tBatch Loss: 739.418271\tLearning Rate (w_theta): 0.001000\t TIME:4298.0s\n",
      "\t\t\t\tDisc: 0.490260\t\tSym: 13.579805\t\tSpars: 725.348206\n",
      "\t TVw: 0.033082 | TVb: -2.041985 | GSw: -0.234959 | GSb: 0.065032 | TSUw: 0.464945 | TSUb: 0.034798\n",
      "\n",
      "Train Epoch: 2080 [4000/8000 (50%)]\tBatch Loss: 747.146017\tLearning Rate (w_theta): 0.001000\t TIME:4299.6s\n",
      "\t\t\t\tDisc: 0.507746\t\tSym: 12.878444\t\tSpars: 733.759827\n",
      "\t TVw: 0.033696 | TVb: -2.041978 | GSw: -0.234959 | GSb: 0.065032 | TSUw: 0.464945 | TSUb: 0.034798\n",
      "Validating epoch 2080...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 731.9368059127787\n",
      "Average validation loss: 67.9744857426548\n",
      "Training epoch 2081...\n",
      "\n",
      "Train Epoch: 2081 [0/8000 (0%)]\tBatch Loss: 749.280553\tLearning Rate (w_theta): 0.001000\t TIME:4302.6s\n",
      "\t\t\t\tDisc: 0.517252\t\tSym: 13.674434\t\tSpars: 735.088867\n",
      "\t TVw: 0.034344 | TVb: -2.041969 | GSw: -0.234959 | GSb: 0.065032 | TSUw: 0.464945 | TSUb: 0.034798\n",
      "\n",
      "Train Epoch: 2081 [4000/8000 (50%)]\tBatch Loss: 751.176850\tLearning Rate (w_theta): 0.001000\t TIME:4304.2s\n",
      "\t\t\t\tDisc: 0.524677\t\tSym: 13.166333\t\tSpars: 737.485840\n",
      "\t TVw: 0.034997 | TVb: -2.041960 | GSw: -0.234959 | GSb: 0.065032 | TSUw: 0.464945 | TSUb: 0.034798\n",
      "Validating epoch 2081...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 730.4698526295375\n",
      "Average validation loss: 67.52473914699038\n",
      "Training epoch 2082...\n",
      "\n",
      "Train Epoch: 2082 [0/8000 (0%)]\tBatch Loss: 696.986577\tLearning Rate (w_theta): 0.001000\t TIME:4306.7s\n",
      "\t\t\t\tDisc: 0.497803\t\tSym: 12.073125\t\tSpars: 684.415649\n",
      "\t TVw: 0.035613 | TVb: -2.041953 | GSw: -0.234959 | GSb: 0.065032 | TSUw: 0.464944 | TSUb: 0.034798\n",
      "\n",
      "Train Epoch: 2082 [4000/8000 (50%)]\tBatch Loss: 714.038431\tLearning Rate (w_theta): 0.001000\t TIME:4308.2s\n",
      "\t\t\t\tDisc: 0.470108\t\tSym: 11.659143\t\tSpars: 701.909180\n",
      "\t TVw: 0.036200 | TVb: -2.041947 | GSw: -0.234959 | GSb: 0.065032 | TSUw: 0.464944 | TSUb: 0.034798\n",
      "Validating epoch 2082...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 728.6754062320082\n",
      "Average validation loss: 66.68258045571811\n",
      "Training epoch 2083...\n",
      "\n",
      "Train Epoch: 2083 [0/8000 (0%)]\tBatch Loss: 777.975026\tLearning Rate (w_theta): 0.001000\t TIME:4310.6s\n",
      "\t\t\t\tDisc: 0.555406\t\tSym: 14.630862\t\tSpars: 762.788757\n",
      "\t TVw: 0.036794 | TVb: -2.041942 | GSw: -0.234959 | GSb: 0.065032 | TSUw: 0.464944 | TSUb: 0.034798\n",
      "\n",
      "Train Epoch: 2083 [4000/8000 (50%)]\tBatch Loss: 741.874908\tLearning Rate (w_theta): 0.001000\t TIME:4312.2s\n",
      "\t\t\t\tDisc: 0.545027\t\tSym: 13.675219\t\tSpars: 727.654663\n",
      "\t TVw: 0.037428 | TVb: -2.041936 | GSw: -0.234959 | GSb: 0.065032 | TSUw: 0.464944 | TSUb: 0.034798\n",
      "Validating epoch 2083...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 729.827194050479\n",
      "Average validation loss: 67.30583444667613\n",
      "Training epoch 2084...\n",
      "\n",
      "Train Epoch: 2084 [0/8000 (0%)]\tBatch Loss: 755.210555\tLearning Rate (w_theta): 0.001000\t TIME:4314.8s\n",
      "\t\t\t\tDisc: 0.525045\t\tSym: 14.462366\t\tSpars: 740.223145\n",
      "\t TVw: 0.038045 | TVb: -2.041930 | GSw: -0.234959 | GSb: 0.065032 | TSUw: 0.464944 | TSUb: 0.034798\n",
      "\n",
      "Train Epoch: 2084 [4000/8000 (50%)]\tBatch Loss: 745.538109\tLearning Rate (w_theta): 0.001000\t TIME:4316.3s\n",
      "\t\t\t\tDisc: 0.478667\t\tSym: 12.595148\t\tSpars: 732.464294\n",
      "\t TVw: 0.038607 | TVb: -2.041928 | GSw: -0.234959 | GSb: 0.065032 | TSUw: 0.464944 | TSUb: 0.034798\n",
      "Validating epoch 2084...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 729.942048463377\n",
      "Average validation loss: 67.70402320813878\n",
      "Training epoch 2085...\n",
      "\n",
      "Train Epoch: 2085 [0/8000 (0%)]\tBatch Loss: 719.134015\tLearning Rate (w_theta): 0.001000\t TIME:4318.7s\n",
      "\t\t\t\tDisc: 0.463758\t\tSym: 12.401824\t\tSpars: 706.268433\n",
      "\t TVw: 0.039188 | TVb: -2.041924 | GSw: -0.234959 | GSb: 0.065032 | TSUw: 0.464944 | TSUb: 0.034798\n",
      "\n",
      "Train Epoch: 2085 [4000/8000 (50%)]\tBatch Loss: 742.442631\tLearning Rate (w_theta): 0.001000\t TIME:4320.3s\n",
      "\t\t\t\tDisc: 0.494483\t\tSym: 13.015775\t\tSpars: 728.932373\n",
      "\t TVw: 0.039804 | TVb: -2.041917 | GSw: -0.234959 | GSb: 0.065032 | TSUw: 0.464944 | TSUb: 0.034798\n",
      "Validating epoch 2085...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 732.6397005260533\n",
      "Average validation loss: 67.27162563715777\n",
      "Training epoch 2086...\n",
      "\n",
      "Train Epoch: 2086 [0/8000 (0%)]\tBatch Loss: 767.489824\tLearning Rate (w_theta): 0.001000\t TIME:4323.1s\n",
      "\t\t\t\tDisc: 0.577173\t\tSym: 14.550407\t\tSpars: 752.362244\n",
      "\t TVw: 0.040423 | TVb: -2.041911 | GSw: -0.234959 | GSb: 0.065032 | TSUw: 0.464944 | TSUb: 0.034798\n",
      "\n",
      "Train Epoch: 2086 [4000/8000 (50%)]\tBatch Loss: 709.037682\tLearning Rate (w_theta): 0.001000\t TIME:4324.6s\n",
      "\t\t\t\tDisc: 0.438613\t\tSym: 12.139962\t\tSpars: 696.459106\n",
      "\t TVw: 0.041020 | TVb: -2.041905 | GSw: -0.234959 | GSb: 0.065032 | TSUw: 0.464943 | TSUb: 0.034799\n",
      "Validating epoch 2086...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 728.3410149377906\n",
      "Average validation loss: 67.91956167500575\n",
      "Training epoch 2087...\n",
      "\n",
      "Train Epoch: 2087 [0/8000 (0%)]\tBatch Loss: 740.043082\tLearning Rate (w_theta): 0.001000\t TIME:4327.0s\n",
      "\t\t\t\tDisc: 0.521946\t\tSym: 13.809039\t\tSpars: 725.712097\n",
      "\t TVw: 0.041614 | TVb: -2.041898 | GSw: -0.234959 | GSb: 0.065031 | TSUw: 0.464943 | TSUb: 0.034799\n",
      "\n",
      "Train Epoch: 2087 [4000/8000 (50%)]\tBatch Loss: 795.499654\tLearning Rate (w_theta): 0.001000\t TIME:4328.5s\n",
      "\t\t\t\tDisc: 0.531735\t\tSym: 16.057457\t\tSpars: 778.910461\n",
      "\t TVw: 0.042216 | TVb: -2.041889 | GSw: -0.234959 | GSb: 0.065031 | TSUw: 0.464943 | TSUb: 0.034799\n",
      "Validating epoch 2087...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 729.8120678770591\n",
      "Average validation loss: 67.31068153436892\n",
      "Training epoch 2088...\n",
      "\n",
      "Train Epoch: 2088 [0/8000 (0%)]\tBatch Loss: 688.657987\tLearning Rate (w_theta): 0.001000\t TIME:4330.9s\n",
      "\t\t\t\tDisc: 0.420130\t\tSym: 11.020450\t\tSpars: 677.217407\n",
      "\t TVw: 0.042803 | TVb: -2.041884 | GSw: -0.234959 | GSb: 0.065031 | TSUw: 0.464943 | TSUb: 0.034799\n",
      "\n",
      "Train Epoch: 2088 [4000/8000 (50%)]\tBatch Loss: 730.082632\tLearning Rate (w_theta): 0.001000\t TIME:4332.5s\n",
      "\t\t\t\tDisc: 0.475070\t\tSym: 13.257892\t\tSpars: 716.349670\n",
      "\t TVw: 0.043372 | TVb: -2.041880 | GSw: -0.234959 | GSb: 0.065031 | TSUw: 0.464943 | TSUb: 0.034799\n",
      "Validating epoch 2088...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 723.4529970027744\n",
      "Average validation loss: 66.76038748248624\n",
      "Training epoch 2089...\n",
      "\n",
      "Train Epoch: 2089 [0/8000 (0%)]\tBatch Loss: 734.059111\tLearning Rate (w_theta): 0.001000\t TIME:4334.9s\n",
      "\t\t\t\tDisc: 0.446284\t\tSym: 13.695163\t\tSpars: 719.917664\n",
      "\t TVw: 0.043953 | TVb: -2.041876 | GSw: -0.234959 | GSb: 0.065031 | TSUw: 0.464943 | TSUb: 0.034799\n",
      "\n",
      "Train Epoch: 2089 [4000/8000 (50%)]\tBatch Loss: 723.161341\tLearning Rate (w_theta): 0.001000\t TIME:4336.4s\n",
      "\t\t\t\tDisc: 0.480441\t\tSym: 11.977592\t\tSpars: 710.703308\n",
      "\t TVw: 0.044581 | TVb: -2.041871 | GSw: -0.234959 | GSb: 0.065031 | TSUw: 0.464943 | TSUb: 0.034799\n",
      "Validating epoch 2089...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 725.5775916342241\n",
      "Average validation loss: 67.84482081769913\n",
      "Training epoch 2090...\n",
      "\n",
      "Train Epoch: 2090 [0/8000 (0%)]\tBatch Loss: 720.416616\tLearning Rate (w_theta): 0.001000\t TIME:4338.9s\n",
      "\t\t\t\tDisc: 0.490176\t\tSym: 12.448962\t\tSpars: 707.477478\n",
      "\t TVw: 0.045224 | TVb: -2.041863 | GSw: -0.234959 | GSb: 0.065031 | TSUw: 0.464943 | TSUb: 0.034799\n",
      "\n",
      "Train Epoch: 2090 [4000/8000 (50%)]\tBatch Loss: 743.533707\tLearning Rate (w_theta): 0.001000\t TIME:4340.4s\n",
      "\t\t\t\tDisc: 0.452714\t\tSym: 13.962708\t\tSpars: 729.118286\n",
      "\t TVw: 0.045870 | TVb: -2.041856 | GSw: -0.234959 | GSb: 0.065031 | TSUw: 0.464943 | TSUb: 0.034799\n",
      "Validating epoch 2090...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 725.6584669512848\n",
      "Average validation loss: 65.96028146963204\n",
      "Training epoch 2091...\n",
      "\n",
      "Train Epoch: 2091 [0/8000 (0%)]\tBatch Loss: 731.001511\tLearning Rate (w_theta): 0.001000\t TIME:4343.5s\n",
      "\t\t\t\tDisc: 0.412865\t\tSym: 13.480186\t\tSpars: 717.108459\n",
      "\t TVw: 0.046479 | TVb: -2.041852 | GSw: -0.234959 | GSb: 0.065031 | TSUw: 0.464942 | TSUb: 0.034799\n",
      "\n",
      "Train Epoch: 2091 [4000/8000 (50%)]\tBatch Loss: 732.592688\tLearning Rate (w_theta): 0.001000\t TIME:4345.1s\n",
      "\t\t\t\tDisc: 0.479032\t\tSym: 13.124092\t\tSpars: 718.989563\n",
      "\t TVw: 0.047062 | TVb: -2.041846 | GSw: -0.234959 | GSb: 0.065031 | TSUw: 0.464942 | TSUb: 0.034799\n",
      "Validating epoch 2091...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 727.3009281831626\n",
      "Average validation loss: 67.85275031813508\n",
      "Training epoch 2092...\n",
      "\n",
      "Train Epoch: 2092 [0/8000 (0%)]\tBatch Loss: 731.897728\tLearning Rate (w_theta): 0.001000\t TIME:4347.5s\n",
      "\t\t\t\tDisc: 0.508328\t\tSym: 12.712947\t\tSpars: 718.676453\n",
      "\t TVw: 0.047639 | TVb: -2.041839 | GSw: -0.234959 | GSb: 0.065031 | TSUw: 0.464942 | TSUb: 0.034799\n",
      "\n",
      "Train Epoch: 2092 [4000/8000 (50%)]\tBatch Loss: 705.969569\tLearning Rate (w_theta): 0.001000\t TIME:4349.1s\n",
      "\t\t\t\tDisc: 0.423155\t\tSym: 12.186368\t\tSpars: 693.360046\n",
      "\t TVw: 0.048240 | TVb: -2.041831 | GSw: -0.234959 | GSb: 0.065031 | TSUw: 0.464942 | TSUb: 0.034799\n",
      "Validating epoch 2092...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 723.1551992915347\n",
      "Average validation loss: 66.62015897149998\n",
      "Training epoch 2093...\n",
      "\n",
      "Train Epoch: 2093 [0/8000 (0%)]\tBatch Loss: 741.935283\tLearning Rate (w_theta): 0.001000\t TIME:4351.5s\n",
      "\t\t\t\tDisc: 0.485385\t\tSym: 13.292610\t\tSpars: 728.157288\n",
      "\t TVw: 0.048800 | TVb: -2.041824 | GSw: -0.234959 | GSb: 0.065031 | TSUw: 0.464942 | TSUb: 0.034799\n",
      "\n",
      "Train Epoch: 2093 [4000/8000 (50%)]\tBatch Loss: 700.575357\tLearning Rate (w_theta): 0.001000\t TIME:4353.1s\n",
      "\t\t\t\tDisc: 0.459642\t\tSym: 12.197258\t\tSpars: 687.918457\n",
      "\t TVw: 0.049387 | TVb: -2.041817 | GSw: -0.234959 | GSb: 0.065031 | TSUw: 0.464942 | TSUb: 0.034799\n",
      "Validating epoch 2093...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 719.8806499867314\n",
      "Average validation loss: 66.8826426484624\n",
      "Training epoch 2094...\n",
      "\n",
      "Train Epoch: 2094 [0/8000 (0%)]\tBatch Loss: 732.760838\tLearning Rate (w_theta): 0.001000\t TIME:4355.5s\n",
      "\t\t\t\tDisc: 0.394375\t\tSym: 13.565804\t\tSpars: 718.800659\n",
      "\t TVw: 0.050028 | TVb: -2.041810 | GSw: -0.234959 | GSb: 0.065031 | TSUw: 0.464942 | TSUb: 0.034799\n",
      "\n",
      "Train Epoch: 2094 [4000/8000 (50%)]\tBatch Loss: 737.365475\tLearning Rate (w_theta): 0.001000\t TIME:4357.0s\n",
      "\t\t\t\tDisc: 0.482751\t\tSym: 13.849887\t\tSpars: 723.032837\n",
      "\t TVw: 0.050631 | TVb: -2.041805 | GSw: -0.234959 | GSb: 0.065031 | TSUw: 0.464942 | TSUb: 0.034799\n",
      "Validating epoch 2094...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 721.2181190771066\n",
      "Average validation loss: 66.431127935379\n",
      "Training epoch 2095...\n",
      "\n",
      "Train Epoch: 2095 [0/8000 (0%)]\tBatch Loss: 707.594339\tLearning Rate (w_theta): 0.001000\t TIME:4359.4s\n",
      "\t\t\t\tDisc: 0.472583\t\tSym: 11.811270\t\tSpars: 695.310486\n",
      "\t TVw: 0.051250 | TVb: -2.041798 | GSw: -0.234959 | GSb: 0.065030 | TSUw: 0.464941 | TSUb: 0.034800\n",
      "\n",
      "Train Epoch: 2095 [4000/8000 (50%)]\tBatch Loss: 732.907962\tLearning Rate (w_theta): 0.001000\t TIME:4361.0s\n",
      "\t\t\t\tDisc: 0.482666\t\tSym: 14.165896\t\tSpars: 718.259399\n",
      "\t TVw: 0.051866 | TVb: -2.041791 | GSw: -0.234959 | GSb: 0.065030 | TSUw: 0.464941 | TSUb: 0.034800\n",
      "Validating epoch 2095...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 716.9035559636973\n",
      "Average validation loss: 66.24759228175921\n",
      "Training epoch 2096...\n",
      "\n",
      "Train Epoch: 2096 [0/8000 (0%)]\tBatch Loss: 713.765637\tLearning Rate (w_theta): 0.001000\t TIME:4363.4s\n",
      "\t\t\t\tDisc: 0.450700\t\tSym: 12.034480\t\tSpars: 701.280457\n",
      "\t TVw: 0.052441 | TVb: -2.041787 | GSw: -0.234959 | GSb: 0.065030 | TSUw: 0.464941 | TSUb: 0.034800\n",
      "\n",
      "Train Epoch: 2096 [4000/8000 (50%)]\tBatch Loss: 718.473798\tLearning Rate (w_theta): 0.001000\t TIME:4365.3s\n",
      "\t\t\t\tDisc: 0.524066\t\tSym: 12.350307\t\tSpars: 705.599426\n",
      "\t TVw: 0.053038 | TVb: -2.041782 | GSw: -0.234959 | GSb: 0.065030 | TSUw: 0.464941 | TSUb: 0.034800\n",
      "Validating epoch 2096...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 724.0322919704814\n",
      "Average validation loss: 67.36294193989431\n",
      "Training epoch 2097...\n",
      "\n",
      "Train Epoch: 2097 [0/8000 (0%)]\tBatch Loss: 703.107550\tLearning Rate (w_theta): 0.001000\t TIME:4367.7s\n",
      "\t\t\t\tDisc: 0.473084\t\tSym: 12.200140\t\tSpars: 690.434326\n",
      "\t TVw: 0.053636 | TVb: -2.041776 | GSw: -0.234959 | GSb: 0.065030 | TSUw: 0.464941 | TSUb: 0.034800\n",
      "\n",
      "Train Epoch: 2097 [4000/8000 (50%)]\tBatch Loss: 726.792383\tLearning Rate (w_theta): 0.001000\t TIME:4369.2s\n",
      "\t\t\t\tDisc: 0.472999\t\tSym: 12.863207\t\tSpars: 713.456177\n",
      "\t TVw: 0.054207 | TVb: -2.041771 | GSw: -0.234959 | GSb: 0.065030 | TSUw: 0.464941 | TSUb: 0.034800\n",
      "Validating epoch 2097...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 724.8242679452121\n",
      "Average validation loss: 65.9240845978319\n",
      "Training epoch 2098...\n",
      "\n",
      "Train Epoch: 2098 [0/8000 (0%)]\tBatch Loss: 757.162860\tLearning Rate (w_theta): 0.001000\t TIME:4371.6s\n",
      "\t\t\t\tDisc: 0.442396\t\tSym: 13.200627\t\tSpars: 743.519836\n",
      "\t TVw: 0.054699 | TVb: -2.041769 | GSw: -0.234959 | GSb: 0.065030 | TSUw: 0.464941 | TSUb: 0.034800\n",
      "\n",
      "Train Epoch: 2098 [4000/8000 (50%)]\tBatch Loss: 677.018231\tLearning Rate (w_theta): 0.001000\t TIME:4373.2s\n",
      "\t\t\t\tDisc: 0.435953\t\tSym: 10.812747\t\tSpars: 665.769531\n",
      "\t TVw: 0.055175 | TVb: -2.041765 | GSw: -0.234959 | GSb: 0.065030 | TSUw: 0.464941 | TSUb: 0.034800\n",
      "Validating epoch 2098...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 720.6081450138078\n",
      "Average validation loss: 67.9263968347221\n",
      "Training epoch 2099...\n",
      "\n",
      "Train Epoch: 2099 [0/8000 (0%)]\tBatch Loss: 706.745924\tLearning Rate (w_theta): 0.001000\t TIME:4375.6s\n",
      "\t\t\t\tDisc: 0.452722\t\tSym: 12.843495\t\tSpars: 693.449707\n",
      "\t TVw: 0.055752 | TVb: -2.041759 | GSw: -0.234959 | GSb: 0.065030 | TSUw: 0.464940 | TSUb: 0.034800\n",
      "\n",
      "Train Epoch: 2099 [4000/8000 (50%)]\tBatch Loss: 753.390127\tLearning Rate (w_theta): 0.001000\t TIME:4377.2s\n",
      "\t\t\t\tDisc: 0.534901\t\tSym: 14.536257\t\tSpars: 738.318970\n",
      "\t TVw: 0.056403 | TVb: -2.041749 | GSw: -0.234959 | GSb: 0.065030 | TSUw: 0.464940 | TSUb: 0.034800\n",
      "Validating epoch 2099...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 716.4414746909231\n",
      "Average validation loss: 66.8616106336368\n",
      "Training epoch 2100...\n",
      "\n",
      "Train Epoch: 2100 [0/8000 (0%)]\tBatch Loss: 753.661338\tLearning Rate (w_theta): 0.001000\t TIME:4379.5s\n",
      "\t\t\t\tDisc: 0.545136\t\tSym: 14.193778\t\tSpars: 738.922424\n",
      "\t TVw: 0.057012 | TVb: -2.041742 | GSw: -0.234959 | GSb: 0.065030 | TSUw: 0.464940 | TSUb: 0.034800\n",
      "\n",
      "Train Epoch: 2100 [4000/8000 (50%)]\tBatch Loss: 717.514027\tLearning Rate (w_theta): 0.001000\t TIME:4381.1s\n",
      "\t\t\t\tDisc: 0.402931\t\tSym: 13.037671\t\tSpars: 704.073425\n",
      "\t TVw: 0.057597 | TVb: -2.041738 | GSw: -0.234959 | GSb: 0.065030 | TSUw: 0.464940 | TSUb: 0.034800\n",
      "Validating epoch 2100...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 714.9178105692145\n",
      "Average validation loss: 66.75795716148454\n",
      "Training epoch 2101...\n",
      "\n",
      "Train Epoch: 2101 [0/8000 (0%)]\tBatch Loss: 723.195634\tLearning Rate (w_theta): 0.001000\t TIME:4384.2s\n",
      "\t\t\t\tDisc: 0.439055\t\tSym: 13.108629\t\tSpars: 709.647949\n",
      "\t TVw: 0.058255 | TVb: -2.041730 | GSw: -0.234959 | GSb: 0.065030 | TSUw: 0.464940 | TSUb: 0.034800\n",
      "\n",
      "Train Epoch: 2101 [4000/8000 (50%)]\tBatch Loss: 751.301676\tLearning Rate (w_theta): 0.001000\t TIME:4385.8s\n",
      "\t\t\t\tDisc: 0.547854\t\tSym: 14.979713\t\tSpars: 735.774109\n",
      "\t TVw: 0.058949 | TVb: -2.041721 | GSw: -0.234959 | GSb: 0.065029 | TSUw: 0.464940 | TSUb: 0.034800\n",
      "Validating epoch 2101...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 712.9731599944406\n",
      "Average validation loss: 66.36532117053397\n",
      "Training epoch 2102...\n",
      "\n",
      "Train Epoch: 2102 [0/8000 (0%)]\tBatch Loss: 731.937221\tLearning Rate (w_theta): 0.001000\t TIME:4388.2s\n",
      "\t\t\t\tDisc: 0.506281\t\tSym: 13.573702\t\tSpars: 717.857239\n",
      "\t TVw: 0.059607 | TVb: -2.041715 | GSw: -0.234959 | GSb: 0.065029 | TSUw: 0.464940 | TSUb: 0.034800\n",
      "\n",
      "Train Epoch: 2102 [4000/8000 (50%)]\tBatch Loss: 700.729916\tLearning Rate (w_theta): 0.001000\t TIME:4389.8s\n",
      "\t\t\t\tDisc: 0.449740\t\tSym: 12.166895\t\tSpars: 688.113281\n",
      "\t TVw: 0.060238 | TVb: -2.041710 | GSw: -0.234959 | GSb: 0.065029 | TSUw: 0.464940 | TSUb: 0.034800\n",
      "Validating epoch 2102...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 711.2411711687889\n",
      "Average validation loss: 66.47057797601471\n",
      "Training epoch 2103...\n",
      "\n",
      "Train Epoch: 2103 [0/8000 (0%)]\tBatch Loss: 719.471151\tLearning Rate (w_theta): 0.001000\t TIME:4392.2s\n",
      "\t\t\t\tDisc: 0.474504\t\tSym: 12.972356\t\tSpars: 706.024292\n",
      "\t TVw: 0.060853 | TVb: -2.041704 | GSw: -0.234959 | GSb: 0.065029 | TSUw: 0.464940 | TSUb: 0.034800\n",
      "\n",
      "Train Epoch: 2103 [4000/8000 (50%)]\tBatch Loss: 673.089439\tLearning Rate (w_theta): 0.001000\t TIME:4393.7s\n",
      "\t\t\t\tDisc: 0.431426\t\tSym: 11.255608\t\tSpars: 661.402405\n",
      "\t TVw: 0.061483 | TVb: -2.041698 | GSw: -0.234959 | GSb: 0.065029 | TSUw: 0.464939 | TSUb: 0.034801\n",
      "Validating epoch 2103...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 711.4972920874065\n",
      "Average validation loss: 66.24223786672462\n",
      "Training epoch 2104...\n",
      "\n",
      "Train Epoch: 2104 [0/8000 (0%)]\tBatch Loss: 706.431758\tLearning Rate (w_theta): 0.001000\t TIME:4396.1s\n",
      "\t\t\t\tDisc: 0.402975\t\tSym: 12.490758\t\tSpars: 693.538025\n",
      "\t TVw: 0.062087 | TVb: -2.041694 | GSw: -0.234959 | GSb: 0.065029 | TSUw: 0.464939 | TSUb: 0.034801\n",
      "\n",
      "Train Epoch: 2104 [4000/8000 (50%)]\tBatch Loss: 711.775539\tLearning Rate (w_theta): 0.001000\t TIME:4397.7s\n",
      "\t\t\t\tDisc: 0.456181\t\tSym: 12.232383\t\tSpars: 699.086975\n",
      "\t TVw: 0.062688 | TVb: -2.041690 | GSw: -0.234959 | GSb: 0.065029 | TSUw: 0.464939 | TSUb: 0.034801\n",
      "Validating epoch 2104...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 711.017506097802\n",
      "Average validation loss: 66.93467771844635\n",
      "Training epoch 2105...\n",
      "\n",
      "Train Epoch: 2105 [0/8000 (0%)]\tBatch Loss: 718.907848\tLearning Rate (w_theta): 0.001000\t TIME:4400.0s\n",
      "\t\t\t\tDisc: 0.458803\t\tSym: 13.314585\t\tSpars: 705.134460\n",
      "\t TVw: 0.063262 | TVb: -2.041686 | GSw: -0.234959 | GSb: 0.065029 | TSUw: 0.464939 | TSUb: 0.034801\n",
      "\n",
      "Train Epoch: 2105 [4000/8000 (50%)]\tBatch Loss: 695.878794\tLearning Rate (w_theta): 0.001000\t TIME:4401.6s\n",
      "\t\t\t\tDisc: 0.378868\t\tSym: 12.205615\t\tSpars: 683.294312\n",
      "\t TVw: 0.063856 | TVb: -2.041683 | GSw: -0.234959 | GSb: 0.065029 | TSUw: 0.464939 | TSUb: 0.034801\n",
      "Validating epoch 2105...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 708.7482500145632\n",
      "Average validation loss: 66.13270163916178\n",
      "Training epoch 2106...\n",
      "\n",
      "Train Epoch: 2106 [0/8000 (0%)]\tBatch Loss: 713.690544\tLearning Rate (w_theta): 0.001000\t TIME:4404.0s\n",
      "\t\t\t\tDisc: 0.427480\t\tSym: 12.966067\t\tSpars: 700.296997\n",
      "\t TVw: 0.064426 | TVb: -2.041679 | GSw: -0.234959 | GSb: 0.065029 | TSUw: 0.464939 | TSUb: 0.034801\n",
      "\n",
      "Train Epoch: 2106 [4000/8000 (50%)]\tBatch Loss: 709.077536\tLearning Rate (w_theta): 0.001000\t TIME:4405.6s\n",
      "\t\t\t\tDisc: 0.461727\t\tSym: 12.049159\t\tSpars: 696.566650\n",
      "\t TVw: 0.065050 | TVb: -2.041671 | GSw: -0.234959 | GSb: 0.065029 | TSUw: 0.464939 | TSUb: 0.034801\n",
      "Validating epoch 2106...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 711.0786653259362\n",
      "Average validation loss: 66.6640690948295\n",
      "Training epoch 2107...\n",
      "\n",
      "Train Epoch: 2107 [0/8000 (0%)]\tBatch Loss: 723.110206\tLearning Rate (w_theta): 0.001000\t TIME:4408.3s\n",
      "\t\t\t\tDisc: 0.447741\t\tSym: 12.976369\t\tSpars: 709.686096\n",
      "\t TVw: 0.065669 | TVb: -2.041663 | GSw: -0.234959 | GSb: 0.065028 | TSUw: 0.464939 | TSUb: 0.034801\n",
      "\n",
      "Train Epoch: 2107 [4000/8000 (50%)]\tBatch Loss: 706.820019\tLearning Rate (w_theta): 0.001000\t TIME:4409.8s\n",
      "\t\t\t\tDisc: 0.441263\t\tSym: 13.532565\t\tSpars: 692.846191\n",
      "\t TVw: 0.066228 | TVb: -2.041661 | GSw: -0.234959 | GSb: 0.065028 | TSUw: 0.464938 | TSUb: 0.034801\n",
      "Validating epoch 2107...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 709.1003817594502\n",
      "Average validation loss: 67.41904557650176\n",
      "Training epoch 2108...\n",
      "\n",
      "Train Epoch: 2108 [0/8000 (0%)]\tBatch Loss: 724.009608\tLearning Rate (w_theta): 0.001000\t TIME:4412.2s\n",
      "\t\t\t\tDisc: 0.497635\t\tSym: 13.562021\t\tSpars: 709.949951\n",
      "\t TVw: 0.066819 | TVb: -2.041655 | GSw: -0.234959 | GSb: 0.065028 | TSUw: 0.464938 | TSUb: 0.034801\n",
      "\n",
      "Train Epoch: 2108 [4000/8000 (50%)]\tBatch Loss: 708.594175\tLearning Rate (w_theta): 0.001000\t TIME:4413.8s\n",
      "\t\t\t\tDisc: 0.444472\t\tSym: 12.805344\t\tSpars: 695.344360\n",
      "\t TVw: 0.067421 | TVb: -2.041649 | GSw: -0.234959 | GSb: 0.065028 | TSUw: 0.464938 | TSUb: 0.034801\n",
      "Validating epoch 2108...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 708.1470421668591\n",
      "Average validation loss: 66.88528766759386\n",
      "Training epoch 2109...\n",
      "\n",
      "Train Epoch: 2109 [0/8000 (0%)]\tBatch Loss: 691.726872\tLearning Rate (w_theta): 0.001000\t TIME:4416.1s\n",
      "\t\t\t\tDisc: 0.436014\t\tSym: 11.995203\t\tSpars: 679.295654\n",
      "\t TVw: 0.068020 | TVb: -2.041643 | GSw: -0.234959 | GSb: 0.065028 | TSUw: 0.464938 | TSUb: 0.034801\n",
      "\n",
      "Train Epoch: 2109 [4000/8000 (50%)]\tBatch Loss: 722.064319\tLearning Rate (w_theta): 0.001000\t TIME:4417.7s\n",
      "\t\t\t\tDisc: 0.481866\t\tSym: 13.682367\t\tSpars: 707.900085\n",
      "\t TVw: 0.068596 | TVb: -2.041638 | GSw: -0.234959 | GSb: 0.065028 | TSUw: 0.464938 | TSUb: 0.034801\n",
      "Validating epoch 2109...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 705.5491820336588\n",
      "Average validation loss: 67.0849426966704\n",
      "Training epoch 2110...\n",
      "\n",
      "Train Epoch: 2110 [0/8000 (0%)]\tBatch Loss: 743.693730\tLearning Rate (w_theta): 0.001000\t TIME:4420.1s\n",
      "\t\t\t\tDisc: 0.480881\t\tSym: 13.598775\t\tSpars: 729.614075\n",
      "\t TVw: 0.069179 | TVb: -2.041632 | GSw: -0.234959 | GSb: 0.065028 | TSUw: 0.464938 | TSUb: 0.034801\n",
      "\n",
      "Train Epoch: 2110 [4000/8000 (50%)]\tBatch Loss: 716.015065\tLearning Rate (w_theta): 0.001000\t TIME:4421.7s\n",
      "\t\t\t\tDisc: 0.442508\t\tSym: 13.475634\t\tSpars: 702.096924\n",
      "\t TVw: 0.069739 | TVb: -2.041627 | GSw: -0.234959 | GSb: 0.065028 | TSUw: 0.464938 | TSUb: 0.034801\n",
      "Validating epoch 2110...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 705.9780843367988\n",
      "Average validation loss: 67.10255149480838\n",
      "Training epoch 2111...\n",
      "\n",
      "Train Epoch: 2111 [0/8000 (0%)]\tBatch Loss: 655.320974\tLearning Rate (w_theta): 0.001000\t TIME:4424.8s\n",
      "\t\t\t\tDisc: 0.430552\t\tSym: 10.486247\t\tSpars: 644.404175\n",
      "\t TVw: 0.070300 | TVb: -2.041622 | GSw: -0.234959 | GSb: 0.065028 | TSUw: 0.464938 | TSUb: 0.034801\n",
      "\n",
      "Train Epoch: 2111 [4000/8000 (50%)]\tBatch Loss: 685.877169\tLearning Rate (w_theta): 0.001000\t TIME:4426.4s\n",
      "\t\t\t\tDisc: 0.429522\t\tSym: 12.402969\t\tSpars: 673.044678\n",
      "\t TVw: 0.070863 | TVb: -2.041615 | GSw: -0.234959 | GSb: 0.065028 | TSUw: 0.464938 | TSUb: 0.034802\n",
      "Validating epoch 2111...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 705.6737939379746\n",
      "Average validation loss: 66.88569961231575\n",
      "Training epoch 2112...\n",
      "\n",
      "Train Epoch: 2112 [0/8000 (0%)]\tBatch Loss: 690.261245\tLearning Rate (w_theta): 0.001000\t TIME:4428.8s\n",
      "\t\t\t\tDisc: 0.431454\t\tSym: 12.186969\t\tSpars: 677.642822\n",
      "\t TVw: 0.071417 | TVb: -2.041607 | GSw: -0.234959 | GSb: 0.065028 | TSUw: 0.464937 | TSUb: 0.034802\n",
      "\n",
      "Train Epoch: 2112 [4000/8000 (50%)]\tBatch Loss: 716.297787\tLearning Rate (w_theta): 0.001000\t TIME:4430.4s\n",
      "\t\t\t\tDisc: 0.490556\t\tSym: 14.351848\t\tSpars: 701.455383\n",
      "\t TVw: 0.071950 | TVb: -2.041600 | GSw: -0.234959 | GSb: 0.065027 | TSUw: 0.464937 | TSUb: 0.034802\n",
      "Validating epoch 2112...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 704.0554002478502\n",
      "Average validation loss: 66.39710100470437\n",
      "Training epoch 2113...\n",
      "\n",
      "Train Epoch: 2113 [0/8000 (0%)]\tBatch Loss: 708.256529\tLearning Rate (w_theta): 0.001000\t TIME:4432.8s\n",
      "\t\t\t\tDisc: 0.396318\t\tSym: 13.109967\t\tSpars: 694.750244\n",
      "\t TVw: 0.072474 | TVb: -2.041595 | GSw: -0.234959 | GSb: 0.065027 | TSUw: 0.464937 | TSUb: 0.034802\n",
      "\n",
      "Train Epoch: 2113 [4000/8000 (50%)]\tBatch Loss: 693.385419\tLearning Rate (w_theta): 0.001000\t TIME:4434.4s\n",
      "\t\t\t\tDisc: 0.403896\t\tSym: 11.910356\t\tSpars: 681.071167\n",
      "\t TVw: 0.073026 | TVb: -2.041587 | GSw: -0.234959 | GSb: 0.065027 | TSUw: 0.464937 | TSUb: 0.034802\n",
      "Validating epoch 2113...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 702.9330441335169\n",
      "Average validation loss: 66.85970455460118\n",
      "Training epoch 2114...\n",
      "\n",
      "Train Epoch: 2114 [0/8000 (0%)]\tBatch Loss: 696.732105\tLearning Rate (w_theta): 0.001000\t TIME:4436.8s\n",
      "\t\t\t\tDisc: 0.469632\t\tSym: 11.890647\t\tSpars: 684.371826\n",
      "\t TVw: 0.073579 | TVb: -2.041580 | GSw: -0.234959 | GSb: 0.065027 | TSUw: 0.464937 | TSUb: 0.034802\n",
      "\n",
      "Train Epoch: 2114 [4000/8000 (50%)]\tBatch Loss: 707.530436\tLearning Rate (w_theta): 0.001000\t TIME:4438.3s\n",
      "\t\t\t\tDisc: 0.382082\t\tSym: 13.421181\t\tSpars: 693.727173\n",
      "\t TVw: 0.074059 | TVb: -2.041577 | GSw: -0.234959 | GSb: 0.065027 | TSUw: 0.464937 | TSUb: 0.034802\n",
      "Validating epoch 2114...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 704.1346658326119\n",
      "Average validation loss: 66.64572129842938\n",
      "Training epoch 2115...\n",
      "\n",
      "Train Epoch: 2115 [0/8000 (0%)]\tBatch Loss: 698.198533\tLearning Rate (w_theta): 0.001000\t TIME:4440.7s\n",
      "\t\t\t\tDisc: 0.465288\t\tSym: 12.698394\t\tSpars: 685.034851\n",
      "\t TVw: 0.074588 | TVb: -2.041571 | GSw: -0.234959 | GSb: 0.065027 | TSUw: 0.464937 | TSUb: 0.034802\n",
      "\n",
      "Train Epoch: 2115 [4000/8000 (50%)]\tBatch Loss: 705.199752\tLearning Rate (w_theta): 0.001000\t TIME:4442.2s\n",
      "\t\t\t\tDisc: 0.402485\t\tSym: 12.565822\t\tSpars: 692.231445\n",
      "\t TVw: 0.075097 | TVb: -2.041564 | GSw: -0.234959 | GSb: 0.065027 | TSUw: 0.464937 | TSUb: 0.034802\n",
      "Validating epoch 2115...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 700.6518076308691\n",
      "Average validation loss: 66.69507059609333\n",
      "Training epoch 2116...\n",
      "\n",
      "Train Epoch: 2116 [0/8000 (0%)]\tBatch Loss: 700.972158\tLearning Rate (w_theta): 0.001000\t TIME:4444.6s\n",
      "\t\t\t\tDisc: 0.405810\t\tSym: 13.072146\t\tSpars: 687.494202\n",
      "\t TVw: 0.075610 | TVb: -2.041561 | GSw: -0.234959 | GSb: 0.065027 | TSUw: 0.464936 | TSUb: 0.034802\n",
      "\n",
      "Train Epoch: 2116 [4000/8000 (50%)]\tBatch Loss: 704.012948\tLearning Rate (w_theta): 0.001000\t TIME:4446.2s\n",
      "\t\t\t\tDisc: 0.398566\t\tSym: 12.694704\t\tSpars: 690.919678\n",
      "\t TVw: 0.076102 | TVb: -2.041558 | GSw: -0.234959 | GSb: 0.065027 | TSUw: 0.464936 | TSUb: 0.034802\n",
      "Validating epoch 2116...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 699.800483199309\n",
      "Average validation loss: 67.10353440048107\n",
      "Training epoch 2117...\n",
      "\n",
      "Train Epoch: 2117 [0/8000 (0%)]\tBatch Loss: 693.751045\tLearning Rate (w_theta): 0.001000\t TIME:4448.9s\n",
      "\t\t\t\tDisc: 0.418133\t\tSym: 12.367702\t\tSpars: 680.965210\n",
      "\t TVw: 0.076631 | TVb: -2.041555 | GSw: -0.234959 | GSb: 0.065027 | TSUw: 0.464936 | TSUb: 0.034802\n",
      "\n",
      "Train Epoch: 2117 [4000/8000 (50%)]\tBatch Loss: 692.223625\tLearning Rate (w_theta): 0.001000\t TIME:4450.5s\n",
      "\t\t\t\tDisc: 0.415549\t\tSym: 12.150117\t\tSpars: 679.657959\n",
      "\t TVw: 0.077190 | TVb: -2.041550 | GSw: -0.234959 | GSb: 0.065027 | TSUw: 0.464936 | TSUb: 0.034802\n",
      "Validating epoch 2117...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 699.9567061232133\n",
      "Average validation loss: 66.95175375783477\n",
      "Training epoch 2118...\n",
      "\n",
      "Train Epoch: 2118 [0/8000 (0%)]\tBatch Loss: 709.540467\tLearning Rate (w_theta): 0.001000\t TIME:4453.0s\n",
      "\t\t\t\tDisc: 0.451380\t\tSym: 12.004004\t\tSpars: 697.085083\n",
      "\t TVw: 0.077760 | TVb: -2.041546 | GSw: -0.234959 | GSb: 0.065026 | TSUw: 0.464936 | TSUb: 0.034802\n",
      "\n",
      "Train Epoch: 2118 [4000/8000 (50%)]\tBatch Loss: 692.365976\tLearning Rate (w_theta): 0.001000\t TIME:4454.5s\n",
      "\t\t\t\tDisc: 0.425757\t\tSym: 12.355868\t\tSpars: 679.584351\n",
      "\t TVw: 0.078376 | TVb: -2.041540 | GSw: -0.234959 | GSb: 0.065026 | TSUw: 0.464936 | TSUb: 0.034802\n",
      "Validating epoch 2118...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 699.7208240383524\n",
      "Average validation loss: 67.49329823736247\n",
      "Training epoch 2119...\n",
      "\n",
      "Train Epoch: 2119 [0/8000 (0%)]\tBatch Loss: 715.785817\tLearning Rate (w_theta): 0.001000\t TIME:4456.9s\n",
      "\t\t\t\tDisc: 0.462052\t\tSym: 13.225743\t\tSpars: 702.098022\n",
      "\t TVw: 0.078973 | TVb: -2.041535 | GSw: -0.234959 | GSb: 0.065026 | TSUw: 0.464936 | TSUb: 0.034802\n",
      "\n",
      "Train Epoch: 2119 [4000/8000 (50%)]\tBatch Loss: 671.697343\tLearning Rate (w_theta): 0.001000\t TIME:4458.5s\n",
      "\t\t\t\tDisc: 0.405130\t\tSym: 10.987404\t\tSpars: 660.304810\n",
      "\t TVw: 0.079573 | TVb: -2.041531 | GSw: -0.234959 | GSb: 0.065026 | TSUw: 0.464936 | TSUb: 0.034802\n",
      "Validating epoch 2119...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 697.422656127972\n",
      "Average validation loss: 67.29140512394468\n",
      "Training epoch 2120...\n",
      "\n",
      "Train Epoch: 2120 [0/8000 (0%)]\tBatch Loss: 672.200652\tLearning Rate (w_theta): 0.001000\t TIME:4460.8s\n",
      "\t\t\t\tDisc: 0.396972\t\tSym: 12.117339\t\tSpars: 659.686340\n",
      "\t TVw: 0.080213 | TVb: -2.041524 | GSw: -0.234959 | GSb: 0.065026 | TSUw: 0.464935 | TSUb: 0.034803\n",
      "\n",
      "Train Epoch: 2120 [4000/8000 (50%)]\tBatch Loss: 715.495265\tLearning Rate (w_theta): 0.001000\t TIME:4462.4s\n",
      "\t\t\t\tDisc: 0.447904\t\tSym: 13.065854\t\tSpars: 701.981506\n",
      "\t TVw: 0.080829 | TVb: -2.041518 | GSw: -0.234959 | GSb: 0.065026 | TSUw: 0.464935 | TSUb: 0.034803\n",
      "Validating epoch 2120...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 697.7101821942222\n",
      "Average validation loss: 68.14326356001806\n",
      "Training epoch 2121...\n",
      "\n",
      "Train Epoch: 2121 [0/8000 (0%)]\tBatch Loss: 686.066436\tLearning Rate (w_theta): 0.001000\t TIME:4465.6s\n",
      "\t\t\t\tDisc: 0.443181\t\tSym: 11.408716\t\tSpars: 674.214539\n",
      "\t TVw: 0.081489 | TVb: -2.041508 | GSw: -0.234959 | GSb: 0.065026 | TSUw: 0.464935 | TSUb: 0.034803\n",
      "\n",
      "Train Epoch: 2121 [4000/8000 (50%)]\tBatch Loss: 687.493072\tLearning Rate (w_theta): 0.001000\t TIME:4467.2s\n",
      "\t\t\t\tDisc: 0.444413\t\tSym: 11.877151\t\tSpars: 675.171509\n",
      "\t TVw: 0.082096 | TVb: -2.041498 | GSw: -0.234959 | GSb: 0.065026 | TSUw: 0.464935 | TSUb: 0.034803\n",
      "Validating epoch 2121...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 700.2676228886062\n",
      "Average validation loss: 66.46874522436806\n",
      "Training epoch 2122...\n",
      "\n",
      "Train Epoch: 2122 [0/8000 (0%)]\tBatch Loss: 679.068998\tLearning Rate (w_theta): 0.001000\t TIME:4469.5s\n",
      "\t\t\t\tDisc: 0.404830\t\tSym: 11.713729\t\tSpars: 666.950439\n",
      "\t TVw: 0.082614 | TVb: -2.041493 | GSw: -0.234959 | GSb: 0.065026 | TSUw: 0.464935 | TSUb: 0.034803\n",
      "\n",
      "Train Epoch: 2122 [4000/8000 (50%)]\tBatch Loss: 678.664603\tLearning Rate (w_theta): 0.001000\t TIME:4471.1s\n",
      "\t\t\t\tDisc: 0.374248\t\tSym: 11.263011\t\tSpars: 667.027344\n",
      "\t TVw: 0.083176 | TVb: -2.041487 | GSw: -0.234959 | GSb: 0.065026 | TSUw: 0.464935 | TSUb: 0.034803\n",
      "Validating epoch 2122...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 698.2161213437514\n",
      "Average validation loss: 67.34328043406376\n",
      "Training epoch 2123...\n",
      "\n",
      "Train Epoch: 2123 [0/8000 (0%)]\tBatch Loss: 713.177017\tLearning Rate (w_theta): 0.001000\t TIME:4473.5s\n",
      "\t\t\t\tDisc: 0.466238\t\tSym: 13.291834\t\tSpars: 699.418945\n",
      "\t TVw: 0.083780 | TVb: -2.041481 | GSw: -0.234959 | GSb: 0.065026 | TSUw: 0.464935 | TSUb: 0.034803\n",
      "\n",
      "Train Epoch: 2123 [4000/8000 (50%)]\tBatch Loss: 689.618127\tLearning Rate (w_theta): 0.001000\t TIME:4475.1s\n",
      "\t\t\t\tDisc: 0.434801\t\tSym: 12.060584\t\tSpars: 677.122742\n",
      "\t TVw: 0.084374 | TVb: -2.041474 | GSw: -0.234959 | GSb: 0.065026 | TSUw: 0.464935 | TSUb: 0.034803\n",
      "Validating epoch 2123...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 695.7009752785202\n",
      "Average validation loss: 67.83438641080795\n",
      "Training epoch 2124...\n",
      "\n",
      "Train Epoch: 2124 [0/8000 (0%)]\tBatch Loss: 727.445836\tLearning Rate (w_theta): 0.001000\t TIME:4477.4s\n",
      "\t\t\t\tDisc: 0.493528\t\tSym: 14.799842\t\tSpars: 712.152466\n",
      "\t TVw: 0.084922 | TVb: -2.041469 | GSw: -0.234959 | GSb: 0.065025 | TSUw: 0.464935 | TSUb: 0.034803\n",
      "\n",
      "Train Epoch: 2124 [4000/8000 (50%)]\tBatch Loss: 722.393765\tLearning Rate (w_theta): 0.001000\t TIME:4479.0s\n",
      "\t\t\t\tDisc: 0.437504\t\tSym: 13.434532\t\tSpars: 708.521729\n",
      "\t TVw: 0.085402 | TVb: -2.041466 | GSw: -0.234959 | GSb: 0.065025 | TSUw: 0.464934 | TSUb: 0.034803\n",
      "Validating epoch 2124...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 700.9277144110307\n",
      "Average validation loss: 66.72949211169649\n",
      "Training epoch 2125...\n",
      "\n",
      "Train Epoch: 2125 [0/8000 (0%)]\tBatch Loss: 663.867814\tLearning Rate (w_theta): 0.001000\t TIME:4481.4s\n",
      "\t\t\t\tDisc: 0.393497\t\tSym: 11.378980\t\tSpars: 652.095337\n",
      "\t TVw: 0.085824 | TVb: -2.041468 | GSw: -0.234959 | GSb: 0.065025 | TSUw: 0.464934 | TSUb: 0.034803\n",
      "\n",
      "Train Epoch: 2125 [4000/8000 (50%)]\tBatch Loss: 676.507163\tLearning Rate (w_theta): 0.001000\t TIME:4483.0s\n",
      "\t\t\t\tDisc: 0.422185\t\tSym: 12.048540\t\tSpars: 664.036438\n",
      "\t TVw: 0.086238 | TVb: -2.041470 | GSw: -0.234959 | GSb: 0.065025 | TSUw: 0.464934 | TSUb: 0.034803\n",
      "Validating epoch 2125...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 698.7064069149395\n",
      "Average validation loss: 68.93547205866935\n",
      "Training epoch 2126...\n",
      "\n",
      "Train Epoch: 2126 [0/8000 (0%)]\tBatch Loss: 690.616790\tLearning Rate (w_theta): 0.001000\t TIME:4485.4s\n",
      "\t\t\t\tDisc: 0.476307\t\tSym: 13.150920\t\tSpars: 676.989563\n",
      "\t TVw: 0.086753 | TVb: -2.041465 | GSw: -0.234959 | GSb: 0.065025 | TSUw: 0.464934 | TSUb: 0.034803\n",
      "\n",
      "Train Epoch: 2126 [4000/8000 (50%)]\tBatch Loss: 690.999843\tLearning Rate (w_theta): 0.001000\t TIME:4487.0s\n",
      "\t\t\t\tDisc: 0.453980\t\tSym: 12.460841\t\tSpars: 678.085022\n",
      "\t TVw: 0.087312 | TVb: -2.041458 | GSw: -0.234959 | GSb: 0.065025 | TSUw: 0.464934 | TSUb: 0.034803\n",
      "Validating epoch 2126...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 694.273601597003\n",
      "Average validation loss: 68.10709586666505\n",
      "Training epoch 2127...\n",
      "\n",
      "Train Epoch: 2127 [0/8000 (0%)]\tBatch Loss: 693.217109\tLearning Rate (w_theta): 0.001000\t TIME:4489.7s\n",
      "\t\t\t\tDisc: 0.415266\t\tSym: 11.413111\t\tSpars: 681.388733\n",
      "\t TVw: 0.087934 | TVb: -2.041450 | GSw: -0.234959 | GSb: 0.065025 | TSUw: 0.464934 | TSUb: 0.034803\n",
      "\n",
      "Train Epoch: 2127 [4000/8000 (50%)]\tBatch Loss: 693.632294\tLearning Rate (w_theta): 0.001000\t TIME:4491.3s\n",
      "\t\t\t\tDisc: 0.405788\t\tSym: 12.858769\t\tSpars: 680.367737\n",
      "\t TVw: 0.088602 | TVb: -2.041440 | GSw: -0.234959 | GSb: 0.065025 | TSUw: 0.464934 | TSUb: 0.034803\n",
      "Validating epoch 2127...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 692.1109377036746\n",
      "Average validation loss: 68.4771620452881\n",
      "Training epoch 2128...\n",
      "\n",
      "Train Epoch: 2128 [0/8000 (0%)]\tBatch Loss: 691.500323\tLearning Rate (w_theta): 0.001000\t TIME:4493.7s\n",
      "\t\t\t\tDisc: 0.441795\t\tSym: 12.202144\t\tSpars: 678.856384\n",
      "\t TVw: 0.089291 | TVb: -2.041429 | GSw: -0.234959 | GSb: 0.065025 | TSUw: 0.464934 | TSUb: 0.034804\n",
      "\n",
      "Train Epoch: 2128 [4000/8000 (50%)]\tBatch Loss: 698.014971\tLearning Rate (w_theta): 0.001000\t TIME:4495.2s\n",
      "\t\t\t\tDisc: 0.430679\t\tSym: 12.809878\t\tSpars: 684.774414\n",
      "\t TVw: 0.089963 | TVb: -2.041418 | GSw: -0.234959 | GSb: 0.065025 | TSUw: 0.464933 | TSUb: 0.034804\n",
      "Validating epoch 2128...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 691.844953626456\n",
      "Average validation loss: 67.4419148285306\n",
      "Training epoch 2129...\n",
      "\n",
      "Train Epoch: 2129 [0/8000 (0%)]\tBatch Loss: 704.464932\tLearning Rate (w_theta): 0.001000\t TIME:4497.7s\n",
      "\t\t\t\tDisc: 0.439869\t\tSym: 13.376503\t\tSpars: 690.648560\n",
      "\t TVw: 0.090556 | TVb: -2.041411 | GSw: -0.234959 | GSb: 0.065025 | TSUw: 0.464933 | TSUb: 0.034804\n",
      "\n",
      "Train Epoch: 2129 [4000/8000 (50%)]\tBatch Loss: 702.572170\tLearning Rate (w_theta): 0.001000\t TIME:4499.3s\n",
      "\t\t\t\tDisc: 0.437249\t\tSym: 13.234164\t\tSpars: 688.900757\n",
      "\t TVw: 0.091123 | TVb: -2.041406 | GSw: -0.234959 | GSb: 0.065024 | TSUw: 0.464933 | TSUb: 0.034804\n",
      "Validating epoch 2129...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 691.955179334251\n",
      "Average validation loss: 68.30390676596565\n",
      "Training epoch 2130...\n",
      "\n",
      "Train Epoch: 2130 [0/8000 (0%)]\tBatch Loss: 675.646181\tLearning Rate (w_theta): 0.001000\t TIME:4501.7s\n",
      "\t\t\t\tDisc: 0.401776\t\tSym: 11.047017\t\tSpars: 664.197388\n",
      "\t TVw: 0.091717 | TVb: -2.041401 | GSw: -0.234959 | GSb: 0.065024 | TSUw: 0.464933 | TSUb: 0.034804\n",
      "\n",
      "Train Epoch: 2130 [4000/8000 (50%)]\tBatch Loss: 681.135856\tLearning Rate (w_theta): 0.001000\t TIME:4503.2s\n",
      "\t\t\t\tDisc: 0.388463\t\tSym: 12.562274\t\tSpars: 668.185120\n",
      "\t TVw: 0.092319 | TVb: -2.041392 | GSw: -0.234959 | GSb: 0.065024 | TSUw: 0.464933 | TSUb: 0.034804\n",
      "Validating epoch 2130...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 688.3608224172336\n",
      "Average validation loss: 68.34027891947724\n",
      "Training epoch 2131...\n",
      "\n",
      "Train Epoch: 2131 [0/8000 (0%)]\tBatch Loss: 687.111702\tLearning Rate (w_theta): 0.001000\t TIME:4506.4s\n",
      "\t\t\t\tDisc: 0.418736\t\tSym: 11.994907\t\tSpars: 674.698059\n",
      "\t TVw: 0.093025 | TVb: -2.041382 | GSw: -0.234959 | GSb: 0.065024 | TSUw: 0.464933 | TSUb: 0.034804\n",
      "\n",
      "Train Epoch: 2131 [4000/8000 (50%)]\tBatch Loss: 680.509918\tLearning Rate (w_theta): 0.001000\t TIME:4507.9s\n",
      "\t\t\t\tDisc: 0.436793\t\tSym: 12.720403\t\tSpars: 667.352722\n",
      "\t TVw: 0.093727 | TVb: -2.041372 | GSw: -0.234959 | GSb: 0.065024 | TSUw: 0.464933 | TSUb: 0.034804\n",
      "Validating epoch 2131...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 688.7421498539475\n",
      "Average validation loss: 68.02853478187109\n",
      "Training epoch 2132...\n",
      "\n",
      "Train Epoch: 2132 [0/8000 (0%)]\tBatch Loss: 674.002254\tLearning Rate (w_theta): 0.001000\t TIME:4510.3s\n",
      "\t\t\t\tDisc: 0.451367\t\tSym: 12.349348\t\tSpars: 661.201538\n",
      "\t TVw: 0.094353 | TVb: -2.041363 | GSw: -0.234959 | GSb: 0.065024 | TSUw: 0.464933 | TSUb: 0.034804\n",
      "\n",
      "Train Epoch: 2132 [4000/8000 (50%)]\tBatch Loss: 708.926633\tLearning Rate (w_theta): 0.001000\t TIME:4511.9s\n",
      "\t\t\t\tDisc: 0.405488\t\tSym: 12.710171\t\tSpars: 695.810974\n",
      "\t TVw: 0.094975 | TVb: -2.041355 | GSw: -0.234959 | GSb: 0.065024 | TSUw: 0.464933 | TSUb: 0.034804\n",
      "Validating epoch 2132...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 696.0703296027721\n",
      "Average validation loss: 67.75073298795064\n",
      "Training epoch 2133...\n",
      "\n",
      "Train Epoch: 2133 [0/8000 (0%)]\tBatch Loss: 725.284945\tLearning Rate (w_theta): 0.001000\t TIME:4514.4s\n",
      "\t\t\t\tDisc: 0.369112\t\tSym: 13.439880\t\tSpars: 711.475952\n",
      "\t TVw: 0.095485 | TVb: -2.041350 | GSw: -0.234959 | GSb: 0.065024 | TSUw: 0.464932 | TSUb: 0.034804\n",
      "\n",
      "Train Epoch: 2133 [4000/8000 (50%)]\tBatch Loss: 693.108111\tLearning Rate (w_theta): 0.001000\t TIME:4515.9s\n",
      "\t\t\t\tDisc: 0.379803\t\tSym: 11.939979\t\tSpars: 680.788330\n",
      "\t TVw: 0.096000 | TVb: -2.041344 | GSw: -0.234959 | GSb: 0.065024 | TSUw: 0.464932 | TSUb: 0.034804\n",
      "Validating epoch 2133...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 695.6736536970566\n",
      "Average validation loss: 68.9439113642291\n",
      "Training epoch 2134...\n",
      "\n",
      "Train Epoch: 2134 [0/8000 (0%)]\tBatch Loss: 714.032840\tLearning Rate (w_theta): 0.001000\t TIME:4518.3s\n",
      "\t\t\t\tDisc: 0.517585\t\tSym: 14.321652\t\tSpars: 699.193604\n",
      "\t TVw: 0.096512 | TVb: -2.041337 | GSw: -0.234959 | GSb: 0.065024 | TSUw: 0.464932 | TSUb: 0.034804\n",
      "\n",
      "Train Epoch: 2134 [4000/8000 (50%)]\tBatch Loss: 675.745767\tLearning Rate (w_theta): 0.001000\t TIME:4519.9s\n",
      "\t\t\t\tDisc: 0.374323\t\tSym: 11.828292\t\tSpars: 663.543152\n",
      "\t TVw: 0.097064 | TVb: -2.041330 | GSw: -0.234959 | GSb: 0.065024 | TSUw: 0.464932 | TSUb: 0.034804\n",
      "Validating epoch 2134...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 690.4957283383937\n",
      "Average validation loss: 68.71003051889667\n",
      "Training epoch 2135...\n",
      "\n",
      "Train Epoch: 2135 [0/8000 (0%)]\tBatch Loss: 688.145978\tLearning Rate (w_theta): 0.001000\t TIME:4522.3s\n",
      "\t\t\t\tDisc: 0.444035\t\tSym: 12.920265\t\tSpars: 674.781677\n",
      "\t TVw: 0.097697 | TVb: -2.041322 | GSw: -0.234959 | GSb: 0.065023 | TSUw: 0.464932 | TSUb: 0.034805\n",
      "\n",
      "Train Epoch: 2135 [4000/8000 (50%)]\tBatch Loss: 694.315239\tLearning Rate (w_theta): 0.001000\t TIME:4523.8s\n",
      "\t\t\t\tDisc: 0.417790\t\tSym: 11.785450\t\tSpars: 682.112000\n",
      "\t TVw: 0.098364 | TVb: -2.041311 | GSw: -0.234959 | GSb: 0.065023 | TSUw: 0.464932 | TSUb: 0.034805\n",
      "Validating epoch 2135...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 684.2814962565519\n",
      "Average validation loss: 68.30229186054214\n",
      "Training epoch 2136...\n",
      "\n",
      "Train Epoch: 2136 [0/8000 (0%)]\tBatch Loss: 688.716577\tLearning Rate (w_theta): 0.001000\t TIME:4526.2s\n",
      "\t\t\t\tDisc: 0.358618\t\tSym: 12.708728\t\tSpars: 675.649231\n",
      "\t TVw: 0.099013 | TVb: -2.041301 | GSw: -0.234959 | GSb: 0.065023 | TSUw: 0.464932 | TSUb: 0.034805\n",
      "\n",
      "Train Epoch: 2136 [4000/8000 (50%)]\tBatch Loss: 685.156626\tLearning Rate (w_theta): 0.001000\t TIME:4527.8s\n",
      "\t\t\t\tDisc: 0.446496\t\tSym: 12.240464\t\tSpars: 672.469666\n",
      "\t TVw: 0.099673 | TVb: -2.041292 | GSw: -0.234959 | GSb: 0.065023 | TSUw: 0.464932 | TSUb: 0.034805\n",
      "Validating epoch 2136...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 685.3296514380179\n",
      "Average validation loss: 68.74153140698492\n",
      "Training epoch 2137...\n",
      "\n",
      "Train Epoch: 2137 [0/8000 (0%)]\tBatch Loss: 702.001660\tLearning Rate (w_theta): 0.001000\t TIME:4530.6s\n",
      "\t\t\t\tDisc: 0.415042\t\tSym: 13.482737\t\tSpars: 688.103882\n",
      "\t TVw: 0.100308 | TVb: -2.041283 | GSw: -0.234959 | GSb: 0.065023 | TSUw: 0.464931 | TSUb: 0.034805\n",
      "\n",
      "Train Epoch: 2137 [4000/8000 (50%)]\tBatch Loss: 675.866233\tLearning Rate (w_theta): 0.001000\t TIME:4532.1s\n",
      "\t\t\t\tDisc: 0.416375\t\tSym: 12.137907\t\tSpars: 663.311951\n",
      "\t TVw: 0.100937 | TVb: -2.041275 | GSw: -0.234959 | GSb: 0.065023 | TSUw: 0.464931 | TSUb: 0.034805\n",
      "Validating epoch 2137...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 683.2054642516372\n",
      "Average validation loss: 68.87201407108938\n",
      "Training epoch 2138...\n",
      "\n",
      "Train Epoch: 2138 [0/8000 (0%)]\tBatch Loss: 682.799444\tLearning Rate (w_theta): 0.001000\t TIME:4534.5s\n",
      "\t\t\t\tDisc: 0.393584\t\tSym: 12.195350\t\tSpars: 670.210510\n",
      "\t TVw: 0.101576 | TVb: -2.041266 | GSw: -0.234959 | GSb: 0.065023 | TSUw: 0.464931 | TSUb: 0.034805\n",
      "\n",
      "Train Epoch: 2138 [4000/8000 (50%)]\tBatch Loss: 659.601554\tLearning Rate (w_theta): 0.001000\t TIME:4536.1s\n",
      "\t\t\t\tDisc: 0.377252\t\tSym: 11.400938\t\tSpars: 647.823364\n",
      "\t TVw: 0.102182 | TVb: -2.041258 | GSw: -0.234959 | GSb: 0.065023 | TSUw: 0.464931 | TSUb: 0.034805\n",
      "Validating epoch 2138...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 682.2407028321054\n",
      "Average validation loss: 68.54426893808194\n",
      "Training epoch 2139...\n",
      "\n",
      "Train Epoch: 2139 [0/8000 (0%)]\tBatch Loss: 669.965355\tLearning Rate (w_theta): 0.001000\t TIME:4538.5s\n",
      "\t\t\t\tDisc: 0.378028\t\tSym: 11.433335\t\tSpars: 658.153992\n",
      "\t TVw: 0.102802 | TVb: -2.041248 | GSw: -0.234959 | GSb: 0.065023 | TSUw: 0.464931 | TSUb: 0.034805\n",
      "\n",
      "Train Epoch: 2139 [4000/8000 (50%)]\tBatch Loss: 684.684109\tLearning Rate (w_theta): 0.001000\t TIME:4540.1s\n",
      "\t\t\t\tDisc: 0.408746\t\tSym: 12.234225\t\tSpars: 672.041138\n",
      "\t TVw: 0.103367 | TVb: -2.041242 | GSw: -0.234959 | GSb: 0.065023 | TSUw: 0.464931 | TSUb: 0.034805\n",
      "Validating epoch 2139...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 682.6293207839238\n",
      "Average validation loss: 68.68180704699967\n",
      "Training epoch 2140...\n",
      "\n",
      "Train Epoch: 2140 [0/8000 (0%)]\tBatch Loss: 660.468222\tLearning Rate (w_theta): 0.001000\t TIME:4542.5s\n",
      "\t\t\t\tDisc: 0.406685\t\tSym: 11.978408\t\tSpars: 648.083130\n",
      "\t TVw: 0.103932 | TVb: -2.041237 | GSw: -0.234959 | GSb: 0.065023 | TSUw: 0.464931 | TSUb: 0.034805\n",
      "\n",
      "Train Epoch: 2140 [4000/8000 (50%)]\tBatch Loss: 669.010819\tLearning Rate (w_theta): 0.001000\t TIME:4544.0s\n",
      "\t\t\t\tDisc: 0.394301\t\tSym: 11.620180\t\tSpars: 656.996338\n",
      "\t TVw: 0.104492 | TVb: -2.041229 | GSw: -0.234959 | GSb: 0.065022 | TSUw: 0.464931 | TSUb: 0.034805\n",
      "Validating epoch 2140...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 688.1028374785079\n",
      "Average validation loss: 68.55822672039231\n",
      "Training epoch 2141...\n",
      "\n",
      "Train Epoch: 2141 [0/8000 (0%)]\tBatch Loss: 693.097864\tLearning Rate (w_theta): 0.001000\t TIME:4547.2s\n",
      "\t\t\t\tDisc: 0.390039\t\tSym: 12.258240\t\tSpars: 680.449585\n",
      "\t TVw: 0.104981 | TVb: -2.041226 | GSw: -0.234959 | GSb: 0.065022 | TSUw: 0.464930 | TSUb: 0.034805\n",
      "\n",
      "Train Epoch: 2141 [4000/8000 (50%)]\tBatch Loss: 689.114498\tLearning Rate (w_theta): 0.001000\t TIME:4548.7s\n",
      "\t\t\t\tDisc: 0.349168\t\tSym: 11.848704\t\tSpars: 676.916626\n",
      "\t TVw: 0.105492 | TVb: -2.041224 | GSw: -0.234959 | GSb: 0.065022 | TSUw: 0.464930 | TSUb: 0.034806\n",
      "Validating epoch 2141...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 685.646345273578\n",
      "Average validation loss: 68.50072819142882\n",
      "Training epoch 2142...\n",
      "\n",
      "Train Epoch: 2142 [0/8000 (0%)]\tBatch Loss: 686.338198\tLearning Rate (w_theta): 0.001000\t TIME:4551.1s\n",
      "\t\t\t\tDisc: 0.439348\t\tSym: 12.546188\t\tSpars: 673.352661\n",
      "\t TVw: 0.106027 | TVb: -2.041223 | GSw: -0.234959 | GSb: 0.065022 | TSUw: 0.464930 | TSUb: 0.034806\n",
      "\n",
      "Train Epoch: 2142 [4000/8000 (50%)]\tBatch Loss: 713.888963\tLearning Rate (w_theta): 0.001000\t TIME:4552.7s\n",
      "\t\t\t\tDisc: 0.431927\t\tSym: 13.517339\t\tSpars: 699.939697\n",
      "\t TVw: 0.106590 | TVb: -2.041218 | GSw: -0.234959 | GSb: 0.065022 | TSUw: 0.464930 | TSUb: 0.034806\n",
      "Validating epoch 2142...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 687.478993588137\n",
      "Average validation loss: 71.06065620829831\n",
      "Training epoch 2143...\n",
      "\n",
      "Train Epoch: 2143 [0/8000 (0%)]\tBatch Loss: 688.271710\tLearning Rate (w_theta): 0.001000\t TIME:4555.1s\n",
      "\t\t\t\tDisc: 0.337720\t\tSym: 12.791534\t\tSpars: 675.142456\n",
      "\t TVw: 0.107216 | TVb: -2.041209 | GSw: -0.234959 | GSb: 0.065022 | TSUw: 0.464930 | TSUb: 0.034806\n",
      "\n",
      "Train Epoch: 2143 [4000/8000 (50%)]\tBatch Loss: 651.814084\tLearning Rate (w_theta): 0.001000\t TIME:4556.7s\n",
      "\t\t\t\tDisc: 0.377009\t\tSym: 10.739993\t\tSpars: 640.697083\n",
      "\t TVw: 0.107780 | TVb: -2.041202 | GSw: -0.234959 | GSb: 0.065022 | TSUw: 0.464930 | TSUb: 0.034806\n",
      "Validating epoch 2143...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 681.9252444213613\n",
      "Average validation loss: 69.01013001434156\n",
      "Training epoch 2144...\n",
      "\n",
      "Train Epoch: 2144 [0/8000 (0%)]\tBatch Loss: 668.553400\tLearning Rate (w_theta): 0.001000\t TIME:4559.1s\n",
      "\t\t\t\tDisc: 0.394396\t\tSym: 11.816535\t\tSpars: 656.342468\n",
      "\t TVw: 0.108360 | TVb: -2.041196 | GSw: -0.234959 | GSb: 0.065022 | TSUw: 0.464930 | TSUb: 0.034806\n",
      "\n",
      "Train Epoch: 2144 [4000/8000 (50%)]\tBatch Loss: 656.576856\tLearning Rate (w_theta): 0.001000\t TIME:4560.7s\n",
      "\t\t\t\tDisc: 0.318112\t\tSym: 11.186540\t\tSpars: 645.072205\n",
      "\t TVw: 0.109037 | TVb: -2.041186 | GSw: -0.234959 | GSb: 0.065022 | TSUw: 0.464930 | TSUb: 0.034806\n",
      "Validating epoch 2144...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 679.773269344178\n",
      "Average validation loss: 70.68694956383173\n",
      "Training epoch 2145...\n",
      "\n",
      "Train Epoch: 2145 [0/8000 (0%)]\tBatch Loss: 687.277103\tLearning Rate (w_theta): 0.001000\t TIME:4563.1s\n",
      "\t\t\t\tDisc: 0.373869\t\tSym: 12.750890\t\tSpars: 674.152344\n",
      "\t TVw: 0.109726 | TVb: -2.041177 | GSw: -0.234959 | GSb: 0.065022 | TSUw: 0.464930 | TSUb: 0.034806\n",
      "\n",
      "Train Epoch: 2145 [4000/8000 (50%)]\tBatch Loss: 660.239863\tLearning Rate (w_theta): 0.001000\t TIME:4564.6s\n",
      "\t\t\t\tDisc: 0.413921\t\tSym: 11.682815\t\tSpars: 648.143127\n",
      "\t TVw: 0.110398 | TVb: -2.041167 | GSw: -0.234959 | GSb: 0.065022 | TSUw: 0.464929 | TSUb: 0.034806\n",
      "Validating epoch 2145...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 677.0066785403548\n",
      "Average validation loss: 69.25961666179694\n",
      "Training epoch 2146...\n",
      "\n",
      "Train Epoch: 2146 [0/8000 (0%)]\tBatch Loss: 665.606576\tLearning Rate (w_theta): 0.001000\t TIME:4567.0s\n",
      "\t\t\t\tDisc: 0.378687\t\tSym: 11.317550\t\tSpars: 653.910339\n",
      "\t TVw: 0.111061 | TVb: -2.041156 | GSw: -0.234959 | GSb: 0.065021 | TSUw: 0.464929 | TSUb: 0.034806\n",
      "\n",
      "Train Epoch: 2146 [4000/8000 (50%)]\tBatch Loss: 694.545394\tLearning Rate (w_theta): 0.001000\t TIME:4568.6s\n",
      "\t\t\t\tDisc: 0.387929\t\tSym: 12.883661\t\tSpars: 681.273804\n",
      "\t TVw: 0.111729 | TVb: -2.041144 | GSw: -0.234959 | GSb: 0.065021 | TSUw: 0.464929 | TSUb: 0.034806\n",
      "Validating epoch 2146...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 674.823990196875\n",
      "Average validation loss: 69.77914095739116\n",
      "Training epoch 2147...\n",
      "\n",
      "Train Epoch: 2147 [0/8000 (0%)]\tBatch Loss: 637.465789\tLearning Rate (w_theta): 0.001000\t TIME:4571.0s\n",
      "\t\t\t\tDisc: 0.345528\t\tSym: 10.658164\t\tSpars: 626.462097\n",
      "\t TVw: 0.112336 | TVb: -2.041135 | GSw: -0.234959 | GSb: 0.065021 | TSUw: 0.464929 | TSUb: 0.034806\n",
      "\n",
      "Train Epoch: 2147 [4000/8000 (50%)]\tBatch Loss: 687.334964\tLearning Rate (w_theta): 0.001000\t TIME:4572.6s\n",
      "\t\t\t\tDisc: 0.401419\t\tSym: 12.887586\t\tSpars: 674.045959\n",
      "\t TVw: 0.112935 | TVb: -2.041125 | GSw: -0.234959 | GSb: 0.065021 | TSUw: 0.464929 | TSUb: 0.034806\n",
      "Validating epoch 2147...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 673.8811934566859\n",
      "Average validation loss: 69.49346948061827\n",
      "Training epoch 2148...\n",
      "\n",
      "Train Epoch: 2148 [0/8000 (0%)]\tBatch Loss: 665.995234\tLearning Rate (w_theta): 0.001000\t TIME:4575.3s\n",
      "\t\t\t\tDisc: 0.400979\t\tSym: 11.768511\t\tSpars: 653.825745\n",
      "\t TVw: 0.113521 | TVb: -2.041114 | GSw: -0.234959 | GSb: 0.065021 | TSUw: 0.464929 | TSUb: 0.034806\n",
      "\n",
      "Train Epoch: 2148 [4000/8000 (50%)]\tBatch Loss: 671.172757\tLearning Rate (w_theta): 0.001000\t TIME:4576.8s\n",
      "\t\t\t\tDisc: 0.398773\t\tSym: 12.629148\t\tSpars: 658.144836\n",
      "\t TVw: 0.114118 | TVb: -2.041106 | GSw: -0.234959 | GSb: 0.065021 | TSUw: 0.464929 | TSUb: 0.034807\n",
      "Validating epoch 2148...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 671.8898224506798\n",
      "Average validation loss: 68.86114178393254\n",
      "Training epoch 2149...\n",
      "\n",
      "Train Epoch: 2149 [0/8000 (0%)]\tBatch Loss: 670.738752\tLearning Rate (w_theta): 0.001000\t TIME:4579.3s\n",
      "\t\t\t\tDisc: 0.361232\t\tSym: 11.898761\t\tSpars: 658.478760\n",
      "\t TVw: 0.114668 | TVb: -2.041100 | GSw: -0.234959 | GSb: 0.065021 | TSUw: 0.464929 | TSUb: 0.034807\n",
      "\n",
      "Train Epoch: 2149 [4000/8000 (50%)]\tBatch Loss: 678.893084\tLearning Rate (w_theta): 0.001000\t TIME:4580.8s\n",
      "\t\t\t\tDisc: 0.389629\t\tSym: 12.151160\t\tSpars: 666.352295\n",
      "\t TVw: 0.115233 | TVb: -2.041092 | GSw: -0.234959 | GSb: 0.065021 | TSUw: 0.464928 | TSUb: 0.034807\n",
      "Validating epoch 2149...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 672.046164581938\n",
      "Average validation loss: 69.06395100472517\n",
      "Training epoch 2150...\n",
      "\n",
      "Train Epoch: 2150 [0/8000 (0%)]\tBatch Loss: 655.046064\tLearning Rate (w_theta): 0.001000\t TIME:4583.2s\n",
      "\t\t\t\tDisc: 0.380156\t\tSym: 11.260512\t\tSpars: 643.405396\n",
      "\t TVw: 0.115794 | TVb: -2.041085 | GSw: -0.234959 | GSb: 0.065021 | TSUw: 0.464928 | TSUb: 0.034807\n",
      "\n",
      "Train Epoch: 2150 [4000/8000 (50%)]\tBatch Loss: 666.306014\tLearning Rate (w_theta): 0.001000\t TIME:4584.8s\n",
      "\t\t\t\tDisc: 0.402959\t\tSym: 11.181252\t\tSpars: 654.721802\n",
      "\t TVw: 0.116394 | TVb: -2.041078 | GSw: -0.234959 | GSb: 0.065021 | TSUw: 0.464928 | TSUb: 0.034807\n",
      "Validating epoch 2150...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 669.4864768871527\n",
      "Average validation loss: 69.0900534707803\n",
      "Training epoch 2151...\n",
      "\n",
      "Train Epoch: 2151 [0/8000 (0%)]\tBatch Loss: 677.333686\tLearning Rate (w_theta): 0.001000\t TIME:4587.9s\n",
      "\t\t\t\tDisc: 0.364628\t\tSym: 12.456790\t\tSpars: 664.512268\n",
      "\t TVw: 0.116979 | TVb: -2.041071 | GSw: -0.234959 | GSb: 0.065021 | TSUw: 0.464928 | TSUb: 0.034807\n",
      "\n",
      "Train Epoch: 2151 [4000/8000 (50%)]\tBatch Loss: 642.471376\tLearning Rate (w_theta): 0.001000\t TIME:4589.5s\n",
      "\t\t\t\tDisc: 0.372856\t\tSym: 10.763010\t\tSpars: 631.335510\n",
      "\t TVw: 0.117557 | TVb: -2.041063 | GSw: -0.234959 | GSb: 0.065020 | TSUw: 0.464928 | TSUb: 0.034807\n",
      "Validating epoch 2151...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 669.4159601285636\n",
      "Average validation loss: 69.46807996367562\n",
      "Training epoch 2152...\n",
      "\n",
      "Train Epoch: 2152 [0/8000 (0%)]\tBatch Loss: 673.708765\tLearning Rate (w_theta): 0.001000\t TIME:4591.9s\n",
      "\t\t\t\tDisc: 0.423695\t\tSym: 12.398229\t\tSpars: 660.886841\n",
      "\t TVw: 0.118081 | TVb: -2.041058 | GSw: -0.234959 | GSb: 0.065020 | TSUw: 0.464928 | TSUb: 0.034807\n",
      "\n",
      "Train Epoch: 2152 [4000/8000 (50%)]\tBatch Loss: 653.633784\tLearning Rate (w_theta): 0.001000\t TIME:4593.5s\n",
      "\t\t\t\tDisc: 0.356212\t\tSym: 11.102646\t\tSpars: 642.174927\n",
      "\t TVw: 0.118608 | TVb: -2.041053 | GSw: -0.234959 | GSb: 0.065020 | TSUw: 0.464928 | TSUb: 0.034807\n",
      "Validating epoch 2152...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 668.9675449923568\n",
      "Average validation loss: 69.48443571994493\n",
      "Training epoch 2153...\n",
      "\n",
      "Train Epoch: 2153 [0/8000 (0%)]\tBatch Loss: 679.105638\tLearning Rate (w_theta): 0.001000\t TIME:4595.9s\n",
      "\t\t\t\tDisc: 0.403388\t\tSym: 12.865946\t\tSpars: 665.836304\n",
      "\t TVw: 0.119141 | TVb: -2.041048 | GSw: -0.234959 | GSb: 0.065020 | TSUw: 0.464928 | TSUb: 0.034807\n",
      "\n",
      "Train Epoch: 2153 [4000/8000 (50%)]\tBatch Loss: 676.942003\tLearning Rate (w_theta): 0.001000\t TIME:4597.4s\n",
      "\t\t\t\tDisc: 0.443171\t\tSym: 12.638236\t\tSpars: 663.860596\n",
      "\t TVw: 0.119714 | TVb: -2.041039 | GSw: -0.234959 | GSb: 0.065020 | TSUw: 0.464927 | TSUb: 0.034807\n",
      "Validating epoch 2153...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 668.4136946305524\n",
      "Average validation loss: 70.22926984524166\n",
      "Training epoch 2154...\n",
      "\n",
      "Train Epoch: 2154 [0/8000 (0%)]\tBatch Loss: 672.678800\tLearning Rate (w_theta): 0.001000\t TIME:4599.8s\n",
      "\t\t\t\tDisc: 0.392716\t\tSym: 12.478527\t\tSpars: 659.807556\n",
      "\t TVw: 0.120328 | TVb: -2.041028 | GSw: -0.234959 | GSb: 0.065020 | TSUw: 0.464927 | TSUb: 0.034807\n",
      "\n",
      "Train Epoch: 2154 [4000/8000 (50%)]\tBatch Loss: 674.916270\tLearning Rate (w_theta): 0.001000\t TIME:4601.4s\n",
      "\t\t\t\tDisc: 0.430347\t\tSym: 12.515159\t\tSpars: 661.970764\n",
      "\t TVw: 0.120920 | TVb: -2.041020 | GSw: -0.234959 | GSb: 0.065020 | TSUw: 0.464927 | TSUb: 0.034807\n",
      "Validating epoch 2154...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 666.9141267515225\n",
      "Average validation loss: 69.41351644409555\n",
      "Training epoch 2155...\n",
      "\n",
      "Train Epoch: 2155 [0/8000 (0%)]\tBatch Loss: 672.885570\tLearning Rate (w_theta): 0.001000\t TIME:4603.8s\n",
      "\t\t\t\tDisc: 0.385836\t\tSym: 12.869913\t\tSpars: 659.629822\n",
      "\t TVw: 0.121435 | TVb: -2.041016 | GSw: -0.234959 | GSb: 0.065020 | TSUw: 0.464927 | TSUb: 0.034808\n",
      "\n",
      "Train Epoch: 2155 [4000/8000 (50%)]\tBatch Loss: 667.213130\tLearning Rate (w_theta): 0.001000\t TIME:4605.4s\n",
      "\t\t\t\tDisc: 0.357967\t\tSym: 11.962280\t\tSpars: 654.892883\n",
      "\t TVw: 0.121975 | TVb: -2.041009 | GSw: -0.234959 | GSb: 0.065020 | TSUw: 0.464927 | TSUb: 0.034808\n",
      "Validating epoch 2155...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 666.5807409009502\n",
      "Average validation loss: 70.09460868773586\n",
      "Training epoch 2156...\n",
      "\n",
      "Train Epoch: 2156 [0/8000 (0%)]\tBatch Loss: 671.608819\tLearning Rate (w_theta): 0.001000\t TIME:4607.8s\n",
      "\t\t\t\tDisc: 0.393540\t\tSym: 11.999519\t\tSpars: 659.215759\n",
      "\t TVw: 0.122540 | TVb: -2.041001 | GSw: -0.234959 | GSb: 0.065020 | TSUw: 0.464927 | TSUb: 0.034808\n",
      "\n",
      "Train Epoch: 2156 [4000/8000 (50%)]\tBatch Loss: 653.569739\tLearning Rate (w_theta): 0.001000\t TIME:4609.3s\n",
      "\t\t\t\tDisc: 0.416315\t\tSym: 11.421613\t\tSpars: 641.731812\n",
      "\t TVw: 0.123102 | TVb: -2.040995 | GSw: -0.234959 | GSb: 0.065020 | TSUw: 0.464927 | TSUb: 0.034808\n",
      "Validating epoch 2156...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 663.9356687714118\n",
      "Average validation loss: 70.06053429331794\n",
      "Training epoch 2157...\n",
      "\n",
      "Train Epoch: 2157 [0/8000 (0%)]\tBatch Loss: 653.607147\tLearning Rate (w_theta): 0.001000\t TIME:4611.7s\n",
      "\t\t\t\tDisc: 0.376347\t\tSym: 11.671596\t\tSpars: 641.559204\n",
      "\t TVw: 0.123642 | TVb: -2.040990 | GSw: -0.234959 | GSb: 0.065020 | TSUw: 0.464927 | TSUb: 0.034808\n",
      "\n",
      "Train Epoch: 2157 [4000/8000 (50%)]\tBatch Loss: 676.277873\tLearning Rate (w_theta): 0.001000\t TIME:4613.3s\n",
      "\t\t\t\tDisc: 0.358437\t\tSym: 12.611086\t\tSpars: 663.308350\n",
      "\t TVw: 0.124110 | TVb: -2.040986 | GSw: -0.234959 | GSb: 0.065019 | TSUw: 0.464927 | TSUb: 0.034808\n",
      "Validating epoch 2157...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 665.1642661562523\n",
      "Average validation loss: 70.95189241550666\n",
      "Training epoch 2158...\n",
      "\n",
      "Train Epoch: 2158 [0/8000 (0%)]\tBatch Loss: 682.656400\tLearning Rate (w_theta): 0.001000\t TIME:4616.0s\n",
      "\t\t\t\tDisc: 0.350844\t\tSym: 12.567579\t\tSpars: 669.737976\n",
      "\t TVw: 0.124666 | TVb: -2.040979 | GSw: -0.234959 | GSb: 0.065019 | TSUw: 0.464926 | TSUb: 0.034808\n",
      "\n",
      "Train Epoch: 2158 [4000/8000 (50%)]\tBatch Loss: 662.553981\tLearning Rate (w_theta): 0.001000\t TIME:4617.6s\n",
      "\t\t\t\tDisc: 0.377557\t\tSym: 12.750887\t\tSpars: 649.425537\n",
      "\t TVw: 0.125166 | TVb: -2.040975 | GSw: -0.234959 | GSb: 0.065019 | TSUw: 0.464926 | TSUb: 0.034808\n",
      "Validating epoch 2158...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 665.9097514296584\n",
      "Average validation loss: 70.67521440228802\n",
      "Training epoch 2159...\n",
      "\n",
      "Train Epoch: 2159 [0/8000 (0%)]\tBatch Loss: 631.541494\tLearning Rate (w_theta): 0.001000\t TIME:4620.0s\n",
      "\t\t\t\tDisc: 0.361751\t\tSym: 10.959407\t\tSpars: 620.220337\n",
      "\t TVw: 0.125603 | TVb: -2.040972 | GSw: -0.234959 | GSb: 0.065019 | TSUw: 0.464926 | TSUb: 0.034808\n",
      "\n",
      "Train Epoch: 2159 [4000/8000 (50%)]\tBatch Loss: 653.392121\tLearning Rate (w_theta): 0.001000\t TIME:4621.5s\n",
      "\t\t\t\tDisc: 0.391669\t\tSym: 12.072597\t\tSpars: 640.927856\n",
      "\t TVw: 0.126108 | TVb: -2.040965 | GSw: -0.234959 | GSb: 0.065019 | TSUw: 0.464926 | TSUb: 0.034808\n",
      "Validating epoch 2159...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 664.845374493975\n",
      "Average validation loss: 69.8845510677676\n",
      "Training epoch 2160...\n",
      "\n",
      "Train Epoch: 2160 [0/8000 (0%)]\tBatch Loss: 662.673404\tLearning Rate (w_theta): 0.001000\t TIME:4624.0s\n",
      "\t\t\t\tDisc: 0.365639\t\tSym: 11.324183\t\tSpars: 650.983582\n",
      "\t TVw: 0.126630 | TVb: -2.040959 | GSw: -0.234959 | GSb: 0.065019 | TSUw: 0.464926 | TSUb: 0.034808\n",
      "\n",
      "Train Epoch: 2160 [4000/8000 (50%)]\tBatch Loss: 647.098183\tLearning Rate (w_theta): 0.001000\t TIME:4625.6s\n",
      "\t\t\t\tDisc: 0.371325\t\tSym: 11.221731\t\tSpars: 635.505127\n",
      "\t TVw: 0.127182 | TVb: -2.040950 | GSw: -0.234959 | GSb: 0.065019 | TSUw: 0.464926 | TSUb: 0.034808\n",
      "Validating epoch 2160...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 662.8427973822742\n",
      "Average validation loss: 71.18598079576927\n",
      "Training epoch 2161...\n",
      "\n",
      "Train Epoch: 2161 [0/8000 (0%)]\tBatch Loss: 659.194645\tLearning Rate (w_theta): 0.001000\t TIME:4628.7s\n",
      "\t\t\t\tDisc: 0.375617\t\tSym: 12.356443\t\tSpars: 646.462585\n",
      "\t TVw: 0.127712 | TVb: -2.040941 | GSw: -0.234959 | GSb: 0.065019 | TSUw: 0.464926 | TSUb: 0.034808\n",
      "\n",
      "Train Epoch: 2161 [4000/8000 (50%)]\tBatch Loss: 658.474539\tLearning Rate (w_theta): 0.001000\t TIME:4630.2s\n",
      "\t\t\t\tDisc: 0.363090\t\tSym: 11.944701\t\tSpars: 646.166748\n",
      "\t TVw: 0.128191 | TVb: -2.040935 | GSw: -0.234959 | GSb: 0.065019 | TSUw: 0.464926 | TSUb: 0.034808\n",
      "Validating epoch 2161...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 666.4940979955097\n",
      "Average validation loss: 70.36006008202959\n",
      "Training epoch 2162...\n",
      "\n",
      "Train Epoch: 2162 [0/8000 (0%)]\tBatch Loss: 643.992598\tLearning Rate (w_theta): 0.001000\t TIME:4632.6s\n",
      "\t\t\t\tDisc: 0.347499\t\tSym: 11.309894\t\tSpars: 632.335205\n",
      "\t TVw: 0.128672 | TVb: -2.040929 | GSw: -0.234959 | GSb: 0.065019 | TSUw: 0.464925 | TSUb: 0.034809\n",
      "\n",
      "Train Epoch: 2162 [4000/8000 (50%)]\tBatch Loss: 700.664630\tLearning Rate (w_theta): 0.001000\t TIME:4634.2s\n",
      "\t\t\t\tDisc: 0.351444\t\tSym: 13.373550\t\tSpars: 686.939636\n",
      "\t TVw: 0.129129 | TVb: -2.040923 | GSw: -0.234959 | GSb: 0.065019 | TSUw: 0.464925 | TSUb: 0.034809\n",
      "Validating epoch 2162...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 678.4475762741986\n",
      "Average validation loss: 71.15437393092927\n",
      "Training epoch 2163...\n",
      "\n",
      "Train Epoch: 2163 [0/8000 (0%)]\tBatch Loss: 661.070417\tLearning Rate (w_theta): 0.001000\t TIME:4636.6s\n",
      "\t\t\t\tDisc: 0.379016\t\tSym: 12.096003\t\tSpars: 648.595398\n",
      "\t TVw: 0.129449 | TVb: -2.040924 | GSw: -0.234960 | GSb: 0.065018 | TSUw: 0.464925 | TSUb: 0.034809\n",
      "\n",
      "Train Epoch: 2163 [4000/8000 (50%)]\tBatch Loss: 680.544161\tLearning Rate (w_theta): 0.001000\t TIME:4638.2s\n",
      "\t\t\t\tDisc: 0.378492\t\tSym: 12.266987\t\tSpars: 667.898682\n",
      "\t TVw: 0.129781 | TVb: -2.040927 | GSw: -0.234960 | GSb: 0.065018 | TSUw: 0.464925 | TSUb: 0.034809\n",
      "Validating epoch 2163...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 667.914118257212\n",
      "Average validation loss: 71.5247094197591\n",
      "Training epoch 2164...\n",
      "\n",
      "Train Epoch: 2164 [0/8000 (0%)]\tBatch Loss: 663.392165\tLearning Rate (w_theta): 0.001000\t TIME:4640.6s\n",
      "\t\t\t\tDisc: 0.372431\t\tSym: 12.759603\t\tSpars: 650.260132\n",
      "\t TVw: 0.130265 | TVb: -2.040924 | GSw: -0.234960 | GSb: 0.065018 | TSUw: 0.464925 | TSUb: 0.034809\n",
      "\n",
      "Train Epoch: 2164 [4000/8000 (50%)]\tBatch Loss: 684.432417\tLearning Rate (w_theta): 0.001000\t TIME:4642.2s\n",
      "\t\t\t\tDisc: 0.340582\t\tSym: 12.852089\t\tSpars: 671.239746\n",
      "\t TVw: 0.130889 | TVb: -2.040910 | GSw: -0.234960 | GSb: 0.065018 | TSUw: 0.464925 | TSUb: 0.034809\n",
      "Validating epoch 2164...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 666.5271487503633\n",
      "Average validation loss: 72.46352315190148\n",
      "Training epoch 2165...\n",
      "\n",
      "Train Epoch: 2165 [0/8000 (0%)]\tBatch Loss: 663.339554\tLearning Rate (w_theta): 0.001000\t TIME:4644.6s\n",
      "\t\t\t\tDisc: 0.360665\t\tSym: 12.457771\t\tSpars: 650.521118\n",
      "\t TVw: 0.131501 | TVb: -2.040901 | GSw: -0.234960 | GSb: 0.065018 | TSUw: 0.464925 | TSUb: 0.034809\n",
      "\n",
      "Train Epoch: 2165 [4000/8000 (50%)]\tBatch Loss: 652.901141\tLearning Rate (w_theta): 0.001000\t TIME:4646.1s\n",
      "\t\t\t\tDisc: 0.385811\t\tSym: 11.985178\t\tSpars: 640.530151\n",
      "\t TVw: 0.132028 | TVb: -2.040896 | GSw: -0.234960 | GSb: 0.065018 | TSUw: 0.464925 | TSUb: 0.034809\n",
      "Validating epoch 2165...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 666.8747236564417\n",
      "Average validation loss: 72.13944132891342\n",
      "Training epoch 2166...\n",
      "\n",
      "Train Epoch: 2166 [0/8000 (0%)]\tBatch Loss: 623.478062\tLearning Rate (w_theta): 0.001000\t TIME:4648.5s\n",
      "\t\t\t\tDisc: 0.349711\t\tSym: 10.798882\t\tSpars: 612.329468\n",
      "\t TVw: 0.132563 | TVb: -2.040891 | GSw: -0.234960 | GSb: 0.065018 | TSUw: 0.464925 | TSUb: 0.034809\n",
      "\n",
      "Train Epoch: 2166 [4000/8000 (50%)]\tBatch Loss: 657.188359\tLearning Rate (w_theta): 0.001000\t TIME:4650.1s\n",
      "\t\t\t\tDisc: 0.306622\t\tSym: 11.335045\t\tSpars: 645.546692\n",
      "\t TVw: 0.133069 | TVb: -2.040884 | GSw: -0.234960 | GSb: 0.065018 | TSUw: 0.464924 | TSUb: 0.034809\n",
      "Validating epoch 2166...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 667.6023066143987\n",
      "Average validation loss: 73.93954834587416\n",
      "Training epoch 2167...\n",
      "\n",
      "Train Epoch: 2167 [0/8000 (0%)]\tBatch Loss: 696.385196\tLearning Rate (w_theta): 0.001000\t TIME:4652.5s\n",
      "\t\t\t\tDisc: 0.370494\t\tSym: 13.586601\t\tSpars: 682.428101\n",
      "\t TVw: 0.133628 | TVb: -2.040877 | GSw: -0.234960 | GSb: 0.065018 | TSUw: 0.464924 | TSUb: 0.034809\n",
      "\n",
      "Train Epoch: 2167 [4000/8000 (50%)]\tBatch Loss: 640.205293\tLearning Rate (w_theta): 0.001000\t TIME:4654.1s\n",
      "\t\t\t\tDisc: 0.384311\t\tSym: 10.921446\t\tSpars: 628.899536\n",
      "\t TVw: 0.134257 | TVb: -2.040867 | GSw: -0.234960 | GSb: 0.065018 | TSUw: 0.464924 | TSUb: 0.034809\n",
      "Validating epoch 2167...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 661.0453542949137\n",
      "Average validation loss: 72.9428910029262\n",
      "Training epoch 2168...\n",
      "\n",
      "Train Epoch: 2168 [0/8000 (0%)]\tBatch Loss: 666.018474\tLearning Rate (w_theta): 0.001000\t TIME:4656.5s\n",
      "\t\t\t\tDisc: 0.378601\t\tSym: 12.131572\t\tSpars: 653.508301\n",
      "\t TVw: 0.134884 | TVb: -2.040854 | GSw: -0.234960 | GSb: 0.065018 | TSUw: 0.464924 | TSUb: 0.034809\n",
      "\n",
      "Train Epoch: 2168 [4000/8000 (50%)]\tBatch Loss: 659.898002\tLearning Rate (w_theta): 0.001000\t TIME:4658.0s\n",
      "\t\t\t\tDisc: 0.327195\t\tSym: 11.905829\t\tSpars: 647.664978\n",
      "\t TVw: 0.135530 | TVb: -2.040840 | GSw: -0.234960 | GSb: 0.065017 | TSUw: 0.464924 | TSUb: 0.034810\n",
      "Validating epoch 2168...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 660.7807836455978\n",
      "Average validation loss: 71.3970750308268\n",
      "Training epoch 2169...\n",
      "\n",
      "Train Epoch: 2169 [0/8000 (0%)]\tBatch Loss: 652.162750\tLearning Rate (w_theta): 0.001000\t TIME:4660.8s\n",
      "\t\t\t\tDisc: 0.353869\t\tSym: 11.583966\t\tSpars: 640.224915\n",
      "\t TVw: 0.136135 | TVb: -2.040828 | GSw: -0.234960 | GSb: 0.065017 | TSUw: 0.464924 | TSUb: 0.034810\n",
      "\n",
      "Train Epoch: 2169 [4000/8000 (50%)]\tBatch Loss: 658.230906\tLearning Rate (w_theta): 0.001000\t TIME:4662.3s\n",
      "\t\t\t\tDisc: 0.335571\t\tSym: 12.241343\t\tSpars: 645.653992\n",
      "\t TVw: 0.136735 | TVb: -2.040818 | GSw: -0.234960 | GSb: 0.065017 | TSUw: 0.464924 | TSUb: 0.034810\n",
      "Validating epoch 2169...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 659.1695810802725\n",
      "Average validation loss: 72.83872039490272\n",
      "Training epoch 2170...\n",
      "\n",
      "Train Epoch: 2170 [0/8000 (0%)]\tBatch Loss: 675.794615\tLearning Rate (w_theta): 0.001000\t TIME:4664.7s\n",
      "\t\t\t\tDisc: 0.400063\t\tSym: 12.547812\t\tSpars: 662.846741\n",
      "\t TVw: 0.137349 | TVb: -2.040803 | GSw: -0.234960 | GSb: 0.065017 | TSUw: 0.464924 | TSUb: 0.034810\n",
      "\n",
      "Train Epoch: 2170 [4000/8000 (50%)]\tBatch Loss: 649.100575\tLearning Rate (w_theta): 0.001000\t TIME:4666.3s\n",
      "\t\t\t\tDisc: 0.370494\t\tSym: 11.600076\t\tSpars: 637.130005\n",
      "\t TVw: 0.137947 | TVb: -2.040792 | GSw: -0.234960 | GSb: 0.065017 | TSUw: 0.464923 | TSUb: 0.034810\n",
      "Validating epoch 2170...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 655.5833724233077\n",
      "Average validation loss: 71.71251750017687\n",
      "Training epoch 2171...\n",
      "\n",
      "Train Epoch: 2171 [0/8000 (0%)]\tBatch Loss: 672.364236\tLearning Rate (w_theta): 0.001000\t TIME:4669.4s\n",
      "\t\t\t\tDisc: 0.406015\t\tSym: 12.830291\t\tSpars: 659.127930\n",
      "\t TVw: 0.138557 | TVb: -2.040784 | GSw: -0.234960 | GSb: 0.065017 | TSUw: 0.464923 | TSUb: 0.034810\n",
      "\n",
      "Train Epoch: 2171 [4000/8000 (50%)]\tBatch Loss: 651.731396\tLearning Rate (w_theta): 0.001000\t TIME:4670.9s\n",
      "\t\t\t\tDisc: 0.384681\t\tSym: 12.384435\t\tSpars: 638.962280\n",
      "\t TVw: 0.139203 | TVb: -2.040773 | GSw: -0.234960 | GSb: 0.065017 | TSUw: 0.464923 | TSUb: 0.034810\n",
      "Validating epoch 2171...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 651.5016746791591\n",
      "Average validation loss: 71.33981718343475\n",
      "Training epoch 2172...\n",
      "\n",
      "Train Epoch: 2172 [0/8000 (0%)]\tBatch Loss: 629.158853\tLearning Rate (w_theta): 0.001000\t TIME:4673.4s\n",
      "\t\t\t\tDisc: 0.322693\t\tSym: 11.111245\t\tSpars: 617.724915\n",
      "\t TVw: 0.139826 | TVb: -2.040761 | GSw: -0.234960 | GSb: 0.065017 | TSUw: 0.464923 | TSUb: 0.034810\n",
      "\n",
      "Train Epoch: 2172 [4000/8000 (50%)]\tBatch Loss: 637.662397\tLearning Rate (w_theta): 0.001000\t TIME:4675.0s\n",
      "\t\t\t\tDisc: 0.341182\t\tSym: 11.257556\t\tSpars: 626.063660\n",
      "\t TVw: 0.140407 | TVb: -2.040752 | GSw: -0.234960 | GSb: 0.065017 | TSUw: 0.464923 | TSUb: 0.034810\n",
      "Validating epoch 2172...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 650.3426242956383\n",
      "Average validation loss: 71.47056702822671\n",
      "Training epoch 2173...\n",
      "\n",
      "Train Epoch: 2173 [0/8000 (0%)]\tBatch Loss: 639.929569\tLearning Rate (w_theta): 0.001000\t TIME:4677.4s\n",
      "\t\t\t\tDisc: 0.363243\t\tSym: 11.737225\t\tSpars: 627.829102\n",
      "\t TVw: 0.141004 | TVb: -2.040741 | GSw: -0.234960 | GSb: 0.065017 | TSUw: 0.464923 | TSUb: 0.034810\n",
      "\n",
      "Train Epoch: 2173 [4000/8000 (50%)]\tBatch Loss: 638.516926\tLearning Rate (w_theta): 0.001000\t TIME:4678.9s\n",
      "\t\t\t\tDisc: 0.357070\t\tSym: 11.399725\t\tSpars: 626.760132\n",
      "\t TVw: 0.141560 | TVb: -2.040735 | GSw: -0.234960 | GSb: 0.065017 | TSUw: 0.464923 | TSUb: 0.034810\n",
      "Validating epoch 2173...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 650.3749034368163\n",
      "Average validation loss: 71.54501374726235\n",
      "Training epoch 2174...\n",
      "\n",
      "Train Epoch: 2174 [0/8000 (0%)]\tBatch Loss: 683.935600\tLearning Rate (w_theta): 0.001000\t TIME:4681.4s\n",
      "\t\t\t\tDisc: 0.423380\t\tSym: 13.809094\t\tSpars: 669.703125\n",
      "\t TVw: 0.142060 | TVb: -2.040729 | GSw: -0.234960 | GSb: 0.065016 | TSUw: 0.464923 | TSUb: 0.034810\n",
      "\n",
      "Train Epoch: 2174 [4000/8000 (50%)]\tBatch Loss: 648.640565\tLearning Rate (w_theta): 0.001000\t TIME:4682.9s\n",
      "\t\t\t\tDisc: 0.343428\t\tSym: 11.827044\t\tSpars: 636.470093\n",
      "\t TVw: 0.142608 | TVb: -2.040718 | GSw: -0.234960 | GSb: 0.065016 | TSUw: 0.464922 | TSUb: 0.034810\n",
      "Validating epoch 2174...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 650.2873712675605\n",
      "Average validation loss: 71.08250042794084\n",
      "Training epoch 2175...\n",
      "\n",
      "Train Epoch: 2175 [0/8000 (0%)]\tBatch Loss: 660.088418\tLearning Rate (w_theta): 0.001000\t TIME:4685.3s\n",
      "\t\t\t\tDisc: 0.365188\t\tSym: 12.498194\t\tSpars: 647.225037\n",
      "\t TVw: 0.143106 | TVb: -2.040711 | GSw: -0.234960 | GSb: 0.065016 | TSUw: 0.464922 | TSUb: 0.034810\n",
      "\n",
      "Train Epoch: 2175 [4000/8000 (50%)]\tBatch Loss: 632.954372\tLearning Rate (w_theta): 0.001000\t TIME:4686.9s\n",
      "\t\t\t\tDisc: 0.380398\t\tSym: 11.824096\t\tSpars: 620.749878\n",
      "\t TVw: 0.143576 | TVb: -2.040704 | GSw: -0.234960 | GSb: 0.065016 | TSUw: 0.464922 | TSUb: 0.034811\n",
      "Validating epoch 2175...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 648.56495446135\n",
      "Average validation loss: 71.69907086660145\n",
      "Training epoch 2176...\n",
      "\n",
      "Train Epoch: 2176 [0/8000 (0%)]\tBatch Loss: 638.848712\tLearning Rate (w_theta): 0.001000\t TIME:4689.4s\n",
      "\t\t\t\tDisc: 0.370102\t\tSym: 11.461825\t\tSpars: 627.016785\n",
      "\t TVw: 0.144052 | TVb: -2.040699 | GSw: -0.234960 | GSb: 0.065016 | TSUw: 0.464922 | TSUb: 0.034811\n",
      "\n",
      "Train Epoch: 2176 [4000/8000 (50%)]\tBatch Loss: 633.898633\tLearning Rate (w_theta): 0.001000\t TIME:4691.0s\n",
      "\t\t\t\tDisc: 0.367800\t\tSym: 11.594737\t\tSpars: 621.936096\n",
      "\t TVw: 0.144473 | TVb: -2.040695 | GSw: -0.234960 | GSb: 0.065016 | TSUw: 0.464922 | TSUb: 0.034811\n",
      "Validating epoch 2176...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 647.0238356869\n",
      "Average validation loss: 71.86790768614807\n",
      "Training epoch 2177...\n",
      "\n",
      "Train Epoch: 2177 [0/8000 (0%)]\tBatch Loss: 667.512595\tLearning Rate (w_theta): 0.001000\t TIME:4693.4s\n",
      "\t\t\t\tDisc: 0.399260\t\tSym: 12.657097\t\tSpars: 654.456238\n",
      "\t TVw: 0.144928 | TVb: -2.040691 | GSw: -0.234960 | GSb: 0.065016 | TSUw: 0.464922 | TSUb: 0.034811\n",
      "\n",
      "Train Epoch: 2177 [4000/8000 (50%)]\tBatch Loss: 665.378319\tLearning Rate (w_theta): 0.001000\t TIME:4694.9s\n",
      "\t\t\t\tDisc: 0.370159\t\tSym: 12.642010\t\tSpars: 652.366150\n",
      "\t TVw: 0.145431 | TVb: -2.040684 | GSw: -0.234960 | GSb: 0.065016 | TSUw: 0.464922 | TSUb: 0.034811\n",
      "Validating epoch 2177...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 646.3668101200858\n",
      "Average validation loss: 71.87172503469253\n",
      "Training epoch 2178...\n",
      "\n",
      "Train Epoch: 2178 [0/8000 (0%)]\tBatch Loss: 666.449168\tLearning Rate (w_theta): 0.001000\t TIME:4697.4s\n",
      "\t\t\t\tDisc: 0.400677\t\tSym: 12.578094\t\tSpars: 653.470398\n",
      "\t TVw: 0.145874 | TVb: -2.040681 | GSw: -0.234960 | GSb: 0.065016 | TSUw: 0.464922 | TSUb: 0.034811\n",
      "\n",
      "Train Epoch: 2178 [4000/8000 (50%)]\tBatch Loss: 642.306256\tLearning Rate (w_theta): 0.001000\t TIME:4698.9s\n",
      "\t\t\t\tDisc: 0.356284\t\tSym: 11.684407\t\tSpars: 630.265564\n",
      "\t TVw: 0.146314 | TVb: -2.040678 | GSw: -0.234960 | GSb: 0.065016 | TSUw: 0.464922 | TSUb: 0.034811\n",
      "Validating epoch 2178...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 645.1690752463235\n",
      "Average validation loss: 72.19669789848975\n",
      "Training epoch 2179...\n",
      "\n",
      "Train Epoch: 2179 [0/8000 (0%)]\tBatch Loss: 652.076520\tLearning Rate (w_theta): 0.001000\t TIME:4701.3s\n",
      "\t\t\t\tDisc: 0.394636\t\tSym: 11.738402\t\tSpars: 639.943481\n",
      "\t TVw: 0.146800 | TVb: -2.040673 | GSw: -0.234960 | GSb: 0.065016 | TSUw: 0.464921 | TSUb: 0.034811\n",
      "\n",
      "Train Epoch: 2179 [4000/8000 (50%)]\tBatch Loss: 622.854515\tLearning Rate (w_theta): 0.001000\t TIME:4702.9s\n",
      "\t\t\t\tDisc: 0.374688\t\tSym: 11.257293\t\tSpars: 611.222534\n",
      "\t TVw: 0.147301 | TVb: -2.040669 | GSw: -0.234960 | GSb: 0.065015 | TSUw: 0.464921 | TSUb: 0.034811\n",
      "Validating epoch 2179...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 643.8534395635508\n",
      "Average validation loss: 72.63971762942154\n",
      "Training epoch 2180...\n",
      "\n",
      "Train Epoch: 2180 [0/8000 (0%)]\tBatch Loss: 655.243926\tLearning Rate (w_theta): 0.001000\t TIME:4705.7s\n",
      "\t\t\t\tDisc: 0.387253\t\tSym: 12.566573\t\tSpars: 642.290100\n",
      "\t TVw: 0.147890 | TVb: -2.040657 | GSw: -0.234960 | GSb: 0.065015 | TSUw: 0.464921 | TSUb: 0.034811\n",
      "\n",
      "Train Epoch: 2180 [4000/8000 (50%)]\tBatch Loss: 670.995299\tLearning Rate (w_theta): 0.001000\t TIME:4707.3s\n",
      "\t\t\t\tDisc: 0.389609\t\tSym: 13.738930\t\tSpars: 656.866760\n",
      "\t TVw: 0.148475 | TVb: -2.040647 | GSw: -0.234960 | GSb: 0.065015 | TSUw: 0.464921 | TSUb: 0.034811\n",
      "Validating epoch 2180...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 643.5583209647762\n",
      "Average validation loss: 71.68345470849722\n",
      "Training epoch 2181...\n",
      "\n",
      "Train Epoch: 2181 [0/8000 (0%)]\tBatch Loss: 642.685422\tLearning Rate (w_theta): 0.001000\t TIME:4710.4s\n",
      "\t\t\t\tDisc: 0.411480\t\tSym: 12.494157\t\tSpars: 629.779785\n",
      "\t TVw: 0.148940 | TVb: -2.040639 | GSw: -0.234960 | GSb: 0.065015 | TSUw: 0.464921 | TSUb: 0.034811\n",
      "\n",
      "Train Epoch: 2181 [4000/8000 (50%)]\tBatch Loss: 650.565828\tLearning Rate (w_theta): 0.001000\t TIME:4712.0s\n",
      "\t\t\t\tDisc: 0.386504\t\tSym: 12.592592\t\tSpars: 637.586731\n",
      "\t TVw: 0.149305 | TVb: -2.040634 | GSw: -0.234960 | GSb: 0.065015 | TSUw: 0.464921 | TSUb: 0.034811\n",
      "Validating epoch 2181...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 643.1597682334012\n",
      "Average validation loss: 72.24190609208972\n",
      "Training epoch 2182...\n",
      "\n",
      "Train Epoch: 2182 [0/8000 (0%)]\tBatch Loss: 625.397200\tLearning Rate (w_theta): 0.001000\t TIME:4714.4s\n",
      "\t\t\t\tDisc: 0.378292\t\tSym: 11.574084\t\tSpars: 613.444824\n",
      "\t TVw: 0.149723 | TVb: -2.040627 | GSw: -0.234960 | GSb: 0.065015 | TSUw: 0.464921 | TSUb: 0.034812\n",
      "\n",
      "Train Epoch: 2182 [4000/8000 (50%)]\tBatch Loss: 649.895997\tLearning Rate (w_theta): 0.001000\t TIME:4716.0s\n",
      "\t\t\t\tDisc: 0.368702\t\tSym: 11.872876\t\tSpars: 637.654419\n",
      "\t TVw: 0.150188 | TVb: -2.040619 | GSw: -0.234960 | GSb: 0.065015 | TSUw: 0.464921 | TSUb: 0.034812\n",
      "Validating epoch 2182...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 644.7395871089008\n",
      "Average validation loss: 72.4312415936929\n",
      "Training epoch 2183...\n",
      "\n",
      "Train Epoch: 2183 [0/8000 (0%)]\tBatch Loss: 646.882975\tLearning Rate (w_theta): 0.001000\t TIME:4718.4s\n",
      "\t\t\t\tDisc: 0.335938\t\tSym: 12.029580\t\tSpars: 634.517456\n",
      "\t TVw: 0.150585 | TVb: -2.040614 | GSw: -0.234960 | GSb: 0.065015 | TSUw: 0.464920 | TSUb: 0.034812\n",
      "\n",
      "Train Epoch: 2183 [4000/8000 (50%)]\tBatch Loss: 680.797379\tLearning Rate (w_theta): 0.001000\t TIME:4720.0s\n",
      "\t\t\t\tDisc: 0.353437\t\tSym: 13.508945\t\tSpars: 666.934998\n",
      "\t TVw: 0.150916 | TVb: -2.040613 | GSw: -0.234960 | GSb: 0.065015 | TSUw: 0.464920 | TSUb: 0.034812\n",
      "Validating epoch 2183...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 648.2000805570945\n",
      "Average validation loss: 73.55581881777435\n",
      "Training epoch 2184...\n",
      "\n",
      "Train Epoch: 2184 [0/8000 (0%)]\tBatch Loss: 672.949297\tLearning Rate (w_theta): 0.001000\t TIME:4722.6s\n",
      "\t\t\t\tDisc: 0.374637\t\tSym: 13.205337\t\tSpars: 659.369324\n",
      "\t TVw: 0.151378 | TVb: -2.040605 | GSw: -0.234960 | GSb: 0.065015 | TSUw: 0.464920 | TSUb: 0.034812\n",
      "\n",
      "Train Epoch: 2184 [4000/8000 (50%)]\tBatch Loss: 654.180831\tLearning Rate (w_theta): 0.001000\t TIME:4724.2s\n",
      "\t\t\t\tDisc: 0.351467\t\tSym: 13.033099\t\tSpars: 640.796265\n",
      "\t TVw: 0.151921 | TVb: -2.040595 | GSw: -0.234961 | GSb: 0.065015 | TSUw: 0.464920 | TSUb: 0.034812\n",
      "Validating epoch 2184...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 642.5886976803822\n",
      "Average validation loss: 72.48300398167558\n",
      "Training epoch 2185...\n",
      "\n",
      "Train Epoch: 2185 [0/8000 (0%)]\tBatch Loss: 666.775019\tLearning Rate (w_theta): 0.001000\t TIME:4726.6s\n",
      "\t\t\t\tDisc: 0.349470\t\tSym: 13.373914\t\tSpars: 653.051636\n",
      "\t TVw: 0.152456 | TVb: -2.040587 | GSw: -0.234961 | GSb: 0.065015 | TSUw: 0.464920 | TSUb: 0.034812\n",
      "\n",
      "Train Epoch: 2185 [4000/8000 (50%)]\tBatch Loss: 645.670700\tLearning Rate (w_theta): 0.001000\t TIME:4728.2s\n",
      "\t\t\t\tDisc: 0.345327\t\tSym: 12.487177\t\tSpars: 632.838196\n",
      "\t TVw: 0.153037 | TVb: -2.040573 | GSw: -0.234961 | GSb: 0.065014 | TSUw: 0.464920 | TSUb: 0.034812\n",
      "Validating epoch 2185...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 640.9447432406129\n",
      "Average validation loss: 72.18140211693209\n",
      "Training epoch 2186...\n",
      "\n",
      "Train Epoch: 2186 [0/8000 (0%)]\tBatch Loss: 627.183335\tLearning Rate (w_theta): 0.001000\t TIME:4730.6s\n",
      "\t\t\t\tDisc: 0.330616\t\tSym: 11.099179\t\tSpars: 615.753540\n",
      "\t TVw: 0.153558 | TVb: -2.040565 | GSw: -0.234961 | GSb: 0.065014 | TSUw: 0.464920 | TSUb: 0.034812\n",
      "\n",
      "Train Epoch: 2186 [4000/8000 (50%)]\tBatch Loss: 659.873459\tLearning Rate (w_theta): 0.001000\t TIME:4732.1s\n",
      "\t\t\t\tDisc: 0.390565\t\tSym: 13.282699\t\tSpars: 646.200195\n",
      "\t TVw: 0.154143 | TVb: -2.040553 | GSw: -0.234961 | GSb: 0.065014 | TSUw: 0.464920 | TSUb: 0.034812\n",
      "Validating epoch 2186...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 638.4744436519993\n",
      "Average validation loss: 73.10663046835239\n",
      "Training epoch 2187...\n",
      "\n",
      "Train Epoch: 2187 [0/8000 (0%)]\tBatch Loss: 626.741988\tLearning Rate (w_theta): 0.001000\t TIME:4734.5s\n",
      "\t\t\t\tDisc: 0.357004\t\tSym: 10.730382\t\tSpars: 615.654602\n",
      "\t TVw: 0.154709 | TVb: -2.040539 | GSw: -0.234961 | GSb: 0.065014 | TSUw: 0.464920 | TSUb: 0.034812\n",
      "\n",
      "Train Epoch: 2187 [4000/8000 (50%)]\tBatch Loss: 632.185271\tLearning Rate (w_theta): 0.001000\t TIME:4736.1s\n",
      "\t\t\t\tDisc: 0.352310\t\tSym: 11.589492\t\tSpars: 620.243469\n",
      "\t TVw: 0.155119 | TVb: -2.040532 | GSw: -0.234961 | GSb: 0.065014 | TSUw: 0.464919 | TSUb: 0.034812\n",
      "Validating epoch 2187...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 643.8701184089641\n",
      "Average validation loss: 72.84527995682768\n",
      "Training epoch 2188...\n",
      "\n",
      "Train Epoch: 2188 [0/8000 (0%)]\tBatch Loss: 641.899715\tLearning Rate (w_theta): 0.001000\t TIME:4738.5s\n",
      "\t\t\t\tDisc: 0.382451\t\tSym: 11.945914\t\tSpars: 629.571350\n",
      "\t TVw: 0.155561 | TVb: -2.040524 | GSw: -0.234961 | GSb: 0.065014 | TSUw: 0.464919 | TSUb: 0.034812\n",
      "\n",
      "Train Epoch: 2188 [4000/8000 (50%)]\tBatch Loss: 666.974161\tLearning Rate (w_theta): 0.001000\t TIME:4740.1s\n",
      "\t\t\t\tDisc: 0.350772\t\tSym: 12.846778\t\tSpars: 653.776611\n",
      "\t TVw: 0.156060 | TVb: -2.040513 | GSw: -0.234961 | GSb: 0.065014 | TSUw: 0.464919 | TSUb: 0.034813\n",
      "Validating epoch 2188...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 640.6706093253754\n",
      "Average validation loss: 73.47345870991906\n",
      "Training epoch 2189...\n",
      "\n",
      "Train Epoch: 2189 [0/8000 (0%)]\tBatch Loss: 620.688798\tLearning Rate (w_theta): 0.001000\t TIME:4742.5s\n",
      "\t\t\t\tDisc: 0.384142\t\tSym: 11.176543\t\tSpars: 609.128113\n",
      "\t TVw: 0.156488 | TVb: -2.040506 | GSw: -0.234961 | GSb: 0.065014 | TSUw: 0.464919 | TSUb: 0.034813\n",
      "\n",
      "Train Epoch: 2189 [4000/8000 (50%)]\tBatch Loss: 633.284288\tLearning Rate (w_theta): 0.001000\t TIME:4744.1s\n",
      "\t\t\t\tDisc: 0.319836\t\tSym: 11.906529\t\tSpars: 621.057922\n",
      "\t TVw: 0.156897 | TVb: -2.040498 | GSw: -0.234961 | GSb: 0.065014 | TSUw: 0.464919 | TSUb: 0.034813\n",
      "Validating epoch 2189...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 637.9948230282705\n",
      "Average validation loss: 73.2376921696624\n",
      "Training epoch 2190...\n",
      "\n",
      "Train Epoch: 2190 [0/8000 (0%)]\tBatch Loss: 614.555218\tLearning Rate (w_theta): 0.001000\t TIME:4746.8s\n",
      "\t\t\t\tDisc: 0.334504\t\tSym: 10.869700\t\tSpars: 603.351013\n",
      "\t TVw: 0.157405 | TVb: -2.040486 | GSw: -0.234961 | GSb: 0.065014 | TSUw: 0.464919 | TSUb: 0.034813\n",
      "\n",
      "Train Epoch: 2190 [4000/8000 (50%)]\tBatch Loss: 653.927197\tLearning Rate (w_theta): 0.001000\t TIME:4748.4s\n",
      "\t\t\t\tDisc: 0.376882\t\tSym: 12.909751\t\tSpars: 640.640564\n",
      "\t TVw: 0.157971 | TVb: -2.040472 | GSw: -0.234961 | GSb: 0.065014 | TSUw: 0.464919 | TSUb: 0.034813\n",
      "Validating epoch 2190...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 635.3061252814825\n",
      "Average validation loss: 72.98180963666447\n",
      "Training epoch 2191...\n",
      "\n",
      "Train Epoch: 2191 [0/8000 (0%)]\tBatch Loss: 628.794982\tLearning Rate (w_theta): 0.001000\t TIME:4751.5s\n",
      "\t\t\t\tDisc: 0.388365\t\tSym: 12.035034\t\tSpars: 616.371582\n",
      "\t TVw: 0.158399 | TVb: -2.040465 | GSw: -0.234961 | GSb: 0.065013 | TSUw: 0.464919 | TSUb: 0.034813\n",
      "\n",
      "Train Epoch: 2191 [4000/8000 (50%)]\tBatch Loss: 649.100766\tLearning Rate (w_theta): 0.001000\t TIME:4753.1s\n",
      "\t\t\t\tDisc: 0.338112\t\tSym: 11.667255\t\tSpars: 637.095398\n",
      "\t TVw: 0.158840 | TVb: -2.040457 | GSw: -0.234961 | GSb: 0.065013 | TSUw: 0.464918 | TSUb: 0.034813\n",
      "Validating epoch 2191...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 638.4660657641201\n",
      "Average validation loss: 73.06465859100138\n",
      "Training epoch 2192...\n",
      "\n",
      "Train Epoch: 2192 [0/8000 (0%)]\tBatch Loss: 639.856385\tLearning Rate (w_theta): 0.001000\t TIME:4755.5s\n",
      "\t\t\t\tDisc: 0.419856\t\tSym: 12.365666\t\tSpars: 627.070862\n",
      "\t TVw: 0.159256 | TVb: -2.040450 | GSw: -0.234961 | GSb: 0.065013 | TSUw: 0.464918 | TSUb: 0.034813\n",
      "\n",
      "Train Epoch: 2192 [4000/8000 (50%)]\tBatch Loss: 631.000356\tLearning Rate (w_theta): 0.001000\t TIME:4757.1s\n",
      "\t\t\t\tDisc: 0.288682\t\tSym: 11.051274\t\tSpars: 619.660400\n",
      "\t TVw: 0.159604 | TVb: -2.040445 | GSw: -0.234961 | GSb: 0.065013 | TSUw: 0.464918 | TSUb: 0.034813\n",
      "Validating epoch 2192...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 640.9666100027932\n",
      "Average validation loss: 73.43566143390552\n",
      "Training epoch 2193...\n",
      "\n",
      "Train Epoch: 2193 [0/8000 (0%)]\tBatch Loss: 644.547732\tLearning Rate (w_theta): 0.001000\t TIME:4759.5s\n",
      "\t\t\t\tDisc: 0.408888\t\tSym: 12.964833\t\tSpars: 631.174011\n",
      "\t TVw: 0.160026 | TVb: -2.040438 | GSw: -0.234962 | GSb: 0.065013 | TSUw: 0.464918 | TSUb: 0.034813\n",
      "\n",
      "Train Epoch: 2193 [4000/8000 (50%)]\tBatch Loss: 592.946759\tLearning Rate (w_theta): 0.001000\t TIME:4761.1s\n",
      "\t\t\t\tDisc: 0.297975\t\tSym: 9.929180\t\tSpars: 582.719604\n",
      "\t TVw: 0.160572 | TVb: -2.040425 | GSw: -0.234962 | GSb: 0.065013 | TSUw: 0.464918 | TSUb: 0.034813\n",
      "Validating epoch 2193...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 631.9531367675842\n",
      "Average validation loss: 73.45102641233993\n",
      "Training epoch 2194...\n",
      "\n",
      "Train Epoch: 2194 [0/8000 (0%)]\tBatch Loss: 649.720160\tLearning Rate (w_theta): 0.001000\t TIME:4763.5s\n",
      "\t\t\t\tDisc: 0.384950\t\tSym: 12.921453\t\tSpars: 636.413757\n",
      "\t TVw: 0.161144 | TVb: -2.040411 | GSw: -0.234962 | GSb: 0.065013 | TSUw: 0.464918 | TSUb: 0.034813\n",
      "\n",
      "Train Epoch: 2194 [4000/8000 (50%)]\tBatch Loss: 611.185428\tLearning Rate (w_theta): 0.001000\t TIME:4765.1s\n",
      "\t\t\t\tDisc: 0.358586\t\tSym: 11.200988\t\tSpars: 599.625854\n",
      "\t TVw: 0.161693 | TVb: -2.040398 | GSw: -0.234962 | GSb: 0.065013 | TSUw: 0.464918 | TSUb: 0.034813\n",
      "Validating epoch 2194...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 632.9235976398203\n",
      "Average validation loss: 73.10053365765603\n",
      "Training epoch 2195...\n",
      "\n",
      "Train Epoch: 2195 [0/8000 (0%)]\tBatch Loss: 632.436739\tLearning Rate (w_theta): 0.001000\t TIME:4767.5s\n",
      "\t\t\t\tDisc: 0.401540\t\tSym: 12.001508\t\tSpars: 620.033691\n",
      "\t TVw: 0.162095 | TVb: -2.040392 | GSw: -0.234962 | GSb: 0.065013 | TSUw: 0.464918 | TSUb: 0.034814\n",
      "\n",
      "Train Epoch: 2195 [4000/8000 (50%)]\tBatch Loss: 692.214484\tLearning Rate (w_theta): 0.001000\t TIME:4769.1s\n",
      "\t\t\t\tDisc: 0.317080\t\tSym: 14.781072\t\tSpars: 677.116333\n",
      "\t TVw: 0.162550 | TVb: -2.040381 | GSw: -0.234962 | GSb: 0.065013 | TSUw: 0.464917 | TSUb: 0.034814\n",
      "Validating epoch 2195...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 646.9682591254995\n",
      "Average validation loss: 73.07304425159145\n",
      "Training epoch 2196...\n",
      "\n",
      "Train Epoch: 2196 [0/8000 (0%)]\tBatch Loss: 643.448931\tLearning Rate (w_theta): 0.001000\t TIME:4771.5s\n",
      "\t\t\t\tDisc: 0.384492\t\tSym: 12.512803\t\tSpars: 630.551636\n",
      "\t TVw: 0.162785 | TVb: -2.040386 | GSw: -0.234962 | GSb: 0.065013 | TSUw: 0.464917 | TSUb: 0.034814\n",
      "\n",
      "Train Epoch: 2196 [4000/8000 (50%)]\tBatch Loss: 651.604163\tLearning Rate (w_theta): 0.001000\t TIME:4773.1s\n",
      "\t\t\t\tDisc: 0.308222\t\tSym: 11.756391\t\tSpars: 639.539551\n",
      "\t TVw: 0.162943 | TVb: -2.040393 | GSw: -0.234962 | GSb: 0.065012 | TSUw: 0.464917 | TSUb: 0.034814\n",
      "Validating epoch 2196...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 648.6341013528895\n",
      "Average validation loss: 74.89651659819374\n",
      "Training epoch 2197...\n",
      "\n",
      "Train Epoch: 2197 [0/8000 (0%)]\tBatch Loss: 617.141391\tLearning Rate (w_theta): 0.001000\t TIME:4775.5s\n",
      "\t\t\t\tDisc: 0.308439\t\tSym: 10.836370\t\tSpars: 605.996582\n",
      "\t TVw: 0.163246 | TVb: -2.040393 | GSw: -0.234962 | GSb: 0.065012 | TSUw: 0.464917 | TSUb: 0.034814\n",
      "\n",
      "Train Epoch: 2197 [4000/8000 (50%)]\tBatch Loss: 659.574979\tLearning Rate (w_theta): 0.001000\t TIME:4777.1s\n",
      "\t\t\t\tDisc: 0.418084\t\tSym: 14.269261\t\tSpars: 644.887634\n",
      "\t TVw: 0.163625 | TVb: -2.040390 | GSw: -0.234962 | GSb: 0.065012 | TSUw: 0.464917 | TSUb: 0.034814\n",
      "Validating epoch 2197...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 638.2582404524909\n",
      "Average validation loss: 75.47097464665801\n",
      "Training epoch 2198...\n",
      "\n",
      "Train Epoch: 2198 [0/8000 (0%)]\tBatch Loss: 671.624269\tLearning Rate (w_theta): 0.001000\t TIME:4779.5s\n",
      "\t\t\t\tDisc: 0.422299\t\tSym: 13.785832\t\tSpars: 657.416138\n",
      "\t TVw: 0.164158 | TVb: -2.040377 | GSw: -0.234962 | GSb: 0.065012 | TSUw: 0.464917 | TSUb: 0.034814\n",
      "\n",
      "Train Epoch: 2198 [4000/8000 (50%)]\tBatch Loss: 583.713905\tLearning Rate (w_theta): 0.001000\t TIME:4781.1s\n",
      "\t\t\t\tDisc: 0.317531\t\tSym: 9.990124\t\tSpars: 573.406250\n",
      "\t TVw: 0.164864 | TVb: -2.040357 | GSw: -0.234962 | GSb: 0.065012 | TSUw: 0.464917 | TSUb: 0.034814\n",
      "Validating epoch 2198...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 629.6601262961155\n",
      "Average validation loss: 73.3876229134428\n",
      "Training epoch 2199...\n",
      "\n",
      "Train Epoch: 2199 [0/8000 (0%)]\tBatch Loss: 625.465787\tLearning Rate (w_theta): 0.001000\t TIME:4783.5s\n",
      "\t\t\t\tDisc: 0.331140\t\tSym: 11.395939\t\tSpars: 613.738708\n",
      "\t TVw: 0.165645 | TVb: -2.040335 | GSw: -0.234962 | GSb: 0.065012 | TSUw: 0.464917 | TSUb: 0.034814\n",
      "\n",
      "Train Epoch: 2199 [4000/8000 (50%)]\tBatch Loss: 631.039055\tLearning Rate (w_theta): 0.001000\t TIME:4785.1s\n",
      "\t\t\t\tDisc: 0.356586\t\tSym: 12.259739\t\tSpars: 618.422729\n",
      "\t TVw: 0.166433 | TVb: -2.040311 | GSw: -0.234962 | GSb: 0.065012 | TSUw: 0.464917 | TSUb: 0.034814\n",
      "Validating epoch 2199...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 627.0736216799795\n",
      "Average validation loss: 73.82268646622501\n",
      "Training epoch 2200...\n",
      "\n",
      "Train Epoch: 2200 [0/8000 (0%)]\tBatch Loss: 643.430193\tLearning Rate (w_theta): 0.001000\t TIME:4787.5s\n",
      "\t\t\t\tDisc: 0.377468\t\tSym: 13.008048\t\tSpars: 630.044678\n",
      "\t TVw: 0.167155 | TVb: -2.040292 | GSw: -0.234962 | GSb: 0.065012 | TSUw: 0.464916 | TSUb: 0.034814\n",
      "\n",
      "Train Epoch: 2200 [4000/8000 (50%)]\tBatch Loss: 625.311734\tLearning Rate (w_theta): 0.001000\t TIME:4789.1s\n",
      "\t\t\t\tDisc: 0.367613\t\tSym: 12.226043\t\tSpars: 612.718079\n",
      "\t TVw: 0.167818 | TVb: -2.040277 | GSw: -0.234962 | GSb: 0.065012 | TSUw: 0.464916 | TSUb: 0.034814\n",
      "Validating epoch 2200...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 624.795579717453\n",
      "Average validation loss: 73.86176106843101\n",
      "Training epoch 2201...\n",
      "\n",
      "Train Epoch: 2201 [0/8000 (0%)]\tBatch Loss: 619.108929\tLearning Rate (w_theta): 0.001000\t TIME:4792.5s\n",
      "\t\t\t\tDisc: 0.360402\t\tSym: 11.664908\t\tSpars: 607.083618\n",
      "\t TVw: 0.168420 | TVb: -2.040265 | GSw: -0.234962 | GSb: 0.065012 | TSUw: 0.464916 | TSUb: 0.034815\n",
      "\n",
      "Train Epoch: 2201 [4000/8000 (50%)]\tBatch Loss: 632.197851\tLearning Rate (w_theta): 0.001000\t TIME:4794.1s\n",
      "\t\t\t\tDisc: 0.361338\t\tSym: 12.053187\t\tSpars: 619.783325\n",
      "\t TVw: 0.168856 | TVb: -2.040255 | GSw: -0.234963 | GSb: 0.065012 | TSUw: 0.464916 | TSUb: 0.034815\n",
      "Validating epoch 2201...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 624.5874207562791\n",
      "Average validation loss: 73.70676740072872\n",
      "Training epoch 2202...\n",
      "\n",
      "Train Epoch: 2202 [0/8000 (0%)]\tBatch Loss: 618.386919\tLearning Rate (w_theta): 0.001000\t TIME:4796.5s\n",
      "\t\t\t\tDisc: 0.326648\t\tSym: 11.619353\t\tSpars: 606.440918\n",
      "\t TVw: 0.169342 | TVb: -2.040243 | GSw: -0.234963 | GSb: 0.065011 | TSUw: 0.464916 | TSUb: 0.034815\n",
      "\n",
      "Train Epoch: 2202 [4000/8000 (50%)]\tBatch Loss: 629.647076\tLearning Rate (w_theta): 0.001000\t TIME:4798.1s\n",
      "\t\t\t\tDisc: 0.398566\t\tSym: 12.194738\t\tSpars: 617.053772\n",
      "\t TVw: 0.169838 | TVb: -2.040230 | GSw: -0.234963 | GSb: 0.065011 | TSUw: 0.464916 | TSUb: 0.034815\n",
      "Validating epoch 2202...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 623.5496439582058\n",
      "Average validation loss: 73.0230656302517\n",
      "Training epoch 2203...\n",
      "\n",
      "Train Epoch: 2203 [0/8000 (0%)]\tBatch Loss: 631.883802\tLearning Rate (w_theta): 0.001000\t TIME:4800.5s\n",
      "\t\t\t\tDisc: 0.384993\t\tSym: 12.163543\t\tSpars: 619.335266\n",
      "\t TVw: 0.170181 | TVb: -2.040223 | GSw: -0.234963 | GSb: 0.065011 | TSUw: 0.464916 | TSUb: 0.034815\n",
      "\n",
      "Train Epoch: 2203 [4000/8000 (50%)]\tBatch Loss: 639.218566\tLearning Rate (w_theta): 0.001000\t TIME:4802.1s\n",
      "\t\t\t\tDisc: 0.385101\t\tSym: 11.649505\t\tSpars: 627.183960\n",
      "\t TVw: 0.170447 | TVb: -2.040215 | GSw: -0.234963 | GSb: 0.065011 | TSUw: 0.464916 | TSUb: 0.034815\n",
      "Validating epoch 2203...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 626.3165048881391\n",
      "Average validation loss: 73.18932000356459\n",
      "Training epoch 2204...\n",
      "\n",
      "Train Epoch: 2204 [0/8000 (0%)]\tBatch Loss: 623.163125\tLearning Rate (w_theta): 0.001000\t TIME:4804.5s\n",
      "\t\t\t\tDisc: 0.369399\t\tSym: 11.435389\t\tSpars: 611.358337\n",
      "\t TVw: 0.170561 | TVb: -2.040215 | GSw: -0.234963 | GSb: 0.065011 | TSUw: 0.464915 | TSUb: 0.034815\n",
      "\n",
      "Train Epoch: 2204 [4000/8000 (50%)]\tBatch Loss: 615.696839\tLearning Rate (w_theta): 0.001000\t TIME:4806.1s\n",
      "\t\t\t\tDisc: 0.339924\t\tSym: 11.152326\t\tSpars: 604.204590\n",
      "\t TVw: 0.170651 | TVb: -2.040219 | GSw: -0.234963 | GSb: 0.065011 | TSUw: 0.464915 | TSUb: 0.034815\n",
      "Validating epoch 2204...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 630.5549419340883\n",
      "Average validation loss: 75.34141115151783\n",
      "Training epoch 2205...\n",
      "\n",
      "Train Epoch: 2205 [0/8000 (0%)]\tBatch Loss: 657.870622\tLearning Rate (w_theta): 0.001000\t TIME:4808.6s\n",
      "\t\t\t\tDisc: 0.316172\t\tSym: 12.611152\t\tSpars: 644.943298\n",
      "\t TVw: 0.170804 | TVb: -2.040215 | GSw: -0.234963 | GSb: 0.065011 | TSUw: 0.464915 | TSUb: 0.034815\n",
      "\n",
      "Train Epoch: 2205 [4000/8000 (50%)]\tBatch Loss: 604.998423\tLearning Rate (w_theta): 0.001000\t TIME:4810.1s\n",
      "\t\t\t\tDisc: 0.321710\t\tSym: 10.745866\t\tSpars: 593.930847\n",
      "\t TVw: 0.170851 | TVb: -2.040216 | GSw: -0.234963 | GSb: 0.065011 | TSUw: 0.464915 | TSUb: 0.034815\n",
      "Validating epoch 2205...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 638.7595423271857\n",
      "Average validation loss: 73.70630852781741\n",
      "Training epoch 2206...\n",
      "\n",
      "Train Epoch: 2206 [0/8000 (0%)]\tBatch Loss: 596.053282\tLearning Rate (w_theta): 0.001000\t TIME:4812.5s\n",
      "\t\t\t\tDisc: 0.299553\t\tSym: 9.829229\t\tSpars: 585.924500\n",
      "\t TVw: 0.170956 | TVb: -2.040218 | GSw: -0.234963 | GSb: 0.065011 | TSUw: 0.464915 | TSUb: 0.034815\n",
      "\n",
      "Train Epoch: 2206 [4000/8000 (50%)]\tBatch Loss: 629.612262\tLearning Rate (w_theta): 0.001000\t TIME:4814.1s\n",
      "\t\t\t\tDisc: 0.337309\t\tSym: 12.614247\t\tSpars: 616.660706\n",
      "\t TVw: 0.171153 | TVb: -2.040220 | GSw: -0.234963 | GSb: 0.065011 | TSUw: 0.464915 | TSUb: 0.034815\n",
      "Validating epoch 2206...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 633.8856765558949\n",
      "Average validation loss: 76.0657083631484\n",
      "Training epoch 2207...\n",
      "\n",
      "Train Epoch: 2207 [0/8000 (0%)]\tBatch Loss: 659.920681\tLearning Rate (w_theta): 0.001000\t TIME:4816.5s\n",
      "\t\t\t\tDisc: 0.382015\t\tSym: 13.144623\t\tSpars: 646.394043\n",
      "\t TVw: 0.171553 | TVb: -2.040213 | GSw: -0.234963 | GSb: 0.065010 | TSUw: 0.464915 | TSUb: 0.034816\n",
      "\n",
      "Train Epoch: 2207 [4000/8000 (50%)]\tBatch Loss: 601.274555\tLearning Rate (w_theta): 0.001000\t TIME:4818.2s\n",
      "\t\t\t\tDisc: 0.333256\t\tSym: 11.018447\t\tSpars: 589.922852\n",
      "\t TVw: 0.172116 | TVb: -2.040197 | GSw: -0.234963 | GSb: 0.065010 | TSUw: 0.464915 | TSUb: 0.034816\n",
      "Validating epoch 2207...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 621.7297361119784\n",
      "Average validation loss: 75.29970308177704\n",
      "Training epoch 2208...\n",
      "\n",
      "Train Epoch: 2208 [0/8000 (0%)]\tBatch Loss: 626.632028\tLearning Rate (w_theta): 0.001000\t TIME:4820.6s\n",
      "\t\t\t\tDisc: 0.341975\t\tSym: 12.198683\t\tSpars: 614.091370\n",
      "\t TVw: 0.172840 | TVb: -2.040170 | GSw: -0.234963 | GSb: 0.065010 | TSUw: 0.464915 | TSUb: 0.034816\n",
      "\n",
      "Train Epoch: 2208 [4000/8000 (50%)]\tBatch Loss: 637.671153\tLearning Rate (w_theta): 0.001000\t TIME:4822.2s\n",
      "\t\t\t\tDisc: 0.356031\t\tSym: 13.239926\t\tSpars: 624.075195\n",
      "\t TVw: 0.173539 | TVb: -2.040141 | GSw: -0.234963 | GSb: 0.065010 | TSUw: 0.464914 | TSUb: 0.034816\n",
      "Validating epoch 2208...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 617.6206547853687\n",
      "Average validation loss: 73.95178266720639\n",
      "Training epoch 2209...\n",
      "\n",
      "Train Epoch: 2209 [0/8000 (0%)]\tBatch Loss: 604.284743\tLearning Rate (w_theta): 0.001000\t TIME:4824.6s\n",
      "\t\t\t\tDisc: 0.360722\t\tSym: 10.955821\t\tSpars: 592.968201\n",
      "\t TVw: 0.174235 | TVb: -2.040115 | GSw: -0.234963 | GSb: 0.065010 | TSUw: 0.464914 | TSUb: 0.034816\n",
      "\n",
      "Train Epoch: 2209 [4000/8000 (50%)]\tBatch Loss: 615.995402\tLearning Rate (w_theta): 0.001000\t TIME:4826.1s\n",
      "\t\t\t\tDisc: 0.414490\t\tSym: 11.940409\t\tSpars: 603.640503\n",
      "\t TVw: 0.174849 | TVb: -2.040095 | GSw: -0.234963 | GSb: 0.065010 | TSUw: 0.464914 | TSUb: 0.034816\n",
      "Validating epoch 2209...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 616.9129552804952\n",
      "Average validation loss: 73.62724137676318\n",
      "Training epoch 2210...\n",
      "\n",
      "Train Epoch: 2210 [0/8000 (0%)]\tBatch Loss: 613.484951\tLearning Rate (w_theta): 0.001000\t TIME:4828.5s\n",
      "\t\t\t\tDisc: 0.359324\t\tSym: 11.285111\t\tSpars: 601.840515\n",
      "\t TVw: 0.175375 | TVb: -2.040078 | GSw: -0.234964 | GSb: 0.065010 | TSUw: 0.464914 | TSUb: 0.034816\n",
      "\n",
      "Train Epoch: 2210 [4000/8000 (50%)]\tBatch Loss: 608.557463\tLearning Rate (w_theta): 0.001000\t TIME:4830.1s\n",
      "\t\t\t\tDisc: 0.333802\t\tSym: 11.554167\t\tSpars: 596.669495\n",
      "\t TVw: 0.175819 | TVb: -2.040066 | GSw: -0.234964 | GSb: 0.065010 | TSUw: 0.464914 | TSUb: 0.034816\n",
      "Validating epoch 2210...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 615.0855749452543\n",
      "Average validation loss: 73.81626834020604\n",
      "Training epoch 2211...\n",
      "\n",
      "Train Epoch: 2211 [0/8000 (0%)]\tBatch Loss: 602.464635\tLearning Rate (w_theta): 0.001000\t TIME:4833.6s\n",
      "\t\t\t\tDisc: 0.362995\t\tSym: 11.437089\t\tSpars: 590.664551\n",
      "\t TVw: 0.176188 | TVb: -2.040057 | GSw: -0.234964 | GSb: 0.065010 | TSUw: 0.464914 | TSUb: 0.034816\n",
      "\n",
      "Train Epoch: 2211 [4000/8000 (50%)]\tBatch Loss: 616.079461\tLearning Rate (w_theta): 0.001000\t TIME:4835.2s\n",
      "\t\t\t\tDisc: 0.348442\t\tSym: 11.716249\t\tSpars: 604.014771\n",
      "\t TVw: 0.176429 | TVb: -2.040053 | GSw: -0.234964 | GSb: 0.065010 | TSUw: 0.464914 | TSUb: 0.034816\n",
      "Validating epoch 2211...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 614.9156216914777\n",
      "Average validation loss: 74.07838109752016\n",
      "Training epoch 2212...\n",
      "\n",
      "Train Epoch: 2212 [0/8000 (0%)]\tBatch Loss: 587.267970\tLearning Rate (w_theta): 0.001000\t TIME:4837.6s\n",
      "\t\t\t\tDisc: 0.349115\t\tSym: 10.034760\t\tSpars: 576.884094\n",
      "\t TVw: 0.176728 | TVb: -2.040047 | GSw: -0.234964 | GSb: 0.065009 | TSUw: 0.464914 | TSUb: 0.034816\n",
      "\n",
      "Train Epoch: 2212 [4000/8000 (50%)]\tBatch Loss: 632.924459\tLearning Rate (w_theta): 0.001000\t TIME:4839.2s\n",
      "\t\t\t\tDisc: 0.399929\t\tSym: 12.581109\t\tSpars: 619.943420\n",
      "\t TVw: 0.176989 | TVb: -2.040041 | GSw: -0.234964 | GSb: 0.065009 | TSUw: 0.464913 | TSUb: 0.034817\n",
      "Validating epoch 2212...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 614.0873847792537\n",
      "Average validation loss: 74.4940890894505\n",
      "Training epoch 2213...\n",
      "\n",
      "Train Epoch: 2213 [0/8000 (0%)]\tBatch Loss: 650.748898\tLearning Rate (w_theta): 0.001000\t TIME:4841.6s\n",
      "\t\t\t\tDisc: 0.387052\t\tSym: 13.745818\t\tSpars: 636.616028\n",
      "\t TVw: 0.177284 | TVb: -2.040031 | GSw: -0.234964 | GSb: 0.065009 | TSUw: 0.464913 | TSUb: 0.034817\n",
      "\n",
      "Train Epoch: 2213 [4000/8000 (50%)]\tBatch Loss: 626.901156\tLearning Rate (w_theta): 0.001000\t TIME:4843.2s\n",
      "\t\t\t\tDisc: 0.368927\t\tSym: 12.176517\t\tSpars: 614.355713\n",
      "\t TVw: 0.177626 | TVb: -2.040016 | GSw: -0.234964 | GSb: 0.065009 | TSUw: 0.464913 | TSUb: 0.034817\n",
      "Validating epoch 2213...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 615.6089292540379\n",
      "Average validation loss: 73.73163540030491\n",
      "Training epoch 2214...\n",
      "\n",
      "Train Epoch: 2214 [0/8000 (0%)]\tBatch Loss: 596.093743\tLearning Rate (w_theta): 0.001000\t TIME:4845.7s\n",
      "\t\t\t\tDisc: 0.348386\t\tSym: 10.251155\t\tSpars: 585.494202\n",
      "\t TVw: 0.177777 | TVb: -2.040014 | GSw: -0.234964 | GSb: 0.065009 | TSUw: 0.464913 | TSUb: 0.034817\n",
      "\n",
      "Train Epoch: 2214 [4000/8000 (50%)]\tBatch Loss: 604.343325\tLearning Rate (w_theta): 0.001000\t TIME:4847.2s\n",
      "\t\t\t\tDisc: 0.381974\t\tSym: 11.490099\t\tSpars: 592.471252\n",
      "\t TVw: 0.177995 | TVb: -2.040006 | GSw: -0.234964 | GSb: 0.065009 | TSUw: 0.464913 | TSUb: 0.034817\n",
      "Validating epoch 2214...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 613.165552381807\n",
      "Average validation loss: 73.25789777363549\n",
      "Training epoch 2215...\n",
      "\n",
      "Train Epoch: 2215 [0/8000 (0%)]\tBatch Loss: 621.442863\tLearning Rate (w_theta): 0.001000\t TIME:4849.7s\n",
      "\t\t\t\tDisc: 0.352173\t\tSym: 11.751884\t\tSpars: 609.338806\n",
      "\t TVw: 0.178198 | TVb: -2.039999 | GSw: -0.234964 | GSb: 0.065009 | TSUw: 0.464913 | TSUb: 0.034817\n",
      "\n",
      "Train Epoch: 2215 [4000/8000 (50%)]\tBatch Loss: 615.625736\tLearning Rate (w_theta): 0.001000\t TIME:4851.3s\n",
      "\t\t\t\tDisc: 0.363348\t\tSym: 11.642697\t\tSpars: 603.619690\n",
      "\t TVw: 0.178436 | TVb: -2.039993 | GSw: -0.234964 | GSb: 0.065009 | TSUw: 0.464913 | TSUb: 0.034817\n",
      "Validating epoch 2215...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 613.7216970714887\n",
      "Average validation loss: 74.685672243225\n",
      "Training epoch 2216...\n",
      "\n",
      "Train Epoch: 2216 [0/8000 (0%)]\tBatch Loss: 609.824163\tLearning Rate (w_theta): 0.001000\t TIME:4853.7s\n",
      "\t\t\t\tDisc: 0.343368\t\tSym: 11.263205\t\tSpars: 598.217590\n",
      "\t TVw: 0.178741 | TVb: -2.039981 | GSw: -0.234964 | GSb: 0.065009 | TSUw: 0.464913 | TSUb: 0.034817\n",
      "\n",
      "Train Epoch: 2216 [4000/8000 (50%)]\tBatch Loss: 622.978631\tLearning Rate (w_theta): 0.001000\t TIME:4855.3s\n",
      "\t\t\t\tDisc: 0.323709\t\tSym: 12.092483\t\tSpars: 610.562439\n",
      "\t TVw: 0.178986 | TVb: -2.039975 | GSw: -0.234964 | GSb: 0.065009 | TSUw: 0.464912 | TSUb: 0.034817\n",
      "Validating epoch 2216...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 617.5399525630002\n",
      "Average validation loss: 73.92121760492546\n",
      "Training epoch 2217...\n",
      "\n",
      "Train Epoch: 2217 [0/8000 (0%)]\tBatch Loss: 605.672939\tLearning Rate (w_theta): 0.001000\t TIME:4857.8s\n",
      "\t\t\t\tDisc: 0.410199\t\tSym: 11.576278\t\tSpars: 593.686462\n",
      "\t TVw: 0.179090 | TVb: -2.039974 | GSw: -0.234964 | GSb: 0.065008 | TSUw: 0.464912 | TSUb: 0.034817\n",
      "\n",
      "Train Epoch: 2217 [4000/8000 (50%)]\tBatch Loss: 637.632750\tLearning Rate (w_theta): 0.001000\t TIME:4859.3s\n",
      "\t\t\t\tDisc: 0.340484\t\tSym: 12.434722\t\tSpars: 624.857544\n",
      "\t TVw: 0.179233 | TVb: -2.039969 | GSw: -0.234964 | GSb: 0.065008 | TSUw: 0.464912 | TSUb: 0.034817\n",
      "Validating epoch 2217...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 623.7113160256215\n",
      "Average validation loss: 74.72611115295308\n",
      "Training epoch 2218...\n",
      "\n",
      "Train Epoch: 2218 [0/8000 (0%)]\tBatch Loss: 613.903619\tLearning Rate (w_theta): 0.001000\t TIME:4861.8s\n",
      "\t\t\t\tDisc: 0.401896\t\tSym: 11.247207\t\tSpars: 602.254517\n",
      "\t TVw: 0.179267 | TVb: -2.039970 | GSw: -0.234965 | GSb: 0.065008 | TSUw: 0.464912 | TSUb: 0.034817\n",
      "\n",
      "Train Epoch: 2218 [4000/8000 (50%)]\tBatch Loss: 612.907944\tLearning Rate (w_theta): 0.001000\t TIME:4863.3s\n",
      "\t\t\t\tDisc: 0.298215\t\tSym: 11.659595\t\tSpars: 600.950134\n",
      "\t TVw: 0.179497 | TVb: -2.039964 | GSw: -0.234965 | GSb: 0.065008 | TSUw: 0.464912 | TSUb: 0.034818\n",
      "Validating epoch 2218...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 619.0279860048317\n",
      "Average validation loss: 73.48132831623418\n",
      "Training epoch 2219...\n",
      "\n",
      "Train Epoch: 2219 [0/8000 (0%)]\tBatch Loss: 613.770270\tLearning Rate (w_theta): 0.001000\t TIME:4865.8s\n",
      "\t\t\t\tDisc: 0.299176\t\tSym: 10.683558\t\tSpars: 602.787537\n",
      "\t TVw: 0.179632 | TVb: -2.039961 | GSw: -0.234965 | GSb: 0.065008 | TSUw: 0.464912 | TSUb: 0.034818\n",
      "\n",
      "Train Epoch: 2219 [4000/8000 (50%)]\tBatch Loss: 624.320049\tLearning Rate (w_theta): 0.001000\t TIME:4867.4s\n",
      "\t\t\t\tDisc: 0.287173\t\tSym: 12.069924\t\tSpars: 611.962952\n",
      "\t TVw: 0.179878 | TVb: -2.039956 | GSw: -0.234965 | GSb: 0.065008 | TSUw: 0.464912 | TSUb: 0.034818\n",
      "Validating epoch 2219...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 622.2921472439598\n",
      "Average validation loss: 75.8477393169073\n",
      "Training epoch 2220...\n",
      "\n",
      "Train Epoch: 2220 [0/8000 (0%)]\tBatch Loss: 599.145125\tLearning Rate (w_theta): 0.001000\t TIME:4869.8s\n",
      "\t\t\t\tDisc: 0.343352\t\tSym: 11.758194\t\tSpars: 587.043579\n",
      "\t TVw: 0.180170 | TVb: -2.039946 | GSw: -0.234965 | GSb: 0.065008 | TSUw: 0.464912 | TSUb: 0.034818\n",
      "\n",
      "Train Epoch: 2220 [4000/8000 (50%)]\tBatch Loss: 616.684197\tLearning Rate (w_theta): 0.001000\t TIME:4871.4s\n",
      "\t\t\t\tDisc: 0.335971\t\tSym: 12.198628\t\tSpars: 604.149597\n",
      "\t TVw: 0.180558 | TVb: -2.039933 | GSw: -0.234965 | GSb: 0.065008 | TSUw: 0.464912 | TSUb: 0.034818\n",
      "Validating epoch 2220...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 614.1037351025816\n",
      "Average validation loss: 75.87554010619473\n",
      "Training epoch 2221...\n",
      "\n",
      "Train Epoch: 2221 [0/8000 (0%)]\tBatch Loss: 587.834449\tLearning Rate (w_theta): 0.001000\t TIME:4874.5s\n",
      "\t\t\t\tDisc: 0.331301\t\tSym: 10.920812\t\tSpars: 576.582336\n",
      "\t TVw: 0.181021 | TVb: -2.039917 | GSw: -0.234965 | GSb: 0.065008 | TSUw: 0.464911 | TSUb: 0.034818\n",
      "\n",
      "Train Epoch: 2221 [4000/8000 (50%)]\tBatch Loss: 585.790365\tLearning Rate (w_theta): 0.001000\t TIME:4876.0s\n",
      "\t\t\t\tDisc: 0.315265\t\tSym: 10.921756\t\tSpars: 574.553345\n",
      "\t TVw: 0.181528 | TVb: -2.039899 | GSw: -0.234965 | GSb: 0.065007 | TSUw: 0.464911 | TSUb: 0.034818\n",
      "Validating epoch 2221...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 610.7809019378104\n",
      "Average validation loss: 74.3540270802585\n",
      "Training epoch 2222...\n",
      "\n",
      "Train Epoch: 2222 [0/8000 (0%)]\tBatch Loss: 633.169142\tLearning Rate (w_theta): 0.001000\t TIME:4878.8s\n",
      "\t\t\t\tDisc: 0.352095\t\tSym: 13.086090\t\tSpars: 619.730957\n",
      "\t TVw: 0.182094 | TVb: -2.039879 | GSw: -0.234965 | GSb: 0.065007 | TSUw: 0.464911 | TSUb: 0.034818\n",
      "\n",
      "Train Epoch: 2222 [4000/8000 (50%)]\tBatch Loss: 613.883567\tLearning Rate (w_theta): 0.001000\t TIME:4880.4s\n",
      "\t\t\t\tDisc: 0.361748\t\tSym: 11.537749\t\tSpars: 601.984070\n",
      "\t TVw: 0.182724 | TVb: -2.039856 | GSw: -0.234965 | GSb: 0.065007 | TSUw: 0.464911 | TSUb: 0.034818\n",
      "Validating epoch 2222...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 608.9268092680186\n",
      "Average validation loss: 73.87768825907459\n",
      "Training epoch 2223...\n",
      "\n",
      "Train Epoch: 2223 [0/8000 (0%)]\tBatch Loss: 603.688675\tLearning Rate (w_theta): 0.001000\t TIME:4882.8s\n",
      "\t\t\t\tDisc: 0.375218\t\tSym: 11.157818\t\tSpars: 592.155640\n",
      "\t TVw: 0.183348 | TVb: -2.039828 | GSw: -0.234965 | GSb: 0.065007 | TSUw: 0.464911 | TSUb: 0.034818\n",
      "\n",
      "Train Epoch: 2223 [4000/8000 (50%)]\tBatch Loss: 627.450464\tLearning Rate (w_theta): 0.001000\t TIME:4884.4s\n",
      "\t\t\t\tDisc: 0.382727\t\tSym: 12.999866\t\tSpars: 614.067871\n",
      "\t TVw: 0.183886 | TVb: -2.039802 | GSw: -0.234965 | GSb: 0.065007 | TSUw: 0.464911 | TSUb: 0.034818\n",
      "Validating epoch 2223...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 606.3311410911858\n",
      "Average validation loss: 74.20829946326138\n",
      "Training epoch 2224...\n",
      "\n",
      "Train Epoch: 2224 [0/8000 (0%)]\tBatch Loss: 583.513062\tLearning Rate (w_theta): 0.001000\t TIME:4886.8s\n",
      "\t\t\t\tDisc: 0.355978\t\tSym: 10.735454\t\tSpars: 572.421631\n",
      "\t TVw: 0.184414 | TVb: -2.039779 | GSw: -0.234965 | GSb: 0.065007 | TSUw: 0.464911 | TSUb: 0.034819\n",
      "\n",
      "Train Epoch: 2224 [4000/8000 (50%)]\tBatch Loss: 592.170363\tLearning Rate (w_theta): 0.001000\t TIME:4888.4s\n",
      "\t\t\t\tDisc: 0.344590\t\tSym: 11.364897\t\tSpars: 580.460876\n",
      "\t TVw: 0.184738 | TVb: -2.039769 | GSw: -0.234965 | GSb: 0.065007 | TSUw: 0.464911 | TSUb: 0.034819\n",
      "Validating epoch 2224...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 603.5867734313634\n",
      "Average validation loss: 74.38374232786234\n",
      "Training epoch 2225...\n",
      "\n",
      "Train Epoch: 2225 [0/8000 (0%)]\tBatch Loss: 586.164963\tLearning Rate (w_theta): 0.001000\t TIME:4890.8s\n",
      "\t\t\t\tDisc: 0.351116\t\tSym: 11.365238\t\tSpars: 574.448608\n",
      "\t TVw: 0.184973 | TVb: -2.039761 | GSw: -0.234965 | GSb: 0.065007 | TSUw: 0.464910 | TSUb: 0.034819\n",
      "\n",
      "Train Epoch: 2225 [4000/8000 (50%)]\tBatch Loss: 620.154112\tLearning Rate (w_theta): 0.001000\t TIME:4892.4s\n",
      "\t\t\t\tDisc: 0.416940\t\tSym: 12.177785\t\tSpars: 607.559387\n",
      "\t TVw: 0.185166 | TVb: -2.039754 | GSw: -0.234965 | GSb: 0.065006 | TSUw: 0.464910 | TSUb: 0.034819\n",
      "Validating epoch 2225...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 603.3430989655308\n",
      "Average validation loss: 73.67827333872587\n",
      "Training epoch 2226...\n",
      "\n",
      "Train Epoch: 2226 [0/8000 (0%)]\tBatch Loss: 611.763419\tLearning Rate (w_theta): 0.001000\t TIME:4894.8s\n",
      "\t\t\t\tDisc: 0.358388\t\tSym: 12.132936\t\tSpars: 599.272095\n",
      "\t TVw: 0.185314 | TVb: -2.039750 | GSw: -0.234965 | GSb: 0.065006 | TSUw: 0.464910 | TSUb: 0.034819\n",
      "\n",
      "Train Epoch: 2226 [4000/8000 (50%)]\tBatch Loss: 573.026587\tLearning Rate (w_theta): 0.001000\t TIME:4896.4s\n",
      "\t\t\t\tDisc: 0.351029\t\tSym: 10.064535\t\tSpars: 562.611023\n",
      "\t TVw: 0.185546 | TVb: -2.039739 | GSw: -0.234966 | GSb: 0.065006 | TSUw: 0.464910 | TSUb: 0.034819\n",
      "Validating epoch 2226...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 601.979382208264\n",
      "Average validation loss: 74.67569881637331\n",
      "Training epoch 2227...\n",
      "\n",
      "Train Epoch: 2227 [0/8000 (0%)]\tBatch Loss: 639.415526\tLearning Rate (w_theta): 0.001000\t TIME:4898.8s\n",
      "\t\t\t\tDisc: 0.424501\t\tSym: 13.108274\t\tSpars: 625.882751\n",
      "\t TVw: 0.185709 | TVb: -2.039731 | GSw: -0.234966 | GSb: 0.065006 | TSUw: 0.464910 | TSUb: 0.034819\n",
      "\n",
      "Train Epoch: 2227 [4000/8000 (50%)]\tBatch Loss: 604.149758\tLearning Rate (w_theta): 0.001000\t TIME:4900.4s\n",
      "\t\t\t\tDisc: 0.357886\t\tSym: 11.675356\t\tSpars: 592.116516\n",
      "\t TVw: 0.185759 | TVb: -2.039730 | GSw: -0.234966 | GSb: 0.065006 | TSUw: 0.464910 | TSUb: 0.034819\n",
      "Validating epoch 2227...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 601.5773964689326\n",
      "Average validation loss: 74.20024934486295\n",
      "Training epoch 2228...\n",
      "\n",
      "Train Epoch: 2228 [0/8000 (0%)]\tBatch Loss: 582.779267\tLearning Rate (w_theta): 0.001000\t TIME:4902.9s\n",
      "\t\t\t\tDisc: 0.372677\t\tSym: 10.664220\t\tSpars: 571.742371\n",
      "\t TVw: 0.185888 | TVb: -2.039721 | GSw: -0.234966 | GSb: 0.065006 | TSUw: 0.464910 | TSUb: 0.034819\n",
      "\n",
      "Train Epoch: 2228 [4000/8000 (50%)]\tBatch Loss: 588.312355\tLearning Rate (w_theta): 0.001000\t TIME:4904.4s\n",
      "\t\t\t\tDisc: 0.343633\t\tSym: 11.114413\t\tSpars: 576.854309\n",
      "\t TVw: 0.186047 | TVb: -2.039709 | GSw: -0.234966 | GSb: 0.065006 | TSUw: 0.464910 | TSUb: 0.034819\n",
      "Validating epoch 2228...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 600.0993793030949\n",
      "Average validation loss: 74.05504936814695\n",
      "Training epoch 2229...\n",
      "\n",
      "Train Epoch: 2229 [0/8000 (0%)]\tBatch Loss: 598.478758\tLearning Rate (w_theta): 0.001000\t TIME:4906.9s\n",
      "\t\t\t\tDisc: 0.341169\t\tSym: 11.547379\t\tSpars: 586.590210\n",
      "\t TVw: 0.186184 | TVb: -2.039701 | GSw: -0.234966 | GSb: 0.065006 | TSUw: 0.464909 | TSUb: 0.034819\n",
      "\n",
      "Train Epoch: 2229 [4000/8000 (50%)]\tBatch Loss: 602.766944\tLearning Rate (w_theta): 0.001000\t TIME:4908.5s\n",
      "\t\t\t\tDisc: 0.373935\t\tSym: 11.599795\t\tSpars: 590.793213\n",
      "\t TVw: 0.186316 | TVb: -2.039694 | GSw: -0.234966 | GSb: 0.065005 | TSUw: 0.464909 | TSUb: 0.034820\n",
      "Validating epoch 2229...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 598.8299612555334\n",
      "Average validation loss: 74.13329749778694\n",
      "Training epoch 2230...\n",
      "\n",
      "Train Epoch: 2230 [0/8000 (0%)]\tBatch Loss: 585.766296\tLearning Rate (w_theta): 0.001000\t TIME:4910.9s\n",
      "\t\t\t\tDisc: 0.329999\t\tSym: 10.858538\t\tSpars: 574.577759\n",
      "\t TVw: 0.186457 | TVb: -2.039687 | GSw: -0.234966 | GSb: 0.065005 | TSUw: 0.464909 | TSUb: 0.034820\n",
      "\n",
      "Train Epoch: 2230 [4000/8000 (50%)]\tBatch Loss: 584.222451\tLearning Rate (w_theta): 0.001000\t TIME:4912.4s\n",
      "\t\t\t\tDisc: 0.330918\t\tSym: 10.760002\t\tSpars: 573.131531\n",
      "\t TVw: 0.186650 | TVb: -2.039677 | GSw: -0.234966 | GSb: 0.065005 | TSUw: 0.464909 | TSUb: 0.034820\n",
      "Validating epoch 2230...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 601.091030570484\n",
      "Average validation loss: 73.68328167145545\n",
      "Training epoch 2231...\n",
      "\n",
      "Train Epoch: 2231 [0/8000 (0%)]\tBatch Loss: 606.412506\tLearning Rate (w_theta): 0.001000\t TIME:4915.6s\n",
      "\t\t\t\tDisc: 0.376835\t\tSym: 12.012538\t\tSpars: 594.023132\n",
      "\t TVw: 0.186832 | TVb: -2.039668 | GSw: -0.234966 | GSb: 0.065005 | TSUw: 0.464909 | TSUb: 0.034820\n",
      "\n",
      "Train Epoch: 2231 [4000/8000 (50%)]\tBatch Loss: 598.839268\tLearning Rate (w_theta): 0.001000\t TIME:4917.2s\n",
      "\t\t\t\tDisc: 0.349413\t\tSym: 11.709521\t\tSpars: 586.780334\n",
      "\t TVw: 0.187045 | TVb: -2.039661 | GSw: -0.234966 | GSb: 0.065005 | TSUw: 0.464909 | TSUb: 0.034820\n",
      "Validating epoch 2231...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 599.8299819317144\n",
      "Average validation loss: 74.932309424446\n",
      "Training epoch 2232...\n",
      "\n",
      "Train Epoch: 2232 [0/8000 (0%)]\tBatch Loss: 605.484566\tLearning Rate (w_theta): 0.001000\t TIME:4919.6s\n",
      "\t\t\t\tDisc: 0.369400\t\tSym: 12.037712\t\tSpars: 593.077454\n",
      "\t TVw: 0.187279 | TVb: -2.039647 | GSw: -0.234966 | GSb: 0.065005 | TSUw: 0.464909 | TSUb: 0.034820\n",
      "\n",
      "Train Epoch: 2232 [4000/8000 (50%)]\tBatch Loss: 610.672092\tLearning Rate (w_theta): 0.001000\t TIME:4921.2s\n",
      "\t\t\t\tDisc: 0.371930\t\tSym: 12.065909\t\tSpars: 598.234253\n",
      "\t TVw: 0.187530 | TVb: -2.039633 | GSw: -0.234966 | GSb: 0.065005 | TSUw: 0.464909 | TSUb: 0.034820\n",
      "Validating epoch 2232...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 598.4387873336684\n",
      "Average validation loss: 73.61512343463781\n",
      "Training epoch 2233...\n",
      "\n",
      "Train Epoch: 2233 [0/8000 (0%)]\tBatch Loss: 566.128761\tLearning Rate (w_theta): 0.001000\t TIME:4923.9s\n",
      "\t\t\t\tDisc: 0.309698\t\tSym: 9.639803\t\tSpars: 556.179260\n",
      "\t TVw: 0.187765 | TVb: -2.039622 | GSw: -0.234966 | GSb: 0.065005 | TSUw: 0.464909 | TSUb: 0.034820\n",
      "\n",
      "Train Epoch: 2233 [4000/8000 (50%)]\tBatch Loss: 624.139084\tLearning Rate (w_theta): 0.001000\t TIME:4925.5s\n",
      "\t\t\t\tDisc: 0.335597\t\tSym: 13.308187\t\tSpars: 610.495300\n",
      "\t TVw: 0.188020 | TVb: -2.039614 | GSw: -0.234966 | GSb: 0.065005 | TSUw: 0.464908 | TSUb: 0.034820\n",
      "Validating epoch 2233...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 596.6239774171929\n",
      "Average validation loss: 74.28996008578976\n",
      "Training epoch 2234...\n",
      "\n",
      "Train Epoch: 2234 [0/8000 (0%)]\tBatch Loss: 590.199071\tLearning Rate (w_theta): 0.001000\t TIME:4927.9s\n",
      "\t\t\t\tDisc: 0.345896\t\tSym: 11.725856\t\tSpars: 578.127319\n",
      "\t TVw: 0.188278 | TVb: -2.039604 | GSw: -0.234966 | GSb: 0.065004 | TSUw: 0.464908 | TSUb: 0.034820\n",
      "\n",
      "Train Epoch: 2234 [4000/8000 (50%)]\tBatch Loss: 601.136830\tLearning Rate (w_theta): 0.001000\t TIME:4929.4s\n",
      "\t\t\t\tDisc: 0.379930\t\tSym: 12.142642\t\tSpars: 588.614258\n",
      "\t TVw: 0.188565 | TVb: -2.039593 | GSw: -0.234966 | GSb: 0.065004 | TSUw: 0.464908 | TSUb: 0.034820\n",
      "Validating epoch 2234...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 593.6226101887889\n",
      "Average validation loss: 73.91739464312296\n",
      "Training epoch 2235...\n",
      "\n",
      "Train Epoch: 2235 [0/8000 (0%)]\tBatch Loss: 582.686299\tLearning Rate (w_theta): 0.001000\t TIME:4931.9s\n",
      "\t\t\t\tDisc: 0.314601\t\tSym: 10.452204\t\tSpars: 571.919495\n",
      "\t TVw: 0.188939 | TVb: -2.039580 | GSw: -0.234967 | GSb: 0.065004 | TSUw: 0.464908 | TSUb: 0.034821\n",
      "\n",
      "Train Epoch: 2235 [4000/8000 (50%)]\tBatch Loss: 588.829125\tLearning Rate (w_theta): 0.001000\t TIME:4933.4s\n",
      "\t\t\t\tDisc: 0.355992\t\tSym: 11.906299\t\tSpars: 576.566833\n",
      "\t TVw: 0.189284 | TVb: -2.039566 | GSw: -0.234967 | GSb: 0.065004 | TSUw: 0.464908 | TSUb: 0.034821\n",
      "Validating epoch 2235...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 592.6779271944729\n",
      "Average validation loss: 74.03828064103342\n",
      "Training epoch 2236...\n",
      "\n",
      "Train Epoch: 2236 [0/8000 (0%)]\tBatch Loss: 607.763834\tLearning Rate (w_theta): 0.001000\t TIME:4935.8s\n",
      "\t\t\t\tDisc: 0.361690\t\tSym: 12.512617\t\tSpars: 594.889526\n",
      "\t TVw: 0.189595 | TVb: -2.039554 | GSw: -0.234967 | GSb: 0.065004 | TSUw: 0.464908 | TSUb: 0.034821\n",
      "\n",
      "Train Epoch: 2236 [4000/8000 (50%)]\tBatch Loss: 582.414848\tLearning Rate (w_theta): 0.001000\t TIME:4937.4s\n",
      "\t\t\t\tDisc: 0.356050\t\tSym: 11.379721\t\tSpars: 570.679077\n",
      "\t TVw: 0.190004 | TVb: -2.039540 | GSw: -0.234967 | GSb: 0.065004 | TSUw: 0.464908 | TSUb: 0.034821\n",
      "Validating epoch 2236...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 592.2976587917324\n",
      "Average validation loss: 73.89082668543686\n",
      "Training epoch 2237...\n",
      "\n",
      "Train Epoch: 2237 [0/8000 (0%)]\tBatch Loss: 621.246799\tLearning Rate (w_theta): 0.001000\t TIME:4939.8s\n",
      "\t\t\t\tDisc: 0.375961\t\tSym: 13.129565\t\tSpars: 607.741272\n",
      "\t TVw: 0.190284 | TVb: -2.039529 | GSw: -0.234967 | GSb: 0.065004 | TSUw: 0.464908 | TSUb: 0.034821\n",
      "\n",
      "Train Epoch: 2237 [4000/8000 (50%)]\tBatch Loss: 585.342512\tLearning Rate (w_theta): 0.001000\t TIME:4941.4s\n",
      "\t\t\t\tDisc: 0.365918\t\tSym: 11.093904\t\tSpars: 573.882690\n",
      "\t TVw: 0.190415 | TVb: -2.039522 | GSw: -0.234967 | GSb: 0.065004 | TSUw: 0.464907 | TSUb: 0.034821\n",
      "Validating epoch 2237...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 595.7682092733457\n",
      "Average validation loss: 74.89667825281553\n",
      "Training epoch 2238...\n",
      "\n",
      "Train Epoch: 2238 [0/8000 (0%)]\tBatch Loss: 609.807424\tLearning Rate (w_theta): 0.001000\t TIME:4943.8s\n",
      "\t\t\t\tDisc: 0.356451\t\tSym: 12.118941\t\tSpars: 597.332031\n",
      "\t TVw: 0.190447 | TVb: -2.039514 | GSw: -0.234967 | GSb: 0.065003 | TSUw: 0.464907 | TSUb: 0.034821\n",
      "\n",
      "Train Epoch: 2238 [4000/8000 (50%)]\tBatch Loss: 580.161339\tLearning Rate (w_theta): 0.001000\t TIME:4945.4s\n",
      "\t\t\t\tDisc: 0.273691\t\tSym: 10.298475\t\tSpars: 569.589172\n",
      "\t TVw: 0.190247 | TVb: -2.039523 | GSw: -0.234967 | GSb: 0.065003 | TSUw: 0.464907 | TSUb: 0.034821\n",
      "Validating epoch 2238...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 603.2932548660262\n",
      "Average validation loss: 74.46278567817535\n",
      "Training epoch 2239...\n",
      "\n",
      "Train Epoch: 2239 [0/8000 (0%)]\tBatch Loss: 597.697145\tLearning Rate (w_theta): 0.001000\t TIME:4947.9s\n",
      "\t\t\t\tDisc: 0.328502\t\tSym: 11.465812\t\tSpars: 585.902832\n",
      "\t TVw: 0.190069 | TVb: -2.039528 | GSw: -0.234967 | GSb: 0.065003 | TSUw: 0.464907 | TSUb: 0.034821\n",
      "\n",
      "Train Epoch: 2239 [4000/8000 (50%)]\tBatch Loss: 640.027821\tLearning Rate (w_theta): 0.001000\t TIME:4949.4s\n",
      "\t\t\t\tDisc: 0.359659\t\tSym: 13.380626\t\tSpars: 626.287537\n",
      "\t TVw: 0.189962 | TVb: -2.039526 | GSw: -0.234967 | GSb: 0.065003 | TSUw: 0.464907 | TSUb: 0.034821\n",
      "Validating epoch 2239...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 603.5490545839348\n",
      "Average validation loss: 75.29747477951531\n",
      "Training epoch 2240...\n",
      "\n",
      "Train Epoch: 2240 [0/8000 (0%)]\tBatch Loss: 571.157972\tLearning Rate (w_theta): 0.001000\t TIME:4951.9s\n",
      "\t\t\t\tDisc: 0.339572\t\tSym: 11.321635\t\tSpars: 559.496765\n",
      "\t TVw: 0.189991 | TVb: -2.039520 | GSw: -0.234967 | GSb: 0.065003 | TSUw: 0.464907 | TSUb: 0.034821\n",
      "\n",
      "Train Epoch: 2240 [4000/8000 (50%)]\tBatch Loss: 599.116876\tLearning Rate (w_theta): 0.001000\t TIME:4953.5s\n",
      "\t\t\t\tDisc: 0.358381\t\tSym: 12.200512\t\tSpars: 586.557983\n",
      "\t TVw: 0.190220 | TVb: -2.039508 | GSw: -0.234967 | GSb: 0.065003 | TSUw: 0.464907 | TSUb: 0.034822\n",
      "Validating epoch 2240...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 593.6599915623111\n",
      "Average validation loss: 74.45170966505417\n",
      "Training epoch 2241...\n",
      "\n",
      "Train Epoch: 2241 [0/8000 (0%)]\tBatch Loss: 590.939082\tLearning Rate (w_theta): 0.001000\t TIME:4956.5s\n",
      "\t\t\t\tDisc: 0.334252\t\tSym: 11.265779\t\tSpars: 579.339050\n",
      "\t TVw: 0.190760 | TVb: -2.039488 | GSw: -0.234967 | GSb: 0.065003 | TSUw: 0.464907 | TSUb: 0.034822\n",
      "\n",
      "Train Epoch: 2241 [4000/8000 (50%)]\tBatch Loss: 612.156210\tLearning Rate (w_theta): 0.001000\t TIME:4958.1s\n",
      "\t\t\t\tDisc: 0.351226\t\tSym: 12.465140\t\tSpars: 599.339844\n",
      "\t TVw: 0.191399 | TVb: -2.039464 | GSw: -0.234967 | GSb: 0.065003 | TSUw: 0.464907 | TSUb: 0.034822\n",
      "Validating epoch 2241...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 591.9795926914961\n",
      "Average validation loss: 74.28482688729157\n",
      "Training epoch 2242...\n",
      "\n",
      "Train Epoch: 2242 [0/8000 (0%)]\tBatch Loss: 600.305686\tLearning Rate (w_theta): 0.001000\t TIME:4960.5s\n",
      "\t\t\t\tDisc: 0.346244\t\tSym: 12.051299\t\tSpars: 587.908142\n",
      "\t TVw: 0.192077 | TVb: -2.039440 | GSw: -0.234967 | GSb: 0.065003 | TSUw: 0.464906 | TSUb: 0.034822\n",
      "\n",
      "Train Epoch: 2242 [4000/8000 (50%)]\tBatch Loss: 586.231685\tLearning Rate (w_theta): 0.001000\t TIME:4962.1s\n",
      "\t\t\t\tDisc: 0.337066\t\tSym: 11.361172\t\tSpars: 574.533447\n",
      "\t TVw: 0.192695 | TVb: -2.039415 | GSw: -0.234967 | GSb: 0.065002 | TSUw: 0.464906 | TSUb: 0.034822\n",
      "Validating epoch 2242...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 591.5510452058073\n",
      "Average validation loss: 74.81686963552573\n",
      "Training epoch 2243...\n",
      "\n",
      "Train Epoch: 2243 [0/8000 (0%)]\tBatch Loss: 564.024845\tLearning Rate (w_theta): 0.001000\t TIME:4964.5s\n",
      "\t\t\t\tDisc: 0.341491\t\tSym: 10.240911\t\tSpars: 553.442444\n",
      "\t TVw: 0.193255 | TVb: -2.039394 | GSw: -0.234967 | GSb: 0.065002 | TSUw: 0.464906 | TSUb: 0.034822\n",
      "\n",
      "Train Epoch: 2243 [4000/8000 (50%)]\tBatch Loss: 596.443141\tLearning Rate (w_theta): 0.001000\t TIME:4966.1s\n",
      "\t\t\t\tDisc: 0.358440\t\tSym: 12.041061\t\tSpars: 584.043640\n",
      "\t TVw: 0.193689 | TVb: -2.039379 | GSw: -0.234968 | GSb: 0.065002 | TSUw: 0.464906 | TSUb: 0.034822\n",
      "Validating epoch 2243...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 588.1470954577727\n",
      "Average validation loss: 74.12532437071889\n",
      "Training epoch 2244...\n",
      "\n",
      "Train Epoch: 2244 [0/8000 (0%)]\tBatch Loss: 574.491965\tLearning Rate (w_theta): 0.001000\t TIME:4968.9s\n",
      "\t\t\t\tDisc: 0.296163\t\tSym: 10.770876\t\tSpars: 563.424927\n",
      "\t TVw: 0.194052 | TVb: -2.039366 | GSw: -0.234968 | GSb: 0.065002 | TSUw: 0.464906 | TSUb: 0.034822\n",
      "\n",
      "Train Epoch: 2244 [4000/8000 (50%)]\tBatch Loss: 581.889021\tLearning Rate (w_theta): 0.001000\t TIME:4970.5s\n",
      "\t\t\t\tDisc: 0.337604\t\tSym: 11.495997\t\tSpars: 570.055420\n",
      "\t TVw: 0.194379 | TVb: -2.039353 | GSw: -0.234968 | GSb: 0.065002 | TSUw: 0.464906 | TSUb: 0.034822\n",
      "Validating epoch 2244...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 585.6078092572255\n",
      "Average validation loss: 74.77853487819134\n",
      "Training epoch 2245...\n",
      "\n",
      "Train Epoch: 2245 [0/8000 (0%)]\tBatch Loss: 561.317240\tLearning Rate (w_theta): 0.001000\t TIME:4972.9s\n",
      "\t\t\t\tDisc: 0.342322\t\tSym: 9.920841\t\tSpars: 551.054077\n",
      "\t TVw: 0.194704 | TVb: -2.039340 | GSw: -0.234968 | GSb: 0.065002 | TSUw: 0.464906 | TSUb: 0.034822\n",
      "\n",
      "Train Epoch: 2245 [4000/8000 (50%)]\tBatch Loss: 596.168586\tLearning Rate (w_theta): 0.001000\t TIME:4974.4s\n",
      "\t\t\t\tDisc: 0.327079\t\tSym: 11.519608\t\tSpars: 584.321899\n",
      "\t TVw: 0.194934 | TVb: -2.039334 | GSw: -0.234968 | GSb: 0.065002 | TSUw: 0.464906 | TSUb: 0.034822\n",
      "Validating epoch 2245...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 591.3643840737288\n",
      "Average validation loss: 74.42966846568706\n",
      "Training epoch 2246...\n",
      "\n",
      "Train Epoch: 2246 [0/8000 (0%)]\tBatch Loss: 569.430779\tLearning Rate (w_theta): 0.001000\t TIME:4976.9s\n",
      "\t\t\t\tDisc: 0.337228\t\tSym: 10.977950\t\tSpars: 558.115601\n",
      "\t TVw: 0.195126 | TVb: -2.039330 | GSw: -0.234968 | GSb: 0.065002 | TSUw: 0.464905 | TSUb: 0.034822\n",
      "\n",
      "Train Epoch: 2246 [4000/8000 (50%)]\tBatch Loss: 614.259728\tLearning Rate (w_theta): 0.001000\t TIME:4978.5s\n",
      "\t\t\t\tDisc: 0.339742\t\tSym: 12.586490\t\tSpars: 601.333496\n",
      "\t TVw: 0.195275 | TVb: -2.039328 | GSw: -0.234968 | GSb: 0.065001 | TSUw: 0.464905 | TSUb: 0.034823\n",
      "Validating epoch 2246...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 587.3860179763259\n",
      "Average validation loss: 74.97427190928707\n",
      "Training epoch 2247...\n",
      "\n",
      "Train Epoch: 2247 [0/8000 (0%)]\tBatch Loss: 563.843904\tLearning Rate (w_theta): 0.001000\t TIME:4980.9s\n",
      "\t\t\t\tDisc: 0.365251\t\tSym: 10.300797\t\tSpars: 553.177856\n",
      "\t TVw: 0.195497 | TVb: -2.039318 | GSw: -0.234968 | GSb: 0.065001 | TSUw: 0.464905 | TSUb: 0.034823\n",
      "\n",
      "Train Epoch: 2247 [4000/8000 (50%)]\tBatch Loss: 579.128043\tLearning Rate (w_theta): 0.001000\t TIME:4982.5s\n",
      "\t\t\t\tDisc: 0.344308\t\tSym: 10.925886\t\tSpars: 567.857849\n",
      "\t TVw: 0.195834 | TVb: -2.039301 | GSw: -0.234968 | GSb: 0.065001 | TSUw: 0.464905 | TSUb: 0.034823\n",
      "Validating epoch 2247...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 585.6982953762906\n",
      "Average validation loss: 76.01786711189226\n",
      "Training epoch 2248...\n",
      "\n",
      "Train Epoch: 2248 [0/8000 (0%)]\tBatch Loss: 617.473257\tLearning Rate (w_theta): 0.001000\t TIME:4984.9s\n",
      "\t\t\t\tDisc: 0.307547\t\tSym: 12.332397\t\tSpars: 604.833313\n",
      "\t TVw: 0.196277 | TVb: -2.039280 | GSw: -0.234968 | GSb: 0.065001 | TSUw: 0.464905 | TSUb: 0.034823\n",
      "\n",
      "Train Epoch: 2248 [4000/8000 (50%)]\tBatch Loss: 564.647679\tLearning Rate (w_theta): 0.001000\t TIME:4986.5s\n",
      "\t\t\t\tDisc: 0.343092\t\tSym: 10.646201\t\tSpars: 553.658386\n",
      "\t TVw: 0.196510 | TVb: -2.039274 | GSw: -0.234968 | GSb: 0.065001 | TSUw: 0.464905 | TSUb: 0.034823\n",
      "Validating epoch 2248...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 589.37185711481\n",
      "Average validation loss: 75.01332490110772\n",
      "Training epoch 2249...\n",
      "\n",
      "Train Epoch: 2249 [0/8000 (0%)]\tBatch Loss: 565.822642\tLearning Rate (w_theta): 0.001000\t TIME:4988.9s\n",
      "\t\t\t\tDisc: 0.309117\t\tSym: 11.000341\t\tSpars: 554.513184\n",
      "\t TVw: 0.196716 | TVb: -2.039267 | GSw: -0.234968 | GSb: 0.065001 | TSUw: 0.464905 | TSUb: 0.034823\n",
      "\n",
      "Train Epoch: 2249 [4000/8000 (50%)]\tBatch Loss: 607.303448\tLearning Rate (w_theta): 0.001000\t TIME:4990.5s\n",
      "\t\t\t\tDisc: 0.349063\t\tSym: 12.489968\t\tSpars: 594.464417\n",
      "\t TVw: 0.196990 | TVb: -2.039258 | GSw: -0.234968 | GSb: 0.065001 | TSUw: 0.464905 | TSUb: 0.034823\n",
      "Validating epoch 2249...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 581.2963793521963\n",
      "Average validation loss: 75.44351349731184\n",
      "Training epoch 2250...\n",
      "\n",
      "Train Epoch: 2250 [0/8000 (0%)]\tBatch Loss: 587.189556\tLearning Rate (w_theta): 0.001000\t TIME:4992.9s\n",
      "\t\t\t\tDisc: 0.352416\t\tSym: 11.719403\t\tSpars: 575.117737\n",
      "\t TVw: 0.197461 | TVb: -2.039239 | GSw: -0.234968 | GSb: 0.065001 | TSUw: 0.464904 | TSUb: 0.034823\n",
      "\n",
      "Train Epoch: 2250 [4000/8000 (50%)]\tBatch Loss: 589.432697\tLearning Rate (w_theta): 0.001000\t TIME:4994.5s\n",
      "\t\t\t\tDisc: 0.361884\t\tSym: 12.360059\t\tSpars: 576.710754\n",
      "\t TVw: 0.197942 | TVb: -2.039219 | GSw: -0.234968 | GSb: 0.065000 | TSUw: 0.464904 | TSUb: 0.034823\n",
      "Validating epoch 2250...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 578.9819567183076\n",
      "Average validation loss: 75.06447854915105\n",
      "Training epoch 2251...\n",
      "\n",
      "Train Epoch: 2251 [0/8000 (0%)]\tBatch Loss: 577.610016\tLearning Rate (w_theta): 0.001000\t TIME:4997.7s\n",
      "\t\t\t\tDisc: 0.359666\t\tSym: 11.699752\t\tSpars: 565.550598\n",
      "\t TVw: 0.198334 | TVb: -2.039197 | GSw: -0.234968 | GSb: 0.065000 | TSUw: 0.464904 | TSUb: 0.034823\n",
      "\n",
      "Train Epoch: 2251 [4000/8000 (50%)]\tBatch Loss: 592.249423\tLearning Rate (w_theta): 0.001000\t TIME:4999.2s\n",
      "\t\t\t\tDisc: 0.363409\t\tSym: 11.510343\t\tSpars: 580.375671\n",
      "\t TVw: 0.198705 | TVb: -2.039175 | GSw: -0.234968 | GSb: 0.065000 | TSUw: 0.464904 | TSUb: 0.034823\n",
      "Validating epoch 2251...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 577.1720851361362\n",
      "Average validation loss: 74.57137844100886\n",
      "Training epoch 2252...\n",
      "\n",
      "Train Epoch: 2252 [0/8000 (0%)]\tBatch Loss: 548.113740\tLearning Rate (w_theta): 0.001000\t TIME:5001.6s\n",
      "\t\t\t\tDisc: 0.309631\t\tSym: 10.112032\t\tSpars: 537.692078\n",
      "\t TVw: 0.198959 | TVb: -2.039159 | GSw: -0.234969 | GSb: 0.065000 | TSUw: 0.464904 | TSUb: 0.034824\n",
      "\n",
      "Train Epoch: 2252 [4000/8000 (50%)]\tBatch Loss: 567.375288\tLearning Rate (w_theta): 0.001000\t TIME:5003.2s\n",
      "\t\t\t\tDisc: 0.344441\t\tSym: 10.360681\t\tSpars: 556.670166\n",
      "\t TVw: 0.199236 | TVb: -2.039146 | GSw: -0.234969 | GSb: 0.065000 | TSUw: 0.464904 | TSUb: 0.034824\n",
      "Validating epoch 2252...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 576.3456332144821\n",
      "Average validation loss: 74.69569950178145\n",
      "Training epoch 2253...\n",
      "\n",
      "Train Epoch: 2253 [0/8000 (0%)]\tBatch Loss: 567.681767\tLearning Rate (w_theta): 0.001000\t TIME:5005.7s\n",
      "\t\t\t\tDisc: 0.360410\t\tSym: 10.898078\t\tSpars: 556.423279\n",
      "\t TVw: 0.199351 | TVb: -2.039142 | GSw: -0.234969 | GSb: 0.065000 | TSUw: 0.464904 | TSUb: 0.034824\n",
      "\n",
      "Train Epoch: 2253 [4000/8000 (50%)]\tBatch Loss: 587.436834\tLearning Rate (w_theta): 0.001000\t TIME:5007.3s\n",
      "\t\t\t\tDisc: 0.352706\t\tSym: 12.400106\t\tSpars: 574.684021\n",
      "\t TVw: 0.199427 | TVb: -2.039137 | GSw: -0.234969 | GSb: 0.065000 | TSUw: 0.464904 | TSUb: 0.034824\n",
      "Validating epoch 2253...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 575.9039965440095\n",
      "Average validation loss: 75.12767857191353\n",
      "Training epoch 2254...\n",
      "\n",
      "Train Epoch: 2254 [0/8000 (0%)]\tBatch Loss: 563.557999\tLearning Rate (w_theta): 0.001000\t TIME:5009.7s\n",
      "\t\t\t\tDisc: 0.320386\t\tSym: 10.695804\t\tSpars: 552.541809\n",
      "\t TVw: 0.199554 | TVb: -2.039129 | GSw: -0.234969 | GSb: 0.065000 | TSUw: 0.464904 | TSUb: 0.034824\n",
      "\n",
      "Train Epoch: 2254 [4000/8000 (50%)]\tBatch Loss: 577.854848\tLearning Rate (w_theta): 0.001000\t TIME:5011.3s\n",
      "\t\t\t\tDisc: 0.322083\t\tSym: 11.552236\t\tSpars: 565.980530\n",
      "\t TVw: 0.199655 | TVb: -2.039119 | GSw: -0.234969 | GSb: 0.065000 | TSUw: 0.464903 | TSUb: 0.034824\n",
      "Validating epoch 2254...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 578.5772256786667\n",
      "Average validation loss: 74.95646947185557\n",
      "Training epoch 2255...\n",
      "\n",
      "Train Epoch: 2255 [0/8000 (0%)]\tBatch Loss: 571.531257\tLearning Rate (w_theta): 0.001000\t TIME:5014.1s\n",
      "\t\t\t\tDisc: 0.352811\t\tSym: 10.791300\t\tSpars: 560.387146\n",
      "\t TVw: 0.199629 | TVb: -2.039116 | GSw: -0.234969 | GSb: 0.064999 | TSUw: 0.464903 | TSUb: 0.034824\n",
      "\n",
      "Train Epoch: 2255 [4000/8000 (50%)]\tBatch Loss: 553.567754\tLearning Rate (w_theta): 0.001000\t TIME:5015.7s\n",
      "\t\t\t\tDisc: 0.325627\t\tSym: 10.223328\t\tSpars: 543.018799\n",
      "\t TVw: 0.199640 | TVb: -2.039109 | GSw: -0.234969 | GSb: 0.064999 | TSUw: 0.464903 | TSUb: 0.034824\n",
      "Validating epoch 2255...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 579.8154654020547\n",
      "Average validation loss: 75.3145692403769\n",
      "Training epoch 2256...\n",
      "\n",
      "Train Epoch: 2256 [0/8000 (0%)]\tBatch Loss: 611.721358\tLearning Rate (w_theta): 0.001000\t TIME:5018.1s\n",
      "\t\t\t\tDisc: 0.341598\t\tSym: 12.707947\t\tSpars: 598.671814\n",
      "\t TVw: 0.199645 | TVb: -2.039106 | GSw: -0.234969 | GSb: 0.064999 | TSUw: 0.464903 | TSUb: 0.034824\n",
      "\n",
      "Train Epoch: 2256 [4000/8000 (50%)]\tBatch Loss: 571.851546\tLearning Rate (w_theta): 0.001000\t TIME:5019.7s\n",
      "\t\t\t\tDisc: 0.291313\t\tSym: 11.759574\t\tSpars: 559.800659\n",
      "\t TVw: 0.199607 | TVb: -2.039106 | GSw: -0.234969 | GSb: 0.064999 | TSUw: 0.464903 | TSUb: 0.034824\n",
      "Validating epoch 2256...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 580.8567135698682\n",
      "Average validation loss: 75.66355769500706\n",
      "Training epoch 2257...\n",
      "\n",
      "Train Epoch: 2257 [0/8000 (0%)]\tBatch Loss: 581.492601\tLearning Rate (w_theta): 0.001000\t TIME:5022.1s\n",
      "\t\t\t\tDisc: 0.351642\t\tSym: 12.788176\t\tSpars: 568.352783\n",
      "\t TVw: 0.199701 | TVb: -2.039097 | GSw: -0.234969 | GSb: 0.064999 | TSUw: 0.464903 | TSUb: 0.034824\n",
      "\n",
      "Train Epoch: 2257 [4000/8000 (50%)]\tBatch Loss: 556.811719\tLearning Rate (w_theta): 0.001000\t TIME:5023.6s\n",
      "\t\t\t\tDisc: 0.326534\t\tSym: 10.851884\t\tSpars: 545.633301\n",
      "\t TVw: 0.199990 | TVb: -2.039081 | GSw: -0.234969 | GSb: 0.064999 | TSUw: 0.464903 | TSUb: 0.034825\n",
      "Validating epoch 2257...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 573.1626009506458\n",
      "Average validation loss: 75.49686253579738\n",
      "Training epoch 2258...\n",
      "\n",
      "Train Epoch: 2258 [0/8000 (0%)]\tBatch Loss: 575.760152\tLearning Rate (w_theta): 0.001000\t TIME:5026.1s\n",
      "\t\t\t\tDisc: 0.396883\t\tSym: 11.953601\t\tSpars: 563.409668\n",
      "\t TVw: 0.200464 | TVb: -2.039062 | GSw: -0.234969 | GSb: 0.064999 | TSUw: 0.464903 | TSUb: 0.034825\n",
      "\n",
      "Train Epoch: 2258 [4000/8000 (50%)]\tBatch Loss: 578.089523\tLearning Rate (w_theta): 0.001000\t TIME:5027.7s\n",
      "\t\t\t\tDisc: 0.356475\t\tSym: 11.341263\t\tSpars: 566.391785\n",
      "\t TVw: 0.201040 | TVb: -2.039042 | GSw: -0.234969 | GSb: 0.064999 | TSUw: 0.464902 | TSUb: 0.034825\n",
      "Validating epoch 2258...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 571.193053942444\n",
      "Average validation loss: 75.42931750526296\n",
      "Training epoch 2259...\n",
      "\n",
      "Train Epoch: 2259 [0/8000 (0%)]\tBatch Loss: 577.412811\tLearning Rate (w_theta): 0.001000\t TIME:5030.1s\n",
      "\t\t\t\tDisc: 0.321345\t\tSym: 11.759740\t\tSpars: 565.331726\n",
      "\t TVw: 0.201598 | TVb: -2.039020 | GSw: -0.234969 | GSb: 0.064998 | TSUw: 0.464902 | TSUb: 0.034825\n",
      "\n",
      "Train Epoch: 2259 [4000/8000 (50%)]\tBatch Loss: 574.088403\tLearning Rate (w_theta): 0.001000\t TIME:5031.7s\n",
      "\t\t\t\tDisc: 0.347896\t\tSym: 11.281645\t\tSpars: 562.458862\n",
      "\t TVw: 0.202060 | TVb: -2.038998 | GSw: -0.234969 | GSb: 0.064998 | TSUw: 0.464902 | TSUb: 0.034825\n",
      "Validating epoch 2259...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 570.4339075493713\n",
      "Average validation loss: 75.39848431218178\n",
      "Training epoch 2260...\n",
      "\n",
      "Train Epoch: 2260 [0/8000 (0%)]\tBatch Loss: 534.254427\tLearning Rate (w_theta): 0.001000\t TIME:5034.1s\n",
      "\t\t\t\tDisc: 0.332565\t\tSym: 10.090930\t\tSpars: 523.830933\n",
      "\t TVw: 0.202495 | TVb: -2.038978 | GSw: -0.234970 | GSb: 0.064998 | TSUw: 0.464902 | TSUb: 0.034825\n",
      "\n",
      "Train Epoch: 2260 [4000/8000 (50%)]\tBatch Loss: 601.398513\tLearning Rate (w_theta): 0.001000\t TIME:5035.7s\n",
      "\t\t\t\tDisc: 0.354515\t\tSym: 13.107841\t\tSpars: 587.936157\n",
      "\t TVw: 0.202721 | TVb: -2.038965 | GSw: -0.234970 | GSb: 0.064998 | TSUw: 0.464902 | TSUb: 0.034825\n",
      "Validating epoch 2260...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 571.2459069537848\n",
      "Average validation loss: 75.39234357171188\n",
      "Training epoch 2261...\n",
      "\n",
      "Train Epoch: 2261 [0/8000 (0%)]\tBatch Loss: 575.885290\tLearning Rate (w_theta): 0.001000\t TIME:5038.8s\n",
      "\t\t\t\tDisc: 0.343830\t\tSym: 11.489702\t\tSpars: 564.051758\n",
      "\t TVw: 0.202784 | TVb: -2.038960 | GSw: -0.234970 | GSb: 0.064998 | TSUw: 0.464902 | TSUb: 0.034825\n",
      "\n",
      "Train Epoch: 2261 [4000/8000 (50%)]\tBatch Loss: 580.403569\tLearning Rate (w_theta): 0.001000\t TIME:5040.4s\n",
      "\t\t\t\tDisc: 0.351100\t\tSym: 11.661722\t\tSpars: 568.390747\n",
      "\t TVw: 0.202891 | TVb: -2.038949 | GSw: -0.234970 | GSb: 0.064998 | TSUw: 0.464902 | TSUb: 0.034825\n",
      "Validating epoch 2261...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 576.6047130522815\n",
      "Average validation loss: 76.1215394015272\n",
      "Training epoch 2262...\n",
      "\n",
      "Train Epoch: 2262 [0/8000 (0%)]\tBatch Loss: 581.887647\tLearning Rate (w_theta): 0.001000\t TIME:5042.9s\n",
      "\t\t\t\tDisc: 0.301874\t\tSym: 11.433856\t\tSpars: 570.151917\n",
      "\t TVw: 0.202859 | TVb: -2.038946 | GSw: -0.234970 | GSb: 0.064998 | TSUw: 0.464902 | TSUb: 0.034825\n",
      "\n",
      "Train Epoch: 2262 [4000/8000 (50%)]\tBatch Loss: 576.179722\tLearning Rate (w_theta): 0.001000\t TIME:5044.4s\n",
      "\t\t\t\tDisc: 0.312928\t\tSym: 10.817477\t\tSpars: 565.049316\n",
      "\t TVw: 0.202608 | TVb: -2.038953 | GSw: -0.234970 | GSb: 0.064998 | TSUw: 0.464902 | TSUb: 0.034825\n",
      "Validating epoch 2262...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 577.4472872821912\n",
      "Average validation loss: 76.0602764389482\n",
      "Training epoch 2263...\n",
      "\n",
      "Train Epoch: 2263 [0/8000 (0%)]\tBatch Loss: 572.923920\tLearning Rate (w_theta): 0.001000\t TIME:5046.8s\n",
      "\t\t\t\tDisc: 0.343783\t\tSym: 12.191587\t\tSpars: 560.388550\n",
      "\t TVw: 0.202524 | TVb: -2.038951 | GSw: -0.234970 | GSb: 0.064998 | TSUw: 0.464901 | TSUb: 0.034826\n",
      "\n",
      "Train Epoch: 2263 [4000/8000 (50%)]\tBatch Loss: 556.899897\tLearning Rate (w_theta): 0.001000\t TIME:5048.4s\n",
      "\t\t\t\tDisc: 0.343347\t\tSym: 11.241180\t\tSpars: 545.315369\n",
      "\t TVw: 0.202760 | TVb: -2.038937 | GSw: -0.234970 | GSb: 0.064997 | TSUw: 0.464901 | TSUb: 0.034826\n",
      "Validating epoch 2263...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 568.4167413500325\n",
      "Average validation loss: 75.96336700299081\n",
      "Training epoch 2264...\n",
      "\n",
      "Train Epoch: 2264 [0/8000 (0%)]\tBatch Loss: 562.369678\tLearning Rate (w_theta): 0.001000\t TIME:5050.8s\n",
      "\t\t\t\tDisc: 0.402379\t\tSym: 11.599441\t\tSpars: 550.367859\n",
      "\t TVw: 0.203205 | TVb: -2.038916 | GSw: -0.234970 | GSb: 0.064997 | TSUw: 0.464901 | TSUb: 0.034826\n",
      "\n",
      "Train Epoch: 2264 [4000/8000 (50%)]\tBatch Loss: 586.835032\tLearning Rate (w_theta): 0.001000\t TIME:5052.4s\n",
      "\t\t\t\tDisc: 0.403197\t\tSym: 12.740550\t\tSpars: 573.691284\n",
      "\t TVw: 0.203744 | TVb: -2.038893 | GSw: -0.234970 | GSb: 0.064997 | TSUw: 0.464901 | TSUb: 0.034826\n",
      "Validating epoch 2264...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 566.2135331507516\n",
      "Average validation loss: 75.95337633113651\n",
      "Training epoch 2265...\n",
      "\n",
      "Train Epoch: 2265 [0/8000 (0%)]\tBatch Loss: 554.084793\tLearning Rate (w_theta): 0.001000\t TIME:5054.9s\n",
      "\t\t\t\tDisc: 0.335955\t\tSym: 11.475888\t\tSpars: 542.272949\n",
      "\t TVw: 0.204301 | TVb: -2.038868 | GSw: -0.234970 | GSb: 0.064997 | TSUw: 0.464901 | TSUb: 0.034826\n",
      "\n",
      "Train Epoch: 2265 [4000/8000 (50%)]\tBatch Loss: 585.357096\tLearning Rate (w_theta): 0.001000\t TIME:5056.5s\n",
      "\t\t\t\tDisc: 0.337245\t\tSym: 12.209914\t\tSpars: 572.809937\n",
      "\t TVw: 0.204907 | TVb: -2.038843 | GSw: -0.234970 | GSb: 0.064997 | TSUw: 0.464901 | TSUb: 0.034826\n",
      "Validating epoch 2265...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 563.8387295140207\n",
      "Average validation loss: 75.99034781678242\n",
      "Training epoch 2266...\n",
      "\n",
      "Train Epoch: 2266 [0/8000 (0%)]\tBatch Loss: 568.615680\tLearning Rate (w_theta): 0.001000\t TIME:5059.3s\n",
      "\t\t\t\tDisc: 0.342160\t\tSym: 11.291281\t\tSpars: 556.982239\n",
      "\t TVw: 0.205410 | TVb: -2.038817 | GSw: -0.234970 | GSb: 0.064997 | TSUw: 0.464901 | TSUb: 0.034826\n",
      "\n",
      "Train Epoch: 2266 [4000/8000 (50%)]\tBatch Loss: 551.285109\tLearning Rate (w_theta): 0.001000\t TIME:5060.9s\n",
      "\t\t\t\tDisc: 0.351195\t\tSym: 10.681533\t\tSpars: 540.252380\n",
      "\t TVw: 0.205858 | TVb: -2.038793 | GSw: -0.234970 | GSb: 0.064997 | TSUw: 0.464901 | TSUb: 0.034826\n",
      "Validating epoch 2266...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 563.5783654536525\n",
      "Average validation loss: 75.87523766620808\n",
      "Training epoch 2267...\n",
      "\n",
      "Train Epoch: 2267 [0/8000 (0%)]\tBatch Loss: 541.243608\tLearning Rate (w_theta): 0.001000\t TIME:5063.3s\n",
      "\t\t\t\tDisc: 0.336960\t\tSym: 10.356721\t\tSpars: 530.549927\n",
      "\t TVw: 0.206042 | TVb: -2.038778 | GSw: -0.234970 | GSb: 0.064997 | TSUw: 0.464900 | TSUb: 0.034826\n",
      "\n",
      "Train Epoch: 2267 [4000/8000 (50%)]\tBatch Loss: 590.699571\tLearning Rate (w_theta): 0.001000\t TIME:5064.9s\n",
      "\t\t\t\tDisc: 0.355803\t\tSym: 12.483844\t\tSpars: 577.859924\n",
      "\t TVw: 0.206129 | TVb: -2.038762 | GSw: -0.234970 | GSb: 0.064996 | TSUw: 0.464900 | TSUb: 0.034826\n",
      "Validating epoch 2267...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 568.5970426884768\n",
      "Average validation loss: 77.52415182061094\n",
      "Training epoch 2268...\n",
      "\n",
      "Train Epoch: 2268 [0/8000 (0%)]\tBatch Loss: 568.925587\tLearning Rate (w_theta): 0.001000\t TIME:5067.3s\n",
      "\t\t\t\tDisc: 0.297320\t\tSym: 10.989106\t\tSpars: 557.639160\n",
      "\t TVw: 0.206012 | TVb: -2.038761 | GSw: -0.234970 | GSb: 0.064996 | TSUw: 0.464900 | TSUb: 0.034826\n",
      "\n",
      "Train Epoch: 2268 [4000/8000 (50%)]\tBatch Loss: 562.251328\tLearning Rate (w_theta): 0.001000\t TIME:5068.9s\n",
      "\t\t\t\tDisc: 0.302891\t\tSym: 11.358898\t\tSpars: 550.589539\n",
      "\t TVw: 0.205546 | TVb: -2.038781 | GSw: -0.234971 | GSb: 0.064996 | TSUw: 0.464900 | TSUb: 0.034827\n",
      "Validating epoch 2268...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 587.2180388890644\n",
      "Average validation loss: 77.1664462048797\n",
      "Training epoch 2269...\n",
      "\n",
      "Train Epoch: 2269 [0/8000 (0%)]\tBatch Loss: 594.946079\tLearning Rate (w_theta): 0.001000\t TIME:5071.3s\n",
      "\t\t\t\tDisc: 0.309937\t\tSym: 13.124911\t\tSpars: 581.511230\n",
      "\t TVw: 0.205183 | TVb: -2.038793 | GSw: -0.234971 | GSb: 0.064996 | TSUw: 0.464900 | TSUb: 0.034827\n",
      "\n",
      "Train Epoch: 2269 [4000/8000 (50%)]\tBatch Loss: 563.146631\tLearning Rate (w_theta): 0.001000\t TIME:5072.9s\n",
      "\t\t\t\tDisc: 0.344961\t\tSym: 10.899937\t\tSpars: 551.901733\n",
      "\t TVw: 0.205115 | TVb: -2.038795 | GSw: -0.234971 | GSb: 0.064996 | TSUw: 0.464900 | TSUb: 0.034827\n",
      "Validating epoch 2269...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 572.0057056904283\n",
      "Average validation loss: 77.53072408071415\n",
      "Training epoch 2270...\n",
      "\n",
      "Train Epoch: 2270 [0/8000 (0%)]\tBatch Loss: 557.492734\tLearning Rate (w_theta): 0.001000\t TIME:5075.4s\n",
      "\t\t\t\tDisc: 0.327867\t\tSym: 10.898814\t\tSpars: 546.266052\n",
      "\t TVw: 0.205210 | TVb: -2.038794 | GSw: -0.234971 | GSb: 0.064996 | TSUw: 0.464900 | TSUb: 0.034827\n",
      "\n",
      "Train Epoch: 2270 [4000/8000 (50%)]\tBatch Loss: 545.603853\tLearning Rate (w_theta): 0.001000\t TIME:5077.0s\n",
      "\t\t\t\tDisc: 0.360201\t\tSym: 11.133301\t\tSpars: 534.110352\n",
      "\t TVw: 0.205666 | TVb: -2.038777 | GSw: -0.234971 | GSb: 0.064996 | TSUw: 0.464900 | TSUb: 0.034827\n",
      "Validating epoch 2270...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 566.5126643770459\n",
      "Average validation loss: 77.16432491289058\n",
      "Training epoch 2271...\n",
      "\n",
      "Train Epoch: 2271 [0/8000 (0%)]\tBatch Loss: 549.036808\tLearning Rate (w_theta): 0.001000\t TIME:5080.1s\n",
      "\t\t\t\tDisc: 0.299981\t\tSym: 11.140574\t\tSpars: 537.596252\n",
      "\t TVw: 0.206410 | TVb: -2.038746 | GSw: -0.234971 | GSb: 0.064996 | TSUw: 0.464899 | TSUb: 0.034827\n",
      "\n",
      "Train Epoch: 2271 [4000/8000 (50%)]\tBatch Loss: 578.198578\tLearning Rate (w_theta): 0.001000\t TIME:5081.7s\n",
      "\t\t\t\tDisc: 0.358536\t\tSym: 11.952957\t\tSpars: 565.887085\n",
      "\t TVw: 0.207363 | TVb: -2.038707 | GSw: -0.234971 | GSb: 0.064995 | TSUw: 0.464899 | TSUb: 0.034827\n",
      "Validating epoch 2271...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 564.9933002452236\n",
      "Average validation loss: 77.9128816595508\n",
      "Training epoch 2272...\n",
      "\n",
      "Train Epoch: 2272 [0/8000 (0%)]\tBatch Loss: 579.019262\tLearning Rate (w_theta): 0.001000\t TIME:5084.1s\n",
      "\t\t\t\tDisc: 0.288067\t\tSym: 11.912958\t\tSpars: 566.818237\n",
      "\t TVw: 0.208161 | TVb: -2.038676 | GSw: -0.234971 | GSb: 0.064995 | TSUw: 0.464899 | TSUb: 0.034827\n",
      "\n",
      "Train Epoch: 2272 [4000/8000 (50%)]\tBatch Loss: 562.243352\tLearning Rate (w_theta): 0.001000\t TIME:5085.7s\n",
      "\t\t\t\tDisc: 0.331277\t\tSym: 11.028713\t\tSpars: 550.883362\n",
      "\t TVw: 0.208689 | TVb: -2.038652 | GSw: -0.234971 | GSb: 0.064995 | TSUw: 0.464899 | TSUb: 0.034827\n",
      "Validating epoch 2272...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 562.9038461707405\n",
      "Average validation loss: 78.01974528111323\n",
      "Training epoch 2273...\n",
      "\n",
      "Train Epoch: 2273 [0/8000 (0%)]\tBatch Loss: 547.330162\tLearning Rate (w_theta): 0.001000\t TIME:5088.1s\n",
      "\t\t\t\tDisc: 0.311567\t\tSym: 10.272745\t\tSpars: 536.745850\n",
      "\t TVw: 0.209242 | TVb: -2.038630 | GSw: -0.234971 | GSb: 0.064995 | TSUw: 0.464899 | TSUb: 0.034828\n",
      "\n",
      "Train Epoch: 2273 [4000/8000 (50%)]\tBatch Loss: 555.620157\tLearning Rate (w_theta): 0.001000\t TIME:5089.7s\n",
      "\t\t\t\tDisc: 0.319323\t\tSym: 11.061210\t\tSpars: 544.239624\n",
      "\t TVw: 0.209778 | TVb: -2.038609 | GSw: -0.234971 | GSb: 0.064995 | TSUw: 0.464899 | TSUb: 0.034828\n",
      "Validating epoch 2273...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 560.3225284235189\n",
      "Average validation loss: 77.43786462708569\n",
      "Training epoch 2274...\n",
      "\n",
      "Train Epoch: 2274 [0/8000 (0%)]\tBatch Loss: 548.125892\tLearning Rate (w_theta): 0.001000\t TIME:5092.1s\n",
      "\t\t\t\tDisc: 0.332622\t\tSym: 11.418087\t\tSpars: 536.375183\n",
      "\t TVw: 0.210195 | TVb: -2.038590 | GSw: -0.234971 | GSb: 0.064995 | TSUw: 0.464899 | TSUb: 0.034828\n",
      "\n",
      "Train Epoch: 2274 [4000/8000 (50%)]\tBatch Loss: 554.849603\tLearning Rate (w_theta): 0.001000\t TIME:5093.7s\n",
      "\t\t\t\tDisc: 0.389202\t\tSym: 11.139722\t\tSpars: 543.320679\n",
      "\t TVw: 0.210499 | TVb: -2.038572 | GSw: -0.234971 | GSb: 0.064995 | TSUw: 0.464899 | TSUb: 0.034828\n",
      "Validating epoch 2274...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 558.2145708951239\n",
      "Average validation loss: 77.19815213460193\n",
      "Training epoch 2275...\n",
      "\n",
      "Train Epoch: 2275 [0/8000 (0%)]\tBatch Loss: 552.876653\tLearning Rate (w_theta): 0.001000\t TIME:5096.1s\n",
      "\t\t\t\tDisc: 0.359459\t\tSym: 10.617108\t\tSpars: 541.900085\n",
      "\t TVw: 0.210802 | TVb: -2.038552 | GSw: -0.234971 | GSb: 0.064995 | TSUw: 0.464899 | TSUb: 0.034828\n",
      "\n",
      "Train Epoch: 2275 [4000/8000 (50%)]\tBatch Loss: 541.434202\tLearning Rate (w_theta): 0.001000\t TIME:5097.7s\n",
      "\t\t\t\tDisc: 0.314254\t\tSym: 11.033889\t\tSpars: 530.086060\n",
      "\t TVw: 0.211046 | TVb: -2.038538 | GSw: -0.234971 | GSb: 0.064995 | TSUw: 0.464898 | TSUb: 0.034828\n",
      "Validating epoch 2275...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 559.2528257882187\n",
      "Average validation loss: 78.24182584516535\n",
      "Training epoch 2276...\n",
      "\n",
      "Train Epoch: 2276 [0/8000 (0%)]\tBatch Loss: 559.648473\tLearning Rate (w_theta): 0.001000\t TIME:5100.1s\n",
      "\t\t\t\tDisc: 0.336910\t\tSym: 11.686747\t\tSpars: 547.624817\n",
      "\t TVw: 0.211075 | TVb: -2.038537 | GSw: -0.234971 | GSb: 0.064994 | TSUw: 0.464898 | TSUb: 0.034828\n",
      "\n",
      "Train Epoch: 2276 [4000/8000 (50%)]\tBatch Loss: 568.197539\tLearning Rate (w_theta): 0.001000\t TIME:5101.7s\n",
      "\t\t\t\tDisc: 0.371464\t\tSym: 11.786036\t\tSpars: 556.040039\n",
      "\t TVw: 0.211123 | TVb: -2.038532 | GSw: -0.234971 | GSb: 0.064994 | TSUw: 0.464898 | TSUb: 0.034828\n",
      "Validating epoch 2276...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 555.0508989568434\n",
      "Average validation loss: 77.47577711156745\n",
      "Training epoch 2277...\n",
      "\n",
      "Train Epoch: 2277 [0/8000 (0%)]\tBatch Loss: 557.227813\tLearning Rate (w_theta): 0.001000\t TIME:5104.1s\n",
      "\t\t\t\tDisc: 0.389853\t\tSym: 11.495858\t\tSpars: 545.342102\n",
      "\t TVw: 0.211311 | TVb: -2.038521 | GSw: -0.234972 | GSb: 0.064994 | TSUw: 0.464898 | TSUb: 0.034828\n",
      "\n",
      "Train Epoch: 2277 [4000/8000 (50%)]\tBatch Loss: 562.668453\tLearning Rate (w_theta): 0.001000\t TIME:5105.7s\n",
      "\t\t\t\tDisc: 0.379086\t\tSym: 12.430724\t\tSpars: 549.858643\n",
      "\t TVw: 0.211518 | TVb: -2.038504 | GSw: -0.234972 | GSb: 0.064994 | TSUw: 0.464898 | TSUb: 0.034828\n",
      "Validating epoch 2277...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 553.0828189695906\n",
      "Average validation loss: 78.21028060209508\n",
      "Training epoch 2278...\n",
      "\n",
      "Train Epoch: 2278 [0/8000 (0%)]\tBatch Loss: 534.701795\tLearning Rate (w_theta): 0.001000\t TIME:5108.6s\n",
      "\t\t\t\tDisc: 0.329487\t\tSym: 10.537347\t\tSpars: 523.834961\n",
      "\t TVw: 0.211782 | TVb: -2.038488 | GSw: -0.234972 | GSb: 0.064994 | TSUw: 0.464898 | TSUb: 0.034829\n",
      "\n",
      "Train Epoch: 2278 [4000/8000 (50%)]\tBatch Loss: 573.885684\tLearning Rate (w_theta): 0.001000\t TIME:5110.1s\n",
      "\t\t\t\tDisc: 0.368567\t\tSym: 12.550504\t\tSpars: 560.966614\n",
      "\t TVw: 0.211987 | TVb: -2.038474 | GSw: -0.234972 | GSb: 0.064994 | TSUw: 0.464898 | TSUb: 0.034829\n",
      "Validating epoch 2278...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 551.2653288179235\n",
      "Average validation loss: 77.7933745303343\n",
      "Training epoch 2279...\n",
      "\n",
      "Train Epoch: 2279 [0/8000 (0%)]\tBatch Loss: 566.106571\tLearning Rate (w_theta): 0.001000\t TIME:5112.5s\n",
      "\t\t\t\tDisc: 0.375230\t\tSym: 11.607196\t\tSpars: 554.124146\n",
      "\t TVw: 0.212283 | TVb: -2.038453 | GSw: -0.234972 | GSb: 0.064994 | TSUw: 0.464898 | TSUb: 0.034829\n",
      "\n",
      "Train Epoch: 2279 [4000/8000 (50%)]\tBatch Loss: 563.200523\tLearning Rate (w_theta): 0.001000\t TIME:5114.1s\n",
      "\t\t\t\tDisc: 0.315707\t\tSym: 11.665822\t\tSpars: 551.218994\n",
      "\t TVw: 0.212605 | TVb: -2.038432 | GSw: -0.234972 | GSb: 0.064994 | TSUw: 0.464897 | TSUb: 0.034829\n",
      "Validating epoch 2279...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 551.4411532971992\n",
      "Average validation loss: 78.16498233269292\n",
      "Training epoch 2280...\n",
      "\n",
      "Train Epoch: 2280 [0/8000 (0%)]\tBatch Loss: 566.116812\tLearning Rate (w_theta): 0.001000\t TIME:5116.6s\n",
      "\t\t\t\tDisc: 0.345057\t\tSym: 12.686733\t\tSpars: 553.085022\n",
      "\t TVw: 0.212760 | TVb: -2.038413 | GSw: -0.234972 | GSb: 0.064993 | TSUw: 0.464897 | TSUb: 0.034829\n",
      "\n",
      "Train Epoch: 2280 [4000/8000 (50%)]\tBatch Loss: 530.766004\tLearning Rate (w_theta): 0.001000\t TIME:5118.2s\n",
      "\t\t\t\tDisc: 0.336437\t\tSym: 10.341920\t\tSpars: 520.087646\n",
      "\t TVw: 0.212898 | TVb: -2.038396 | GSw: -0.234972 | GSb: 0.064993 | TSUw: 0.464897 | TSUb: 0.034829\n",
      "Validating epoch 2280...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 549.2923191113276\n",
      "Average validation loss: 78.61417527139312\n",
      "Training epoch 2281...\n",
      "\n",
      "Train Epoch: 2281 [0/8000 (0%)]\tBatch Loss: 559.553651\tLearning Rate (w_theta): 0.001000\t TIME:5121.4s\n",
      "\t\t\t\tDisc: 0.351369\t\tSym: 11.840710\t\tSpars: 547.361572\n",
      "\t TVw: 0.212976 | TVb: -2.038383 | GSw: -0.234972 | GSb: 0.064993 | TSUw: 0.464897 | TSUb: 0.034829\n",
      "\n",
      "Train Epoch: 2281 [4000/8000 (50%)]\tBatch Loss: 559.079323\tLearning Rate (w_theta): 0.001000\t TIME:5123.0s\n",
      "\t\t\t\tDisc: 0.345990\t\tSym: 12.154231\t\tSpars: 546.579102\n",
      "\t TVw: 0.213067 | TVb: -2.038374 | GSw: -0.234972 | GSb: 0.064993 | TSUw: 0.464897 | TSUb: 0.034829\n",
      "Validating epoch 2281...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 549.1285268548787\n",
      "Average validation loss: 77.87869797138124\n",
      "Training epoch 2282...\n",
      "\n",
      "Train Epoch: 2282 [0/8000 (0%)]\tBatch Loss: 568.370592\tLearning Rate (w_theta): 0.001000\t TIME:5125.4s\n",
      "\t\t\t\tDisc: 0.370463\t\tSym: 12.313239\t\tSpars: 555.686890\n",
      "\t TVw: 0.213191 | TVb: -2.038359 | GSw: -0.234972 | GSb: 0.064993 | TSUw: 0.464897 | TSUb: 0.034829\n",
      "\n",
      "Train Epoch: 2282 [4000/8000 (50%)]\tBatch Loss: 558.725229\tLearning Rate (w_theta): 0.001000\t TIME:5127.0s\n",
      "\t\t\t\tDisc: 0.345176\t\tSym: 11.902148\t\tSpars: 546.477905\n",
      "\t TVw: 0.213311 | TVb: -2.038344 | GSw: -0.234972 | GSb: 0.064993 | TSUw: 0.464897 | TSUb: 0.034829\n",
      "Validating epoch 2282...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 548.883821116883\n",
      "Average validation loss: 79.23330267377263\n",
      "Training epoch 2283...\n",
      "\n",
      "Train Epoch: 2283 [0/8000 (0%)]\tBatch Loss: 542.195804\tLearning Rate (w_theta): 0.001000\t TIME:5129.4s\n",
      "\t\t\t\tDisc: 0.307025\t\tSym: 11.205796\t\tSpars: 530.682983\n",
      "\t TVw: 0.213408 | TVb: -2.038331 | GSw: -0.234972 | GSb: 0.064993 | TSUw: 0.464897 | TSUb: 0.034829\n",
      "\n",
      "Train Epoch: 2283 [4000/8000 (50%)]\tBatch Loss: 542.525328\tLearning Rate (w_theta): 0.001000\t TIME:5131.0s\n",
      "\t\t\t\tDisc: 0.372706\t\tSym: 10.781651\t\tSpars: 531.370972\n",
      "\t TVw: 0.213541 | TVb: -2.038316 | GSw: -0.234972 | GSb: 0.064993 | TSUw: 0.464897 | TSUb: 0.034830\n",
      "Validating epoch 2283...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 546.448784091985\n",
      "Average validation loss: 78.71851056022714\n",
      "Training epoch 2284...\n",
      "\n",
      "Train Epoch: 2284 [0/8000 (0%)]\tBatch Loss: 571.741037\tLearning Rate (w_theta): 0.001000\t TIME:5133.4s\n",
      "\t\t\t\tDisc: 0.399756\t\tSym: 12.532931\t\tSpars: 558.808350\n",
      "\t TVw: 0.213748 | TVb: -2.038296 | GSw: -0.234972 | GSb: 0.064993 | TSUw: 0.464896 | TSUb: 0.034830\n",
      "\n",
      "Train Epoch: 2284 [4000/8000 (50%)]\tBatch Loss: 543.288334\tLearning Rate (w_theta): 0.001000\t TIME:5135.0s\n",
      "\t\t\t\tDisc: 0.337775\t\tSym: 10.469725\t\tSpars: 532.480835\n",
      "\t TVw: 0.213872 | TVb: -2.038284 | GSw: -0.234972 | GSb: 0.064992 | TSUw: 0.464896 | TSUb: 0.034830\n",
      "Validating epoch 2284...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 548.1482506688272\n",
      "Average validation loss: 78.99511415825629\n",
      "Training epoch 2285...\n",
      "\n",
      "Train Epoch: 2285 [0/8000 (0%)]\tBatch Loss: 550.746018\tLearning Rate (w_theta): 0.001000\t TIME:5137.4s\n",
      "\t\t\t\tDisc: 0.349301\t\tSym: 11.043262\t\tSpars: 539.353455\n",
      "\t TVw: 0.213967 | TVb: -2.038271 | GSw: -0.234972 | GSb: 0.064992 | TSUw: 0.464896 | TSUb: 0.034830\n",
      "\n",
      "Train Epoch: 2285 [4000/8000 (50%)]\tBatch Loss: 570.821129\tLearning Rate (w_theta): 0.001000\t TIME:5139.0s\n",
      "\t\t\t\tDisc: 0.357106\t\tSym: 12.011569\t\tSpars: 558.452454\n",
      "\t TVw: 0.214123 | TVb: -2.038255 | GSw: -0.234973 | GSb: 0.064992 | TSUw: 0.464896 | TSUb: 0.034830\n",
      "Validating epoch 2285...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 551.6781508948952\n",
      "Average validation loss: 79.45227216831857\n",
      "Training epoch 2286...\n",
      "\n",
      "Train Epoch: 2286 [0/8000 (0%)]\tBatch Loss: 527.428867\tLearning Rate (w_theta): 0.001000\t TIME:5141.4s\n",
      "\t\t\t\tDisc: 0.334287\t\tSym: 10.866858\t\tSpars: 516.227722\n",
      "\t TVw: 0.214093 | TVb: -2.038254 | GSw: -0.234973 | GSb: 0.064992 | TSUw: 0.464896 | TSUb: 0.034830\n",
      "\n",
      "Train Epoch: 2286 [4000/8000 (50%)]\tBatch Loss: 544.563976\tLearning Rate (w_theta): 0.001000\t TIME:5143.0s\n",
      "\t\t\t\tDisc: 0.325315\t\tSym: 11.387953\t\tSpars: 532.850708\n",
      "\t TVw: 0.214060 | TVb: -2.038254 | GSw: -0.234973 | GSb: 0.064992 | TSUw: 0.464896 | TSUb: 0.034830\n",
      "Validating epoch 2286...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 545.8012142000341\n",
      "Average validation loss: 79.44728786489031\n",
      "Training epoch 2287...\n",
      "\n",
      "Train Epoch: 2287 [0/8000 (0%)]\tBatch Loss: 529.972051\tLearning Rate (w_theta): 0.001000\t TIME:5145.4s\n",
      "\t\t\t\tDisc: 0.306505\t\tSym: 10.943073\t\tSpars: 518.722473\n",
      "\t TVw: 0.214282 | TVb: -2.038240 | GSw: -0.234973 | GSb: 0.064992 | TSUw: 0.464896 | TSUb: 0.034830\n",
      "\n",
      "Train Epoch: 2287 [4000/8000 (50%)]\tBatch Loss: 565.661413\tLearning Rate (w_theta): 0.001000\t TIME:5147.0s\n",
      "\t\t\t\tDisc: 0.403500\t\tSym: 11.896219\t\tSpars: 553.361694\n",
      "\t TVw: 0.214617 | TVb: -2.038221 | GSw: -0.234973 | GSb: 0.064992 | TSUw: 0.464896 | TSUb: 0.034830\n",
      "Validating epoch 2287...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 542.8627630423139\n",
      "Average validation loss: 78.54662085120486\n",
      "Training epoch 2288...\n",
      "\n",
      "Train Epoch: 2288 [0/8000 (0%)]\tBatch Loss: 534.984375\tLearning Rate (w_theta): 0.001000\t TIME:5149.5s\n",
      "\t\t\t\tDisc: 0.354607\t\tSym: 10.881110\t\tSpars: 523.748657\n",
      "\t TVw: 0.215032 | TVb: -2.038198 | GSw: -0.234973 | GSb: 0.064992 | TSUw: 0.464895 | TSUb: 0.034830\n",
      "\n",
      "Train Epoch: 2288 [4000/8000 (50%)]\tBatch Loss: 560.047739\tLearning Rate (w_theta): 0.001000\t TIME:5151.0s\n",
      "\t\t\t\tDisc: 0.381055\t\tSym: 11.599422\t\tSpars: 548.067261\n",
      "\t TVw: 0.215409 | TVb: -2.038178 | GSw: -0.234973 | GSb: 0.064991 | TSUw: 0.464895 | TSUb: 0.034831\n",
      "Validating epoch 2288...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 545.0387597355585\n",
      "Average validation loss: 80.71922445542131\n",
      "Training epoch 2289...\n",
      "\n",
      "Train Epoch: 2289 [0/8000 (0%)]\tBatch Loss: 585.295978\tLearning Rate (w_theta): 0.001000\t TIME:5153.9s\n",
      "\t\t\t\tDisc: 0.356331\t\tSym: 12.918712\t\tSpars: 572.020935\n",
      "\t TVw: 0.215844 | TVb: -2.038159 | GSw: -0.234973 | GSb: 0.064991 | TSUw: 0.464895 | TSUb: 0.034831\n",
      "\n",
      "Train Epoch: 2289 [4000/8000 (50%)]\tBatch Loss: 525.956028\tLearning Rate (w_theta): 0.001000\t TIME:5155.5s\n",
      "\t\t\t\tDisc: 0.319618\t\tSym: 10.076107\t\tSpars: 515.560303\n",
      "\t TVw: 0.216311 | TVb: -2.038139 | GSw: -0.234973 | GSb: 0.064991 | TSUw: 0.464895 | TSUb: 0.034831\n",
      "Validating epoch 2289...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 543.4429649755085\n",
      "Average validation loss: 79.68851650896244\n",
      "Training epoch 2290...\n",
      "\n",
      "Train Epoch: 2290 [0/8000 (0%)]\tBatch Loss: 548.604566\tLearning Rate (w_theta): 0.001000\t TIME:5157.9s\n",
      "\t\t\t\tDisc: 0.386529\t\tSym: 11.745930\t\tSpars: 536.472107\n",
      "\t TVw: 0.216765 | TVb: -2.038116 | GSw: -0.234973 | GSb: 0.064991 | TSUw: 0.464895 | TSUb: 0.034831\n",
      "\n",
      "Train Epoch: 2290 [4000/8000 (50%)]\tBatch Loss: 546.109887\tLearning Rate (w_theta): 0.001000\t TIME:5159.5s\n",
      "\t\t\t\tDisc: 0.350069\t\tSym: 12.349418\t\tSpars: 533.410400\n",
      "\t TVw: 0.216997 | TVb: -2.038103 | GSw: -0.234973 | GSb: 0.064991 | TSUw: 0.464895 | TSUb: 0.034831\n",
      "Validating epoch 2290...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 541.3477826284474\n",
      "Average validation loss: 80.37344638892877\n",
      "Training epoch 2291...\n",
      "\n",
      "Train Epoch: 2291 [0/8000 (0%)]\tBatch Loss: 543.200481\tLearning Rate (w_theta): 0.001000\t TIME:5162.6s\n",
      "\t\t\t\tDisc: 0.384838\t\tSym: 11.301605\t\tSpars: 531.514038\n",
      "\t TVw: 0.217333 | TVb: -2.038087 | GSw: -0.234973 | GSb: 0.064991 | TSUw: 0.464895 | TSUb: 0.034831\n",
      "\n",
      "Train Epoch: 2291 [4000/8000 (50%)]\tBatch Loss: 550.367412\tLearning Rate (w_theta): 0.001000\t TIME:5164.2s\n",
      "\t\t\t\tDisc: 0.369612\t\tSym: 11.634885\t\tSpars: 538.362915\n",
      "\t TVw: 0.217596 | TVb: -2.038069 | GSw: -0.234973 | GSb: 0.064991 | TSUw: 0.464895 | TSUb: 0.034831\n",
      "Validating epoch 2291...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 540.8551635650457\n",
      "Average validation loss: 81.48299630631512\n",
      "Training epoch 2292...\n",
      "\n",
      "Train Epoch: 2292 [0/8000 (0%)]\tBatch Loss: 545.509770\tLearning Rate (w_theta): 0.001000\t TIME:5166.6s\n",
      "\t\t\t\tDisc: 0.345766\t\tSym: 11.022220\t\tSpars: 534.141785\n",
      "\t TVw: 0.217929 | TVb: -2.038049 | GSw: -0.234973 | GSb: 0.064991 | TSUw: 0.464894 | TSUb: 0.034831\n",
      "\n",
      "Train Epoch: 2292 [4000/8000 (50%)]\tBatch Loss: 571.552373\tLearning Rate (w_theta): 0.001000\t TIME:5168.2s\n",
      "\t\t\t\tDisc: 0.392095\t\tSym: 13.536742\t\tSpars: 557.623535\n",
      "\t TVw: 0.218220 | TVb: -2.038025 | GSw: -0.234973 | GSb: 0.064990 | TSUw: 0.464894 | TSUb: 0.034831\n",
      "Validating epoch 2292...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 538.7223295150401\n",
      "Average validation loss: 80.22226389465837\n",
      "Training epoch 2293...\n",
      "\n",
      "Train Epoch: 2293 [0/8000 (0%)]\tBatch Loss: 545.398220\tLearning Rate (w_theta): 0.001000\t TIME:5170.7s\n",
      "\t\t\t\tDisc: 0.338245\t\tSym: 11.148171\t\tSpars: 533.911804\n",
      "\t TVw: 0.218412 | TVb: -2.038008 | GSw: -0.234973 | GSb: 0.064990 | TSUw: 0.464894 | TSUb: 0.034832\n",
      "\n",
      "Train Epoch: 2293 [4000/8000 (50%)]\tBatch Loss: 510.853484\tLearning Rate (w_theta): 0.001000\t TIME:5172.3s\n",
      "\t\t\t\tDisc: 0.293880\t\tSym: 10.064792\t\tSpars: 500.494812\n",
      "\t TVw: 0.218507 | TVb: -2.037995 | GSw: -0.234974 | GSb: 0.064990 | TSUw: 0.464894 | TSUb: 0.034832\n",
      "Validating epoch 2293...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 537.7754806953546\n",
      "Average validation loss: 81.22783669769913\n",
      "Training epoch 2294...\n",
      "\n",
      "Train Epoch: 2294 [0/8000 (0%)]\tBatch Loss: 528.701945\tLearning Rate (w_theta): 0.001000\t TIME:5174.7s\n",
      "\t\t\t\tDisc: 0.360313\t\tSym: 11.023028\t\tSpars: 517.318604\n",
      "\t TVw: 0.218492 | TVb: -2.037987 | GSw: -0.234974 | GSb: 0.064990 | TSUw: 0.464894 | TSUb: 0.034832\n",
      "\n",
      "Train Epoch: 2294 [4000/8000 (50%)]\tBatch Loss: 535.581380\tLearning Rate (w_theta): 0.001000\t TIME:5176.3s\n",
      "\t\t\t\tDisc: 0.334657\t\tSym: 11.416705\t\tSpars: 523.830017\n",
      "\t TVw: 0.218438 | TVb: -2.037979 | GSw: -0.234974 | GSb: 0.064990 | TSUw: 0.464894 | TSUb: 0.034832\n",
      "Validating epoch 2294...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 535.5271019708728\n",
      "Average validation loss: 81.34808817190553\n",
      "Training epoch 2295...\n",
      "\n",
      "Train Epoch: 2295 [0/8000 (0%)]\tBatch Loss: 531.106495\tLearning Rate (w_theta): 0.001000\t TIME:5178.7s\n",
      "\t\t\t\tDisc: 0.358796\t\tSym: 10.827289\t\tSpars: 519.920410\n",
      "\t TVw: 0.218676 | TVb: -2.037963 | GSw: -0.234974 | GSb: 0.064990 | TSUw: 0.464894 | TSUb: 0.034832\n",
      "\n",
      "Train Epoch: 2295 [4000/8000 (50%)]\tBatch Loss: 542.130015\tLearning Rate (w_theta): 0.001000\t TIME:5180.3s\n",
      "\t\t\t\tDisc: 0.379004\t\tSym: 11.224827\t\tSpars: 530.526184\n",
      "\t TVw: 0.218887 | TVb: -2.037946 | GSw: -0.234974 | GSb: 0.064990 | TSUw: 0.464894 | TSUb: 0.034832\n",
      "Validating epoch 2295...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 537.5474190814871\n",
      "Average validation loss: 83.85333169176238\n",
      "Training epoch 2296...\n",
      "\n",
      "Train Epoch: 2296 [0/8000 (0%)]\tBatch Loss: 536.896858\tLearning Rate (w_theta): 0.001000\t TIME:5182.7s\n",
      "\t\t\t\tDisc: 0.315287\t\tSym: 11.011991\t\tSpars: 525.569580\n",
      "\t TVw: 0.218917 | TVb: -2.037942 | GSw: -0.234974 | GSb: 0.064990 | TSUw: 0.464894 | TSUb: 0.034832\n",
      "\n",
      "Train Epoch: 2296 [4000/8000 (50%)]\tBatch Loss: 548.630629\tLearning Rate (w_theta): 0.001000\t TIME:5184.3s\n",
      "\t\t\t\tDisc: 0.309083\t\tSym: 12.171766\t\tSpars: 536.149780\n",
      "\t TVw: 0.218768 | TVb: -2.037953 | GSw: -0.234974 | GSb: 0.064990 | TSUw: 0.464893 | TSUb: 0.034832\n",
      "Validating epoch 2296...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 555.1150453215307\n",
      "Average validation loss: 80.24117801241272\n",
      "Training epoch 2297...\n",
      "\n",
      "Train Epoch: 2297 [0/8000 (0%)]\tBatch Loss: 538.407335\tLearning Rate (w_theta): 0.001000\t TIME:5186.8s\n",
      "\t\t\t\tDisc: 0.337183\t\tSym: 11.104210\t\tSpars: 526.965942\n",
      "\t TVw: 0.218709 | TVb: -2.037959 | GSw: -0.234974 | GSb: 0.064989 | TSUw: 0.464893 | TSUb: 0.034832\n",
      "\n",
      "Train Epoch: 2297 [4000/8000 (50%)]\tBatch Loss: 558.021105\tLearning Rate (w_theta): 0.001000\t TIME:5188.4s\n",
      "\t\t\t\tDisc: 0.348941\t\tSym: 12.315597\t\tSpars: 545.356567\n",
      "\t TVw: 0.218758 | TVb: -2.037961 | GSw: -0.234974 | GSb: 0.064989 | TSUw: 0.464893 | TSUb: 0.034832\n",
      "Validating epoch 2297...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 546.3845809914749\n",
      "Average validation loss: 80.49567066311828\n",
      "Training epoch 2298...\n",
      "\n",
      "Train Epoch: 2298 [0/8000 (0%)]\tBatch Loss: 532.225982\tLearning Rate (w_theta): 0.001000\t TIME:5190.8s\n",
      "\t\t\t\tDisc: 0.371227\t\tSym: 10.931781\t\tSpars: 520.922974\n",
      "\t TVw: 0.219048 | TVb: -2.037957 | GSw: -0.234974 | GSb: 0.064989 | TSUw: 0.464893 | TSUb: 0.034833\n",
      "\n",
      "Train Epoch: 2298 [4000/8000 (50%)]\tBatch Loss: 544.890601\tLearning Rate (w_theta): 0.001000\t TIME:5192.4s\n",
      "\t\t\t\tDisc: 0.344062\t\tSym: 11.675994\t\tSpars: 532.870544\n",
      "\t TVw: 0.219802 | TVb: -2.037934 | GSw: -0.234974 | GSb: 0.064989 | TSUw: 0.464893 | TSUb: 0.034833\n",
      "Validating epoch 2298...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 538.8252895782446\n",
      "Average validation loss: 82.31615574871029\n",
      "Training epoch 2299...\n",
      "\n",
      "Train Epoch: 2299 [0/8000 (0%)]\tBatch Loss: 511.272265\tLearning Rate (w_theta): 0.001000\t TIME:5194.8s\n",
      "\t\t\t\tDisc: 0.289124\t\tSym: 9.543535\t\tSpars: 501.439606\n",
      "\t TVw: 0.220639 | TVb: -2.037904 | GSw: -0.234974 | GSb: 0.064989 | TSUw: 0.464893 | TSUb: 0.034833\n",
      "\n",
      "Train Epoch: 2299 [4000/8000 (50%)]\tBatch Loss: 542.582891\tLearning Rate (w_theta): 0.001000\t TIME:5196.4s\n",
      "\t\t\t\tDisc: 0.344970\t\tSym: 11.886114\t\tSpars: 530.351807\n",
      "\t TVw: 0.221620 | TVb: -2.037870 | GSw: -0.234974 | GSb: 0.064989 | TSUw: 0.464893 | TSUb: 0.034833\n",
      "Validating epoch 2299...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 534.7273714633252\n",
      "Average validation loss: 82.65577818404962\n",
      "Training epoch 2300...\n",
      "\n",
      "Train Epoch: 2300 [0/8000 (0%)]\tBatch Loss: 526.064734\tLearning Rate (w_theta): 0.001000\t TIME:5198.8s\n",
      "\t\t\t\tDisc: 0.304149\t\tSym: 10.806788\t\tSpars: 514.953796\n",
      "\t TVw: 0.222580 | TVb: -2.037828 | GSw: -0.234974 | GSb: 0.064989 | TSUw: 0.464893 | TSUb: 0.034833\n",
      "\n",
      "Train Epoch: 2300 [4000/8000 (50%)]\tBatch Loss: 531.301548\tLearning Rate (w_theta): 0.001000\t TIME:5200.4s\n",
      "\t\t\t\tDisc: 0.367675\t\tSym: 10.840611\t\tSpars: 520.093262\n",
      "\t TVw: 0.223498 | TVb: -2.037786 | GSw: -0.234974 | GSb: 0.064988 | TSUw: 0.464892 | TSUb: 0.034833\n",
      "Validating epoch 2300...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 530.5680714281114\n",
      "Average validation loss: 82.41952843075404\n",
      "Training epoch 2301...\n",
      "\n",
      "Train Epoch: 2301 [0/8000 (0%)]\tBatch Loss: 524.223086\tLearning Rate (w_theta): 0.001000\t TIME:5203.9s\n",
      "\t\t\t\tDisc: 0.323066\t\tSym: 10.367305\t\tSpars: 513.532715\n",
      "\t TVw: 0.224145 | TVb: -2.037752 | GSw: -0.234974 | GSb: 0.064988 | TSUw: 0.464892 | TSUb: 0.034833\n",
      "\n",
      "Train Epoch: 2301 [4000/8000 (50%)]\tBatch Loss: 531.136352\tLearning Rate (w_theta): 0.001000\t TIME:5205.5s\n",
      "\t\t\t\tDisc: 0.371270\t\tSym: 11.542913\t\tSpars: 519.222168\n",
      "\t TVw: 0.224565 | TVb: -2.037726 | GSw: -0.234974 | GSb: 0.064988 | TSUw: 0.464892 | TSUb: 0.034833\n",
      "Validating epoch 2301...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 529.3222399602606\n",
      "Average validation loss: 83.98578350252797\n",
      "Training epoch 2302...\n",
      "\n",
      "Train Epoch: 2302 [0/8000 (0%)]\tBatch Loss: 557.013693\tLearning Rate (w_theta): 0.001000\t TIME:5207.9s\n",
      "\t\t\t\tDisc: 0.385096\t\tSym: 13.063289\t\tSpars: 543.565308\n",
      "\t TVw: 0.224884 | TVb: -2.037700 | GSw: -0.234975 | GSb: 0.064988 | TSUw: 0.464892 | TSUb: 0.034833\n",
      "\n",
      "Train Epoch: 2302 [4000/8000 (50%)]\tBatch Loss: 532.819521\tLearning Rate (w_theta): 0.001000\t TIME:5209.5s\n",
      "\t\t\t\tDisc: 0.355269\t\tSym: 11.585712\t\tSpars: 520.878540\n",
      "\t TVw: 0.225077 | TVb: -2.037681 | GSw: -0.234975 | GSb: 0.064988 | TSUw: 0.464892 | TSUb: 0.034834\n",
      "Validating epoch 2302...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 529.794889989642\n",
      "Average validation loss: 83.8475653683197\n",
      "Training epoch 2303...\n",
      "\n",
      "Train Epoch: 2303 [0/8000 (0%)]\tBatch Loss: 541.434551\tLearning Rate (w_theta): 0.001000\t TIME:5211.9s\n",
      "\t\t\t\tDisc: 0.340600\t\tSym: 12.136493\t\tSpars: 528.957458\n",
      "\t TVw: 0.224977 | TVb: -2.037678 | GSw: -0.234975 | GSb: 0.064988 | TSUw: 0.464892 | TSUb: 0.034834\n",
      "\n",
      "Train Epoch: 2303 [4000/8000 (50%)]\tBatch Loss: 575.826968\tLearning Rate (w_theta): 0.001000\t TIME:5213.5s\n",
      "\t\t\t\tDisc: 0.333926\t\tSym: 12.654175\t\tSpars: 562.838867\n",
      "\t TVw: 0.224740 | TVb: -2.037681 | GSw: -0.234975 | GSb: 0.064988 | TSUw: 0.464892 | TSUb: 0.034834\n",
      "Validating epoch 2303...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 544.6312556501604\n",
      "Average validation loss: 86.13448354344695\n",
      "Training epoch 2304...\n",
      "\n",
      "Train Epoch: 2304 [0/8000 (0%)]\tBatch Loss: 546.715992\tLearning Rate (w_theta): 0.001000\t TIME:5215.9s\n",
      "\t\t\t\tDisc: 0.310704\t\tSym: 11.021132\t\tSpars: 535.384155\n",
      "\t TVw: 0.224184 | TVb: -2.037710 | GSw: -0.234975 | GSb: 0.064988 | TSUw: 0.464892 | TSUb: 0.034834\n",
      "\n",
      "Train Epoch: 2304 [4000/8000 (50%)]\tBatch Loss: 520.426241\tLearning Rate (w_theta): 0.001000\t TIME:5217.5s\n",
      "\t\t\t\tDisc: 0.298803\t\tSym: 10.285763\t\tSpars: 509.841675\n",
      "\t TVw: 0.223971 | TVb: -2.037733 | GSw: -0.234975 | GSb: 0.064987 | TSUw: 0.464891 | TSUb: 0.034834\n",
      "Validating epoch 2304...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 535.904654962867\n",
      "Average validation loss: 84.94591908690333\n",
      "Training epoch 2305...\n",
      "\n",
      "Train Epoch: 2305 [0/8000 (0%)]\tBatch Loss: 533.032265\tLearning Rate (w_theta): 0.001000\t TIME:5220.1s\n",
      "\t\t\t\tDisc: 0.317661\t\tSym: 11.184147\t\tSpars: 521.530457\n",
      "\t TVw: 0.224140 | TVb: -2.037733 | GSw: -0.234975 | GSb: 0.064987 | TSUw: 0.464891 | TSUb: 0.034834\n",
      "\n",
      "Train Epoch: 2305 [4000/8000 (50%)]\tBatch Loss: 527.938876\tLearning Rate (w_theta): 0.001000\t TIME:5221.7s\n",
      "\t\t\t\tDisc: 0.312675\t\tSym: 10.916606\t\tSpars: 516.709595\n",
      "\t TVw: 0.224421 | TVb: -2.037722 | GSw: -0.234975 | GSb: 0.064987 | TSUw: 0.464891 | TSUb: 0.034834\n",
      "Validating epoch 2305...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 532.6835270821291\n",
      "Average validation loss: 84.23093748977361\n",
      "Training epoch 2306...\n",
      "\n",
      "Train Epoch: 2306 [0/8000 (0%)]\tBatch Loss: 543.008951\tLearning Rate (w_theta): 0.001000\t TIME:5224.1s\n",
      "\t\t\t\tDisc: 0.331924\t\tSym: 12.343531\t\tSpars: 530.333496\n",
      "\t TVw: 0.225055 | TVb: -2.037694 | GSw: -0.234975 | GSb: 0.064987 | TSUw: 0.464891 | TSUb: 0.034834\n",
      "\n",
      "Train Epoch: 2306 [4000/8000 (50%)]\tBatch Loss: 525.269753\tLearning Rate (w_theta): 0.001000\t TIME:5225.7s\n",
      "\t\t\t\tDisc: 0.333161\t\tSym: 11.321114\t\tSpars: 513.615479\n",
      "\t TVw: 0.226016 | TVb: -2.037651 | GSw: -0.234975 | GSb: 0.064987 | TSUw: 0.464891 | TSUb: 0.034834\n",
      "Validating epoch 2306...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 529.9233549863848\n",
      "Average validation loss: 81.55447973295261\n",
      "Training epoch 2307...\n",
      "\n",
      "Train Epoch: 2307 [0/8000 (0%)]\tBatch Loss: 536.328445\tLearning Rate (w_theta): 0.001000\t TIME:5228.1s\n",
      "\t\t\t\tDisc: 0.340669\t\tSym: 11.233321\t\tSpars: 524.754456\n",
      "\t TVw: 0.226914 | TVb: -2.037605 | GSw: -0.234975 | GSb: 0.064987 | TSUw: 0.464891 | TSUb: 0.034835\n",
      "\n",
      "Train Epoch: 2307 [4000/8000 (50%)]\tBatch Loss: 541.134349\tLearning Rate (w_theta): 0.001000\t TIME:5229.7s\n",
      "\t\t\t\tDisc: 0.350741\t\tSym: 11.648659\t\tSpars: 529.134949\n",
      "\t TVw: 0.227476 | TVb: -2.037571 | GSw: -0.234975 | GSb: 0.064987 | TSUw: 0.464891 | TSUb: 0.034835\n",
      "Validating epoch 2307...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 536.5148449460936\n",
      "Average validation loss: 84.24025556940961\n",
      "Training epoch 2308...\n",
      "\n",
      "Train Epoch: 2308 [0/8000 (0%)]\tBatch Loss: 532.721686\tLearning Rate (w_theta): 0.001000\t TIME:5232.1s\n",
      "\t\t\t\tDisc: 0.346899\t\tSym: 11.620637\t\tSpars: 520.754150\n",
      "\t TVw: 0.227696 | TVb: -2.037563 | GSw: -0.234975 | GSb: 0.064986 | TSUw: 0.464891 | TSUb: 0.034835\n",
      "\n",
      "Train Epoch: 2308 [4000/8000 (50%)]\tBatch Loss: 536.806203\tLearning Rate (w_theta): 0.001000\t TIME:5233.7s\n",
      "\t\t\t\tDisc: 0.318690\t\tSym: 10.959682\t\tSpars: 525.527832\n",
      "\t TVw: 0.227960 | TVb: -2.037554 | GSw: -0.234975 | GSb: 0.064986 | TSUw: 0.464891 | TSUb: 0.034835\n",
      "Validating epoch 2308...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 530.7488598863621\n",
      "Average validation loss: 87.48746828645777\n",
      "Training epoch 2309...\n",
      "\n",
      "Train Epoch: 2309 [0/8000 (0%)]\tBatch Loss: 540.155324\tLearning Rate (w_theta): 0.001000\t TIME:5236.1s\n",
      "\t\t\t\tDisc: 0.314621\t\tSym: 11.545110\t\tSpars: 528.295593\n",
      "\t TVw: 0.228011 | TVb: -2.037557 | GSw: -0.234975 | GSb: 0.064986 | TSUw: 0.464890 | TSUb: 0.034835\n",
      "\n",
      "Train Epoch: 2309 [4000/8000 (50%)]\tBatch Loss: 498.107648\tLearning Rate (w_theta): 0.001000\t TIME:5237.7s\n",
      "\t\t\t\tDisc: 0.321549\t\tSym: 9.373562\t\tSpars: 488.412537\n",
      "\t TVw: 0.228180 | TVb: -2.037548 | GSw: -0.234975 | GSb: 0.064986 | TSUw: 0.464890 | TSUb: 0.034835\n",
      "Validating epoch 2309...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 530.8796560663422\n",
      "Average validation loss: 88.3456635139239\n",
      "Training epoch 2310...\n",
      "\n",
      "Train Epoch: 2310 [0/8000 (0%)]\tBatch Loss: 541.643368\tLearning Rate (w_theta): 0.001000\t TIME:5240.1s\n",
      "\t\t\t\tDisc: 0.334647\t\tSym: 11.313848\t\tSpars: 529.994873\n",
      "\t TVw: 0.228478 | TVb: -2.037532 | GSw: -0.234975 | GSb: 0.064986 | TSUw: 0.464890 | TSUb: 0.034835\n",
      "\n",
      "Train Epoch: 2310 [4000/8000 (50%)]\tBatch Loss: 544.150034\tLearning Rate (w_theta): 0.001000\t TIME:5241.7s\n",
      "\t\t\t\tDisc: 0.290927\t\tSym: 11.478309\t\tSpars: 532.380798\n",
      "\t TVw: 0.228577 | TVb: -2.037530 | GSw: -0.234976 | GSb: 0.064986 | TSUw: 0.464890 | TSUb: 0.034835\n",
      "Validating epoch 2310...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 539.6464286752869\n",
      "Average validation loss: 85.89552021495511\n",
      "Training epoch 2311...\n",
      "\n",
      "Train Epoch: 2311 [0/8000 (0%)]\tBatch Loss: 532.761572\tLearning Rate (w_theta): 0.001000\t TIME:5245.2s\n",
      "\t\t\t\tDisc: 0.305576\t\tSym: 11.582095\t\tSpars: 520.873901\n",
      "\t TVw: 0.228773 | TVb: -2.037527 | GSw: -0.234976 | GSb: 0.064986 | TSUw: 0.464890 | TSUb: 0.034835\n",
      "\n",
      "Train Epoch: 2311 [4000/8000 (50%)]\tBatch Loss: 510.253862\tLearning Rate (w_theta): 0.001000\t TIME:5246.7s\n",
      "\t\t\t\tDisc: 0.325610\t\tSym: 10.268371\t\tSpars: 499.659882\n",
      "\t TVw: 0.229258 | TVb: -2.037507 | GSw: -0.234976 | GSb: 0.064985 | TSUw: 0.464890 | TSUb: 0.034836\n",
      "Validating epoch 2311...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 526.3246364724091\n",
      "Average validation loss: 85.39519334958256\n",
      "Training epoch 2312...\n",
      "\n",
      "Train Epoch: 2312 [0/8000 (0%)]\tBatch Loss: 523.670922\tLearning Rate (w_theta): 0.001000\t TIME:5249.2s\n",
      "\t\t\t\tDisc: 0.326866\t\tSym: 11.121034\t\tSpars: 512.223022\n",
      "\t TVw: 0.229886 | TVb: -2.037476 | GSw: -0.234976 | GSb: 0.064985 | TSUw: 0.464890 | TSUb: 0.034836\n",
      "\n",
      "Train Epoch: 2312 [4000/8000 (50%)]\tBatch Loss: 512.138701\tLearning Rate (w_theta): 0.001000\t TIME:5250.8s\n",
      "\t\t\t\tDisc: 0.326755\t\tSym: 11.001431\t\tSpars: 500.810516\n",
      "\t TVw: 0.230682 | TVb: -2.037433 | GSw: -0.234976 | GSb: 0.064985 | TSUw: 0.464890 | TSUb: 0.034836\n",
      "Validating epoch 2312...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 521.7419743014166\n",
      "Average validation loss: 84.22139287259606\n",
      "Training epoch 2313...\n",
      "\n",
      "Train Epoch: 2313 [0/8000 (0%)]\tBatch Loss: 511.571611\tLearning Rate (w_theta): 0.001000\t TIME:5253.2s\n",
      "\t\t\t\tDisc: 0.400226\t\tSym: 10.420653\t\tSpars: 500.750732\n",
      "\t TVw: 0.231450 | TVb: -2.037388 | GSw: -0.234976 | GSb: 0.064985 | TSUw: 0.464889 | TSUb: 0.034836\n",
      "\n",
      "Train Epoch: 2313 [4000/8000 (50%)]\tBatch Loss: 500.855782\tLearning Rate (w_theta): 0.001000\t TIME:5254.8s\n",
      "\t\t\t\tDisc: 0.342770\t\tSym: 10.431744\t\tSpars: 490.081268\n",
      "\t TVw: 0.232226 | TVb: -2.037341 | GSw: -0.234976 | GSb: 0.064985 | TSUw: 0.464889 | TSUb: 0.034836\n",
      "Validating epoch 2313...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 517.8804972522647\n",
      "Average validation loss: 86.31577542662887\n",
      "Training epoch 2314...\n",
      "\n",
      "Train Epoch: 2314 [0/8000 (0%)]\tBatch Loss: 519.044237\tLearning Rate (w_theta): 0.001000\t TIME:5257.2s\n",
      "\t\t\t\tDisc: 0.356721\t\tSym: 10.906480\t\tSpars: 507.781036\n",
      "\t TVw: 0.232698 | TVb: -2.037302 | GSw: -0.234976 | GSb: 0.064985 | TSUw: 0.464889 | TSUb: 0.034836\n",
      "\n",
      "Train Epoch: 2314 [4000/8000 (50%)]\tBatch Loss: 496.509154\tLearning Rate (w_theta): 0.001000\t TIME:5258.8s\n",
      "\t\t\t\tDisc: 0.357306\t\tSym: 9.804710\t\tSpars: 486.347137\n",
      "\t TVw: 0.232907 | TVb: -2.037273 | GSw: -0.234976 | GSb: 0.064984 | TSUw: 0.464889 | TSUb: 0.034836\n",
      "Validating epoch 2314...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 518.842168717141\n",
      "Average validation loss: 88.23031815799867\n",
      "Training epoch 2315...\n",
      "\n",
      "Train Epoch: 2315 [0/8000 (0%)]\tBatch Loss: 518.915418\tLearning Rate (w_theta): 0.001000\t TIME:5261.2s\n",
      "\t\t\t\tDisc: 0.372920\t\tSym: 11.260577\t\tSpars: 507.281921\n",
      "\t TVw: 0.232873 | TVb: -2.037263 | GSw: -0.234976 | GSb: 0.064984 | TSUw: 0.464889 | TSUb: 0.034836\n",
      "\n",
      "Train Epoch: 2315 [4000/8000 (50%)]\tBatch Loss: 560.860030\tLearning Rate (w_theta): 0.001000\t TIME:5262.8s\n",
      "\t\t\t\tDisc: 0.365488\t\tSym: 12.215184\t\tSpars: 548.279358\n",
      "\t TVw: 0.232623 | TVb: -2.037258 | GSw: -0.234976 | GSb: 0.064984 | TSUw: 0.464889 | TSUb: 0.034836\n",
      "Validating epoch 2315...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 528.7889550091311\n",
      "Average validation loss: 86.67221624522689\n",
      "Training epoch 2316...\n",
      "\n",
      "Train Epoch: 2316 [0/8000 (0%)]\tBatch Loss: 499.161471\tLearning Rate (w_theta): 0.001000\t TIME:5265.2s\n",
      "\t\t\t\tDisc: 0.348087\t\tSym: 10.264617\t\tSpars: 488.548767\n",
      "\t TVw: 0.232128 | TVb: -2.037271 | GSw: -0.234976 | GSb: 0.064984 | TSUw: 0.464889 | TSUb: 0.034837\n",
      "\n",
      "Train Epoch: 2316 [4000/8000 (50%)]\tBatch Loss: 518.625023\tLearning Rate (w_theta): 0.001000\t TIME:5266.8s\n",
      "\t\t\t\tDisc: 0.350646\t\tSym: 11.297051\t\tSpars: 506.977325\n",
      "\t TVw: 0.231641 | TVb: -2.037282 | GSw: -0.234976 | GSb: 0.064984 | TSUw: 0.464889 | TSUb: 0.034837\n",
      "Validating epoch 2316...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 516.2685119574508\n",
      "Average validation loss: 85.48855391536635\n",
      "Training epoch 2317...\n",
      "\n",
      "Train Epoch: 2317 [0/8000 (0%)]\tBatch Loss: 493.527760\tLearning Rate (w_theta): 0.001000\t TIME:5269.2s\n",
      "\t\t\t\tDisc: 0.321464\t\tSym: 9.784726\t\tSpars: 483.421570\n",
      "\t TVw: 0.231454 | TVb: -2.037274 | GSw: -0.234976 | GSb: 0.064984 | TSUw: 0.464889 | TSUb: 0.034837\n",
      "\n",
      "Train Epoch: 2317 [4000/8000 (50%)]\tBatch Loss: 521.478324\tLearning Rate (w_theta): 0.001000\t TIME:5270.8s\n",
      "\t\t\t\tDisc: 0.386197\t\tSym: 10.834345\t\tSpars: 510.257782\n",
      "\t TVw: 0.231587 | TVb: -2.037250 | GSw: -0.234976 | GSb: 0.064984 | TSUw: 0.464888 | TSUb: 0.034837\n",
      "Validating epoch 2317...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 513.7584648432282\n",
      "Average validation loss: 85.90560091749674\n",
      "Training epoch 2318...\n",
      "\n",
      "Train Epoch: 2318 [0/8000 (0%)]\tBatch Loss: 508.008383\tLearning Rate (w_theta): 0.001000\t TIME:5273.2s\n",
      "\t\t\t\tDisc: 0.335784\t\tSym: 10.399497\t\tSpars: 497.273102\n",
      "\t TVw: 0.231871 | TVb: -2.037212 | GSw: -0.234976 | GSb: 0.064983 | TSUw: 0.464888 | TSUb: 0.034837\n",
      "\n",
      "Train Epoch: 2318 [4000/8000 (50%)]\tBatch Loss: 501.815314\tLearning Rate (w_theta): 0.001000\t TIME:5274.8s\n",
      "\t\t\t\tDisc: 0.357601\t\tSym: 10.462535\t\tSpars: 490.995178\n",
      "\t TVw: 0.232337 | TVb: -2.037165 | GSw: -0.234976 | GSb: 0.064983 | TSUw: 0.464888 | TSUb: 0.034837\n",
      "Validating epoch 2318...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 513.7935897859445\n",
      "Average validation loss: 89.00599320680917\n",
      "Training epoch 2319...\n",
      "\n",
      "Train Epoch: 2319 [0/8000 (0%)]\tBatch Loss: 512.791422\tLearning Rate (w_theta): 0.001000\t TIME:5277.2s\n",
      "\t\t\t\tDisc: 0.355160\t\tSym: 10.914259\t\tSpars: 501.522003\n",
      "\t TVw: 0.232684 | TVb: -2.037128 | GSw: -0.234977 | GSb: 0.064983 | TSUw: 0.464888 | TSUb: 0.034837\n",
      "\n",
      "Train Epoch: 2319 [4000/8000 (50%)]\tBatch Loss: 500.821254\tLearning Rate (w_theta): 0.001000\t TIME:5278.8s\n",
      "\t\t\t\tDisc: 0.311517\t\tSym: 9.525545\t\tSpars: 490.984192\n",
      "\t TVw: 0.232784 | TVb: -2.037105 | GSw: -0.234977 | GSb: 0.064983 | TSUw: 0.464888 | TSUb: 0.034837\n",
      "Validating epoch 2319...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 516.0066696377054\n",
      "Average validation loss: 86.92533975293696\n",
      "Training epoch 2320...\n",
      "\n",
      "Train Epoch: 2320 [0/8000 (0%)]\tBatch Loss: 506.733399\tLearning Rate (w_theta): 0.001000\t TIME:5281.2s\n",
      "\t\t\t\tDisc: 0.348807\t\tSym: 10.840647\t\tSpars: 495.543945\n",
      "\t TVw: 0.232627 | TVb: -2.037094 | GSw: -0.234977 | GSb: 0.064983 | TSUw: 0.464888 | TSUb: 0.034837\n",
      "\n",
      "Train Epoch: 2320 [4000/8000 (50%)]\tBatch Loss: 513.179658\tLearning Rate (w_theta): 0.001000\t TIME:5282.8s\n",
      "\t\t\t\tDisc: 0.373849\t\tSym: 10.405937\t\tSpars: 502.399872\n",
      "\t TVw: 0.232480 | TVb: -2.037078 | GSw: -0.234977 | GSb: 0.064983 | TSUw: 0.464888 | TSUb: 0.034837\n",
      "Validating epoch 2320...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 513.7953067191664\n",
      "Average validation loss: 86.54072733222387\n",
      "Training epoch 2321...\n",
      "\n",
      "Train Epoch: 2321 [0/8000 (0%)]\tBatch Loss: 513.424093\tLearning Rate (w_theta): 0.001000\t TIME:5285.9s\n",
      "\t\t\t\tDisc: 0.372653\t\tSym: 11.318805\t\tSpars: 501.732635\n",
      "\t TVw: 0.232375 | TVb: -2.037065 | GSw: -0.234977 | GSb: 0.064983 | TSUw: 0.464888 | TSUb: 0.034838\n",
      "\n",
      "Train Epoch: 2321 [4000/8000 (50%)]\tBatch Loss: 522.447934\tLearning Rate (w_theta): 0.001000\t TIME:5287.5s\n",
      "\t\t\t\tDisc: 0.317541\t\tSym: 10.207358\t\tSpars: 511.923035\n",
      "\t TVw: 0.232143 | TVb: -2.037055 | GSw: -0.234977 | GSb: 0.064982 | TSUw: 0.464887 | TSUb: 0.034838\n",
      "Validating epoch 2321...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 517.3795139502259\n",
      "Average validation loss: 90.15368974323704\n",
      "Training epoch 2322...\n",
      "\n",
      "Train Epoch: 2322 [0/8000 (0%)]\tBatch Loss: 553.177529\tLearning Rate (w_theta): 0.001000\t TIME:5289.9s\n",
      "\t\t\t\tDisc: 0.345148\t\tSym: 12.642561\t\tSpars: 540.189819\n",
      "\t TVw: 0.232004 | TVb: -2.037055 | GSw: -0.234977 | GSb: 0.064982 | TSUw: 0.464887 | TSUb: 0.034838\n",
      "\n",
      "Train Epoch: 2322 [4000/8000 (50%)]\tBatch Loss: 502.426741\tLearning Rate (w_theta): 0.001000\t TIME:5291.5s\n",
      "\t\t\t\tDisc: 0.332954\t\tSym: 10.126349\t\tSpars: 491.967438\n",
      "\t TVw: 0.231977 | TVb: -2.037049 | GSw: -0.234977 | GSb: 0.064982 | TSUw: 0.464887 | TSUb: 0.034838\n",
      "Validating epoch 2322...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 514.9777640166266\n",
      "Average validation loss: 84.5720607448421\n",
      "Training epoch 2323...\n",
      "\n",
      "Train Epoch: 2323 [0/8000 (0%)]\tBatch Loss: 499.112364\tLearning Rate (w_theta): 0.001000\t TIME:5294.3s\n",
      "\t\t\t\tDisc: 0.360121\t\tSym: 10.619095\t\tSpars: 488.133148\n",
      "\t TVw: 0.232137 | TVb: -2.037031 | GSw: -0.234977 | GSb: 0.064982 | TSUw: 0.464887 | TSUb: 0.034838\n",
      "\n",
      "Train Epoch: 2323 [4000/8000 (50%)]\tBatch Loss: 522.421308\tLearning Rate (w_theta): 0.001000\t TIME:5295.8s\n",
      "\t\t\t\tDisc: 0.391200\t\tSym: 11.887072\t\tSpars: 510.143036\n",
      "\t TVw: 0.232245 | TVb: -2.037009 | GSw: -0.234977 | GSb: 0.064982 | TSUw: 0.464887 | TSUb: 0.034838\n",
      "Validating epoch 2323...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 509.4906127164984\n",
      "Average validation loss: 85.96408765911764\n",
      "Training epoch 2324...\n",
      "\n",
      "Train Epoch: 2324 [0/8000 (0%)]\tBatch Loss: 495.448961\tLearning Rate (w_theta): 0.001000\t TIME:5298.3s\n",
      "\t\t\t\tDisc: 0.336816\t\tSym: 10.206322\t\tSpars: 484.905823\n",
      "\t TVw: 0.232451 | TVb: -2.036981 | GSw: -0.234977 | GSb: 0.064982 | TSUw: 0.464887 | TSUb: 0.034838\n",
      "\n",
      "Train Epoch: 2324 [4000/8000 (50%)]\tBatch Loss: 524.656112\tLearning Rate (w_theta): 0.001000\t TIME:5299.9s\n",
      "\t\t\t\tDisc: 0.350670\t\tSym: 11.618552\t\tSpars: 512.686890\n",
      "\t TVw: 0.232667 | TVb: -2.036955 | GSw: -0.234977 | GSb: 0.064981 | TSUw: 0.464887 | TSUb: 0.034838\n",
      "Validating epoch 2324...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 507.6649488708933\n",
      "Average validation loss: 87.67921624726777\n",
      "Training epoch 2325...\n",
      "\n",
      "Train Epoch: 2325 [0/8000 (0%)]\tBatch Loss: 515.394645\tLearning Rate (w_theta): 0.001000\t TIME:5302.3s\n",
      "\t\t\t\tDisc: 0.359194\t\tSym: 11.853322\t\tSpars: 503.182129\n",
      "\t TVw: 0.233001 | TVb: -2.036925 | GSw: -0.234977 | GSb: 0.064981 | TSUw: 0.464887 | TSUb: 0.034838\n",
      "\n",
      "Train Epoch: 2325 [4000/8000 (50%)]\tBatch Loss: 495.666199\tLearning Rate (w_theta): 0.001000\t TIME:5303.9s\n",
      "\t\t\t\tDisc: 0.352364\t\tSym: 10.687431\t\tSpars: 484.626404\n",
      "\t TVw: 0.233232 | TVb: -2.036895 | GSw: -0.234977 | GSb: 0.064981 | TSUw: 0.464886 | TSUb: 0.034839\n",
      "Validating epoch 2325...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 507.0093862867494\n",
      "Average validation loss: 85.5802035891114\n",
      "Training epoch 2326...\n",
      "\n",
      "Train Epoch: 2326 [0/8000 (0%)]\tBatch Loss: 509.968977\tLearning Rate (w_theta): 0.001000\t TIME:5306.3s\n",
      "\t\t\t\tDisc: 0.344557\t\tSym: 10.949738\t\tSpars: 498.674683\n",
      "\t TVw: 0.233314 | TVb: -2.036868 | GSw: -0.234977 | GSb: 0.064981 | TSUw: 0.464886 | TSUb: 0.034839\n",
      "\n",
      "Train Epoch: 2326 [4000/8000 (50%)]\tBatch Loss: 519.977709\tLearning Rate (w_theta): 0.001000\t TIME:5307.9s\n",
      "\t\t\t\tDisc: 0.351638\t\tSym: 11.323428\t\tSpars: 508.302643\n",
      "\t TVw: 0.233142 | TVb: -2.036858 | GSw: -0.234977 | GSb: 0.064981 | TSUw: 0.464886 | TSUb: 0.034839\n",
      "Validating epoch 2326...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 510.5727994544989\n",
      "Average validation loss: 89.20034025997636\n",
      "Training epoch 2327...\n",
      "\n",
      "Train Epoch: 2327 [0/8000 (0%)]\tBatch Loss: 519.769821\tLearning Rate (w_theta): 0.001000\t TIME:5310.3s\n",
      "\t\t\t\tDisc: 0.372768\t\tSym: 11.784078\t\tSpars: 507.612976\n",
      "\t TVw: 0.232861 | TVb: -2.036858 | GSw: -0.234977 | GSb: 0.064981 | TSUw: 0.464886 | TSUb: 0.034839\n",
      "\n",
      "Train Epoch: 2327 [4000/8000 (50%)]\tBatch Loss: 495.135200\tLearning Rate (w_theta): 0.001000\t TIME:5311.8s\n",
      "\t\t\t\tDisc: 0.359299\t\tSym: 10.414359\t\tSpars: 484.361542\n",
      "\t TVw: 0.232634 | TVb: -2.036850 | GSw: -0.234978 | GSb: 0.064981 | TSUw: 0.464886 | TSUb: 0.034839\n",
      "Validating epoch 2327...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 505.90555368326943\n",
      "Average validation loss: 84.70310035522043\n",
      "Training epoch 2328...\n",
      "\n",
      "Train Epoch: 2328 [0/8000 (0%)]\tBatch Loss: 506.448601\tLearning Rate (w_theta): 0.001000\t TIME:5314.3s\n",
      "\t\t\t\tDisc: 0.332509\t\tSym: 10.740664\t\tSpars: 495.375427\n",
      "\t TVw: 0.232524 | TVb: -2.036833 | GSw: -0.234978 | GSb: 0.064980 | TSUw: 0.464886 | TSUb: 0.034839\n",
      "\n",
      "Train Epoch: 2328 [4000/8000 (50%)]\tBatch Loss: 498.262933\tLearning Rate (w_theta): 0.001000\t TIME:5315.9s\n",
      "\t\t\t\tDisc: 0.378808\t\tSym: 10.580597\t\tSpars: 487.303528\n",
      "\t TVw: 0.232512 | TVb: -2.036820 | GSw: -0.234978 | GSb: 0.064980 | TSUw: 0.464886 | TSUb: 0.034839\n",
      "Validating epoch 2328...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 507.44681861350165\n",
      "Average validation loss: 89.0420192195022\n",
      "Training epoch 2329...\n",
      "\n",
      "Train Epoch: 2329 [0/8000 (0%)]\tBatch Loss: 502.284495\tLearning Rate (w_theta): 0.001000\t TIME:5318.3s\n",
      "\t\t\t\tDisc: 0.345550\t\tSym: 10.492595\t\tSpars: 491.446350\n",
      "\t TVw: 0.232668 | TVb: -2.036800 | GSw: -0.234978 | GSb: 0.064980 | TSUw: 0.464886 | TSUb: 0.034839\n",
      "\n",
      "Train Epoch: 2329 [4000/8000 (50%)]\tBatch Loss: 518.437734\tLearning Rate (w_theta): 0.001000\t TIME:5319.8s\n",
      "\t\t\t\tDisc: 0.359095\t\tSym: 12.322200\t\tSpars: 505.756439\n",
      "\t TVw: 0.232817 | TVb: -2.036784 | GSw: -0.234978 | GSb: 0.064980 | TSUw: 0.464886 | TSUb: 0.034839\n",
      "Validating epoch 2329...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 506.24025729839866\n",
      "Average validation loss: 84.77282446887895\n",
      "Training epoch 2330...\n",
      "\n",
      "Train Epoch: 2330 [0/8000 (0%)]\tBatch Loss: 509.381912\tLearning Rate (w_theta): 0.001000\t TIME:5322.2s\n",
      "\t\t\t\tDisc: 0.320563\t\tSym: 10.884195\t\tSpars: 498.177155\n",
      "\t TVw: 0.232948 | TVb: -2.036764 | GSw: -0.234978 | GSb: 0.064980 | TSUw: 0.464885 | TSUb: 0.034840\n",
      "\n",
      "Train Epoch: 2330 [4000/8000 (50%)]\tBatch Loss: 492.624340\tLearning Rate (w_theta): 0.001000\t TIME:5323.8s\n",
      "\t\t\t\tDisc: 0.358222\t\tSym: 9.989110\t\tSpars: 482.277008\n",
      "\t TVw: 0.233151 | TVb: -2.036746 | GSw: -0.234978 | GSb: 0.064980 | TSUw: 0.464885 | TSUb: 0.034840\n",
      "Validating epoch 2330...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 503.3536604838573\n",
      "Average validation loss: 85.93952502742862\n",
      "Training epoch 2331...\n",
      "\n",
      "Train Epoch: 2331 [0/8000 (0%)]\tBatch Loss: 491.870039\tLearning Rate (w_theta): 0.001000\t TIME:5326.9s\n",
      "\t\t\t\tDisc: 0.336025\t\tSym: 10.794909\t\tSpars: 480.739105\n",
      "\t TVw: 0.233435 | TVb: -2.036726 | GSw: -0.234978 | GSb: 0.064980 | TSUw: 0.464885 | TSUb: 0.034840\n",
      "\n",
      "Train Epoch: 2331 [4000/8000 (50%)]\tBatch Loss: 509.409350\tLearning Rate (w_theta): 0.001000\t TIME:5328.5s\n",
      "\t\t\t\tDisc: 0.340550\t\tSym: 11.294783\t\tSpars: 497.774017\n",
      "\t TVw: 0.233601 | TVb: -2.036707 | GSw: -0.234978 | GSb: 0.064979 | TSUw: 0.464885 | TSUb: 0.034840\n",
      "Validating epoch 2331...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 501.00837987669775\n",
      "Average validation loss: 88.17849085684588\n",
      "Training epoch 2332...\n",
      "\n",
      "Train Epoch: 2332 [0/8000 (0%)]\tBatch Loss: 492.888921\tLearning Rate (w_theta): 0.001000\t TIME:5331.0s\n",
      "\t\t\t\tDisc: 0.348763\t\tSym: 11.236478\t\tSpars: 481.303680\n",
      "\t TVw: 0.233835 | TVb: -2.036682 | GSw: -0.234978 | GSb: 0.064979 | TSUw: 0.464885 | TSUb: 0.034840\n",
      "\n",
      "Train Epoch: 2332 [4000/8000 (50%)]\tBatch Loss: 509.500133\tLearning Rate (w_theta): 0.001000\t TIME:5332.5s\n",
      "\t\t\t\tDisc: 0.348477\t\tSym: 11.609572\t\tSpars: 497.542084\n",
      "\t TVw: 0.234103 | TVb: -2.036653 | GSw: -0.234978 | GSb: 0.064979 | TSUw: 0.464885 | TSUb: 0.034840\n",
      "Validating epoch 2332...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 499.041607769253\n",
      "Average validation loss: 87.45715774662132\n",
      "Training epoch 2333...\n",
      "\n",
      "Train Epoch: 2333 [0/8000 (0%)]\tBatch Loss: 494.187914\tLearning Rate (w_theta): 0.001000\t TIME:5335.0s\n",
      "\t\t\t\tDisc: 0.345210\t\tSym: 10.586418\t\tSpars: 483.256287\n",
      "\t TVw: 0.234304 | TVb: -2.036628 | GSw: -0.234978 | GSb: 0.064979 | TSUw: 0.464885 | TSUb: 0.034840\n",
      "\n",
      "Train Epoch: 2333 [4000/8000 (50%)]\tBatch Loss: 514.848348\tLearning Rate (w_theta): 0.001000\t TIME:5336.6s\n",
      "\t\t\t\tDisc: 0.350089\t\tSym: 11.589355\t\tSpars: 502.908905\n",
      "\t TVw: 0.234288 | TVb: -2.036616 | GSw: -0.234978 | GSb: 0.064979 | TSUw: 0.464885 | TSUb: 0.034840\n",
      "Validating epoch 2333...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 500.13109632413875\n",
      "Average validation loss: 90.49228716436292\n",
      "Training epoch 2334...\n",
      "\n",
      "Train Epoch: 2334 [0/8000 (0%)]\tBatch Loss: 510.629560\tLearning Rate (w_theta): 0.001000\t TIME:5339.0s\n",
      "\t\t\t\tDisc: 0.326060\t\tSym: 11.075259\t\tSpars: 499.228241\n",
      "\t TVw: 0.234222 | TVb: -2.036603 | GSw: -0.234978 | GSb: 0.064979 | TSUw: 0.464884 | TSUb: 0.034840\n",
      "\n",
      "Train Epoch: 2334 [4000/8000 (50%)]\tBatch Loss: 495.251157\tLearning Rate (w_theta): 0.001000\t TIME:5340.6s\n",
      "\t\t\t\tDisc: 0.348613\t\tSym: 11.128130\t\tSpars: 483.774414\n",
      "\t TVw: 0.234205 | TVb: -2.036588 | GSw: -0.234978 | GSb: 0.064979 | TSUw: 0.464884 | TSUb: 0.034841\n",
      "Validating epoch 2334...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 499.203747264925\n",
      "Average validation loss: 86.64984588305299\n",
      "Training epoch 2335...\n",
      "\n",
      "Train Epoch: 2335 [0/8000 (0%)]\tBatch Loss: 479.875954\tLearning Rate (w_theta): 0.001000\t TIME:5343.4s\n",
      "\t\t\t\tDisc: 0.331562\t\tSym: 9.918629\t\tSpars: 469.625763\n",
      "\t TVw: 0.234213 | TVb: -2.036578 | GSw: -0.234978 | GSb: 0.064978 | TSUw: 0.464884 | TSUb: 0.034841\n",
      "\n",
      "Train Epoch: 2335 [4000/8000 (50%)]\tBatch Loss: 515.835239\tLearning Rate (w_theta): 0.001000\t TIME:5344.9s\n",
      "\t\t\t\tDisc: 0.394829\t\tSym: 12.659495\t\tSpars: 502.780914\n",
      "\t TVw: 0.234231 | TVb: -2.036567 | GSw: -0.234979 | GSb: 0.064978 | TSUw: 0.464884 | TSUb: 0.034841\n",
      "Validating epoch 2335...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 497.6954450874551\n",
      "Average validation loss: 90.10467382537949\n",
      "Training epoch 2336...\n",
      "\n",
      "Train Epoch: 2336 [0/8000 (0%)]\tBatch Loss: 484.189410\tLearning Rate (w_theta): 0.001000\t TIME:5347.4s\n",
      "\t\t\t\tDisc: 0.334456\t\tSym: 9.794316\t\tSpars: 474.060638\n",
      "\t TVw: 0.234276 | TVb: -2.036553 | GSw: -0.234979 | GSb: 0.064978 | TSUw: 0.464884 | TSUb: 0.034841\n",
      "\n",
      "Train Epoch: 2336 [4000/8000 (50%)]\tBatch Loss: 514.319415\tLearning Rate (w_theta): 0.001000\t TIME:5348.9s\n",
      "\t\t\t\tDisc: 0.367995\t\tSym: 11.441838\t\tSpars: 502.509583\n",
      "\t TVw: 0.234234 | TVb: -2.036547 | GSw: -0.234979 | GSb: 0.064978 | TSUw: 0.464884 | TSUb: 0.034841\n",
      "Validating epoch 2336...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 505.2051927902595\n",
      "Average validation loss: 84.3779209464354\n",
      "Training epoch 2337...\n",
      "\n",
      "Train Epoch: 2337 [0/8000 (0%)]\tBatch Loss: 502.701864\tLearning Rate (w_theta): 0.001000\t TIME:5351.4s\n",
      "\t\t\t\tDisc: 0.321829\t\tSym: 10.926909\t\tSpars: 491.453125\n",
      "\t TVw: 0.234055 | TVb: -2.036549 | GSw: -0.234979 | GSb: 0.064978 | TSUw: 0.464884 | TSUb: 0.034841\n",
      "\n",
      "Train Epoch: 2337 [4000/8000 (50%)]\tBatch Loss: 506.587150\tLearning Rate (w_theta): 0.001000\t TIME:5352.9s\n",
      "\t\t\t\tDisc: 0.362937\t\tSym: 11.377686\t\tSpars: 494.846527\n",
      "\t TVw: 0.234118 | TVb: -2.036551 | GSw: -0.234979 | GSb: 0.064978 | TSUw: 0.464884 | TSUb: 0.034841\n",
      "Validating epoch 2337...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 505.3392218694379\n",
      "Average validation loss: 87.93685973830927\n",
      "Training epoch 2338...\n",
      "\n",
      "Train Epoch: 2338 [0/8000 (0%)]\tBatch Loss: 505.636525\tLearning Rate (w_theta): 0.001000\t TIME:5355.3s\n",
      "\t\t\t\tDisc: 0.331213\t\tSym: 10.643844\t\tSpars: 494.661469\n",
      "\t TVw: 0.234302 | TVb: -2.036550 | GSw: -0.234979 | GSb: 0.064977 | TSUw: 0.464884 | TSUb: 0.034841\n",
      "\n",
      "Train Epoch: 2338 [4000/8000 (50%)]\tBatch Loss: 487.869056\tLearning Rate (w_theta): 0.001000\t TIME:5356.9s\n",
      "\t\t\t\tDisc: 0.353352\t\tSym: 10.578418\t\tSpars: 476.937286\n",
      "\t TVw: 0.234762 | TVb: -2.036531 | GSw: -0.234979 | GSb: 0.064977 | TSUw: 0.464883 | TSUb: 0.034841\n",
      "Validating epoch 2338...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 497.3273540887767\n",
      "Average validation loss: 89.19993214391586\n",
      "Training epoch 2339...\n",
      "\n",
      "Train Epoch: 2339 [0/8000 (0%)]\tBatch Loss: 501.253078\tLearning Rate (w_theta): 0.001000\t TIME:5359.3s\n",
      "\t\t\t\tDisc: 0.352505\t\tSym: 11.334105\t\tSpars: 489.566467\n",
      "\t TVw: 0.235465 | TVb: -2.036494 | GSw: -0.234979 | GSb: 0.064977 | TSUw: 0.464883 | TSUb: 0.034842\n",
      "\n",
      "Train Epoch: 2339 [4000/8000 (50%)]\tBatch Loss: 484.212169\tLearning Rate (w_theta): 0.001000\t TIME:5360.9s\n",
      "\t\t\t\tDisc: 0.307797\t\tSym: 10.415267\t\tSpars: 473.489105\n",
      "\t TVw: 0.236108 | TVb: -2.036455 | GSw: -0.234979 | GSb: 0.064977 | TSUw: 0.464883 | TSUb: 0.034842\n",
      "Validating epoch 2339...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 495.4164320425071\n",
      "Average validation loss: 90.11339846875613\n",
      "Training epoch 2340...\n",
      "\n",
      "Train Epoch: 2340 [0/8000 (0%)]\tBatch Loss: 486.932035\tLearning Rate (w_theta): 0.001000\t TIME:5363.4s\n",
      "\t\t\t\tDisc: 0.324375\t\tSym: 10.434319\t\tSpars: 476.173340\n",
      "\t TVw: 0.236737 | TVb: -2.036414 | GSw: -0.234979 | GSb: 0.064977 | TSUw: 0.464883 | TSUb: 0.034842\n",
      "\n",
      "Train Epoch: 2340 [4000/8000 (50%)]\tBatch Loss: 485.087214\tLearning Rate (w_theta): 0.001000\t TIME:5364.9s\n",
      "\t\t\t\tDisc: 0.336104\t\tSym: 10.521191\t\tSpars: 474.229919\n",
      "\t TVw: 0.237213 | TVb: -2.036378 | GSw: -0.234979 | GSb: 0.064977 | TSUw: 0.464883 | TSUb: 0.034842\n",
      "Validating epoch 2340...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 494.1161360381518\n",
      "Average validation loss: 86.7416881108776\n",
      "Training epoch 2341...\n",
      "\n",
      "Train Epoch: 2341 [0/8000 (0%)]\tBatch Loss: 485.126965\tLearning Rate (w_theta): 0.001000\t TIME:5368.1s\n",
      "\t\t\t\tDisc: 0.301281\t\tSym: 10.233918\t\tSpars: 474.591766\n",
      "\t TVw: 0.237582 | TVb: -2.036344 | GSw: -0.234979 | GSb: 0.064977 | TSUw: 0.464883 | TSUb: 0.034842\n",
      "\n",
      "Train Epoch: 2341 [4000/8000 (50%)]\tBatch Loss: 480.684772\tLearning Rate (w_theta): 0.001000\t TIME:5369.7s\n",
      "\t\t\t\tDisc: 0.373641\t\tSym: 10.563909\t\tSpars: 469.747223\n",
      "\t TVw: 0.237711 | TVb: -2.036322 | GSw: -0.234979 | GSb: 0.064976 | TSUw: 0.464883 | TSUb: 0.034842\n",
      "Validating epoch 2341...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 492.64022213190043\n",
      "Average validation loss: 91.89863364927506\n",
      "Training epoch 2342...\n",
      "\n",
      "Train Epoch: 2342 [0/8000 (0%)]\tBatch Loss: 507.212603\tLearning Rate (w_theta): 0.001000\t TIME:5372.1s\n",
      "\t\t\t\tDisc: 0.326715\t\tSym: 11.593132\t\tSpars: 495.292755\n",
      "\t TVw: 0.237718 | TVb: -2.036303 | GSw: -0.234979 | GSb: 0.064976 | TSUw: 0.464883 | TSUb: 0.034842\n",
      "\n",
      "Train Epoch: 2342 [4000/8000 (50%)]\tBatch Loss: 472.628678\tLearning Rate (w_theta): 0.001000\t TIME:5373.7s\n",
      "\t\t\t\tDisc: 0.336703\t\tSym: 10.171156\t\tSpars: 462.120819\n",
      "\t TVw: 0.237648 | TVb: -2.036289 | GSw: -0.234979 | GSb: 0.064976 | TSUw: 0.464882 | TSUb: 0.034842\n",
      "Validating epoch 2342...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 492.0423024104711\n",
      "Average validation loss: 87.28451442566622\n",
      "Training epoch 2343...\n",
      "\n",
      "Train Epoch: 2343 [0/8000 (0%)]\tBatch Loss: 491.617203\tLearning Rate (w_theta): 0.001000\t TIME:5376.1s\n",
      "\t\t\t\tDisc: 0.361378\t\tSym: 10.945827\t\tSpars: 480.309998\n",
      "\t TVw: 0.237656 | TVb: -2.036277 | GSw: -0.234979 | GSb: 0.064976 | TSUw: 0.464882 | TSUb: 0.034842\n",
      "\n",
      "Train Epoch: 2343 [4000/8000 (50%)]\tBatch Loss: 511.003854\tLearning Rate (w_theta): 0.001000\t TIME:5377.7s\n",
      "\t\t\t\tDisc: 0.365940\t\tSym: 11.499212\t\tSpars: 499.138702\n",
      "\t TVw: 0.237666 | TVb: -2.036267 | GSw: -0.234979 | GSb: 0.064976 | TSUw: 0.464882 | TSUb: 0.034843\n",
      "Validating epoch 2343...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 489.69219278248505\n",
      "Average validation loss: 89.86704061414314\n",
      "Training epoch 2344...\n",
      "\n",
      "Train Epoch: 2344 [0/8000 (0%)]\tBatch Loss: 492.961654\tLearning Rate (w_theta): 0.001000\t TIME:5380.1s\n",
      "\t\t\t\tDisc: 0.361978\t\tSym: 11.537085\t\tSpars: 481.062592\n",
      "\t TVw: 0.237621 | TVb: -2.036253 | GSw: -0.234980 | GSb: 0.064976 | TSUw: 0.464882 | TSUb: 0.034843\n",
      "\n",
      "Train Epoch: 2344 [4000/8000 (50%)]\tBatch Loss: 485.166422\tLearning Rate (w_theta): 0.001000\t TIME:5381.7s\n",
      "\t\t\t\tDisc: 0.379998\t\tSym: 10.108477\t\tSpars: 474.677948\n",
      "\t TVw: 0.237679 | TVb: -2.036230 | GSw: -0.234980 | GSb: 0.064976 | TSUw: 0.464882 | TSUb: 0.034843\n",
      "Validating epoch 2344...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 488.2341687838754\n",
      "Average validation loss: 89.61835445599652\n",
      "Training epoch 2345...\n",
      "\n",
      "Train Epoch: 2345 [0/8000 (0%)]\tBatch Loss: 495.281322\tLearning Rate (w_theta): 0.001000\t TIME:5384.1s\n",
      "\t\t\t\tDisc: 0.359281\t\tSym: 11.049299\t\tSpars: 483.872742\n",
      "\t TVw: 0.237775 | TVb: -2.036205 | GSw: -0.234980 | GSb: 0.064975 | TSUw: 0.464882 | TSUb: 0.034843\n",
      "\n",
      "Train Epoch: 2345 [4000/8000 (50%)]\tBatch Loss: 496.320670\tLearning Rate (w_theta): 0.001000\t TIME:5385.7s\n",
      "\t\t\t\tDisc: 0.348456\t\tSym: 11.368913\t\tSpars: 484.603302\n",
      "\t TVw: 0.237916 | TVb: -2.036179 | GSw: -0.234980 | GSb: 0.064975 | TSUw: 0.464882 | TSUb: 0.034843\n",
      "Validating epoch 2345...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 490.47665741866433\n",
      "Average validation loss: 89.242595879643\n",
      "Training epoch 2346...\n",
      "\n",
      "Train Epoch: 2346 [0/8000 (0%)]\tBatch Loss: 467.855410\tLearning Rate (w_theta): 0.001000\t TIME:5388.1s\n",
      "\t\t\t\tDisc: 0.353271\t\tSym: 9.557162\t\tSpars: 457.944977\n",
      "\t TVw: 0.237924 | TVb: -2.036159 | GSw: -0.234980 | GSb: 0.064975 | TSUw: 0.464882 | TSUb: 0.034843\n",
      "\n",
      "Train Epoch: 2346 [4000/8000 (50%)]\tBatch Loss: 466.160153\tLearning Rate (w_theta): 0.001000\t TIME:5389.7s\n",
      "\t\t\t\tDisc: 0.326241\t\tSym: 9.225239\t\tSpars: 456.608673\n",
      "\t TVw: 0.237797 | TVb: -2.036147 | GSw: -0.234980 | GSb: 0.064975 | TSUw: 0.464881 | TSUb: 0.034843\n",
      "Validating epoch 2346...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 492.68953774578245\n",
      "Average validation loss: 91.42324877633693\n",
      "Training epoch 2347...\n",
      "\n",
      "Train Epoch: 2347 [0/8000 (0%)]\tBatch Loss: 515.050842\tLearning Rate (w_theta): 0.001000\t TIME:5392.5s\n",
      "\t\t\t\tDisc: 0.336408\t\tSym: 12.287371\t\tSpars: 502.427063\n",
      "\t TVw: 0.237522 | TVb: -2.036155 | GSw: -0.234980 | GSb: 0.064975 | TSUw: 0.464881 | TSUb: 0.034843\n",
      "\n",
      "Train Epoch: 2347 [4000/8000 (50%)]\tBatch Loss: 483.667287\tLearning Rate (w_theta): 0.001000\t TIME:5394.1s\n",
      "\t\t\t\tDisc: 0.366873\t\tSym: 10.419523\t\tSpars: 472.880890\n",
      "\t TVw: 0.237549 | TVb: -2.036155 | GSw: -0.234980 | GSb: 0.064975 | TSUw: 0.464881 | TSUb: 0.034844\n",
      "Validating epoch 2347...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 491.38546504913495\n",
      "Average validation loss: 85.64906744941553\n",
      "Training epoch 2348...\n",
      "\n",
      "Train Epoch: 2348 [0/8000 (0%)]\tBatch Loss: 486.858062\tLearning Rate (w_theta): 0.001000\t TIME:5396.5s\n",
      "\t\t\t\tDisc: 0.356447\t\tSym: 10.592527\t\tSpars: 475.909088\n",
      "\t TVw: 0.237800 | TVb: -2.036144 | GSw: -0.234980 | GSb: 0.064974 | TSUw: 0.464881 | TSUb: 0.034844\n",
      "\n",
      "Train Epoch: 2348 [4000/8000 (50%)]\tBatch Loss: 482.862842\tLearning Rate (w_theta): 0.001000\t TIME:5398.1s\n",
      "\t\t\t\tDisc: 0.371413\t\tSym: 10.441899\t\tSpars: 472.049530\n",
      "\t TVw: 0.238230 | TVb: -2.036121 | GSw: -0.234980 | GSb: 0.064974 | TSUw: 0.464881 | TSUb: 0.034844\n",
      "Validating epoch 2348...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 488.2613023125345\n",
      "Average validation loss: 89.50040893772167\n",
      "Training epoch 2349...\n",
      "\n",
      "Train Epoch: 2349 [0/8000 (0%)]\tBatch Loss: 493.887808\tLearning Rate (w_theta): 0.001000\t TIME:5400.5s\n",
      "\t\t\t\tDisc: 0.347533\t\tSym: 11.016411\t\tSpars: 482.523865\n",
      "\t TVw: 0.238663 | TVb: -2.036091 | GSw: -0.234980 | GSb: 0.064974 | TSUw: 0.464881 | TSUb: 0.034844\n",
      "\n",
      "Train Epoch: 2349 [4000/8000 (50%)]\tBatch Loss: 495.592072\tLearning Rate (w_theta): 0.001000\t TIME:5402.1s\n",
      "\t\t\t\tDisc: 0.314356\t\tSym: 11.437720\t\tSpars: 483.839996\n",
      "\t TVw: 0.239194 | TVb: -2.036058 | GSw: -0.234980 | GSb: 0.064974 | TSUw: 0.464881 | TSUb: 0.034844\n",
      "Validating epoch 2349...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 490.90274082376413\n",
      "Average validation loss: 95.8665731019588\n",
      "Training epoch 2350...\n",
      "\n",
      "Train Epoch: 2350 [0/8000 (0%)]\tBatch Loss: 519.523491\tLearning Rate (w_theta): 0.001000\t TIME:5404.5s\n",
      "\t\t\t\tDisc: 0.314897\t\tSym: 11.654486\t\tSpars: 507.554108\n",
      "\t TVw: 0.239552 | TVb: -2.036041 | GSw: -0.234980 | GSb: 0.064974 | TSUw: 0.464881 | TSUb: 0.034844\n",
      "\n",
      "Train Epoch: 2350 [4000/8000 (50%)]\tBatch Loss: 473.842855\tLearning Rate (w_theta): 0.001000\t TIME:5406.0s\n",
      "\t\t\t\tDisc: 0.352788\t\tSym: 9.878312\t\tSpars: 463.611755\n",
      "\t TVw: 0.239744 | TVb: -2.036034 | GSw: -0.234980 | GSb: 0.064974 | TSUw: 0.464881 | TSUb: 0.034844\n",
      "Validating epoch 2350...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 495.23842093426015\n",
      "Average validation loss: 86.73535420197817\n",
      "Training epoch 2351...\n",
      "\n",
      "Train Epoch: 2351 [0/8000 (0%)]\tBatch Loss: 480.912715\tLearning Rate (w_theta): 0.001000\t TIME:5409.2s\n",
      "\t\t\t\tDisc: 0.350800\t\tSym: 11.118983\t\tSpars: 469.442932\n",
      "\t TVw: 0.240105 | TVb: -2.036018 | GSw: -0.234980 | GSb: 0.064974 | TSUw: 0.464880 | TSUb: 0.034844\n",
      "\n",
      "Train Epoch: 2351 [4000/8000 (50%)]\tBatch Loss: 486.710073\tLearning Rate (w_theta): 0.001000\t TIME:5410.8s\n",
      "\t\t\t\tDisc: 0.318320\t\tSym: 10.870757\t\tSpars: 475.520996\n",
      "\t TVw: 0.240367 | TVb: -2.036003 | GSw: -0.234980 | GSb: 0.064973 | TSUw: 0.464880 | TSUb: 0.034844\n",
      "Validating epoch 2351...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 485.3029926480868\n",
      "Average validation loss: 86.17292221864689\n",
      "Training epoch 2352...\n",
      "\n",
      "Train Epoch: 2352 [0/8000 (0%)]\tBatch Loss: 485.694279\tLearning Rate (w_theta): 0.001000\t TIME:5413.3s\n",
      "\t\t\t\tDisc: 0.360744\t\tSym: 11.340035\t\tSpars: 473.993500\n",
      "\t TVw: 0.240738 | TVb: -2.035981 | GSw: -0.234980 | GSb: 0.064973 | TSUw: 0.464880 | TSUb: 0.034845\n",
      "\n",
      "Train Epoch: 2352 [4000/8000 (50%)]\tBatch Loss: 465.962777\tLearning Rate (w_theta): 0.001000\t TIME:5414.9s\n",
      "\t\t\t\tDisc: 0.344124\t\tSym: 9.663301\t\tSpars: 455.955353\n",
      "\t TVw: 0.241286 | TVb: -2.035948 | GSw: -0.234981 | GSb: 0.064973 | TSUw: 0.464880 | TSUb: 0.034845\n",
      "Validating epoch 2352...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 483.4599714572104\n",
      "Average validation loss: 90.06810345061233\n",
      "Training epoch 2353...\n",
      "\n",
      "Train Epoch: 2353 [0/8000 (0%)]\tBatch Loss: 469.638732\tLearning Rate (w_theta): 0.001000\t TIME:5417.3s\n",
      "\t\t\t\tDisc: 0.339680\t\tSym: 10.474650\t\tSpars: 458.824402\n",
      "\t TVw: 0.241997 | TVb: -2.035901 | GSw: -0.234981 | GSb: 0.064973 | TSUw: 0.464880 | TSUb: 0.034845\n",
      "\n",
      "Train Epoch: 2353 [4000/8000 (50%)]\tBatch Loss: 444.644541\tLearning Rate (w_theta): 0.001000\t TIME:5418.8s\n",
      "\t\t\t\tDisc: 0.332533\t\tSym: 8.842770\t\tSpars: 435.469238\n",
      "\t TVw: 0.242506 | TVb: -2.035860 | GSw: -0.234981 | GSb: 0.064973 | TSUw: 0.464880 | TSUb: 0.034845\n",
      "Validating epoch 2353...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 480.79230938635203\n",
      "Average validation loss: 92.61290504938506\n",
      "Training epoch 2354...\n",
      "\n",
      "Train Epoch: 2354 [0/8000 (0%)]\tBatch Loss: 476.509471\tLearning Rate (w_theta): 0.001000\t TIME:5421.3s\n",
      "\t\t\t\tDisc: 0.326218\t\tSym: 10.845607\t\tSpars: 465.337646\n",
      "\t TVw: 0.242732 | TVb: -2.035828 | GSw: -0.234981 | GSb: 0.064973 | TSUw: 0.464880 | TSUb: 0.034845\n",
      "\n",
      "Train Epoch: 2354 [4000/8000 (50%)]\tBatch Loss: 484.078270\tLearning Rate (w_theta): 0.001000\t TIME:5422.9s\n",
      "\t\t\t\tDisc: 0.347409\t\tSym: 11.402187\t\tSpars: 472.328674\n",
      "\t TVw: 0.242760 | TVb: -2.035803 | GSw: -0.234981 | GSb: 0.064973 | TSUw: 0.464880 | TSUb: 0.034845\n",
      "Validating epoch 2354...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 480.5342062968707\n",
      "Average validation loss: 88.21152260547676\n",
      "Training epoch 2355...\n",
      "\n",
      "Train Epoch: 2355 [0/8000 (0%)]\tBatch Loss: 501.315458\tLearning Rate (w_theta): 0.001000\t TIME:5425.3s\n",
      "\t\t\t\tDisc: 0.348635\t\tSym: 11.887691\t\tSpars: 489.079132\n",
      "\t TVw: 0.242722 | TVb: -2.035774 | GSw: -0.234981 | GSb: 0.064972 | TSUw: 0.464879 | TSUb: 0.034845\n",
      "\n",
      "Train Epoch: 2355 [4000/8000 (50%)]\tBatch Loss: 488.724415\tLearning Rate (w_theta): 0.001000\t TIME:5426.9s\n",
      "\t\t\t\tDisc: 0.339759\t\tSym: 10.942243\t\tSpars: 477.442413\n",
      "\t TVw: 0.242546 | TVb: -2.035759 | GSw: -0.234981 | GSb: 0.064972 | TSUw: 0.464879 | TSUb: 0.034845\n",
      "Validating epoch 2355...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 485.2794070781735\n",
      "Average validation loss: 95.425016776022\n",
      "Training epoch 2356...\n",
      "\n",
      "Train Epoch: 2356 [0/8000 (0%)]\tBatch Loss: 492.721813\tLearning Rate (w_theta): 0.001000\t TIME:5429.4s\n",
      "\t\t\t\tDisc: 0.306697\t\tSym: 11.030992\t\tSpars: 481.384125\n",
      "\t TVw: 0.242198 | TVb: -2.035761 | GSw: -0.234981 | GSb: 0.064972 | TSUw: 0.464879 | TSUb: 0.034846\n",
      "\n",
      "Train Epoch: 2356 [4000/8000 (50%)]\tBatch Loss: 486.849362\tLearning Rate (w_theta): 0.001000\t TIME:5430.9s\n",
      "\t\t\t\tDisc: 0.362810\t\tSym: 11.157297\t\tSpars: 475.329254\n",
      "\t TVw: 0.241892 | TVb: -2.035764 | GSw: -0.234981 | GSb: 0.064972 | TSUw: 0.464879 | TSUb: 0.034846\n",
      "Validating epoch 2356...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 485.13699829034977\n",
      "Average validation loss: 86.98256148709251\n",
      "Training epoch 2357...\n",
      "\n",
      "Train Epoch: 2357 [0/8000 (0%)]\tBatch Loss: 498.516108\tLearning Rate (w_theta): 0.001000\t TIME:5433.3s\n",
      "\t\t\t\tDisc: 0.373905\t\tSym: 12.775106\t\tSpars: 485.367096\n",
      "\t TVw: 0.241814 | TVb: -2.035758 | GSw: -0.234981 | GSb: 0.064972 | TSUw: 0.464879 | TSUb: 0.034846\n",
      "\n",
      "Train Epoch: 2357 [4000/8000 (50%)]\tBatch Loss: 500.467931\tLearning Rate (w_theta): 0.001000\t TIME:5434.9s\n",
      "\t\t\t\tDisc: 0.372409\t\tSym: 11.593173\t\tSpars: 488.502350\n",
      "\t TVw: 0.242001 | TVb: -2.035738 | GSw: -0.234981 | GSb: 0.064972 | TSUw: 0.464879 | TSUb: 0.034846\n",
      "Validating epoch 2357...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 478.09004367194143\n",
      "Average validation loss: 87.78446463221502\n",
      "Training epoch 2358...\n",
      "\n",
      "Train Epoch: 2358 [0/8000 (0%)]\tBatch Loss: 485.948667\tLearning Rate (w_theta): 0.001000\t TIME:5437.3s\n",
      "\t\t\t\tDisc: 0.366285\t\tSym: 11.446731\t\tSpars: 474.135651\n",
      "\t TVw: 0.242277 | TVb: -2.035708 | GSw: -0.234981 | GSb: 0.064971 | TSUw: 0.464879 | TSUb: 0.034846\n",
      "\n",
      "Train Epoch: 2358 [4000/8000 (50%)]\tBatch Loss: 483.277467\tLearning Rate (w_theta): 0.001000\t TIME:5438.9s\n",
      "\t\t\t\tDisc: 0.371396\t\tSym: 11.246799\t\tSpars: 471.659271\n",
      "\t TVw: 0.242589 | TVb: -2.035673 | GSw: -0.234981 | GSb: 0.064971 | TSUw: 0.464879 | TSUb: 0.034846\n",
      "Validating epoch 2358...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 476.7087599892624\n",
      "Average validation loss: 89.47373193553386\n",
      "Training epoch 2359...\n",
      "\n",
      "Train Epoch: 2359 [0/8000 (0%)]\tBatch Loss: 468.973788\tLearning Rate (w_theta): 0.001000\t TIME:5441.4s\n",
      "\t\t\t\tDisc: 0.309996\t\tSym: 10.695713\t\tSpars: 457.968079\n",
      "\t TVw: 0.242984 | TVb: -2.035634 | GSw: -0.234981 | GSb: 0.064971 | TSUw: 0.464878 | TSUb: 0.034846\n",
      "\n",
      "Train Epoch: 2359 [4000/8000 (50%)]\tBatch Loss: 489.981306\tLearning Rate (w_theta): 0.001000\t TIME:5443.0s\n",
      "\t\t\t\tDisc: 0.367537\t\tSym: 11.306274\t\tSpars: 478.307495\n",
      "\t TVw: 0.243306 | TVb: -2.035594 | GSw: -0.234981 | GSb: 0.064971 | TSUw: 0.464878 | TSUb: 0.034846\n",
      "Validating epoch 2359...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 474.3344355423546\n",
      "Average validation loss: 90.82555221944065\n",
      "Training epoch 2360...\n",
      "\n",
      "Train Epoch: 2360 [0/8000 (0%)]\tBatch Loss: 472.850559\tLearning Rate (w_theta): 0.001000\t TIME:5445.7s\n",
      "\t\t\t\tDisc: 0.367654\t\tSym: 10.549373\t\tSpars: 461.933533\n",
      "\t TVw: 0.243529 | TVb: -2.035556 | GSw: -0.234981 | GSb: 0.064971 | TSUw: 0.464878 | TSUb: 0.034847\n",
      "\n",
      "Train Epoch: 2360 [4000/8000 (50%)]\tBatch Loss: 459.405580\tLearning Rate (w_theta): 0.001000\t TIME:5447.3s\n",
      "\t\t\t\tDisc: 0.363258\t\tSym: 10.556360\t\tSpars: 448.485962\n",
      "\t TVw: 0.243452 | TVb: -2.035530 | GSw: -0.234981 | GSb: 0.064971 | TSUw: 0.464878 | TSUb: 0.034847\n",
      "Validating epoch 2360...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 472.73323165677556\n",
      "Average validation loss: 91.99060077874076\n",
      "Training epoch 2361...\n",
      "\n",
      "Train Epoch: 2361 [0/8000 (0%)]\tBatch Loss: 458.402291\tLearning Rate (w_theta): 0.001000\t TIME:5450.4s\n",
      "\t\t\t\tDisc: 0.337914\t\tSym: 9.392471\t\tSpars: 448.671906\n",
      "\t TVw: 0.243375 | TVb: -2.035505 | GSw: -0.234982 | GSb: 0.064971 | TSUw: 0.464878 | TSUb: 0.034847\n",
      "\n",
      "Train Epoch: 2361 [4000/8000 (50%)]\tBatch Loss: 471.496915\tLearning Rate (w_theta): 0.001000\t TIME:5452.0s\n",
      "\t\t\t\tDisc: 0.346122\t\tSym: 10.901709\t\tSpars: 460.249084\n",
      "\t TVw: 0.243331 | TVb: -2.035480 | GSw: -0.234982 | GSb: 0.064970 | TSUw: 0.464878 | TSUb: 0.034847\n",
      "Validating epoch 2361...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 472.8697029362182\n",
      "Average validation loss: 89.8686114375181\n",
      "Training epoch 2362...\n",
      "\n",
      "Train Epoch: 2362 [0/8000 (0%)]\tBatch Loss: 491.525861\tLearning Rate (w_theta): 0.001000\t TIME:5454.4s\n",
      "\t\t\t\tDisc: 0.366140\t\tSym: 11.893944\t\tSpars: 479.265778\n",
      "\t TVw: 0.243209 | TVb: -2.035463 | GSw: -0.234982 | GSb: 0.064970 | TSUw: 0.464878 | TSUb: 0.034847\n",
      "\n",
      "Train Epoch: 2362 [4000/8000 (50%)]\tBatch Loss: 450.346259\tLearning Rate (w_theta): 0.001000\t TIME:5456.0s\n",
      "\t\t\t\tDisc: 0.317295\t\tSym: 9.432284\t\tSpars: 440.596680\n",
      "\t TVw: 0.243036 | TVb: -2.035450 | GSw: -0.234982 | GSb: 0.064970 | TSUw: 0.464878 | TSUb: 0.034847\n",
      "Validating epoch 2362...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 473.9472880023843\n",
      "Average validation loss: 91.58593861794085\n",
      "Training epoch 2363...\n",
      "\n",
      "Train Epoch: 2363 [0/8000 (0%)]\tBatch Loss: 482.315369\tLearning Rate (w_theta): 0.001000\t TIME:5458.5s\n",
      "\t\t\t\tDisc: 0.357549\t\tSym: 11.496394\t\tSpars: 470.461426\n",
      "\t TVw: 0.242734 | TVb: -2.035447 | GSw: -0.234982 | GSb: 0.064970 | TSUw: 0.464878 | TSUb: 0.034847\n",
      "\n",
      "Train Epoch: 2363 [4000/8000 (50%)]\tBatch Loss: 484.250646\tLearning Rate (w_theta): 0.001000\t TIME:5460.0s\n",
      "\t\t\t\tDisc: 0.375578\t\tSym: 11.816199\t\tSpars: 472.058868\n",
      "\t TVw: 0.242682 | TVb: -2.035434 | GSw: -0.234982 | GSb: 0.064970 | TSUw: 0.464877 | TSUb: 0.034847\n",
      "Validating epoch 2363...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 470.73968552439726\n",
      "Average validation loss: 89.71875946934726\n",
      "Training epoch 2364...\n",
      "\n",
      "Train Epoch: 2364 [0/8000 (0%)]\tBatch Loss: 463.766616\tLearning Rate (w_theta): 0.001000\t TIME:5462.5s\n",
      "\t\t\t\tDisc: 0.333576\t\tSym: 10.319973\t\tSpars: 453.113068\n",
      "\t TVw: 0.242790 | TVb: -2.035414 | GSw: -0.234982 | GSb: 0.064970 | TSUw: 0.464877 | TSUb: 0.034847\n",
      "\n",
      "Train Epoch: 2364 [4000/8000 (50%)]\tBatch Loss: 478.949424\tLearning Rate (w_theta): 0.001000\t TIME:5464.1s\n",
      "\t\t\t\tDisc: 0.342574\t\tSym: 11.069679\t\tSpars: 467.537170\n",
      "\t TVw: 0.242869 | TVb: -2.035390 | GSw: -0.234982 | GSb: 0.064970 | TSUw: 0.464877 | TSUb: 0.034848\n",
      "Validating epoch 2364...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 469.51212565154236\n",
      "Average validation loss: 89.59056186059213\n",
      "Training epoch 2365...\n",
      "\n",
      "Train Epoch: 2365 [0/8000 (0%)]\tBatch Loss: 505.675588\tLearning Rate (w_theta): 0.001000\t TIME:5466.5s\n",
      "\t\t\t\tDisc: 0.386816\t\tSym: 12.325881\t\tSpars: 492.962891\n",
      "\t TVw: 0.242933 | TVb: -2.035365 | GSw: -0.234982 | GSb: 0.064969 | TSUw: 0.464877 | TSUb: 0.034848\n",
      "\n",
      "Train Epoch: 2365 [4000/8000 (50%)]\tBatch Loss: 452.977067\tLearning Rate (w_theta): 0.001000\t TIME:5468.1s\n",
      "\t\t\t\tDisc: 0.342318\t\tSym: 9.669570\t\tSpars: 442.965179\n",
      "\t TVw: 0.242976 | TVb: -2.035340 | GSw: -0.234982 | GSb: 0.064969 | TSUw: 0.464877 | TSUb: 0.034848\n",
      "Validating epoch 2365...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 468.9214392026224\n",
      "Average validation loss: 91.01219321480615\n",
      "Training epoch 2366...\n",
      "\n",
      "Train Epoch: 2366 [0/8000 (0%)]\tBatch Loss: 470.222746\tLearning Rate (w_theta): 0.001000\t TIME:5470.6s\n",
      "\t\t\t\tDisc: 0.389433\t\tSym: 10.857758\t\tSpars: 458.975555\n",
      "\t TVw: 0.243138 | TVb: -2.035309 | GSw: -0.234982 | GSb: 0.064969 | TSUw: 0.464877 | TSUb: 0.034848\n",
      "\n",
      "Train Epoch: 2366 [4000/8000 (50%)]\tBatch Loss: 475.086469\tLearning Rate (w_theta): 0.001000\t TIME:5472.1s\n",
      "\t\t\t\tDisc: 0.352923\t\tSym: 11.079646\t\tSpars: 463.653900\n",
      "\t TVw: 0.243246 | TVb: -2.035278 | GSw: -0.234982 | GSb: 0.064969 | TSUw: 0.464877 | TSUb: 0.034848\n",
      "Validating epoch 2366...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 467.56546834538193\n",
      "Average validation loss: 91.54224353394854\n",
      "Training epoch 2367...\n",
      "\n",
      "Train Epoch: 2367 [0/8000 (0%)]\tBatch Loss: 449.850637\tLearning Rate (w_theta): 0.001000\t TIME:5474.7s\n",
      "\t\t\t\tDisc: 0.324861\t\tSym: 9.370838\t\tSpars: 440.154938\n",
      "\t TVw: 0.243217 | TVb: -2.035257 | GSw: -0.234982 | GSb: 0.064969 | TSUw: 0.464877 | TSUb: 0.034848\n",
      "\n",
      "Train Epoch: 2367 [4000/8000 (50%)]\tBatch Loss: 468.026852\tLearning Rate (w_theta): 0.001000\t TIME:5476.2s\n",
      "\t\t\t\tDisc: 0.321008\t\tSym: 10.944095\t\tSpars: 456.761749\n",
      "\t TVw: 0.243297 | TVb: -2.035238 | GSw: -0.234982 | GSb: 0.064969 | TSUw: 0.464876 | TSUb: 0.034848\n",
      "Validating epoch 2367...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 470.0855440004975\n",
      "Average validation loss: 96.33100769030065\n",
      "Training epoch 2368...\n",
      "\n",
      "Train Epoch: 2368 [0/8000 (0%)]\tBatch Loss: 480.722666\tLearning Rate (w_theta): 0.001000\t TIME:5478.7s\n",
      "\t\t\t\tDisc: 0.332975\t\tSym: 10.732800\t\tSpars: 469.656891\n",
      "\t TVw: 0.243250 | TVb: -2.035230 | GSw: -0.234982 | GSb: 0.064969 | TSUw: 0.464876 | TSUb: 0.034848\n",
      "\n",
      "Train Epoch: 2368 [4000/8000 (50%)]\tBatch Loss: 469.773943\tLearning Rate (w_theta): 0.001000\t TIME:5480.2s\n",
      "\t\t\t\tDisc: 0.329957\t\tSym: 10.425675\t\tSpars: 459.018311\n",
      "\t TVw: 0.242684 | TVb: -2.035256 | GSw: -0.234982 | GSb: 0.064968 | TSUw: 0.464876 | TSUb: 0.034849\n",
      "Validating epoch 2368...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 489.43084297899577\n",
      "Average validation loss: 86.58723751795652\n",
      "Training epoch 2369...\n",
      "\n",
      "Train Epoch: 2369 [0/8000 (0%)]\tBatch Loss: 475.563486\tLearning Rate (w_theta): 0.001000\t TIME:5482.7s\n",
      "\t\t\t\tDisc: 0.314375\t\tSym: 11.165920\t\tSpars: 464.083191\n",
      "\t TVw: 0.242210 | TVb: -2.035285 | GSw: -0.234983 | GSb: 0.064968 | TSUw: 0.464876 | TSUb: 0.034849\n",
      "\n",
      "Train Epoch: 2369 [4000/8000 (50%)]\tBatch Loss: 525.434216\tLearning Rate (w_theta): 0.001000\t TIME:5484.2s\n",
      "\t\t\t\tDisc: 0.319778\t\tSym: 12.730283\t\tSpars: 512.384155\n",
      "\t TVw: 0.242032 | TVb: -2.035307 | GSw: -0.234983 | GSb: 0.064968 | TSUw: 0.464876 | TSUb: 0.034849\n",
      "Validating epoch 2369...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 505.3174148294685\n",
      "Average validation loss: 84.02654200975155\n",
      "Training epoch 2370...\n",
      "\n",
      "Train Epoch: 2370 [0/8000 (0%)]\tBatch Loss: 486.711556\tLearning Rate (w_theta): 0.001000\t TIME:5486.7s\n",
      "\t\t\t\tDisc: 0.311314\t\tSym: 11.886234\t\tSpars: 474.514008\n",
      "\t TVw: 0.241759 | TVb: -2.035336 | GSw: -0.234983 | GSb: 0.064968 | TSUw: 0.464876 | TSUb: 0.034849\n",
      "\n",
      "Train Epoch: 2370 [4000/8000 (50%)]\tBatch Loss: 492.171893\tLearning Rate (w_theta): 0.001000\t TIME:5488.3s\n",
      "\t\t\t\tDisc: 0.342606\t\tSym: 11.373446\t\tSpars: 480.455841\n",
      "\t TVw: 0.241779 | TVb: -2.035352 | GSw: -0.234983 | GSb: 0.064968 | TSUw: 0.464876 | TSUb: 0.034849\n",
      "Validating epoch 2370...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 513.4602825643666\n",
      "Average validation loss: 87.94657932254835\n",
      "Training epoch 2371...\n",
      "\n",
      "Train Epoch: 2371 [0/8000 (0%)]\tBatch Loss: 468.166668\tLearning Rate (w_theta): 0.001000\t TIME:5491.8s\n",
      "\t\t\t\tDisc: 0.291085\t\tSym: 9.692111\t\tSpars: 458.183472\n",
      "\t TVw: 0.242108 | TVb: -2.035363 | GSw: -0.234983 | GSb: 0.064968 | TSUw: 0.464876 | TSUb: 0.034849\n",
      "\n",
      "Train Epoch: 2371 [4000/8000 (50%)]\tBatch Loss: 578.457850\tLearning Rate (w_theta): 0.001000\t TIME:5493.4s\n",
      "\t\t\t\tDisc: 0.475406\t\tSym: 11.927878\t\tSpars: 566.054565\n",
      "\t TVw: 0.243376 | TVb: -2.035333 | GSw: -0.234983 | GSb: 0.064967 | TSUw: 0.464875 | TSUb: 0.034849\n",
      "Validating epoch 2371...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 555.4471430564851\n",
      "Average validation loss: 91.05325001177127\n",
      "Training epoch 2372...\n",
      "\n",
      "Train Epoch: 2372 [0/8000 (0%)]\tBatch Loss: 490.630376\tLearning Rate (w_theta): 0.001000\t TIME:5495.8s\n",
      "\t\t\t\tDisc: 0.262987\t\tSym: 11.030078\t\tSpars: 479.337311\n",
      "\t TVw: 0.245541 | TVb: -2.035263 | GSw: -0.234983 | GSb: 0.064967 | TSUw: 0.464875 | TSUb: 0.034850\n",
      "\n",
      "Train Epoch: 2372 [4000/8000 (50%)]\tBatch Loss: 546.986273\tLearning Rate (w_theta): 0.001000\t TIME:5497.4s\n",
      "\t\t\t\tDisc: 0.375252\t\tSym: 12.229063\t\tSpars: 534.381958\n",
      "\t TVw: 0.247735 | TVb: -2.035225 | GSw: -0.234983 | GSb: 0.064967 | TSUw: 0.464875 | TSUb: 0.034850\n",
      "Validating epoch 2372...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 516.0453111046946\n",
      "Average validation loss: 88.96821933025925\n",
      "Training epoch 2373...\n",
      "\n",
      "Train Epoch: 2373 [0/8000 (0%)]\tBatch Loss: 476.530552\tLearning Rate (w_theta): 0.001000\t TIME:5499.9s\n",
      "\t\t\t\tDisc: 0.320222\t\tSym: 10.957492\t\tSpars: 465.252838\n",
      "\t TVw: 0.250816 | TVb: -2.035141 | GSw: -0.234983 | GSb: 0.064967 | TSUw: 0.464875 | TSUb: 0.034850\n",
      "\n",
      "Train Epoch: 2373 [4000/8000 (50%)]\tBatch Loss: 477.640542\tLearning Rate (w_theta): 0.001000\t TIME:5501.4s\n",
      "\t\t\t\tDisc: 0.320513\t\tSym: 10.674033\t\tSpars: 466.645996\n",
      "\t TVw: 0.253825 | TVb: -2.035046 | GSw: -0.234983 | GSb: 0.064967 | TSUw: 0.464875 | TSUb: 0.034850\n",
      "Validating epoch 2373...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 486.27445217264983\n",
      "Average validation loss: 99.24571724721754\n",
      "Training epoch 2374...\n",
      "\n",
      "Train Epoch: 2374 [0/8000 (0%)]\tBatch Loss: 515.797161\tLearning Rate (w_theta): 0.001000\t TIME:5503.8s\n",
      "\t\t\t\tDisc: 0.379019\t\tSym: 12.025839\t\tSpars: 503.392303\n",
      "\t TVw: 0.256153 | TVb: -2.034964 | GSw: -0.234983 | GSb: 0.064966 | TSUw: 0.464875 | TSUb: 0.034850\n",
      "\n",
      "Train Epoch: 2374 [4000/8000 (50%)]\tBatch Loss: 524.772908\tLearning Rate (w_theta): 0.001000\t TIME:5505.4s\n",
      "\t\t\t\tDisc: 0.381918\t\tSym: 12.270080\t\tSpars: 512.120911\n",
      "\t TVw: 0.257448 | TVb: -2.034909 | GSw: -0.234983 | GSb: 0.064966 | TSUw: 0.464874 | TSUb: 0.034850\n",
      "Validating epoch 2374...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 492.19685285192094\n",
      "Average validation loss: 100.37955144171437\n",
      "Training epoch 2375...\n",
      "\n",
      "Train Epoch: 2375 [0/8000 (0%)]\tBatch Loss: 504.555325\tLearning Rate (w_theta): 0.001000\t TIME:5507.9s\n",
      "\t\t\t\tDisc: 0.372634\t\tSym: 11.363417\t\tSpars: 492.819275\n",
      "\t TVw: 0.258649 | TVb: -2.034847 | GSw: -0.234983 | GSb: 0.064966 | TSUw: 0.464874 | TSUb: 0.034851\n",
      "\n",
      "Train Epoch: 2375 [4000/8000 (50%)]\tBatch Loss: 458.944535\tLearning Rate (w_theta): 0.001000\t TIME:5509.5s\n",
      "\t\t\t\tDisc: 0.363392\t\tSym: 10.913297\t\tSpars: 447.667847\n",
      "\t TVw: 0.259648 | TVb: -2.034807 | GSw: -0.234983 | GSb: 0.064966 | TSUw: 0.464874 | TSUb: 0.034851\n",
      "Validating epoch 2375...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 487.40923277370837\n",
      "Average validation loss: 86.27019918818948\n",
      "Training epoch 2376...\n",
      "\n",
      "Train Epoch: 2376 [0/8000 (0%)]\tBatch Loss: 496.113629\tLearning Rate (w_theta): 0.001000\t TIME:5511.9s\n",
      "\t\t\t\tDisc: 0.374063\t\tSym: 12.021976\t\tSpars: 483.717590\n",
      "\t TVw: 0.260717 | TVb: -2.034769 | GSw: -0.234983 | GSb: 0.064966 | TSUw: 0.464874 | TSUb: 0.034851\n",
      "\n",
      "Train Epoch: 2376 [4000/8000 (50%)]\tBatch Loss: 462.017601\tLearning Rate (w_theta): 0.001000\t TIME:5513.5s\n",
      "\t\t\t\tDisc: 0.335851\t\tSym: 9.890703\t\tSpars: 451.791046\n",
      "\t TVw: 0.261154 | TVb: -2.034755 | GSw: -0.234983 | GSb: 0.064965 | TSUw: 0.464874 | TSUb: 0.034851\n",
      "Validating epoch 2376...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 484.1770111954119\n",
      "Average validation loss: 82.55335817197819\n",
      "Training epoch 2377...\n",
      "\n",
      "Train Epoch: 2377 [0/8000 (0%)]\tBatch Loss: 531.831013\tLearning Rate (w_theta): 0.001000\t TIME:5515.9s\n",
      "\t\t\t\tDisc: 0.447896\t\tSym: 11.184325\t\tSpars: 520.198792\n",
      "\t TVw: 0.260969 | TVb: -2.034771 | GSw: -0.234983 | GSb: 0.064965 | TSUw: 0.464874 | TSUb: 0.034851\n",
      "\n",
      "Train Epoch: 2377 [4000/8000 (50%)]\tBatch Loss: 447.724262\tLearning Rate (w_theta): 0.001000\t TIME:5517.5s\n",
      "\t\t\t\tDisc: 0.399762\t\tSym: 10.248115\t\tSpars: 437.076385\n",
      "\t TVw: 0.261330 | TVb: -2.034762 | GSw: -0.234984 | GSb: 0.064965 | TSUw: 0.464874 | TSUb: 0.034851\n",
      "Validating epoch 2377...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 495.9311426994416\n",
      "Average validation loss: 99.89603292587611\n",
      "Training epoch 2378...\n",
      "\n",
      "Train Epoch: 2378 [0/8000 (0%)]\tBatch Loss: 478.172196\tLearning Rate (w_theta): 0.001000\t TIME:5519.9s\n",
      "\t\t\t\tDisc: 0.368021\t\tSym: 10.485267\t\tSpars: 467.318909\n",
      "\t TVw: 0.262213 | TVb: -2.034721 | GSw: -0.234984 | GSb: 0.064965 | TSUw: 0.464874 | TSUb: 0.034852\n",
      "\n",
      "Train Epoch: 2378 [4000/8000 (50%)]\tBatch Loss: 479.503716\tLearning Rate (w_theta): 0.001000\t TIME:5521.5s\n",
      "\t\t\t\tDisc: 0.386466\t\tSym: 10.455262\t\tSpars: 468.661987\n",
      "\t TVw: 0.263297 | TVb: -2.034669 | GSw: -0.234984 | GSb: 0.064965 | TSUw: 0.464873 | TSUb: 0.034852\n",
      "Validating epoch 2378...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 481.8880487916119\n",
      "Average validation loss: 97.02692998322539\n",
      "Training epoch 2379...\n",
      "\n",
      "Train Epoch: 2379 [0/8000 (0%)]\tBatch Loss: 488.846889\tLearning Rate (w_theta): 0.001000\t TIME:5524.0s\n",
      "\t\t\t\tDisc: 0.377960\t\tSym: 11.934658\t\tSpars: 476.534271\n",
      "\t TVw: 0.264295 | TVb: -2.034620 | GSw: -0.234984 | GSb: 0.064965 | TSUw: 0.464873 | TSUb: 0.034852\n",
      "\n",
      "Train Epoch: 2379 [4000/8000 (50%)]\tBatch Loss: 469.514737\tLearning Rate (w_theta): 0.001000\t TIME:5525.6s\n",
      "\t\t\t\tDisc: 0.364276\t\tSym: 11.259470\t\tSpars: 457.890991\n",
      "\t TVw: 0.264500 | TVb: -2.034594 | GSw: -0.234984 | GSb: 0.064964 | TSUw: 0.464873 | TSUb: 0.034852\n",
      "Validating epoch 2379...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 497.2676064324007\n",
      "Average validation loss: 81.92410905409875\n",
      "Training epoch 2380...\n",
      "\n",
      "Train Epoch: 2380 [0/8000 (0%)]\tBatch Loss: 551.176791\tLearning Rate (w_theta): 0.001000\t TIME:5528.0s\n",
      "\t\t\t\tDisc: 0.481807\t\tSym: 12.957252\t\tSpars: 537.737732\n",
      "\t TVw: 0.264712 | TVb: -2.034589 | GSw: -0.234984 | GSb: 0.064964 | TSUw: 0.464873 | TSUb: 0.034852\n",
      "\n",
      "Train Epoch: 2380 [4000/8000 (50%)]\tBatch Loss: 474.204026\tLearning Rate (w_theta): 0.001000\t TIME:5529.6s\n",
      "\t\t\t\tDisc: 0.359744\t\tSym: 10.522871\t\tSpars: 463.321411\n",
      "\t TVw: 0.264500 | TVb: -2.034611 | GSw: -0.234984 | GSb: 0.064964 | TSUw: 0.464873 | TSUb: 0.034852\n",
      "Validating epoch 2380...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 532.7026695613877\n",
      "Average validation loss: 104.86492159832804\n",
      "Training epoch 2381...\n",
      "\n",
      "Train Epoch: 2381 [0/8000 (0%)]\tBatch Loss: 541.950797\tLearning Rate (w_theta): 0.001000\t TIME:5532.7s\n",
      "\t\t\t\tDisc: 0.435223\t\tSym: 12.606638\t\tSpars: 528.908936\n",
      "\t TVw: 0.265411 | TVb: -2.034570 | GSw: -0.234984 | GSb: 0.064964 | TSUw: 0.464873 | TSUb: 0.034852\n",
      "\n",
      "Train Epoch: 2381 [4000/8000 (50%)]\tBatch Loss: 468.928243\tLearning Rate (w_theta): 0.001000\t TIME:5534.2s\n",
      "\t\t\t\tDisc: 0.358383\t\tSym: 10.561193\t\tSpars: 458.008667\n",
      "\t TVw: 0.266787 | TVb: -2.034527 | GSw: -0.234984 | GSb: 0.064964 | TSUw: 0.464873 | TSUb: 0.034853\n",
      "Validating epoch 2381...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 498.2045476292851\n",
      "Average validation loss: 85.33778645445925\n",
      "Training epoch 2382...\n",
      "\n",
      "Train Epoch: 2382 [0/8000 (0%)]\tBatch Loss: 481.368698\tLearning Rate (w_theta): 0.001000\t TIME:5537.1s\n",
      "\t\t\t\tDisc: 0.318713\t\tSym: 11.169126\t\tSpars: 469.880859\n",
      "\t TVw: 0.267810 | TVb: -2.034499 | GSw: -0.234984 | GSb: 0.064963 | TSUw: 0.464872 | TSUb: 0.034853\n",
      "\n",
      "Train Epoch: 2382 [4000/8000 (50%)]\tBatch Loss: 539.238034\tLearning Rate (w_theta): 0.001000\t TIME:5538.7s\n",
      "\t\t\t\tDisc: 0.511076\t\tSym: 12.148161\t\tSpars: 526.578796\n",
      "\t TVw: 0.268046 | TVb: -2.034504 | GSw: -0.234984 | GSb: 0.064963 | TSUw: 0.464872 | TSUb: 0.034853\n",
      "Validating epoch 2382...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 495.223473557636\n",
      "Average validation loss: 94.87099776226147\n",
      "Training epoch 2383...\n",
      "\n",
      "Train Epoch: 2383 [0/8000 (0%)]\tBatch Loss: 450.063044\tLearning Rate (w_theta): 0.001000\t TIME:5541.1s\n",
      "\t\t\t\tDisc: 0.358287\t\tSym: 9.641189\t\tSpars: 440.063568\n",
      "\t TVw: 0.268852 | TVb: -2.034472 | GSw: -0.234984 | GSb: 0.064963 | TSUw: 0.464872 | TSUb: 0.034853\n",
      "\n",
      "Train Epoch: 2383 [4000/8000 (50%)]\tBatch Loss: 451.696718\tLearning Rate (w_theta): 0.001000\t TIME:5542.7s\n",
      "\t\t\t\tDisc: 0.380983\t\tSym: 9.836395\t\tSpars: 441.479340\n",
      "\t TVw: 0.270182 | TVb: -2.034400 | GSw: -0.234984 | GSb: 0.064963 | TSUw: 0.464872 | TSUb: 0.034853\n",
      "Validating epoch 2383...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 468.69828173135124\n",
      "Average validation loss: 93.47000670001026\n",
      "Training epoch 2384...\n",
      "\n",
      "Train Epoch: 2384 [0/8000 (0%)]\tBatch Loss: 472.945420\tLearning Rate (w_theta): 0.001000\t TIME:5545.1s\n",
      "\t\t\t\tDisc: 0.384402\t\tSym: 11.629377\t\tSpars: 460.931641\n",
      "\t TVw: 0.271840 | TVb: -2.034323 | GSw: -0.234984 | GSb: 0.064963 | TSUw: 0.464872 | TSUb: 0.034853\n",
      "\n",
      "Train Epoch: 2384 [4000/8000 (50%)]\tBatch Loss: 439.287909\tLearning Rate (w_theta): 0.001000\t TIME:5546.7s\n",
      "\t\t\t\tDisc: 0.383159\t\tSym: 9.919581\t\tSpars: 428.985168\n",
      "\t TVw: 0.273176 | TVb: -2.034254 | GSw: -0.234984 | GSb: 0.064963 | TSUw: 0.464872 | TSUb: 0.034854\n",
      "Validating epoch 2384...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 458.21253933298794\n",
      "Average validation loss: 92.73211641202239\n",
      "Training epoch 2385...\n",
      "\n",
      "Train Epoch: 2385 [0/8000 (0%)]\tBatch Loss: 451.455062\tLearning Rate (w_theta): 0.001000\t TIME:5549.1s\n",
      "\t\t\t\tDisc: 0.402178\t\tSym: 10.697202\t\tSpars: 440.355682\n",
      "\t TVw: 0.274209 | TVb: -2.034171 | GSw: -0.234984 | GSb: 0.064962 | TSUw: 0.464872 | TSUb: 0.034854\n",
      "\n",
      "Train Epoch: 2385 [4000/8000 (50%)]\tBatch Loss: 441.448612\tLearning Rate (w_theta): 0.001000\t TIME:5550.7s\n",
      "\t\t\t\tDisc: 0.414085\t\tSym: 9.779522\t\tSpars: 431.255005\n",
      "\t TVw: 0.274788 | TVb: -2.034101 | GSw: -0.234984 | GSb: 0.064962 | TSUw: 0.464871 | TSUb: 0.034854\n",
      "Validating epoch 2385...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 454.77278126233597\n",
      "Average validation loss: 97.44248120382355\n",
      "Training epoch 2386...\n",
      "\n",
      "Train Epoch: 2386 [0/8000 (0%)]\tBatch Loss: 442.914908\tLearning Rate (w_theta): 0.001000\t TIME:5553.1s\n",
      "\t\t\t\tDisc: 0.401281\t\tSym: 9.856766\t\tSpars: 432.656860\n",
      "\t TVw: 0.274918 | TVb: -2.034047 | GSw: -0.234985 | GSb: 0.064962 | TSUw: 0.464871 | TSUb: 0.034854\n",
      "\n",
      "Train Epoch: 2386 [4000/8000 (50%)]\tBatch Loss: 463.312613\tLearning Rate (w_theta): 0.001000\t TIME:5554.7s\n",
      "\t\t\t\tDisc: 0.413345\t\tSym: 11.062934\t\tSpars: 451.836334\n",
      "\t TVw: 0.274719 | TVb: -2.034014 | GSw: -0.234985 | GSb: 0.064962 | TSUw: 0.464871 | TSUb: 0.034854\n",
      "Validating epoch 2386...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 463.60246022882495\n",
      "Average validation loss: 98.11977156103845\n",
      "Training epoch 2387...\n",
      "\n",
      "Train Epoch: 2387 [0/8000 (0%)]\tBatch Loss: 461.521167\tLearning Rate (w_theta): 0.001000\t TIME:5557.2s\n",
      "\t\t\t\tDisc: 0.405876\t\tSym: 10.891139\t\tSpars: 450.224152\n",
      "\t TVw: 0.274142 | TVb: -2.034009 | GSw: -0.234985 | GSb: 0.064962 | TSUw: 0.464871 | TSUb: 0.034854\n",
      "\n",
      "Train Epoch: 2387 [4000/8000 (50%)]\tBatch Loss: 458.046573\tLearning Rate (w_theta): 0.001000\t TIME:5558.7s\n",
      "\t\t\t\tDisc: 0.371019\t\tSym: 10.897692\t\tSpars: 446.777863\n",
      "\t TVw: 0.273384 | TVb: -2.034013 | GSw: -0.234985 | GSb: 0.064961 | TSUw: 0.464871 | TSUb: 0.034854\n",
      "Validating epoch 2387...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 465.0182006117195\n",
      "Average validation loss: 94.66503168332773\n",
      "Training epoch 2388...\n",
      "\n",
      "Train Epoch: 2388 [0/8000 (0%)]\tBatch Loss: 436.438918\tLearning Rate (w_theta): 0.001000\t TIME:5561.2s\n",
      "\t\t\t\tDisc: 0.368297\t\tSym: 9.459568\t\tSpars: 426.611053\n",
      "\t TVw: 0.272393 | TVb: -2.034036 | GSw: -0.234985 | GSb: 0.064961 | TSUw: 0.464871 | TSUb: 0.034855\n",
      "\n",
      "Train Epoch: 2388 [4000/8000 (50%)]\tBatch Loss: 450.826490\tLearning Rate (w_theta): 0.001000\t TIME:5562.8s\n",
      "\t\t\t\tDisc: 0.381838\t\tSym: 10.920238\t\tSpars: 439.524414\n",
      "\t TVw: 0.271916 | TVb: -2.034040 | GSw: -0.234985 | GSb: 0.064961 | TSUw: 0.464871 | TSUb: 0.034855\n",
      "Validating epoch 2388...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 453.62543953882033\n",
      "Average validation loss: 89.25213104305216\n",
      "Training epoch 2389...\n",
      "\n",
      "Train Epoch: 2389 [0/8000 (0%)]\tBatch Loss: 456.968782\tLearning Rate (w_theta): 0.001000\t TIME:5565.2s\n",
      "\t\t\t\tDisc: 0.348210\t\tSym: 11.071317\t\tSpars: 445.549255\n",
      "\t TVw: 0.271699 | TVb: -2.034021 | GSw: -0.234985 | GSb: 0.064961 | TSUw: 0.464871 | TSUb: 0.034855\n",
      "\n",
      "Train Epoch: 2389 [4000/8000 (50%)]\tBatch Loss: 456.004483\tLearning Rate (w_theta): 0.001000\t TIME:5566.8s\n",
      "\t\t\t\tDisc: 0.357759\t\tSym: 11.207516\t\tSpars: 444.439209\n",
      "\t TVw: 0.271765 | TVb: -2.033981 | GSw: -0.234985 | GSb: 0.064961 | TSUw: 0.464871 | TSUb: 0.034855\n",
      "Validating epoch 2389...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 451.07804934508147\n",
      "Average validation loss: 90.7606973367142\n",
      "Training epoch 2390...\n",
      "\n",
      "Train Epoch: 2390 [0/8000 (0%)]\tBatch Loss: 439.393432\tLearning Rate (w_theta): 0.001000\t TIME:5569.3s\n",
      "\t\t\t\tDisc: 0.364815\t\tSym: 10.046256\t\tSpars: 428.982361\n",
      "\t TVw: 0.271825 | TVb: -2.033935 | GSw: -0.234985 | GSb: 0.064961 | TSUw: 0.464870 | TSUb: 0.034855\n",
      "\n",
      "Train Epoch: 2390 [4000/8000 (50%)]\tBatch Loss: 438.765808\tLearning Rate (w_theta): 0.001000\t TIME:5570.8s\n",
      "\t\t\t\tDisc: 0.375596\t\tSym: 10.448836\t\tSpars: 427.941376\n",
      "\t TVw: 0.271828 | TVb: -2.033880 | GSw: -0.234985 | GSb: 0.064960 | TSUw: 0.464870 | TSUb: 0.034855\n",
      "Validating epoch 2390...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 447.9804659118048\n",
      "Average validation loss: 92.65356415445736\n",
      "Training epoch 2391...\n",
      "\n",
      "Train Epoch: 2391 [0/8000 (0%)]\tBatch Loss: 456.844507\tLearning Rate (w_theta): 0.001000\t TIME:5574.0s\n",
      "\t\t\t\tDisc: 0.373822\t\tSym: 11.492108\t\tSpars: 444.978577\n",
      "\t TVw: 0.271804 | TVb: -2.033825 | GSw: -0.234985 | GSb: 0.064960 | TSUw: 0.464870 | TSUb: 0.034855\n",
      "\n",
      "Train Epoch: 2391 [4000/8000 (50%)]\tBatch Loss: 457.940719\tLearning Rate (w_theta): 0.001000\t TIME:5575.5s\n",
      "\t\t\t\tDisc: 0.389865\t\tSym: 12.005749\t\tSpars: 445.545105\n",
      "\t TVw: 0.271728 | TVb: -2.033777 | GSw: -0.234985 | GSb: 0.064960 | TSUw: 0.464870 | TSUb: 0.034856\n",
      "Validating epoch 2391...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 445.69703823111485\n",
      "Average validation loss: 94.40909784472014\n",
      "Training epoch 2392...\n",
      "\n",
      "Train Epoch: 2392 [0/8000 (0%)]\tBatch Loss: 423.388426\tLearning Rate (w_theta): 0.001000\t TIME:5578.0s\n",
      "\t\t\t\tDisc: 0.351243\t\tSym: 9.304090\t\tSpars: 413.733093\n",
      "\t TVw: 0.271470 | TVb: -2.033733 | GSw: -0.234985 | GSb: 0.064960 | TSUw: 0.464870 | TSUb: 0.034856\n",
      "\n",
      "Train Epoch: 2392 [4000/8000 (50%)]\tBatch Loss: 432.450519\tLearning Rate (w_theta): 0.001000\t TIME:5579.6s\n",
      "\t\t\t\tDisc: 0.395111\t\tSym: 9.860217\t\tSpars: 422.195190\n",
      "\t TVw: 0.271152 | TVb: -2.033693 | GSw: -0.234985 | GSb: 0.064960 | TSUw: 0.464870 | TSUb: 0.034856\n",
      "Validating epoch 2392...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 444.5248509567051\n",
      "Average validation loss: 95.0708124586995\n",
      "Training epoch 2393...\n",
      "\n",
      "Train Epoch: 2393 [0/8000 (0%)]\tBatch Loss: 438.052091\tLearning Rate (w_theta): 0.001000\t TIME:5582.0s\n",
      "\t\t\t\tDisc: 0.380934\t\tSym: 10.369704\t\tSpars: 427.301453\n",
      "\t TVw: 0.270673 | TVb: -2.033662 | GSw: -0.234985 | GSb: 0.064960 | TSUw: 0.464870 | TSUb: 0.034856\n",
      "\n",
      "Train Epoch: 2393 [4000/8000 (50%)]\tBatch Loss: 454.585862\tLearning Rate (w_theta): 0.001000\t TIME:5583.6s\n",
      "\t\t\t\tDisc: 0.390006\t\tSym: 11.156153\t\tSpars: 443.039703\n",
      "\t TVw: 0.269977 | TVb: -2.033643 | GSw: -0.234985 | GSb: 0.064960 | TSUw: 0.464870 | TSUb: 0.034856\n",
      "Validating epoch 2393...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 447.5250347197094\n",
      "Average validation loss: 91.35517379354258\n",
      "Training epoch 2394...\n",
      "\n",
      "Train Epoch: 2394 [0/8000 (0%)]\tBatch Loss: 436.258380\tLearning Rate (w_theta): 0.001000\t TIME:5586.1s\n",
      "\t\t\t\tDisc: 0.355391\t\tSym: 10.385961\t\tSpars: 425.517029\n",
      "\t TVw: 0.269105 | TVb: -2.033640 | GSw: -0.234986 | GSb: 0.064959 | TSUw: 0.464869 | TSUb: 0.034856\n",
      "\n",
      "Train Epoch: 2394 [4000/8000 (50%)]\tBatch Loss: 455.251786\tLearning Rate (w_theta): 0.001000\t TIME:5587.6s\n",
      "\t\t\t\tDisc: 0.365036\t\tSym: 11.067079\t\tSpars: 443.819672\n",
      "\t TVw: 0.268408 | TVb: -2.033635 | GSw: -0.234986 | GSb: 0.064959 | TSUw: 0.464869 | TSUb: 0.034856\n",
      "Validating epoch 2394...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 447.113523625419\n",
      "Average validation loss: 90.63017857002853\n",
      "Training epoch 2395...\n",
      "\n",
      "Train Epoch: 2395 [0/8000 (0%)]\tBatch Loss: 429.068971\tLearning Rate (w_theta): 0.001000\t TIME:5590.4s\n",
      "\t\t\t\tDisc: 0.356383\t\tSym: 10.265200\t\tSpars: 418.447388\n",
      "\t TVw: 0.267816 | TVb: -2.033633 | GSw: -0.234986 | GSb: 0.064959 | TSUw: 0.464869 | TSUb: 0.034856\n",
      "\n",
      "Train Epoch: 2395 [4000/8000 (50%)]\tBatch Loss: 422.690822\tLearning Rate (w_theta): 0.001000\t TIME:5592.0s\n",
      "\t\t\t\tDisc: 0.359404\t\tSym: 9.934354\t\tSpars: 412.397064\n",
      "\t TVw: 0.267599 | TVb: -2.033615 | GSw: -0.234986 | GSb: 0.064959 | TSUw: 0.464869 | TSUb: 0.034857\n",
      "Validating epoch 2395...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 445.32734280633076\n",
      "Average validation loss: 91.30762594403488\n",
      "Training epoch 2396...\n",
      "\n",
      "Train Epoch: 2396 [0/8000 (0%)]\tBatch Loss: 460.666356\tLearning Rate (w_theta): 0.001000\t TIME:5594.4s\n",
      "\t\t\t\tDisc: 0.365174\t\tSym: 11.591802\t\tSpars: 448.709381\n",
      "\t TVw: 0.267563 | TVb: -2.033592 | GSw: -0.234986 | GSb: 0.064959 | TSUw: 0.464869 | TSUb: 0.034857\n",
      "\n",
      "Train Epoch: 2396 [4000/8000 (50%)]\tBatch Loss: 424.808561\tLearning Rate (w_theta): 0.001000\t TIME:5596.0s\n",
      "\t\t\t\tDisc: 0.354665\t\tSym: 9.668831\t\tSpars: 414.785065\n",
      "\t TVw: 0.267312 | TVb: -2.033581 | GSw: -0.234986 | GSb: 0.064959 | TSUw: 0.464869 | TSUb: 0.034857\n",
      "Validating epoch 2396...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 452.7048563428264\n",
      "Average validation loss: 86.70490593731243\n",
      "Training epoch 2397...\n",
      "\n",
      "Train Epoch: 2397 [0/8000 (0%)]\tBatch Loss: 453.535016\tLearning Rate (w_theta): 0.001000\t TIME:5598.4s\n",
      "\t\t\t\tDisc: 0.337734\t\tSym: 10.794450\t\tSpars: 442.402832\n",
      "\t TVw: 0.266883 | TVb: -2.033588 | GSw: -0.234986 | GSb: 0.064958 | TSUw: 0.464869 | TSUb: 0.034857\n",
      "\n",
      "Train Epoch: 2397 [4000/8000 (50%)]\tBatch Loss: 457.684053\tLearning Rate (w_theta): 0.001000\t TIME:5600.0s\n",
      "\t\t\t\tDisc: 0.375887\t\tSym: 11.255980\t\tSpars: 446.052185\n",
      "\t TVw: 0.266738 | TVb: -2.033591 | GSw: -0.234986 | GSb: 0.064958 | TSUw: 0.464869 | TSUb: 0.034857\n",
      "Validating epoch 2397...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 456.8917639090228\n",
      "Average validation loss: 90.28401312212753\n",
      "Training epoch 2398...\n",
      "\n",
      "Train Epoch: 2398 [0/8000 (0%)]\tBatch Loss: 441.950446\tLearning Rate (w_theta): 0.001000\t TIME:5602.5s\n",
      "\t\t\t\tDisc: 0.354660\t\tSym: 10.843467\t\tSpars: 430.752319\n",
      "\t TVw: 0.266792 | TVb: -2.033588 | GSw: -0.234986 | GSb: 0.064958 | TSUw: 0.464869 | TSUb: 0.034857\n",
      "\n",
      "Train Epoch: 2398 [4000/8000 (50%)]\tBatch Loss: 472.281081\tLearning Rate (w_theta): 0.001000\t TIME:5604.1s\n",
      "\t\t\t\tDisc: 0.377601\t\tSym: 10.910773\t\tSpars: 460.992706\n",
      "\t TVw: 0.267127 | TVb: -2.033555 | GSw: -0.234986 | GSb: 0.064958 | TSUw: 0.464868 | TSUb: 0.034857\n",
      "Validating epoch 2398...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 461.1968815460695\n",
      "Average validation loss: 97.9499293712241\n",
      "Training epoch 2399...\n",
      "\n",
      "Train Epoch: 2399 [0/8000 (0%)]\tBatch Loss: 445.777391\tLearning Rate (w_theta): 0.001000\t TIME:5606.5s\n",
      "\t\t\t\tDisc: 0.372052\t\tSym: 9.827245\t\tSpars: 435.578094\n",
      "\t TVw: 0.267538 | TVb: -2.033524 | GSw: -0.234986 | GSb: 0.064958 | TSUw: 0.464868 | TSUb: 0.034858\n",
      "\n",
      "Train Epoch: 2399 [4000/8000 (50%)]\tBatch Loss: 453.599088\tLearning Rate (w_theta): 0.001000\t TIME:5608.1s\n",
      "\t\t\t\tDisc: 0.344377\t\tSym: 11.932049\t\tSpars: 441.322662\n",
      "\t TVw: 0.268256 | TVb: -2.033482 | GSw: -0.234986 | GSb: 0.064958 | TSUw: 0.464868 | TSUb: 0.034858\n",
      "Validating epoch 2399...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 449.8435243699975\n",
      "Average validation loss: 93.7031962548335\n",
      "Training epoch 2400...\n",
      "\n",
      "Train Epoch: 2400 [0/8000 (0%)]\tBatch Loss: 452.274830\tLearning Rate (w_theta): 0.001000\t TIME:5610.5s\n",
      "\t\t\t\tDisc: 0.362144\t\tSym: 10.921322\t\tSpars: 440.991364\n",
      "\t TVw: 0.269372 | TVb: -2.033411 | GSw: -0.234986 | GSb: 0.064957 | TSUw: 0.464868 | TSUb: 0.034858\n",
      "\n",
      "Train Epoch: 2400 [4000/8000 (50%)]\tBatch Loss: 437.614714\tLearning Rate (w_theta): 0.001000\t TIME:5612.1s\n",
      "\t\t\t\tDisc: 0.350998\t\tSym: 10.424269\t\tSpars: 426.839447\n",
      "\t TVw: 0.270060 | TVb: -2.033364 | GSw: -0.234986 | GSb: 0.064957 | TSUw: 0.464868 | TSUb: 0.034858\n",
      "Validating epoch 2400...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 446.33606618221444\n",
      "Average validation loss: 98.44811193284337\n",
      "Training epoch 2401...\n",
      "\n",
      "Train Epoch: 2401 [0/8000 (0%)]\tBatch Loss: 455.380870\tLearning Rate (w_theta): 0.001000\t TIME:5615.2s\n",
      "\t\t\t\tDisc: 0.380426\t\tSym: 10.453997\t\tSpars: 444.546448\n",
      "\t TVw: 0.270677 | TVb: -2.033314 | GSw: -0.234986 | GSb: 0.064957 | TSUw: 0.464868 | TSUb: 0.034858\n",
      "\n",
      "Train Epoch: 2401 [4000/8000 (50%)]\tBatch Loss: 456.753931\tLearning Rate (w_theta): 0.001000\t TIME:5616.7s\n",
      "\t\t\t\tDisc: 0.380473\t\tSym: 11.235824\t\tSpars: 445.137634\n",
      "\t TVw: 0.270738 | TVb: -2.033292 | GSw: -0.234986 | GSb: 0.064957 | TSUw: 0.464868 | TSUb: 0.034858\n",
      "Validating epoch 2401...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 466.5512506582135\n",
      "Average validation loss: 87.35131305387924\n",
      "Training epoch 2402...\n",
      "\n",
      "Train Epoch: 2402 [0/8000 (0%)]\tBatch Loss: 444.822671\tLearning Rate (w_theta): 0.001000\t TIME:5619.2s\n",
      "\t\t\t\tDisc: 0.361983\t\tSym: 10.748194\t\tSpars: 433.712494\n",
      "\t TVw: 0.270543 | TVb: -2.033296 | GSw: -0.234986 | GSb: 0.064957 | TSUw: 0.464868 | TSUb: 0.034858\n",
      "\n",
      "Train Epoch: 2402 [4000/8000 (50%)]\tBatch Loss: 504.939641\tLearning Rate (w_theta): 0.001000\t TIME:5620.8s\n",
      "\t\t\t\tDisc: 0.464185\t\tSym: 11.875205\t\tSpars: 492.600250\n",
      "\t TVw: 0.270645 | TVb: -2.033297 | GSw: -0.234987 | GSb: 0.064957 | TSUw: 0.464867 | TSUb: 0.034859\n",
      "Validating epoch 2402...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 463.8214139566312\n",
      "Average validation loss: 87.30862173764555\n",
      "Training epoch 2403...\n",
      "\n",
      "Train Epoch: 2403 [0/8000 (0%)]\tBatch Loss: 447.675651\tLearning Rate (w_theta): 0.001000\t TIME:5623.2s\n",
      "\t\t\t\tDisc: 0.361843\t\tSym: 11.540584\t\tSpars: 435.773224\n",
      "\t TVw: 0.270840 | TVb: -2.033284 | GSw: -0.234987 | GSb: 0.064956 | TSUw: 0.464867 | TSUb: 0.034859\n",
      "\n",
      "Train Epoch: 2403 [4000/8000 (50%)]\tBatch Loss: 477.145938\tLearning Rate (w_theta): 0.001000\t TIME:5624.8s\n",
      "\t\t\t\tDisc: 0.384469\t\tSym: 11.992243\t\tSpars: 464.769226\n",
      "\t TVw: 0.271396 | TVb: -2.033240 | GSw: -0.234987 | GSb: 0.064956 | TSUw: 0.464867 | TSUb: 0.034859\n",
      "Validating epoch 2403...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 456.5829767998826\n",
      "Average validation loss: 97.17621257840362\n",
      "Training epoch 2404...\n",
      "\n",
      "Train Epoch: 2404 [0/8000 (0%)]\tBatch Loss: 452.302602\tLearning Rate (w_theta): 0.001000\t TIME:5627.2s\n",
      "\t\t\t\tDisc: 0.381665\t\tSym: 10.409981\t\tSpars: 441.510956\n",
      "\t TVw: 0.272126 | TVb: -2.033184 | GSw: -0.234987 | GSb: 0.064956 | TSUw: 0.464867 | TSUb: 0.034859\n",
      "\n",
      "Train Epoch: 2404 [4000/8000 (50%)]\tBatch Loss: 463.107855\tLearning Rate (w_theta): 0.001000\t TIME:5628.8s\n",
      "\t\t\t\tDisc: 0.387013\t\tSym: 11.611528\t\tSpars: 451.109314\n",
      "\t TVw: 0.272986 | TVb: -2.033119 | GSw: -0.234987 | GSb: 0.064956 | TSUw: 0.464867 | TSUb: 0.034859\n",
      "Validating epoch 2404...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 449.31458570523273\n",
      "Average validation loss: 94.13978213113751\n",
      "Training epoch 2405...\n",
      "\n",
      "Train Epoch: 2405 [0/8000 (0%)]\tBatch Loss: 419.518582\tLearning Rate (w_theta): 0.001000\t TIME:5631.2s\n",
      "\t\t\t\tDisc: 0.356664\t\tSym: 9.112327\t\tSpars: 410.049591\n",
      "\t TVw: 0.273653 | TVb: -2.033066 | GSw: -0.234987 | GSb: 0.064956 | TSUw: 0.464867 | TSUb: 0.034859\n",
      "\n",
      "Train Epoch: 2405 [4000/8000 (50%)]\tBatch Loss: 444.155954\tLearning Rate (w_theta): 0.001000\t TIME:5632.8s\n",
      "\t\t\t\tDisc: 0.385099\t\tSym: 10.703442\t\tSpars: 433.067413\n",
      "\t TVw: 0.273965 | TVb: -2.033029 | GSw: -0.234987 | GSb: 0.064955 | TSUw: 0.464867 | TSUb: 0.034860\n",
      "Validating epoch 2405...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 446.6049931914541\n",
      "Average validation loss: 86.57609319102743\n",
      "Training epoch 2406...\n",
      "\n",
      "Train Epoch: 2406 [0/8000 (0%)]\tBatch Loss: 456.376074\tLearning Rate (w_theta): 0.001000\t TIME:5635.3s\n",
      "\t\t\t\tDisc: 0.369399\t\tSym: 11.308066\t\tSpars: 444.698608\n",
      "\t TVw: 0.273961 | TVb: -2.033007 | GSw: -0.234987 | GSb: 0.064955 | TSUw: 0.464867 | TSUb: 0.034860\n",
      "\n",
      "Train Epoch: 2406 [4000/8000 (50%)]\tBatch Loss: 455.751466\tLearning Rate (w_theta): 0.001000\t TIME:5636.8s\n",
      "\t\t\t\tDisc: 0.384314\t\tSym: 10.446040\t\tSpars: 444.921112\n",
      "\t TVw: 0.274111 | TVb: -2.032983 | GSw: -0.234987 | GSb: 0.064955 | TSUw: 0.464866 | TSUb: 0.034860\n",
      "Validating epoch 2406...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 444.52906421793693\n",
      "Average validation loss: 86.74477464989943\n",
      "Training epoch 2407...\n",
      "\n",
      "Train Epoch: 2407 [0/8000 (0%)]\tBatch Loss: 431.568892\tLearning Rate (w_theta): 0.001000\t TIME:5639.6s\n",
      "\t\t\t\tDisc: 0.365852\t\tSym: 10.333747\t\tSpars: 420.869293\n",
      "\t TVw: 0.274511 | TVb: -2.032944 | GSw: -0.234987 | GSb: 0.064955 | TSUw: 0.464866 | TSUb: 0.034860\n",
      "\n",
      "Train Epoch: 2407 [4000/8000 (50%)]\tBatch Loss: 443.452687\tLearning Rate (w_theta): 0.001000\t TIME:5641.2s\n",
      "\t\t\t\tDisc: 0.375903\t\tSym: 11.477297\t\tSpars: 431.599487\n",
      "\t TVw: 0.274884 | TVb: -2.032898 | GSw: -0.234987 | GSb: 0.064955 | TSUw: 0.464866 | TSUb: 0.034860\n",
      "Validating epoch 2407...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 436.40476878844373\n",
      "Average validation loss: 92.46307058897611\n",
      "Training epoch 2408...\n",
      "\n",
      "Train Epoch: 2408 [0/8000 (0%)]\tBatch Loss: 409.280006\tLearning Rate (w_theta): 0.001000\t TIME:5643.6s\n",
      "\t\t\t\tDisc: 0.363805\t\tSym: 9.562807\t\tSpars: 399.353394\n",
      "\t TVw: 0.275199 | TVb: -2.032849 | GSw: -0.234987 | GSb: 0.064955 | TSUw: 0.464866 | TSUb: 0.034860\n",
      "\n",
      "Train Epoch: 2408 [4000/8000 (50%)]\tBatch Loss: 454.931856\tLearning Rate (w_theta): 0.001000\t TIME:5645.2s\n",
      "\t\t\t\tDisc: 0.379473\t\tSym: 11.989272\t\tSpars: 442.563110\n",
      "\t TVw: 0.275610 | TVb: -2.032794 | GSw: -0.234987 | GSb: 0.064954 | TSUw: 0.464866 | TSUb: 0.034860\n",
      "Validating epoch 2408...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 432.1316995274179\n",
      "Average validation loss: 92.82428762432609\n",
      "Training epoch 2409...\n",
      "\n",
      "Train Epoch: 2409 [0/8000 (0%)]\tBatch Loss: 414.903037\tLearning Rate (w_theta): 0.001000\t TIME:5647.6s\n",
      "\t\t\t\tDisc: 0.388901\t\tSym: 9.724586\t\tSpars: 404.789551\n",
      "\t TVw: 0.275901 | TVb: -2.032731 | GSw: -0.234987 | GSb: 0.064954 | TSUw: 0.464866 | TSUb: 0.034861\n",
      "\n",
      "Train Epoch: 2409 [4000/8000 (50%)]\tBatch Loss: 438.298772\tLearning Rate (w_theta): 0.001000\t TIME:5649.2s\n",
      "\t\t\t\tDisc: 0.382441\t\tSym: 10.935893\t\tSpars: 426.980438\n",
      "\t TVw: 0.276001 | TVb: -2.032670 | GSw: -0.234987 | GSb: 0.064954 | TSUw: 0.464866 | TSUb: 0.034861\n",
      "Validating epoch 2409...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 430.17639753549923\n",
      "Average validation loss: 93.84528960597154\n",
      "Training epoch 2410...\n",
      "\n",
      "Train Epoch: 2410 [0/8000 (0%)]\tBatch Loss: 431.359431\tLearning Rate (w_theta): 0.001000\t TIME:5651.7s\n",
      "\t\t\t\tDisc: 0.402585\t\tSym: 10.145474\t\tSpars: 420.811371\n",
      "\t TVw: 0.275928 | TVb: -2.032620 | GSw: -0.234987 | GSb: 0.064954 | TSUw: 0.464866 | TSUb: 0.034861\n",
      "\n",
      "Train Epoch: 2410 [4000/8000 (50%)]\tBatch Loss: 429.108459\tLearning Rate (w_theta): 0.001000\t TIME:5653.3s\n",
      "\t\t\t\tDisc: 0.417322\t\tSym: 10.207830\t\tSpars: 418.483307\n",
      "\t TVw: 0.275738 | TVb: -2.032578 | GSw: -0.234987 | GSb: 0.064954 | TSUw: 0.464866 | TSUb: 0.034861\n",
      "Validating epoch 2410...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 428.7517657509749\n",
      "Average validation loss: 93.8348701937405\n",
      "Training epoch 2411...\n",
      "\n",
      "Train Epoch: 2411 [0/8000 (0%)]\tBatch Loss: 432.907389\tLearning Rate (w_theta): 0.001000\t TIME:5656.5s\n",
      "\t\t\t\tDisc: 0.395633\t\tSym: 10.573249\t\tSpars: 421.938507\n",
      "\t TVw: 0.275303 | TVb: -2.032549 | GSw: -0.234988 | GSb: 0.064953 | TSUw: 0.464865 | TSUb: 0.034861\n",
      "\n",
      "Train Epoch: 2411 [4000/8000 (50%)]\tBatch Loss: 442.192425\tLearning Rate (w_theta): 0.001000\t TIME:5658.0s\n",
      "\t\t\t\tDisc: 0.380413\t\tSym: 11.215760\t\tSpars: 430.596252\n",
      "\t TVw: 0.274687 | TVb: -2.032530 | GSw: -0.234988 | GSb: 0.064953 | TSUw: 0.464865 | TSUb: 0.034861\n",
      "Validating epoch 2411...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 428.37334252319715\n",
      "Average validation loss: 92.98018848190239\n",
      "Training epoch 2412...\n",
      "\n",
      "Train Epoch: 2412 [0/8000 (0%)]\tBatch Loss: 453.370038\tLearning Rate (w_theta): 0.001000\t TIME:5660.5s\n",
      "\t\t\t\tDisc: 0.384432\t\tSym: 12.029918\t\tSpars: 440.955688\n",
      "\t TVw: 0.274185 | TVb: -2.032511 | GSw: -0.234988 | GSb: 0.064953 | TSUw: 0.464865 | TSUb: 0.034861\n",
      "\n",
      "Train Epoch: 2412 [4000/8000 (50%)]\tBatch Loss: 460.431433\tLearning Rate (w_theta): 0.001000\t TIME:5662.0s\n",
      "\t\t\t\tDisc: 0.429380\t\tSym: 12.649514\t\tSpars: 447.352539\n",
      "\t TVw: 0.273760 | TVb: -2.032488 | GSw: -0.234988 | GSb: 0.064953 | TSUw: 0.464865 | TSUb: 0.034862\n",
      "Validating epoch 2412...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 427.0627253408553\n",
      "Average validation loss: 92.99835274985334\n",
      "Training epoch 2413...\n",
      "\n",
      "Train Epoch: 2413 [0/8000 (0%)]\tBatch Loss: 424.112574\tLearning Rate (w_theta): 0.001000\t TIME:5664.5s\n",
      "\t\t\t\tDisc: 0.398663\t\tSym: 10.829634\t\tSpars: 412.884277\n",
      "\t TVw: 0.273272 | TVb: -2.032458 | GSw: -0.234988 | GSb: 0.064953 | TSUw: 0.464865 | TSUb: 0.034862\n",
      "\n",
      "Train Epoch: 2413 [4000/8000 (50%)]\tBatch Loss: 414.732795\tLearning Rate (w_theta): 0.001000\t TIME:5666.1s\n",
      "\t\t\t\tDisc: 0.357659\t\tSym: 9.885177\t\tSpars: 404.489960\n",
      "\t TVw: 0.272910 | TVb: -2.032427 | GSw: -0.234988 | GSb: 0.064953 | TSUw: 0.464865 | TSUb: 0.034862\n",
      "Validating epoch 2413...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 426.2501532641462\n",
      "Average validation loss: 91.48793912068565\n",
      "Training epoch 2414...\n",
      "\n",
      "Train Epoch: 2414 [0/8000 (0%)]\tBatch Loss: 430.427855\tLearning Rate (w_theta): 0.001000\t TIME:5668.5s\n",
      "\t\t\t\tDisc: 0.397703\t\tSym: 10.921571\t\tSpars: 419.108582\n",
      "\t TVw: 0.272553 | TVb: -2.032400 | GSw: -0.234988 | GSb: 0.064952 | TSUw: 0.464865 | TSUb: 0.034862\n",
      "\n",
      "Train Epoch: 2414 [4000/8000 (50%)]\tBatch Loss: 408.834814\tLearning Rate (w_theta): 0.001000\t TIME:5670.1s\n",
      "\t\t\t\tDisc: 0.381303\t\tSym: 9.100026\t\tSpars: 399.353485\n",
      "\t TVw: 0.272101 | TVb: -2.032384 | GSw: -0.234988 | GSb: 0.064952 | TSUw: 0.464865 | TSUb: 0.034862\n",
      "Validating epoch 2414...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 426.53054737224215\n",
      "Average validation loss: 87.2835269747375\n",
      "Training epoch 2415...\n",
      "\n",
      "Train Epoch: 2415 [0/8000 (0%)]\tBatch Loss: 444.747645\tLearning Rate (w_theta): 0.001000\t TIME:5672.5s\n",
      "\t\t\t\tDisc: 0.348777\t\tSym: 11.431918\t\tSpars: 432.966949\n",
      "\t TVw: 0.271699 | TVb: -2.032361 | GSw: -0.234988 | GSb: 0.064952 | TSUw: 0.464864 | TSUb: 0.034862\n",
      "\n",
      "Train Epoch: 2415 [4000/8000 (50%)]\tBatch Loss: 450.309613\tLearning Rate (w_theta): 0.001000\t TIME:5674.1s\n",
      "\t\t\t\tDisc: 0.346143\t\tSym: 10.945739\t\tSpars: 439.017731\n",
      "\t TVw: 0.271056 | TVb: -2.032366 | GSw: -0.234988 | GSb: 0.064952 | TSUw: 0.464864 | TSUb: 0.034862\n",
      "Validating epoch 2415...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 438.2910473833945\n",
      "Average validation loss: 83.0260635119605\n",
      "Training epoch 2416...\n",
      "\n",
      "Train Epoch: 2416 [0/8000 (0%)]\tBatch Loss: 448.841087\tLearning Rate (w_theta): 0.001000\t TIME:5676.6s\n",
      "\t\t\t\tDisc: 0.383348\t\tSym: 10.710608\t\tSpars: 437.747131\n",
      "\t TVw: 0.270135 | TVb: -2.032399 | GSw: -0.234988 | GSb: 0.064952 | TSUw: 0.464864 | TSUb: 0.034862\n",
      "\n",
      "Train Epoch: 2416 [4000/8000 (50%)]\tBatch Loss: 473.904006\tLearning Rate (w_theta): 0.001000\t TIME:5678.1s\n",
      "\t\t\t\tDisc: 0.373938\t\tSym: 12.228646\t\tSpars: 461.301422\n",
      "\t TVw: 0.269882 | TVb: -2.032413 | GSw: -0.234988 | GSb: 0.064951 | TSUw: 0.464864 | TSUb: 0.034863\n",
      "Validating epoch 2416...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 441.7638254081823\n",
      "Average validation loss: 85.14621224564235\n",
      "Training epoch 2417...\n",
      "\n",
      "Train Epoch: 2417 [0/8000 (0%)]\tBatch Loss: 432.463154\tLearning Rate (w_theta): 0.001000\t TIME:5680.6s\n",
      "\t\t\t\tDisc: 0.334619\t\tSym: 10.767664\t\tSpars: 421.360870\n",
      "\t TVw: 0.270060 | TVb: -2.032414 | GSw: -0.234988 | GSb: 0.064951 | TSUw: 0.464864 | TSUb: 0.034863\n",
      "\n",
      "Train Epoch: 2417 [4000/8000 (50%)]\tBatch Loss: 421.308316\tLearning Rate (w_theta): 0.001000\t TIME:5682.2s\n",
      "\t\t\t\tDisc: 0.337769\t\tSym: 10.692471\t\tSpars: 410.278076\n",
      "\t TVw: 0.270731 | TVb: -2.032371 | GSw: -0.234988 | GSb: 0.064951 | TSUw: 0.464864 | TSUb: 0.034863\n",
      "Validating epoch 2417...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 426.58860738794283\n",
      "Average validation loss: 87.97194123627428\n",
      "Training epoch 2418...\n",
      "\n",
      "Train Epoch: 2418 [0/8000 (0%)]\tBatch Loss: 418.367342\tLearning Rate (w_theta): 0.001000\t TIME:5684.7s\n",
      "\t\t\t\tDisc: 0.376797\t\tSym: 9.887457\t\tSpars: 408.103088\n",
      "\t TVw: 0.271526 | TVb: -2.032305 | GSw: -0.234988 | GSb: 0.064951 | TSUw: 0.464864 | TSUb: 0.034863\n",
      "\n",
      "Train Epoch: 2418 [4000/8000 (50%)]\tBatch Loss: 425.900582\tLearning Rate (w_theta): 0.001000\t TIME:5686.2s\n",
      "\t\t\t\tDisc: 0.360000\t\tSym: 10.192957\t\tSpars: 415.347626\n",
      "\t TVw: 0.272329 | TVb: -2.032235 | GSw: -0.234988 | GSb: 0.064951 | TSUw: 0.464864 | TSUb: 0.034863\n",
      "Validating epoch 2418...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 422.7178909303218\n",
      "Average validation loss: 90.38767173461594\n",
      "Training epoch 2419...\n",
      "\n",
      "Train Epoch: 2419 [0/8000 (0%)]\tBatch Loss: 436.535459\tLearning Rate (w_theta): 0.001000\t TIME:5688.7s\n",
      "\t\t\t\tDisc: 0.384913\t\tSym: 10.941409\t\tSpars: 425.209137\n",
      "\t TVw: 0.272917 | TVb: -2.032173 | GSw: -0.234988 | GSb: 0.064951 | TSUw: 0.464864 | TSUb: 0.034863\n",
      "\n",
      "Train Epoch: 2419 [4000/8000 (50%)]\tBatch Loss: 408.570520\tLearning Rate (w_theta): 0.001000\t TIME:5690.3s\n",
      "\t\t\t\tDisc: 0.354254\t\tSym: 9.490314\t\tSpars: 398.725952\n",
      "\t TVw: 0.273547 | TVb: -2.032102 | GSw: -0.234989 | GSb: 0.064950 | TSUw: 0.464863 | TSUb: 0.034864\n",
      "Validating epoch 2419...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 421.56688645973816\n",
      "Average validation loss: 89.01090578803053\n",
      "Training epoch 2420...\n",
      "\n",
      "Train Epoch: 2420 [0/8000 (0%)]\tBatch Loss: 411.770798\tLearning Rate (w_theta): 0.001000\t TIME:5693.1s\n",
      "\t\t\t\tDisc: 0.356169\t\tSym: 9.943407\t\tSpars: 401.471222\n",
      "\t TVw: 0.274041 | TVb: -2.032034 | GSw: -0.234989 | GSb: 0.064950 | TSUw: 0.464863 | TSUb: 0.034864\n",
      "\n",
      "Train Epoch: 2420 [4000/8000 (50%)]\tBatch Loss: 442.224782\tLearning Rate (w_theta): 0.001000\t TIME:5694.7s\n",
      "\t\t\t\tDisc: 0.392217\t\tSym: 11.655013\t\tSpars: 430.177551\n",
      "\t TVw: 0.274316 | TVb: -2.031979 | GSw: -0.234989 | GSb: 0.064950 | TSUw: 0.464863 | TSUb: 0.034864\n",
      "Validating epoch 2420...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 419.787090606447\n",
      "Average validation loss: 90.89982373071858\n",
      "Training epoch 2421...\n",
      "\n",
      "Train Epoch: 2421 [0/8000 (0%)]\tBatch Loss: 416.972457\tLearning Rate (w_theta): 0.001000\t TIME:5697.9s\n",
      "\t\t\t\tDisc: 0.389771\t\tSym: 10.096541\t\tSpars: 406.486145\n",
      "\t TVw: 0.274355 | TVb: -2.031931 | GSw: -0.234989 | GSb: 0.064950 | TSUw: 0.464863 | TSUb: 0.034864\n",
      "\n",
      "Train Epoch: 2421 [4000/8000 (50%)]\tBatch Loss: 439.216011\tLearning Rate (w_theta): 0.001000\t TIME:5699.5s\n",
      "\t\t\t\tDisc: 0.406379\t\tSym: 11.077302\t\tSpars: 427.732330\n",
      "\t TVw: 0.274158 | TVb: -2.031900 | GSw: -0.234989 | GSb: 0.064950 | TSUw: 0.464863 | TSUb: 0.034864\n",
      "Validating epoch 2421...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 417.9939277087252\n",
      "Average validation loss: 90.52659415912805\n",
      "Training epoch 2422...\n",
      "\n",
      "Train Epoch: 2422 [0/8000 (0%)]\tBatch Loss: 424.515915\tLearning Rate (w_theta): 0.001000\t TIME:5701.9s\n",
      "\t\t\t\tDisc: 0.380750\t\tSym: 11.411532\t\tSpars: 412.723633\n",
      "\t TVw: 0.273777 | TVb: -2.031881 | GSw: -0.234989 | GSb: 0.064950 | TSUw: 0.464863 | TSUb: 0.034864\n",
      "\n",
      "Train Epoch: 2422 [4000/8000 (50%)]\tBatch Loss: 409.544691\tLearning Rate (w_theta): 0.001000\t TIME:5703.5s\n",
      "\t\t\t\tDisc: 0.407408\t\tSym: 9.667496\t\tSpars: 399.469788\n",
      "\t TVw: 0.273303 | TVb: -2.031866 | GSw: -0.234989 | GSb: 0.064949 | TSUw: 0.464863 | TSUb: 0.034864\n",
      "Validating epoch 2422...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 417.2520580455546\n",
      "Average validation loss: 92.24652940063115\n",
      "Training epoch 2423...\n",
      "\n",
      "Train Epoch: 2423 [0/8000 (0%)]\tBatch Loss: 434.686463\tLearning Rate (w_theta): 0.001000\t TIME:5706.0s\n",
      "\t\t\t\tDisc: 0.384973\t\tSym: 11.191016\t\tSpars: 423.110474\n",
      "\t TVw: 0.272995 | TVb: -2.031844 | GSw: -0.234989 | GSb: 0.064949 | TSUw: 0.464863 | TSUb: 0.034864\n",
      "\n",
      "Train Epoch: 2423 [4000/8000 (50%)]\tBatch Loss: 420.299832\tLearning Rate (w_theta): 0.001000\t TIME:5707.5s\n",
      "\t\t\t\tDisc: 0.379038\t\tSym: 10.772783\t\tSpars: 409.148010\n",
      "\t TVw: 0.272790 | TVb: -2.031816 | GSw: -0.234989 | GSb: 0.064949 | TSUw: 0.464862 | TSUb: 0.034865\n",
      "Validating epoch 2423...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 417.36969501923176\n",
      "Average validation loss: 87.40305512168918\n",
      "Training epoch 2424...\n",
      "\n",
      "Train Epoch: 2424 [0/8000 (0%)]\tBatch Loss: 406.199509\tLearning Rate (w_theta): 0.001000\t TIME:5710.0s\n",
      "\t\t\t\tDisc: 0.355296\t\tSym: 10.116399\t\tSpars: 395.727814\n",
      "\t TVw: 0.272459 | TVb: -2.031790 | GSw: -0.234989 | GSb: 0.064949 | TSUw: 0.464862 | TSUb: 0.034865\n",
      "\n",
      "Train Epoch: 2424 [4000/8000 (50%)]\tBatch Loss: 431.593164\tLearning Rate (w_theta): 0.001000\t TIME:5711.6s\n",
      "\t\t\t\tDisc: 0.414044\t\tSym: 11.605329\t\tSpars: 419.573792\n",
      "\t TVw: 0.272186 | TVb: -2.031762 | GSw: -0.234989 | GSb: 0.064949 | TSUw: 0.464862 | TSUb: 0.034865\n",
      "Validating epoch 2424...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 416.3259503839657\n",
      "Average validation loss: 89.26761073079922\n",
      "Training epoch 2425...\n",
      "\n",
      "Train Epoch: 2425 [0/8000 (0%)]\tBatch Loss: 400.265813\tLearning Rate (w_theta): 0.001000\t TIME:5714.1s\n",
      "\t\t\t\tDisc: 0.371916\t\tSym: 9.426336\t\tSpars: 390.467560\n",
      "\t TVw: 0.271917 | TVb: -2.031737 | GSw: -0.234989 | GSb: 0.064948 | TSUw: 0.464862 | TSUb: 0.034865\n",
      "\n",
      "Train Epoch: 2425 [4000/8000 (50%)]\tBatch Loss: 415.622691\tLearning Rate (w_theta): 0.001000\t TIME:5715.7s\n",
      "\t\t\t\tDisc: 0.371791\t\tSym: 10.379195\t\tSpars: 404.871704\n",
      "\t TVw: 0.271756 | TVb: -2.031710 | GSw: -0.234989 | GSb: 0.064948 | TSUw: 0.464862 | TSUb: 0.034865\n",
      "Validating epoch 2425...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 415.92240484532715\n",
      "Average validation loss: 92.17233254018436\n",
      "Training epoch 2426...\n",
      "\n",
      "Train Epoch: 2426 [0/8000 (0%)]\tBatch Loss: 438.700686\tLearning Rate (w_theta): 0.001000\t TIME:5718.1s\n",
      "\t\t\t\tDisc: 0.371693\t\tSym: 11.313307\t\tSpars: 427.015686\n",
      "\t TVw: 0.271580 | TVb: -2.031688 | GSw: -0.234989 | GSb: 0.064948 | TSUw: 0.464862 | TSUb: 0.034865\n",
      "\n",
      "Train Epoch: 2426 [4000/8000 (50%)]\tBatch Loss: 431.730310\tLearning Rate (w_theta): 0.001000\t TIME:5719.7s\n",
      "\t\t\t\tDisc: 0.371600\t\tSym: 10.953284\t\tSpars: 420.405426\n",
      "\t TVw: 0.271267 | TVb: -2.031688 | GSw: -0.234989 | GSb: 0.064948 | TSUw: 0.464862 | TSUb: 0.034865\n",
      "Validating epoch 2426...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 423.97435698222887\n",
      "Average validation loss: 85.4013039344273\n",
      "Training epoch 2427...\n",
      "\n",
      "Train Epoch: 2427 [0/8000 (0%)]\tBatch Loss: 419.009316\tLearning Rate (w_theta): 0.001000\t TIME:5722.1s\n",
      "\t\t\t\tDisc: 0.357304\t\tSym: 10.815189\t\tSpars: 407.836823\n",
      "\t TVw: 0.270996 | TVb: -2.031686 | GSw: -0.234989 | GSb: 0.064948 | TSUw: 0.464862 | TSUb: 0.034866\n",
      "\n",
      "Train Epoch: 2427 [4000/8000 (50%)]\tBatch Loss: 423.322983\tLearning Rate (w_theta): 0.001000\t TIME:5723.7s\n",
      "\t\t\t\tDisc: 0.335988\t\tSym: 11.109370\t\tSpars: 411.877625\n",
      "\t TVw: 0.271105 | TVb: -2.031664 | GSw: -0.234989 | GSb: 0.064948 | TSUw: 0.464861 | TSUb: 0.034866\n",
      "Validating epoch 2427...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 416.27784176892914\n",
      "Average validation loss: 85.47574821022869\n",
      "Training epoch 2428...\n",
      "\n",
      "Train Epoch: 2428 [0/8000 (0%)]\tBatch Loss: 387.134230\tLearning Rate (w_theta): 0.001000\t TIME:5726.2s\n",
      "\t\t\t\tDisc: 0.337165\t\tSym: 8.905372\t\tSpars: 377.891693\n",
      "\t TVw: 0.271422 | TVb: -2.031639 | GSw: -0.234990 | GSb: 0.064947 | TSUw: 0.464861 | TSUb: 0.034866\n",
      "\n",
      "Train Epoch: 2428 [4000/8000 (50%)]\tBatch Loss: 405.860154\tLearning Rate (w_theta): 0.001000\t TIME:5727.8s\n",
      "\t\t\t\tDisc: 0.349560\t\tSym: 10.056493\t\tSpars: 395.454102\n",
      "\t TVw: 0.271933 | TVb: -2.031595 | GSw: -0.234990 | GSb: 0.064947 | TSUw: 0.464861 | TSUb: 0.034866\n",
      "Validating epoch 2428...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 413.2486388064939\n",
      "Average validation loss: 85.83492698100461\n",
      "Training epoch 2429...\n",
      "\n",
      "Train Epoch: 2429 [0/8000 (0%)]\tBatch Loss: 401.528695\tLearning Rate (w_theta): 0.001000\t TIME:5730.3s\n",
      "\t\t\t\tDisc: 0.343022\t\tSym: 9.678136\t\tSpars: 391.507538\n",
      "\t TVw: 0.272495 | TVb: -2.031544 | GSw: -0.234990 | GSb: 0.064947 | TSUw: 0.464861 | TSUb: 0.034866\n",
      "\n",
      "Train Epoch: 2429 [4000/8000 (50%)]\tBatch Loss: 418.549766\tLearning Rate (w_theta): 0.001000\t TIME:5731.9s\n",
      "\t\t\t\tDisc: 0.374926\t\tSym: 10.687352\t\tSpars: 407.487488\n",
      "\t TVw: 0.272812 | TVb: -2.031501 | GSw: -0.234990 | GSb: 0.064947 | TSUw: 0.464861 | TSUb: 0.034866\n",
      "Validating epoch 2429...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 413.52397200038206\n",
      "Average validation loss: 90.67277409780236\n",
      "Training epoch 2430...\n",
      "\n",
      "Train Epoch: 2430 [0/8000 (0%)]\tBatch Loss: 434.084775\tLearning Rate (w_theta): 0.001000\t TIME:5734.3s\n",
      "\t\t\t\tDisc: 0.385971\t\tSym: 11.291181\t\tSpars: 422.407623\n",
      "\t TVw: 0.273287 | TVb: -2.031453 | GSw: -0.234990 | GSb: 0.064947 | TSUw: 0.464861 | TSUb: 0.034866\n",
      "\n",
      "Train Epoch: 2430 [4000/8000 (50%)]\tBatch Loss: 413.876466\tLearning Rate (w_theta): 0.001000\t TIME:5735.9s\n",
      "\t\t\t\tDisc: 0.394977\t\tSym: 10.924726\t\tSpars: 402.556763\n",
      "\t TVw: 0.273662 | TVb: -2.031409 | GSw: -0.234990 | GSb: 0.064946 | TSUw: 0.464861 | TSUb: 0.034867\n",
      "Validating epoch 2430...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 412.5440842057086\n",
      "Average validation loss: 85.68226793095508\n",
      "Training epoch 2431...\n",
      "\n",
      "Train Epoch: 2431 [0/8000 (0%)]\tBatch Loss: 421.351317\tLearning Rate (w_theta): 0.001000\t TIME:5739.3s\n",
      "\t\t\t\tDisc: 0.356117\t\tSym: 10.441733\t\tSpars: 410.553467\n",
      "\t TVw: 0.273875 | TVb: -2.031367 | GSw: -0.234990 | GSb: 0.064946 | TSUw: 0.464861 | TSUb: 0.034867\n",
      "\n",
      "Train Epoch: 2431 [4000/8000 (50%)]\tBatch Loss: 395.940668\tLearning Rate (w_theta): 0.001000\t TIME:5740.9s\n",
      "\t\t\t\tDisc: 0.380122\t\tSym: 9.771880\t\tSpars: 385.788666\n",
      "\t TVw: 0.273819 | TVb: -2.031348 | GSw: -0.234990 | GSb: 0.064946 | TSUw: 0.464861 | TSUb: 0.034867\n",
      "Validating epoch 2431...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 414.93957905033295\n",
      "Average validation loss: 91.05231621182182\n",
      "Training epoch 2432...\n",
      "\n",
      "Train Epoch: 2432 [0/8000 (0%)]\tBatch Loss: 420.480613\tLearning Rate (w_theta): 0.001000\t TIME:5743.4s\n",
      "\t\t\t\tDisc: 0.389507\t\tSym: 10.706676\t\tSpars: 409.384430\n",
      "\t TVw: 0.273869 | TVb: -2.031330 | GSw: -0.234990 | GSb: 0.064946 | TSUw: 0.464860 | TSUb: 0.034867\n",
      "\n",
      "Train Epoch: 2432 [4000/8000 (50%)]\tBatch Loss: 388.864764\tLearning Rate (w_theta): 0.001000\t TIME:5744.9s\n",
      "\t\t\t\tDisc: 0.363712\t\tSym: 9.428603\t\tSpars: 379.072449\n",
      "\t TVw: 0.273943 | TVb: -2.031304 | GSw: -0.234990 | GSb: 0.064946 | TSUw: 0.464860 | TSUb: 0.034867\n",
      "Validating epoch 2432...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 410.68500127268794\n",
      "Average validation loss: 87.19562412769392\n",
      "Training epoch 2433...\n",
      "\n",
      "Train Epoch: 2433 [0/8000 (0%)]\tBatch Loss: 412.399833\tLearning Rate (w_theta): 0.001000\t TIME:5747.4s\n",
      "\t\t\t\tDisc: 0.356780\t\tSym: 10.945763\t\tSpars: 401.097290\n",
      "\t TVw: 0.274045 | TVb: -2.031271 | GSw: -0.234990 | GSb: 0.064946 | TSUw: 0.464860 | TSUb: 0.034867\n",
      "\n",
      "Train Epoch: 2433 [4000/8000 (50%)]\tBatch Loss: 409.989320\tLearning Rate (w_theta): 0.001000\t TIME:5749.0s\n",
      "\t\t\t\tDisc: 0.355694\t\tSym: 10.808064\t\tSpars: 398.825562\n",
      "\t TVw: 0.274135 | TVb: -2.031234 | GSw: -0.234990 | GSb: 0.064945 | TSUw: 0.464860 | TSUb: 0.034867\n",
      "Validating epoch 2433...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 408.4211997435433\n",
      "Average validation loss: 87.47237372570198\n",
      "Training epoch 2434...\n",
      "\n",
      "Train Epoch: 2434 [0/8000 (0%)]\tBatch Loss: 418.380123\tLearning Rate (w_theta): 0.001000\t TIME:5751.4s\n",
      "\t\t\t\tDisc: 0.378771\t\tSym: 11.159829\t\tSpars: 406.841522\n",
      "\t TVw: 0.274271 | TVb: -2.031193 | GSw: -0.234990 | GSb: 0.064945 | TSUw: 0.464860 | TSUb: 0.034868\n",
      "\n",
      "Train Epoch: 2434 [4000/8000 (50%)]\tBatch Loss: 432.255956\tLearning Rate (w_theta): 0.001000\t TIME:5753.0s\n",
      "\t\t\t\tDisc: 0.402231\t\tSym: 11.449092\t\tSpars: 420.404633\n",
      "\t TVw: 0.274384 | TVb: -2.031152 | GSw: -0.234990 | GSb: 0.064945 | TSUw: 0.464860 | TSUb: 0.034868\n",
      "Validating epoch 2434...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 407.48081370998256\n",
      "Average validation loss: 90.56845328717296\n",
      "Training epoch 2435...\n",
      "\n",
      "Train Epoch: 2435 [0/8000 (0%)]\tBatch Loss: 405.379338\tLearning Rate (w_theta): 0.001000\t TIME:5755.5s\n",
      "\t\t\t\tDisc: 0.395128\t\tSym: 9.511584\t\tSpars: 395.472626\n",
      "\t TVw: 0.274424 | TVb: -2.031113 | GSw: -0.234990 | GSb: 0.064945 | TSUw: 0.464860 | TSUb: 0.034868\n",
      "\n",
      "Train Epoch: 2435 [4000/8000 (50%)]\tBatch Loss: 404.687164\tLearning Rate (w_theta): 0.001000\t TIME:5757.1s\n",
      "\t\t\t\tDisc: 0.378892\t\tSym: 10.228133\t\tSpars: 394.080139\n",
      "\t TVw: 0.274420 | TVb: -2.031087 | GSw: -0.234990 | GSb: 0.064945 | TSUw: 0.464860 | TSUb: 0.034868\n",
      "Validating epoch 2435...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 407.453518563465\n",
      "Average validation loss: 87.67177371625013\n",
      "Training epoch 2436...\n",
      "\n",
      "Train Epoch: 2436 [0/8000 (0%)]\tBatch Loss: 394.505638\tLearning Rate (w_theta): 0.001000\t TIME:5759.5s\n",
      "\t\t\t\tDisc: 0.381063\t\tSym: 9.575564\t\tSpars: 384.549011\n",
      "\t TVw: 0.274475 | TVb: -2.031053 | GSw: -0.234991 | GSb: 0.064945 | TSUw: 0.464859 | TSUb: 0.034868\n",
      "\n",
      "Train Epoch: 2436 [4000/8000 (50%)]\tBatch Loss: 407.591536\tLearning Rate (w_theta): 0.001000\t TIME:5761.1s\n",
      "\t\t\t\tDisc: 0.387783\t\tSym: 10.324512\t\tSpars: 396.879242\n",
      "\t TVw: 0.274338 | TVb: -2.031029 | GSw: -0.234991 | GSb: 0.064944 | TSUw: 0.464859 | TSUb: 0.034868\n",
      "Validating epoch 2436...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 404.7743165789846\n",
      "Average validation loss: 87.19028700942584\n",
      "Training epoch 2437...\n",
      "\n",
      "Train Epoch: 2437 [0/8000 (0%)]\tBatch Loss: 426.213021\tLearning Rate (w_theta): 0.001000\t TIME:5763.6s\n",
      "\t\t\t\tDisc: 0.388533\t\tSym: 11.633662\t\tSpars: 414.190826\n",
      "\t TVw: 0.274254 | TVb: -2.031004 | GSw: -0.234991 | GSb: 0.064944 | TSUw: 0.464859 | TSUb: 0.034868\n",
      "\n",
      "Train Epoch: 2437 [4000/8000 (50%)]\tBatch Loss: 396.578456\tLearning Rate (w_theta): 0.001000\t TIME:5765.2s\n",
      "\t\t\t\tDisc: 0.398823\t\tSym: 9.978309\t\tSpars: 386.201324\n",
      "\t TVw: 0.274263 | TVb: -2.030978 | GSw: -0.234991 | GSb: 0.064944 | TSUw: 0.464859 | TSUb: 0.034869\n",
      "Validating epoch 2437...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 404.3647269114971\n",
      "Average validation loss: 87.18876466851943\n",
      "Training epoch 2438...\n",
      "\n",
      "Train Epoch: 2438 [0/8000 (0%)]\tBatch Loss: 394.319327\tLearning Rate (w_theta): 0.001000\t TIME:5767.6s\n",
      "\t\t\t\tDisc: 0.380070\t\tSym: 9.803546\t\tSpars: 384.135712\n",
      "\t TVw: 0.274243 | TVb: -2.030948 | GSw: -0.234991 | GSb: 0.064944 | TSUw: 0.464859 | TSUb: 0.034869\n",
      "\n",
      "Train Epoch: 2438 [4000/8000 (50%)]\tBatch Loss: 400.244558\tLearning Rate (w_theta): 0.001000\t TIME:5769.2s\n",
      "\t\t\t\tDisc: 0.372046\t\tSym: 10.422286\t\tSpars: 389.450226\n",
      "\t TVw: 0.274249 | TVb: -2.030913 | GSw: -0.234991 | GSb: 0.064944 | TSUw: 0.464859 | TSUb: 0.034869\n",
      "Validating epoch 2438...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 404.26451541418794\n",
      "Average validation loss: 89.10225757461838\n",
      "Training epoch 2439...\n",
      "\n",
      "Train Epoch: 2439 [0/8000 (0%)]\tBatch Loss: 394.582312\tLearning Rate (w_theta): 0.001000\t TIME:5771.7s\n",
      "\t\t\t\tDisc: 0.368780\t\tSym: 9.732605\t\tSpars: 384.480927\n",
      "\t TVw: 0.274364 | TVb: -2.030879 | GSw: -0.234991 | GSb: 0.064943 | TSUw: 0.464859 | TSUb: 0.034869\n",
      "\n",
      "Train Epoch: 2439 [4000/8000 (50%)]\tBatch Loss: 395.768718\tLearning Rate (w_theta): 0.001000\t TIME:5773.3s\n",
      "\t\t\t\tDisc: 0.408684\t\tSym: 9.391498\t\tSpars: 385.968536\n",
      "\t TVw: 0.274558 | TVb: -2.030836 | GSw: -0.234991 | GSb: 0.064943 | TSUw: 0.464859 | TSUb: 0.034869\n",
      "Validating epoch 2439...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 402.8835952373632\n",
      "Average validation loss: 89.39667358316892\n",
      "Training epoch 2440...\n",
      "\n",
      "Train Epoch: 2440 [0/8000 (0%)]\tBatch Loss: 417.551024\tLearning Rate (w_theta): 0.001000\t TIME:5775.7s\n",
      "\t\t\t\tDisc: 0.392440\t\tSym: 10.979384\t\tSpars: 406.179199\n",
      "\t TVw: 0.274616 | TVb: -2.030801 | GSw: -0.234991 | GSb: 0.064943 | TSUw: 0.464859 | TSUb: 0.034869\n",
      "\n",
      "Train Epoch: 2440 [4000/8000 (50%)]\tBatch Loss: 394.768408\tLearning Rate (w_theta): 0.001000\t TIME:5777.3s\n",
      "\t\t\t\tDisc: 0.394187\t\tSym: 9.782851\t\tSpars: 384.591370\n",
      "\t TVw: 0.274616 | TVb: -2.030769 | GSw: -0.234991 | GSb: 0.064943 | TSUw: 0.464858 | TSUb: 0.034869\n",
      "Validating epoch 2440...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 401.98202043496116\n",
      "Average validation loss: 86.60462261592293\n",
      "Training epoch 2441...\n",
      "\n",
      "Train Epoch: 2441 [0/8000 (0%)]\tBatch Loss: 404.282140\tLearning Rate (w_theta): 0.001000\t TIME:5780.4s\n",
      "\t\t\t\tDisc: 0.384690\t\tSym: 10.295186\t\tSpars: 393.602264\n",
      "\t TVw: 0.274733 | TVb: -2.030735 | GSw: -0.234991 | GSb: 0.064943 | TSUw: 0.464858 | TSUb: 0.034870\n",
      "\n",
      "Train Epoch: 2441 [4000/8000 (50%)]\tBatch Loss: 391.058204\tLearning Rate (w_theta): 0.001000\t TIME:5782.0s\n",
      "\t\t\t\tDisc: 0.386137\t\tSym: 9.655985\t\tSpars: 381.016083\n",
      "\t TVw: 0.274793 | TVb: -2.030706 | GSw: -0.234991 | GSb: 0.064943 | TSUw: 0.464858 | TSUb: 0.034870\n",
      "Validating epoch 2441...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 401.02305437239636\n",
      "Average validation loss: 87.73736729634511\n",
      "Training epoch 2442...\n",
      "\n",
      "Train Epoch: 2442 [0/8000 (0%)]\tBatch Loss: 389.745695\tLearning Rate (w_theta): 0.001000\t TIME:5784.4s\n",
      "\t\t\t\tDisc: 0.375212\t\tSym: 9.390777\t\tSpars: 379.979706\n",
      "\t TVw: 0.274741 | TVb: -2.030682 | GSw: -0.234991 | GSb: 0.064942 | TSUw: 0.464858 | TSUb: 0.034870\n",
      "\n",
      "Train Epoch: 2442 [4000/8000 (50%)]\tBatch Loss: 396.774029\tLearning Rate (w_theta): 0.001000\t TIME:5786.0s\n",
      "\t\t\t\tDisc: 0.394005\t\tSym: 9.896046\t\tSpars: 386.483978\n",
      "\t TVw: 0.274709 | TVb: -2.030659 | GSw: -0.234991 | GSb: 0.064942 | TSUw: 0.464858 | TSUb: 0.034870\n",
      "Validating epoch 2442...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 399.9030123323967\n",
      "Average validation loss: 85.97303819906496\n",
      "Training epoch 2443...\n",
      "\n",
      "Train Epoch: 2443 [0/8000 (0%)]\tBatch Loss: 398.510471\tLearning Rate (w_theta): 0.001000\t TIME:5788.5s\n",
      "\t\t\t\tDisc: 0.371749\t\tSym: 9.753102\t\tSpars: 388.385620\n",
      "\t TVw: 0.274736 | TVb: -2.030627 | GSw: -0.234991 | GSb: 0.064942 | TSUw: 0.464858 | TSUb: 0.034870\n",
      "\n",
      "Train Epoch: 2443 [4000/8000 (50%)]\tBatch Loss: 399.732480\tLearning Rate (w_theta): 0.001000\t TIME:5790.5s\n",
      "\t\t\t\tDisc: 0.368029\t\tSym: 10.586253\t\tSpars: 388.778198\n",
      "\t TVw: 0.274862 | TVb: -2.030590 | GSw: -0.234991 | GSb: 0.064942 | TSUw: 0.464858 | TSUb: 0.034870\n",
      "Validating epoch 2443...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 398.58572896897493\n",
      "Average validation loss: 84.70439267907781\n",
      "Training epoch 2444...\n",
      "\n",
      "Train Epoch: 2444 [0/8000 (0%)]\tBatch Loss: 404.671514\tLearning Rate (w_theta): 0.001000\t TIME:5792.9s\n",
      "\t\t\t\tDisc: 0.358040\t\tSym: 10.668180\t\tSpars: 393.645294\n",
      "\t TVw: 0.274998 | TVb: -2.030545 | GSw: -0.234991 | GSb: 0.064942 | TSUw: 0.464858 | TSUb: 0.034870\n",
      "\n",
      "Train Epoch: 2444 [4000/8000 (50%)]\tBatch Loss: 379.738404\tLearning Rate (w_theta): 0.001000\t TIME:5794.5s\n",
      "\t\t\t\tDisc: 0.390256\t\tSym: 8.895877\t\tSpars: 370.452271\n",
      "\t TVw: 0.275028 | TVb: -2.030514 | GSw: -0.234992 | GSb: 0.064941 | TSUw: 0.464857 | TSUb: 0.034870\n",
      "Validating epoch 2444...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 399.6066689151538\n",
      "Average validation loss: 85.84615405774258\n",
      "Training epoch 2445...\n",
      "\n",
      "Train Epoch: 2445 [0/8000 (0%)]\tBatch Loss: 394.773865\tLearning Rate (w_theta): 0.001000\t TIME:5797.0s\n",
      "\t\t\t\tDisc: 0.376944\t\tSym: 10.344309\t\tSpars: 384.052612\n",
      "\t TVw: 0.275016 | TVb: -2.030482 | GSw: -0.234992 | GSb: 0.064941 | TSUw: 0.464857 | TSUb: 0.034871\n",
      "\n",
      "Train Epoch: 2445 [4000/8000 (50%)]\tBatch Loss: 415.513750\tLearning Rate (w_theta): 0.001000\t TIME:5798.6s\n",
      "\t\t\t\tDisc: 0.410694\t\tSym: 10.612303\t\tSpars: 404.490753\n",
      "\t TVw: 0.275034 | TVb: -2.030449 | GSw: -0.234992 | GSb: 0.064941 | TSUw: 0.464857 | TSUb: 0.034871\n",
      "Validating epoch 2445...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 403.55728975770194\n",
      "Average validation loss: 91.6437689440221\n",
      "Training epoch 2446...\n",
      "\n",
      "Train Epoch: 2446 [0/8000 (0%)]\tBatch Loss: 421.312234\tLearning Rate (w_theta): 0.001000\t TIME:5801.0s\n",
      "\t\t\t\tDisc: 0.446878\t\tSym: 10.676696\t\tSpars: 410.188660\n",
      "\t TVw: 0.274500 | TVb: -2.030452 | GSw: -0.234992 | GSb: 0.064941 | TSUw: 0.464857 | TSUb: 0.034871\n",
      "\n",
      "Train Epoch: 2446 [4000/8000 (50%)]\tBatch Loss: 400.336682\tLearning Rate (w_theta): 0.001000\t TIME:5802.6s\n",
      "\t\t\t\tDisc: 0.337746\t\tSym: 10.280614\t\tSpars: 389.718323\n",
      "\t TVw: 0.273845 | TVb: -2.030463 | GSw: -0.234992 | GSb: 0.064941 | TSUw: 0.464857 | TSUb: 0.034871\n",
      "Validating epoch 2446...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 406.38345446810825\n",
      "Average validation loss: 84.04635828365824\n",
      "Training epoch 2447...\n",
      "\n",
      "Train Epoch: 2447 [0/8000 (0%)]\tBatch Loss: 387.549271\tLearning Rate (w_theta): 0.001000\t TIME:5805.0s\n",
      "\t\t\t\tDisc: 0.348729\t\tSym: 9.403667\t\tSpars: 377.796875\n",
      "\t TVw: 0.274048 | TVb: -2.030427 | GSw: -0.234992 | GSb: 0.064941 | TSUw: 0.464857 | TSUb: 0.034871\n",
      "\n",
      "Train Epoch: 2447 [4000/8000 (50%)]\tBatch Loss: 426.446595\tLearning Rate (w_theta): 0.001000\t TIME:5806.6s\n",
      "\t\t\t\tDisc: 0.403203\t\tSym: 11.326961\t\tSpars: 414.716431\n",
      "\t TVw: 0.274423 | TVb: -2.030395 | GSw: -0.234992 | GSb: 0.064940 | TSUw: 0.464857 | TSUb: 0.034871\n",
      "Validating epoch 2447...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 406.7124384304219\n",
      "Average validation loss: 89.32418802678214\n",
      "Training epoch 2448...\n",
      "\n",
      "Train Epoch: 2448 [0/8000 (0%)]\tBatch Loss: 434.925952\tLearning Rate (w_theta): 0.001000\t TIME:5809.1s\n",
      "\t\t\t\tDisc: 0.412448\t\tSym: 11.438217\t\tSpars: 423.075287\n",
      "\t TVw: 0.274399 | TVb: -2.030391 | GSw: -0.234992 | GSb: 0.064940 | TSUw: 0.464857 | TSUb: 0.034872\n",
      "\n",
      "Train Epoch: 2448 [4000/8000 (50%)]\tBatch Loss: 382.876070\tLearning Rate (w_theta): 0.001000\t TIME:5810.7s\n",
      "\t\t\t\tDisc: 0.376019\t\tSym: 9.810597\t\tSpars: 372.689453\n",
      "\t TVw: 0.274121 | TVb: -2.030387 | GSw: -0.234992 | GSb: 0.064940 | TSUw: 0.464856 | TSUb: 0.034872\n",
      "Validating epoch 2448...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 408.6290732576277\n",
      "Average validation loss: 82.51616261903357\n",
      "Training epoch 2449...\n",
      "\n",
      "Train Epoch: 2449 [0/8000 (0%)]\tBatch Loss: 397.421449\tLearning Rate (w_theta): 0.001000\t TIME:5813.1s\n",
      "\t\t\t\tDisc: 0.386049\t\tSym: 10.514160\t\tSpars: 386.521240\n",
      "\t TVw: 0.274221 | TVb: -2.030363 | GSw: -0.234992 | GSb: 0.064940 | TSUw: 0.464856 | TSUb: 0.034872\n",
      "\n",
      "Train Epoch: 2449 [4000/8000 (50%)]\tBatch Loss: 421.729456\tLearning Rate (w_theta): 0.001000\t TIME:5814.7s\n",
      "\t\t\t\tDisc: 0.369845\t\tSym: 10.699454\t\tSpars: 410.660156\n",
      "\t TVw: 0.274851 | TVb: -2.030312 | GSw: -0.234992 | GSb: 0.064940 | TSUw: 0.464856 | TSUb: 0.034872\n",
      "Validating epoch 2449...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 402.14521226300496\n",
      "Average validation loss: 81.88006354177432\n",
      "Training epoch 2450...\n",
      "\n",
      "Train Epoch: 2450 [0/8000 (0%)]\tBatch Loss: 403.282855\tLearning Rate (w_theta): 0.001000\t TIME:5817.2s\n",
      "\t\t\t\tDisc: 0.404722\t\tSym: 10.931508\t\tSpars: 391.946625\n",
      "\t TVw: 0.275470 | TVb: -2.030267 | GSw: -0.234992 | GSb: 0.064940 | TSUw: 0.464856 | TSUb: 0.034872\n",
      "\n",
      "Train Epoch: 2450 [4000/8000 (50%)]\tBatch Loss: 404.645792\tLearning Rate (w_theta): 0.001000\t TIME:5818.7s\n",
      "\t\t\t\tDisc: 0.379615\t\tSym: 10.338840\t\tSpars: 393.927338\n",
      "\t TVw: 0.276191 | TVb: -2.030209 | GSw: -0.234992 | GSb: 0.064939 | TSUw: 0.464856 | TSUb: 0.034872\n",
      "Validating epoch 2450...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 396.4590601883534\n",
      "Average validation loss: 85.46024238442659\n",
      "Training epoch 2451...\n",
      "\n",
      "Train Epoch: 2451 [0/8000 (0%)]\tBatch Loss: 372.463371\tLearning Rate (w_theta): 0.001000\t TIME:5821.9s\n",
      "\t\t\t\tDisc: 0.367738\t\tSym: 8.525076\t\tSpars: 363.570557\n",
      "\t TVw: 0.276819 | TVb: -2.030153 | GSw: -0.234992 | GSb: 0.064939 | TSUw: 0.464856 | TSUb: 0.034873\n",
      "\n",
      "Train Epoch: 2451 [4000/8000 (50%)]\tBatch Loss: 385.360843\tLearning Rate (w_theta): 0.001000\t TIME:5823.5s\n",
      "\t\t\t\tDisc: 0.399033\t\tSym: 10.212786\t\tSpars: 374.749023\n",
      "\t TVw: 0.277426 | TVb: -2.030100 | GSw: -0.234992 | GSb: 0.064939 | TSUw: 0.464856 | TSUb: 0.034873\n",
      "Validating epoch 2451...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 395.04702727853567\n",
      "Average validation loss: 87.50302040923917\n",
      "Training epoch 2452...\n",
      "\n",
      "Train Epoch: 2452 [0/8000 (0%)]\tBatch Loss: 412.249007\tLearning Rate (w_theta): 0.001000\t TIME:5826.0s\n",
      "\t\t\t\tDisc: 0.404789\t\tSym: 11.470103\t\tSpars: 400.374115\n",
      "\t TVw: 0.277943 | TVb: -2.030043 | GSw: -0.234992 | GSb: 0.064939 | TSUw: 0.464856 | TSUb: 0.034873\n",
      "\n",
      "Train Epoch: 2452 [4000/8000 (50%)]\tBatch Loss: 385.439696\tLearning Rate (w_theta): 0.001000\t TIME:5827.6s\n",
      "\t\t\t\tDisc: 0.402687\t\tSym: 9.685233\t\tSpars: 375.351776\n",
      "\t TVw: 0.278290 | TVb: -2.029989 | GSw: -0.234992 | GSb: 0.064939 | TSUw: 0.464856 | TSUb: 0.034873\n",
      "Validating epoch 2452...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 395.65284253779464\n",
      "Average validation loss: 83.64182139960968\n",
      "Training epoch 2453...\n",
      "\n",
      "Train Epoch: 2453 [0/8000 (0%)]\tBatch Loss: 387.448289\tLearning Rate (w_theta): 0.001000\t TIME:5830.0s\n",
      "\t\t\t\tDisc: 0.403406\t\tSym: 9.682670\t\tSpars: 377.362213\n",
      "\t TVw: 0.278384 | TVb: -2.029943 | GSw: -0.234993 | GSb: 0.064938 | TSUw: 0.464855 | TSUb: 0.034873\n",
      "\n",
      "Train Epoch: 2453 [4000/8000 (50%)]\tBatch Loss: 396.778192\tLearning Rate (w_theta): 0.001000\t TIME:5831.6s\n",
      "\t\t\t\tDisc: 0.410411\t\tSym: 10.564833\t\tSpars: 385.802948\n",
      "\t TVw: 0.278281 | TVb: -2.029911 | GSw: -0.234993 | GSb: 0.064938 | TSUw: 0.464855 | TSUb: 0.034873\n",
      "Validating epoch 2453...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 393.40656628940854\n",
      "Average validation loss: 88.60977776047665\n",
      "Training epoch 2454...\n",
      "\n",
      "Train Epoch: 2454 [0/8000 (0%)]\tBatch Loss: 382.234375\tLearning Rate (w_theta): 0.001000\t TIME:5834.1s\n",
      "\t\t\t\tDisc: 0.413708\t\tSym: 9.271839\t\tSpars: 372.548828\n",
      "\t TVw: 0.278086 | TVb: -2.029885 | GSw: -0.234993 | GSb: 0.064938 | TSUw: 0.464855 | TSUb: 0.034873\n",
      "\n",
      "Train Epoch: 2454 [4000/8000 (50%)]\tBatch Loss: 407.583143\tLearning Rate (w_theta): 0.001000\t TIME:5835.6s\n",
      "\t\t\t\tDisc: 0.405051\t\tSym: 11.635154\t\tSpars: 395.542938\n",
      "\t TVw: 0.277865 | TVb: -2.029860 | GSw: -0.234993 | GSb: 0.064938 | TSUw: 0.464855 | TSUb: 0.034874\n",
      "Validating epoch 2454...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 391.90417113400764\n",
      "Average validation loss: 86.52630099019025\n",
      "Training epoch 2455...\n",
      "\n",
      "Train Epoch: 2455 [0/8000 (0%)]\tBatch Loss: 408.172760\tLearning Rate (w_theta): 0.001000\t TIME:5838.1s\n",
      "\t\t\t\tDisc: 0.419434\t\tSym: 11.745270\t\tSpars: 396.008057\n",
      "\t TVw: 0.277736 | TVb: -2.029830 | GSw: -0.234993 | GSb: 0.064938 | TSUw: 0.464855 | TSUb: 0.034874\n",
      "\n",
      "Train Epoch: 2455 [4000/8000 (50%)]\tBatch Loss: 395.889662\tLearning Rate (w_theta): 0.001000\t TIME:5839.7s\n",
      "\t\t\t\tDisc: 0.374485\t\tSym: 10.028300\t\tSpars: 385.486877\n",
      "\t TVw: 0.277398 | TVb: -2.029802 | GSw: -0.234993 | GSb: 0.064938 | TSUw: 0.464855 | TSUb: 0.034874\n",
      "Validating epoch 2455...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 394.7101413702452\n",
      "Average validation loss: 85.40676282929579\n",
      "Training epoch 2456...\n",
      "\n",
      "Train Epoch: 2456 [0/8000 (0%)]\tBatch Loss: 406.081743\tLearning Rate (w_theta): 0.001000\t TIME:5842.6s\n",
      "\t\t\t\tDisc: 0.396441\t\tSym: 10.684142\t\tSpars: 395.001160\n",
      "\t TVw: 0.277105 | TVb: -2.029785 | GSw: -0.234993 | GSb: 0.064937 | TSUw: 0.464855 | TSUb: 0.034874\n",
      "\n",
      "Train Epoch: 2456 [4000/8000 (50%)]\tBatch Loss: 393.418154\tLearning Rate (w_theta): 0.001000\t TIME:5844.2s\n",
      "\t\t\t\tDisc: 0.395858\t\tSym: 10.426716\t\tSpars: 382.595581\n",
      "\t TVw: 0.276893 | TVb: -2.029772 | GSw: -0.234993 | GSb: 0.064937 | TSUw: 0.464855 | TSUb: 0.034874\n",
      "Validating epoch 2456...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 391.38135002175096\n",
      "Average validation loss: 86.30689686617104\n",
      "Training epoch 2457...\n",
      "\n",
      "Train Epoch: 2457 [0/8000 (0%)]\tBatch Loss: 394.731046\tLearning Rate (w_theta): 0.001000\t TIME:5846.6s\n",
      "\t\t\t\tDisc: 0.403257\t\tSym: 10.744354\t\tSpars: 383.583435\n",
      "\t TVw: 0.277052 | TVb: -2.029732 | GSw: -0.234993 | GSb: 0.064937 | TSUw: 0.464854 | TSUb: 0.034874\n",
      "\n",
      "Train Epoch: 2457 [4000/8000 (50%)]\tBatch Loss: 385.141796\tLearning Rate (w_theta): 0.001000\t TIME:5848.2s\n",
      "\t\t\t\tDisc: 0.386507\t\tSym: 9.585215\t\tSpars: 375.170074\n",
      "\t TVw: 0.277435 | TVb: -2.029681 | GSw: -0.234993 | GSb: 0.064937 | TSUw: 0.464854 | TSUb: 0.034874\n",
      "Validating epoch 2457...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 387.9002609058855\n",
      "Average validation loss: 84.76175205389346\n",
      "Training epoch 2458...\n",
      "\n",
      "Train Epoch: 2458 [0/8000 (0%)]\tBatch Loss: 380.311134\tLearning Rate (w_theta): 0.001000\t TIME:5850.6s\n",
      "\t\t\t\tDisc: 0.382770\t\tSym: 9.774282\t\tSpars: 370.154083\n",
      "\t TVw: 0.277644 | TVb: -2.029639 | GSw: -0.234993 | GSb: 0.064937 | TSUw: 0.464854 | TSUb: 0.034875\n",
      "\n",
      "Train Epoch: 2458 [4000/8000 (50%)]\tBatch Loss: 382.501672\tLearning Rate (w_theta): 0.001000\t TIME:5852.2s\n",
      "\t\t\t\tDisc: 0.363425\t\tSym: 9.621737\t\tSpars: 372.516510\n",
      "\t TVw: 0.277623 | TVb: -2.029600 | GSw: -0.234993 | GSb: 0.064936 | TSUw: 0.464854 | TSUb: 0.034875\n",
      "Validating epoch 2458...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 386.8290129188285\n",
      "Average validation loss: 83.84498685203427\n",
      "Training epoch 2459...\n",
      "\n",
      "Train Epoch: 2459 [0/8000 (0%)]\tBatch Loss: 383.692300\tLearning Rate (w_theta): 0.001000\t TIME:5854.6s\n",
      "\t\t\t\tDisc: 0.397707\t\tSym: 10.097846\t\tSpars: 373.196747\n",
      "\t TVw: 0.277718 | TVb: -2.029559 | GSw: -0.234993 | GSb: 0.064936 | TSUw: 0.464854 | TSUb: 0.034875\n",
      "\n",
      "Train Epoch: 2459 [4000/8000 (50%)]\tBatch Loss: 405.697098\tLearning Rate (w_theta): 0.001000\t TIME:5856.2s\n",
      "\t\t\t\tDisc: 0.386601\t\tSym: 11.836314\t\tSpars: 393.474182\n",
      "\t TVw: 0.277955 | TVb: -2.029509 | GSw: -0.234993 | GSb: 0.064936 | TSUw: 0.464854 | TSUb: 0.034875\n",
      "Validating epoch 2459...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 385.78309104510106\n",
      "Average validation loss: 84.53789011532835\n",
      "Training epoch 2460...\n",
      "\n",
      "Train Epoch: 2460 [0/8000 (0%)]\tBatch Loss: 386.133932\tLearning Rate (w_theta): 0.001000\t TIME:5858.7s\n",
      "\t\t\t\tDisc: 0.390515\t\tSym: 10.394265\t\tSpars: 375.349152\n",
      "\t TVw: 0.278050 | TVb: -2.029463 | GSw: -0.234993 | GSb: 0.064936 | TSUw: 0.464854 | TSUb: 0.034875\n",
      "\n",
      "Train Epoch: 2460 [4000/8000 (50%)]\tBatch Loss: 381.707127\tLearning Rate (w_theta): 0.001000\t TIME:5860.3s\n",
      "\t\t\t\tDisc: 0.413265\t\tSym: 9.925820\t\tSpars: 371.368042\n",
      "\t TVw: 0.278013 | TVb: -2.029427 | GSw: -0.234993 | GSb: 0.064936 | TSUw: 0.464854 | TSUb: 0.034875\n",
      "Validating epoch 2460...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 385.7804599031865\n",
      "Average validation loss: 82.11850760680733\n",
      "Training epoch 2461...\n",
      "\n",
      "Train Epoch: 2461 [0/8000 (0%)]\tBatch Loss: 381.029458\tLearning Rate (w_theta): 0.001000\t TIME:5863.4s\n",
      "\t\t\t\tDisc: 0.375933\t\tSym: 9.735953\t\tSpars: 370.917572\n",
      "\t TVw: 0.278005 | TVb: -2.029384 | GSw: -0.234993 | GSb: 0.064936 | TSUw: 0.464853 | TSUb: 0.034876\n",
      "\n",
      "Train Epoch: 2461 [4000/8000 (50%)]\tBatch Loss: 375.405300\tLearning Rate (w_theta): 0.001000\t TIME:5865.0s\n",
      "\t\t\t\tDisc: 0.374448\t\tSym: 9.917418\t\tSpars: 365.113434\n",
      "\t TVw: 0.277870 | TVb: -2.029353 | GSw: -0.234994 | GSb: 0.064935 | TSUw: 0.464853 | TSUb: 0.034876\n",
      "Validating epoch 2461...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 385.62924509528483\n",
      "Average validation loss: 86.2678898471941\n",
      "Training epoch 2462...\n",
      "\n",
      "Train Epoch: 2462 [0/8000 (0%)]\tBatch Loss: 384.414049\tLearning Rate (w_theta): 0.001000\t TIME:5867.4s\n",
      "\t\t\t\tDisc: 0.405585\t\tSym: 10.341716\t\tSpars: 373.666748\n",
      "\t TVw: 0.277635 | TVb: -2.029332 | GSw: -0.234994 | GSb: 0.064935 | TSUw: 0.464853 | TSUb: 0.034876\n",
      "\n",
      "Train Epoch: 2462 [4000/8000 (50%)]\tBatch Loss: 386.844474\tLearning Rate (w_theta): 0.001000\t TIME:5869.0s\n",
      "\t\t\t\tDisc: 0.379842\t\tSym: 10.041353\t\tSpars: 376.423279\n",
      "\t TVw: 0.277502 | TVb: -2.029309 | GSw: -0.234994 | GSb: 0.064935 | TSUw: 0.464853 | TSUb: 0.034876\n",
      "Validating epoch 2462...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 386.58019959792847\n",
      "Average validation loss: 80.81682785942125\n",
      "Training epoch 2463...\n",
      "\n",
      "Train Epoch: 2463 [0/8000 (0%)]\tBatch Loss: 372.308642\tLearning Rate (w_theta): 0.001000\t TIME:5871.5s\n",
      "\t\t\t\tDisc: 0.364678\t\tSym: 9.765284\t\tSpars: 362.178680\n",
      "\t TVw: 0.277343 | TVb: -2.029282 | GSw: -0.234994 | GSb: 0.064935 | TSUw: 0.464853 | TSUb: 0.034876\n",
      "\n",
      "Train Epoch: 2463 [4000/8000 (50%)]\tBatch Loss: 399.263485\tLearning Rate (w_theta): 0.001000\t TIME:5873.1s\n",
      "\t\t\t\tDisc: 0.416503\t\tSym: 10.057889\t\tSpars: 388.789093\n",
      "\t TVw: 0.276852 | TVb: -2.029279 | GSw: -0.234994 | GSb: 0.064935 | TSUw: 0.464853 | TSUb: 0.034876\n",
      "Validating epoch 2463...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 394.145676731065\n",
      "Average validation loss: 86.76046483129184\n",
      "Training epoch 2464...\n",
      "\n",
      "Train Epoch: 2464 [0/8000 (0%)]\tBatch Loss: 415.052818\tLearning Rate (w_theta): 0.001000\t TIME:5875.6s\n",
      "\t\t\t\tDisc: 0.416637\t\tSym: 11.416241\t\tSpars: 403.219940\n",
      "\t TVw: 0.276635 | TVb: -2.029284 | GSw: -0.234994 | GSb: 0.064934 | TSUw: 0.464853 | TSUb: 0.034876\n",
      "\n",
      "Train Epoch: 2464 [4000/8000 (50%)]\tBatch Loss: 385.688343\tLearning Rate (w_theta): 0.001000\t TIME:5877.2s\n",
      "\t\t\t\tDisc: 0.376640\t\tSym: 10.160641\t\tSpars: 375.151062\n",
      "\t TVw: 0.276819 | TVb: -2.029264 | GSw: -0.234994 | GSb: 0.064934 | TSUw: 0.464853 | TSUb: 0.034877\n",
      "Validating epoch 2464...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 389.9153533977549\n",
      "Average validation loss: 78.9415157937295\n",
      "Training epoch 2465...\n",
      "\n",
      "Train Epoch: 2465 [0/8000 (0%)]\tBatch Loss: 398.980069\tLearning Rate (w_theta): 0.001000\t TIME:5879.7s\n",
      "\t\t\t\tDisc: 0.389046\t\tSym: 11.154194\t\tSpars: 387.436829\n",
      "\t TVw: 0.277220 | TVb: -2.029224 | GSw: -0.234994 | GSb: 0.064934 | TSUw: 0.464853 | TSUb: 0.034877\n",
      "\n",
      "Train Epoch: 2465 [4000/8000 (50%)]\tBatch Loss: 385.704329\tLearning Rate (w_theta): 0.001000\t TIME:5881.3s\n",
      "\t\t\t\tDisc: 0.405422\t\tSym: 9.858294\t\tSpars: 375.440613\n",
      "\t TVw: 0.277504 | TVb: -2.029191 | GSw: -0.234994 | GSb: 0.064934 | TSUw: 0.464852 | TSUb: 0.034877\n",
      "Validating epoch 2465...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 390.2340750636505\n",
      "Average validation loss: 83.76475956452545\n",
      "Training epoch 2466...\n",
      "\n",
      "Train Epoch: 2466 [0/8000 (0%)]\tBatch Loss: 378.966501\tLearning Rate (w_theta): 0.001000\t TIME:5883.7s\n",
      "\t\t\t\tDisc: 0.378566\t\tSym: 9.524428\t\tSpars: 369.063507\n",
      "\t TVw: 0.277777 | TVb: -2.029161 | GSw: -0.234994 | GSb: 0.064934 | TSUw: 0.464852 | TSUb: 0.034877\n",
      "\n",
      "Train Epoch: 2466 [4000/8000 (50%)]\tBatch Loss: 375.181339\tLearning Rate (w_theta): 0.001000\t TIME:5885.3s\n",
      "\t\t\t\tDisc: 0.406492\t\tSym: 9.834448\t\tSpars: 364.940399\n",
      "\t TVw: 0.278295 | TVb: -2.029105 | GSw: -0.234994 | GSb: 0.064934 | TSUw: 0.464852 | TSUb: 0.034877\n",
      "Validating epoch 2466...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 383.99045698208323\n",
      "Average validation loss: 82.7985640613859\n",
      "Training epoch 2467...\n",
      "\n",
      "Train Epoch: 2467 [0/8000 (0%)]\tBatch Loss: 374.093943\tLearning Rate (w_theta): 0.001000\t TIME:5887.7s\n",
      "\t\t\t\tDisc: 0.403289\t\tSym: 9.368083\t\tSpars: 364.322571\n",
      "\t TVw: 0.278871 | TVb: -2.029038 | GSw: -0.234994 | GSb: 0.064933 | TSUw: 0.464852 | TSUb: 0.034877\n",
      "\n",
      "Train Epoch: 2467 [4000/8000 (50%)]\tBatch Loss: 382.305883\tLearning Rate (w_theta): 0.001000\t TIME:5889.3s\n",
      "\t\t\t\tDisc: 0.395750\t\tSym: 9.871956\t\tSpars: 372.038177\n",
      "\t TVw: 0.279280 | TVb: -2.028975 | GSw: -0.234994 | GSb: 0.064933 | TSUw: 0.464852 | TSUb: 0.034878\n",
      "Validating epoch 2467...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 379.61594233731415\n",
      "Average validation loss: 82.4006254662291\n",
      "Training epoch 2468...\n",
      "\n",
      "Train Epoch: 2468 [0/8000 (0%)]\tBatch Loss: 380.856032\tLearning Rate (w_theta): 0.001000\t TIME:5891.8s\n",
      "\t\t\t\tDisc: 0.393685\t\tSym: 10.301610\t\tSpars: 370.160736\n",
      "\t TVw: 0.279535 | TVb: -2.028918 | GSw: -0.234994 | GSb: 0.064933 | TSUw: 0.464852 | TSUb: 0.034878\n",
      "\n",
      "Train Epoch: 2468 [4000/8000 (50%)]\tBatch Loss: 396.142599\tLearning Rate (w_theta): 0.001000\t TIME:5893.4s\n",
      "\t\t\t\tDisc: 0.414288\t\tSym: 11.497751\t\tSpars: 384.230560\n",
      "\t TVw: 0.279709 | TVb: -2.028863 | GSw: -0.234994 | GSb: 0.064933 | TSUw: 0.464852 | TSUb: 0.034878\n",
      "Validating epoch 2468...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 378.42558671577234\n",
      "Average validation loss: 85.26957299491059\n",
      "Training epoch 2469...\n",
      "\n",
      "Train Epoch: 2469 [0/8000 (0%)]\tBatch Loss: 392.019595\tLearning Rate (w_theta): 0.001000\t TIME:5896.2s\n",
      "\t\t\t\tDisc: 0.418667\t\tSym: 11.338232\t\tSpars: 380.262695\n",
      "\t TVw: 0.279883 | TVb: -2.028812 | GSw: -0.234994 | GSb: 0.064933 | TSUw: 0.464852 | TSUb: 0.034878\n",
      "\n",
      "Train Epoch: 2469 [4000/8000 (50%)]\tBatch Loss: 343.142699\tLearning Rate (w_theta): 0.001000\t TIME:5897.8s\n",
      "\t\t\t\tDisc: 0.400782\t\tSym: 7.852695\t\tSpars: 334.889221\n",
      "\t TVw: 0.279904 | TVb: -2.028769 | GSw: -0.234995 | GSb: 0.064933 | TSUw: 0.464851 | TSUb: 0.034878\n",
      "Validating epoch 2469...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 377.6050465606998\n",
      "Average validation loss: 83.55980069313975\n",
      "Training epoch 2470...\n",
      "\n",
      "Train Epoch: 2470 [0/8000 (0%)]\tBatch Loss: 381.095299\tLearning Rate (w_theta): 0.001000\t TIME:5900.3s\n",
      "\t\t\t\tDisc: 0.397943\t\tSym: 10.521422\t\tSpars: 370.175934\n",
      "\t TVw: 0.279678 | TVb: -2.028738 | GSw: -0.234995 | GSb: 0.064932 | TSUw: 0.464851 | TSUb: 0.034878\n",
      "\n",
      "Train Epoch: 2470 [4000/8000 (50%)]\tBatch Loss: 382.854029\tLearning Rate (w_theta): 0.001000\t TIME:5901.8s\n",
      "\t\t\t\tDisc: 0.389823\t\tSym: 9.937504\t\tSpars: 372.526703\n",
      "\t TVw: 0.279501 | TVb: -2.028712 | GSw: -0.234995 | GSb: 0.064932 | TSUw: 0.464851 | TSUb: 0.034878\n",
      "Validating epoch 2470...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 376.2478952405172\n",
      "Average validation loss: 82.76113430548993\n",
      "Training epoch 2471...\n",
      "\n",
      "Train Epoch: 2471 [0/8000 (0%)]\tBatch Loss: 363.638112\tLearning Rate (w_theta): 0.001000\t TIME:5904.9s\n",
      "\t\t\t\tDisc: 0.407959\t\tSym: 9.373189\t\tSpars: 353.856964\n",
      "\t TVw: 0.279230 | TVb: -2.028696 | GSw: -0.234995 | GSb: 0.064932 | TSUw: 0.464851 | TSUb: 0.034879\n",
      "\n",
      "Train Epoch: 2471 [4000/8000 (50%)]\tBatch Loss: 373.597860\tLearning Rate (w_theta): 0.001000\t TIME:5906.5s\n",
      "\t\t\t\tDisc: 0.420860\t\tSym: 10.342436\t\tSpars: 362.834564\n",
      "\t TVw: 0.279038 | TVb: -2.028677 | GSw: -0.234995 | GSb: 0.064932 | TSUw: 0.464851 | TSUb: 0.034879\n",
      "Validating epoch 2471...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 375.45687704394754\n",
      "Average validation loss: 81.69504800166726\n",
      "Training epoch 2472...\n",
      "\n",
      "Train Epoch: 2472 [0/8000 (0%)]\tBatch Loss: 391.011789\tLearning Rate (w_theta): 0.001000\t TIME:5909.0s\n",
      "\t\t\t\tDisc: 0.395949\t\tSym: 10.752711\t\tSpars: 379.863129\n",
      "\t TVw: 0.278934 | TVb: -2.028647 | GSw: -0.234995 | GSb: 0.064932 | TSUw: 0.464851 | TSUb: 0.034879\n",
      "\n",
      "Train Epoch: 2472 [4000/8000 (50%)]\tBatch Loss: 358.443462\tLearning Rate (w_theta): 0.001000\t TIME:5910.5s\n",
      "\t\t\t\tDisc: 0.390176\t\tSym: 9.706972\t\tSpars: 348.346313\n",
      "\t TVw: 0.278856 | TVb: -2.028614 | GSw: -0.234995 | GSb: 0.064931 | TSUw: 0.464851 | TSUb: 0.034879\n",
      "Validating epoch 2472...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 374.98621574777223\n",
      "Average validation loss: 81.73230242016572\n",
      "Training epoch 2473...\n",
      "\n",
      "Train Epoch: 2473 [0/8000 (0%)]\tBatch Loss: 361.284651\tLearning Rate (w_theta): 0.001000\t TIME:5913.0s\n",
      "\t\t\t\tDisc: 0.403631\t\tSym: 9.531716\t\tSpars: 351.349304\n",
      "\t TVw: 0.278806 | TVb: -2.028581 | GSw: -0.234995 | GSb: 0.064931 | TSUw: 0.464851 | TSUb: 0.034879\n",
      "\n",
      "Train Epoch: 2473 [4000/8000 (50%)]\tBatch Loss: 366.659955\tLearning Rate (w_theta): 0.001000\t TIME:5914.6s\n",
      "\t\t\t\tDisc: 0.445721\t\tSym: 8.911714\t\tSpars: 357.302521\n",
      "\t TVw: 0.278725 | TVb: -2.028543 | GSw: -0.234995 | GSb: 0.064931 | TSUw: 0.464851 | TSUb: 0.034879\n",
      "Validating epoch 2473...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 381.640571623331\n",
      "Average validation loss: 84.80546567262485\n",
      "Training epoch 2474...\n",
      "\n",
      "Train Epoch: 2474 [0/8000 (0%)]\tBatch Loss: 370.958849\tLearning Rate (w_theta): 0.001000\t TIME:5917.0s\n",
      "\t\t\t\tDisc: 0.422447\t\tSym: 9.481318\t\tSpars: 361.055084\n",
      "\t TVw: 0.278069 | TVb: -2.028559 | GSw: -0.234995 | GSb: 0.064931 | TSUw: 0.464850 | TSUb: 0.034880\n",
      "\n",
      "Train Epoch: 2474 [4000/8000 (50%)]\tBatch Loss: 403.271771\tLearning Rate (w_theta): 0.001000\t TIME:5918.6s\n",
      "\t\t\t\tDisc: 0.397912\t\tSym: 11.295276\t\tSpars: 391.578583\n",
      "\t TVw: 0.277607 | TVb: -2.028569 | GSw: -0.234995 | GSb: 0.064931 | TSUw: 0.464850 | TSUb: 0.034880\n",
      "Validating epoch 2474...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 385.41418385707976\n",
      "Average validation loss: 76.98239752086539\n",
      "Training epoch 2475...\n",
      "\n",
      "Train Epoch: 2475 [0/8000 (0%)]\tBatch Loss: 374.970942\tLearning Rate (w_theta): 0.001000\t TIME:5921.1s\n",
      "\t\t\t\tDisc: 0.370631\t\tSym: 10.076508\t\tSpars: 364.523804\n",
      "\t TVw: 0.277740 | TVb: -2.028557 | GSw: -0.234995 | GSb: 0.064930 | TSUw: 0.464850 | TSUb: 0.034880\n",
      "\n",
      "Train Epoch: 2475 [4000/8000 (50%)]\tBatch Loss: 353.828478\tLearning Rate (w_theta): 0.001000\t TIME:5922.7s\n",
      "\t\t\t\tDisc: 0.404353\t\tSym: 8.880790\t\tSpars: 344.543335\n",
      "\t TVw: 0.277998 | TVb: -2.028545 | GSw: -0.234995 | GSb: 0.064930 | TSUw: 0.464850 | TSUb: 0.034880\n",
      "Validating epoch 2475...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 385.50472857200475\n",
      "Average validation loss: 86.2971580353447\n",
      "Training epoch 2476...\n",
      "\n",
      "Train Epoch: 2476 [0/8000 (0%)]\tBatch Loss: 385.738028\tLearning Rate (w_theta): 0.001000\t TIME:5925.1s\n",
      "\t\t\t\tDisc: 0.453288\t\tSym: 9.580699\t\tSpars: 375.704041\n",
      "\t TVw: 0.278616 | TVb: -2.028511 | GSw: -0.234995 | GSb: 0.064930 | TSUw: 0.464850 | TSUb: 0.034880\n",
      "\n",
      "Train Epoch: 2476 [4000/8000 (50%)]\tBatch Loss: 384.269635\tLearning Rate (w_theta): 0.001000\t TIME:5926.7s\n",
      "\t\t\t\tDisc: 0.389540\t\tSym: 10.736358\t\tSpars: 373.143738\n",
      "\t TVw: 0.278838 | TVb: -2.028499 | GSw: -0.234995 | GSb: 0.064930 | TSUw: 0.464850 | TSUb: 0.034880\n",
      "Validating epoch 2476...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 382.9709657012382\n",
      "Average validation loss: 84.12464766338523\n",
      "Training epoch 2477...\n",
      "\n",
      "Train Epoch: 2477 [0/8000 (0%)]\tBatch Loss: 383.804367\tLearning Rate (w_theta): 0.001000\t TIME:5929.2s\n",
      "\t\t\t\tDisc: 0.424558\t\tSym: 10.599292\t\tSpars: 372.780518\n",
      "\t TVw: 0.279875 | TVb: -2.028419 | GSw: -0.234995 | GSb: 0.064930 | TSUw: 0.464849 | TSUb: 0.034881\n",
      "\n",
      "Train Epoch: 2477 [4000/8000 (50%)]\tBatch Loss: 378.317082\tLearning Rate (w_theta): 0.001000\t TIME:5930.8s\n",
      "\t\t\t\tDisc: 0.365871\t\tSym: 9.240304\t\tSpars: 368.710907\n",
      "\t TVw: 0.280401 | TVb: -2.028347 | GSw: -0.234995 | GSb: 0.064929 | TSUw: 0.464849 | TSUb: 0.034881\n",
      "Validating epoch 2477...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 376.3117286869429\n",
      "Average validation loss: 81.42528751282157\n",
      "Training epoch 2478...\n",
      "\n",
      "Train Epoch: 2478 [0/8000 (0%)]\tBatch Loss: 363.320378\tLearning Rate (w_theta): 0.001000\t TIME:5933.2s\n",
      "\t\t\t\tDisc: 0.418659\t\tSym: 9.358109\t\tSpars: 353.543610\n",
      "\t TVw: 0.280989 | TVb: -2.028267 | GSw: -0.234996 | GSb: 0.064929 | TSUw: 0.464849 | TSUb: 0.034881\n",
      "\n",
      "Train Epoch: 2478 [4000/8000 (50%)]\tBatch Loss: 387.745569\tLearning Rate (w_theta): 0.001000\t TIME:5934.8s\n",
      "\t\t\t\tDisc: 0.438502\t\tSym: 11.008086\t\tSpars: 376.298981\n",
      "\t TVw: 0.281603 | TVb: -2.028186 | GSw: -0.234996 | GSb: 0.064929 | TSUw: 0.464849 | TSUb: 0.034881\n",
      "Validating epoch 2478...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 371.9018755579374\n",
      "Average validation loss: 83.62840457648109\n",
      "Training epoch 2479...\n",
      "\n",
      "Train Epoch: 2479 [0/8000 (0%)]\tBatch Loss: 379.118422\tLearning Rate (w_theta): 0.001000\t TIME:5937.3s\n",
      "\t\t\t\tDisc: 0.425738\t\tSym: 10.507412\t\tSpars: 368.185272\n",
      "\t TVw: 0.281773 | TVb: -2.028131 | GSw: -0.234996 | GSb: 0.064929 | TSUw: 0.464849 | TSUb: 0.034881\n",
      "\n",
      "Train Epoch: 2479 [4000/8000 (50%)]\tBatch Loss: 368.384214\tLearning Rate (w_theta): 0.001000\t TIME:5938.9s\n",
      "\t\t\t\tDisc: 0.455642\t\tSym: 10.058272\t\tSpars: 357.870300\n",
      "\t TVw: 0.281882 | TVb: -2.028076 | GSw: -0.234996 | GSb: 0.064929 | TSUw: 0.464849 | TSUb: 0.034881\n",
      "Validating epoch 2479...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 370.2776527120279\n",
      "Average validation loss: 83.15784548091004\n",
      "Training epoch 2480...\n",
      "\n",
      "Train Epoch: 2480 [0/8000 (0%)]\tBatch Loss: 357.695494\tLearning Rate (w_theta): 0.001000\t TIME:5941.4s\n",
      "\t\t\t\tDisc: 0.428204\t\tSym: 9.573442\t\tSpars: 347.693848\n",
      "\t TVw: 0.281580 | TVb: -2.028043 | GSw: -0.234996 | GSb: 0.064929 | TSUw: 0.464849 | TSUb: 0.034882\n",
      "\n",
      "Train Epoch: 2480 [4000/8000 (50%)]\tBatch Loss: 375.244244\tLearning Rate (w_theta): 0.001000\t TIME:5943.0s\n",
      "\t\t\t\tDisc: 0.425609\t\tSym: 10.595460\t\tSpars: 364.223175\n",
      "\t TVw: 0.281132 | TVb: -2.028016 | GSw: -0.234996 | GSb: 0.064928 | TSUw: 0.464848 | TSUb: 0.034882\n",
      "Validating epoch 2480...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 368.14889694908373\n",
      "Average validation loss: 81.76415222593741\n",
      "Training epoch 2481...\n",
      "\n",
      "Train Epoch: 2481 [0/8000 (0%)]\tBatch Loss: 372.824935\tLearning Rate (w_theta): 0.001000\t TIME:5946.5s\n",
      "\t\t\t\tDisc: 0.426201\t\tSym: 10.203696\t\tSpars: 362.195038\n",
      "\t TVw: 0.280759 | TVb: -2.027992 | GSw: -0.234996 | GSb: 0.064928 | TSUw: 0.464848 | TSUb: 0.034882\n",
      "\n",
      "Train Epoch: 2481 [4000/8000 (50%)]\tBatch Loss: 349.373399\tLearning Rate (w_theta): 0.001000\t TIME:5948.0s\n",
      "\t\t\t\tDisc: 0.407318\t\tSym: 8.905809\t\tSpars: 340.060272\n",
      "\t TVw: 0.280213 | TVb: -2.027981 | GSw: -0.234996 | GSb: 0.064928 | TSUw: 0.464848 | TSUb: 0.034882\n",
      "Validating epoch 2481...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 368.53781534055634\n",
      "Average validation loss: 82.6704611966875\n",
      "Training epoch 2482...\n",
      "\n",
      "Train Epoch: 2482 [0/8000 (0%)]\tBatch Loss: 355.329227\tLearning Rate (w_theta): 0.001000\t TIME:5950.5s\n",
      "\t\t\t\tDisc: 0.416207\t\tSym: 9.155574\t\tSpars: 345.757446\n",
      "\t TVw: 0.279738 | TVb: -2.027971 | GSw: -0.234996 | GSb: 0.064928 | TSUw: 0.464848 | TSUb: 0.034882\n",
      "\n",
      "Train Epoch: 2482 [4000/8000 (50%)]\tBatch Loss: 408.635150\tLearning Rate (w_theta): 0.001000\t TIME:5952.1s\n",
      "\t\t\t\tDisc: 0.451378\t\tSym: 11.652003\t\tSpars: 396.531769\n",
      "\t TVw: 0.279276 | TVb: -2.027968 | GSw: -0.234996 | GSb: 0.064928 | TSUw: 0.464848 | TSUb: 0.034882\n",
      "Validating epoch 2482...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 376.12242397070435\n",
      "Average validation loss: 75.99720130831253\n",
      "Training epoch 2483...\n",
      "\n",
      "Train Epoch: 2483 [0/8000 (0%)]\tBatch Loss: 405.480074\tLearning Rate (w_theta): 0.001000\t TIME:5954.6s\n",
      "\t\t\t\tDisc: 0.415983\t\tSym: 11.711675\t\tSpars: 393.352417\n",
      "\t TVw: 0.278929 | TVb: -2.027963 | GSw: -0.234996 | GSb: 0.064927 | TSUw: 0.464848 | TSUb: 0.034882\n",
      "\n",
      "Train Epoch: 2483 [4000/8000 (50%)]\tBatch Loss: 344.810731\tLearning Rate (w_theta): 0.001000\t TIME:5956.2s\n",
      "\t\t\t\tDisc: 0.395944\t\tSym: 8.240196\t\tSpars: 336.174591\n",
      "\t TVw: 0.278424 | TVb: -2.027978 | GSw: -0.234996 | GSb: 0.064927 | TSUw: 0.464848 | TSUb: 0.034883\n",
      "Validating epoch 2483...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 385.13334679102496\n",
      "Average validation loss: 80.22515113524597\n",
      "Training epoch 2484...\n",
      "\n",
      "Train Epoch: 2484 [0/8000 (0%)]\tBatch Loss: 371.653916\tLearning Rate (w_theta): 0.001000\t TIME:5958.6s\n",
      "\t\t\t\tDisc: 0.401148\t\tSym: 10.439901\t\tSpars: 360.812866\n",
      "\t TVw: 0.278716 | TVb: -2.027959 | GSw: -0.234996 | GSb: 0.064927 | TSUw: 0.464847 | TSUb: 0.034883\n",
      "\n",
      "Train Epoch: 2484 [4000/8000 (50%)]\tBatch Loss: 371.192499\tLearning Rate (w_theta): 0.001000\t TIME:5960.2s\n",
      "\t\t\t\tDisc: 0.411863\t\tSym: 10.203304\t\tSpars: 360.577332\n",
      "\t TVw: 0.279657 | TVb: -2.027897 | GSw: -0.234996 | GSb: 0.064927 | TSUw: 0.464847 | TSUb: 0.034883\n",
      "Validating epoch 2484...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 371.4388896930108\n",
      "Average validation loss: 81.62233256786008\n",
      "Training epoch 2485...\n",
      "\n",
      "Train Epoch: 2485 [0/8000 (0%)]\tBatch Loss: 367.754042\tLearning Rate (w_theta): 0.001000\t TIME:5962.7s\n",
      "\t\t\t\tDisc: 0.414931\t\tSym: 10.023682\t\tSpars: 357.315430\n",
      "\t TVw: 0.280756 | TVb: -2.027822 | GSw: -0.234996 | GSb: 0.064927 | TSUw: 0.464847 | TSUb: 0.034883\n",
      "\n",
      "Train Epoch: 2485 [4000/8000 (50%)]\tBatch Loss: 386.968802\tLearning Rate (w_theta): 0.001000\t TIME:5964.3s\n",
      "\t\t\t\tDisc: 0.399436\t\tSym: 11.076140\t\tSpars: 375.493225\n",
      "\t TVw: 0.281551 | TVb: -2.027747 | GSw: -0.234996 | GSb: 0.064926 | TSUw: 0.464847 | TSUb: 0.034883\n",
      "Validating epoch 2485...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 370.79566178378445\n",
      "Average validation loss: 77.49552657684683\n",
      "Training epoch 2486...\n",
      "\n",
      "Train Epoch: 2486 [0/8000 (0%)]\tBatch Loss: 374.884440\tLearning Rate (w_theta): 0.001000\t TIME:5966.7s\n",
      "\t\t\t\tDisc: 0.430746\t\tSym: 10.462025\t\tSpars: 363.991669\n",
      "\t TVw: 0.281925 | TVb: -2.027690 | GSw: -0.234996 | GSb: 0.064926 | TSUw: 0.464847 | TSUb: 0.034884\n",
      "\n",
      "Train Epoch: 2486 [4000/8000 (50%)]\tBatch Loss: 368.075417\tLearning Rate (w_theta): 0.001000\t TIME:5968.3s\n",
      "\t\t\t\tDisc: 0.432492\t\tSym: 10.214641\t\tSpars: 357.428284\n",
      "\t TVw: 0.282080 | TVb: -2.027647 | GSw: -0.234997 | GSb: 0.064926 | TSUw: 0.464846 | TSUb: 0.034884\n",
      "Validating epoch 2486...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 369.6098183205883\n",
      "Average validation loss: 82.73507107371127\n",
      "Training epoch 2487...\n",
      "\n",
      "Train Epoch: 2487 [0/8000 (0%)]\tBatch Loss: 369.147700\tLearning Rate (w_theta): 0.001000\t TIME:5970.8s\n",
      "\t\t\t\tDisc: 0.432840\t\tSym: 10.264787\t\tSpars: 358.450073\n",
      "\t TVw: 0.282335 | TVb: -2.027597 | GSw: -0.234997 | GSb: 0.064926 | TSUw: 0.464846 | TSUb: 0.034884\n",
      "\n",
      "Train Epoch: 2487 [4000/8000 (50%)]\tBatch Loss: 366.015213\tLearning Rate (w_theta): 0.001000\t TIME:5972.4s\n",
      "\t\t\t\tDisc: 0.405030\t\tSym: 9.431198\t\tSpars: 356.178986\n",
      "\t TVw: 0.282421 | TVb: -2.027544 | GSw: -0.234997 | GSb: 0.064926 | TSUw: 0.464846 | TSUb: 0.034884\n",
      "Validating epoch 2487...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 364.27802929049403\n",
      "Average validation loss: 82.37452432728911\n",
      "Training epoch 2488...\n",
      "\n",
      "Train Epoch: 2488 [0/8000 (0%)]\tBatch Loss: 367.913882\tLearning Rate (w_theta): 0.001000\t TIME:5974.9s\n",
      "\t\t\t\tDisc: 0.424946\t\tSym: 11.108718\t\tSpars: 356.380219\n",
      "\t TVw: 0.282310 | TVb: -2.027489 | GSw: -0.234997 | GSb: 0.064925 | TSUw: 0.464846 | TSUb: 0.034884\n",
      "\n",
      "Train Epoch: 2488 [4000/8000 (50%)]\tBatch Loss: 352.267402\tLearning Rate (w_theta): 0.001000\t TIME:5976.5s\n",
      "\t\t\t\tDisc: 0.434852\t\tSym: 9.127715\t\tSpars: 342.704834\n",
      "\t TVw: 0.281922 | TVb: -2.027444 | GSw: -0.234997 | GSb: 0.064925 | TSUw: 0.464846 | TSUb: 0.034884\n",
      "Validating epoch 2488...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 363.92332200159444\n",
      "Average validation loss: 79.6622643027196\n",
      "Training epoch 2489...\n",
      "\n",
      "Train Epoch: 2489 [0/8000 (0%)]\tBatch Loss: 387.243580\tLearning Rate (w_theta): 0.001000\t TIME:5978.9s\n",
      "\t\t\t\tDisc: 0.430990\t\tSym: 11.126982\t\tSpars: 375.685608\n",
      "\t TVw: 0.281366 | TVb: -2.027402 | GSw: -0.234997 | GSb: 0.064925 | TSUw: 0.464846 | TSUb: 0.034885\n",
      "\n",
      "Train Epoch: 2489 [4000/8000 (50%)]\tBatch Loss: 366.735730\tLearning Rate (w_theta): 0.001000\t TIME:5980.5s\n",
      "\t\t\t\tDisc: 0.409416\t\tSym: 9.988149\t\tSpars: 356.338165\n",
      "\t TVw: 0.280745 | TVb: -2.027375 | GSw: -0.234997 | GSb: 0.064925 | TSUw: 0.464846 | TSUb: 0.034885\n",
      "Validating epoch 2489...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 360.8890601476911\n",
      "Average validation loss: 80.39310271259387\n",
      "Training epoch 2490...\n",
      "\n",
      "Train Epoch: 2490 [0/8000 (0%)]\tBatch Loss: 379.680173\tLearning Rate (w_theta): 0.001000\t TIME:5983.0s\n",
      "\t\t\t\tDisc: 0.420241\t\tSym: 11.083906\t\tSpars: 368.176025\n",
      "\t TVw: 0.280321 | TVb: -2.027350 | GSw: -0.234997 | GSb: 0.064924 | TSUw: 0.464846 | TSUb: 0.034885\n",
      "\n",
      "Train Epoch: 2490 [4000/8000 (50%)]\tBatch Loss: 347.892885\tLearning Rate (w_theta): 0.001000\t TIME:5984.5s\n",
      "\t\t\t\tDisc: 0.408408\t\tSym: 8.717083\t\tSpars: 338.767395\n",
      "\t TVw: 0.280036 | TVb: -2.027322 | GSw: -0.234997 | GSb: 0.064924 | TSUw: 0.464845 | TSUb: 0.034885\n",
      "Validating epoch 2490...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 359.4356356488846\n",
      "Average validation loss: 79.12887020060388\n",
      "Training epoch 2491...\n",
      "\n",
      "Train Epoch: 2491 [0/8000 (0%)]\tBatch Loss: 358.287584\tLearning Rate (w_theta): 0.001000\t TIME:5987.7s\n",
      "\t\t\t\tDisc: 0.398236\t\tSym: 9.847814\t\tSpars: 348.041534\n",
      "\t TVw: 0.279899 | TVb: -2.027285 | GSw: -0.234997 | GSb: 0.064924 | TSUw: 0.464845 | TSUb: 0.034885\n",
      "\n",
      "Train Epoch: 2491 [4000/8000 (50%)]\tBatch Loss: 366.849781\tLearning Rate (w_theta): 0.001000\t TIME:5989.2s\n",
      "\t\t\t\tDisc: 0.413045\t\tSym: 10.622375\t\tSpars: 355.814362\n",
      "\t TVw: 0.279806 | TVb: -2.027248 | GSw: -0.234997 | GSb: 0.064924 | TSUw: 0.464845 | TSUb: 0.034885\n",
      "Validating epoch 2491...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 358.55651531085454\n",
      "Average validation loss: 81.01237065438872\n",
      "Training epoch 2492...\n",
      "\n",
      "Train Epoch: 2492 [0/8000 (0%)]\tBatch Loss: 359.099019\tLearning Rate (w_theta): 0.001000\t TIME:5991.7s\n",
      "\t\t\t\tDisc: 0.430447\t\tSym: 9.669609\t\tSpars: 348.998962\n",
      "\t TVw: 0.279788 | TVb: -2.027202 | GSw: -0.234997 | GSb: 0.064924 | TSUw: 0.464845 | TSUb: 0.034885\n",
      "\n",
      "Train Epoch: 2492 [4000/8000 (50%)]\tBatch Loss: 364.587554\tLearning Rate (w_theta): 0.001000\t TIME:5993.3s\n",
      "\t\t\t\tDisc: 0.385856\t\tSym: 10.763282\t\tSpars: 353.438416\n",
      "\t TVw: 0.279713 | TVb: -2.027159 | GSw: -0.234997 | GSb: 0.064924 | TSUw: 0.464845 | TSUb: 0.034886\n",
      "Validating epoch 2492...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 358.31908415285943\n",
      "Average validation loss: 78.91441792784511\n",
      "Training epoch 2493...\n",
      "\n",
      "Train Epoch: 2493 [0/8000 (0%)]\tBatch Loss: 361.168127\tLearning Rate (w_theta): 0.001000\t TIME:5995.7s\n",
      "\t\t\t\tDisc: 0.402297\t\tSym: 10.270621\t\tSpars: 350.495209\n",
      "\t TVw: 0.279691 | TVb: -2.027105 | GSw: -0.234997 | GSb: 0.064923 | TSUw: 0.464845 | TSUb: 0.034886\n",
      "\n",
      "Train Epoch: 2493 [4000/8000 (50%)]\tBatch Loss: 355.230386\tLearning Rate (w_theta): 0.001000\t TIME:5997.3s\n",
      "\t\t\t\tDisc: 0.430027\t\tSym: 9.410315\t\tSpars: 345.390045\n",
      "\t TVw: 0.279522 | TVb: -2.027064 | GSw: -0.234997 | GSb: 0.064923 | TSUw: 0.464845 | TSUb: 0.034886\n",
      "Validating epoch 2493...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 359.1365574131087\n",
      "Average validation loss: 78.40153683326065\n",
      "Training epoch 2494...\n",
      "\n",
      "Train Epoch: 2494 [0/8000 (0%)]\tBatch Loss: 350.889387\tLearning Rate (w_theta): 0.001000\t TIME:6000.2s\n",
      "\t\t\t\tDisc: 0.403356\t\tSym: 10.135628\t\tSpars: 340.350403\n",
      "\t TVw: 0.279335 | TVb: -2.027020 | GSw: -0.234997 | GSb: 0.064923 | TSUw: 0.464845 | TSUb: 0.034886\n",
      "\n",
      "Train Epoch: 2494 [4000/8000 (50%)]\tBatch Loss: 374.573157\tLearning Rate (w_theta): 0.001000\t TIME:6001.8s\n",
      "\t\t\t\tDisc: 0.438357\t\tSym: 11.021336\t\tSpars: 363.113464\n",
      "\t TVw: 0.279179 | TVb: -2.026984 | GSw: -0.234997 | GSb: 0.064923 | TSUw: 0.464844 | TSUb: 0.034886\n",
      "Validating epoch 2494...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 358.2000525458351\n",
      "Average validation loss: 79.1684004724235\n",
      "Training epoch 2495...\n",
      "\n",
      "Train Epoch: 2495 [0/8000 (0%)]\tBatch Loss: 367.961632\tLearning Rate (w_theta): 0.001000\t TIME:6004.2s\n",
      "\t\t\t\tDisc: 0.443336\t\tSym: 11.048080\t\tSpars: 356.470215\n",
      "\t TVw: 0.278963 | TVb: -2.026949 | GSw: -0.234998 | GSb: 0.064923 | TSUw: 0.464844 | TSUb: 0.034886\n",
      "\n",
      "Train Epoch: 2495 [4000/8000 (50%)]\tBatch Loss: 384.590920\tLearning Rate (w_theta): 0.001000\t TIME:6005.8s\n",
      "\t\t\t\tDisc: 0.422224\t\tSym: 11.244288\t\tSpars: 372.924408\n",
      "\t TVw: 0.278612 | TVb: -2.026920 | GSw: -0.234998 | GSb: 0.064922 | TSUw: 0.464844 | TSUb: 0.034887\n",
      "Validating epoch 2495...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 367.81439420665436\n",
      "Average validation loss: 79.57170486543815\n",
      "Training epoch 2496...\n",
      "\n",
      "Train Epoch: 2496 [0/8000 (0%)]\tBatch Loss: 351.553394\tLearning Rate (w_theta): 0.001000\t TIME:6008.3s\n",
      "\t\t\t\tDisc: 0.427470\t\tSym: 9.512765\t\tSpars: 341.613159\n",
      "\t TVw: 0.278257 | TVb: -2.026927 | GSw: -0.234998 | GSb: 0.064922 | TSUw: 0.464844 | TSUb: 0.034887\n",
      "\n",
      "Train Epoch: 2496 [4000/8000 (50%)]\tBatch Loss: 369.633257\tLearning Rate (w_theta): 0.001000\t TIME:6009.9s\n",
      "\t\t\t\tDisc: 0.406207\t\tSym: 11.443206\t\tSpars: 357.783844\n",
      "\t TVw: 0.278593 | TVb: -2.026900 | GSw: -0.234998 | GSb: 0.064922 | TSUw: 0.464844 | TSUb: 0.034887\n",
      "Validating epoch 2496...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 358.0106491117538\n",
      "Average validation loss: 78.55154167358842\n",
      "Training epoch 2497...\n",
      "\n",
      "Train Epoch: 2497 [0/8000 (0%)]\tBatch Loss: 350.225383\tLearning Rate (w_theta): 0.001000\t TIME:6012.3s\n",
      "\t\t\t\tDisc: 0.428805\t\tSym: 9.864816\t\tSpars: 339.931763\n",
      "\t TVw: 0.279126 | TVb: -2.026837 | GSw: -0.234998 | GSb: 0.064922 | TSUw: 0.464844 | TSUb: 0.034887\n",
      "\n",
      "Train Epoch: 2497 [4000/8000 (50%)]\tBatch Loss: 354.723952\tLearning Rate (w_theta): 0.001000\t TIME:6013.9s\n",
      "\t\t\t\tDisc: 0.419612\t\tSym: 10.059802\t\tSpars: 344.244537\n",
      "\t TVw: 0.279592 | TVb: -2.026763 | GSw: -0.234998 | GSb: 0.064922 | TSUw: 0.464843 | TSUb: 0.034887\n",
      "Validating epoch 2497...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 353.61334868331807\n",
      "Average validation loss: 78.92878416621663\n",
      "Training epoch 2498...\n",
      "\n",
      "Train Epoch: 2498 [0/8000 (0%)]\tBatch Loss: 357.774135\tLearning Rate (w_theta): 0.001000\t TIME:6016.3s\n",
      "\t\t\t\tDisc: 0.410839\t\tSym: 10.078353\t\tSpars: 347.284943\n",
      "\t TVw: 0.279668 | TVb: -2.026708 | GSw: -0.234998 | GSb: 0.064921 | TSUw: 0.464843 | TSUb: 0.034887\n",
      "\n",
      "Train Epoch: 2498 [4000/8000 (50%)]\tBatch Loss: 351.280483\tLearning Rate (w_theta): 0.001000\t TIME:6017.9s\n",
      "\t\t\t\tDisc: 0.429784\t\tSym: 10.049216\t\tSpars: 340.801483\n",
      "\t TVw: 0.279505 | TVb: -2.026664 | GSw: -0.234998 | GSb: 0.064921 | TSUw: 0.464843 | TSUb: 0.034888\n",
      "Validating epoch 2498...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 352.31276931026343\n",
      "Average validation loss: 79.18130483573083\n",
      "Training epoch 2499...\n",
      "\n",
      "Train Epoch: 2499 [0/8000 (0%)]\tBatch Loss: 349.782177\tLearning Rate (w_theta): 0.001000\t TIME:6020.4s\n",
      "\t\t\t\tDisc: 0.417681\t\tSym: 9.713769\t\tSpars: 339.650726\n",
      "\t TVw: 0.279465 | TVb: -2.026618 | GSw: -0.234998 | GSb: 0.064921 | TSUw: 0.464843 | TSUb: 0.034888\n",
      "\n",
      "Train Epoch: 2499 [4000/8000 (50%)]\tBatch Loss: 359.489068\tLearning Rate (w_theta): 0.001000\t TIME:6022.0s\n",
      "\t\t\t\tDisc: 0.434684\t\tSym: 10.575228\t\tSpars: 348.479156\n",
      "\t TVw: 0.279441 | TVb: -2.026577 | GSw: -0.234998 | GSb: 0.064921 | TSUw: 0.464843 | TSUb: 0.034888\n",
      "Validating epoch 2499...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 352.6364367586323\n",
      "Average validation loss: 77.43470556441365\n",
      "Training epoch 2500...\n",
      "\n",
      "Train Epoch: 2500 [0/8000 (0%)]\tBatch Loss: 332.808128\tLearning Rate (w_theta): 0.001000\t TIME:6024.4s\n",
      "\t\t\t\tDisc: 0.400122\t\tSym: 8.748491\t\tSpars: 323.659515\n",
      "\t TVw: 0.279417 | TVb: -2.026536 | GSw: -0.234998 | GSb: 0.064921 | TSUw: 0.464843 | TSUb: 0.034888\n",
      "\n",
      "Train Epoch: 2500 [4000/8000 (50%)]\tBatch Loss: 354.198135\tLearning Rate (w_theta): 0.001000\t TIME:6026.0s\n",
      "\t\t\t\tDisc: 0.446084\t\tSym: 9.994055\t\tSpars: 343.757996\n",
      "\t TVw: 0.279118 | TVb: -2.026517 | GSw: -0.234998 | GSb: 0.064920 | TSUw: 0.464843 | TSUb: 0.034888\n",
      "Validating epoch 2500...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 351.51711327181926\n",
      "Average validation loss: 78.07320066100397\n",
      "Training epoch 2501...\n",
      "\n",
      "Train Epoch: 2501 [0/8000 (0%)]\tBatch Loss: 343.079700\tLearning Rate (w_theta): 0.001000\t TIME:6029.1s\n",
      "\t\t\t\tDisc: 0.419363\t\tSym: 10.080960\t\tSpars: 332.579376\n",
      "\t TVw: 0.278947 | TVb: -2.026485 | GSw: -0.234998 | GSb: 0.064920 | TSUw: 0.464843 | TSUb: 0.034888\n",
      "\n",
      "Train Epoch: 2501 [4000/8000 (50%)]\tBatch Loss: 349.242598\tLearning Rate (w_theta): 0.001000\t TIME:6030.7s\n",
      "\t\t\t\tDisc: 0.406006\t\tSym: 9.787063\t\tSpars: 339.049530\n",
      "\t TVw: 0.278781 | TVb: -2.026452 | GSw: -0.234998 | GSb: 0.064920 | TSUw: 0.464842 | TSUb: 0.034888\n",
      "Validating epoch 2501...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 349.566085491339\n",
      "Average validation loss: 78.13114378382741\n",
      "Training epoch 2502...\n",
      "\n",
      "Train Epoch: 2502 [0/8000 (0%)]\tBatch Loss: 340.554478\tLearning Rate (w_theta): 0.001000\t TIME:6033.2s\n",
      "\t\t\t\tDisc: 0.420880\t\tSym: 9.428947\t\tSpars: 330.704651\n",
      "\t TVw: 0.278682 | TVb: -2.026421 | GSw: -0.234998 | GSb: 0.064920 | TSUw: 0.464842 | TSUb: 0.034889\n",
      "\n",
      "Train Epoch: 2502 [4000/8000 (50%)]\tBatch Loss: 351.434357\tLearning Rate (w_theta): 0.001000\t TIME:6034.8s\n",
      "\t\t\t\tDisc: 0.427686\t\tSym: 10.177112\t\tSpars: 340.829559\n",
      "\t TVw: 0.278795 | TVb: -2.026378 | GSw: -0.234998 | GSb: 0.064920 | TSUw: 0.464842 | TSUb: 0.034889\n",
      "Validating epoch 2502...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 348.97385577036005\n",
      "Average validation loss: 77.38941972483651\n",
      "Training epoch 2503...\n",
      "\n",
      "Train Epoch: 2503 [0/8000 (0%)]\tBatch Loss: 350.756545\tLearning Rate (w_theta): 0.001000\t TIME:6037.2s\n",
      "\t\t\t\tDisc: 0.425130\t\tSym: 10.305657\t\tSpars: 340.025757\n",
      "\t TVw: 0.278871 | TVb: -2.026336 | GSw: -0.234998 | GSb: 0.064919 | TSUw: 0.464842 | TSUb: 0.034889\n",
      "\n",
      "Train Epoch: 2503 [4000/8000 (50%)]\tBatch Loss: 349.499955\tLearning Rate (w_theta): 0.001000\t TIME:6038.8s\n",
      "\t\t\t\tDisc: 0.420100\t\tSym: 9.812460\t\tSpars: 339.267395\n",
      "\t TVw: 0.278864 | TVb: -2.026305 | GSw: -0.234999 | GSb: 0.064919 | TSUw: 0.464842 | TSUb: 0.034889\n",
      "Validating epoch 2503...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 349.43509910621356\n",
      "Average validation loss: 75.93088660915643\n",
      "Training epoch 2504...\n",
      "\n",
      "Train Epoch: 2504 [0/8000 (0%)]\tBatch Loss: 354.963025\tLearning Rate (w_theta): 0.001000\t TIME:6041.3s\n",
      "\t\t\t\tDisc: 0.399395\t\tSym: 9.951234\t\tSpars: 344.612396\n",
      "\t TVw: 0.278957 | TVb: -2.026257 | GSw: -0.234999 | GSb: 0.064919 | TSUw: 0.464842 | TSUb: 0.034889\n",
      "\n",
      "Train Epoch: 2504 [4000/8000 (50%)]\tBatch Loss: 369.330138\tLearning Rate (w_theta): 0.001000\t TIME:6042.9s\n",
      "\t\t\t\tDisc: 0.523825\t\tSym: 10.184608\t\tSpars: 358.621704\n",
      "\t TVw: 0.278867 | TVb: -2.026226 | GSw: -0.234999 | GSb: 0.064919 | TSUw: 0.464842 | TSUb: 0.034889\n",
      "Validating epoch 2504...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 360.90603937293474\n",
      "Average validation loss: 80.02687769802017\n",
      "Training epoch 2505...\n",
      "\n",
      "Train Epoch: 2505 [0/8000 (0%)]\tBatch Loss: 352.950396\tLearning Rate (w_theta): 0.001000\t TIME:6045.3s\n",
      "\t\t\t\tDisc: 0.480949\t\tSym: 8.873500\t\tSpars: 343.595947\n",
      "\t TVw: 0.278144 | TVb: -2.026247 | GSw: -0.234999 | GSb: 0.064919 | TSUw: 0.464842 | TSUb: 0.034890\n",
      "\n",
      "Train Epoch: 2505 [4000/8000 (50%)]\tBatch Loss: 335.277036\tLearning Rate (w_theta): 0.001000\t TIME:6046.9s\n",
      "\t\t\t\tDisc: 0.432207\t\tSym: 8.703013\t\tSpars: 326.141815\n",
      "\t TVw: 0.278251 | TVb: -2.026227 | GSw: -0.234999 | GSb: 0.064918 | TSUw: 0.464841 | TSUb: 0.034890\n",
      "Validating epoch 2505...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 354.98650792186453\n",
      "Average validation loss: 72.89234317343144\n",
      "Training epoch 2506...\n",
      "\n",
      "Train Epoch: 2506 [0/8000 (0%)]\tBatch Loss: 356.458237\tLearning Rate (w_theta): 0.001000\t TIME:6049.4s\n",
      "\t\t\t\tDisc: 0.404660\t\tSym: 10.010456\t\tSpars: 346.043121\n",
      "\t TVw: 0.278688 | TVb: -2.026173 | GSw: -0.234999 | GSb: 0.064918 | TSUw: 0.464841 | TSUb: 0.034890\n",
      "\n",
      "Train Epoch: 2506 [4000/8000 (50%)]\tBatch Loss: 364.989582\tLearning Rate (w_theta): 0.001000\t TIME:6051.0s\n",
      "\t\t\t\tDisc: 0.413089\t\tSym: 11.050797\t\tSpars: 353.525696\n",
      "\t TVw: 0.278775 | TVb: -2.026155 | GSw: -0.234999 | GSb: 0.064918 | TSUw: 0.464841 | TSUb: 0.034890\n",
      "Validating epoch 2506...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 360.94949536095567\n",
      "Average validation loss: 78.62298776733518\n",
      "Training epoch 2507...\n",
      "\n",
      "Train Epoch: 2507 [0/8000 (0%)]\tBatch Loss: 364.705700\tLearning Rate (w_theta): 0.001000\t TIME:6053.9s\n",
      "\t\t\t\tDisc: 0.445875\t\tSym: 10.859343\t\tSpars: 353.400482\n",
      "\t TVw: 0.279048 | TVb: -2.026127 | GSw: -0.234999 | GSb: 0.064918 | TSUw: 0.464841 | TSUb: 0.034890\n",
      "\n",
      "Train Epoch: 2507 [4000/8000 (50%)]\tBatch Loss: 349.412054\tLearning Rate (w_theta): 0.001000\t TIME:6055.5s\n",
      "\t\t\t\tDisc: 0.438475\t\tSym: 9.360724\t\tSpars: 339.612854\n",
      "\t TVw: 0.279195 | TVb: -2.026100 | GSw: -0.234999 | GSb: 0.064917 | TSUw: 0.464840 | TSUb: 0.034891\n",
      "Validating epoch 2507...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 363.4996175541206\n",
      "Average validation loss: 73.8190910337819\n",
      "Training epoch 2508...\n",
      "\n",
      "Train Epoch: 2508 [0/8000 (0%)]\tBatch Loss: 331.150127\tLearning Rate (w_theta): 0.001000\t TIME:6057.9s\n",
      "\t\t\t\tDisc: 0.420899\t\tSym: 8.558543\t\tSpars: 322.170685\n",
      "\t TVw: 0.279685 | TVb: -2.026062 | GSw: -0.234999 | GSb: 0.064917 | TSUw: 0.464840 | TSUb: 0.034891\n",
      "\n",
      "Train Epoch: 2508 [4000/8000 (50%)]\tBatch Loss: 371.248244\tLearning Rate (w_theta): 0.001000\t TIME:6059.5s\n",
      "\t\t\t\tDisc: 0.441018\t\tSym: 10.565527\t\tSpars: 360.241699\n",
      "\t TVw: 0.280129 | TVb: -2.026015 | GSw: -0.234999 | GSb: 0.064917 | TSUw: 0.464840 | TSUb: 0.034891\n",
      "Validating epoch 2508...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 359.62393066973823\n",
      "Average validation loss: 71.68290115647231\n",
      "Training epoch 2509...\n",
      "\n",
      "Train Epoch: 2509 [0/8000 (0%)]\tBatch Loss: 357.987982\tLearning Rate (w_theta): 0.001000\t TIME:6061.9s\n",
      "\t\t\t\tDisc: 0.412478\t\tSym: 9.597751\t\tSpars: 347.977753\n",
      "\t TVw: 0.280843 | TVb: -2.025950 | GSw: -0.234999 | GSb: 0.064917 | TSUw: 0.464840 | TSUb: 0.034891\n",
      "\n",
      "Train Epoch: 2509 [4000/8000 (50%)]\tBatch Loss: 335.554555\tLearning Rate (w_theta): 0.001000\t TIME:6063.5s\n",
      "\t\t\t\tDisc: 0.464144\t\tSym: 8.571704\t\tSpars: 326.518707\n",
      "\t TVw: 0.281428 | TVb: -2.025908 | GSw: -0.234999 | GSb: 0.064917 | TSUw: 0.464839 | TSUb: 0.034891\n",
      "Validating epoch 2509...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 359.723205941294\n",
      "Average validation loss: 78.3923280234163\n",
      "Training epoch 2510...\n",
      "\n",
      "Train Epoch: 2510 [0/8000 (0%)]\tBatch Loss: 341.465461\tLearning Rate (w_theta): 0.001000\t TIME:6066.0s\n",
      "\t\t\t\tDisc: 0.498093\t\tSym: 8.846213\t\tSpars: 332.121155\n",
      "\t TVw: 0.281871 | TVb: -2.025878 | GSw: -0.234999 | GSb: 0.064916 | TSUw: 0.464839 | TSUb: 0.034891\n",
      "\n",
      "Train Epoch: 2510 [4000/8000 (50%)]\tBatch Loss: 352.282766\tLearning Rate (w_theta): 0.001000\t TIME:6067.6s\n",
      "\t\t\t\tDisc: 0.463314\t\tSym: 10.282250\t\tSpars: 341.537201\n",
      "\t TVw: 0.282263 | TVb: -2.025820 | GSw: -0.234999 | GSb: 0.064916 | TSUw: 0.464839 | TSUb: 0.034892\n",
      "Validating epoch 2510...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 349.1672006556906\n",
      "Average validation loss: 76.83905390511708\n",
      "Training epoch 2511...\n",
      "\n",
      "Train Epoch: 2511 [0/8000 (0%)]\tBatch Loss: 349.862594\tLearning Rate (w_theta): 0.001000\t TIME:6070.8s\n",
      "\t\t\t\tDisc: 0.453161\t\tSym: 10.463755\t\tSpars: 338.945679\n",
      "\t TVw: 0.282685 | TVb: -2.025746 | GSw: -0.234999 | GSb: 0.064916 | TSUw: 0.464839 | TSUb: 0.034892\n",
      "\n",
      "Train Epoch: 2511 [4000/8000 (50%)]\tBatch Loss: 369.231751\tLearning Rate (w_theta): 0.001000\t TIME:6072.4s\n",
      "\t\t\t\tDisc: 0.444726\t\tSym: 11.101997\t\tSpars: 357.685028\n",
      "\t TVw: 0.282973 | TVb: -2.025669 | GSw: -0.235000 | GSb: 0.064916 | TSUw: 0.464838 | TSUb: 0.034892\n",
      "Validating epoch 2511...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 348.42750635670905\n",
      "Average validation loss: 75.16138556746839\n",
      "Training epoch 2512...\n",
      "\n",
      "Train Epoch: 2512 [0/8000 (0%)]\tBatch Loss: 332.721175\tLearning Rate (w_theta): 0.001000\t TIME:6074.8s\n",
      "\t\t\t\tDisc: 0.472672\t\tSym: 9.030242\t\tSpars: 323.218262\n",
      "\t TVw: 0.282737 | TVb: -2.025634 | GSw: -0.235000 | GSb: 0.064916 | TSUw: 0.464838 | TSUb: 0.034892\n",
      "\n",
      "Train Epoch: 2512 [4000/8000 (50%)]\tBatch Loss: 352.461895\tLearning Rate (w_theta): 0.001000\t TIME:6076.4s\n",
      "\t\t\t\tDisc: 0.522802\t\tSym: 9.683722\t\tSpars: 342.255371\n",
      "\t TVw: 0.282528 | TVb: -2.025595 | GSw: -0.235000 | GSb: 0.064915 | TSUw: 0.464838 | TSUb: 0.034892\n",
      "Validating epoch 2512...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 354.28619192339494\n",
      "Average validation loss: 80.53299793683709\n",
      "Training epoch 2513...\n",
      "\n",
      "Train Epoch: 2513 [0/8000 (0%)]\tBatch Loss: 364.266115\tLearning Rate (w_theta): 0.001000\t TIME:6078.8s\n",
      "\t\t\t\tDisc: 0.540374\t\tSym: 9.935823\t\tSpars: 353.789917\n",
      "\t TVw: 0.282269 | TVb: -2.025589 | GSw: -0.235000 | GSb: 0.064915 | TSUw: 0.464838 | TSUb: 0.034893\n",
      "\n",
      "Train Epoch: 2513 [4000/8000 (50%)]\tBatch Loss: 395.361846\tLearning Rate (w_theta): 0.001000\t TIME:6080.4s\n",
      "\t\t\t\tDisc: 0.543172\t\tSym: 12.417246\t\tSpars: 382.401428\n",
      "\t TVw: 0.282337 | TVb: -2.025559 | GSw: -0.235000 | GSb: 0.064915 | TSUw: 0.464838 | TSUb: 0.034893\n",
      "Validating epoch 2513...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 360.32538984840187\n",
      "Average validation loss: 80.73107447611697\n",
      "Training epoch 2514...\n",
      "\n",
      "Train Epoch: 2514 [0/8000 (0%)]\tBatch Loss: 396.567892\tLearning Rate (w_theta): 0.001000\t TIME:6082.9s\n",
      "\t\t\t\tDisc: 0.597545\t\tSym: 11.688272\t\tSpars: 384.282074\n",
      "\t TVw: 0.282128 | TVb: -2.025547 | GSw: -0.235000 | GSb: 0.064915 | TSUw: 0.464837 | TSUb: 0.034893\n",
      "\n",
      "Train Epoch: 2514 [4000/8000 (50%)]\tBatch Loss: 343.561295\tLearning Rate (w_theta): 0.001000\t TIME:6084.5s\n",
      "\t\t\t\tDisc: 0.446752\t\tSym: 10.403178\t\tSpars: 332.711365\n",
      "\t TVw: 0.281969 | TVb: -2.025529 | GSw: -0.235000 | GSb: 0.064914 | TSUw: 0.464837 | TSUb: 0.034893\n",
      "Validating epoch 2514...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 352.11373306890476\n",
      "Average validation loss: 73.52899570493477\n",
      "Training epoch 2515...\n",
      "\n",
      "Train Epoch: 2515 [0/8000 (0%)]\tBatch Loss: 342.882846\tLearning Rate (w_theta): 0.001000\t TIME:6087.0s\n",
      "\t\t\t\tDisc: 0.435732\t\tSym: 10.291352\t\tSpars: 332.155762\n",
      "\t TVw: 0.282434 | TVb: -2.025475 | GSw: -0.235000 | GSb: 0.064914 | TSUw: 0.464837 | TSUb: 0.034893\n",
      "\n",
      "Train Epoch: 2515 [4000/8000 (50%)]\tBatch Loss: 319.908621\tLearning Rate (w_theta): 0.001000\t TIME:6088.6s\n",
      "\t\t\t\tDisc: 0.459012\t\tSym: 8.398370\t\tSpars: 311.051239\n",
      "\t TVw: 0.283136 | TVb: -2.025391 | GSw: -0.235000 | GSb: 0.064914 | TSUw: 0.464837 | TSUb: 0.034894\n",
      "Validating epoch 2515...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 341.6948744318033\n",
      "Average validation loss: 73.27218137923812\n",
      "Training epoch 2516...\n",
      "\n",
      "Train Epoch: 2516 [0/8000 (0%)]\tBatch Loss: 344.906164\tLearning Rate (w_theta): 0.001000\t TIME:6091.0s\n",
      "\t\t\t\tDisc: 0.433178\t\tSym: 9.979578\t\tSpars: 334.493408\n",
      "\t TVw: 0.283542 | TVb: -2.025306 | GSw: -0.235000 | GSb: 0.064914 | TSUw: 0.464836 | TSUb: 0.034894\n",
      "\n",
      "Train Epoch: 2516 [4000/8000 (50%)]\tBatch Loss: 349.078041\tLearning Rate (w_theta): 0.001000\t TIME:6092.6s\n",
      "\t\t\t\tDisc: 0.453927\t\tSym: 10.750976\t\tSpars: 337.873138\n",
      "\t TVw: 0.283568 | TVb: -2.025233 | GSw: -0.235000 | GSb: 0.064914 | TSUw: 0.464836 | TSUb: 0.034894\n",
      "Validating epoch 2516...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 339.7133411624337\n",
      "Average validation loss: 75.86438182214211\n",
      "Training epoch 2517...\n",
      "\n",
      "Train Epoch: 2517 [0/8000 (0%)]\tBatch Loss: 328.586751\tLearning Rate (w_theta): 0.001000\t TIME:6095.1s\n",
      "\t\t\t\tDisc: 0.483156\t\tSym: 9.178485\t\tSpars: 318.925110\n",
      "\t TVw: 0.283324 | TVb: -2.025167 | GSw: -0.235000 | GSb: 0.064913 | TSUw: 0.464836 | TSUb: 0.034894\n",
      "\n",
      "Train Epoch: 2517 [4000/8000 (50%)]\tBatch Loss: 348.743282\tLearning Rate (w_theta): 0.001000\t TIME:6096.7s\n",
      "\t\t\t\tDisc: 0.442403\t\tSym: 10.877173\t\tSpars: 337.423706\n",
      "\t TVw: 0.282858 | TVb: -2.025107 | GSw: -0.235000 | GSb: 0.064913 | TSUw: 0.464836 | TSUb: 0.034894\n",
      "Validating epoch 2517...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 337.6987359081515\n",
      "Average validation loss: 77.24331592021922\n",
      "Training epoch 2518...\n",
      "\n",
      "Train Epoch: 2518 [0/8000 (0%)]\tBatch Loss: 333.850096\tLearning Rate (w_theta): 0.001000\t TIME:6099.2s\n",
      "\t\t\t\tDisc: 0.469637\t\tSym: 9.995419\t\tSpars: 323.385040\n",
      "\t TVw: 0.282801 | TVb: -2.025042 | GSw: -0.235000 | GSb: 0.064913 | TSUw: 0.464836 | TSUb: 0.034894\n",
      "\n",
      "Train Epoch: 2518 [4000/8000 (50%)]\tBatch Loss: 329.057237\tLearning Rate (w_theta): 0.001000\t TIME:6100.7s\n",
      "\t\t\t\tDisc: 0.443389\t\tSym: 9.382708\t\tSpars: 319.231140\n",
      "\t TVw: 0.282683 | TVb: -2.024978 | GSw: -0.235000 | GSb: 0.064913 | TSUw: 0.464836 | TSUb: 0.034895\n",
      "Validating epoch 2518...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 337.1128274736666\n",
      "Average validation loss: 76.13024019058626\n",
      "Training epoch 2519...\n",
      "\n",
      "Train Epoch: 2519 [0/8000 (0%)]\tBatch Loss: 312.161376\tLearning Rate (w_theta): 0.001000\t TIME:6103.2s\n",
      "\t\t\t\tDisc: 0.466786\t\tSym: 8.662516\t\tSpars: 303.032074\n",
      "\t TVw: 0.282192 | TVb: -2.024942 | GSw: -0.235000 | GSb: 0.064913 | TSUw: 0.464836 | TSUb: 0.034895\n",
      "\n",
      "Train Epoch: 2519 [4000/8000 (50%)]\tBatch Loss: 348.136790\tLearning Rate (w_theta): 0.001000\t TIME:6104.8s\n",
      "\t\t\t\tDisc: 0.467034\t\tSym: 11.140612\t\tSpars: 336.529144\n",
      "\t TVw: 0.281405 | TVb: -2.024937 | GSw: -0.235000 | GSb: 0.064912 | TSUw: 0.464836 | TSUb: 0.034895\n",
      "Validating epoch 2519...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 336.99890427973014\n",
      "Average validation loss: 74.25733303734576\n",
      "Training epoch 2520...\n",
      "\n",
      "Train Epoch: 2520 [0/8000 (0%)]\tBatch Loss: 332.491217\tLearning Rate (w_theta): 0.001000\t TIME:6107.6s\n",
      "\t\t\t\tDisc: 0.453948\t\tSym: 9.626197\t\tSpars: 322.411072\n",
      "\t TVw: 0.280698 | TVb: -2.024919 | GSw: -0.235001 | GSb: 0.064912 | TSUw: 0.464835 | TSUb: 0.034895\n",
      "\n",
      "Train Epoch: 2520 [4000/8000 (50%)]\tBatch Loss: 355.177430\tLearning Rate (w_theta): 0.001000\t TIME:6109.2s\n",
      "\t\t\t\tDisc: 0.450390\t\tSym: 11.215505\t\tSpars: 343.511536\n",
      "\t TVw: 0.280075 | TVb: -2.024904 | GSw: -0.235001 | GSb: 0.064912 | TSUw: 0.464835 | TSUb: 0.034895\n",
      "Validating epoch 2520...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 335.0450436756849\n",
      "Average validation loss: 76.45057080225983\n",
      "Training epoch 2521...\n",
      "\n",
      "Train Epoch: 2521 [0/8000 (0%)]\tBatch Loss: 325.616119\tLearning Rate (w_theta): 0.001000\t TIME:6112.3s\n",
      "\t\t\t\tDisc: 0.446278\t\tSym: 9.089274\t\tSpars: 316.080566\n",
      "\t TVw: 0.279782 | TVb: -2.024880 | GSw: -0.235001 | GSb: 0.064912 | TSUw: 0.464835 | TSUb: 0.034895\n",
      "\n",
      "Train Epoch: 2521 [4000/8000 (50%)]\tBatch Loss: 338.036356\tLearning Rate (w_theta): 0.001000\t TIME:6113.9s\n",
      "\t\t\t\tDisc: 0.438991\t\tSym: 10.630690\t\tSpars: 326.966675\n",
      "\t TVw: 0.279658 | TVb: -2.024845 | GSw: -0.235001 | GSb: 0.064912 | TSUw: 0.464835 | TSUb: 0.034896\n",
      "Validating epoch 2521...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 342.3993888853928\n",
      "Average validation loss: 70.17923026317993\n",
      "Training epoch 2522...\n",
      "\n",
      "Train Epoch: 2522 [0/8000 (0%)]\tBatch Loss: 366.540017\tLearning Rate (w_theta): 0.001000\t TIME:6116.4s\n",
      "\t\t\t\tDisc: 0.542493\t\tSym: 10.675503\t\tSpars: 355.322021\n",
      "\t TVw: 0.279235 | TVb: -2.024834 | GSw: -0.235001 | GSb: 0.064911 | TSUw: 0.464835 | TSUb: 0.034896\n",
      "\n",
      "Train Epoch: 2522 [4000/8000 (50%)]\tBatch Loss: 423.458750\tLearning Rate (w_theta): 0.001000\t TIME:6118.0s\n",
      "\t\t\t\tDisc: 0.602788\t\tSym: 13.608647\t\tSpars: 409.247314\n",
      "\t TVw: 0.278607 | TVb: -2.024844 | GSw: -0.235001 | GSb: 0.064911 | TSUw: 0.464835 | TSUb: 0.034896\n",
      "Validating epoch 2522...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 355.6319589442022\n",
      "Average validation loss: 69.84343075453819\n",
      "Training epoch 2523...\n",
      "\n",
      "Train Epoch: 2523 [0/8000 (0%)]\tBatch Loss: 364.782397\tLearning Rate (w_theta): 0.001000\t TIME:6120.4s\n",
      "\t\t\t\tDisc: 0.479574\t\tSym: 10.739682\t\tSpars: 353.563141\n",
      "\t TVw: 0.278452 | TVb: -2.024847 | GSw: -0.235001 | GSb: 0.064911 | TSUw: 0.464834 | TSUb: 0.034896\n",
      "\n",
      "Train Epoch: 2523 [4000/8000 (50%)]\tBatch Loss: 347.095880\tLearning Rate (w_theta): 0.001000\t TIME:6122.0s\n",
      "\t\t\t\tDisc: 0.409903\t\tSym: 10.855227\t\tSpars: 335.830750\n",
      "\t TVw: 0.279021 | TVb: -2.024805 | GSw: -0.235001 | GSb: 0.064911 | TSUw: 0.464834 | TSUb: 0.034896\n",
      "Validating epoch 2523...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 345.21998680938583\n",
      "Average validation loss: 75.26700274137823\n",
      "Training epoch 2524...\n",
      "\n",
      "Train Epoch: 2524 [0/8000 (0%)]\tBatch Loss: 344.057260\tLearning Rate (w_theta): 0.001000\t TIME:6124.7s\n",
      "\t\t\t\tDisc: 0.457124\t\tSym: 10.784402\t\tSpars: 332.815735\n",
      "\t TVw: 0.280046 | TVb: -2.024740 | GSw: -0.235001 | GSb: 0.064910 | TSUw: 0.464834 | TSUb: 0.034896\n",
      "\n",
      "Train Epoch: 2524 [4000/8000 (50%)]\tBatch Loss: 340.532884\tLearning Rate (w_theta): 0.001000\t TIME:6126.2s\n",
      "\t\t\t\tDisc: 0.547321\t\tSym: 8.791837\t\tSpars: 331.193726\n",
      "\t TVw: 0.280833 | TVb: -2.024683 | GSw: -0.235001 | GSb: 0.064910 | TSUw: 0.464834 | TSUb: 0.034897\n",
      "Validating epoch 2524...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 345.1307233925338\n",
      "Average validation loss: 76.71990946600397\n",
      "Training epoch 2525...\n",
      "\n",
      "Train Epoch: 2525 [0/8000 (0%)]\tBatch Loss: 323.424920\tLearning Rate (w_theta): 0.001000\t TIME:6128.7s\n",
      "\t\t\t\tDisc: 0.487381\t\tSym: 8.822640\t\tSpars: 314.114899\n",
      "\t TVw: 0.281335 | TVb: -2.024652 | GSw: -0.235001 | GSb: 0.064910 | TSUw: 0.464833 | TSUb: 0.034897\n",
      "\n",
      "Train Epoch: 2525 [4000/8000 (50%)]\tBatch Loss: 343.710037\tLearning Rate (w_theta): 0.001000\t TIME:6130.3s\n",
      "\t\t\t\tDisc: 0.475970\t\tSym: 9.895627\t\tSpars: 333.338440\n",
      "\t TVw: 0.282123 | TVb: -2.024600 | GSw: -0.235001 | GSb: 0.064910 | TSUw: 0.464833 | TSUb: 0.034897\n",
      "Validating epoch 2525...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 341.758131524267\n",
      "Average validation loss: 77.56316305881153\n",
      "Training epoch 2526...\n",
      "\n",
      "Train Epoch: 2526 [0/8000 (0%)]\tBatch Loss: 356.681012\tLearning Rate (w_theta): 0.001000\t TIME:6132.8s\n",
      "\t\t\t\tDisc: 0.542970\t\tSym: 10.432994\t\tSpars: 345.705048\n",
      "\t TVw: 0.282765 | TVb: -2.024547 | GSw: -0.235001 | GSb: 0.064910 | TSUw: 0.464833 | TSUb: 0.034897\n",
      "\n",
      "Train Epoch: 2526 [4000/8000 (50%)]\tBatch Loss: 336.387929\tLearning Rate (w_theta): 0.001000\t TIME:6134.4s\n",
      "\t\t\t\tDisc: 0.462054\t\tSym: 10.211611\t\tSpars: 325.714264\n",
      "\t TVw: 0.283325 | TVb: -2.024483 | GSw: -0.235001 | GSb: 0.064909 | TSUw: 0.464833 | TSUb: 0.034897\n",
      "Validating epoch 2526...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 338.10477360307\n",
      "Average validation loss: 73.11913409397975\n",
      "Training epoch 2527...\n",
      "\n",
      "Train Epoch: 2527 [0/8000 (0%)]\tBatch Loss: 322.347037\tLearning Rate (w_theta): 0.001000\t TIME:6136.9s\n",
      "\t\t\t\tDisc: 0.439549\t\tSym: 9.267504\t\tSpars: 312.639984\n",
      "\t TVw: 0.283778 | TVb: -2.024409 | GSw: -0.235001 | GSb: 0.064909 | TSUw: 0.464833 | TSUb: 0.034898\n",
      "\n",
      "Train Epoch: 2527 [4000/8000 (50%)]\tBatch Loss: 325.606374\tLearning Rate (w_theta): 0.001000\t TIME:6138.4s\n",
      "\t\t\t\tDisc: 0.457746\t\tSym: 8.963783\t\tSpars: 316.184845\n",
      "\t TVw: 0.283955 | TVb: -2.024333 | GSw: -0.235001 | GSb: 0.064909 | TSUw: 0.464832 | TSUb: 0.034898\n",
      "Validating epoch 2527...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 330.36000069067705\n",
      "Average validation loss: 74.30668197709852\n",
      "Training epoch 2528...\n",
      "\n",
      "Train Epoch: 2528 [0/8000 (0%)]\tBatch Loss: 331.225449\tLearning Rate (w_theta): 0.001000\t TIME:6140.9s\n",
      "\t\t\t\tDisc: 0.484831\t\tSym: 9.893419\t\tSpars: 320.847198\n",
      "\t TVw: 0.283922 | TVb: -2.024259 | GSw: -0.235001 | GSb: 0.064909 | TSUw: 0.464832 | TSUb: 0.034898\n",
      "\n",
      "Train Epoch: 2528 [4000/8000 (50%)]\tBatch Loss: 336.675457\tLearning Rate (w_theta): 0.001000\t TIME:6142.4s\n",
      "\t\t\t\tDisc: 0.470279\t\tSym: 10.711862\t\tSpars: 325.493317\n",
      "\t TVw: 0.283722 | TVb: -2.024192 | GSw: -0.235002 | GSb: 0.064909 | TSUw: 0.464832 | TSUb: 0.034898\n",
      "Validating epoch 2528...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 328.5217047459232\n",
      "Average validation loss: 74.93265240594573\n",
      "Training epoch 2529...\n",
      "\n",
      "Train Epoch: 2529 [0/8000 (0%)]\tBatch Loss: 335.664020\tLearning Rate (w_theta): 0.001000\t TIME:6144.9s\n",
      "\t\t\t\tDisc: 0.501637\t\tSym: 10.270812\t\tSpars: 324.891571\n",
      "\t TVw: 0.283357 | TVb: -2.024132 | GSw: -0.235002 | GSb: 0.064908 | TSUw: 0.464832 | TSUb: 0.034898\n",
      "\n",
      "Train Epoch: 2529 [4000/8000 (50%)]\tBatch Loss: 327.608653\tLearning Rate (w_theta): 0.001000\t TIME:6146.5s\n",
      "\t\t\t\tDisc: 0.467335\t\tSym: 10.531394\t\tSpars: 316.609924\n",
      "\t TVw: 0.282831 | TVb: -2.024091 | GSw: -0.235002 | GSb: 0.064908 | TSUw: 0.464832 | TSUb: 0.034899\n",
      "Validating epoch 2529...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 326.9368056035972\n",
      "Average validation loss: 73.16657454234401\n",
      "Training epoch 2530...\n",
      "\n",
      "Train Epoch: 2530 [0/8000 (0%)]\tBatch Loss: 311.436577\tLearning Rate (w_theta): 0.001000\t TIME:6148.9s\n",
      "\t\t\t\tDisc: 0.460570\t\tSym: 8.820764\t\tSpars: 302.155243\n",
      "\t TVw: 0.282277 | TVb: -2.024050 | GSw: -0.235002 | GSb: 0.064908 | TSUw: 0.464831 | TSUb: 0.034899\n",
      "\n",
      "Train Epoch: 2530 [4000/8000 (50%)]\tBatch Loss: 316.858721\tLearning Rate (w_theta): 0.001000\t TIME:6150.5s\n",
      "\t\t\t\tDisc: 0.473335\t\tSym: 9.152628\t\tSpars: 307.232758\n",
      "\t TVw: 0.281753 | TVb: -2.024014 | GSw: -0.235002 | GSb: 0.064908 | TSUw: 0.464831 | TSUb: 0.034899\n",
      "Validating epoch 2530...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 326.9048244354624\n",
      "Average validation loss: 74.22133641677401\n",
      "Training epoch 2531...\n",
      "\n",
      "Train Epoch: 2531 [0/8000 (0%)]\tBatch Loss: 312.259264\tLearning Rate (w_theta): 0.001000\t TIME:6153.6s\n",
      "\t\t\t\tDisc: 0.492543\t\tSym: 8.980191\t\tSpars: 302.786530\n",
      "\t TVw: 0.281082 | TVb: -2.023988 | GSw: -0.235002 | GSb: 0.064908 | TSUw: 0.464831 | TSUb: 0.034899\n",
      "\n",
      "Train Epoch: 2531 [4000/8000 (50%)]\tBatch Loss: 365.347324\tLearning Rate (w_theta): 0.001000\t TIME:6155.2s\n",
      "\t\t\t\tDisc: 0.523816\t\tSym: 10.942191\t\tSpars: 353.881317\n",
      "\t TVw: 0.280205 | TVb: -2.023980 | GSw: -0.235002 | GSb: 0.064907 | TSUw: 0.464831 | TSUb: 0.034899\n",
      "Validating epoch 2531...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 339.0617363577305\n",
      "Average validation loss: 74.19381148782344\n",
      "Training epoch 2532...\n",
      "\n",
      "Train Epoch: 2532 [0/8000 (0%)]\tBatch Loss: 327.254099\tLearning Rate (w_theta): 0.001000\t TIME:6158.1s\n",
      "\t\t\t\tDisc: 0.466036\t\tSym: 9.771034\t\tSpars: 317.017029\n",
      "\t TVw: 0.278985 | TVb: -2.024017 | GSw: -0.235002 | GSb: 0.064907 | TSUw: 0.464831 | TSUb: 0.034899\n",
      "\n",
      "Train Epoch: 2532 [4000/8000 (50%)]\tBatch Loss: 325.722703\tLearning Rate (w_theta): 0.001000\t TIME:6159.6s\n",
      "\t\t\t\tDisc: 0.449693\t\tSym: 9.069946\t\tSpars: 316.203064\n",
      "\t TVw: 0.278574 | TVb: -2.024013 | GSw: -0.235002 | GSb: 0.064907 | TSUw: 0.464831 | TSUb: 0.034900\n",
      "Validating epoch 2532...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 330.02903750727745\n",
      "Average validation loss: 74.03470985028689\n",
      "Training epoch 2533...\n",
      "\n",
      "Train Epoch: 2533 [0/8000 (0%)]\tBatch Loss: 334.976827\tLearning Rate (w_theta): 0.001000\t TIME:6162.1s\n",
      "\t\t\t\tDisc: 0.458955\t\tSym: 10.137104\t\tSpars: 324.380768\n",
      "\t TVw: 0.278607 | TVb: -2.023983 | GSw: -0.235002 | GSb: 0.064907 | TSUw: 0.464830 | TSUb: 0.034900\n",
      "\n",
      "Train Epoch: 2533 [4000/8000 (50%)]\tBatch Loss: 323.990433\tLearning Rate (w_theta): 0.001000\t TIME:6163.7s\n",
      "\t\t\t\tDisc: 0.457308\t\tSym: 9.621687\t\tSpars: 313.911438\n",
      "\t TVw: 0.278915 | TVb: -2.023942 | GSw: -0.235002 | GSb: 0.064906 | TSUw: 0.464830 | TSUb: 0.034900\n",
      "Validating epoch 2533...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 333.77432897341475\n",
      "Average validation loss: 69.54028204643441\n",
      "Training epoch 2534...\n",
      "\n",
      "Train Epoch: 2534 [0/8000 (0%)]\tBatch Loss: 337.769512\tLearning Rate (w_theta): 0.001000\t TIME:6166.2s\n",
      "\t\t\t\tDisc: 0.445479\t\tSym: 10.661313\t\tSpars: 326.662720\n",
      "\t TVw: 0.279048 | TVb: -2.023895 | GSw: -0.235002 | GSb: 0.064906 | TSUw: 0.464830 | TSUb: 0.034900\n",
      "\n",
      "Train Epoch: 2534 [4000/8000 (50%)]\tBatch Loss: 312.023904\tLearning Rate (w_theta): 0.001000\t TIME:6167.7s\n",
      "\t\t\t\tDisc: 0.463286\t\tSym: 9.367167\t\tSpars: 302.193451\n",
      "\t TVw: 0.279515 | TVb: -2.023824 | GSw: -0.235002 | GSb: 0.064906 | TSUw: 0.464830 | TSUb: 0.034900\n",
      "Validating epoch 2534...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 324.25098618660905\n",
      "Average validation loss: 71.51988353503936\n",
      "Training epoch 2535...\n",
      "\n",
      "Train Epoch: 2535 [0/8000 (0%)]\tBatch Loss: 318.529711\tLearning Rate (w_theta): 0.001000\t TIME:6170.2s\n",
      "\t\t\t\tDisc: 0.447260\t\tSym: 9.124199\t\tSpars: 308.958252\n",
      "\t TVw: 0.279984 | TVb: -2.023734 | GSw: -0.235002 | GSb: 0.064906 | TSUw: 0.464829 | TSUb: 0.034901\n",
      "\n",
      "Train Epoch: 2535 [4000/8000 (50%)]\tBatch Loss: 309.477381\tLearning Rate (w_theta): 0.001000\t TIME:6171.7s\n",
      "\t\t\t\tDisc: 0.441005\t\tSym: 9.230987\t\tSpars: 299.805389\n",
      "\t TVw: 0.280323 | TVb: -2.023645 | GSw: -0.235002 | GSb: 0.064906 | TSUw: 0.464829 | TSUb: 0.034901\n",
      "Validating epoch 2535...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 322.21525871766454\n",
      "Average validation loss: 74.35185020328507\n",
      "Training epoch 2536...\n",
      "\n",
      "Train Epoch: 2536 [0/8000 (0%)]\tBatch Loss: 326.021142\tLearning Rate (w_theta): 0.001000\t TIME:6174.2s\n",
      "\t\t\t\tDisc: 0.464709\t\tSym: 10.089850\t\tSpars: 315.466583\n",
      "\t TVw: 0.280469 | TVb: -2.023566 | GSw: -0.235002 | GSb: 0.064905 | TSUw: 0.464829 | TSUb: 0.034901\n",
      "\n",
      "Train Epoch: 2536 [4000/8000 (50%)]\tBatch Loss: 305.025231\tLearning Rate (w_theta): 0.001000\t TIME:6175.8s\n",
      "\t\t\t\tDisc: 0.488724\t\tSym: 9.161842\t\tSpars: 295.374664\n",
      "\t TVw: 0.280194 | TVb: -2.023526 | GSw: -0.235003 | GSb: 0.064905 | TSUw: 0.464829 | TSUb: 0.034901\n",
      "Validating epoch 2536...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 329.33571402618605\n",
      "Average validation loss: 71.55810819040953\n",
      "Training epoch 2537...\n",
      "\n",
      "Train Epoch: 2537 [0/8000 (0%)]\tBatch Loss: 323.435158\tLearning Rate (w_theta): 0.001000\t TIME:6178.3s\n",
      "\t\t\t\tDisc: 0.445803\t\tSym: 9.254644\t\tSpars: 313.734711\n",
      "\t TVw: 0.279847 | TVb: -2.023501 | GSw: -0.235003 | GSb: 0.064905 | TSUw: 0.464828 | TSUb: 0.034901\n",
      "\n",
      "Train Epoch: 2537 [4000/8000 (50%)]\tBatch Loss: 334.601713\tLearning Rate (w_theta): 0.001000\t TIME:6179.9s\n",
      "\t\t\t\tDisc: 0.441481\t\tSym: 10.177444\t\tSpars: 323.982788\n",
      "\t TVw: 0.279389 | TVb: -2.023488 | GSw: -0.235003 | GSb: 0.064905 | TSUw: 0.464828 | TSUb: 0.034901\n",
      "Validating epoch 2537...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 329.9759794356064\n",
      "Average validation loss: 75.94639659389136\n",
      "Training epoch 2538...\n",
      "\n",
      "Train Epoch: 2538 [0/8000 (0%)]\tBatch Loss: 331.104990\tLearning Rate (w_theta): 0.001000\t TIME:6182.3s\n",
      "\t\t\t\tDisc: 0.526077\t\tSym: 10.025935\t\tSpars: 320.552979\n",
      "\t TVw: 0.279091 | TVb: -2.023474 | GSw: -0.235003 | GSb: 0.064905 | TSUw: 0.464828 | TSUb: 0.034902\n",
      "\n",
      "Train Epoch: 2538 [4000/8000 (50%)]\tBatch Loss: 326.578400\tLearning Rate (w_theta): 0.001000\t TIME:6183.9s\n",
      "\t\t\t\tDisc: 0.513305\t\tSym: 10.163850\t\tSpars: 315.901245\n",
      "\t TVw: 0.278470 | TVb: -2.023486 | GSw: -0.235003 | GSb: 0.064904 | TSUw: 0.464828 | TSUb: 0.034902\n",
      "Validating epoch 2538...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 329.6114131322741\n",
      "Average validation loss: 70.09912266913088\n",
      "Training epoch 2539...\n",
      "\n",
      "Train Epoch: 2539 [0/8000 (0%)]\tBatch Loss: 311.990424\tLearning Rate (w_theta): 0.001000\t TIME:6186.4s\n",
      "\t\t\t\tDisc: 0.435676\t\tSym: 8.908385\t\tSpars: 302.646362\n",
      "\t TVw: 0.278207 | TVb: -2.023471 | GSw: -0.235003 | GSb: 0.064904 | TSUw: 0.464828 | TSUb: 0.034902\n",
      "\n",
      "Train Epoch: 2539 [4000/8000 (50%)]\tBatch Loss: 324.771257\tLearning Rate (w_theta): 0.001000\t TIME:6187.9s\n",
      "\t\t\t\tDisc: 0.431379\t\tSym: 10.291446\t\tSpars: 314.048431\n",
      "\t TVw: 0.278399 | TVb: -2.023417 | GSw: -0.235003 | GSb: 0.064904 | TSUw: 0.464827 | TSUb: 0.034902\n",
      "Validating epoch 2539...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 320.4321114794789\n",
      "Average validation loss: 70.78950359504826\n",
      "Training epoch 2540...\n",
      "\n",
      "Train Epoch: 2540 [0/8000 (0%)]\tBatch Loss: 321.654883\tLearning Rate (w_theta): 0.001000\t TIME:6190.4s\n",
      "\t\t\t\tDisc: 0.426827\t\tSym: 10.074369\t\tSpars: 311.153687\n",
      "\t TVw: 0.278703 | TVb: -2.023342 | GSw: -0.235003 | GSb: 0.064904 | TSUw: 0.464827 | TSUb: 0.034902\n",
      "\n",
      "Train Epoch: 2540 [4000/8000 (50%)]\tBatch Loss: 312.806765\tLearning Rate (w_theta): 0.001000\t TIME:6191.9s\n",
      "\t\t\t\tDisc: 0.451168\t\tSym: 9.120429\t\tSpars: 303.235168\n",
      "\t TVw: 0.279022 | TVb: -2.023258 | GSw: -0.235003 | GSb: 0.064904 | TSUw: 0.464827 | TSUb: 0.034903\n",
      "Validating epoch 2540...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 318.7679513321171\n",
      "Average validation loss: 71.75928503574363\n",
      "Training epoch 2541...\n",
      "\n",
      "Train Epoch: 2541 [0/8000 (0%)]\tBatch Loss: 324.660714\tLearning Rate (w_theta): 0.001000\t TIME:6195.1s\n",
      "\t\t\t\tDisc: 0.449108\t\tSym: 10.545255\t\tSpars: 313.666351\n",
      "\t TVw: 0.279280 | TVb: -2.023186 | GSw: -0.235003 | GSb: 0.064903 | TSUw: 0.464827 | TSUb: 0.034903\n",
      "\n",
      "Train Epoch: 2541 [4000/8000 (50%)]\tBatch Loss: 314.340151\tLearning Rate (w_theta): 0.001000\t TIME:6196.7s\n",
      "\t\t\t\tDisc: 0.467699\t\tSym: 9.615189\t\tSpars: 304.257263\n",
      "\t TVw: 0.279642 | TVb: -2.023113 | GSw: -0.235003 | GSb: 0.064903 | TSUw: 0.464826 | TSUb: 0.034903\n",
      "Validating epoch 2541...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 318.88216860148884\n",
      "Average validation loss: 74.91814069434626\n",
      "Training epoch 2542...\n",
      "\n",
      "Train Epoch: 2542 [0/8000 (0%)]\tBatch Loss: 340.139167\tLearning Rate (w_theta): 0.001000\t TIME:6199.1s\n",
      "\t\t\t\tDisc: 0.512820\t\tSym: 11.346745\t\tSpars: 328.279602\n",
      "\t TVw: 0.279515 | TVb: -2.023076 | GSw: -0.235003 | GSb: 0.064903 | TSUw: 0.464826 | TSUb: 0.034903\n",
      "\n",
      "Train Epoch: 2542 [4000/8000 (50%)]\tBatch Loss: 309.986919\tLearning Rate (w_theta): 0.001000\t TIME:6200.7s\n",
      "\t\t\t\tDisc: 0.477783\t\tSym: 9.163128\t\tSpars: 300.346008\n",
      "\t TVw: 0.279123 | TVb: -2.023060 | GSw: -0.235003 | GSb: 0.064903 | TSUw: 0.464826 | TSUb: 0.034903\n",
      "Validating epoch 2542...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 324.767290414351\n",
      "Average validation loss: 67.7139852651558\n",
      "Training epoch 2543...\n",
      "\n",
      "Train Epoch: 2543 [0/8000 (0%)]\tBatch Loss: 336.267474\tLearning Rate (w_theta): 0.001000\t TIME:6203.2s\n",
      "\t\t\t\tDisc: 0.529960\t\tSym: 9.677180\t\tSpars: 326.060333\n",
      "\t TVw: 0.278398 | TVb: -2.023069 | GSw: -0.235003 | GSb: 0.064902 | TSUw: 0.464826 | TSUb: 0.034903\n",
      "\n",
      "Train Epoch: 2543 [4000/8000 (50%)]\tBatch Loss: 325.402742\tLearning Rate (w_theta): 0.001000\t TIME:6204.8s\n",
      "\t\t\t\tDisc: 0.429830\t\tSym: 10.082410\t\tSpars: 314.890503\n",
      "\t TVw: 0.277715 | TVb: -2.023074 | GSw: -0.235003 | GSb: 0.064902 | TSUw: 0.464825 | TSUb: 0.034904\n",
      "Validating epoch 2543...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 328.7098096470255\n",
      "Average validation loss: 71.37190684571054\n",
      "Training epoch 2544...\n",
      "\n",
      "Train Epoch: 2544 [0/8000 (0%)]\tBatch Loss: 317.289154\tLearning Rate (w_theta): 0.001000\t TIME:6207.2s\n",
      "\t\t\t\tDisc: 0.450815\t\tSym: 10.105581\t\tSpars: 306.732758\n",
      "\t TVw: 0.277681 | TVb: -2.023053 | GSw: -0.235003 | GSb: 0.064902 | TSUw: 0.464825 | TSUb: 0.034904\n",
      "\n",
      "Train Epoch: 2544 [4000/8000 (50%)]\tBatch Loss: 341.903854\tLearning Rate (w_theta): 0.001000\t TIME:6208.8s\n",
      "\t\t\t\tDisc: 0.514215\t\tSym: 10.594290\t\tSpars: 330.795349\n",
      "\t TVw: 0.277955 | TVb: -2.023024 | GSw: -0.235003 | GSb: 0.064902 | TSUw: 0.464825 | TSUb: 0.034904\n",
      "Validating epoch 2544...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 325.1991727838229\n",
      "Average validation loss: 74.1163244995079\n",
      "Training epoch 2545...\n",
      "\n",
      "Train Epoch: 2545 [0/8000 (0%)]\tBatch Loss: 324.748152\tLearning Rate (w_theta): 0.001000\t TIME:6211.3s\n",
      "\t\t\t\tDisc: 0.492999\t\tSym: 9.738978\t\tSpars: 314.516174\n",
      "\t TVw: 0.278551 | TVb: -2.022974 | GSw: -0.235004 | GSb: 0.064902 | TSUw: 0.464825 | TSUb: 0.034904\n",
      "\n",
      "Train Epoch: 2545 [4000/8000 (50%)]\tBatch Loss: 310.673008\tLearning Rate (w_theta): 0.001000\t TIME:6212.8s\n",
      "\t\t\t\tDisc: 0.438990\t\tSym: 9.444039\t\tSpars: 300.789978\n",
      "\t TVw: 0.279067 | TVb: -2.022915 | GSw: -0.235004 | GSb: 0.064901 | TSUw: 0.464824 | TSUb: 0.034904\n",
      "Validating epoch 2545...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 322.5302830880424\n",
      "Average validation loss: 69.61282096339049\n",
      "Training epoch 2546...\n",
      "\n",
      "Train Epoch: 2546 [0/8000 (0%)]\tBatch Loss: 306.925020\tLearning Rate (w_theta): 0.001000\t TIME:6215.8s\n",
      "\t\t\t\tDisc: 0.463976\t\tSym: 8.602218\t\tSpars: 297.858826\n",
      "\t TVw: 0.279687 | TVb: -2.022851 | GSw: -0.235004 | GSb: 0.064901 | TSUw: 0.464824 | TSUb: 0.034905\n",
      "\n",
      "Train Epoch: 2546 [4000/8000 (50%)]\tBatch Loss: 333.722945\tLearning Rate (w_theta): 0.001000\t TIME:6217.3s\n",
      "\t\t\t\tDisc: 0.500858\t\tSym: 10.440715\t\tSpars: 322.781372\n",
      "\t TVw: 0.280268 | TVb: -2.022785 | GSw: -0.235004 | GSb: 0.064901 | TSUw: 0.464824 | TSUb: 0.034905\n",
      "Validating epoch 2546...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 324.1479279875732\n",
      "Average validation loss: 71.90198284790456\n",
      "Training epoch 2547...\n",
      "\n",
      "Train Epoch: 2547 [0/8000 (0%)]\tBatch Loss: 308.540412\tLearning Rate (w_theta): 0.001000\t TIME:6219.8s\n",
      "\t\t\t\tDisc: 0.483797\t\tSym: 9.800328\t\tSpars: 298.256287\n",
      "\t TVw: 0.280668 | TVb: -2.022744 | GSw: -0.235004 | GSb: 0.064901 | TSUw: 0.464824 | TSUb: 0.034905\n",
      "\n",
      "Train Epoch: 2547 [4000/8000 (50%)]\tBatch Loss: 312.642244\tLearning Rate (w_theta): 0.001000\t TIME:6221.3s\n",
      "\t\t\t\tDisc: 0.501086\t\tSym: 9.311202\t\tSpars: 302.829956\n",
      "\t TVw: 0.280833 | TVb: -2.022705 | GSw: -0.235004 | GSb: 0.064900 | TSUw: 0.464824 | TSUb: 0.034905\n",
      "Validating epoch 2547...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 318.20416664450283\n",
      "Average validation loss: 73.13562251179002\n",
      "Training epoch 2548...\n",
      "\n",
      "Train Epoch: 2548 [0/8000 (0%)]\tBatch Loss: 315.806396\tLearning Rate (w_theta): 0.001000\t TIME:6223.8s\n",
      "\t\t\t\tDisc: 0.496948\t\tSym: 9.496216\t\tSpars: 305.813232\n",
      "\t TVw: 0.281367 | TVb: -2.022665 | GSw: -0.235004 | GSb: 0.064900 | TSUw: 0.464823 | TSUb: 0.034905\n",
      "\n",
      "Train Epoch: 2548 [4000/8000 (50%)]\tBatch Loss: 318.547325\tLearning Rate (w_theta): 0.001000\t TIME:6225.4s\n",
      "\t\t\t\tDisc: 0.472993\t\tSym: 10.431205\t\tSpars: 307.643127\n",
      "\t TVw: 0.281790 | TVb: -2.022609 | GSw: -0.235004 | GSb: 0.064900 | TSUw: 0.464823 | TSUb: 0.034906\n",
      "Validating epoch 2548...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 315.65409659952684\n",
      "Average validation loss: 70.30433831977844\n",
      "Training epoch 2549...\n",
      "\n",
      "Train Epoch: 2549 [0/8000 (0%)]\tBatch Loss: 316.042287\tLearning Rate (w_theta): 0.001000\t TIME:6227.8s\n",
      "\t\t\t\tDisc: 0.487734\t\tSym: 9.803454\t\tSpars: 305.751099\n",
      "\t TVw: 0.281847 | TVb: -2.022561 | GSw: -0.235004 | GSb: 0.064900 | TSUw: 0.464823 | TSUb: 0.034906\n",
      "\n",
      "Train Epoch: 2549 [4000/8000 (50%)]\tBatch Loss: 299.851399\tLearning Rate (w_theta): 0.001000\t TIME:6229.4s\n",
      "\t\t\t\tDisc: 0.482328\t\tSym: 8.763113\t\tSpars: 290.605957\n",
      "\t TVw: 0.281689 | TVb: -2.022503 | GSw: -0.235004 | GSb: 0.064900 | TSUw: 0.464823 | TSUb: 0.034906\n",
      "Validating epoch 2549...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 312.3808418037236\n",
      "Average validation loss: 70.23376008824299\n",
      "Training epoch 2550...\n",
      "\n",
      "Train Epoch: 2550 [0/8000 (0%)]\tBatch Loss: 307.369845\tLearning Rate (w_theta): 0.001000\t TIME:6231.8s\n",
      "\t\t\t\tDisc: 0.467002\t\tSym: 10.330455\t\tSpars: 296.572388\n",
      "\t TVw: 0.281326 | TVb: -2.022453 | GSw: -0.235004 | GSb: 0.064899 | TSUw: 0.464822 | TSUb: 0.034906\n",
      "\n",
      "Train Epoch: 2550 [4000/8000 (50%)]\tBatch Loss: 315.907443\tLearning Rate (w_theta): 0.001000\t TIME:6233.4s\n",
      "\t\t\t\tDisc: 0.493522\t\tSym: 10.333568\t\tSpars: 305.080353\n",
      "\t TVw: 0.281139 | TVb: -2.022386 | GSw: -0.235004 | GSb: 0.064899 | TSUw: 0.464822 | TSUb: 0.034906\n",
      "Validating epoch 2550...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 310.77230247121383\n",
      "Average validation loss: 73.55040090365144\n",
      "Training epoch 2551...\n",
      "\n",
      "Train Epoch: 2551 [0/8000 (0%)]\tBatch Loss: 316.532769\tLearning Rate (w_theta): 0.001000\t TIME:6236.5s\n",
      "\t\t\t\tDisc: 0.559262\t\tSym: 9.505459\t\tSpars: 306.468048\n",
      "\t TVw: 0.280868 | TVb: -2.022336 | GSw: -0.235004 | GSb: 0.064899 | TSUw: 0.464822 | TSUb: 0.034906\n",
      "\n",
      "Train Epoch: 2551 [4000/8000 (50%)]\tBatch Loss: 311.163405\tLearning Rate (w_theta): 0.001000\t TIME:6238.1s\n",
      "\t\t\t\tDisc: 0.522158\t\tSym: 9.467297\t\tSpars: 301.173950\n",
      "\t TVw: 0.280061 | TVb: -2.022346 | GSw: -0.235004 | GSb: 0.064899 | TSUw: 0.464822 | TSUb: 0.034907\n",
      "Validating epoch 2551...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 320.093878650699\n",
      "Average validation loss: 68.3365357937443\n",
      "Training epoch 2552...\n",
      "\n",
      "Train Epoch: 2552 [0/8000 (0%)]\tBatch Loss: 301.099130\tLearning Rate (w_theta): 0.001000\t TIME:6240.6s\n",
      "\t\t\t\tDisc: 0.448820\t\tSym: 9.251079\t\tSpars: 291.399231\n",
      "\t TVw: 0.279530 | TVb: -2.022351 | GSw: -0.235004 | GSb: 0.064899 | TSUw: 0.464821 | TSUb: 0.034907\n",
      "\n",
      "Train Epoch: 2552 [4000/8000 (50%)]\tBatch Loss: 328.440308\tLearning Rate (w_theta): 0.001000\t TIME:6242.2s\n",
      "\t\t\t\tDisc: 0.468837\t\tSym: 9.840947\t\tSpars: 318.130524\n",
      "\t TVw: 0.279526 | TVb: -2.022311 | GSw: -0.235004 | GSb: 0.064898 | TSUw: 0.464821 | TSUb: 0.034907\n",
      "Validating epoch 2552...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 318.4265798181971\n",
      "Average validation loss: 70.8597056758716\n",
      "Training epoch 2553...\n",
      "\n",
      "Train Epoch: 2553 [0/8000 (0%)]\tBatch Loss: 315.712488\tLearning Rate (w_theta): 0.001000\t TIME:6244.6s\n",
      "\t\t\t\tDisc: 0.451143\t\tSym: 9.712639\t\tSpars: 305.548706\n",
      "\t TVw: 0.279407 | TVb: -2.022291 | GSw: -0.235004 | GSb: 0.064898 | TSUw: 0.464821 | TSUb: 0.034907\n",
      "\n",
      "Train Epoch: 2553 [4000/8000 (50%)]\tBatch Loss: 335.917176\tLearning Rate (w_theta): 0.001000\t TIME:6246.2s\n",
      "\t\t\t\tDisc: 0.532736\t\tSym: 11.241923\t\tSpars: 324.142517\n",
      "\t TVw: 0.279297 | TVb: -2.022275 | GSw: -0.235005 | GSb: 0.064898 | TSUw: 0.464821 | TSUb: 0.034907\n",
      "Validating epoch 2553...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 318.21428086410555\n",
      "Average validation loss: 71.83465383247386\n",
      "Training epoch 2554...\n",
      "\n",
      "Train Epoch: 2554 [0/8000 (0%)]\tBatch Loss: 334.240652\tLearning Rate (w_theta): 0.001000\t TIME:6248.7s\n",
      "\t\t\t\tDisc: 0.475075\t\tSym: 10.400404\t\tSpars: 323.365173\n",
      "\t TVw: 0.279342 | TVb: -2.022264 | GSw: -0.235005 | GSb: 0.064898 | TSUw: 0.464820 | TSUb: 0.034908\n",
      "\n",
      "Train Epoch: 2554 [4000/8000 (50%)]\tBatch Loss: 313.410702\tLearning Rate (w_theta): 0.001000\t TIME:6250.2s\n",
      "\t\t\t\tDisc: 0.443332\t\tSym: 10.256585\t\tSpars: 302.710785\n",
      "\t TVw: 0.279722 | TVb: -2.022217 | GSw: -0.235005 | GSb: 0.064897 | TSUw: 0.464820 | TSUb: 0.034908\n",
      "Validating epoch 2554...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 312.9534470694834\n",
      "Average validation loss: 68.40784769494685\n",
      "Training epoch 2555...\n",
      "\n",
      "Train Epoch: 2555 [0/8000 (0%)]\tBatch Loss: 309.601191\tLearning Rate (w_theta): 0.001000\t TIME:6252.7s\n",
      "\t\t\t\tDisc: 0.445739\t\tSym: 10.044155\t\tSpars: 299.111298\n",
      "\t TVw: 0.280212 | TVb: -2.022144 | GSw: -0.235005 | GSb: 0.064897 | TSUw: 0.464820 | TSUb: 0.034908\n",
      "\n",
      "Train Epoch: 2555 [4000/8000 (50%)]\tBatch Loss: 319.286123\tLearning Rate (w_theta): 0.001000\t TIME:6254.2s\n",
      "\t\t\t\tDisc: 0.448248\t\tSym: 9.938186\t\tSpars: 308.899689\n",
      "\t TVw: 0.280717 | TVb: -2.022062 | GSw: -0.235005 | GSb: 0.064897 | TSUw: 0.464820 | TSUb: 0.034908\n",
      "Validating epoch 2555...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 311.58677594927207\n",
      "Average validation loss: 67.48503736600018\n",
      "Training epoch 2556...\n",
      "\n",
      "Train Epoch: 2556 [0/8000 (0%)]\tBatch Loss: 307.614384\tLearning Rate (w_theta): 0.001000\t TIME:6256.7s\n",
      "\t\t\t\tDisc: 0.455568\t\tSym: 9.698794\t\tSpars: 297.460022\n",
      "\t TVw: 0.281111 | TVb: -2.021978 | GSw: -0.235005 | GSb: 0.064897 | TSUw: 0.464819 | TSUb: 0.034908\n",
      "\n",
      "Train Epoch: 2556 [4000/8000 (50%)]\tBatch Loss: 304.051232\tLearning Rate (w_theta): 0.001000\t TIME:6258.3s\n",
      "\t\t\t\tDisc: 0.473432\t\tSym: 9.304149\t\tSpars: 294.273651\n",
      "\t TVw: 0.281208 | TVb: -2.021923 | GSw: -0.235005 | GSb: 0.064897 | TSUw: 0.464819 | TSUb: 0.034909\n",
      "Validating epoch 2556...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 309.5779183796912\n",
      "Average validation loss: 73.29997373244404\n",
      "Training epoch 2557...\n",
      "\n",
      "Train Epoch: 2557 [0/8000 (0%)]\tBatch Loss: 321.501856\tLearning Rate (w_theta): 0.001000\t TIME:6260.8s\n",
      "\t\t\t\tDisc: 0.567429\t\tSym: 10.009194\t\tSpars: 310.925232\n",
      "\t TVw: 0.281202 | TVb: -2.021861 | GSw: -0.235005 | GSb: 0.064896 | TSUw: 0.464819 | TSUb: 0.034909\n",
      "\n",
      "Train Epoch: 2557 [4000/8000 (50%)]\tBatch Loss: 320.166685\tLearning Rate (w_theta): 0.001000\t TIME:6262.3s\n",
      "\t\t\t\tDisc: 0.538679\t\tSym: 9.399429\t\tSpars: 310.228577\n",
      "\t TVw: 0.280790 | TVb: -2.021841 | GSw: -0.235005 | GSb: 0.064896 | TSUw: 0.464819 | TSUb: 0.034909\n",
      "Validating epoch 2557...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 314.09295748530326\n",
      "Average validation loss: 69.67174461323975\n",
      "Training epoch 2558...\n",
      "\n",
      "Train Epoch: 2558 [0/8000 (0%)]\tBatch Loss: 306.741407\tLearning Rate (w_theta): 0.001000\t TIME:6264.8s\n",
      "\t\t\t\tDisc: 0.466322\t\tSym: 9.562408\t\tSpars: 296.712677\n",
      "\t TVw: 0.280616 | TVb: -2.021798 | GSw: -0.235005 | GSb: 0.064896 | TSUw: 0.464819 | TSUb: 0.034909\n",
      "\n",
      "Train Epoch: 2558 [4000/8000 (50%)]\tBatch Loss: 309.413199\tLearning Rate (w_theta): 0.001000\t TIME:6266.4s\n",
      "\t\t\t\tDisc: 0.487691\t\tSym: 9.618624\t\tSpars: 299.306885\n",
      "\t TVw: 0.280579 | TVb: -2.021748 | GSw: -0.235005 | GSb: 0.064896 | TSUw: 0.464818 | TSUb: 0.034909\n",
      "Validating epoch 2558...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 305.91588925461815\n",
      "Average validation loss: 67.21423938288774\n",
      "Training epoch 2559...\n",
      "\n",
      "Train Epoch: 2559 [0/8000 (0%)]\tBatch Loss: 309.404471\tLearning Rate (w_theta): 0.001000\t TIME:6268.8s\n",
      "\t\t\t\tDisc: 0.460311\t\tSym: 9.848853\t\tSpars: 299.095306\n",
      "\t TVw: 0.280522 | TVb: -2.021688 | GSw: -0.235005 | GSb: 0.064895 | TSUw: 0.464818 | TSUb: 0.034910\n",
      "\n",
      "Train Epoch: 2559 [4000/8000 (50%)]\tBatch Loss: 308.018495\tLearning Rate (w_theta): 0.001000\t TIME:6270.4s\n",
      "\t\t\t\tDisc: 0.458706\t\tSym: 9.618596\t\tSpars: 297.941193\n",
      "\t TVw: 0.280217 | TVb: -2.021659 | GSw: -0.235005 | GSb: 0.064895 | TSUw: 0.464818 | TSUb: 0.034910\n",
      "Validating epoch 2559...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 310.0781909901863\n",
      "Average validation loss: 72.09720499564149\n",
      "Training epoch 2560...\n",
      "\n",
      "Train Epoch: 2560 [0/8000 (0%)]\tBatch Loss: 318.666783\tLearning Rate (w_theta): 0.001000\t TIME:6273.3s\n",
      "\t\t\t\tDisc: 0.567975\t\tSym: 9.769615\t\tSpars: 308.329193\n",
      "\t TVw: 0.279945 | TVb: -2.021640 | GSw: -0.235005 | GSb: 0.064895 | TSUw: 0.464818 | TSUb: 0.034910\n",
      "\n",
      "Train Epoch: 2560 [4000/8000 (50%)]\tBatch Loss: 305.588527\tLearning Rate (w_theta): 0.001000\t TIME:6274.9s\n",
      "\t\t\t\tDisc: 0.526189\t\tSym: 9.324943\t\tSpars: 295.737396\n",
      "\t TVw: 0.280062 | TVb: -2.021621 | GSw: -0.235005 | GSb: 0.064895 | TSUw: 0.464817 | TSUb: 0.034910\n",
      "Validating epoch 2560...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 311.8886355691717\n",
      "Average validation loss: 69.53293128867858\n",
      "Training epoch 2561...\n",
      "\n",
      "Train Epoch: 2561 [0/8000 (0%)]\tBatch Loss: 308.659130\tLearning Rate (w_theta): 0.001000\t TIME:6278.0s\n",
      "\t\t\t\tDisc: 0.487442\t\tSym: 10.139645\t\tSpars: 298.032043\n",
      "\t TVw: 0.280291 | TVb: -2.021588 | GSw: -0.235005 | GSb: 0.064894 | TSUw: 0.464817 | TSUb: 0.034910\n",
      "\n",
      "Train Epoch: 2561 [4000/8000 (50%)]\tBatch Loss: 294.338623\tLearning Rate (w_theta): 0.001000\t TIME:6279.6s\n",
      "\t\t\t\tDisc: 0.454500\t\tSym: 9.004850\t\tSpars: 284.879272\n",
      "\t TVw: 0.280428 | TVb: -2.021547 | GSw: -0.235005 | GSb: 0.064894 | TSUw: 0.464817 | TSUb: 0.034910\n",
      "Validating epoch 2561...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 306.6563833503272\n",
      "Average validation loss: 66.5015266125307\n",
      "Training epoch 2562...\n",
      "\n",
      "Train Epoch: 2562 [0/8000 (0%)]\tBatch Loss: 315.783224\tLearning Rate (w_theta): 0.001000\t TIME:6282.1s\n",
      "\t\t\t\tDisc: 0.472544\t\tSym: 10.382580\t\tSpars: 304.928101\n",
      "\t TVw: 0.280822 | TVb: -2.021477 | GSw: -0.235006 | GSb: 0.064894 | TSUw: 0.464817 | TSUb: 0.034911\n",
      "\n",
      "Train Epoch: 2562 [4000/8000 (50%)]\tBatch Loss: 295.194092\tLearning Rate (w_theta): 0.001000\t TIME:6283.6s\n",
      "\t\t\t\tDisc: 0.465918\t\tSym: 8.949305\t\tSpars: 285.778870\n",
      "\t TVw: 0.280752 | TVb: -2.021428 | GSw: -0.235006 | GSb: 0.064894 | TSUw: 0.464816 | TSUb: 0.034911\n",
      "Validating epoch 2562...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 308.8155088924577\n",
      "Average validation loss: 70.83498284551503\n",
      "Training epoch 2563...\n",
      "\n",
      "Train Epoch: 2563 [0/8000 (0%)]\tBatch Loss: 309.785654\tLearning Rate (w_theta): 0.001000\t TIME:6286.1s\n",
      "\t\t\t\tDisc: 0.508266\t\tSym: 9.792647\t\tSpars: 299.484741\n",
      "\t TVw: 0.280707 | TVb: -2.021386 | GSw: -0.235006 | GSb: 0.064894 | TSUw: 0.464816 | TSUb: 0.034911\n",
      "\n",
      "Train Epoch: 2563 [4000/8000 (50%)]\tBatch Loss: 290.331634\tLearning Rate (w_theta): 0.001000\t TIME:6287.6s\n",
      "\t\t\t\tDisc: 0.476239\t\tSym: 8.864428\t\tSpars: 280.990967\n",
      "\t TVw: 0.280186 | TVb: -2.021374 | GSw: -0.235006 | GSb: 0.064893 | TSUw: 0.464816 | TSUb: 0.034911\n",
      "Validating epoch 2563...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 303.557260198041\n",
      "Average validation loss: 68.20063422127609\n",
      "Training epoch 2564...\n",
      "\n",
      "Train Epoch: 2564 [0/8000 (0%)]\tBatch Loss: 309.256007\tLearning Rate (w_theta): 0.001000\t TIME:6290.2s\n",
      "\t\t\t\tDisc: 0.491211\t\tSym: 10.274348\t\tSpars: 298.490448\n",
      "\t TVw: 0.280303 | TVb: -2.021312 | GSw: -0.235006 | GSb: 0.064893 | TSUw: 0.464816 | TSUb: 0.034911\n",
      "\n",
      "Train Epoch: 2564 [4000/8000 (50%)]\tBatch Loss: 298.044793\tLearning Rate (w_theta): 0.001000\t TIME:6291.8s\n",
      "\t\t\t\tDisc: 0.473811\t\tSym: 9.613127\t\tSpars: 287.957855\n",
      "\t TVw: 0.280242 | TVb: -2.021246 | GSw: -0.235006 | GSb: 0.064893 | TSUw: 0.464815 | TSUb: 0.034912\n",
      "Validating epoch 2564...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 300.23478324588035\n",
      "Average validation loss: 68.85579332714651\n",
      "Training epoch 2565...\n",
      "\n",
      "Train Epoch: 2565 [0/8000 (0%)]\tBatch Loss: 298.753027\tLearning Rate (w_theta): 0.001000\t TIME:6294.2s\n",
      "\t\t\t\tDisc: 0.489520\t\tSym: 10.001606\t\tSpars: 288.261902\n",
      "\t TVw: 0.280398 | TVb: -2.021162 | GSw: -0.235006 | GSb: 0.064893 | TSUw: 0.464815 | TSUb: 0.034912\n",
      "\n",
      "Train Epoch: 2565 [4000/8000 (50%)]\tBatch Loss: 309.112849\tLearning Rate (w_theta): 0.001000\t TIME:6295.8s\n",
      "\t\t\t\tDisc: 0.487887\t\tSym: 10.253105\t\tSpars: 298.371857\n",
      "\t TVw: 0.280233 | TVb: -2.021103 | GSw: -0.235006 | GSb: 0.064892 | TSUw: 0.464815 | TSUb: 0.034912\n",
      "Validating epoch 2565...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 299.3838943072145\n",
      "Average validation loss: 66.31305474490468\n",
      "Training epoch 2566...\n",
      "\n",
      "Train Epoch: 2566 [0/8000 (0%)]\tBatch Loss: 323.451934\tLearning Rate (w_theta): 0.001000\t TIME:6298.3s\n",
      "\t\t\t\tDisc: 0.498932\t\tSym: 10.590575\t\tSpars: 312.362427\n",
      "\t TVw: 0.280358 | TVb: -2.021025 | GSw: -0.235006 | GSb: 0.064892 | TSUw: 0.464815 | TSUb: 0.034912\n",
      "\n",
      "Train Epoch: 2566 [4000/8000 (50%)]\tBatch Loss: 303.033018\tLearning Rate (w_theta): 0.001000\t TIME:6299.8s\n",
      "\t\t\t\tDisc: 0.517955\t\tSym: 9.490587\t\tSpars: 293.024475\n",
      "\t TVw: 0.279797 | TVb: -2.021019 | GSw: -0.235006 | GSb: 0.064892 | TSUw: 0.464814 | TSUb: 0.034912\n",
      "Validating epoch 2566...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 310.7807888804813\n",
      "Average validation loss: 70.30544504959377\n",
      "Training epoch 2567...\n",
      "\n",
      "Train Epoch: 2567 [0/8000 (0%)]\tBatch Loss: 313.608508\tLearning Rate (w_theta): 0.001000\t TIME:6302.3s\n",
      "\t\t\t\tDisc: 0.531848\t\tSym: 10.340485\t\tSpars: 302.736176\n",
      "\t TVw: 0.279092 | TVb: -2.021046 | GSw: -0.235006 | GSb: 0.064892 | TSUw: 0.464814 | TSUb: 0.034913\n",
      "\n",
      "Train Epoch: 2567 [4000/8000 (50%)]\tBatch Loss: 297.349660\tLearning Rate (w_theta): 0.001000\t TIME:6303.9s\n",
      "\t\t\t\tDisc: 0.474279\t\tSym: 9.462813\t\tSpars: 287.412567\n",
      "\t TVw: 0.278961 | TVb: -2.021030 | GSw: -0.235006 | GSb: 0.064892 | TSUw: 0.464814 | TSUb: 0.034913\n",
      "Validating epoch 2567...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 302.95288610025335\n",
      "Average validation loss: 65.84300140477042\n",
      "Training epoch 2568...\n",
      "\n",
      "Train Epoch: 2568 [0/8000 (0%)]\tBatch Loss: 290.606088\tLearning Rate (w_theta): 0.001000\t TIME:6306.4s\n",
      "\t\t\t\tDisc: 0.468981\t\tSym: 8.811179\t\tSpars: 281.325928\n",
      "\t TVw: 0.279289 | TVb: -2.020988 | GSw: -0.235006 | GSb: 0.064891 | TSUw: 0.464814 | TSUb: 0.034913\n",
      "\n",
      "Train Epoch: 2568 [4000/8000 (50%)]\tBatch Loss: 301.937125\tLearning Rate (w_theta): 0.001000\t TIME:6308.0s\n",
      "\t\t\t\tDisc: 0.470935\t\tSym: 10.147831\t\tSpars: 291.318359\n",
      "\t TVw: 0.279575 | TVb: -2.020924 | GSw: -0.235006 | GSb: 0.064891 | TSUw: 0.464814 | TSUb: 0.034913\n",
      "Validating epoch 2568...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 297.9910281709964\n",
      "Average validation loss: 67.04394684534525\n",
      "Training epoch 2569...\n",
      "\n",
      "Train Epoch: 2569 [0/8000 (0%)]\tBatch Loss: 307.457387\tLearning Rate (w_theta): 0.001000\t TIME:6310.4s\n",
      "\t\t\t\tDisc: 0.489974\t\tSym: 10.624945\t\tSpars: 296.342468\n",
      "\t TVw: 0.280101 | TVb: -2.020830 | GSw: -0.235006 | GSb: 0.064891 | TSUw: 0.464813 | TSUb: 0.034913\n",
      "\n",
      "Train Epoch: 2569 [4000/8000 (50%)]\tBatch Loss: 300.871754\tLearning Rate (w_theta): 0.001000\t TIME:6312.0s\n",
      "\t\t\t\tDisc: 0.527196\t\tSym: 9.868423\t\tSpars: 290.476135\n",
      "\t TVw: 0.280286 | TVb: -2.020752 | GSw: -0.235006 | GSb: 0.064891 | TSUw: 0.464813 | TSUb: 0.034914\n",
      "Validating epoch 2569...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 300.4897572867012\n",
      "Average validation loss: 70.49872961299914\n",
      "Training epoch 2570...\n",
      "\n",
      "Train Epoch: 2570 [0/8000 (0%)]\tBatch Loss: 295.872049\tLearning Rate (w_theta): 0.001000\t TIME:6314.4s\n",
      "\t\t\t\tDisc: 0.534015\t\tSym: 9.618949\t\tSpars: 285.719086\n",
      "\t TVw: 0.280027 | TVb: -2.020714 | GSw: -0.235006 | GSb: 0.064890 | TSUw: 0.464813 | TSUb: 0.034914\n",
      "\n",
      "Train Epoch: 2570 [4000/8000 (50%)]\tBatch Loss: 309.668971\tLearning Rate (w_theta): 0.001000\t TIME:6316.0s\n",
      "\t\t\t\tDisc: 0.490258\t\tSym: 10.304140\t\tSpars: 298.874573\n",
      "\t TVw: 0.279289 | TVb: -2.020711 | GSw: -0.235007 | GSb: 0.064890 | TSUw: 0.464813 | TSUb: 0.034914\n",
      "Validating epoch 2570...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 302.9074781763832\n",
      "Average validation loss: 64.04727262939699\n",
      "Training epoch 2571...\n",
      "\n",
      "Train Epoch: 2571 [0/8000 (0%)]\tBatch Loss: 303.153003\tLearning Rate (w_theta): 0.001000\t TIME:6319.1s\n",
      "\t\t\t\tDisc: 0.458521\t\tSym: 9.210871\t\tSpars: 293.483612\n",
      "\t TVw: 0.278735 | TVb: -2.020705 | GSw: -0.235007 | GSb: 0.064890 | TSUw: 0.464812 | TSUb: 0.034914\n",
      "\n",
      "Train Epoch: 2571 [4000/8000 (50%)]\tBatch Loss: 300.430846\tLearning Rate (w_theta): 0.001000\t TIME:6320.7s\n",
      "\t\t\t\tDisc: 0.466867\t\tSym: 9.690175\t\tSpars: 290.273804\n",
      "\t TVw: 0.278890 | TVb: -2.020660 | GSw: -0.235007 | GSb: 0.064890 | TSUw: 0.464812 | TSUb: 0.034914\n",
      "Validating epoch 2571...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 301.03110213293235\n",
      "Average validation loss: 68.99939777769832\n",
      "Training epoch 2572...\n",
      "\n",
      "Train Epoch: 2572 [0/8000 (0%)]\tBatch Loss: 302.528089\tLearning Rate (w_theta): 0.001000\t TIME:6323.6s\n",
      "\t\t\t\tDisc: 0.563677\t\tSym: 9.200496\t\tSpars: 292.763916\n",
      "\t TVw: 0.279022 | TVb: -2.020612 | GSw: -0.235007 | GSb: 0.064889 | TSUw: 0.464812 | TSUb: 0.034914\n",
      "\n",
      "Train Epoch: 2572 [4000/8000 (50%)]\tBatch Loss: 307.638214\tLearning Rate (w_theta): 0.001000\t TIME:6325.1s\n",
      "\t\t\t\tDisc: 0.561553\t\tSym: 9.554261\t\tSpars: 297.522400\n",
      "\t TVw: 0.279054 | TVb: -2.020590 | GSw: -0.235007 | GSb: 0.064889 | TSUw: 0.464812 | TSUb: 0.034915\n",
      "Validating epoch 2572...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 307.5083770149854\n",
      "Average validation loss: 66.34218944865638\n",
      "Training epoch 2573...\n",
      "\n",
      "Train Epoch: 2573 [0/8000 (0%)]\tBatch Loss: 306.095106\tLearning Rate (w_theta): 0.001000\t TIME:6327.6s\n",
      "\t\t\t\tDisc: 0.473181\t\tSym: 10.450904\t\tSpars: 295.171021\n",
      "\t TVw: 0.278569 | TVb: -2.020607 | GSw: -0.235007 | GSb: 0.064889 | TSUw: 0.464811 | TSUb: 0.034915\n",
      "\n",
      "Train Epoch: 2573 [4000/8000 (50%)]\tBatch Loss: 299.707452\tLearning Rate (w_theta): 0.001000\t TIME:6329.2s\n",
      "\t\t\t\tDisc: 0.475183\t\tSym: 10.095183\t\tSpars: 289.137085\n",
      "\t TVw: 0.279155 | TVb: -2.020552 | GSw: -0.235007 | GSb: 0.064889 | TSUw: 0.464811 | TSUb: 0.034915\n",
      "Validating epoch 2573...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 300.58682120847214\n",
      "Average validation loss: 64.59726436480923\n",
      "Training epoch 2574...\n",
      "\n",
      "Train Epoch: 2574 [0/8000 (0%)]\tBatch Loss: 300.933595\tLearning Rate (w_theta): 0.001000\t TIME:6331.6s\n",
      "\t\t\t\tDisc: 0.467448\t\tSym: 10.183311\t\tSpars: 290.282837\n",
      "\t TVw: 0.279388 | TVb: -2.020505 | GSw: -0.235007 | GSb: 0.064889 | TSUw: 0.464811 | TSUb: 0.034915\n",
      "\n",
      "Train Epoch: 2574 [4000/8000 (50%)]\tBatch Loss: 306.777537\tLearning Rate (w_theta): 0.001000\t TIME:6333.2s\n",
      "\t\t\t\tDisc: 0.488920\t\tSym: 10.131360\t\tSpars: 296.157257\n",
      "\t TVw: 0.280426 | TVb: -2.020402 | GSw: -0.235007 | GSb: 0.064888 | TSUw: 0.464811 | TSUb: 0.034916\n",
      "Validating epoch 2574...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 298.9201989500563\n",
      "Average validation loss: 63.935807984972364\n",
      "Training epoch 2575...\n",
      "\n",
      "Train Epoch: 2575 [0/8000 (0%)]\tBatch Loss: 308.463261\tLearning Rate (w_theta): 0.001000\t TIME:6335.7s\n",
      "\t\t\t\tDisc: 0.489058\t\tSym: 10.886769\t\tSpars: 297.087433\n",
      "\t TVw: 0.280493 | TVb: -2.020353 | GSw: -0.235007 | GSb: 0.064888 | TSUw: 0.464810 | TSUb: 0.034916\n",
      "\n",
      "Train Epoch: 2575 [4000/8000 (50%)]\tBatch Loss: 277.078665\tLearning Rate (w_theta): 0.001000\t TIME:6337.2s\n",
      "\t\t\t\tDisc: 0.479983\t\tSym: 8.607409\t\tSpars: 267.991272\n",
      "\t TVw: 0.280979 | TVb: -2.020292 | GSw: -0.235007 | GSb: 0.064888 | TSUw: 0.464810 | TSUb: 0.034916\n",
      "Validating epoch 2575...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 298.30424974815907\n",
      "Average validation loss: 68.12283185689628\n",
      "Training epoch 2576...\n",
      "\n",
      "Train Epoch: 2576 [0/8000 (0%)]\tBatch Loss: 270.082196\tLearning Rate (w_theta): 0.001000\t TIME:6339.7s\n",
      "\t\t\t\tDisc: 0.522778\t\tSym: 7.911224\t\tSpars: 261.648193\n",
      "\t TVw: 0.280964 | TVb: -2.020254 | GSw: -0.235007 | GSb: 0.064888 | TSUw: 0.464810 | TSUb: 0.034916\n",
      "\n",
      "Train Epoch: 2576 [4000/8000 (50%)]\tBatch Loss: 300.024778\tLearning Rate (w_theta): 0.001000\t TIME:6341.3s\n",
      "\t\t\t\tDisc: 0.519403\t\tSym: 9.914768\t\tSpars: 289.590607\n",
      "\t TVw: 0.280760 | TVb: -2.020235 | GSw: -0.235007 | GSb: 0.064887 | TSUw: 0.464810 | TSUb: 0.034916\n",
      "Validating epoch 2576...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 297.0343024113716\n",
      "Average validation loss: 66.75523018809979\n",
      "Training epoch 2577...\n",
      "\n",
      "Train Epoch: 2577 [0/8000 (0%)]\tBatch Loss: 292.914399\tLearning Rate (w_theta): 0.001000\t TIME:6343.7s\n",
      "\t\t\t\tDisc: 0.506520\t\tSym: 9.407482\t\tSpars: 283.000397\n",
      "\t TVw: 0.280695 | TVb: -2.020184 | GSw: -0.235007 | GSb: 0.064887 | TSUw: 0.464809 | TSUb: 0.034917\n",
      "\n",
      "Train Epoch: 2577 [4000/8000 (50%)]\tBatch Loss: 294.147681\tLearning Rate (w_theta): 0.001000\t TIME:6345.3s\n",
      "\t\t\t\tDisc: 0.479260\t\tSym: 10.054560\t\tSpars: 283.613861\n",
      "\t TVw: 0.280559 | TVb: -2.020130 | GSw: -0.235007 | GSb: 0.064887 | TSUw: 0.464809 | TSUb: 0.034917\n",
      "Validating epoch 2577...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 293.6966477309557\n",
      "Average validation loss: 64.51757495223202\n",
      "Training epoch 2578...\n",
      "\n",
      "Train Epoch: 2578 [0/8000 (0%)]\tBatch Loss: 291.009681\tLearning Rate (w_theta): 0.001000\t TIME:6347.8s\n",
      "\t\t\t\tDisc: 0.492279\t\tSym: 9.358253\t\tSpars: 281.159149\n",
      "\t TVw: 0.280693 | TVb: -2.020049 | GSw: -0.235008 | GSb: 0.064887 | TSUw: 0.464809 | TSUb: 0.034917\n",
      "\n",
      "Train Epoch: 2578 [4000/8000 (50%)]\tBatch Loss: 284.509405\tLearning Rate (w_theta): 0.001000\t TIME:6349.4s\n",
      "\t\t\t\tDisc: 0.508387\t\tSym: 9.132091\t\tSpars: 274.868927\n",
      "\t TVw: 0.280686 | TVb: -2.019976 | GSw: -0.235008 | GSb: 0.064886 | TSUw: 0.464809 | TSUb: 0.034917\n",
      "Validating epoch 2578...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 291.28279078771305\n",
      "Average validation loss: 66.99868075340864\n",
      "Training epoch 2579...\n",
      "\n",
      "Train Epoch: 2579 [0/8000 (0%)]\tBatch Loss: 283.521805\tLearning Rate (w_theta): 0.001000\t TIME:6351.8s\n",
      "\t\t\t\tDisc: 0.542115\t\tSym: 9.114669\t\tSpars: 273.865021\n",
      "\t TVw: 0.280835 | TVb: -2.019888 | GSw: -0.235008 | GSb: 0.064886 | TSUw: 0.464808 | TSUb: 0.034917\n",
      "\n",
      "Train Epoch: 2579 [4000/8000 (50%)]\tBatch Loss: 299.984008\tLearning Rate (w_theta): 0.001000\t TIME:6353.4s\n",
      "\t\t\t\tDisc: 0.503961\t\tSym: 10.194890\t\tSpars: 289.285156\n",
      "\t TVw: 0.280320 | TVb: -2.019826 | GSw: -0.235008 | GSb: 0.064886 | TSUw: 0.464808 | TSUb: 0.034917\n",
      "Validating epoch 2579...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 289.30659295688656\n",
      "Average validation loss: 65.37685480184007\n",
      "Training epoch 2580...\n",
      "\n",
      "Train Epoch: 2580 [0/8000 (0%)]\tBatch Loss: 280.739238\tLearning Rate (w_theta): 0.001000\t TIME:6355.9s\n",
      "\t\t\t\tDisc: 0.501747\t\tSym: 9.288181\t\tSpars: 270.949310\n",
      "\t TVw: 0.280025 | TVb: -2.019758 | GSw: -0.235008 | GSb: 0.064886 | TSUw: 0.464808 | TSUb: 0.034918\n",
      "\n",
      "Train Epoch: 2580 [4000/8000 (50%)]\tBatch Loss: 285.462551\tLearning Rate (w_theta): 0.001000\t TIME:6357.4s\n",
      "\t\t\t\tDisc: 0.484773\t\tSym: 9.158748\t\tSpars: 275.819031\n",
      "\t TVw: 0.279592 | TVb: -2.019704 | GSw: -0.235008 | GSb: 0.064885 | TSUw: 0.464808 | TSUb: 0.034918\n",
      "Validating epoch 2580...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 288.8573470432357\n",
      "Average validation loss: 69.2413323889951\n",
      "Training epoch 2581...\n",
      "\n",
      "Train Epoch: 2581 [0/8000 (0%)]\tBatch Loss: 305.015016\tLearning Rate (w_theta): 0.001000\t TIME:6360.6s\n",
      "\t\t\t\tDisc: 0.575230\t\tSym: 9.775998\t\tSpars: 294.663788\n",
      "\t TVw: 0.279168 | TVb: -2.019668 | GSw: -0.235008 | GSb: 0.064885 | TSUw: 0.464808 | TSUb: 0.034918\n",
      "\n",
      "Train Epoch: 2581 [4000/8000 (50%)]\tBatch Loss: 288.437211\tLearning Rate (w_theta): 0.001000\t TIME:6362.1s\n",
      "\t\t\t\tDisc: 0.524499\t\tSym: 9.589531\t\tSpars: 278.323181\n",
      "\t TVw: 0.278501 | TVb: -2.019663 | GSw: -0.235008 | GSb: 0.064885 | TSUw: 0.464807 | TSUb: 0.034918\n",
      "Validating epoch 2581...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 296.13417494660337\n",
      "Average validation loss: 64.7899085798449\n",
      "Training epoch 2582...\n",
      "\n",
      "Train Epoch: 2582 [0/8000 (0%)]\tBatch Loss: 288.298090\tLearning Rate (w_theta): 0.001000\t TIME:6364.6s\n",
      "\t\t\t\tDisc: 0.477330\t\tSym: 9.789845\t\tSpars: 278.030914\n",
      "\t TVw: 0.277910 | TVb: -2.019652 | GSw: -0.235008 | GSb: 0.064885 | TSUw: 0.464807 | TSUb: 0.034918\n",
      "\n",
      "Train Epoch: 2582 [4000/8000 (50%)]\tBatch Loss: 298.927766\tLearning Rate (w_theta): 0.001000\t TIME:6366.2s\n",
      "\t\t\t\tDisc: 0.499380\t\tSym: 9.937358\t\tSpars: 288.491028\n",
      "\t TVw: 0.277689 | TVb: -2.019621 | GSw: -0.235008 | GSb: 0.064884 | TSUw: 0.464807 | TSUb: 0.034919\n",
      "Validating epoch 2582...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 292.1009255673718\n",
      "Average validation loss: 62.445718371537005\n",
      "Training epoch 2583...\n",
      "\n",
      "Train Epoch: 2583 [0/8000 (0%)]\tBatch Loss: 286.841858\tLearning Rate (w_theta): 0.001000\t TIME:6368.7s\n",
      "\t\t\t\tDisc: 0.476129\t\tSym: 9.119056\t\tSpars: 277.246674\n",
      "\t TVw: 0.277662 | TVb: -2.019581 | GSw: -0.235008 | GSb: 0.064884 | TSUw: 0.464807 | TSUb: 0.034919\n",
      "\n",
      "Train Epoch: 2583 [4000/8000 (50%)]\tBatch Loss: 297.226547\tLearning Rate (w_theta): 0.001000\t TIME:6370.3s\n",
      "\t\t\t\tDisc: 0.489108\t\tSym: 10.613538\t\tSpars: 286.123901\n",
      "\t TVw: 0.277690 | TVb: -2.019548 | GSw: -0.235008 | GSb: 0.064884 | TSUw: 0.464806 | TSUb: 0.034919\n",
      "Validating epoch 2583...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 292.55407588106203\n",
      "Average validation loss: 66.21838890434779\n",
      "Training epoch 2584...\n",
      "\n",
      "Train Epoch: 2584 [0/8000 (0%)]\tBatch Loss: 292.563081\tLearning Rate (w_theta): 0.001000\t TIME:6372.7s\n",
      "\t\t\t\tDisc: 0.540066\t\tSym: 9.513371\t\tSpars: 282.509644\n",
      "\t TVw: 0.277620 | TVb: -2.019515 | GSw: -0.235008 | GSb: 0.064884 | TSUw: 0.464806 | TSUb: 0.034919\n",
      "\n",
      "Train Epoch: 2584 [4000/8000 (50%)]\tBatch Loss: 291.605260\tLearning Rate (w_theta): 0.001000\t TIME:6374.3s\n",
      "\t\t\t\tDisc: 0.513198\t\tSym: 9.893606\t\tSpars: 281.198456\n",
      "\t TVw: 0.277757 | TVb: -2.019474 | GSw: -0.235008 | GSb: 0.064884 | TSUw: 0.464806 | TSUb: 0.034919\n",
      "Validating epoch 2584...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 289.8427940420774\n",
      "Average validation loss: 64.4179630219109\n",
      "Training epoch 2585...\n",
      "\n",
      "Train Epoch: 2585 [0/8000 (0%)]\tBatch Loss: 285.695798\tLearning Rate (w_theta): 0.001000\t TIME:6377.2s\n",
      "\t\t\t\tDisc: 0.494575\t\tSym: 9.132924\t\tSpars: 276.068298\n",
      "\t TVw: 0.277860 | TVb: -2.019424 | GSw: -0.235008 | GSb: 0.064883 | TSUw: 0.464806 | TSUb: 0.034920\n",
      "\n",
      "Train Epoch: 2585 [4000/8000 (50%)]\tBatch Loss: 288.993048\tLearning Rate (w_theta): 0.001000\t TIME:6378.8s\n",
      "\t\t\t\tDisc: 0.509073\t\tSym: 9.887204\t\tSpars: 278.596771\n",
      "\t TVw: 0.278209 | TVb: -2.019353 | GSw: -0.235008 | GSb: 0.064883 | TSUw: 0.464805 | TSUb: 0.034920\n",
      "Validating epoch 2585...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 286.89021723502555\n",
      "Average validation loss: 62.35895540598371\n",
      "Training epoch 2586...\n",
      "\n",
      "Train Epoch: 2586 [0/8000 (0%)]\tBatch Loss: 273.571041\tLearning Rate (w_theta): 0.001000\t TIME:6381.2s\n",
      "\t\t\t\tDisc: 0.471845\t\tSym: 8.715499\t\tSpars: 264.383698\n",
      "\t TVw: 0.278425 | TVb: -2.019275 | GSw: -0.235008 | GSb: 0.064883 | TSUw: 0.464805 | TSUb: 0.034920\n",
      "\n",
      "Train Epoch: 2586 [4000/8000 (50%)]\tBatch Loss: 274.409511\tLearning Rate (w_theta): 0.001000\t TIME:6382.8s\n",
      "\t\t\t\tDisc: 0.492617\t\tSym: 8.345788\t\tSpars: 265.571106\n",
      "\t TVw: 0.278522 | TVb: -2.019208 | GSw: -0.235009 | GSb: 0.064883 | TSUw: 0.464805 | TSUb: 0.034920\n",
      "Validating epoch 2586...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 285.4189615567532\n",
      "Average validation loss: 64.02909173376726\n",
      "Training epoch 2587...\n",
      "\n",
      "Train Epoch: 2587 [0/8000 (0%)]\tBatch Loss: 289.494940\tLearning Rate (w_theta): 0.001000\t TIME:6385.3s\n",
      "\t\t\t\tDisc: 0.490042\t\tSym: 9.687027\t\tSpars: 279.317871\n",
      "\t TVw: 0.278428 | TVb: -2.019154 | GSw: -0.235009 | GSb: 0.064882 | TSUw: 0.464805 | TSUb: 0.034920\n",
      "\n",
      "Train Epoch: 2587 [4000/8000 (50%)]\tBatch Loss: 302.771424\tLearning Rate (w_theta): 0.001000\t TIME:6386.8s\n",
      "\t\t\t\tDisc: 0.562052\t\tSym: 9.713981\t\tSpars: 292.495392\n",
      "\t TVw: 0.278468 | TVb: -2.019089 | GSw: -0.235009 | GSb: 0.064882 | TSUw: 0.464804 | TSUb: 0.034921\n",
      "Validating epoch 2587...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 291.70461870551804\n",
      "Average validation loss: 63.23841101938456\n",
      "Training epoch 2588...\n",
      "\n",
      "Train Epoch: 2588 [0/8000 (0%)]\tBatch Loss: 281.808760\tLearning Rate (w_theta): 0.001000\t TIME:6389.3s\n",
      "\t\t\t\tDisc: 0.483424\t\tSym: 9.753895\t\tSpars: 271.571442\n",
      "\t TVw: 0.277849 | TVb: -2.019085 | GSw: -0.235009 | GSb: 0.064882 | TSUw: 0.464804 | TSUb: 0.034921\n",
      "\n",
      "Train Epoch: 2588 [4000/8000 (50%)]\tBatch Loss: 287.692267\tLearning Rate (w_theta): 0.001000\t TIME:6390.9s\n",
      "\t\t\t\tDisc: 0.517048\t\tSym: 9.579028\t\tSpars: 277.596191\n",
      "\t TVw: 0.277657 | TVb: -2.019064 | GSw: -0.235009 | GSb: 0.064882 | TSUw: 0.464804 | TSUb: 0.034921\n",
      "Validating epoch 2588...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 289.0458694667135\n",
      "Average validation loss: 65.86302809108997\n",
      "Training epoch 2589...\n",
      "\n",
      "Train Epoch: 2589 [0/8000 (0%)]\tBatch Loss: 279.864569\tLearning Rate (w_theta): 0.001000\t TIME:6393.4s\n",
      "\t\t\t\tDisc: 0.508562\t\tSym: 9.438282\t\tSpars: 269.917725\n",
      "\t TVw: 0.277707 | TVb: -2.019029 | GSw: -0.235009 | GSb: 0.064881 | TSUw: 0.464804 | TSUb: 0.034921\n",
      "\n",
      "Train Epoch: 2589 [4000/8000 (50%)]\tBatch Loss: 289.979711\tLearning Rate (w_theta): 0.001000\t TIME:6394.9s\n",
      "\t\t\t\tDisc: 0.568229\t\tSym: 9.673781\t\tSpars: 279.737701\n",
      "\t TVw: 0.277673 | TVb: -2.018991 | GSw: -0.235009 | GSb: 0.064881 | TSUw: 0.464803 | TSUb: 0.034922\n",
      "Validating epoch 2589...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 285.32573098699066\n",
      "Average validation loss: 64.05302451909355\n",
      "Training epoch 2590...\n",
      "\n",
      "Train Epoch: 2590 [0/8000 (0%)]\tBatch Loss: 281.295828\tLearning Rate (w_theta): 0.001000\t TIME:6397.4s\n",
      "\t\t\t\tDisc: 0.493906\t\tSym: 9.478864\t\tSpars: 271.323059\n",
      "\t TVw: 0.278023 | TVb: -2.018930 | GSw: -0.235009 | GSb: 0.064881 | TSUw: 0.464803 | TSUb: 0.034922\n",
      "\n",
      "Train Epoch: 2590 [4000/8000 (50%)]\tBatch Loss: 283.009607\tLearning Rate (w_theta): 0.001000\t TIME:6399.0s\n",
      "\t\t\t\tDisc: 0.481372\t\tSym: 9.022497\t\tSpars: 273.505737\n",
      "\t TVw: 0.278071 | TVb: -2.018857 | GSw: -0.235009 | GSb: 0.064881 | TSUw: 0.464803 | TSUb: 0.034922\n",
      "Validating epoch 2590...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 281.53282092360837\n",
      "Average validation loss: 64.7501832425157\n",
      "Training epoch 2591...\n",
      "\n",
      "Train Epoch: 2591 [0/8000 (0%)]\tBatch Loss: 282.740402\tLearning Rate (w_theta): 0.001000\t TIME:6402.2s\n",
      "\t\t\t\tDisc: 0.515823\t\tSym: 10.063049\t\tSpars: 272.161530\n",
      "\t TVw: 0.278427 | TVb: -2.018762 | GSw: -0.235009 | GSb: 0.064880 | TSUw: 0.464803 | TSUb: 0.034922\n",
      "\n",
      "Train Epoch: 2591 [4000/8000 (50%)]\tBatch Loss: 269.416841\tLearning Rate (w_theta): 0.001000\t TIME:6403.8s\n",
      "\t\t\t\tDisc: 0.505470\t\tSym: 8.202936\t\tSpars: 260.708435\n",
      "\t TVw: 0.278435 | TVb: -2.018674 | GSw: -0.235009 | GSb: 0.064880 | TSUw: 0.464803 | TSUb: 0.034922\n",
      "Validating epoch 2591...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 280.13497005933465\n",
      "Average validation loss: 63.977888602905786\n",
      "Training epoch 2592...\n",
      "\n",
      "Train Epoch: 2592 [0/8000 (0%)]\tBatch Loss: 265.210604\tLearning Rate (w_theta): 0.001000\t TIME:6406.2s\n",
      "\t\t\t\tDisc: 0.531138\t\tSym: 8.824364\t\tSpars: 255.855103\n",
      "\t TVw: 0.278398 | TVb: -2.018596 | GSw: -0.235009 | GSb: 0.064880 | TSUw: 0.464802 | TSUb: 0.034922\n",
      "\n",
      "Train Epoch: 2592 [4000/8000 (50%)]\tBatch Loss: 275.193770\tLearning Rate (w_theta): 0.001000\t TIME:6407.8s\n",
      "\t\t\t\tDisc: 0.520941\t\tSym: 9.269692\t\tSpars: 265.403137\n",
      "\t TVw: 0.278155 | TVb: -2.018521 | GSw: -0.235009 | GSb: 0.064880 | TSUw: 0.464802 | TSUb: 0.034923\n",
      "Validating epoch 2592...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 278.4735947307089\n",
      "Average validation loss: 63.03864310000987\n",
      "Training epoch 2593...\n",
      "\n",
      "Train Epoch: 2593 [0/8000 (0%)]\tBatch Loss: 284.659669\tLearning Rate (w_theta): 0.001000\t TIME:6410.3s\n",
      "\t\t\t\tDisc: 0.500796\t\tSym: 10.343780\t\tSpars: 273.815094\n",
      "\t TVw: 0.277968 | TVb: -2.018450 | GSw: -0.235009 | GSb: 0.064879 | TSUw: 0.464802 | TSUb: 0.034923\n",
      "\n",
      "Train Epoch: 2593 [4000/8000 (50%)]\tBatch Loss: 283.149203\tLearning Rate (w_theta): 0.001000\t TIME:6411.8s\n",
      "\t\t\t\tDisc: 0.575549\t\tSym: 9.136002\t\tSpars: 273.437653\n",
      "\t TVw: 0.277556 | TVb: -2.018395 | GSw: -0.235009 | GSb: 0.064879 | TSUw: 0.464802 | TSUb: 0.034923\n",
      "Validating epoch 2593...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 282.89062711118686\n",
      "Average validation loss: 66.76414980751683\n",
      "Training epoch 2594...\n",
      "\n",
      "Train Epoch: 2594 [0/8000 (0%)]\tBatch Loss: 288.830183\tLearning Rate (w_theta): 0.001000\t TIME:6414.3s\n",
      "\t\t\t\tDisc: 0.605363\t\tSym: 9.648770\t\tSpars: 278.576050\n",
      "\t TVw: 0.276626 | TVb: -2.018396 | GSw: -0.235009 | GSb: 0.064879 | TSUw: 0.464801 | TSUb: 0.034923\n",
      "\n",
      "Train Epoch: 2594 [4000/8000 (50%)]\tBatch Loss: 282.762922\tLearning Rate (w_theta): 0.001000\t TIME:6415.9s\n",
      "\t\t\t\tDisc: 0.492687\t\tSym: 9.878267\t\tSpars: 272.391968\n",
      "\t TVw: 0.275470 | TVb: -2.018417 | GSw: -0.235010 | GSb: 0.064879 | TSUw: 0.464801 | TSUb: 0.034923\n",
      "Validating epoch 2594...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 280.5421982005493\n",
      "Average validation loss: 60.973323980782595\n",
      "Training epoch 2595...\n",
      "\n",
      "Train Epoch: 2595 [0/8000 (0%)]\tBatch Loss: 278.077303\tLearning Rate (w_theta): 0.001000\t TIME:6418.4s\n",
      "\t\t\t\tDisc: 0.493695\t\tSym: 9.264058\t\tSpars: 268.319550\n",
      "\t TVw: 0.275150 | TVb: -2.018372 | GSw: -0.235010 | GSb: 0.064879 | TSUw: 0.464801 | TSUb: 0.034924\n",
      "\n",
      "Train Epoch: 2595 [4000/8000 (50%)]\tBatch Loss: 279.535982\tLearning Rate (w_theta): 0.001000\t TIME:6420.0s\n",
      "\t\t\t\tDisc: 0.527743\t\tSym: 9.310760\t\tSpars: 269.697479\n",
      "\t TVw: 0.274821 | TVb: -2.018342 | GSw: -0.235010 | GSb: 0.064878 | TSUw: 0.464801 | TSUb: 0.034924\n",
      "Validating epoch 2595...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 281.22287244665324\n",
      "Average validation loss: 62.24322370349419\n",
      "Training epoch 2596...\n",
      "\n",
      "Train Epoch: 2596 [0/8000 (0%)]\tBatch Loss: 275.774397\tLearning Rate (w_theta): 0.001000\t TIME:6422.5s\n",
      "\t\t\t\tDisc: 0.487350\t\tSym: 9.864928\t\tSpars: 265.422119\n",
      "\t TVw: 0.274600 | TVb: -2.018310 | GSw: -0.235010 | GSb: 0.064878 | TSUw: 0.464800 | TSUb: 0.034924\n",
      "\n",
      "Train Epoch: 2596 [4000/8000 (50%)]\tBatch Loss: 282.640179\tLearning Rate (w_theta): 0.001000\t TIME:6424.1s\n",
      "\t\t\t\tDisc: 0.500640\t\tSym: 10.057263\t\tSpars: 272.082275\n",
      "\t TVw: 0.274545 | TVb: -2.018245 | GSw: -0.235010 | GSb: 0.064878 | TSUw: 0.464800 | TSUb: 0.034924\n",
      "Validating epoch 2596...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 276.6011249785985\n",
      "Average validation loss: 61.45941970647259\n",
      "Training epoch 2597...\n",
      "\n",
      "Train Epoch: 2597 [0/8000 (0%)]\tBatch Loss: 268.841584\tLearning Rate (w_theta): 0.001000\t TIME:6426.5s\n",
      "\t\t\t\tDisc: 0.510728\t\tSym: 9.119918\t\tSpars: 259.210938\n",
      "\t TVw: 0.274642 | TVb: -2.018161 | GSw: -0.235010 | GSb: 0.064878 | TSUw: 0.464800 | TSUb: 0.034924\n",
      "\n",
      "Train Epoch: 2597 [4000/8000 (50%)]\tBatch Loss: 272.697075\tLearning Rate (w_theta): 0.001000\t TIME:6428.1s\n",
      "\t\t\t\tDisc: 0.491428\t\tSym: 9.016193\t\tSpars: 263.189453\n",
      "\t TVw: 0.274777 | TVb: -2.018077 | GSw: -0.235010 | GSb: 0.064877 | TSUw: 0.464800 | TSUb: 0.034925\n",
      "Validating epoch 2597...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 275.2004173440086\n",
      "Average validation loss: 61.413227982826925\n",
      "Training epoch 2598...\n",
      "\n",
      "Train Epoch: 2598 [0/8000 (0%)]\tBatch Loss: 281.181884\tLearning Rate (w_theta): 0.001000\t TIME:6430.6s\n",
      "\t\t\t\tDisc: 0.505226\t\tSym: 9.891044\t\tSpars: 270.785614\n",
      "\t TVw: 0.274899 | TVb: -2.017978 | GSw: -0.235010 | GSb: 0.064877 | TSUw: 0.464799 | TSUb: 0.034925\n",
      "\n",
      "Train Epoch: 2598 [4000/8000 (50%)]\tBatch Loss: 306.984209\tLearning Rate (w_theta): 0.001000\t TIME:6432.1s\n",
      "\t\t\t\tDisc: 0.650103\t\tSym: 10.625092\t\tSpars: 295.709015\n",
      "\t TVw: 0.274721 | TVb: -2.017926 | GSw: -0.235010 | GSb: 0.064877 | TSUw: 0.464799 | TSUb: 0.034925\n",
      "Validating epoch 2598...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 283.1840946933404\n",
      "Average validation loss: 64.35583721462777\n",
      "Training epoch 2599...\n",
      "\n",
      "Train Epoch: 2599 [0/8000 (0%)]\tBatch Loss: 295.215537\tLearning Rate (w_theta): 0.001000\t TIME:6435.1s\n",
      "\t\t\t\tDisc: 0.563667\t\tSym: 10.273269\t\tSpars: 284.378601\n",
      "\t TVw: 0.274054 | TVb: -2.017940 | GSw: -0.235010 | GSb: 0.064877 | TSUw: 0.464799 | TSUb: 0.034925\n",
      "\n",
      "Train Epoch: 2599 [4000/8000 (50%)]\tBatch Loss: 282.134356\tLearning Rate (w_theta): 0.001000\t TIME:6436.7s\n",
      "\t\t\t\tDisc: 0.484387\t\tSym: 10.047064\t\tSpars: 271.602905\n",
      "\t TVw: 0.273406 | TVb: -2.017950 | GSw: -0.235010 | GSb: 0.064876 | TSUw: 0.464799 | TSUb: 0.034925\n",
      "Validating epoch 2599...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 278.45231820581495\n",
      "Average validation loss: 60.38899169638568\n",
      "Training epoch 2600...\n",
      "\n",
      "Train Epoch: 2600 [0/8000 (0%)]\tBatch Loss: 281.890873\tLearning Rate (w_theta): 0.001000\t TIME:6439.2s\n",
      "\t\t\t\tDisc: 0.476457\t\tSym: 9.826587\t\tSpars: 271.587830\n",
      "\t TVw: 0.273157 | TVb: -2.017934 | GSw: -0.235010 | GSb: 0.064876 | TSUw: 0.464798 | TSUb: 0.034926\n",
      "\n",
      "Train Epoch: 2600 [4000/8000 (50%)]\tBatch Loss: 274.825844\tLearning Rate (w_theta): 0.001000\t TIME:6440.7s\n",
      "\t\t\t\tDisc: 0.480988\t\tSym: 9.687325\t\tSpars: 264.657532\n",
      "\t TVw: 0.273273 | TVb: -2.017880 | GSw: -0.235010 | GSb: 0.064876 | TSUw: 0.464798 | TSUb: 0.034926\n",
      "Validating epoch 2600...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 273.06009398642004\n",
      "Average validation loss: 60.7842954335761\n",
      "Training epoch 2601...\n",
      "\n",
      "Train Epoch: 2601 [0/8000 (0%)]\tBatch Loss: 282.656097\tLearning Rate (w_theta): 0.001000\t TIME:6443.8s\n",
      "\t\t\t\tDisc: 0.483830\t\tSym: 10.375453\t\tSpars: 271.796814\n",
      "\t TVw: 0.273859 | TVb: -2.017776 | GSw: -0.235010 | GSb: 0.064876 | TSUw: 0.464798 | TSUb: 0.034926\n",
      "\n",
      "Train Epoch: 2601 [4000/8000 (50%)]\tBatch Loss: 261.055925\tLearning Rate (w_theta): 0.001000\t TIME:6445.4s\n",
      "\t\t\t\tDisc: 0.501562\t\tSym: 8.571788\t\tSpars: 251.982574\n",
      "\t TVw: 0.274594 | TVb: -2.017662 | GSw: -0.235010 | GSb: 0.064875 | TSUw: 0.464798 | TSUb: 0.034926\n",
      "Validating epoch 2601...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 274.77057346321675\n",
      "Average validation loss: 59.59158596425136\n",
      "Training epoch 2602...\n",
      "\n",
      "Train Epoch: 2602 [0/8000 (0%)]\tBatch Loss: 295.370031\tLearning Rate (w_theta): 0.001000\t TIME:6447.9s\n",
      "\t\t\t\tDisc: 0.539507\t\tSym: 10.351185\t\tSpars: 284.479340\n",
      "\t TVw: 0.274797 | TVb: -2.017575 | GSw: -0.235010 | GSb: 0.064875 | TSUw: 0.464798 | TSUb: 0.034926\n",
      "\n",
      "Train Epoch: 2602 [4000/8000 (50%)]\tBatch Loss: 267.033137\tLearning Rate (w_theta): 0.001000\t TIME:6449.5s\n",
      "\t\t\t\tDisc: 0.511456\t\tSym: 9.267501\t\tSpars: 257.254181\n",
      "\t TVw: 0.274541 | TVb: -2.017552 | GSw: -0.235011 | GSb: 0.064875 | TSUw: 0.464797 | TSUb: 0.034927\n",
      "Validating epoch 2602...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 284.5971232895317\n",
      "Average validation loss: 61.724795591362856\n",
      "Training epoch 2603...\n",
      "\n",
      "Train Epoch: 2603 [0/8000 (0%)]\tBatch Loss: 264.168534\tLearning Rate (w_theta): 0.001000\t TIME:6451.9s\n",
      "\t\t\t\tDisc: 0.513875\t\tSym: 9.161418\t\tSpars: 254.493240\n",
      "\t TVw: 0.273872 | TVb: -2.017567 | GSw: -0.235011 | GSb: 0.064875 | TSUw: 0.464797 | TSUb: 0.034927\n",
      "\n",
      "Train Epoch: 2603 [4000/8000 (50%)]\tBatch Loss: 279.118688\tLearning Rate (w_theta): 0.001000\t TIME:6453.5s\n",
      "\t\t\t\tDisc: 0.513989\t\tSym: 9.482934\t\tSpars: 269.121765\n",
      "\t TVw: 0.273757 | TVb: -2.017569 | GSw: -0.235011 | GSb: 0.064874 | TSUw: 0.464797 | TSUb: 0.034927\n",
      "Validating epoch 2603...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 274.9462826198489\n",
      "Average validation loss: 59.131904345610224\n",
      "Training epoch 2604...\n",
      "\n",
      "Train Epoch: 2604 [0/8000 (0%)]\tBatch Loss: 280.238979\tLearning Rate (w_theta): 0.001000\t TIME:6456.0s\n",
      "\t\t\t\tDisc: 0.489841\t\tSym: 10.285485\t\tSpars: 269.463654\n",
      "\t TVw: 0.274168 | TVb: -2.017516 | GSw: -0.235011 | GSb: 0.064874 | TSUw: 0.464797 | TSUb: 0.034927\n",
      "\n",
      "Train Epoch: 2604 [4000/8000 (50%)]\tBatch Loss: 276.486474\tLearning Rate (w_theta): 0.001000\t TIME:6457.6s\n",
      "\t\t\t\tDisc: 0.504304\t\tSym: 9.992760\t\tSpars: 265.989410\n",
      "\t TVw: 0.274896 | TVb: -2.017433 | GSw: -0.235011 | GSb: 0.064874 | TSUw: 0.464796 | TSUb: 0.034928\n",
      "Validating epoch 2604...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 276.19647205826925\n",
      "Average validation loss: 57.60133642231118\n",
      "Training epoch 2605...\n",
      "\n",
      "Train Epoch: 2605 [0/8000 (0%)]\tBatch Loss: 290.352876\tLearning Rate (w_theta): 0.001000\t TIME:6460.1s\n",
      "\t\t\t\tDisc: 0.519091\t\tSym: 11.026473\t\tSpars: 278.807312\n",
      "\t TVw: 0.275280 | TVb: -2.017364 | GSw: -0.235011 | GSb: 0.064874 | TSUw: 0.464796 | TSUb: 0.034928\n",
      "\n",
      "Train Epoch: 2605 [4000/8000 (50%)]\tBatch Loss: 266.929093\tLearning Rate (w_theta): 0.001000\t TIME:6461.6s\n",
      "\t\t\t\tDisc: 0.506792\t\tSym: 9.155456\t\tSpars: 257.266846\n",
      "\t TVw: 0.275718 | TVb: -2.017293 | GSw: -0.235011 | GSb: 0.064873 | TSUw: 0.464796 | TSUb: 0.034928\n",
      "Validating epoch 2605...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 271.41086922871136\n",
      "Average validation loss: 60.28390909406323\n",
      "Training epoch 2606...\n",
      "\n",
      "Train Epoch: 2606 [0/8000 (0%)]\tBatch Loss: 261.253335\tLearning Rate (w_theta): 0.001000\t TIME:6464.1s\n",
      "\t\t\t\tDisc: 0.503408\t\tSym: 8.582843\t\tSpars: 252.167084\n",
      "\t TVw: 0.276054 | TVb: -2.017223 | GSw: -0.235011 | GSb: 0.064873 | TSUw: 0.464796 | TSUb: 0.034928\n",
      "\n",
      "Train Epoch: 2606 [4000/8000 (50%)]\tBatch Loss: 272.549088\tLearning Rate (w_theta): 0.001000\t TIME:6465.7s\n",
      "\t\t\t\tDisc: 0.526799\t\tSym: 9.648205\t\tSpars: 262.374084\n",
      "\t TVw: 0.276241 | TVb: -2.017122 | GSw: -0.235011 | GSb: 0.064873 | TSUw: 0.464795 | TSUb: 0.034928\n",
      "Validating epoch 2606...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 270.6336833937114\n",
      "Average validation loss: 62.67737602794206\n",
      "Training epoch 2607...\n",
      "\n",
      "Train Epoch: 2607 [0/8000 (0%)]\tBatch Loss: 271.885985\tLearning Rate (w_theta): 0.001000\t TIME:6468.2s\n",
      "\t\t\t\tDisc: 0.570940\t\tSym: 9.668896\t\tSpars: 261.646149\n",
      "\t TVw: 0.276146 | TVb: -2.017048 | GSw: -0.235011 | GSb: 0.064873 | TSUw: 0.464795 | TSUb: 0.034929\n",
      "\n",
      "Train Epoch: 2607 [4000/8000 (50%)]\tBatch Loss: 272.689752\tLearning Rate (w_theta): 0.001000\t TIME:6469.8s\n",
      "\t\t\t\tDisc: 0.507564\t\tSym: 9.807127\t\tSpars: 262.375061\n",
      "\t TVw: 0.275406 | TVb: -2.017022 | GSw: -0.235011 | GSb: 0.064873 | TSUw: 0.464795 | TSUb: 0.034929\n",
      "Validating epoch 2607...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 269.44334009962733\n",
      "Average validation loss: 58.63011262923101\n",
      "Training epoch 2608...\n",
      "\n",
      "Train Epoch: 2608 [0/8000 (0%)]\tBatch Loss: 273.665098\tLearning Rate (w_theta): 0.001000\t TIME:6472.3s\n",
      "\t\t\t\tDisc: 0.499990\t\tSym: 9.637429\t\tSpars: 263.527679\n",
      "\t TVw: 0.275146 | TVb: -2.016954 | GSw: -0.235011 | GSb: 0.064872 | TSUw: 0.464795 | TSUb: 0.034929\n",
      "\n",
      "Train Epoch: 2608 [4000/8000 (50%)]\tBatch Loss: 279.806086\tLearning Rate (w_theta): 0.001000\t TIME:6473.9s\n",
      "\t\t\t\tDisc: 0.583987\t\tSym: 10.083182\t\tSpars: 269.138916\n",
      "\t TVw: 0.274801 | TVb: -2.016906 | GSw: -0.235011 | GSb: 0.064872 | TSUw: 0.464794 | TSUb: 0.034929\n",
      "Validating epoch 2608...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 273.80944367878095\n",
      "Average validation loss: 60.190012038829686\n",
      "Training epoch 2609...\n",
      "\n",
      "Train Epoch: 2609 [0/8000 (0%)]\tBatch Loss: 275.454646\tLearning Rate (w_theta): 0.001000\t TIME:6476.4s\n",
      "\t\t\t\tDisc: 0.544057\t\tSym: 9.954504\t\tSpars: 264.956085\n",
      "\t TVw: 0.274119 | TVb: -2.016887 | GSw: -0.235012 | GSb: 0.064872 | TSUw: 0.464794 | TSUb: 0.034929\n",
      "\n",
      "Train Epoch: 2609 [4000/8000 (50%)]\tBatch Loss: 258.711819\tLearning Rate (w_theta): 0.001000\t TIME:6478.0s\n",
      "\t\t\t\tDisc: 0.541082\t\tSym: 8.403693\t\tSpars: 249.767044\n",
      "\t TVw: 0.273591 | TVb: -2.016862 | GSw: -0.235012 | GSb: 0.064872 | TSUw: 0.464794 | TSUb: 0.034930\n",
      "Validating epoch 2609...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 273.3105157048948\n",
      "Average validation loss: 58.47413106394233\n",
      "Training epoch 2610...\n",
      "\n",
      "Train Epoch: 2610 [0/8000 (0%)]\tBatch Loss: 265.480201\tLearning Rate (w_theta): 0.001000\t TIME:6480.4s\n",
      "\t\t\t\tDisc: 0.499256\t\tSym: 9.980060\t\tSpars: 255.000885\n",
      "\t TVw: 0.272941 | TVb: -2.016853 | GSw: -0.235012 | GSb: 0.064871 | TSUw: 0.464794 | TSUb: 0.034930\n",
      "\n",
      "Train Epoch: 2610 [4000/8000 (50%)]\tBatch Loss: 272.068980\tLearning Rate (w_theta): 0.001000\t TIME:6482.1s\n",
      "\t\t\t\tDisc: 0.500516\t\tSym: 9.424818\t\tSpars: 262.143646\n",
      "\t TVw: 0.272850 | TVb: -2.016816 | GSw: -0.235012 | GSb: 0.064871 | TSUw: 0.464793 | TSUb: 0.034930\n",
      "Validating epoch 2610...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 271.8763410959363\n",
      "Average validation loss: 57.20210510957387\n",
      "Training epoch 2611...\n",
      "\n",
      "Train Epoch: 2611 [0/8000 (0%)]\tBatch Loss: 267.960867\tLearning Rate (w_theta): 0.001000\t TIME:6485.2s\n",
      "\t\t\t\tDisc: 0.504504\t\tSym: 9.770847\t\tSpars: 257.685516\n",
      "\t TVw: 0.272888 | TVb: -2.016780 | GSw: -0.235012 | GSb: 0.064871 | TSUw: 0.464793 | TSUb: 0.034930\n",
      "\n",
      "Train Epoch: 2611 [4000/8000 (50%)]\tBatch Loss: 269.390927\tLearning Rate (w_theta): 0.001000\t TIME:6486.8s\n",
      "\t\t\t\tDisc: 0.538425\t\tSym: 9.344995\t\tSpars: 259.507507\n",
      "\t TVw: 0.273366 | TVb: -2.016703 | GSw: -0.235012 | GSb: 0.064871 | TSUw: 0.464793 | TSUb: 0.034931\n",
      "Validating epoch 2611...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 267.13527254094436\n",
      "Average validation loss: 59.82059502316672\n",
      "Training epoch 2612...\n",
      "\n",
      "Train Epoch: 2612 [0/8000 (0%)]\tBatch Loss: 260.457542\tLearning Rate (w_theta): 0.001000\t TIME:6489.7s\n",
      "\t\t\t\tDisc: 0.538162\t\tSym: 8.938652\t\tSpars: 250.980728\n",
      "\t TVw: 0.273548 | TVb: -2.016638 | GSw: -0.235012 | GSb: 0.064870 | TSUw: 0.464793 | TSUb: 0.034931\n",
      "\n",
      "Train Epoch: 2612 [4000/8000 (50%)]\tBatch Loss: 264.010148\tLearning Rate (w_theta): 0.001000\t TIME:6491.3s\n",
      "\t\t\t\tDisc: 0.513491\t\tSym: 9.107008\t\tSpars: 254.389648\n",
      "\t TVw: 0.273660 | TVb: -2.016570 | GSw: -0.235012 | GSb: 0.064870 | TSUw: 0.464793 | TSUb: 0.034931\n",
      "Validating epoch 2612...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 264.5286519699307\n",
      "Average validation loss: 57.41784325581161\n",
      "Training epoch 2613...\n",
      "\n",
      "Train Epoch: 2613 [0/8000 (0%)]\tBatch Loss: 266.519258\tLearning Rate (w_theta): 0.001000\t TIME:6493.7s\n",
      "\t\t\t\tDisc: 0.523496\t\tSym: 9.625919\t\tSpars: 256.369843\n",
      "\t TVw: 0.273743 | TVb: -2.016465 | GSw: -0.235012 | GSb: 0.064870 | TSUw: 0.464792 | TSUb: 0.034931\n",
      "\n",
      "Train Epoch: 2613 [4000/8000 (50%)]\tBatch Loss: 268.424803\tLearning Rate (w_theta): 0.001000\t TIME:6495.3s\n",
      "\t\t\t\tDisc: 0.626686\t\tSym: 8.940237\t\tSpars: 258.857880\n",
      "\t TVw: 0.273471 | TVb: -2.016396 | GSw: -0.235012 | GSb: 0.064870 | TSUw: 0.464792 | TSUb: 0.034931\n",
      "Validating epoch 2613...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 271.2025191260555\n",
      "Average validation loss: 60.32719796274648\n",
      "Training epoch 2614...\n",
      "\n",
      "Train Epoch: 2614 [0/8000 (0%)]\tBatch Loss: 276.232723\tLearning Rate (w_theta): 0.001000\t TIME:6497.8s\n",
      "\t\t\t\tDisc: 0.562784\t\tSym: 9.906420\t\tSpars: 265.763519\n",
      "\t TVw: 0.272833 | TVb: -2.016373 | GSw: -0.235012 | GSb: 0.064869 | TSUw: 0.464792 | TSUb: 0.034932\n",
      "\n",
      "Train Epoch: 2614 [4000/8000 (50%)]\tBatch Loss: 276.754000\tLearning Rate (w_theta): 0.001000\t TIME:6499.4s\n",
      "\t\t\t\tDisc: 0.567779\t\tSym: 10.170962\t\tSpars: 266.015259\n",
      "\t TVw: 0.272200 | TVb: -2.016351 | GSw: -0.235013 | GSb: 0.064869 | TSUw: 0.464792 | TSUb: 0.034932\n",
      "Validating epoch 2614...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 267.2185170417243\n",
      "Average validation loss: 56.78636606644521\n",
      "Training epoch 2615...\n",
      "\n",
      "Train Epoch: 2615 [0/8000 (0%)]\tBatch Loss: 249.431329\tLearning Rate (w_theta): 0.001000\t TIME:6501.9s\n",
      "\t\t\t\tDisc: 0.504575\t\tSym: 8.285778\t\tSpars: 240.640976\n",
      "\t TVw: 0.272198 | TVb: -2.016277 | GSw: -0.235013 | GSb: 0.064869 | TSUw: 0.464791 | TSUb: 0.034932\n",
      "\n",
      "Train Epoch: 2615 [4000/8000 (50%)]\tBatch Loss: 245.603867\tLearning Rate (w_theta): 0.001000\t TIME:6503.5s\n",
      "\t\t\t\tDisc: 0.517322\t\tSym: 7.926359\t\tSpars: 237.160187\n",
      "\t TVw: 0.272070 | TVb: -2.016200 | GSw: -0.235013 | GSb: 0.064869 | TSUw: 0.464791 | TSUb: 0.034932\n",
      "Validating epoch 2615...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 261.70608768228885\n",
      "Average validation loss: 56.20287368160973\n",
      "Training epoch 2616...\n",
      "\n",
      "Train Epoch: 2616 [0/8000 (0%)]\tBatch Loss: 279.432486\tLearning Rate (w_theta): 0.001000\t TIME:6506.0s\n",
      "\t\t\t\tDisc: 0.514761\t\tSym: 11.197175\t\tSpars: 267.720551\n",
      "\t TVw: 0.271952 | TVb: -2.016124 | GSw: -0.235013 | GSb: 0.064868 | TSUw: 0.464791 | TSUb: 0.034932\n",
      "\n",
      "Train Epoch: 2616 [4000/8000 (50%)]\tBatch Loss: 247.764398\tLearning Rate (w_theta): 0.001000\t TIME:6507.5s\n",
      "\t\t\t\tDisc: 0.531153\t\tSym: 8.175490\t\tSpars: 239.057755\n",
      "\t TVw: 0.271510 | TVb: -2.016084 | GSw: -0.235013 | GSb: 0.064868 | TSUw: 0.464791 | TSUb: 0.034933\n",
      "Validating epoch 2616...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 269.70099874523794\n",
      "Average validation loss: 57.753506593578514\n",
      "Training epoch 2617...\n",
      "\n",
      "Train Epoch: 2617 [0/8000 (0%)]\tBatch Loss: 267.981808\tLearning Rate (w_theta): 0.001000\t TIME:6510.0s\n",
      "\t\t\t\tDisc: 0.535291\t\tSym: 9.331923\t\tSpars: 258.114594\n",
      "\t TVw: 0.270731 | TVb: -2.016080 | GSw: -0.235013 | GSb: 0.064868 | TSUw: 0.464790 | TSUb: 0.034933\n",
      "\n",
      "Train Epoch: 2617 [4000/8000 (50%)]\tBatch Loss: 277.596106\tLearning Rate (w_theta): 0.001000\t TIME:6511.6s\n",
      "\t\t\t\tDisc: 0.582254\t\tSym: 9.954129\t\tSpars: 267.059723\n",
      "\t TVw: 0.270428 | TVb: -2.016077 | GSw: -0.235013 | GSb: 0.064868 | TSUw: 0.464790 | TSUb: 0.034933\n",
      "Validating epoch 2617...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 268.71525229081834\n",
      "Average validation loss: 55.00046701956222\n",
      "Training epoch 2618...\n",
      "\n",
      "Train Epoch: 2618 [0/8000 (0%)]\tBatch Loss: 267.316621\tLearning Rate (w_theta): 0.001000\t TIME:6514.1s\n",
      "\t\t\t\tDisc: 0.500993\t\tSym: 10.246779\t\tSpars: 256.568848\n",
      "\t TVw: 0.270248 | TVb: -2.016057 | GSw: -0.235013 | GSb: 0.064868 | TSUw: 0.464790 | TSUb: 0.034933\n",
      "\n",
      "Train Epoch: 2618 [4000/8000 (50%)]\tBatch Loss: 250.075594\tLearning Rate (w_theta): 0.001000\t TIME:6515.7s\n",
      "\t\t\t\tDisc: 0.510535\t\tSym: 8.254527\t\tSpars: 241.310532\n",
      "\t TVw: 0.270701 | TVb: -2.015988 | GSw: -0.235013 | GSb: 0.064867 | TSUw: 0.464790 | TSUb: 0.034933\n",
      "Validating epoch 2618...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 263.9856239751843\n",
      "Average validation loss: 54.428903543291945\n",
      "Training epoch 2619...\n",
      "\n",
      "Train Epoch: 2619 [0/8000 (0%)]\tBatch Loss: 257.861304\tLearning Rate (w_theta): 0.001000\t TIME:6518.2s\n",
      "\t\t\t\tDisc: 0.523326\t\tSym: 9.472057\t\tSpars: 247.865921\n",
      "\t TVw: 0.271196 | TVb: -2.015908 | GSw: -0.235013 | GSb: 0.064867 | TSUw: 0.464789 | TSUb: 0.034934\n",
      "\n",
      "Train Epoch: 2619 [4000/8000 (50%)]\tBatch Loss: 238.587593\tLearning Rate (w_theta): 0.001000\t TIME:6519.8s\n",
      "\t\t\t\tDisc: 0.530375\t\tSym: 7.360868\t\tSpars: 230.696350\n",
      "\t TVw: 0.271351 | TVb: -2.015862 | GSw: -0.235014 | GSb: 0.064867 | TSUw: 0.464789 | TSUb: 0.034934\n",
      "Validating epoch 2619...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 265.4061129060944\n",
      "Average validation loss: 55.71003541910385\n",
      "Training epoch 2620...\n",
      "\n",
      "Train Epoch: 2620 [0/8000 (0%)]\tBatch Loss: 262.981788\tLearning Rate (w_theta): 0.001000\t TIME:6522.3s\n",
      "\t\t\t\tDisc: 0.516101\t\tSym: 9.949635\t\tSpars: 252.516052\n",
      "\t TVw: 0.271232 | TVb: -2.015835 | GSw: -0.235014 | GSb: 0.064867 | TSUw: 0.464789 | TSUb: 0.034934\n",
      "\n",
      "Train Epoch: 2620 [4000/8000 (50%)]\tBatch Loss: 257.492380\tLearning Rate (w_theta): 0.001000\t TIME:6523.9s\n",
      "\t\t\t\tDisc: 0.509656\t\tSym: 8.915218\t\tSpars: 248.067505\n",
      "\t TVw: 0.271210 | TVb: -2.015754 | GSw: -0.235014 | GSb: 0.064866 | TSUw: 0.464789 | TSUb: 0.034934\n",
      "Validating epoch 2620...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 258.50978154200607\n",
      "Average validation loss: 57.43397186040276\n",
      "Training epoch 2621...\n",
      "\n",
      "Train Epoch: 2621 [0/8000 (0%)]\tBatch Loss: 254.677971\tLearning Rate (w_theta): 0.001000\t TIME:6527.0s\n",
      "\t\t\t\tDisc: 0.575333\t\tSym: 8.738135\t\tSpars: 245.364502\n",
      "\t TVw: 0.271450 | TVb: -2.015646 | GSw: -0.235014 | GSb: 0.064866 | TSUw: 0.464788 | TSUb: 0.034935\n",
      "\n",
      "Train Epoch: 2621 [4000/8000 (50%)]\tBatch Loss: 274.387393\tLearning Rate (w_theta): 0.001000\t TIME:6528.6s\n",
      "\t\t\t\tDisc: 0.570059\t\tSym: 10.059644\t\tSpars: 263.757690\n",
      "\t TVw: 0.271241 | TVb: -2.015608 | GSw: -0.235014 | GSb: 0.064866 | TSUw: 0.464788 | TSUb: 0.034935\n",
      "Validating epoch 2621...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 265.29443696393156\n",
      "Average validation loss: 55.77438190584717\n",
      "Training epoch 2622...\n",
      "\n",
      "Train Epoch: 2622 [0/8000 (0%)]\tBatch Loss: 250.636836\tLearning Rate (w_theta): 0.001000\t TIME:6531.1s\n",
      "\t\t\t\tDisc: 0.530264\t\tSym: 8.856342\t\tSpars: 241.250229\n",
      "\t TVw: 0.270939 | TVb: -2.015567 | GSw: -0.235014 | GSb: 0.064866 | TSUw: 0.464788 | TSUb: 0.034935\n",
      "\n",
      "Train Epoch: 2622 [4000/8000 (50%)]\tBatch Loss: 253.856553\tLearning Rate (w_theta): 0.001000\t TIME:6532.7s\n",
      "\t\t\t\tDisc: 0.511472\t\tSym: 9.467533\t\tSpars: 243.877548\n",
      "\t TVw: 0.270626 | TVb: -2.015522 | GSw: -0.235014 | GSb: 0.064865 | TSUw: 0.464788 | TSUb: 0.034935\n",
      "Validating epoch 2622...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 259.80387548274814\n",
      "Average validation loss: 52.772915749913736\n",
      "Training epoch 2623...\n",
      "\n",
      "Train Epoch: 2623 [0/8000 (0%)]\tBatch Loss: 253.641759\tLearning Rate (w_theta): 0.001000\t TIME:6535.2s\n",
      "\t\t\t\tDisc: 0.500539\t\tSym: 9.075668\t\tSpars: 244.065552\n",
      "\t TVw: 0.270539 | TVb: -2.015450 | GSw: -0.235014 | GSb: 0.064865 | TSUw: 0.464788 | TSUb: 0.034935\n",
      "\n",
      "Train Epoch: 2623 [4000/8000 (50%)]\tBatch Loss: 272.371514\tLearning Rate (w_theta): 0.001000\t TIME:6536.8s\n",
      "\t\t\t\tDisc: 0.522741\t\tSym: 11.361835\t\tSpars: 260.486938\n",
      "\t TVw: 0.270794 | TVb: -2.015370 | GSw: -0.235014 | GSb: 0.064865 | TSUw: 0.464787 | TSUb: 0.034936\n",
      "Validating epoch 2623...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 262.0245245854138\n",
      "Average validation loss: 56.545971643128226\n",
      "Training epoch 2624...\n",
      "\n",
      "Train Epoch: 2624 [0/8000 (0%)]\tBatch Loss: 279.780156\tLearning Rate (w_theta): 0.001000\t TIME:6539.3s\n",
      "\t\t\t\tDisc: 0.629777\t\tSym: 10.937428\t\tSpars: 268.212952\n",
      "\t TVw: 0.270751 | TVb: -2.015319 | GSw: -0.235014 | GSb: 0.064865 | TSUw: 0.464787 | TSUb: 0.034936\n",
      "\n",
      "Train Epoch: 2624 [4000/8000 (50%)]\tBatch Loss: 257.987810\tLearning Rate (w_theta): 0.001000\t TIME:6540.9s\n",
      "\t\t\t\tDisc: 0.621512\t\tSym: 8.948375\t\tSpars: 248.417923\n",
      "\t TVw: 0.270613 | TVb: -2.015278 | GSw: -0.235015 | GSb: 0.064864 | TSUw: 0.464787 | TSUb: 0.034936\n",
      "Validating epoch 2624...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 262.40168571092835\n",
      "Average validation loss: 55.23794589369838\n",
      "Training epoch 2625...\n",
      "\n",
      "Train Epoch: 2625 [0/8000 (0%)]\tBatch Loss: 257.838345\tLearning Rate (w_theta): 0.001000\t TIME:6543.4s\n",
      "\t\t\t\tDisc: 0.536905\t\tSym: 9.282657\t\tSpars: 248.018784\n",
      "\t TVw: 0.270335 | TVb: -2.015244 | GSw: -0.235015 | GSb: 0.064864 | TSUw: 0.464787 | TSUb: 0.034936\n",
      "\n",
      "Train Epoch: 2625 [4000/8000 (50%)]\tBatch Loss: 258.810284\tLearning Rate (w_theta): 0.001000\t TIME:6545.0s\n",
      "\t\t\t\tDisc: 0.510178\t\tSym: 9.516322\t\tSpars: 248.783783\n",
      "\t TVw: 0.270214 | TVb: -2.015182 | GSw: -0.235015 | GSb: 0.064864 | TSUw: 0.464786 | TSUb: 0.034937\n",
      "Validating epoch 2625...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 256.2317527690146\n",
      "Average validation loss: 52.38074221808493\n",
      "Training epoch 2626...\n",
      "\n",
      "Train Epoch: 2626 [0/8000 (0%)]\tBatch Loss: 263.389708\tLearning Rate (w_theta): 0.001000\t TIME:6547.9s\n",
      "\t\t\t\tDisc: 0.537403\t\tSym: 9.474177\t\tSpars: 253.378128\n",
      "\t TVw: 0.270569 | TVb: -2.015075 | GSw: -0.235015 | GSb: 0.064864 | TSUw: 0.464786 | TSUb: 0.034937\n",
      "\n",
      "Train Epoch: 2626 [4000/8000 (50%)]\tBatch Loss: 273.676541\tLearning Rate (w_theta): 0.001000\t TIME:6549.5s\n",
      "\t\t\t\tDisc: 0.528096\t\tSym: 11.401313\t\tSpars: 261.747131\n",
      "\t TVw: 0.270340 | TVb: -2.015034 | GSw: -0.235015 | GSb: 0.064863 | TSUw: 0.464786 | TSUb: 0.034937\n",
      "Validating epoch 2626...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 258.70941270484167\n",
      "Average validation loss: 54.855640405708925\n",
      "Training epoch 2627...\n",
      "\n",
      "Train Epoch: 2627 [0/8000 (0%)]\tBatch Loss: 257.203559\tLearning Rate (w_theta): 0.001000\t TIME:6552.0s\n",
      "\t\t\t\tDisc: 0.604766\t\tSym: 8.886345\t\tSpars: 247.712448\n",
      "\t TVw: 0.270129 | TVb: -2.014981 | GSw: -0.235015 | GSb: 0.064863 | TSUw: 0.464786 | TSUb: 0.034937\n",
      "\n",
      "Train Epoch: 2627 [4000/8000 (50%)]\tBatch Loss: 257.659064\tLearning Rate (w_theta): 0.001000\t TIME:6553.6s\n",
      "\t\t\t\tDisc: 0.601418\t\tSym: 9.317717\t\tSpars: 247.739929\n",
      "\t TVw: 0.269921 | TVb: -2.014936 | GSw: -0.235015 | GSb: 0.064863 | TSUw: 0.464785 | TSUb: 0.034937\n",
      "Validating epoch 2627...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 260.55782019881224\n",
      "Average validation loss: 54.00374214276246\n",
      "Training epoch 2628...\n",
      "\n",
      "Train Epoch: 2628 [0/8000 (0%)]\tBatch Loss: 253.575638\tLearning Rate (w_theta): 0.001000\t TIME:6556.1s\n",
      "\t\t\t\tDisc: 0.549064\t\tSym: 8.902551\t\tSpars: 244.124023\n",
      "\t TVw: 0.269103 | TVb: -2.014930 | GSw: -0.235015 | GSb: 0.064863 | TSUw: 0.464785 | TSUb: 0.034938\n",
      "\n",
      "Train Epoch: 2628 [4000/8000 (50%)]\tBatch Loss: 251.831470\tLearning Rate (w_theta): 0.001000\t TIME:6557.7s\n",
      "\t\t\t\tDisc: 0.538815\t\tSym: 9.565238\t\tSpars: 241.727417\n",
      "\t TVw: 0.268990 | TVb: -2.014886 | GSw: -0.235015 | GSb: 0.064862 | TSUw: 0.464785 | TSUb: 0.034938\n",
      "Validating epoch 2628...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 259.02574575688607\n",
      "Average validation loss: 53.633951473055944\n",
      "Training epoch 2629...\n",
      "\n",
      "Train Epoch: 2629 [0/8000 (0%)]\tBatch Loss: 243.386242\tLearning Rate (w_theta): 0.001000\t TIME:6560.2s\n",
      "\t\t\t\tDisc: 0.523892\t\tSym: 8.858764\t\tSpars: 234.003586\n",
      "\t TVw: 0.268999 | TVb: -2.014828 | GSw: -0.235016 | GSb: 0.064862 | TSUw: 0.464785 | TSUb: 0.034938\n",
      "\n",
      "Train Epoch: 2629 [4000/8000 (50%)]\tBatch Loss: 272.064913\tLearning Rate (w_theta): 0.001000\t TIME:6561.8s\n",
      "\t\t\t\tDisc: 0.615514\t\tSym: 10.311490\t\tSpars: 261.137909\n",
      "\t TVw: 0.268452 | TVb: -2.014807 | GSw: -0.235016 | GSb: 0.064862 | TSUw: 0.464784 | TSUb: 0.034938\n",
      "Validating epoch 2629...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 265.3685014720807\n",
      "Average validation loss: 55.02680719995133\n",
      "Training epoch 2630...\n",
      "\n",
      "Train Epoch: 2630 [0/8000 (0%)]\tBatch Loss: 273.999315\tLearning Rate (w_theta): 0.001000\t TIME:6564.3s\n",
      "\t\t\t\tDisc: 0.640749\t\tSym: 10.131882\t\tSpars: 263.226685\n",
      "\t TVw: 0.267734 | TVb: -2.014800 | GSw: -0.235016 | GSb: 0.064862 | TSUw: 0.464784 | TSUb: 0.034939\n",
      "\n",
      "Train Epoch: 2630 [4000/8000 (50%)]\tBatch Loss: 256.158195\tLearning Rate (w_theta): 0.001000\t TIME:6565.9s\n",
      "\t\t\t\tDisc: 0.543527\t\tSym: 10.085448\t\tSpars: 245.529221\n",
      "\t TVw: 0.267278 | TVb: -2.014805 | GSw: -0.235016 | GSb: 0.064861 | TSUw: 0.464784 | TSUb: 0.034939\n",
      "Validating epoch 2630...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 257.8704487706809\n",
      "Average validation loss: 50.740351455051396\n",
      "Training epoch 2631...\n",
      "\n",
      "Train Epoch: 2631 [0/8000 (0%)]\tBatch Loss: 236.025735\tLearning Rate (w_theta): 0.001000\t TIME:6569.1s\n",
      "\t\t\t\tDisc: 0.500301\t\tSym: 8.068892\t\tSpars: 227.456543\n",
      "\t TVw: 0.268147 | TVb: -2.014725 | GSw: -0.235016 | GSb: 0.064861 | TSUw: 0.464784 | TSUb: 0.034939\n",
      "\n",
      "Train Epoch: 2631 [4000/8000 (50%)]\tBatch Loss: 253.448202\tLearning Rate (w_theta): 0.001000\t TIME:6570.6s\n",
      "\t\t\t\tDisc: 0.529279\t\tSym: 9.288796\t\tSpars: 243.630127\n",
      "\t TVw: 0.269207 | TVb: -2.014613 | GSw: -0.235016 | GSb: 0.064861 | TSUw: 0.464783 | TSUb: 0.034939\n",
      "Validating epoch 2631...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 251.69882039465458\n",
      "Average validation loss: 51.36755175216392\n",
      "Training epoch 2632...\n",
      "\n",
      "Train Epoch: 2632 [0/8000 (0%)]\tBatch Loss: 251.389376\tLearning Rate (w_theta): 0.001000\t TIME:6573.1s\n",
      "\t\t\t\tDisc: 0.537724\t\tSym: 9.538893\t\tSpars: 241.312759\n",
      "\t TVw: 0.270230 | TVb: -2.014483 | GSw: -0.235016 | GSb: 0.064861 | TSUw: 0.464783 | TSUb: 0.034939\n",
      "\n",
      "Train Epoch: 2632 [4000/8000 (50%)]\tBatch Loss: 248.808901\tLearning Rate (w_theta): 0.001000\t TIME:6574.7s\n",
      "\t\t\t\tDisc: 0.541773\t\tSym: 9.251076\t\tSpars: 239.016052\n",
      "\t TVw: 0.270716 | TVb: -2.014366 | GSw: -0.235016 | GSb: 0.064860 | TSUw: 0.464783 | TSUb: 0.034940\n",
      "Validating epoch 2632...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 250.1712613413739\n",
      "Average validation loss: 50.659355261315234\n",
      "Training epoch 2633...\n",
      "\n",
      "Train Epoch: 2633 [0/8000 (0%)]\tBatch Loss: 252.847466\tLearning Rate (w_theta): 0.001000\t TIME:6577.2s\n",
      "\t\t\t\tDisc: 0.554135\t\tSym: 9.267390\t\tSpars: 243.025940\n",
      "\t TVw: 0.270652 | TVb: -2.014266 | GSw: -0.235016 | GSb: 0.064860 | TSUw: 0.464783 | TSUb: 0.034940\n",
      "\n",
      "Train Epoch: 2633 [4000/8000 (50%)]\tBatch Loss: 239.990900\tLearning Rate (w_theta): 0.001000\t TIME:6578.8s\n",
      "\t\t\t\tDisc: 0.572456\t\tSym: 8.766513\t\tSpars: 230.651932\n",
      "\t TVw: 0.270032 | TVb: -2.014226 | GSw: -0.235017 | GSb: 0.064860 | TSUw: 0.464783 | TSUb: 0.034940\n",
      "Validating epoch 2633...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 254.0500207229747\n",
      "Average validation loss: 51.982779429090215\n",
      "Training epoch 2634...\n",
      "\n",
      "Train Epoch: 2634 [0/8000 (0%)]\tBatch Loss: 251.411235\tLearning Rate (w_theta): 0.001000\t TIME:6581.3s\n",
      "\t\t\t\tDisc: 0.560044\t\tSym: 9.453258\t\tSpars: 241.397934\n",
      "\t TVw: 0.269178 | TVb: -2.014230 | GSw: -0.235017 | GSb: 0.064860 | TSUw: 0.464782 | TSUb: 0.034940\n",
      "\n",
      "Train Epoch: 2634 [4000/8000 (50%)]\tBatch Loss: 245.305402\tLearning Rate (w_theta): 0.001000\t TIME:6582.9s\n",
      "\t\t\t\tDisc: 0.529133\t\tSym: 9.268121\t\tSpars: 235.508148\n",
      "\t TVw: 0.268549 | TVb: -2.014205 | GSw: -0.235017 | GSb: 0.064859 | TSUw: 0.464782 | TSUb: 0.034940\n",
      "Validating epoch 2634...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 251.34373756283384\n",
      "Average validation loss: 51.238464708017084\n",
      "Training epoch 2635...\n",
      "\n",
      "Train Epoch: 2635 [0/8000 (0%)]\tBatch Loss: 263.483145\tLearning Rate (w_theta): 0.001000\t TIME:6585.4s\n",
      "\t\t\t\tDisc: 0.595393\t\tSym: 10.321406\t\tSpars: 252.566345\n",
      "\t TVw: 0.267762 | TVb: -2.014193 | GSw: -0.235017 | GSb: 0.064859 | TSUw: 0.464782 | TSUb: 0.034941\n",
      "\n",
      "Train Epoch: 2635 [4000/8000 (50%)]\tBatch Loss: 265.322367\tLearning Rate (w_theta): 0.001000\t TIME:6587.0s\n",
      "\t\t\t\tDisc: 0.599055\t\tSym: 9.880417\t\tSpars: 254.842896\n",
      "\t TVw: 0.267387 | TVb: -2.014148 | GSw: -0.235017 | GSb: 0.064859 | TSUw: 0.464782 | TSUb: 0.034941\n",
      "Validating epoch 2635...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 252.33097801257887\n",
      "Average validation loss: 50.67682608539096\n",
      "Training epoch 2636...\n",
      "\n",
      "Train Epoch: 2636 [0/8000 (0%)]\tBatch Loss: 255.532345\tLearning Rate (w_theta): 0.001000\t TIME:6589.5s\n",
      "\t\t\t\tDisc: 0.540990\t\tSym: 10.044486\t\tSpars: 244.946869\n",
      "\t TVw: 0.266911 | TVb: -2.014120 | GSw: -0.235017 | GSb: 0.064859 | TSUw: 0.464781 | TSUb: 0.034941\n",
      "\n",
      "Train Epoch: 2636 [4000/8000 (50%)]\tBatch Loss: 244.775481\tLearning Rate (w_theta): 0.001000\t TIME:6591.1s\n",
      "\t\t\t\tDisc: 0.510277\t\tSym: 9.097983\t\tSpars: 235.167221\n",
      "\t TVw: 0.267232 | TVb: -2.014040 | GSw: -0.235017 | GSb: 0.064858 | TSUw: 0.464781 | TSUb: 0.034941\n",
      "Validating epoch 2636...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 248.3207097678584\n",
      "Average validation loss: 48.81977093485239\n",
      "Training epoch 2637...\n",
      "\n",
      "Train Epoch: 2637 [0/8000 (0%)]\tBatch Loss: 247.357171\tLearning Rate (w_theta): 0.001000\t TIME:6593.6s\n",
      "\t\t\t\tDisc: 0.527212\t\tSym: 9.543841\t\tSpars: 237.286118\n",
      "\t TVw: 0.267703 | TVb: -2.013931 | GSw: -0.235017 | GSb: 0.064858 | TSUw: 0.464781 | TSUb: 0.034942\n",
      "\n",
      "Train Epoch: 2637 [4000/8000 (50%)]\tBatch Loss: 242.746138\tLearning Rate (w_theta): 0.001000\t TIME:6595.2s\n",
      "\t\t\t\tDisc: 0.536899\t\tSym: 8.911693\t\tSpars: 233.297546\n",
      "\t TVw: 0.267752 | TVb: -2.013864 | GSw: -0.235017 | GSb: 0.064858 | TSUw: 0.464781 | TSUb: 0.034942\n",
      "Validating epoch 2637...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 248.13692430704305\n",
      "Average validation loss: 50.233583811495585\n",
      "Training epoch 2638...\n",
      "\n",
      "Train Epoch: 2638 [0/8000 (0%)]\tBatch Loss: 247.898562\tLearning Rate (w_theta): 0.001000\t TIME:6597.7s\n",
      "\t\t\t\tDisc: 0.555951\t\tSym: 9.378622\t\tSpars: 237.963989\n",
      "\t TVw: 0.267688 | TVb: -2.013787 | GSw: -0.235017 | GSb: 0.064858 | TSUw: 0.464780 | TSUb: 0.034942\n",
      "\n",
      "Train Epoch: 2638 [4000/8000 (50%)]\tBatch Loss: 257.411662\tLearning Rate (w_theta): 0.001000\t TIME:6599.2s\n",
      "\t\t\t\tDisc: 0.567356\t\tSym: 10.201743\t\tSpars: 246.642563\n",
      "\t TVw: 0.267462 | TVb: -2.013727 | GSw: -0.235018 | GSb: 0.064858 | TSUw: 0.464780 | TSUb: 0.034942\n",
      "Validating epoch 2638...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 248.34172245490336\n",
      "Average validation loss: 48.16420067025997\n",
      "Training epoch 2639...\n",
      "\n",
      "Train Epoch: 2639 [0/8000 (0%)]\tBatch Loss: 252.240965\tLearning Rate (w_theta): 0.001000\t TIME:6601.7s\n",
      "\t\t\t\tDisc: 0.562419\t\tSym: 9.694752\t\tSpars: 241.983795\n",
      "\t TVw: 0.266828 | TVb: -2.013690 | GSw: -0.235018 | GSb: 0.064857 | TSUw: 0.464780 | TSUb: 0.034942\n",
      "\n",
      "Train Epoch: 2639 [4000/8000 (50%)]\tBatch Loss: 250.086978\tLearning Rate (w_theta): 0.001000\t TIME:6603.3s\n",
      "\t\t\t\tDisc: 0.532482\t\tSym: 9.778144\t\tSpars: 239.776352\n",
      "\t TVw: 0.265909 | TVb: -2.013683 | GSw: -0.235018 | GSb: 0.064857 | TSUw: 0.464780 | TSUb: 0.034943\n",
      "Validating epoch 2639...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 246.48780234892317\n",
      "Average validation loss: 49.235496977293195\n",
      "Training epoch 2640...\n",
      "\n",
      "Train Epoch: 2640 [0/8000 (0%)]\tBatch Loss: 247.467217\tLearning Rate (w_theta): 0.001000\t TIME:6606.2s\n",
      "\t\t\t\tDisc: 0.532310\t\tSym: 9.191819\t\tSpars: 237.743088\n",
      "\t TVw: 0.265555 | TVb: -2.013632 | GSw: -0.235018 | GSb: 0.064857 | TSUw: 0.464779 | TSUb: 0.034943\n",
      "\n",
      "Train Epoch: 2640 [4000/8000 (50%)]\tBatch Loss: 249.134080\tLearning Rate (w_theta): 0.001000\t TIME:6607.8s\n",
      "\t\t\t\tDisc: 0.546629\t\tSym: 9.212604\t\tSpars: 239.374847\n",
      "\t TVw: 0.265367 | TVb: -2.013571 | GSw: -0.235018 | GSb: 0.064857 | TSUw: 0.464779 | TSUb: 0.034943\n",
      "Validating epoch 2640...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 244.4077210596058\n",
      "Average validation loss: 48.41009911905539\n",
      "Training epoch 2641...\n",
      "\n",
      "Train Epoch: 2641 [0/8000 (0%)]\tBatch Loss: 247.526252\tLearning Rate (w_theta): 0.001000\t TIME:6611.0s\n",
      "\t\t\t\tDisc: 0.531090\t\tSym: 10.342055\t\tSpars: 236.653107\n",
      "\t TVw: 0.265107 | TVb: -2.013507 | GSw: -0.235018 | GSb: 0.064856 | TSUw: 0.464779 | TSUb: 0.034943\n",
      "\n",
      "Train Epoch: 2641 [4000/8000 (50%)]\tBatch Loss: 226.292021\tLearning Rate (w_theta): 0.001000\t TIME:6612.6s\n",
      "\t\t\t\tDisc: 0.523117\t\tSym: 8.386168\t\tSpars: 217.382736\n",
      "\t TVw: 0.264950 | TVb: -2.013429 | GSw: -0.235018 | GSb: 0.064856 | TSUw: 0.464779 | TSUb: 0.034943\n",
      "Validating epoch 2641...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 245.3215297262972\n",
      "Average validation loss: 46.18279462678896\n",
      "Training epoch 2642...\n",
      "\n",
      "Train Epoch: 2642 [0/8000 (0%)]\tBatch Loss: 249.270848\tLearning Rate (w_theta): 0.001000\t TIME:6615.1s\n",
      "\t\t\t\tDisc: 0.603622\t\tSym: 9.481436\t\tSpars: 239.185791\n",
      "\t TVw: 0.264631 | TVb: -2.013375 | GSw: -0.235018 | GSb: 0.064856 | TSUw: 0.464778 | TSUb: 0.034944\n",
      "\n",
      "Train Epoch: 2642 [4000/8000 (50%)]\tBatch Loss: 257.880581\tLearning Rate (w_theta): 0.001000\t TIME:6616.6s\n",
      "\t\t\t\tDisc: 0.558331\t\tSym: 9.968506\t\tSpars: 247.353745\n",
      "\t TVw: 0.263200 | TVb: -2.013427 | GSw: -0.235018 | GSb: 0.064856 | TSUw: 0.464778 | TSUb: 0.034944\n",
      "Validating epoch 2642...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 261.6786828839584\n",
      "Average validation loss: 48.29989655409122\n",
      "Training epoch 2643...\n",
      "\n",
      "Train Epoch: 2643 [0/8000 (0%)]\tBatch Loss: 263.984613\tLearning Rate (w_theta): 0.001000\t TIME:6619.1s\n",
      "\t\t\t\tDisc: 0.562355\t\tSym: 10.323824\t\tSpars: 253.098434\n",
      "\t TVw: 0.261159 | TVb: -2.013510 | GSw: -0.235018 | GSb: 0.064855 | TSUw: 0.464778 | TSUb: 0.034944\n",
      "\n",
      "Train Epoch: 2643 [4000/8000 (50%)]\tBatch Loss: 260.348234\tLearning Rate (w_theta): 0.001000\t TIME:6620.7s\n",
      "\t\t\t\tDisc: 0.570834\t\tSym: 9.654567\t\tSpars: 250.122833\n",
      "\t TVw: 0.260253 | TVb: -2.013523 | GSw: -0.235018 | GSb: 0.064855 | TSUw: 0.464778 | TSUb: 0.034944\n",
      "Validating epoch 2643...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 257.37569698479564\n",
      "Average validation loss: 46.19248640022707\n",
      "Training epoch 2644...\n",
      "\n",
      "Train Epoch: 2644 [0/8000 (0%)]\tBatch Loss: 257.277029\tLearning Rate (w_theta): 0.001000\t TIME:6623.2s\n",
      "\t\t\t\tDisc: 0.482444\t\tSym: 9.866363\t\tSpars: 246.928223\n",
      "\t TVw: 0.260837 | TVb: -2.013465 | GSw: -0.235019 | GSb: 0.064855 | TSUw: 0.464777 | TSUb: 0.034945\n",
      "\n",
      "Train Epoch: 2644 [4000/8000 (50%)]\tBatch Loss: 268.601505\tLearning Rate (w_theta): 0.001000\t TIME:6624.8s\n",
      "\t\t\t\tDisc: 0.549017\t\tSym: 10.488126\t\tSpars: 257.564362\n",
      "\t TVw: 0.261643 | TVb: -2.013418 | GSw: -0.235019 | GSb: 0.064855 | TSUw: 0.464777 | TSUb: 0.034945\n",
      "Validating epoch 2644...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 250.72302351674819\n",
      "Average validation loss: 43.004301977157674\n",
      "Training epoch 2645...\n",
      "\n",
      "Train Epoch: 2645 [0/8000 (0%)]\tBatch Loss: 242.736592\tLearning Rate (w_theta): 0.001000\t TIME:6627.3s\n",
      "\t\t\t\tDisc: 0.486162\t\tSym: 8.822696\t\tSpars: 233.427734\n",
      "\t TVw: 0.263768 | TVb: -2.013264 | GSw: -0.235019 | GSb: 0.064854 | TSUw: 0.464777 | TSUb: 0.034945\n",
      "\n",
      "Train Epoch: 2645 [4000/8000 (50%)]\tBatch Loss: 252.851865\tLearning Rate (w_theta): 0.001000\t TIME:6628.9s\n",
      "\t\t\t\tDisc: 0.528430\t\tSym: 10.880565\t\tSpars: 241.442871\n",
      "\t TVw: 0.266447 | TVb: -2.013059 | GSw: -0.235019 | GSb: 0.064854 | TSUw: 0.464777 | TSUb: 0.034945\n",
      "Validating epoch 2645...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 241.95566208177829\n",
      "Average validation loss: 44.57849334149059\n",
      "Training epoch 2646...\n",
      "\n",
      "Train Epoch: 2646 [0/8000 (0%)]\tBatch Loss: 242.940701\tLearning Rate (w_theta): 0.001000\t TIME:6631.3s\n",
      "\t\t\t\tDisc: 0.574693\t\tSym: 9.185267\t\tSpars: 233.180740\n",
      "\t TVw: 0.268633 | TVb: -2.012856 | GSw: -0.235019 | GSb: 0.064854 | TSUw: 0.464777 | TSUb: 0.034946\n",
      "\n",
      "Train Epoch: 2646 [4000/8000 (50%)]\tBatch Loss: 233.622403\tLearning Rate (w_theta): 0.001000\t TIME:6632.9s\n",
      "\t\t\t\tDisc: 0.603485\t\tSym: 9.077909\t\tSpars: 223.941010\n",
      "\t TVw: 0.269981 | TVb: -2.012688 | GSw: -0.235019 | GSb: 0.064853 | TSUw: 0.464776 | TSUb: 0.034946\n",
      "Validating epoch 2646...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 239.64794463542148\n",
      "Average validation loss: 47.09041962092368\n",
      "Training epoch 2647...\n",
      "\n",
      "Train Epoch: 2647 [0/8000 (0%)]\tBatch Loss: 223.338633\tLearning Rate (w_theta): 0.001000\t TIME:6635.4s\n",
      "\t\t\t\tDisc: 0.596884\t\tSym: 8.135517\t\tSpars: 214.606232\n",
      "\t TVw: 0.270356 | TVb: -2.012563 | GSw: -0.235019 | GSb: 0.064853 | TSUw: 0.464776 | TSUb: 0.034946\n",
      "\n",
      "Train Epoch: 2647 [4000/8000 (50%)]\tBatch Loss: 242.456875\tLearning Rate (w_theta): 0.001000\t TIME:6637.0s\n",
      "\t\t\t\tDisc: 0.631251\t\tSym: 9.689989\t\tSpars: 232.135635\n",
      "\t TVw: 0.269772 | TVb: -2.012488 | GSw: -0.235019 | GSb: 0.064853 | TSUw: 0.464776 | TSUb: 0.034946\n",
      "Validating epoch 2647...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 237.55101077328723\n",
      "Average validation loss: 47.013114895405955\n",
      "Training epoch 2648...\n",
      "\n",
      "Train Epoch: 2648 [0/8000 (0%)]\tBatch Loss: 238.931663\tLearning Rate (w_theta): 0.001000\t TIME:6639.5s\n",
      "\t\t\t\tDisc: 0.618206\t\tSym: 9.682170\t\tSpars: 228.631287\n",
      "\t TVw: 0.268857 | TVb: -2.012425 | GSw: -0.235020 | GSb: 0.064853 | TSUw: 0.464776 | TSUb: 0.034946\n",
      "\n",
      "Train Epoch: 2648 [4000/8000 (50%)]\tBatch Loss: 235.029015\tLearning Rate (w_theta): 0.001000\t TIME:6641.1s\n",
      "\t\t\t\tDisc: 0.581510\t\tSym: 9.194545\t\tSpars: 225.252960\n",
      "\t TVw: 0.267681 | TVb: -2.012368 | GSw: -0.235020 | GSb: 0.064852 | TSUw: 0.464775 | TSUb: 0.034947\n",
      "Validating epoch 2648...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 236.72092491754395\n",
      "Average validation loss: 45.244417742331734\n",
      "Training epoch 2649...\n",
      "\n",
      "Train Epoch: 2649 [0/8000 (0%)]\tBatch Loss: 236.279984\tLearning Rate (w_theta): 0.001000\t TIME:6643.6s\n",
      "\t\t\t\tDisc: 0.589385\t\tSym: 9.798966\t\tSpars: 225.891632\n",
      "\t TVw: 0.266532 | TVb: -2.012319 | GSw: -0.235020 | GSb: 0.064852 | TSUw: 0.464775 | TSUb: 0.034947\n",
      "\n",
      "Train Epoch: 2649 [4000/8000 (50%)]\tBatch Loss: 237.622694\tLearning Rate (w_theta): 0.001000\t TIME:6645.2s\n",
      "\t\t\t\tDisc: 0.597315\t\tSym: 9.264652\t\tSpars: 227.760727\n",
      "\t TVw: 0.265665 | TVb: -2.012270 | GSw: -0.235020 | GSb: 0.064852 | TSUw: 0.464775 | TSUb: 0.034947\n",
      "Validating epoch 2649...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 237.86832175644219\n",
      "Average validation loss: 46.23332454861299\n",
      "Training epoch 2650...\n",
      "\n",
      "Train Epoch: 2650 [0/8000 (0%)]\tBatch Loss: 234.358933\tLearning Rate (w_theta): 0.001000\t TIME:6647.7s\n",
      "\t\t\t\tDisc: 0.600297\t\tSym: 8.934920\t\tSpars: 224.823715\n",
      "\t TVw: 0.264463 | TVb: -2.012261 | GSw: -0.235020 | GSb: 0.064852 | TSUw: 0.464775 | TSUb: 0.034947\n",
      "\n",
      "Train Epoch: 2650 [4000/8000 (50%)]\tBatch Loss: 242.519231\tLearning Rate (w_theta): 0.001000\t TIME:6649.3s\n",
      "\t\t\t\tDisc: 0.610236\t\tSym: 8.900373\t\tSpars: 233.008621\n",
      "\t TVw: 0.263521 | TVb: -2.012244 | GSw: -0.235020 | GSb: 0.064852 | TSUw: 0.464774 | TSUb: 0.034947\n",
      "Validating epoch 2650...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 240.39198246022085\n",
      "Average validation loss: 42.97998644779751\n",
      "Training epoch 2651...\n",
      "\n",
      "Train Epoch: 2651 [0/8000 (0%)]\tBatch Loss: 252.947706\tLearning Rate (w_theta): 0.001000\t TIME:6652.4s\n",
      "\t\t\t\tDisc: 0.571675\t\tSym: 10.239358\t\tSpars: 242.136673\n",
      "\t TVw: 0.262610 | TVb: -2.012223 | GSw: -0.235020 | GSb: 0.064851 | TSUw: 0.464774 | TSUb: 0.034948\n",
      "\n",
      "Train Epoch: 2651 [4000/8000 (50%)]\tBatch Loss: 247.749558\tLearning Rate (w_theta): 0.001000\t TIME:6654.0s\n",
      "\t\t\t\tDisc: 0.547342\t\tSym: 10.351783\t\tSpars: 236.850433\n",
      "\t TVw: 0.261870 | TVb: -2.012217 | GSw: -0.235020 | GSb: 0.064851 | TSUw: 0.464774 | TSUb: 0.034948\n",
      "Validating epoch 2651...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 238.81228109795765\n",
      "Average validation loss: 44.781663202462425\n",
      "Training epoch 2652...\n",
      "\n",
      "Train Epoch: 2652 [0/8000 (0%)]\tBatch Loss: 244.681361\tLearning Rate (w_theta): 0.001000\t TIME:6656.4s\n",
      "\t\t\t\tDisc: 0.600655\t\tSym: 9.976504\t\tSpars: 234.104202\n",
      "\t TVw: 0.261681 | TVb: -2.012189 | GSw: -0.235020 | GSb: 0.064851 | TSUw: 0.464774 | TSUb: 0.034948\n",
      "\n",
      "Train Epoch: 2652 [4000/8000 (50%)]\tBatch Loss: 230.240187\tLearning Rate (w_theta): 0.001000\t TIME:6658.1s\n",
      "\t\t\t\tDisc: 0.562950\t\tSym: 8.762198\t\tSpars: 220.915039\n",
      "\t TVw: 0.261950 | TVb: -2.012123 | GSw: -0.235020 | GSb: 0.064850 | TSUw: 0.464773 | TSUb: 0.034948\n",
      "Validating epoch 2652...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 238.33794951266452\n",
      "Average validation loss: 43.63879184130133\n",
      "Training epoch 2653...\n",
      "\n",
      "Train Epoch: 2653 [0/8000 (0%)]\tBatch Loss: 229.301600\tLearning Rate (w_theta): 0.001000\t TIME:6661.0s\n",
      "\t\t\t\tDisc: 0.528281\t\tSym: 8.725376\t\tSpars: 220.047943\n",
      "\t TVw: 0.262380 | TVb: -2.012041 | GSw: -0.235021 | GSb: 0.064850 | TSUw: 0.464773 | TSUb: 0.034949\n",
      "\n",
      "Train Epoch: 2653 [4000/8000 (50%)]\tBatch Loss: 248.508913\tLearning Rate (w_theta): 0.001000\t TIME:6662.6s\n",
      "\t\t\t\tDisc: 0.545797\t\tSym: 10.582089\t\tSpars: 237.381027\n",
      "\t TVw: 0.262917 | TVb: -2.011932 | GSw: -0.235021 | GSb: 0.064850 | TSUw: 0.464773 | TSUb: 0.034949\n",
      "Validating epoch 2653...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 233.74971872348473\n",
      "Average validation loss: 43.657773354077676\n",
      "Training epoch 2654...\n",
      "\n",
      "Train Epoch: 2654 [0/8000 (0%)]\tBatch Loss: 230.777244\tLearning Rate (w_theta): 0.001000\t TIME:6665.1s\n",
      "\t\t\t\tDisc: 0.538307\t\tSym: 9.431457\t\tSpars: 220.807480\n",
      "\t TVw: 0.263367 | TVb: -2.011822 | GSw: -0.235021 | GSb: 0.064850 | TSUw: 0.464773 | TSUb: 0.034949\n",
      "\n",
      "Train Epoch: 2654 [4000/8000 (50%)]\tBatch Loss: 262.003640\tLearning Rate (w_theta): 0.001000\t TIME:6666.7s\n",
      "\t\t\t\tDisc: 0.644377\t\tSym: 10.783168\t\tSpars: 250.576096\n",
      "\t TVw: 0.263409 | TVb: -2.011728 | GSw: -0.235021 | GSb: 0.064849 | TSUw: 0.464772 | TSUb: 0.034949\n",
      "Validating epoch 2654...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 238.58631021725878\n",
      "Average validation loss: 42.078342175325574\n",
      "Training epoch 2655...\n",
      "\n",
      "Train Epoch: 2655 [0/8000 (0%)]\tBatch Loss: 250.771067\tLearning Rate (w_theta): 0.001000\t TIME:6669.1s\n",
      "\t\t\t\tDisc: 0.628465\t\tSym: 10.050638\t\tSpars: 240.091965\n",
      "\t TVw: 0.262773 | TVb: -2.011696 | GSw: -0.235021 | GSb: 0.064849 | TSUw: 0.464772 | TSUb: 0.034949\n",
      "\n",
      "Train Epoch: 2655 [4000/8000 (50%)]\tBatch Loss: 220.086709\tLearning Rate (w_theta): 0.001000\t TIME:6670.7s\n",
      "\t\t\t\tDisc: 0.548460\t\tSym: 8.179820\t\tSpars: 211.358429\n",
      "\t TVw: 0.261385 | TVb: -2.011731 | GSw: -0.235021 | GSb: 0.064849 | TSUw: 0.464772 | TSUb: 0.034950\n",
      "Validating epoch 2655...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 244.0717556294422\n",
      "Average validation loss: 42.54582208418788\n",
      "Training epoch 2656...\n",
      "\n",
      "Train Epoch: 2656 [0/8000 (0%)]\tBatch Loss: 235.640491\tLearning Rate (w_theta): 0.001000\t TIME:6673.2s\n",
      "\t\t\t\tDisc: 0.524602\t\tSym: 9.702711\t\tSpars: 225.413177\n",
      "\t TVw: 0.260267 | TVb: -2.011782 | GSw: -0.235021 | GSb: 0.064849 | TSUw: 0.464772 | TSUb: 0.034950\n",
      "\n",
      "Train Epoch: 2656 [4000/8000 (50%)]\tBatch Loss: 237.986564\tLearning Rate (w_theta): 0.001000\t TIME:6674.8s\n",
      "\t\t\t\tDisc: 0.496647\t\tSym: 10.220218\t\tSpars: 227.269699\n",
      "\t TVw: 0.260042 | TVb: -2.011769 | GSw: -0.235021 | GSb: 0.064848 | TSUw: 0.464772 | TSUb: 0.034950\n",
      "Validating epoch 2656...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 236.66442451113446\n",
      "Average validation loss: 41.770439264357925\n",
      "Training epoch 2657...\n",
      "\n",
      "Train Epoch: 2657 [0/8000 (0%)]\tBatch Loss: 223.897145\tLearning Rate (w_theta): 0.001000\t TIME:6677.3s\n",
      "\t\t\t\tDisc: 0.509402\t\tSym: 8.612841\t\tSpars: 214.774902\n",
      "\t TVw: 0.260807 | TVb: -2.011672 | GSw: -0.235021 | GSb: 0.064848 | TSUw: 0.464771 | TSUb: 0.034950\n",
      "\n",
      "Train Epoch: 2657 [4000/8000 (50%)]\tBatch Loss: 228.476533\tLearning Rate (w_theta): 0.001000\t TIME:6678.9s\n",
      "\t\t\t\tDisc: 0.527155\t\tSym: 9.070472\t\tSpars: 218.878906\n",
      "\t TVw: 0.262164 | TVb: -2.011529 | GSw: -0.235021 | GSb: 0.064848 | TSUw: 0.464771 | TSUb: 0.034951\n",
      "Validating epoch 2657...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 231.22845101577633\n",
      "Average validation loss: 41.88524173851834\n",
      "Training epoch 2658...\n",
      "\n",
      "Train Epoch: 2658 [0/8000 (0%)]\tBatch Loss: 234.244836\tLearning Rate (w_theta): 0.001000\t TIME:6681.4s\n",
      "\t\t\t\tDisc: 0.559444\t\tSym: 9.901655\t\tSpars: 223.783737\n",
      "\t TVw: 0.263631 | TVb: -2.011358 | GSw: -0.235022 | GSb: 0.064848 | TSUw: 0.464771 | TSUb: 0.034951\n",
      "\n",
      "Train Epoch: 2658 [4000/8000 (50%)]\tBatch Loss: 230.134241\tLearning Rate (w_theta): 0.001000\t TIME:6683.0s\n",
      "\t\t\t\tDisc: 0.584723\t\tSym: 9.260119\t\tSpars: 220.289398\n",
      "\t TVw: 0.264523 | TVb: -2.011211 | GSw: -0.235022 | GSb: 0.064847 | TSUw: 0.464771 | TSUb: 0.034951\n",
      "Validating epoch 2658...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 230.24007028976212\n",
      "Average validation loss: 43.826953170358216\n",
      "Training epoch 2659...\n",
      "\n",
      "Train Epoch: 2659 [0/8000 (0%)]\tBatch Loss: 228.188765\tLearning Rate (w_theta): 0.001000\t TIME:6685.5s\n",
      "\t\t\t\tDisc: 0.605526\t\tSym: 9.384768\t\tSpars: 218.198471\n",
      "\t TVw: 0.264986 | TVb: -2.011092 | GSw: -0.235022 | GSb: 0.064847 | TSUw: 0.464770 | TSUb: 0.034951\n",
      "\n",
      "Train Epoch: 2659 [4000/8000 (50%)]\tBatch Loss: 228.477830\tLearning Rate (w_theta): 0.001000\t TIME:6687.1s\n",
      "\t\t\t\tDisc: 0.601823\t\tSym: 9.660660\t\tSpars: 218.215347\n",
      "\t TVw: 0.264599 | TVb: -2.011024 | GSw: -0.235022 | GSb: 0.064847 | TSUw: 0.464770 | TSUb: 0.034952\n",
      "Validating epoch 2659...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 231.46603786607818\n",
      "Average validation loss: 41.15624763871005\n",
      "Training epoch 2660...\n",
      "\n",
      "Train Epoch: 2660 [0/8000 (0%)]\tBatch Loss: 235.820688\tLearning Rate (w_theta): 0.001000\t TIME:6689.6s\n",
      "\t\t\t\tDisc: 0.605839\t\tSym: 9.689733\t\tSpars: 225.525116\n",
      "\t TVw: 0.263756 | TVb: -2.010978 | GSw: -0.235022 | GSb: 0.064847 | TSUw: 0.464770 | TSUb: 0.034952\n",
      "\n",
      "Train Epoch: 2660 [4000/8000 (50%)]\tBatch Loss: 243.136947\tLearning Rate (w_theta): 0.001000\t TIME:6691.2s\n",
      "\t\t\t\tDisc: 0.573583\t\tSym: 9.659235\t\tSpars: 232.904129\n",
      "\t TVw: 0.262528 | TVb: -2.010965 | GSw: -0.235022 | GSb: 0.064846 | TSUw: 0.464770 | TSUb: 0.034952\n",
      "Validating epoch 2660...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 234.43191012103495\n",
      "Average validation loss: 40.98510070818658\n",
      "Training epoch 2661...\n",
      "\n",
      "Train Epoch: 2661 [0/8000 (0%)]\tBatch Loss: 222.102011\tLearning Rate (w_theta): 0.001000\t TIME:6694.4s\n",
      "\t\t\t\tDisc: 0.526915\t\tSym: 8.628043\t\tSpars: 212.947052\n",
      "\t TVw: 0.261366 | TVb: -2.010986 | GSw: -0.235022 | GSb: 0.064846 | TSUw: 0.464769 | TSUb: 0.034952\n",
      "\n",
      "Train Epoch: 2661 [4000/8000 (50%)]\tBatch Loss: 224.677315\tLearning Rate (w_theta): 0.001000\t TIME:6696.0s\n",
      "\t\t\t\tDisc: 0.519675\t\tSym: 9.111330\t\tSpars: 215.046310\n",
      "\t TVw: 0.260482 | TVb: -2.010997 | GSw: -0.235022 | GSb: 0.064846 | TSUw: 0.464769 | TSUb: 0.034952\n",
      "Validating epoch 2661...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 231.36878758377537\n",
      "Average validation loss: 40.419033632653885\n",
      "Training epoch 2662...\n",
      "\n",
      "Train Epoch: 2662 [0/8000 (0%)]\tBatch Loss: 228.005634\tLearning Rate (w_theta): 0.001000\t TIME:6698.4s\n",
      "\t\t\t\tDisc: 0.566113\t\tSym: 9.031226\t\tSpars: 218.408295\n",
      "\t TVw: 0.260492 | TVb: -2.010955 | GSw: -0.235022 | GSb: 0.064845 | TSUw: 0.464769 | TSUb: 0.034953\n",
      "\n",
      "Train Epoch: 2662 [4000/8000 (50%)]\tBatch Loss: 223.354753\tLearning Rate (w_theta): 0.001000\t TIME:6700.0s\n",
      "\t\t\t\tDisc: 0.584623\t\tSym: 8.906344\t\tSpars: 213.863785\n",
      "\t TVw: 0.261292 | TVb: -2.010862 | GSw: -0.235022 | GSb: 0.064845 | TSUw: 0.464769 | TSUb: 0.034953\n",
      "Validating epoch 2662...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 229.96221560503886\n",
      "Average validation loss: 41.633366471315895\n",
      "Training epoch 2663...\n",
      "\n",
      "Train Epoch: 2663 [0/8000 (0%)]\tBatch Loss: 234.397935\tLearning Rate (w_theta): 0.001000\t TIME:6702.5s\n",
      "\t\t\t\tDisc: 0.603817\t\tSym: 9.681722\t\tSpars: 224.112396\n",
      "\t TVw: 0.261811 | TVb: -2.010791 | GSw: -0.235023 | GSb: 0.064845 | TSUw: 0.464768 | TSUb: 0.034953\n",
      "\n",
      "Train Epoch: 2663 [4000/8000 (50%)]\tBatch Loss: 232.662596\tLearning Rate (w_theta): 0.001000\t TIME:6704.1s\n",
      "\t\t\t\tDisc: 0.559831\t\tSym: 10.107816\t\tSpars: 221.994949\n",
      "\t TVw: 0.262474 | TVb: -2.010702 | GSw: -0.235023 | GSb: 0.064845 | TSUw: 0.464768 | TSUb: 0.034953\n",
      "Validating epoch 2663...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 229.34810712700454\n",
      "Average validation loss: 40.00622163564504\n",
      "Training epoch 2664...\n",
      "\n",
      "Train Epoch: 2664 [0/8000 (0%)]\tBatch Loss: 224.600953\tLearning Rate (w_theta): 0.001000\t TIME:6706.6s\n",
      "\t\t\t\tDisc: 0.573465\t\tSym: 8.813712\t\tSpars: 215.213776\n",
      "\t TVw: 0.262812 | TVb: -2.010612 | GSw: -0.235023 | GSb: 0.064844 | TSUw: 0.464768 | TSUb: 0.034954\n",
      "\n",
      "Train Epoch: 2664 [4000/8000 (50%)]\tBatch Loss: 244.842040\tLearning Rate (w_theta): 0.001000\t TIME:6708.2s\n",
      "\t\t\t\tDisc: 0.588303\t\tSym: 10.935576\t\tSpars: 233.318161\n",
      "\t TVw: 0.262664 | TVb: -2.010526 | GSw: -0.235023 | GSb: 0.064844 | TSUw: 0.464768 | TSUb: 0.034954\n",
      "Validating epoch 2664...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 229.008808680168\n",
      "Average validation loss: 40.61675614851724\n",
      "Training epoch 2665...\n",
      "\n",
      "Train Epoch: 2665 [0/8000 (0%)]\tBatch Loss: 219.498633\tLearning Rate (w_theta): 0.001000\t TIME:6710.7s\n",
      "\t\t\t\tDisc: 0.560943\t\tSym: 9.009696\t\tSpars: 209.927994\n",
      "\t TVw: 0.262365 | TVb: -2.010467 | GSw: -0.235023 | GSb: 0.064844 | TSUw: 0.464767 | TSUb: 0.034954\n",
      "\n",
      "Train Epoch: 2665 [4000/8000 (50%)]\tBatch Loss: 232.698606\tLearning Rate (w_theta): 0.001000\t TIME:6712.3s\n",
      "\t\t\t\tDisc: 0.622238\t\tSym: 9.412396\t\tSpars: 222.663971\n",
      "\t TVw: 0.261677 | TVb: -2.010423 | GSw: -0.235023 | GSb: 0.064844 | TSUw: 0.464767 | TSUb: 0.034954\n",
      "Validating epoch 2665...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 227.9174857947994\n",
      "Average validation loss: 40.66158250035229\n",
      "Training epoch 2666...\n",
      "\n",
      "Train Epoch: 2666 [0/8000 (0%)]\tBatch Loss: 212.908108\tLearning Rate (w_theta): 0.001000\t TIME:6714.7s\n",
      "\t\t\t\tDisc: 0.628815\t\tSym: 8.128596\t\tSpars: 204.150696\n",
      "\t TVw: 0.261059 | TVb: -2.010387 | GSw: -0.235023 | GSb: 0.064843 | TSUw: 0.464767 | TSUb: 0.034954\n",
      "\n",
      "Train Epoch: 2666 [4000/8000 (50%)]\tBatch Loss: 235.018950\tLearning Rate (w_theta): 0.001000\t TIME:6716.3s\n",
      "\t\t\t\tDisc: 0.636518\t\tSym: 9.818574\t\tSpars: 224.563858\n",
      "\t TVw: 0.260652 | TVb: -2.010344 | GSw: -0.235023 | GSb: 0.064843 | TSUw: 0.464767 | TSUb: 0.034955\n",
      "Validating epoch 2666...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 227.4239278697769\n",
      "Average validation loss: 39.67942936351733\n",
      "Training epoch 2667...\n",
      "\n",
      "Train Epoch: 2667 [0/8000 (0%)]\tBatch Loss: 227.562234\tLearning Rate (w_theta): 0.001000\t TIME:6719.2s\n",
      "\t\t\t\tDisc: 0.548428\t\tSym: 9.654126\t\tSpars: 217.359680\n",
      "\t TVw: 0.260470 | TVb: -2.010289 | GSw: -0.235024 | GSb: 0.064843 | TSUw: 0.464767 | TSUb: 0.034955\n",
      "\n",
      "Train Epoch: 2667 [4000/8000 (50%)]\tBatch Loss: 218.956056\tLearning Rate (w_theta): 0.001000\t TIME:6720.8s\n",
      "\t\t\t\tDisc: 0.570965\t\tSym: 8.979451\t\tSpars: 209.405640\n",
      "\t TVw: 0.260721 | TVb: -2.010199 | GSw: -0.235024 | GSb: 0.064843 | TSUw: 0.464766 | TSUb: 0.034955\n",
      "Validating epoch 2667...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 227.11335199291076\n",
      "Average validation loss: 37.61751082330309\n",
      "Training epoch 2668...\n",
      "\n",
      "Train Epoch: 2668 [0/8000 (0%)]\tBatch Loss: 225.827563\tLearning Rate (w_theta): 0.001000\t TIME:6723.3s\n",
      "\t\t\t\tDisc: 0.603672\t\tSym: 9.227126\t\tSpars: 215.996765\n",
      "\t TVw: 0.260658 | TVb: -2.010123 | GSw: -0.235024 | GSb: 0.064842 | TSUw: 0.464766 | TSUb: 0.034955\n",
      "\n",
      "Train Epoch: 2668 [4000/8000 (50%)]\tBatch Loss: 217.721637\tLearning Rate (w_theta): 0.001000\t TIME:6724.9s\n",
      "\t\t\t\tDisc: 0.574542\t\tSym: 8.375443\t\tSpars: 208.771652\n",
      "\t TVw: 0.260209 | TVb: -2.010066 | GSw: -0.235024 | GSb: 0.064842 | TSUw: 0.464766 | TSUb: 0.034956\n",
      "Validating epoch 2668...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 226.00519036108534\n",
      "Average validation loss: 37.435739048151696\n",
      "Training epoch 2669...\n",
      "\n",
      "Train Epoch: 2669 [0/8000 (0%)]\tBatch Loss: 227.101225\tLearning Rate (w_theta): 0.001000\t TIME:6727.4s\n",
      "\t\t\t\tDisc: 0.549499\t\tSym: 9.657836\t\tSpars: 216.893890\n",
      "\t TVw: 0.259639 | TVb: -2.010014 | GSw: -0.235024 | GSb: 0.064842 | TSUw: 0.464766 | TSUb: 0.034956\n",
      "\n",
      "Train Epoch: 2669 [4000/8000 (50%)]\tBatch Loss: 214.701232\tLearning Rate (w_theta): 0.001000\t TIME:6729.0s\n",
      "\t\t\t\tDisc: 0.555424\t\tSym: 8.918787\t\tSpars: 205.227020\n",
      "\t TVw: 0.259633 | TVb: -2.009943 | GSw: -0.235024 | GSb: 0.064841 | TSUw: 0.464765 | TSUb: 0.034956\n",
      "Validating epoch 2669...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 224.04577948664\n",
      "Average validation loss: 38.6801147410203\n",
      "Training epoch 2670...\n",
      "\n",
      "Train Epoch: 2670 [0/8000 (0%)]\tBatch Loss: 224.679796\tLearning Rate (w_theta): 0.001000\t TIME:6731.5s\n",
      "\t\t\t\tDisc: 0.559501\t\tSym: 10.229548\t\tSpars: 213.890747\n",
      "\t TVw: 0.259767 | TVb: -2.009859 | GSw: -0.235024 | GSb: 0.064841 | TSUw: 0.464765 | TSUb: 0.034956\n",
      "\n",
      "Train Epoch: 2670 [4000/8000 (50%)]\tBatch Loss: 221.823970\tLearning Rate (w_theta): 0.001000\t TIME:6733.0s\n",
      "\t\t\t\tDisc: 0.574952\t\tSym: 9.003748\t\tSpars: 212.245270\n",
      "\t TVw: 0.259892 | TVb: -2.009763 | GSw: -0.235024 | GSb: 0.064841 | TSUw: 0.464765 | TSUb: 0.034956\n",
      "Validating epoch 2670...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 221.09147729938414\n",
      "Average validation loss: 39.318989398251425\n",
      "Training epoch 2671...\n",
      "\n",
      "Train Epoch: 2671 [0/8000 (0%)]\tBatch Loss: 229.392761\tLearning Rate (w_theta): 0.001000\t TIME:6736.2s\n",
      "\t\t\t\tDisc: 0.600324\t\tSym: 9.628757\t\tSpars: 219.163681\n",
      "\t TVw: 0.260149 | TVb: -2.009645 | GSw: -0.235024 | GSb: 0.064841 | TSUw: 0.464765 | TSUb: 0.034957\n",
      "\n",
      "Train Epoch: 2671 [4000/8000 (50%)]\tBatch Loss: 216.332714\tLearning Rate (w_theta): 0.001000\t TIME:6737.8s\n",
      "\t\t\t\tDisc: 0.594502\t\tSym: 8.783088\t\tSpars: 206.955124\n",
      "\t TVw: 0.260058 | TVb: -2.009561 | GSw: -0.235025 | GSb: 0.064840 | TSUw: 0.464764 | TSUb: 0.034957\n",
      "Validating epoch 2671...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 223.90660705382115\n",
      "Average validation loss: 36.57741243086045\n",
      "Training epoch 2672...\n",
      "\n",
      "Train Epoch: 2672 [0/8000 (0%)]\tBatch Loss: 238.703858\tLearning Rate (w_theta): 0.001000\t TIME:6740.3s\n",
      "\t\t\t\tDisc: 0.631597\t\tSym: 9.648982\t\tSpars: 228.423279\n",
      "\t TVw: 0.259369 | TVb: -2.009519 | GSw: -0.235025 | GSb: 0.064840 | TSUw: 0.464764 | TSUb: 0.034957\n",
      "\n",
      "Train Epoch: 2672 [4000/8000 (50%)]\tBatch Loss: 239.049990\tLearning Rate (w_theta): 0.001000\t TIME:6741.8s\n",
      "\t\t\t\tDisc: 0.637229\t\tSym: 10.221722\t\tSpars: 228.191040\n",
      "\t TVw: 0.258284 | TVb: -2.009503 | GSw: -0.235025 | GSb: 0.064840 | TSUw: 0.464764 | TSUb: 0.034957\n",
      "Validating epoch 2672...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 226.58048221580896\n",
      "Average validation loss: 35.89818022050398\n",
      "Training epoch 2673...\n",
      "\n",
      "Train Epoch: 2673 [0/8000 (0%)]\tBatch Loss: 233.928283\tLearning Rate (w_theta): 0.001000\t TIME:6744.3s\n",
      "\t\t\t\tDisc: 0.607138\t\tSym: 9.475137\t\tSpars: 223.846008\n",
      "\t TVw: 0.257101 | TVb: -2.009496 | GSw: -0.235025 | GSb: 0.064840 | TSUw: 0.464764 | TSUb: 0.034958\n",
      "\n",
      "Train Epoch: 2673 [4000/8000 (50%)]\tBatch Loss: 212.801290\tLearning Rate (w_theta): 0.001000\t TIME:6745.9s\n",
      "\t\t\t\tDisc: 0.524100\t\tSym: 8.879409\t\tSpars: 203.397781\n",
      "\t TVw: 0.255840 | TVb: -2.009506 | GSw: -0.235025 | GSb: 0.064839 | TSUw: 0.464763 | TSUb: 0.034958\n",
      "Validating epoch 2673...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 227.85378564875046\n",
      "Average validation loss: 35.40587508743007\n",
      "Training epoch 2674...\n",
      "\n",
      "Train Epoch: 2674 [0/8000 (0%)]\tBatch Loss: 227.167650\tLearning Rate (w_theta): 0.001000\t TIME:6748.4s\n",
      "\t\t\t\tDisc: 0.510865\t\tSym: 10.103806\t\tSpars: 216.552979\n",
      "\t TVw: 0.255281 | TVb: -2.009508 | GSw: -0.235025 | GSb: 0.064839 | TSUw: 0.464763 | TSUb: 0.034958\n",
      "\n",
      "Train Epoch: 2674 [4000/8000 (50%)]\tBatch Loss: 207.203120\tLearning Rate (w_theta): 0.001000\t TIME:6750.0s\n",
      "\t\t\t\tDisc: 0.498223\t\tSym: 8.185504\t\tSpars: 198.519394\n",
      "\t TVw: 0.256209 | TVb: -2.009404 | GSw: -0.235025 | GSb: 0.064839 | TSUw: 0.464763 | TSUb: 0.034958\n",
      "Validating epoch 2674...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 219.7951017864082\n",
      "Average validation loss: 36.02185370988394\n",
      "Training epoch 2675...\n",
      "\n",
      "Train Epoch: 2675 [0/8000 (0%)]\tBatch Loss: 223.606427\tLearning Rate (w_theta): 0.001000\t TIME:6752.5s\n",
      "\t\t\t\tDisc: 0.547376\t\tSym: 9.692825\t\tSpars: 213.366226\n",
      "\t TVw: 0.257879 | TVb: -2.009226 | GSw: -0.235025 | GSb: 0.064839 | TSUw: 0.464763 | TSUb: 0.034959\n",
      "\n",
      "Train Epoch: 2675 [4000/8000 (50%)]\tBatch Loss: 222.163941\tLearning Rate (w_theta): 0.001000\t TIME:6754.1s\n",
      "\t\t\t\tDisc: 0.566737\t\tSym: 9.637822\t\tSpars: 211.959381\n",
      "\t TVw: 0.259157 | TVb: -2.009071 | GSw: -0.235025 | GSb: 0.064838 | TSUw: 0.464762 | TSUb: 0.034959\n",
      "Validating epoch 2675...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 217.4205803385023\n",
      "Average validation loss: 37.96984505074923\n",
      "Training epoch 2676...\n",
      "\n",
      "Train Epoch: 2676 [0/8000 (0%)]\tBatch Loss: 208.144932\tLearning Rate (w_theta): 0.001000\t TIME:6756.6s\n",
      "\t\t\t\tDisc: 0.641573\t\tSym: 8.215045\t\tSpars: 199.288315\n",
      "\t TVw: 0.259854 | TVb: -2.008936 | GSw: -0.235026 | GSb: 0.064838 | TSUw: 0.464762 | TSUb: 0.034959\n",
      "\n",
      "Train Epoch: 2676 [4000/8000 (50%)]\tBatch Loss: 222.882543\tLearning Rate (w_theta): 0.001000\t TIME:6758.2s\n",
      "\t\t\t\tDisc: 0.633587\t\tSym: 9.473031\t\tSpars: 212.775925\n",
      "\t TVw: 0.259741 | TVb: -2.008864 | GSw: -0.235026 | GSb: 0.064838 | TSUw: 0.464762 | TSUb: 0.034959\n",
      "Validating epoch 2676...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 217.4740315901154\n",
      "Average validation loss: 37.216305300701535\n",
      "Training epoch 2677...\n",
      "\n",
      "Train Epoch: 2677 [0/8000 (0%)]\tBatch Loss: 208.302876\tLearning Rate (w_theta): 0.001000\t TIME:6760.7s\n",
      "\t\t\t\tDisc: 0.589287\t\tSym: 8.580319\t\tSpars: 199.133270\n",
      "\t TVw: 0.258865 | TVb: -2.008835 | GSw: -0.235026 | GSb: 0.064837 | TSUw: 0.464762 | TSUb: 0.034959\n",
      "\n",
      "Train Epoch: 2677 [4000/8000 (50%)]\tBatch Loss: 222.164936\tLearning Rate (w_theta): 0.001000\t TIME:6762.3s\n",
      "\t\t\t\tDisc: 0.611329\t\tSym: 9.863711\t\tSpars: 211.689896\n",
      "\t TVw: 0.258067 | TVb: -2.008787 | GSw: -0.235026 | GSb: 0.064837 | TSUw: 0.464762 | TSUb: 0.034960\n",
      "Validating epoch 2677...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 218.08117128961885\n",
      "Average validation loss: 36.749690897230096\n",
      "Training epoch 2678...\n",
      "\n",
      "Train Epoch: 2678 [0/8000 (0%)]\tBatch Loss: 208.377540\tLearning Rate (w_theta): 0.001000\t TIME:6764.8s\n",
      "\t\t\t\tDisc: 0.576634\t\tSym: 9.088336\t\tSpars: 198.712570\n",
      "\t TVw: 0.257352 | TVb: -2.008744 | GSw: -0.235026 | GSb: 0.064837 | TSUw: 0.464761 | TSUb: 0.034960\n",
      "\n",
      "Train Epoch: 2678 [4000/8000 (50%)]\tBatch Loss: 215.929309\tLearning Rate (w_theta): 0.001000\t TIME:6766.3s\n",
      "\t\t\t\tDisc: 0.632745\t\tSym: 9.299936\t\tSpars: 205.996628\n",
      "\t TVw: 0.256799 | TVb: -2.008695 | GSw: -0.235026 | GSb: 0.064837 | TSUw: 0.464761 | TSUb: 0.034960\n",
      "Validating epoch 2678...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 216.6458305907713\n",
      "Average validation loss: 36.65837008815973\n",
      "Training epoch 2679...\n",
      "\n",
      "Train Epoch: 2679 [0/8000 (0%)]\tBatch Loss: 209.996356\tLearning Rate (w_theta): 0.001000\t TIME:6768.8s\n",
      "\t\t\t\tDisc: 0.598115\t\tSym: 8.936968\t\tSpars: 200.461273\n",
      "\t TVw: 0.256317 | TVb: -2.008660 | GSw: -0.235026 | GSb: 0.064836 | TSUw: 0.464761 | TSUb: 0.034960\n",
      "\n",
      "Train Epoch: 2679 [4000/8000 (50%)]\tBatch Loss: 209.069958\tLearning Rate (w_theta): 0.001000\t TIME:6770.4s\n",
      "\t\t\t\tDisc: 0.567574\t\tSym: 8.978336\t\tSpars: 199.524048\n",
      "\t TVw: 0.255819 | TVb: -2.008609 | GSw: -0.235026 | GSb: 0.064836 | TSUw: 0.464761 | TSUb: 0.034961\n",
      "Validating epoch 2679...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 216.26622646968846\n",
      "Average validation loss: 34.34644455200003\n",
      "Training epoch 2680...\n",
      "\n",
      "Train Epoch: 2680 [0/8000 (0%)]\tBatch Loss: 219.167231\tLearning Rate (w_theta): 0.001000\t TIME:6772.9s\n",
      "\t\t\t\tDisc: 0.587518\t\tSym: 9.314073\t\tSpars: 209.265640\n",
      "\t TVw: 0.255407 | TVb: -2.008553 | GSw: -0.235027 | GSb: 0.064836 | TSUw: 0.464760 | TSUb: 0.034961\n",
      "\n",
      "Train Epoch: 2680 [4000/8000 (50%)]\tBatch Loss: 222.488761\tLearning Rate (w_theta): 0.001000\t TIME:6774.5s\n",
      "\t\t\t\tDisc: 0.593414\t\tSym: 9.404747\t\tSpars: 212.490601\n",
      "\t TVw: 0.255028 | TVb: -2.008494 | GSw: -0.235027 | GSb: 0.064836 | TSUw: 0.464760 | TSUb: 0.034961\n",
      "Validating epoch 2680...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 216.51957088095926\n",
      "Average validation loss: 34.262549648978606\n",
      "Training epoch 2681...\n",
      "\n",
      "Train Epoch: 2681 [0/8000 (0%)]\tBatch Loss: 218.839592\tLearning Rate (w_theta): 0.001000\t TIME:6778.1s\n",
      "\t\t\t\tDisc: 0.562578\t\tSym: 9.629950\t\tSpars: 208.647064\n",
      "\t TVw: 0.254715 | TVb: -2.008432 | GSw: -0.235027 | GSb: 0.064835 | TSUw: 0.464760 | TSUb: 0.034961\n",
      "\n",
      "Train Epoch: 2681 [4000/8000 (50%)]\tBatch Loss: 204.411083\tLearning Rate (w_theta): 0.001000\t TIME:6779.7s\n",
      "\t\t\t\tDisc: 0.554501\t\tSym: 8.585860\t\tSpars: 195.270721\n",
      "\t TVw: 0.254627 | TVb: -2.008377 | GSw: -0.235027 | GSb: 0.064835 | TSUw: 0.464760 | TSUb: 0.034961\n",
      "Validating epoch 2681...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 218.81554085403013\n",
      "Average validation loss: 34.58122767122484\n",
      "Training epoch 2682...\n",
      "\n",
      "Train Epoch: 2682 [0/8000 (0%)]\tBatch Loss: 205.846179\tLearning Rate (w_theta): 0.001000\t TIME:6782.1s\n",
      "\t\t\t\tDisc: 0.533481\t\tSym: 8.738937\t\tSpars: 196.573761\n",
      "\t TVw: 0.254470 | TVb: -2.008328 | GSw: -0.235027 | GSb: 0.064835 | TSUw: 0.464759 | TSUb: 0.034962\n",
      "\n",
      "Train Epoch: 2682 [4000/8000 (50%)]\tBatch Loss: 210.643201\tLearning Rate (w_theta): 0.001000\t TIME:6783.7s\n",
      "\t\t\t\tDisc: 0.556796\t\tSym: 9.062876\t\tSpars: 201.023529\n",
      "\t TVw: 0.254029 | TVb: -2.008294 | GSw: -0.235027 | GSb: 0.064835 | TSUw: 0.464759 | TSUb: 0.034962\n",
      "Validating epoch 2682...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 219.96141615879608\n",
      "Average validation loss: 33.50331867729557\n",
      "Training epoch 2683...\n",
      "\n",
      "Train Epoch: 2683 [0/8000 (0%)]\tBatch Loss: 226.420944\tLearning Rate (w_theta): 0.001000\t TIME:6786.3s\n",
      "\t\t\t\tDisc: 0.537271\t\tSym: 11.394171\t\tSpars: 214.489502\n",
      "\t TVw: 0.253398 | TVb: -2.008290 | GSw: -0.235027 | GSb: 0.064834 | TSUw: 0.464759 | TSUb: 0.034962\n",
      "\n",
      "Train Epoch: 2683 [4000/8000 (50%)]\tBatch Loss: 207.889226\tLearning Rate (w_theta): 0.001000\t TIME:6787.9s\n",
      "\t\t\t\tDisc: 0.553797\t\tSym: 8.802806\t\tSpars: 198.532623\n",
      "\t TVw: 0.253074 | TVb: -2.008291 | GSw: -0.235027 | GSb: 0.064834 | TSUw: 0.464759 | TSUb: 0.034962\n",
      "Validating epoch 2683...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 216.56949550819024\n",
      "Average validation loss: 33.023374266801774\n",
      "Training epoch 2684...\n",
      "\n",
      "Train Epoch: 2684 [0/8000 (0%)]\tBatch Loss: 225.148766\tLearning Rate (w_theta): 0.001000\t TIME:6790.4s\n",
      "\t\t\t\tDisc: 0.559843\t\tSym: 10.435634\t\tSpars: 214.153290\n",
      "\t TVw: 0.253766 | TVb: -2.008214 | GSw: -0.235028 | GSb: 0.064834 | TSUw: 0.464758 | TSUb: 0.034963\n",
      "\n",
      "Train Epoch: 2684 [4000/8000 (50%)]\tBatch Loss: 218.789154\tLearning Rate (w_theta): 0.001000\t TIME:6792.0s\n",
      "\t\t\t\tDisc: 0.549134\t\tSym: 9.682799\t\tSpars: 208.557220\n",
      "\t TVw: 0.255276 | TVb: -2.008066 | GSw: -0.235028 | GSb: 0.064833 | TSUw: 0.464758 | TSUb: 0.034963\n",
      "Validating epoch 2684...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 213.09195636158142\n",
      "Average validation loss: 33.904261702913836\n",
      "Training epoch 2685...\n",
      "\n",
      "Train Epoch: 2685 [0/8000 (0%)]\tBatch Loss: 200.687931\tLearning Rate (w_theta): 0.001000\t TIME:6794.4s\n",
      "\t\t\t\tDisc: 0.587850\t\tSym: 8.316054\t\tSpars: 191.784027\n",
      "\t TVw: 0.256853 | TVb: -2.007895 | GSw: -0.235028 | GSb: 0.064833 | TSUw: 0.464758 | TSUb: 0.034963\n",
      "\n",
      "Train Epoch: 2685 [4000/8000 (50%)]\tBatch Loss: 209.542306\tLearning Rate (w_theta): 0.001000\t TIME:6796.0s\n",
      "\t\t\t\tDisc: 0.603970\t\tSym: 9.102139\t\tSpars: 199.836197\n",
      "\t TVw: 0.257641 | TVb: -2.007748 | GSw: -0.235028 | GSb: 0.064833 | TSUw: 0.464758 | TSUb: 0.034963\n",
      "Validating epoch 2685...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 209.95105641233275\n",
      "Average validation loss: 34.697821185791454\n",
      "Training epoch 2686...\n",
      "\n",
      "Train Epoch: 2686 [0/8000 (0%)]\tBatch Loss: 202.739601\tLearning Rate (w_theta): 0.001000\t TIME:6798.5s\n",
      "\t\t\t\tDisc: 0.631684\t\tSym: 8.787513\t\tSpars: 193.320404\n",
      "\t TVw: 0.257867 | TVb: -2.007635 | GSw: -0.235028 | GSb: 0.064833 | TSUw: 0.464757 | TSUb: 0.034964\n",
      "\n",
      "Train Epoch: 2686 [4000/8000 (50%)]\tBatch Loss: 212.512611\tLearning Rate (w_theta): 0.001000\t TIME:6800.1s\n",
      "\t\t\t\tDisc: 0.633206\t\tSym: 9.639888\t\tSpars: 202.239517\n",
      "\t TVw: 0.257310 | TVb: -2.007585 | GSw: -0.235028 | GSb: 0.064832 | TSUw: 0.464757 | TSUb: 0.034964\n",
      "Validating epoch 2686...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 209.54347336913608\n",
      "Average validation loss: 34.767593100608956\n",
      "Training epoch 2687...\n",
      "\n",
      "Train Epoch: 2687 [0/8000 (0%)]\tBatch Loss: 210.441126\tLearning Rate (w_theta): 0.001000\t TIME:6802.7s\n",
      "\t\t\t\tDisc: 0.635515\t\tSym: 9.868538\t\tSpars: 199.937073\n",
      "\t TVw: 0.256331 | TVb: -2.007560 | GSw: -0.235028 | GSb: 0.064832 | TSUw: 0.464757 | TSUb: 0.034964\n",
      "\n",
      "Train Epoch: 2687 [4000/8000 (50%)]\tBatch Loss: 210.063409\tLearning Rate (w_theta): 0.001000\t TIME:6804.3s\n",
      "\t\t\t\tDisc: 0.599744\t\tSym: 9.219021\t\tSpars: 200.244644\n",
      "\t TVw: 0.255429 | TVb: -2.007522 | GSw: -0.235028 | GSb: 0.064832 | TSUw: 0.464757 | TSUb: 0.034964\n",
      "Validating epoch 2687...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 206.89299194380717\n",
      "Average validation loss: 34.072460301758504\n",
      "Training epoch 2688...\n",
      "\n",
      "Train Epoch: 2688 [0/8000 (0%)]\tBatch Loss: 209.141761\tLearning Rate (w_theta): 0.001000\t TIME:6806.8s\n",
      "\t\t\t\tDisc: 0.593219\t\tSym: 9.203556\t\tSpars: 199.344986\n",
      "\t TVw: 0.254905 | TVb: -2.007464 | GSw: -0.235028 | GSb: 0.064832 | TSUw: 0.464757 | TSUb: 0.034964\n",
      "\n",
      "Train Epoch: 2688 [4000/8000 (50%)]\tBatch Loss: 206.637984\tLearning Rate (w_theta): 0.001000\t TIME:6808.4s\n",
      "\t\t\t\tDisc: 0.584342\t\tSym: 9.070824\t\tSpars: 196.982819\n",
      "\t TVw: 0.254883 | TVb: -2.007368 | GSw: -0.235028 | GSb: 0.064831 | TSUw: 0.464756 | TSUb: 0.034965\n",
      "Validating epoch 2688...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 205.76882529330476\n",
      "Average validation loss: 33.82628991680796\n",
      "Training epoch 2689...\n",
      "\n",
      "Train Epoch: 2689 [0/8000 (0%)]\tBatch Loss: 211.431232\tLearning Rate (w_theta): 0.001000\t TIME:6810.9s\n",
      "\t\t\t\tDisc: 0.590821\t\tSym: 9.920657\t\tSpars: 200.919754\n",
      "\t TVw: 0.254828 | TVb: -2.007274 | GSw: -0.235028 | GSb: 0.064831 | TSUw: 0.464756 | TSUb: 0.034965\n",
      "\n",
      "Train Epoch: 2689 [4000/8000 (50%)]\tBatch Loss: 195.883966\tLearning Rate (w_theta): 0.001000\t TIME:6812.5s\n",
      "\t\t\t\tDisc: 0.592353\t\tSym: 8.371203\t\tSpars: 186.920410\n",
      "\t TVw: 0.254666 | TVb: -2.007201 | GSw: -0.235029 | GSb: 0.064831 | TSUw: 0.464756 | TSUb: 0.034965\n",
      "Validating epoch 2689...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 205.45042561497675\n",
      "Average validation loss: 33.5146658247501\n",
      "Training epoch 2690...\n",
      "\n",
      "Train Epoch: 2690 [0/8000 (0%)]\tBatch Loss: 204.904619\tLearning Rate (w_theta): 0.001000\t TIME:6814.9s\n",
      "\t\t\t\tDisc: 0.602259\t\tSym: 8.818809\t\tSpars: 195.483551\n",
      "\t TVw: 0.254315 | TVb: -2.007135 | GSw: -0.235029 | GSb: 0.064831 | TSUw: 0.464756 | TSUb: 0.034965\n",
      "\n",
      "Train Epoch: 2690 [4000/8000 (50%)]\tBatch Loss: 202.577843\tLearning Rate (w_theta): 0.001000\t TIME:6816.5s\n",
      "\t\t\t\tDisc: 0.613449\t\tSym: 9.207253\t\tSpars: 192.757141\n",
      "\t TVw: 0.253524 | TVb: -2.007116 | GSw: -0.235029 | GSb: 0.064830 | TSUw: 0.464755 | TSUb: 0.034965\n",
      "Validating epoch 2690...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 206.84994395395032\n",
      "Average validation loss: 33.85645953421599\n",
      "Training epoch 2691...\n",
      "\n",
      "Train Epoch: 2691 [0/8000 (0%)]\tBatch Loss: 224.345608\tLearning Rate (w_theta): 0.001000\t TIME:6819.7s\n",
      "\t\t\t\tDisc: 0.638856\t\tSym: 10.969813\t\tSpars: 212.736938\n",
      "\t TVw: 0.252678 | TVb: -2.007108 | GSw: -0.235029 | GSb: 0.064830 | TSUw: 0.464755 | TSUb: 0.034966\n",
      "\n",
      "Train Epoch: 2691 [4000/8000 (50%)]\tBatch Loss: 208.795331\tLearning Rate (w_theta): 0.001000\t TIME:6821.3s\n",
      "\t\t\t\tDisc: 0.558082\t\tSym: 9.956792\t\tSpars: 198.280457\n",
      "\t TVw: 0.252092 | TVb: -2.007068 | GSw: -0.235029 | GSb: 0.064830 | TSUw: 0.464755 | TSUb: 0.034966\n",
      "Validating epoch 2691...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 205.76303661684014\n",
      "Average validation loss: 32.204365802211086\n",
      "Training epoch 2692...\n",
      "\n",
      "Train Epoch: 2692 [0/8000 (0%)]\tBatch Loss: 206.111755\tLearning Rate (w_theta): 0.001000\t TIME:6823.8s\n",
      "\t\t\t\tDisc: 0.596563\t\tSym: 9.416895\t\tSpars: 196.098297\n",
      "\t TVw: 0.252027 | TVb: -2.006994 | GSw: -0.235029 | GSb: 0.064830 | TSUw: 0.464755 | TSUb: 0.034966\n",
      "\n",
      "Train Epoch: 2692 [4000/8000 (50%)]\tBatch Loss: 206.457132\tLearning Rate (w_theta): 0.001000\t TIME:6825.4s\n",
      "\t\t\t\tDisc: 0.599494\t\tSym: 9.016680\t\tSpars: 196.840958\n",
      "\t TVw: 0.251983 | TVb: -2.006926 | GSw: -0.235029 | GSb: 0.064829 | TSUw: 0.464754 | TSUb: 0.034966\n",
      "Validating epoch 2692...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 204.46655226049253\n",
      "Average validation loss: 32.747930976986865\n",
      "Training epoch 2693...\n",
      "\n",
      "Train Epoch: 2693 [0/8000 (0%)]\tBatch Loss: 202.555860\tLearning Rate (w_theta): 0.001000\t TIME:6827.9s\n",
      "\t\t\t\tDisc: 0.592043\t\tSym: 9.141200\t\tSpars: 192.822617\n",
      "\t TVw: 0.252053 | TVb: -2.006870 | GSw: -0.235029 | GSb: 0.064829 | TSUw: 0.464754 | TSUb: 0.034967\n",
      "\n",
      "Train Epoch: 2693 [4000/8000 (50%)]\tBatch Loss: 214.503179\tLearning Rate (w_theta): 0.001000\t TIME:6829.5s\n",
      "\t\t\t\tDisc: 0.573298\t\tSym: 10.342921\t\tSpars: 203.586960\n",
      "\t TVw: 0.252388 | TVb: -2.006779 | GSw: -0.235029 | GSb: 0.064829 | TSUw: 0.464754 | TSUb: 0.034967\n",
      "Validating epoch 2693...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 202.00403000312855\n",
      "Average validation loss: 32.88411948995858\n",
      "Training epoch 2694...\n",
      "\n",
      "Train Epoch: 2694 [0/8000 (0%)]\tBatch Loss: 196.693517\tLearning Rate (w_theta): 0.001000\t TIME:6832.5s\n",
      "\t\t\t\tDisc: 0.591573\t\tSym: 8.971786\t\tSpars: 187.130157\n",
      "\t TVw: 0.252934 | TVb: -2.006678 | GSw: -0.235029 | GSb: 0.064829 | TSUw: 0.464754 | TSUb: 0.034967\n",
      "\n",
      "Train Epoch: 2694 [4000/8000 (50%)]\tBatch Loss: 203.703426\tLearning Rate (w_theta): 0.001000\t TIME:6834.1s\n",
      "\t\t\t\tDisc: 0.604644\t\tSym: 9.441021\t\tSpars: 193.657761\n",
      "\t TVw: 0.253397 | TVb: -2.006591 | GSw: -0.235029 | GSb: 0.064828 | TSUw: 0.464753 | TSUb: 0.034967\n",
      "Validating epoch 2694...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 201.71154536860095\n",
      "Average validation loss: 32.61523152295208\n",
      "Training epoch 2695...\n",
      "\n",
      "Train Epoch: 2695 [0/8000 (0%)]\tBatch Loss: 206.496032\tLearning Rate (w_theta): 0.001000\t TIME:6836.6s\n",
      "\t\t\t\tDisc: 0.622744\t\tSym: 9.838666\t\tSpars: 196.034622\n",
      "\t TVw: 0.253503 | TVb: -2.006508 | GSw: -0.235029 | GSb: 0.064828 | TSUw: 0.464753 | TSUb: 0.034967\n",
      "\n",
      "Train Epoch: 2695 [4000/8000 (50%)]\tBatch Loss: 196.412220\tLearning Rate (w_theta): 0.001000\t TIME:6838.2s\n",
      "\t\t\t\tDisc: 0.629781\t\tSym: 8.681914\t\tSpars: 187.100525\n",
      "\t TVw: 0.253148 | TVb: -2.006476 | GSw: -0.235029 | GSb: 0.064828 | TSUw: 0.464753 | TSUb: 0.034968\n",
      "Validating epoch 2695...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 201.56927025476418\n",
      "Average validation loss: 32.741889310628785\n",
      "Training epoch 2696...\n",
      "\n",
      "Train Epoch: 2696 [0/8000 (0%)]\tBatch Loss: 200.782512\tLearning Rate (w_theta): 0.001000\t TIME:6840.7s\n",
      "\t\t\t\tDisc: 0.609809\t\tSym: 9.129186\t\tSpars: 191.043518\n",
      "\t TVw: 0.252719 | TVb: -2.006444 | GSw: -0.235029 | GSb: 0.064828 | TSUw: 0.464753 | TSUb: 0.034968\n",
      "\n",
      "Train Epoch: 2696 [4000/8000 (50%)]\tBatch Loss: 199.616554\tLearning Rate (w_theta): 0.001000\t TIME:6842.3s\n",
      "\t\t\t\tDisc: 0.595591\t\tSym: 8.738004\t\tSpars: 190.282959\n",
      "\t TVw: 0.252336 | TVb: -2.006402 | GSw: -0.235029 | GSb: 0.064827 | TSUw: 0.464752 | TSUb: 0.034968\n",
      "Validating epoch 2696...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 201.30456184604714\n",
      "Average validation loss: 32.17699031821425\n",
      "Training epoch 2697...\n",
      "\n",
      "Train Epoch: 2697 [0/8000 (0%)]\tBatch Loss: 196.056085\tLearning Rate (w_theta): 0.001000\t TIME:6844.8s\n",
      "\t\t\t\tDisc: 0.595378\t\tSym: 9.742521\t\tSpars: 185.718185\n",
      "\t TVw: 0.252189 | TVb: -2.006347 | GSw: -0.235030 | GSb: 0.064827 | TSUw: 0.464752 | TSUb: 0.034968\n",
      "\n",
      "Train Epoch: 2697 [4000/8000 (50%)]\tBatch Loss: 204.625890\tLearning Rate (w_theta): 0.001000\t TIME:6846.4s\n",
      "\t\t\t\tDisc: 0.599153\t\tSym: 9.402241\t\tSpars: 194.624496\n",
      "\t TVw: 0.252290 | TVb: -2.006276 | GSw: -0.235030 | GSb: 0.064827 | TSUw: 0.464752 | TSUb: 0.034969\n",
      "Validating epoch 2697...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 199.07732082981585\n",
      "Average validation loss: 31.91183737116451\n",
      "Training epoch 2698...\n",
      "\n",
      "Train Epoch: 2698 [0/8000 (0%)]\tBatch Loss: 189.107768\tLearning Rate (w_theta): 0.001000\t TIME:6848.9s\n",
      "\t\t\t\tDisc: 0.596318\t\tSym: 8.519828\t\tSpars: 179.991623\n",
      "\t TVw: 0.252570 | TVb: -2.006193 | GSw: -0.235030 | GSb: 0.064827 | TSUw: 0.464752 | TSUb: 0.034969\n",
      "\n",
      "Train Epoch: 2698 [4000/8000 (50%)]\tBatch Loss: 202.930418\tLearning Rate (w_theta): 0.001000\t TIME:6850.8s\n",
      "\t\t\t\tDisc: 0.646723\t\tSym: 9.202793\t\tSpars: 193.080902\n",
      "\t TVw: 0.252832 | TVb: -2.006112 | GSw: -0.235030 | GSb: 0.064826 | TSUw: 0.464752 | TSUb: 0.034969\n",
      "Validating epoch 2698...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 200.12703924363908\n",
      "Average validation loss: 32.473076024522946\n",
      "Training epoch 2699...\n",
      "\n",
      "Train Epoch: 2699 [0/8000 (0%)]\tBatch Loss: 196.429659\tLearning Rate (w_theta): 0.001000\t TIME:6853.3s\n",
      "\t\t\t\tDisc: 0.596822\t\tSym: 8.497052\t\tSpars: 187.335785\n",
      "\t TVw: 0.252825 | TVb: -2.006072 | GSw: -0.235030 | GSb: 0.064826 | TSUw: 0.464751 | TSUb: 0.034969\n",
      "\n",
      "Train Epoch: 2699 [4000/8000 (50%)]\tBatch Loss: 201.052890\tLearning Rate (w_theta): 0.001000\t TIME:6854.9s\n",
      "\t\t\t\tDisc: 0.617321\t\tSym: 9.560782\t\tSpars: 190.874786\n",
      "\t TVw: 0.252433 | TVb: -2.006050 | GSw: -0.235030 | GSb: 0.064826 | TSUw: 0.464751 | TSUb: 0.034969\n",
      "Validating epoch 2699...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 200.9805829770519\n",
      "Average validation loss: 31.160596777783024\n",
      "Training epoch 2700...\n",
      "\n",
      "Train Epoch: 2700 [0/8000 (0%)]\tBatch Loss: 201.059270\tLearning Rate (w_theta): 0.001000\t TIME:6857.3s\n",
      "\t\t\t\tDisc: 0.602099\t\tSym: 9.567889\t\tSpars: 190.889282\n",
      "\t TVw: 0.252098 | TVb: -2.006006 | GSw: -0.235030 | GSb: 0.064825 | TSUw: 0.464751 | TSUb: 0.034970\n",
      "\n",
      "Train Epoch: 2700 [4000/8000 (50%)]\tBatch Loss: 193.484537\tLearning Rate (w_theta): 0.001000\t TIME:6858.9s\n",
      "\t\t\t\tDisc: 0.605075\t\tSym: 8.540092\t\tSpars: 184.339371\n",
      "\t TVw: 0.252300 | TVb: -2.005948 | GSw: -0.235030 | GSb: 0.064825 | TSUw: 0.464751 | TSUb: 0.034970\n",
      "Validating epoch 2700...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 197.4274000188595\n",
      "Average validation loss: 31.872652666723198\n",
      "Training epoch 2701...\n",
      "\n",
      "Train Epoch: 2701 [0/8000 (0%)]\tBatch Loss: 198.386602\tLearning Rate (w_theta): 0.001000\t TIME:6862.1s\n",
      "\t\t\t\tDisc: 0.633459\t\tSym: 9.313125\t\tSpars: 188.440018\n",
      "\t TVw: 0.252559 | TVb: -2.005876 | GSw: -0.235030 | GSb: 0.064825 | TSUw: 0.464750 | TSUb: 0.034970\n",
      "\n",
      "Train Epoch: 2701 [4000/8000 (50%)]\tBatch Loss: 196.081750\tLearning Rate (w_theta): 0.001000\t TIME:6863.7s\n",
      "\t\t\t\tDisc: 0.602440\t\tSym: 9.135392\t\tSpars: 186.343918\n",
      "\t TVw: 0.252872 | TVb: -2.005804 | GSw: -0.235030 | GSb: 0.064825 | TSUw: 0.464750 | TSUb: 0.034970\n",
      "Validating epoch 2701...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 197.2183311716527\n",
      "Average validation loss: 31.482540444092894\n",
      "Training epoch 2702...\n",
      "\n",
      "Train Epoch: 2702 [0/8000 (0%)]\tBatch Loss: 188.235271\tLearning Rate (w_theta): 0.001000\t TIME:6866.2s\n",
      "\t\t\t\tDisc: 0.625204\t\tSym: 8.498098\t\tSpars: 179.111969\n",
      "\t TVw: 0.253182 | TVb: -2.005725 | GSw: -0.235030 | GSb: 0.064824 | TSUw: 0.464750 | TSUb: 0.034971\n",
      "\n",
      "Train Epoch: 2702 [4000/8000 (50%)]\tBatch Loss: 190.262923\tLearning Rate (w_theta): 0.001000\t TIME:6867.8s\n",
      "\t\t\t\tDisc: 0.609140\t\tSym: 9.075429\t\tSpars: 180.578354\n",
      "\t TVw: 0.253528 | TVb: -2.005640 | GSw: -0.235030 | GSb: 0.064824 | TSUw: 0.464750 | TSUb: 0.034971\n",
      "Validating epoch 2702...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 194.75659848887005\n",
      "Average validation loss: 32.01604363374506\n",
      "Training epoch 2703...\n",
      "\n",
      "Train Epoch: 2703 [0/8000 (0%)]\tBatch Loss: 196.303068\tLearning Rate (w_theta): 0.001000\t TIME:6870.3s\n",
      "\t\t\t\tDisc: 0.629894\t\tSym: 9.629092\t\tSpars: 186.044083\n",
      "\t TVw: 0.254002 | TVb: -2.005550 | GSw: -0.235030 | GSb: 0.064824 | TSUw: 0.464749 | TSUb: 0.034971\n",
      "\n",
      "Train Epoch: 2703 [4000/8000 (50%)]\tBatch Loss: 198.712746\tLearning Rate (w_theta): 0.001000\t TIME:6871.8s\n",
      "\t\t\t\tDisc: 0.622578\t\tSym: 8.861149\t\tSpars: 189.229019\n",
      "\t TVw: 0.254289 | TVb: -2.005475 | GSw: -0.235030 | GSb: 0.064824 | TSUw: 0.464749 | TSUb: 0.034971\n",
      "Validating epoch 2703...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 194.1147026535529\n",
      "Average validation loss: 32.31178725224103\n",
      "Training epoch 2704...\n",
      "\n",
      "Train Epoch: 2704 [0/8000 (0%)]\tBatch Loss: 206.087095\tLearning Rate (w_theta): 0.001000\t TIME:6874.3s\n",
      "\t\t\t\tDisc: 0.664799\t\tSym: 10.583612\t\tSpars: 194.838684\n",
      "\t TVw: 0.254207 | TVb: -2.005419 | GSw: -0.235030 | GSb: 0.064823 | TSUw: 0.464749 | TSUb: 0.034971\n",
      "\n",
      "Train Epoch: 2704 [4000/8000 (50%)]\tBatch Loss: 207.092366\tLearning Rate (w_theta): 0.001000\t TIME:6875.9s\n",
      "\t\t\t\tDisc: 0.645478\t\tSym: 10.605808\t\tSpars: 195.841080\n",
      "\t TVw: 0.253938 | TVb: -2.005358 | GSw: -0.235031 | GSb: 0.064823 | TSUw: 0.464749 | TSUb: 0.034972\n",
      "Validating epoch 2704...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 193.54503133431447\n",
      "Average validation loss: 31.693806604259972\n",
      "Training epoch 2705...\n",
      "\n",
      "Train Epoch: 2705 [0/8000 (0%)]\tBatch Loss: 183.394881\tLearning Rate (w_theta): 0.001000\t TIME:6878.4s\n",
      "\t\t\t\tDisc: 0.629663\t\tSym: 8.344335\t\tSpars: 174.420883\n",
      "\t TVw: 0.253715 | TVb: -2.005312 | GSw: -0.235031 | GSb: 0.064823 | TSUw: 0.464748 | TSUb: 0.034972\n",
      "\n",
      "Train Epoch: 2705 [4000/8000 (50%)]\tBatch Loss: 193.652445\tLearning Rate (w_theta): 0.001000\t TIME:6880.0s\n",
      "\t\t\t\tDisc: 0.632576\t\tSym: 9.239917\t\tSpars: 183.779953\n",
      "\t TVw: 0.253655 | TVb: -2.005252 | GSw: -0.235031 | GSb: 0.064823 | TSUw: 0.464748 | TSUb: 0.034972\n",
      "Validating epoch 2705...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 192.30634264752456\n",
      "Average validation loss: 31.994992567276842\n",
      "Training epoch 2706...\n",
      "\n",
      "Train Epoch: 2706 [0/8000 (0%)]\tBatch Loss: 202.327709\tLearning Rate (w_theta): 0.001000\t TIME:6882.5s\n",
      "\t\t\t\tDisc: 0.684947\t\tSym: 10.276155\t\tSpars: 191.366608\n",
      "\t TVw: 0.253707 | TVb: -2.005185 | GSw: -0.235031 | GSb: 0.064823 | TSUw: 0.464748 | TSUb: 0.034972\n",
      "\n",
      "Train Epoch: 2706 [4000/8000 (50%)]\tBatch Loss: 196.867394\tLearning Rate (w_theta): 0.001000\t TIME:6884.1s\n",
      "\t\t\t\tDisc: 0.636293\t\tSym: 9.585944\t\tSpars: 186.645157\n",
      "\t TVw: 0.253491 | TVb: -2.005131 | GSw: -0.235031 | GSb: 0.064822 | TSUw: 0.464748 | TSUb: 0.034972\n",
      "Validating epoch 2706...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 192.82779712409786\n",
      "Average validation loss: 31.460872014746837\n",
      "Training epoch 2707...\n",
      "\n",
      "Train Epoch: 2707 [0/8000 (0%)]\tBatch Loss: 198.787768\tLearning Rate (w_theta): 0.001000\t TIME:6886.6s\n",
      "\t\t\t\tDisc: 0.624885\t\tSym: 9.637691\t\tSpars: 188.525192\n",
      "\t TVw: 0.253288 | TVb: -2.005088 | GSw: -0.235031 | GSb: 0.064822 | TSUw: 0.464747 | TSUb: 0.034973\n",
      "\n",
      "Train Epoch: 2707 [4000/8000 (50%)]\tBatch Loss: 196.361606\tLearning Rate (w_theta): 0.001000\t TIME:6888.2s\n",
      "\t\t\t\tDisc: 0.650566\t\tSym: 10.011028\t\tSpars: 185.700012\n",
      "\t TVw: 0.253080 | TVb: -2.005031 | GSw: -0.235031 | GSb: 0.064822 | TSUw: 0.464747 | TSUb: 0.034973\n",
      "Validating epoch 2707...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 192.83436405977608\n",
      "Average validation loss: 32.05266852884414\n",
      "Training epoch 2708...\n",
      "\n",
      "Train Epoch: 2708 [0/8000 (0%)]\tBatch Loss: 193.106100\tLearning Rate (w_theta): 0.001000\t TIME:6890.7s\n",
      "\t\t\t\tDisc: 0.744651\t\tSym: 8.748717\t\tSpars: 183.612732\n",
      "\t TVw: 0.252891 | TVb: -2.004993 | GSw: -0.235031 | GSb: 0.064822 | TSUw: 0.464747 | TSUb: 0.034973\n",
      "\n",
      "Train Epoch: 2708 [4000/8000 (50%)]\tBatch Loss: 215.655144\tLearning Rate (w_theta): 0.001000\t TIME:6892.3s\n",
      "\t\t\t\tDisc: 0.782747\t\tSym: 10.120337\t\tSpars: 204.752060\n",
      "\t TVw: 0.252190 | TVb: -2.004984 | GSw: -0.235031 | GSb: 0.064821 | TSUw: 0.464747 | TSUb: 0.034973\n",
      "Validating epoch 2708...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 199.4869896055082\n",
      "Average validation loss: 31.756885833634065\n",
      "Training epoch 2709...\n",
      "\n",
      "Train Epoch: 2709 [0/8000 (0%)]\tBatch Loss: 210.910674\tLearning Rate (w_theta): 0.001000\t TIME:6895.2s\n",
      "\t\t\t\tDisc: 0.745781\t\tSym: 9.897132\t\tSpars: 200.267761\n",
      "\t TVw: 0.251253 | TVb: -2.004990 | GSw: -0.235031 | GSb: 0.064821 | TSUw: 0.464747 | TSUb: 0.034974\n",
      "\n",
      "Train Epoch: 2709 [4000/8000 (50%)]\tBatch Loss: 207.235428\tLearning Rate (w_theta): 0.001000\t TIME:6896.8s\n",
      "\t\t\t\tDisc: 0.696621\t\tSym: 10.138020\t\tSpars: 196.400787\n",
      "\t TVw: 0.250422 | TVb: -2.004989 | GSw: -0.235031 | GSb: 0.064821 | TSUw: 0.464746 | TSUb: 0.034974\n",
      "Validating epoch 2709...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 201.4482634347953\n",
      "Average validation loss: 30.015733070990503\n",
      "Training epoch 2710...\n",
      "\n",
      "Train Epoch: 2710 [0/8000 (0%)]\tBatch Loss: 194.442794\tLearning Rate (w_theta): 0.001000\t TIME:6899.5s\n",
      "\t\t\t\tDisc: 0.570181\t\tSym: 9.640801\t\tSpars: 184.231812\n",
      "\t TVw: 0.249829 | TVb: -2.004996 | GSw: -0.235031 | GSb: 0.064820 | TSUw: 0.464746 | TSUb: 0.034974\n",
      "\n",
      "Train Epoch: 2710 [4000/8000 (50%)]\tBatch Loss: 181.043237\tLearning Rate (w_theta): 0.001000\t TIME:6901.0s\n",
      "\t\t\t\tDisc: 0.606095\t\tSym: 8.300042\t\tSpars: 172.137100\n",
      "\t TVw: 0.250818 | TVb: -2.004874 | GSw: -0.235032 | GSb: 0.064820 | TSUw: 0.464746 | TSUb: 0.034974\n",
      "Validating epoch 2710...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 191.2293523580665\n",
      "Average validation loss: 30.70189003192599\n",
      "Training epoch 2711...\n",
      "\n",
      "Train Epoch: 2711 [0/8000 (0%)]\tBatch Loss: 187.572199\tLearning Rate (w_theta): 0.001000\t TIME:6904.1s\n",
      "\t\t\t\tDisc: 0.633246\t\tSym: 9.191241\t\tSpars: 177.747711\n",
      "\t TVw: 0.252811 | TVb: -2.004679 | GSw: -0.235032 | GSb: 0.064820 | TSUw: 0.464746 | TSUb: 0.034975\n",
      "\n",
      "Train Epoch: 2711 [4000/8000 (50%)]\tBatch Loss: 192.079111\tLearning Rate (w_theta): 0.001000\t TIME:6905.8s\n",
      "\t\t\t\tDisc: 0.675290\t\tSym: 9.615903\t\tSpars: 181.787918\n",
      "\t TVw: 0.255009 | TVb: -2.004459 | GSw: -0.235032 | GSb: 0.064820 | TSUw: 0.464745 | TSUb: 0.034975\n",
      "Validating epoch 2711...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 188.18711416135122\n",
      "Average validation loss: 32.28301076715352\n",
      "Training epoch 2712...\n",
      "\n",
      "Train Epoch: 2712 [0/8000 (0%)]\tBatch Loss: 187.512006\tLearning Rate (w_theta): 0.001000\t TIME:6908.3s\n",
      "\t\t\t\tDisc: 0.696726\t\tSym: 8.816150\t\tSpars: 177.999130\n",
      "\t TVw: 0.256475 | TVb: -2.004281 | GSw: -0.235032 | GSb: 0.064819 | TSUw: 0.464745 | TSUb: 0.034975\n",
      "\n",
      "Train Epoch: 2712 [4000/8000 (50%)]\tBatch Loss: 184.521526\tLearning Rate (w_theta): 0.001000\t TIME:6909.9s\n",
      "\t\t\t\tDisc: 0.768025\t\tSym: 9.096335\t\tSpars: 174.657166\n",
      "\t TVw: 0.256857 | TVb: -2.004160 | GSw: -0.235032 | GSb: 0.064819 | TSUw: 0.464745 | TSUb: 0.034975\n",
      "Validating epoch 2712...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 188.29522103711474\n",
      "Average validation loss: 32.39653916088504\n",
      "Training epoch 2713...\n",
      "\n",
      "Train Epoch: 2713 [0/8000 (0%)]\tBatch Loss: 183.002712\tLearning Rate (w_theta): 0.001000\t TIME:6912.3s\n",
      "\t\t\t\tDisc: 0.728274\t\tSym: 8.895730\t\tSpars: 173.378708\n",
      "\t TVw: 0.256130 | TVb: -2.004112 | GSw: -0.235032 | GSb: 0.064819 | TSUw: 0.464745 | TSUb: 0.034975\n",
      "\n",
      "Train Epoch: 2713 [4000/8000 (50%)]\tBatch Loss: 183.085505\tLearning Rate (w_theta): 0.001000\t TIME:6914.0s\n",
      "\t\t\t\tDisc: 0.708949\t\tSym: 8.430069\t\tSpars: 173.946487\n",
      "\t TVw: 0.254958 | TVb: -2.004101 | GSw: -0.235032 | GSb: 0.064819 | TSUw: 0.464744 | TSUb: 0.034976\n",
      "Validating epoch 2713...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 187.21935118381708\n",
      "Average validation loss: 31.840088055573556\n",
      "Training epoch 2714...\n",
      "\n",
      "Train Epoch: 2714 [0/8000 (0%)]\tBatch Loss: 184.071251\tLearning Rate (w_theta): 0.001000\t TIME:6916.5s\n",
      "\t\t\t\tDisc: 0.680935\t\tSym: 8.752682\t\tSpars: 174.637634\n",
      "\t TVw: 0.253989 | TVb: -2.004091 | GSw: -0.235032 | GSb: 0.064818 | TSUw: 0.464744 | TSUb: 0.034976\n",
      "\n",
      "Train Epoch: 2714 [4000/8000 (50%)]\tBatch Loss: 185.822045\tLearning Rate (w_theta): 0.001000\t TIME:6918.1s\n",
      "\t\t\t\tDisc: 0.691436\t\tSym: 9.126885\t\tSpars: 176.003723\n",
      "\t TVw: 0.253391 | TVb: -2.004040 | GSw: -0.235032 | GSb: 0.064818 | TSUw: 0.464744 | TSUb: 0.034976\n",
      "Validating epoch 2714...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 186.42643083912327\n",
      "Average validation loss: 31.635670061095365\n",
      "Training epoch 2715...\n",
      "\n",
      "Train Epoch: 2715 [0/8000 (0%)]\tBatch Loss: 190.934260\tLearning Rate (w_theta): 0.001000\t TIME:6920.5s\n",
      "\t\t\t\tDisc: 0.703548\t\tSym: 9.848983\t\tSpars: 180.381729\n",
      "\t TVw: 0.253252 | TVb: -2.003975 | GSw: -0.235032 | GSb: 0.064818 | TSUw: 0.464744 | TSUb: 0.034976\n",
      "\n",
      "Train Epoch: 2715 [4000/8000 (50%)]\tBatch Loss: 185.948595\tLearning Rate (w_theta): 0.001000\t TIME:6922.1s\n",
      "\t\t\t\tDisc: 0.690753\t\tSym: 9.254027\t\tSpars: 176.003815\n",
      "\t TVw: 0.253379 | TVb: -2.003884 | GSw: -0.235032 | GSb: 0.064818 | TSUw: 0.464743 | TSUb: 0.034977\n",
      "Validating epoch 2715...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 185.00240708535057\n",
      "Average validation loss: 31.910424649633597\n",
      "Training epoch 2716...\n",
      "\n",
      "Train Epoch: 2716 [0/8000 (0%)]\tBatch Loss: 187.212989\tLearning Rate (w_theta): 0.001000\t TIME:6924.6s\n",
      "\t\t\t\tDisc: 0.725495\t\tSym: 9.231742\t\tSpars: 177.255753\n",
      "\t TVw: 0.253801 | TVb: -2.003780 | GSw: -0.235032 | GSb: 0.064817 | TSUw: 0.464743 | TSUb: 0.034977\n",
      "\n",
      "Train Epoch: 2716 [4000/8000 (50%)]\tBatch Loss: 187.525090\tLearning Rate (w_theta): 0.001000\t TIME:6926.2s\n",
      "\t\t\t\tDisc: 0.712107\t\tSym: 9.318812\t\tSpars: 177.494171\n",
      "\t TVw: 0.254143 | TVb: -2.003684 | GSw: -0.235032 | GSb: 0.064817 | TSUw: 0.464743 | TSUb: 0.034977\n",
      "Validating epoch 2716...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 184.02754535760002\n",
      "Average validation loss: 31.782148187789556\n",
      "Training epoch 2717...\n",
      "\n",
      "Train Epoch: 2717 [0/8000 (0%)]\tBatch Loss: 181.102418\tLearning Rate (w_theta): 0.001000\t TIME:6928.7s\n",
      "\t\t\t\tDisc: 0.710061\t\tSym: 9.135476\t\tSpars: 171.256882\n",
      "\t TVw: 0.254292 | TVb: -2.003601 | GSw: -0.235032 | GSb: 0.064817 | TSUw: 0.464743 | TSUb: 0.034977\n",
      "\n",
      "Train Epoch: 2717 [4000/8000 (50%)]\tBatch Loss: 191.844585\tLearning Rate (w_theta): 0.001000\t TIME:6930.8s\n",
      "\t\t\t\tDisc: 0.737230\t\tSym: 10.115534\t\tSpars: 180.991821\n",
      "\t TVw: 0.254204 | TVb: -2.003525 | GSw: -0.235032 | GSb: 0.064817 | TSUw: 0.464742 | TSUb: 0.034977\n",
      "Validating epoch 2717...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 184.07615067247752\n",
      "Average validation loss: 31.903402872967277\n",
      "Training epoch 2718...\n",
      "\n",
      "Train Epoch: 2718 [0/8000 (0%)]\tBatch Loss: 191.303612\tLearning Rate (w_theta): 0.001000\t TIME:6933.3s\n",
      "\t\t\t\tDisc: 0.705762\t\tSym: 10.313701\t\tSpars: 180.284149\n",
      "\t TVw: 0.253801 | TVb: -2.003479 | GSw: -0.235033 | GSb: 0.064816 | TSUw: 0.464742 | TSUb: 0.034978\n",
      "\n",
      "Train Epoch: 2718 [4000/8000 (50%)]\tBatch Loss: 184.975819\tLearning Rate (w_theta): 0.001000\t TIME:6934.9s\n",
      "\t\t\t\tDisc: 0.721062\t\tSym: 9.555798\t\tSpars: 174.698959\n",
      "\t TVw: 0.253394 | TVb: -2.003417 | GSw: -0.235033 | GSb: 0.064816 | TSUw: 0.464742 | TSUb: 0.034978\n",
      "Validating epoch 2718...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 182.96866761097675\n",
      "Average validation loss: 31.745351918054993\n",
      "Training epoch 2719...\n",
      "\n",
      "Train Epoch: 2719 [0/8000 (0%)]\tBatch Loss: 187.939447\tLearning Rate (w_theta): 0.001000\t TIME:6937.4s\n",
      "\t\t\t\tDisc: 0.736485\t\tSym: 9.700398\t\tSpars: 177.502563\n",
      "\t TVw: 0.253119 | TVb: -2.003356 | GSw: -0.235033 | GSb: 0.064816 | TSUw: 0.464742 | TSUb: 0.034978\n",
      "\n",
      "Train Epoch: 2719 [4000/8000 (50%)]\tBatch Loss: 176.929750\tLearning Rate (w_theta): 0.001000\t TIME:6939.0s\n",
      "\t\t\t\tDisc: 0.716497\t\tSym: 8.609493\t\tSpars: 167.603760\n",
      "\t TVw: 0.253025 | TVb: -2.003280 | GSw: -0.235033 | GSb: 0.064816 | TSUw: 0.464741 | TSUb: 0.034978\n",
      "Validating epoch 2719...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 182.26954042227752\n",
      "Average validation loss: 31.240159334567455\n",
      "Training epoch 2720...\n",
      "\n",
      "Train Epoch: 2720 [0/8000 (0%)]\tBatch Loss: 180.141722\tLearning Rate (w_theta): 0.001000\t TIME:6941.4s\n",
      "\t\t\t\tDisc: 0.726364\t\tSym: 9.367476\t\tSpars: 170.047882\n",
      "\t TVw: 0.252969 | TVb: -2.003190 | GSw: -0.235033 | GSb: 0.064815 | TSUw: 0.464741 | TSUb: 0.034979\n",
      "\n",
      "Train Epoch: 2720 [4000/8000 (50%)]\tBatch Loss: 181.338796\tLearning Rate (w_theta): 0.001000\t TIME:6943.1s\n",
      "\t\t\t\tDisc: 0.713794\t\tSym: 9.104143\t\tSpars: 171.520859\n",
      "\t TVw: 0.252667 | TVb: -2.003123 | GSw: -0.235033 | GSb: 0.064815 | TSUw: 0.464741 | TSUb: 0.034979\n",
      "Validating epoch 2720...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 184.2596477985495\n",
      "Average validation loss: 32.30970792658154\n",
      "Training epoch 2721...\n",
      "\n",
      "Train Epoch: 2721 [0/8000 (0%)]\tBatch Loss: 192.928446\tLearning Rate (w_theta): 0.001000\t TIME:6946.2s\n",
      "\t\t\t\tDisc: 0.799353\t\tSym: 10.169803\t\tSpars: 181.959290\n",
      "\t TVw: 0.252010 | TVb: -2.003093 | GSw: -0.235033 | GSb: 0.064815 | TSUw: 0.464741 | TSUb: 0.034979\n",
      "\n",
      "Train Epoch: 2721 [4000/8000 (50%)]\tBatch Loss: 181.213692\tLearning Rate (w_theta): 0.001000\t TIME:6947.8s\n",
      "\t\t\t\tDisc: 0.729909\t\tSym: 9.270938\t\tSpars: 171.212845\n",
      "\t TVw: 0.251509 | TVb: -2.003061 | GSw: -0.235033 | GSb: 0.064815 | TSUw: 0.464741 | TSUb: 0.034979\n",
      "Validating epoch 2721...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 183.82101674872152\n",
      "Average validation loss: 31.049430638653682\n",
      "Training epoch 2722...\n",
      "\n",
      "Train Epoch: 2722 [0/8000 (0%)]\tBatch Loss: 184.059561\tLearning Rate (w_theta): 0.001000\t TIME:6950.3s\n",
      "\t\t\t\tDisc: 0.703590\t\tSym: 9.748473\t\tSpars: 173.607498\n",
      "\t TVw: 0.251344 | TVb: -2.002998 | GSw: -0.235033 | GSb: 0.064814 | TSUw: 0.464740 | TSUb: 0.034979\n",
      "\n",
      "Train Epoch: 2722 [4000/8000 (50%)]\tBatch Loss: 182.192742\tLearning Rate (w_theta): 0.001000\t TIME:6951.9s\n",
      "\t\t\t\tDisc: 0.698457\t\tSym: 8.828255\t\tSpars: 172.666031\n",
      "\t TVw: 0.251615 | TVb: -2.002901 | GSw: -0.235033 | GSb: 0.064814 | TSUw: 0.464740 | TSUb: 0.034980\n",
      "Validating epoch 2722...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 181.00730863368545\n",
      "Average validation loss: 30.860167439775797\n",
      "Training epoch 2723...\n",
      "\n",
      "Train Epoch: 2723 [0/8000 (0%)]\tBatch Loss: 174.152815\tLearning Rate (w_theta): 0.001000\t TIME:6954.8s\n",
      "\t\t\t\tDisc: 0.706302\t\tSym: 8.719569\t\tSpars: 164.726944\n",
      "\t TVw: 0.252067 | TVb: -2.002792 | GSw: -0.235033 | GSb: 0.064814 | TSUw: 0.464740 | TSUb: 0.034980\n",
      "\n",
      "Train Epoch: 2723 [4000/8000 (50%)]\tBatch Loss: 177.113943\tLearning Rate (w_theta): 0.001000\t TIME:6956.4s\n",
      "\t\t\t\tDisc: 0.720287\t\tSym: 9.041666\t\tSpars: 167.351990\n",
      "\t TVw: 0.252429 | TVb: -2.002684 | GSw: -0.235033 | GSb: 0.064813 | TSUw: 0.464740 | TSUb: 0.034980\n",
      "Validating epoch 2723...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 180.13485526195302\n",
      "Average validation loss: 31.99251727694633\n",
      "Training epoch 2724...\n",
      "\n",
      "Train Epoch: 2724 [0/8000 (0%)]\tBatch Loss: 193.086843\tLearning Rate (w_theta): 0.001000\t TIME:6958.9s\n",
      "\t\t\t\tDisc: 0.761229\t\tSym: 10.507834\t\tSpars: 181.817780\n",
      "\t TVw: 0.252726 | TVb: -2.002591 | GSw: -0.235033 | GSb: 0.064813 | TSUw: 0.464739 | TSUb: 0.034980\n",
      "\n",
      "Train Epoch: 2724 [4000/8000 (50%)]\tBatch Loss: 187.778285\tLearning Rate (w_theta): 0.001000\t TIME:6960.5s\n",
      "\t\t\t\tDisc: 0.759019\t\tSym: 10.331400\t\tSpars: 176.687866\n",
      "\t TVw: 0.252881 | TVb: -2.002490 | GSw: -0.235034 | GSb: 0.064813 | TSUw: 0.464739 | TSUb: 0.034981\n",
      "Validating epoch 2724...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 179.5826977251086\n",
      "Average validation loss: 31.711239950563908\n",
      "Training epoch 2725...\n",
      "\n",
      "Train Epoch: 2725 [0/8000 (0%)]\tBatch Loss: 183.960298\tLearning Rate (w_theta): 0.001000\t TIME:6963.0s\n",
      "\t\t\t\tDisc: 0.777142\t\tSym: 10.401860\t\tSpars: 172.781296\n",
      "\t TVw: 0.252718 | TVb: -2.002400 | GSw: -0.235034 | GSb: 0.064813 | TSUw: 0.464739 | TSUb: 0.034981\n",
      "\n",
      "Train Epoch: 2725 [4000/8000 (50%)]\tBatch Loss: 171.597525\tLearning Rate (w_theta): 0.001000\t TIME:6964.6s\n",
      "\t\t\t\tDisc: 0.750600\t\tSym: 8.064317\t\tSpars: 162.782608\n",
      "\t TVw: 0.251769 | TVb: -2.002373 | GSw: -0.235034 | GSb: 0.064812 | TSUw: 0.464739 | TSUb: 0.034981\n",
      "Validating epoch 2725...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 180.7826341067069\n",
      "Average validation loss: 32.11611625482663\n",
      "Training epoch 2726...\n",
      "\n",
      "Train Epoch: 2726 [0/8000 (0%)]\tBatch Loss: 185.747047\tLearning Rate (w_theta): 0.001000\t TIME:6967.1s\n",
      "\t\t\t\tDisc: 0.827491\t\tSym: 9.365372\t\tSpars: 175.554184\n",
      "\t TVw: 0.250724 | TVb: -2.002360 | GSw: -0.235034 | GSb: 0.064812 | TSUw: 0.464738 | TSUb: 0.034981\n",
      "\n",
      "Train Epoch: 2726 [4000/8000 (50%)]\tBatch Loss: 188.751065\tLearning Rate (w_theta): 0.001000\t TIME:6968.7s\n",
      "\t\t\t\tDisc: 0.811943\t\tSym: 9.582615\t\tSpars: 178.356506\n",
      "\t TVw: 0.249659 | TVb: -2.002341 | GSw: -0.235034 | GSb: 0.064812 | TSUw: 0.464738 | TSUb: 0.034981\n",
      "Validating epoch 2726...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 181.99374639726778\n",
      "Average validation loss: 31.19536530435743\n",
      "Training epoch 2727...\n",
      "\n",
      "Train Epoch: 2727 [0/8000 (0%)]\tBatch Loss: 177.141069\tLearning Rate (w_theta): 0.001000\t TIME:6971.2s\n",
      "\t\t\t\tDisc: 0.762888\t\tSym: 9.236061\t\tSpars: 167.142120\n",
      "\t TVw: 0.248945 | TVb: -2.002290 | GSw: -0.235034 | GSb: 0.064812 | TSUw: 0.464738 | TSUb: 0.034982\n",
      "\n",
      "Train Epoch: 2727 [4000/8000 (50%)]\tBatch Loss: 169.578984\tLearning Rate (w_theta): 0.001000\t TIME:6972.8s\n",
      "\t\t\t\tDisc: 0.691636\t\tSym: 8.723576\t\tSpars: 160.163773\n",
      "\t TVw: 0.249026 | TVb: -2.002193 | GSw: -0.235034 | GSb: 0.064811 | TSUw: 0.464738 | TSUb: 0.034982\n",
      "Validating epoch 2727...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 177.25478923453758\n",
      "Average validation loss: 30.57246363979489\n",
      "Training epoch 2728...\n",
      "\n",
      "Train Epoch: 2728 [0/8000 (0%)]\tBatch Loss: 175.706484\tLearning Rate (w_theta): 0.001000\t TIME:6975.3s\n",
      "\t\t\t\tDisc: 0.718579\t\tSym: 9.318105\t\tSpars: 165.669800\n",
      "\t TVw: 0.249723 | TVb: -2.002051 | GSw: -0.235034 | GSb: 0.064811 | TSUw: 0.464737 | TSUb: 0.034982\n",
      "\n",
      "Train Epoch: 2728 [4000/8000 (50%)]\tBatch Loss: 189.342130\tLearning Rate (w_theta): 0.001000\t TIME:6976.9s\n",
      "\t\t\t\tDisc: 0.755486\t\tSym: 10.610967\t\tSpars: 177.975677\n",
      "\t TVw: 0.250542 | TVb: -2.001903 | GSw: -0.235034 | GSb: 0.064811 | TSUw: 0.464737 | TSUb: 0.034982\n",
      "Validating epoch 2728...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 177.44471395890395\n",
      "Average validation loss: 31.631671487940544\n",
      "Training epoch 2729...\n",
      "\n",
      "Train Epoch: 2729 [0/8000 (0%)]\tBatch Loss: 183.452160\tLearning Rate (w_theta): 0.001000\t TIME:6979.4s\n",
      "\t\t\t\tDisc: 0.763527\t\tSym: 9.985661\t\tSpars: 172.702972\n",
      "\t TVw: 0.250734 | TVb: -2.001810 | GSw: -0.235034 | GSb: 0.064811 | TSUw: 0.464737 | TSUb: 0.034983\n",
      "\n",
      "Train Epoch: 2729 [4000/8000 (50%)]\tBatch Loss: 178.696254\tLearning Rate (w_theta): 0.001000\t TIME:6981.0s\n",
      "\t\t\t\tDisc: 0.807897\t\tSym: 9.286444\t\tSpars: 168.601913\n",
      "\t TVw: 0.250556 | TVb: -2.001727 | GSw: -0.235035 | GSb: 0.064810 | TSUw: 0.464737 | TSUb: 0.034983\n",
      "Validating epoch 2729...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 176.0322826769317\n",
      "Average validation loss: 31.542798265817535\n",
      "Training epoch 2730...\n",
      "\n",
      "Train Epoch: 2730 [0/8000 (0%)]\tBatch Loss: 179.981707\tLearning Rate (w_theta): 0.001000\t TIME:6983.5s\n",
      "\t\t\t\tDisc: 0.756089\t\tSym: 9.795565\t\tSpars: 169.430054\n",
      "\t TVw: 0.250064 | TVb: -2.001665 | GSw: -0.235035 | GSb: 0.064810 | TSUw: 0.464736 | TSUb: 0.034983\n",
      "\n",
      "Train Epoch: 2730 [4000/8000 (50%)]\tBatch Loss: 170.299555\tLearning Rate (w_theta): 0.001000\t TIME:6985.1s\n",
      "\t\t\t\tDisc: 0.759924\t\tSym: 8.643773\t\tSpars: 160.895859\n",
      "\t TVw: 0.249554 | TVb: -2.001604 | GSw: -0.235035 | GSb: 0.064810 | TSUw: 0.464736 | TSUb: 0.034983\n",
      "Validating epoch 2730...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 176.24672508826404\n",
      "Average validation loss: 30.333590870022597\n",
      "Training epoch 2731...\n",
      "\n",
      "Train Epoch: 2731 [0/8000 (0%)]\tBatch Loss: 187.220304\tLearning Rate (w_theta): 0.001000\t TIME:6988.3s\n",
      "\t\t\t\tDisc: 0.739020\t\tSym: 10.028007\t\tSpars: 176.453278\n",
      "\t TVw: 0.249055 | TVb: -2.001549 | GSw: -0.235035 | GSb: 0.064809 | TSUw: 0.464736 | TSUb: 0.034983\n",
      "\n",
      "Train Epoch: 2731 [4000/8000 (50%)]\tBatch Loss: 177.611160\tLearning Rate (w_theta): 0.001000\t TIME:6989.9s\n",
      "\t\t\t\tDisc: 0.744645\t\tSym: 9.436889\t\tSpars: 167.429626\n",
      "\t TVw: 0.248661 | TVb: -2.001476 | GSw: -0.235035 | GSb: 0.064809 | TSUw: 0.464736 | TSUb: 0.034984\n",
      "Validating epoch 2731...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 177.52409495412078\n",
      "Average validation loss: 30.54737614097176\n",
      "Training epoch 2732...\n",
      "\n",
      "Train Epoch: 2732 [0/8000 (0%)]\tBatch Loss: 176.268238\tLearning Rate (w_theta): 0.001000\t TIME:6992.4s\n",
      "\t\t\t\tDisc: 0.711506\t\tSym: 9.516326\t\tSpars: 166.040405\n",
      "\t TVw: 0.248194 | TVb: -2.001412 | GSw: -0.235035 | GSb: 0.064809 | TSUw: 0.464736 | TSUb: 0.034984\n",
      "\n",
      "Train Epoch: 2732 [4000/8000 (50%)]\tBatch Loss: 169.323037\tLearning Rate (w_theta): 0.001000\t TIME:6994.0s\n",
      "\t\t\t\tDisc: 0.737665\t\tSym: 9.261474\t\tSpars: 159.323898\n",
      "\t TVw: 0.247920 | TVb: -2.001343 | GSw: -0.235035 | GSb: 0.064809 | TSUw: 0.464735 | TSUb: 0.034984\n",
      "Validating epoch 2732...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 174.8075174599254\n",
      "Average validation loss: 31.043454309589855\n",
      "Training epoch 2733...\n",
      "\n",
      "Train Epoch: 2733 [0/8000 (0%)]\tBatch Loss: 174.805426\tLearning Rate (w_theta): 0.001000\t TIME:6996.5s\n",
      "\t\t\t\tDisc: 0.796671\t\tSym: 9.406018\t\tSpars: 164.602737\n",
      "\t TVw: 0.247976 | TVb: -2.001255 | GSw: -0.235035 | GSb: 0.064808 | TSUw: 0.464735 | TSUb: 0.034984\n",
      "\n",
      "Train Epoch: 2733 [4000/8000 (50%)]\tBatch Loss: 177.201918\tLearning Rate (w_theta): 0.001000\t TIME:6998.1s\n",
      "\t\t\t\tDisc: 0.815945\t\tSym: 8.904146\t\tSpars: 167.481827\n",
      "\t TVw: 0.248167 | TVb: -2.001162 | GSw: -0.235035 | GSb: 0.064808 | TSUw: 0.464735 | TSUb: 0.034985\n",
      "Validating epoch 2733...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 175.80839373940566\n",
      "Average validation loss: 30.923082872913625\n",
      "Training epoch 2734...\n",
      "\n",
      "Train Epoch: 2734 [0/8000 (0%)]\tBatch Loss: 177.954987\tLearning Rate (w_theta): 0.001000\t TIME:7000.6s\n",
      "\t\t\t\tDisc: 0.759279\t\tSym: 9.806045\t\tSpars: 167.389664\n",
      "\t TVw: 0.248063 | TVb: -2.001073 | GSw: -0.235036 | GSb: 0.064808 | TSUw: 0.464735 | TSUb: 0.034985\n",
      "\n",
      "Train Epoch: 2734 [4000/8000 (50%)]\tBatch Loss: 169.926432\tLearning Rate (w_theta): 0.001000\t TIME:7002.2s\n",
      "\t\t\t\tDisc: 0.743652\t\tSym: 9.459436\t\tSpars: 159.723343\n",
      "\t TVw: 0.248381 | TVb: -2.000936 | GSw: -0.235036 | GSb: 0.064808 | TSUw: 0.464734 | TSUb: 0.034985\n",
      "Validating epoch 2734...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 172.43456785211566\n",
      "Average validation loss: 31.23829894902195\n",
      "Training epoch 2735...\n",
      "\n",
      "Train Epoch: 2735 [0/8000 (0%)]\tBatch Loss: 172.350195\tLearning Rate (w_theta): 0.001000\t TIME:7004.6s\n",
      "\t\t\t\tDisc: 0.773256\t\tSym: 9.208271\t\tSpars: 162.368668\n",
      "\t TVw: 0.248422 | TVb: -2.000820 | GSw: -0.235036 | GSb: 0.064807 | TSUw: 0.464734 | TSUb: 0.034985\n",
      "\n",
      "Train Epoch: 2735 [4000/8000 (50%)]\tBatch Loss: 165.545450\tLearning Rate (w_theta): 0.001000\t TIME:7006.2s\n",
      "\t\t\t\tDisc: 0.752976\t\tSym: 8.717813\t\tSpars: 156.074661\n",
      "\t TVw: 0.248523 | TVb: -2.000714 | GSw: -0.235036 | GSb: 0.064807 | TSUw: 0.464734 | TSUb: 0.034985\n",
      "Validating epoch 2735...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 170.8906908586496\n",
      "Average validation loss: 31.28144997833465\n",
      "Training epoch 2736...\n",
      "\n",
      "Train Epoch: 2736 [0/8000 (0%)]\tBatch Loss: 174.882485\tLearning Rate (w_theta): 0.001000\t TIME:7008.7s\n",
      "\t\t\t\tDisc: 0.790331\t\tSym: 9.647543\t\tSpars: 164.444611\n",
      "\t TVw: 0.248141 | TVb: -2.000631 | GSw: -0.235036 | GSb: 0.064807 | TSUw: 0.464734 | TSUb: 0.034986\n",
      "\n",
      "Train Epoch: 2736 [4000/8000 (50%)]\tBatch Loss: 170.491516\tLearning Rate (w_theta): 0.001000\t TIME:7010.4s\n",
      "\t\t\t\tDisc: 0.747789\t\tSym: 8.998351\t\tSpars: 160.745377\n",
      "\t TVw: 0.247670 | TVb: -2.000579 | GSw: -0.235036 | GSb: 0.064806 | TSUw: 0.464733 | TSUb: 0.034986\n",
      "Validating epoch 2736...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 170.53182372563165\n",
      "Average validation loss: 30.652117056677906\n",
      "Training epoch 2737...\n",
      "\n",
      "Train Epoch: 2737 [0/8000 (0%)]\tBatch Loss: 175.576206\tLearning Rate (w_theta): 0.001000\t TIME:7012.9s\n",
      "\t\t\t\tDisc: 0.744102\t\tSym: 9.799114\t\tSpars: 165.032990\n",
      "\t TVw: 0.247222 | TVb: -2.000520 | GSw: -0.235036 | GSb: 0.064806 | TSUw: 0.464733 | TSUb: 0.034986\n",
      "\n",
      "Train Epoch: 2737 [4000/8000 (50%)]\tBatch Loss: 172.732282\tLearning Rate (w_theta): 0.001000\t TIME:7014.5s\n",
      "\t\t\t\tDisc: 0.737406\t\tSym: 9.698855\t\tSpars: 162.296021\n",
      "\t TVw: 0.246830 | TVb: -2.000466 | GSw: -0.235036 | GSb: 0.064806 | TSUw: 0.464733 | TSUb: 0.034986\n",
      "Validating epoch 2737...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 169.46828799514975\n",
      "Average validation loss: 30.74747960395291\n",
      "Training epoch 2738...\n",
      "\n",
      "Train Epoch: 2738 [0/8000 (0%)]\tBatch Loss: 171.214299\tLearning Rate (w_theta): 0.001000\t TIME:7017.4s\n",
      "\t\t\t\tDisc: 0.730527\t\tSym: 9.131020\t\tSpars: 161.352753\n",
      "\t TVw: 0.246735 | TVb: -2.000391 | GSw: -0.235036 | GSb: 0.064806 | TSUw: 0.464733 | TSUb: 0.034987\n",
      "\n",
      "Train Epoch: 2738 [4000/8000 (50%)]\tBatch Loss: 163.167342\tLearning Rate (w_theta): 0.001000\t TIME:7019.0s\n",
      "\t\t\t\tDisc: 0.753434\t\tSym: 8.351333\t\tSpars: 154.062576\n",
      "\t TVw: 0.246739 | TVb: -2.000309 | GSw: -0.235036 | GSb: 0.064805 | TSUw: 0.464732 | TSUb: 0.034987\n",
      "Validating epoch 2738...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 168.7863665716572\n",
      "Average validation loss: 30.601792349825313\n",
      "Training epoch 2739...\n",
      "\n",
      "Train Epoch: 2739 [0/8000 (0%)]\tBatch Loss: 167.076931\tLearning Rate (w_theta): 0.001000\t TIME:7021.5s\n",
      "\t\t\t\tDisc: 0.751863\t\tSym: 8.730311\t\tSpars: 157.594757\n",
      "\t TVw: 0.246811 | TVb: -2.000217 | GSw: -0.235036 | GSb: 0.064805 | TSUw: 0.464732 | TSUb: 0.034987\n",
      "\n",
      "Train Epoch: 2739 [4000/8000 (50%)]\tBatch Loss: 168.368641\tLearning Rate (w_theta): 0.001000\t TIME:7023.1s\n",
      "\t\t\t\tDisc: 0.768666\t\tSym: 8.950591\t\tSpars: 158.649384\n",
      "\t TVw: 0.246894 | TVb: -2.000149 | GSw: -0.235036 | GSb: 0.064805 | TSUw: 0.464732 | TSUb: 0.034987\n",
      "Validating epoch 2739...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 168.83087185934997\n",
      "Average validation loss: 30.564054277738606\n",
      "Training epoch 2740...\n",
      "\n",
      "Train Epoch: 2740 [0/8000 (0%)]\tBatch Loss: 164.829294\tLearning Rate (w_theta): 0.001000\t TIME:7025.9s\n",
      "\t\t\t\tDisc: 0.752641\t\tSym: 9.042260\t\tSpars: 155.034393\n",
      "\t TVw: 0.246985 | TVb: -2.000063 | GSw: -0.235037 | GSb: 0.064805 | TSUw: 0.464732 | TSUb: 0.034987\n",
      "\n",
      "Train Epoch: 2740 [4000/8000 (50%)]\tBatch Loss: 167.630481\tLearning Rate (w_theta): 0.001000\t TIME:7027.5s\n",
      "\t\t\t\tDisc: 0.735777\t\tSym: 9.069982\t\tSpars: 157.824722\n",
      "\t TVw: 0.246860 | TVb: -1.999993 | GSw: -0.235037 | GSb: 0.064804 | TSUw: 0.464731 | TSUb: 0.034988\n",
      "Validating epoch 2740...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 167.85336808833677\n",
      "Average validation loss: 30.592633848265276\n",
      "Training epoch 2741...\n",
      "\n",
      "Train Epoch: 2741 [0/8000 (0%)]\tBatch Loss: 163.116287\tLearning Rate (w_theta): 0.001000\t TIME:7030.9s\n",
      "\t\t\t\tDisc: 0.752466\t\tSym: 9.142294\t\tSpars: 153.221527\n",
      "\t TVw: 0.246783 | TVb: -1.999908 | GSw: -0.235037 | GSb: 0.064804 | TSUw: 0.464731 | TSUb: 0.034988\n",
      "\n",
      "Train Epoch: 2741 [4000/8000 (50%)]\tBatch Loss: 181.602886\tLearning Rate (w_theta): 0.001000\t TIME:7032.5s\n",
      "\t\t\t\tDisc: 0.759039\t\tSym: 10.638906\t\tSpars: 170.204941\n",
      "\t TVw: 0.246572 | TVb: -1.999833 | GSw: -0.235037 | GSb: 0.064804 | TSUw: 0.464731 | TSUb: 0.034988\n",
      "Validating epoch 2741...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 167.03546951430818\n",
      "Average validation loss: 30.377530234985862\n",
      "Training epoch 2742...\n",
      "\n",
      "Train Epoch: 2742 [0/8000 (0%)]\tBatch Loss: 169.839975\tLearning Rate (w_theta): 0.001000\t TIME:7034.9s\n",
      "\t\t\t\tDisc: 0.749210\t\tSym: 9.308874\t\tSpars: 159.781891\n",
      "\t TVw: 0.246448 | TVb: -1.999740 | GSw: -0.235037 | GSb: 0.064804 | TSUw: 0.464731 | TSUb: 0.034988\n",
      "\n",
      "Train Epoch: 2742 [4000/8000 (50%)]\tBatch Loss: 164.967239\tLearning Rate (w_theta): 0.001000\t TIME:7036.6s\n",
      "\t\t\t\tDisc: 0.781376\t\tSym: 8.573833\t\tSpars: 155.612030\n",
      "\t TVw: 0.246245 | TVb: -1.999664 | GSw: -0.235037 | GSb: 0.064803 | TSUw: 0.464731 | TSUb: 0.034989\n",
      "Validating epoch 2742...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 167.38767554638343\n",
      "Average validation loss: 30.5906485243006\n",
      "Training epoch 2743...\n",
      "\n",
      "Train Epoch: 2743 [0/8000 (0%)]\tBatch Loss: 163.354084\tLearning Rate (w_theta): 0.001000\t TIME:7039.0s\n",
      "\t\t\t\tDisc: 0.745892\t\tSym: 9.129448\t\tSpars: 153.478745\n",
      "\t TVw: 0.245954 | TVb: -1.999579 | GSw: -0.235037 | GSb: 0.064803 | TSUw: 0.464730 | TSUb: 0.034989\n",
      "\n",
      "Train Epoch: 2743 [4000/8000 (50%)]\tBatch Loss: 158.834220\tLearning Rate (w_theta): 0.001000\t TIME:7040.6s\n",
      "\t\t\t\tDisc: 0.735946\t\tSym: 8.345909\t\tSpars: 149.752365\n",
      "\t TVw: 0.245633 | TVb: -1.999494 | GSw: -0.235037 | GSb: 0.064803 | TSUw: 0.464730 | TSUb: 0.034989\n",
      "Validating epoch 2743...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 165.9333111541909\n",
      "Average validation loss: 30.665349559500896\n",
      "Training epoch 2744...\n",
      "\n",
      "Train Epoch: 2744 [0/8000 (0%)]\tBatch Loss: 155.264006\tLearning Rate (w_theta): 0.001000\t TIME:7043.2s\n",
      "\t\t\t\tDisc: 0.769485\t\tSym: 8.016707\t\tSpars: 146.477814\n",
      "\t TVw: 0.245397 | TVb: -1.999408 | GSw: -0.235037 | GSb: 0.064802 | TSUw: 0.464730 | TSUb: 0.034989\n",
      "\n",
      "Train Epoch: 2744 [4000/8000 (50%)]\tBatch Loss: 172.599328\tLearning Rate (w_theta): 0.001000\t TIME:7044.8s\n",
      "\t\t\t\tDisc: 0.744291\t\tSym: 9.693461\t\tSpars: 162.161575\n",
      "\t TVw: 0.244915 | TVb: -1.999335 | GSw: -0.235037 | GSb: 0.064802 | TSUw: 0.464730 | TSUb: 0.034989\n",
      "Validating epoch 2744...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 165.34407583584013\n",
      "Average validation loss: 30.162661935254732\n",
      "Training epoch 2745...\n",
      "\n",
      "Train Epoch: 2745 [0/8000 (0%)]\tBatch Loss: 172.374321\tLearning Rate (w_theta): 0.001000\t TIME:7047.3s\n",
      "\t\t\t\tDisc: 0.770459\t\tSym: 10.049220\t\tSpars: 161.554642\n",
      "\t TVw: 0.244762 | TVb: -1.999251 | GSw: -0.235037 | GSb: 0.064802 | TSUw: 0.464729 | TSUb: 0.034990\n",
      "\n",
      "Train Epoch: 2745 [4000/8000 (50%)]\tBatch Loss: 166.812438\tLearning Rate (w_theta): 0.001000\t TIME:7048.8s\n",
      "\t\t\t\tDisc: 0.760204\t\tSym: 9.042605\t\tSpars: 157.009628\n",
      "\t TVw: 0.244540 | TVb: -1.999172 | GSw: -0.235037 | GSb: 0.064802 | TSUw: 0.464729 | TSUb: 0.034990\n",
      "Validating epoch 2745...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 165.5595375198463\n",
      "Average validation loss: 30.545174833696606\n",
      "Training epoch 2746...\n",
      "\n",
      "Train Epoch: 2746 [0/8000 (0%)]\tBatch Loss: 168.792397\tLearning Rate (w_theta): 0.001000\t TIME:7051.3s\n",
      "\t\t\t\tDisc: 0.759508\t\tSym: 10.012397\t\tSpars: 158.020493\n",
      "\t TVw: 0.244295 | TVb: -1.999088 | GSw: -0.235037 | GSb: 0.064801 | TSUw: 0.464729 | TSUb: 0.034990\n",
      "\n",
      "Train Epoch: 2746 [4000/8000 (50%)]\tBatch Loss: 158.351537\tLearning Rate (w_theta): 0.001000\t TIME:7052.9s\n",
      "\t\t\t\tDisc: 0.765421\t\tSym: 7.903530\t\tSpars: 149.682587\n",
      "\t TVw: 0.243932 | TVb: -1.999012 | GSw: -0.235037 | GSb: 0.064801 | TSUw: 0.464729 | TSUb: 0.034990\n",
      "Validating epoch 2746...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 164.9206990986056\n",
      "Average validation loss: 30.293459565699152\n",
      "Training epoch 2747...\n",
      "\n",
      "Train Epoch: 2747 [0/8000 (0%)]\tBatch Loss: 166.677127\tLearning Rate (w_theta): 0.001000\t TIME:7055.4s\n",
      "\t\t\t\tDisc: 0.725065\t\tSym: 9.631521\t\tSpars: 156.320541\n",
      "\t TVw: 0.243695 | TVb: -1.998927 | GSw: -0.235038 | GSb: 0.064801 | TSUw: 0.464728 | TSUb: 0.034991\n",
      "\n",
      "Train Epoch: 2747 [4000/8000 (50%)]\tBatch Loss: 166.886238\tLearning Rate (w_theta): 0.001000\t TIME:7057.0s\n",
      "\t\t\t\tDisc: 0.772263\t\tSym: 9.495644\t\tSpars: 156.618332\n",
      "\t TVw: 0.243407 | TVb: -1.998839 | GSw: -0.235038 | GSb: 0.064801 | TSUw: 0.464728 | TSUb: 0.034991\n",
      "Validating epoch 2747...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 163.9503187902361\n",
      "Average validation loss: 29.968822350290456\n",
      "Training epoch 2748...\n",
      "\n",
      "Train Epoch: 2748 [0/8000 (0%)]\tBatch Loss: 158.072556\tLearning Rate (w_theta): 0.001000\t TIME:7059.5s\n",
      "\t\t\t\tDisc: 0.776468\t\tSym: 8.717963\t\tSpars: 148.578125\n",
      "\t TVw: 0.243072 | TVb: -1.998758 | GSw: -0.235038 | GSb: 0.064800 | TSUw: 0.464728 | TSUb: 0.034991\n",
      "\n",
      "Train Epoch: 2748 [4000/8000 (50%)]\tBatch Loss: 160.977866\tLearning Rate (w_theta): 0.001000\t TIME:7061.1s\n",
      "\t\t\t\tDisc: 0.733309\t\tSym: 9.004994\t\tSpars: 151.239563\n",
      "\t TVw: 0.242646 | TVb: -1.998683 | GSw: -0.235038 | GSb: 0.064800 | TSUw: 0.464728 | TSUb: 0.034991\n",
      "Validating epoch 2748...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 163.4186734427188\n",
      "Average validation loss: 30.432492123433516\n",
      "Training epoch 2749...\n",
      "\n",
      "Train Epoch: 2749 [0/8000 (0%)]\tBatch Loss: 167.943445\tLearning Rate (w_theta): 0.001000\t TIME:7063.5s\n",
      "\t\t\t\tDisc: 0.782374\t\tSym: 9.431975\t\tSpars: 157.729095\n",
      "\t TVw: 0.242548 | TVb: -1.998600 | GSw: -0.235038 | GSb: 0.064800 | TSUw: 0.464727 | TSUb: 0.034991\n",
      "\n",
      "Train Epoch: 2749 [4000/8000 (50%)]\tBatch Loss: 161.526099\tLearning Rate (w_theta): 0.001000\t TIME:7065.1s\n",
      "\t\t\t\tDisc: 0.746843\t\tSym: 9.104498\t\tSpars: 151.674759\n",
      "\t TVw: 0.242554 | TVb: -1.998504 | GSw: -0.235038 | GSb: 0.064800 | TSUw: 0.464727 | TSUb: 0.034992\n",
      "Validating epoch 2749...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 162.50483331891846\n",
      "Average validation loss: 30.055327589677102\n",
      "Training epoch 2750...\n",
      "\n",
      "Train Epoch: 2750 [0/8000 (0%)]\tBatch Loss: 157.430001\tLearning Rate (w_theta): 0.001000\t TIME:7067.6s\n",
      "\t\t\t\tDisc: 0.764779\t\tSym: 8.535628\t\tSpars: 148.129593\n",
      "\t TVw: 0.242521 | TVb: -1.998413 | GSw: -0.235038 | GSb: 0.064799 | TSUw: 0.464727 | TSUb: 0.034992\n",
      "\n",
      "Train Epoch: 2750 [4000/8000 (50%)]\tBatch Loss: 154.148912\tLearning Rate (w_theta): 0.001000\t TIME:7069.2s\n",
      "\t\t\t\tDisc: 0.767558\t\tSym: 8.391821\t\tSpars: 144.989532\n",
      "\t TVw: 0.242272 | TVb: -1.998350 | GSw: -0.235038 | GSb: 0.064799 | TSUw: 0.464727 | TSUb: 0.034992\n",
      "Validating epoch 2750...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 161.7844690599161\n",
      "Average validation loss: 30.10349736861771\n",
      "Training epoch 2751...\n",
      "\n",
      "Train Epoch: 2751 [0/8000 (0%)]\tBatch Loss: 158.425566\tLearning Rate (w_theta): 0.001000\t TIME:7072.8s\n",
      "\t\t\t\tDisc: 0.754281\t\tSym: 8.982717\t\tSpars: 148.688568\n",
      "\t TVw: 0.242075 | TVb: -1.998265 | GSw: -0.235038 | GSb: 0.064799 | TSUw: 0.464726 | TSUb: 0.034992\n",
      "\n",
      "Train Epoch: 2751 [4000/8000 (50%)]\tBatch Loss: 163.116234\tLearning Rate (w_theta): 0.001000\t TIME:7074.4s\n",
      "\t\t\t\tDisc: 0.736833\t\tSym: 9.186118\t\tSpars: 153.193283\n",
      "\t TVw: 0.241930 | TVb: -1.998179 | GSw: -0.235038 | GSb: 0.064798 | TSUw: 0.464726 | TSUb: 0.034993\n",
      "Validating epoch 2751...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 161.04165542412366\n",
      "Average validation loss: 29.881746014793205\n",
      "Training epoch 2752...\n",
      "\n",
      "Train Epoch: 2752 [0/8000 (0%)]\tBatch Loss: 163.786058\tLearning Rate (w_theta): 0.001000\t TIME:7076.9s\n",
      "\t\t\t\tDisc: 0.766320\t\tSym: 9.257271\t\tSpars: 153.762466\n",
      "\t TVw: 0.241697 | TVb: -1.998087 | GSw: -0.235038 | GSb: 0.064798 | TSUw: 0.464726 | TSUb: 0.034993\n",
      "\n",
      "Train Epoch: 2752 [4000/8000 (50%)]\tBatch Loss: 154.716094\tLearning Rate (w_theta): 0.001000\t TIME:7078.5s\n",
      "\t\t\t\tDisc: 0.743586\t\tSym: 8.356053\t\tSpars: 145.616455\n",
      "\t TVw: 0.241325 | TVb: -1.998009 | GSw: -0.235038 | GSb: 0.064798 | TSUw: 0.464726 | TSUb: 0.034993\n",
      "Validating epoch 2752...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 160.48373522112917\n",
      "Average validation loss: 29.680270367730763\n",
      "Training epoch 2753...\n",
      "\n",
      "Train Epoch: 2753 [0/8000 (0%)]\tBatch Loss: 158.587456\tLearning Rate (w_theta): 0.001000\t TIME:7081.0s\n",
      "\t\t\t\tDisc: 0.743402\t\tSym: 8.538939\t\tSpars: 149.305115\n",
      "\t TVw: 0.240930 | TVb: -1.997924 | GSw: -0.235038 | GSb: 0.064798 | TSUw: 0.464726 | TSUb: 0.034993\n",
      "\n",
      "Train Epoch: 2753 [4000/8000 (50%)]\tBatch Loss: 165.369295\tLearning Rate (w_theta): 0.001000\t TIME:7082.5s\n",
      "\t\t\t\tDisc: 0.768609\t\tSym: 10.110116\t\tSpars: 154.490570\n",
      "\t TVw: 0.240511 | TVb: -1.997845 | GSw: -0.235038 | GSb: 0.064797 | TSUw: 0.464725 | TSUb: 0.034993\n",
      "Validating epoch 2753...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 160.1159502914978\n",
      "Average validation loss: 29.782788544309017\n",
      "Training epoch 2754...\n",
      "\n",
      "Train Epoch: 2754 [0/8000 (0%)]\tBatch Loss: 164.672687\tLearning Rate (w_theta): 0.001000\t TIME:7085.0s\n",
      "\t\t\t\tDisc: 0.722531\t\tSym: 9.300604\t\tSpars: 154.649551\n",
      "\t TVw: 0.240250 | TVb: -1.997762 | GSw: -0.235039 | GSb: 0.064797 | TSUw: 0.464725 | TSUb: 0.034994\n",
      "\n",
      "Train Epoch: 2754 [4000/8000 (50%)]\tBatch Loss: 158.702021\tLearning Rate (w_theta): 0.001000\t TIME:7086.6s\n",
      "\t\t\t\tDisc: 0.746303\t\tSym: 9.384475\t\tSpars: 148.571243\n",
      "\t TVw: 0.240017 | TVb: -1.997674 | GSw: -0.235039 | GSb: 0.064797 | TSUw: 0.464725 | TSUb: 0.034994\n",
      "Validating epoch 2754...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 159.20331490105963\n",
      "Average validation loss: 29.822533475025605\n",
      "Training epoch 2755...\n",
      "\n",
      "Train Epoch: 2755 [0/8000 (0%)]\tBatch Loss: 157.489879\tLearning Rate (w_theta): 0.001000\t TIME:7089.0s\n",
      "\t\t\t\tDisc: 0.774121\t\tSym: 9.232955\t\tSpars: 147.482803\n",
      "\t TVw: 0.239759 | TVb: -1.997595 | GSw: -0.235039 | GSb: 0.064797 | TSUw: 0.464725 | TSUb: 0.034994\n",
      "\n",
      "Train Epoch: 2755 [4000/8000 (50%)]\tBatch Loss: 160.169709\tLearning Rate (w_theta): 0.001000\t TIME:7090.7s\n",
      "\t\t\t\tDisc: 0.752939\t\tSym: 9.290961\t\tSpars: 150.125809\n",
      "\t TVw: 0.239273 | TVb: -1.997499 | GSw: -0.235039 | GSb: 0.064796 | TSUw: 0.464724 | TSUb: 0.034994\n",
      "Validating epoch 2755...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 159.25850131031868\n",
      "Average validation loss: 29.34123603087207\n",
      "Training epoch 2756...\n",
      "\n",
      "Train Epoch: 2756 [0/8000 (0%)]\tBatch Loss: 169.559833\tLearning Rate (w_theta): 0.001000\t TIME:7093.1s\n",
      "\t\t\t\tDisc: 0.768596\t\tSym: 10.803276\t\tSpars: 157.987961\n",
      "\t TVw: 0.239081 | TVb: -1.997401 | GSw: -0.235039 | GSb: 0.064796 | TSUw: 0.464724 | TSUb: 0.034995\n",
      "\n",
      "Train Epoch: 2756 [4000/8000 (50%)]\tBatch Loss: 161.462024\tLearning Rate (w_theta): 0.001000\t TIME:7094.7s\n",
      "\t\t\t\tDisc: 0.756035\t\tSym: 9.551143\t\tSpars: 151.154846\n",
      "\t TVw: 0.239037 | TVb: -1.997306 | GSw: -0.235039 | GSb: 0.064796 | TSUw: 0.464724 | TSUb: 0.034995\n",
      "Validating epoch 2756...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 158.49510889944085\n",
      "Average validation loss: 29.579245338607933\n",
      "Training epoch 2757...\n",
      "\n",
      "Train Epoch: 2757 [0/8000 (0%)]\tBatch Loss: 154.623756\tLearning Rate (w_theta): 0.001000\t TIME:7097.2s\n",
      "\t\t\t\tDisc: 0.740071\t\tSym: 8.751941\t\tSpars: 145.131744\n",
      "\t TVw: 0.238818 | TVb: -1.997219 | GSw: -0.235039 | GSb: 0.064795 | TSUw: 0.464724 | TSUb: 0.034995\n",
      "\n",
      "Train Epoch: 2757 [4000/8000 (50%)]\tBatch Loss: 159.701077\tLearning Rate (w_theta): 0.001000\t TIME:7098.8s\n",
      "\t\t\t\tDisc: 0.806069\t\tSym: 9.409107\t\tSpars: 149.485901\n",
      "\t TVw: 0.238791 | TVb: -1.997127 | GSw: -0.235039 | GSb: 0.064795 | TSUw: 0.464723 | TSUb: 0.034995\n",
      "Validating epoch 2757...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 157.72347650881204\n",
      "Average validation loss: 29.42486398992439\n",
      "Training epoch 2758...\n",
      "\n",
      "Train Epoch: 2758 [0/8000 (0%)]\tBatch Loss: 157.541508\tLearning Rate (w_theta): 0.001000\t TIME:7101.2s\n",
      "\t\t\t\tDisc: 0.763876\t\tSym: 9.073988\t\tSpars: 147.703644\n",
      "\t TVw: 0.238415 | TVb: -1.997048 | GSw: -0.235039 | GSb: 0.064795 | TSUw: 0.464723 | TSUb: 0.034995\n",
      "\n",
      "Train Epoch: 2758 [4000/8000 (50%)]\tBatch Loss: 157.508564\tLearning Rate (w_theta): 0.001000\t TIME:7102.8s\n",
      "\t\t\t\tDisc: 0.759716\t\tSym: 9.012886\t\tSpars: 147.735962\n",
      "\t TVw: 0.237968 | TVb: -1.996977 | GSw: -0.235039 | GSb: 0.064795 | TSUw: 0.464723 | TSUb: 0.034996\n",
      "Validating epoch 2758...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 157.12452942059392\n",
      "Average validation loss: 29.448068483242565\n",
      "Training epoch 2759...\n",
      "\n",
      "Train Epoch: 2759 [0/8000 (0%)]\tBatch Loss: 150.011935\tLearning Rate (w_theta): 0.001000\t TIME:7105.3s\n",
      "\t\t\t\tDisc: 0.777958\t\tSym: 8.216750\t\tSpars: 141.017227\n",
      "\t TVw: 0.237526 | TVb: -1.996908 | GSw: -0.235039 | GSb: 0.064794 | TSUw: 0.464723 | TSUb: 0.034996\n",
      "\n",
      "Train Epoch: 2759 [4000/8000 (50%)]\tBatch Loss: 153.344116\tLearning Rate (w_theta): 0.001000\t TIME:7106.9s\n",
      "\t\t\t\tDisc: 0.740205\t\tSym: 9.028319\t\tSpars: 143.575592\n",
      "\t TVw: 0.237095 | TVb: -1.996816 | GSw: -0.235039 | GSb: 0.064794 | TSUw: 0.464722 | TSUb: 0.034996\n",
      "Validating epoch 2759...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 157.3134275483121\n",
      "Average validation loss: 29.440752833461637\n",
      "Training epoch 2760...\n",
      "\n",
      "Train Epoch: 2760 [0/8000 (0%)]\tBatch Loss: 160.083338\tLearning Rate (w_theta): 0.001000\t TIME:7109.4s\n",
      "\t\t\t\tDisc: 0.799646\t\tSym: 9.674668\t\tSpars: 149.609024\n",
      "\t TVw: 0.236691 | TVb: -1.996754 | GSw: -0.235039 | GSb: 0.064794 | TSUw: 0.464722 | TSUb: 0.034996\n",
      "\n",
      "Train Epoch: 2760 [4000/8000 (50%)]\tBatch Loss: 159.620840\tLearning Rate (w_theta): 0.001000\t TIME:7110.9s\n",
      "\t\t\t\tDisc: 0.737997\t\tSym: 9.445450\t\tSpars: 149.437393\n",
      "\t TVw: 0.236367 | TVb: -1.996688 | GSw: -0.235039 | GSb: 0.064794 | TSUw: 0.464722 | TSUb: 0.034997\n",
      "Validating epoch 2760...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 157.5756822597956\n",
      "Average validation loss: 28.702848979697446\n",
      "Training epoch 2761...\n",
      "\n",
      "Train Epoch: 2761 [0/8000 (0%)]\tBatch Loss: 164.932664\tLearning Rate (w_theta): 0.001000\t TIME:7114.1s\n",
      "\t\t\t\tDisc: 0.749226\t\tSym: 9.614728\t\tSpars: 154.568710\n",
      "\t TVw: 0.236106 | TVb: -1.996611 | GSw: -0.235039 | GSb: 0.064793 | TSUw: 0.464722 | TSUb: 0.034997\n",
      "\n",
      "Train Epoch: 2761 [4000/8000 (50%)]\tBatch Loss: 161.579120\tLearning Rate (w_theta): 0.001000\t TIME:7115.6s\n",
      "\t\t\t\tDisc: 0.768820\t\tSym: 9.572782\t\tSpars: 151.237518\n",
      "\t TVw: 0.235710 | TVb: -1.996553 | GSw: -0.235040 | GSb: 0.064793 | TSUw: 0.464721 | TSUb: 0.034997\n",
      "Validating epoch 2761...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 159.04175809543636\n",
      "Average validation loss: 29.034626740955538\n",
      "Training epoch 2762...\n",
      "\n",
      "Train Epoch: 2762 [0/8000 (0%)]\tBatch Loss: 166.107402\tLearning Rate (w_theta): 0.001000\t TIME:7118.1s\n",
      "\t\t\t\tDisc: 0.785634\t\tSym: 9.320135\t\tSpars: 156.001633\n",
      "\t TVw: 0.235260 | TVb: -1.996510 | GSw: -0.235040 | GSb: 0.064793 | TSUw: 0.464721 | TSUb: 0.034997\n",
      "\n",
      "Train Epoch: 2762 [4000/8000 (50%)]\tBatch Loss: 152.384713\tLearning Rate (w_theta): 0.001000\t TIME:7119.7s\n",
      "\t\t\t\tDisc: 0.711979\t\tSym: 8.735677\t\tSpars: 142.937057\n",
      "\t TVw: 0.235030 | TVb: -1.996440 | GSw: -0.235040 | GSb: 0.064793 | TSUw: 0.464721 | TSUb: 0.034997\n",
      "Validating epoch 2762...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 157.21127024750214\n",
      "Average validation loss: 28.479377960618837\n",
      "Training epoch 2763...\n",
      "\n",
      "Train Epoch: 2763 [0/8000 (0%)]\tBatch Loss: 162.138214\tLearning Rate (w_theta): 0.001000\t TIME:7122.2s\n",
      "\t\t\t\tDisc: 0.700144\t\tSym: 9.740804\t\tSpars: 151.697266\n",
      "\t TVw: 0.235103 | TVb: -1.996327 | GSw: -0.235040 | GSb: 0.064792 | TSUw: 0.464721 | TSUb: 0.034998\n",
      "\n",
      "Train Epoch: 2763 [4000/8000 (50%)]\tBatch Loss: 155.005000\tLearning Rate (w_theta): 0.001000\t TIME:7123.8s\n",
      "\t\t\t\tDisc: 0.742755\t\tSym: 9.122978\t\tSpars: 145.139267\n",
      "\t TVw: 0.235348 | TVb: -1.996203 | GSw: -0.235040 | GSb: 0.064792 | TSUw: 0.464721 | TSUb: 0.034998\n",
      "Validating epoch 2763...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 155.36917037820467\n",
      "Average validation loss: 28.86399049427104\n",
      "Training epoch 2764...\n",
      "\n",
      "Train Epoch: 2764 [0/8000 (0%)]\tBatch Loss: 152.742857\tLearning Rate (w_theta): 0.001000\t TIME:7126.3s\n",
      "\t\t\t\tDisc: 0.750727\t\tSym: 8.858356\t\tSpars: 143.133774\n",
      "\t TVw: 0.235603 | TVb: -1.996084 | GSw: -0.235040 | GSb: 0.064792 | TSUw: 0.464720 | TSUb: 0.034998\n",
      "\n",
      "Train Epoch: 2764 [4000/8000 (50%)]\tBatch Loss: 149.970032\tLearning Rate (w_theta): 0.001000\t TIME:7127.9s\n",
      "\t\t\t\tDisc: 0.735439\t\tSym: 8.617848\t\tSpars: 140.616745\n",
      "\t TVw: 0.235668 | TVb: -1.995982 | GSw: -0.235040 | GSb: 0.064791 | TSUw: 0.464720 | TSUb: 0.034998\n",
      "Validating epoch 2764...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 154.4646282089567\n",
      "Average validation loss: 28.744319993832846\n",
      "Training epoch 2765...\n",
      "\n",
      "Train Epoch: 2765 [0/8000 (0%)]\tBatch Loss: 161.197487\tLearning Rate (w_theta): 0.001000\t TIME:7130.4s\n",
      "\t\t\t\tDisc: 0.761602\t\tSym: 10.284777\t\tSpars: 150.151108\n",
      "\t TVw: 0.235596 | TVb: -1.995872 | GSw: -0.235040 | GSb: 0.064791 | TSUw: 0.464720 | TSUb: 0.034999\n",
      "\n",
      "Train Epoch: 2765 [4000/8000 (50%)]\tBatch Loss: 156.500192\tLearning Rate (w_theta): 0.001000\t TIME:7132.0s\n",
      "\t\t\t\tDisc: 0.770886\t\tSym: 9.547452\t\tSpars: 146.181854\n",
      "\t TVw: 0.235169 | TVb: -1.995800 | GSw: -0.235041 | GSb: 0.064791 | TSUw: 0.464720 | TSUb: 0.034999\n",
      "Validating epoch 2765...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 154.0867032399076\n",
      "Average validation loss: 28.731053888068715\n",
      "Training epoch 2766...\n",
      "\n",
      "Train Epoch: 2766 [0/8000 (0%)]\tBatch Loss: 154.569866\tLearning Rate (w_theta): 0.001000\t TIME:7134.9s\n",
      "\t\t\t\tDisc: 0.744332\t\tSym: 9.333880\t\tSpars: 144.491653\n",
      "\t TVw: 0.234835 | TVb: -1.995718 | GSw: -0.235041 | GSb: 0.064791 | TSUw: 0.464719 | TSUb: 0.034999\n",
      "\n",
      "Train Epoch: 2766 [4000/8000 (50%)]\tBatch Loss: 148.530585\tLearning Rate (w_theta): 0.001000\t TIME:7136.5s\n",
      "\t\t\t\tDisc: 0.751891\t\tSym: 8.551277\t\tSpars: 139.227417\n",
      "\t TVw: 0.234696 | TVb: -1.995623 | GSw: -0.235041 | GSb: 0.064790 | TSUw: 0.464719 | TSUb: 0.034999\n",
      "Validating epoch 2766...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 152.94731154065298\n",
      "Average validation loss: 28.687475121746445\n",
      "Training epoch 2767...\n",
      "\n",
      "Train Epoch: 2767 [0/8000 (0%)]\tBatch Loss: 149.752894\tLearning Rate (w_theta): 0.001000\t TIME:7139.1s\n",
      "\t\t\t\tDisc: 0.754005\t\tSym: 9.044589\t\tSpars: 139.954300\n",
      "\t TVw: 0.234529 | TVb: -1.995527 | GSw: -0.235041 | GSb: 0.064790 | TSUw: 0.464719 | TSUb: 0.035000\n",
      "\n",
      "Train Epoch: 2767 [4000/8000 (50%)]\tBatch Loss: 153.778128\tLearning Rate (w_theta): 0.001000\t TIME:7140.7s\n",
      "\t\t\t\tDisc: 0.749267\t\tSym: 9.354270\t\tSpars: 143.674591\n",
      "\t TVw: 0.234463 | TVb: -1.995423 | GSw: -0.235041 | GSb: 0.064790 | TSUw: 0.464719 | TSUb: 0.035000\n",
      "Validating epoch 2767...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 152.4383240944616\n",
      "Average validation loss: 28.79303211509215\n",
      "Training epoch 2768...\n",
      "\n",
      "Train Epoch: 2768 [0/8000 (0%)]\tBatch Loss: 147.888715\tLearning Rate (w_theta): 0.001000\t TIME:7143.1s\n",
      "\t\t\t\tDisc: 0.781611\t\tSym: 8.375140\t\tSpars: 138.731964\n",
      "\t TVw: 0.234299 | TVb: -1.995330 | GSw: -0.235041 | GSb: 0.064790 | TSUw: 0.464718 | TSUb: 0.035000\n",
      "\n",
      "Train Epoch: 2768 [4000/8000 (50%)]\tBatch Loss: 158.875262\tLearning Rate (w_theta): 0.001000\t TIME:7144.7s\n",
      "\t\t\t\tDisc: 0.761539\t\tSym: 10.094787\t\tSpars: 148.018936\n",
      "\t TVw: 0.233985 | TVb: -1.995241 | GSw: -0.235041 | GSb: 0.064789 | TSUw: 0.464718 | TSUb: 0.035000\n",
      "Validating epoch 2768...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 152.96736176405093\n",
      "Average validation loss: 28.349811580077873\n",
      "Training epoch 2769...\n",
      "\n",
      "Train Epoch: 2769 [0/8000 (0%)]\tBatch Loss: 145.943084\tLearning Rate (w_theta): 0.001000\t TIME:7147.2s\n",
      "\t\t\t\tDisc: 0.768091\t\tSym: 8.226460\t\tSpars: 136.948532\n",
      "\t TVw: 0.233514 | TVb: -1.995132 | GSw: -0.235041 | GSb: 0.064789 | TSUw: 0.464718 | TSUb: 0.035000\n",
      "\n",
      "Train Epoch: 2769 [4000/8000 (50%)]\tBatch Loss: 156.795389\tLearning Rate (w_theta): 0.001000\t TIME:7148.8s\n",
      "\t\t\t\tDisc: 0.807719\t\tSym: 9.851989\t\tSpars: 146.135681\n",
      "\t TVw: 0.232828 | TVb: -1.995060 | GSw: -0.235041 | GSb: 0.064789 | TSUw: 0.464718 | TSUb: 0.035001\n",
      "Validating epoch 2769...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 152.96398092085786\n",
      "Average validation loss: 28.51910157522165\n",
      "Training epoch 2770...\n",
      "\n",
      "Train Epoch: 2770 [0/8000 (0%)]\tBatch Loss: 141.174674\tLearning Rate (w_theta): 0.001000\t TIME:7151.2s\n",
      "\t\t\t\tDisc: 0.752191\t\tSym: 7.580197\t\tSpars: 132.842285\n",
      "\t TVw: 0.232154 | TVb: -1.994994 | GSw: -0.235041 | GSb: 0.064789 | TSUw: 0.464717 | TSUb: 0.035001\n",
      "\n",
      "Train Epoch: 2770 [4000/8000 (50%)]\tBatch Loss: 153.687758\tLearning Rate (w_theta): 0.001000\t TIME:7152.8s\n",
      "\t\t\t\tDisc: 0.698649\t\tSym: 9.339466\t\tSpars: 143.649643\n",
      "\t TVw: 0.231624 | TVb: -1.994904 | GSw: -0.235041 | GSb: 0.064788 | TSUw: 0.464717 | TSUb: 0.035001\n",
      "Validating epoch 2770...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 151.68108645977213\n",
      "Average validation loss: 28.345622396607748\n",
      "Training epoch 2771...\n",
      "\n",
      "Train Epoch: 2771 [0/8000 (0%)]\tBatch Loss: 149.231259\tLearning Rate (w_theta): 0.001000\t TIME:7155.9s\n",
      "\t\t\t\tDisc: 0.727421\t\tSym: 8.793481\t\tSpars: 139.710358\n",
      "\t TVw: 0.231460 | TVb: -1.994811 | GSw: -0.235042 | GSb: 0.064788 | TSUw: 0.464717 | TSUb: 0.035001\n",
      "\n",
      "Train Epoch: 2771 [4000/8000 (50%)]\tBatch Loss: 151.179258\tLearning Rate (w_theta): 0.001000\t TIME:7157.5s\n",
      "\t\t\t\tDisc: 0.727365\t\tSym: 9.223423\t\tSpars: 141.228470\n",
      "\t TVw: 0.231488 | TVb: -1.994707 | GSw: -0.235042 | GSb: 0.064788 | TSUw: 0.464717 | TSUb: 0.035002\n",
      "Validating epoch 2771...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 150.71076557191063\n",
      "Average validation loss: 28.35838100935774\n",
      "Training epoch 2772...\n",
      "\n",
      "Train Epoch: 2772 [0/8000 (0%)]\tBatch Loss: 159.258295\tLearning Rate (w_theta): 0.001000\t TIME:7160.0s\n",
      "\t\t\t\tDisc: 0.743968\t\tSym: 10.496138\t\tSpars: 148.018188\n",
      "\t TVw: 0.231532 | TVb: -1.994607 | GSw: -0.235042 | GSb: 0.064787 | TSUw: 0.464716 | TSUb: 0.035002\n",
      "\n",
      "Train Epoch: 2772 [4000/8000 (50%)]\tBatch Loss: 152.636193\tLearning Rate (w_theta): 0.001000\t TIME:7161.6s\n",
      "\t\t\t\tDisc: 0.761590\t\tSym: 9.666367\t\tSpars: 142.208237\n",
      "\t TVw: 0.231603 | TVb: -1.994515 | GSw: -0.235042 | GSb: 0.064787 | TSUw: 0.464716 | TSUb: 0.035002\n",
      "Validating epoch 2772...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 149.8643889104174\n",
      "Average validation loss: 28.319703076133926\n",
      "Training epoch 2773...\n",
      "\n",
      "Train Epoch: 2773 [0/8000 (0%)]\tBatch Loss: 141.811983\tLearning Rate (w_theta): 0.001000\t TIME:7164.1s\n",
      "\t\t\t\tDisc: 0.748202\t\tSym: 8.059326\t\tSpars: 133.004456\n",
      "\t TVw: 0.231494 | TVb: -1.994433 | GSw: -0.235042 | GSb: 0.064787 | TSUw: 0.464716 | TSUb: 0.035002\n",
      "\n",
      "Train Epoch: 2773 [4000/8000 (50%)]\tBatch Loss: 143.220298\tLearning Rate (w_theta): 0.001000\t TIME:7165.7s\n",
      "\t\t\t\tDisc: 0.743560\t\tSym: 8.169807\t\tSpars: 134.306931\n",
      "\t TVw: 0.231299 | TVb: -1.994362 | GSw: -0.235042 | GSb: 0.064787 | TSUw: 0.464716 | TSUb: 0.035002\n",
      "Validating epoch 2773...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 149.83619258946084\n",
      "Average validation loss: 28.306617781253717\n",
      "Training epoch 2774...\n",
      "\n",
      "Train Epoch: 2774 [0/8000 (0%)]\tBatch Loss: 142.688710\tLearning Rate (w_theta): 0.001000\t TIME:7168.1s\n",
      "\t\t\t\tDisc: 0.753553\t\tSym: 8.222220\t\tSpars: 133.712936\n",
      "\t TVw: 0.231075 | TVb: -1.994281 | GSw: -0.235042 | GSb: 0.064786 | TSUw: 0.464716 | TSUb: 0.035003\n",
      "\n",
      "Train Epoch: 2774 [4000/8000 (50%)]\tBatch Loss: 149.885271\tLearning Rate (w_theta): 0.001000\t TIME:7169.7s\n",
      "\t\t\t\tDisc: 0.745859\t\tSym: 9.246986\t\tSpars: 139.892426\n",
      "\t TVw: 0.230807 | TVb: -1.994204 | GSw: -0.235042 | GSb: 0.064786 | TSUw: 0.464715 | TSUb: 0.035003\n",
      "Validating epoch 2774...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 148.92349689206637\n",
      "Average validation loss: 28.205577071167408\n",
      "Training epoch 2775...\n",
      "\n",
      "Train Epoch: 2775 [0/8000 (0%)]\tBatch Loss: 148.309208\tLearning Rate (w_theta): 0.001000\t TIME:7172.2s\n",
      "\t\t\t\tDisc: 0.767278\t\tSym: 9.124267\t\tSpars: 138.417664\n",
      "\t TVw: 0.230668 | TVb: -1.994121 | GSw: -0.235042 | GSb: 0.064786 | TSUw: 0.464715 | TSUb: 0.035003\n",
      "\n",
      "Train Epoch: 2775 [4000/8000 (50%)]\tBatch Loss: 151.269217\tLearning Rate (w_theta): 0.001000\t TIME:7173.8s\n",
      "\t\t\t\tDisc: 0.750180\t\tSym: 9.334970\t\tSpars: 141.184067\n",
      "\t TVw: 0.230599 | TVb: -1.994030 | GSw: -0.235042 | GSb: 0.064786 | TSUw: 0.464715 | TSUb: 0.035003\n",
      "Validating epoch 2775...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 148.5618660954955\n",
      "Average validation loss: 28.10048054196034\n",
      "Training epoch 2776...\n",
      "\n",
      "Train Epoch: 2776 [0/8000 (0%)]\tBatch Loss: 144.184161\tLearning Rate (w_theta): 0.001000\t TIME:7176.3s\n",
      "\t\t\t\tDisc: 0.726413\t\tSym: 8.866042\t\tSpars: 134.591705\n",
      "\t TVw: 0.230387 | TVb: -1.993938 | GSw: -0.235042 | GSb: 0.064785 | TSUw: 0.464715 | TSUb: 0.035004\n",
      "\n",
      "Train Epoch: 2776 [4000/8000 (50%)]\tBatch Loss: 157.950658\tLearning Rate (w_theta): 0.001000\t TIME:7177.9s\n",
      "\t\t\t\tDisc: 0.755372\t\tSym: 9.812428\t\tSpars: 147.382858\n",
      "\t TVw: 0.230117 | TVb: -1.993832 | GSw: -0.235042 | GSb: 0.064785 | TSUw: 0.464714 | TSUb: 0.035004\n",
      "Validating epoch 2776...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 149.76217778148802\n",
      "Average validation loss: 28.242383145724162\n",
      "Training epoch 2777...\n",
      "\n",
      "Train Epoch: 2777 [0/8000 (0%)]\tBatch Loss: 153.010059\tLearning Rate (w_theta): 0.001000\t TIME:7180.3s\n",
      "\t\t\t\tDisc: 0.796715\t\tSym: 9.384838\t\tSpars: 142.828506\n",
      "\t TVw: 0.229447 | TVb: -1.993780 | GSw: -0.235042 | GSb: 0.064785 | TSUw: 0.464714 | TSUb: 0.035004\n",
      "\n",
      "Train Epoch: 2777 [4000/8000 (50%)]\tBatch Loss: 142.589483\tLearning Rate (w_theta): 0.001000\t TIME:7181.9s\n",
      "\t\t\t\tDisc: 0.743855\t\tSym: 8.207200\t\tSpars: 133.638428\n",
      "\t TVw: 0.228644 | TVb: -1.993746 | GSw: -0.235043 | GSb: 0.064784 | TSUw: 0.464714 | TSUb: 0.035004\n",
      "Validating epoch 2777...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 149.50808776609145\n",
      "Average validation loss: 27.616272759061342\n",
      "Training epoch 2778...\n",
      "\n",
      "Train Epoch: 2778 [0/8000 (0%)]\tBatch Loss: 148.509216\tLearning Rate (w_theta): 0.001000\t TIME:7184.4s\n",
      "\t\t\t\tDisc: 0.684972\t\tSym: 8.987742\t\tSpars: 138.836502\n",
      "\t TVw: 0.228252 | TVb: -1.993657 | GSw: -0.235043 | GSb: 0.064784 | TSUw: 0.464714 | TSUb: 0.035004\n",
      "\n",
      "Train Epoch: 2778 [4000/8000 (50%)]\tBatch Loss: 142.953688\tLearning Rate (w_theta): 0.001000\t TIME:7186.0s\n",
      "\t\t\t\tDisc: 0.729540\t\tSym: 8.674527\t\tSpars: 133.549622\n",
      "\t TVw: 0.228285 | TVb: -1.993542 | GSw: -0.235043 | GSb: 0.064784 | TSUw: 0.464713 | TSUb: 0.035005\n",
      "Validating epoch 2778...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 147.57391622196658\n",
      "Average validation loss: 27.878154668016816\n",
      "Training epoch 2779...\n",
      "\n",
      "Train Epoch: 2779 [0/8000 (0%)]\tBatch Loss: 142.267522\tLearning Rate (w_theta): 0.001000\t TIME:7188.5s\n",
      "\t\t\t\tDisc: 0.739658\t\tSym: 8.302050\t\tSpars: 133.225815\n",
      "\t TVw: 0.228286 | TVb: -1.993426 | GSw: -0.235043 | GSb: 0.064784 | TSUw: 0.464713 | TSUb: 0.035005\n",
      "\n",
      "Train Epoch: 2779 [4000/8000 (50%)]\tBatch Loss: 147.692410\tLearning Rate (w_theta): 0.001000\t TIME:7190.1s\n",
      "\t\t\t\tDisc: 0.717679\t\tSym: 9.402663\t\tSpars: 137.572067\n",
      "\t TVw: 0.228260 | TVb: -1.993307 | GSw: -0.235043 | GSb: 0.064783 | TSUw: 0.464713 | TSUb: 0.035005\n",
      "Validating epoch 2779...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 147.01904777000368\n",
      "Average validation loss: 27.927181531864193\n",
      "Training epoch 2780...\n",
      "\n",
      "Train Epoch: 2780 [0/8000 (0%)]\tBatch Loss: 151.595927\tLearning Rate (w_theta): 0.001000\t TIME:7192.5s\n",
      "\t\t\t\tDisc: 0.783432\t\tSym: 9.507472\t\tSpars: 141.305023\n",
      "\t TVw: 0.227786 | TVb: -1.993234 | GSw: -0.235043 | GSb: 0.064783 | TSUw: 0.464713 | TSUb: 0.035005\n",
      "\n",
      "Train Epoch: 2780 [4000/8000 (50%)]\tBatch Loss: 139.513534\tLearning Rate (w_theta): 0.001000\t TIME:7194.1s\n",
      "\t\t\t\tDisc: 0.696531\t\tSym: 8.033693\t\tSpars: 130.783310\n",
      "\t TVw: 0.227214 | TVb: -1.993149 | GSw: -0.235043 | GSb: 0.064783 | TSUw: 0.464712 | TSUb: 0.035006\n",
      "Validating epoch 2780...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 147.19428318785288\n",
      "Average validation loss: 27.42806544578716\n",
      "Training epoch 2781...\n",
      "\n",
      "Train Epoch: 2781 [0/8000 (0%)]\tBatch Loss: 146.299300\tLearning Rate (w_theta): 0.001000\t TIME:7197.7s\n",
      "\t\t\t\tDisc: 0.727275\t\tSym: 9.284245\t\tSpars: 136.287781\n",
      "\t TVw: 0.226654 | TVb: -1.993044 | GSw: -0.235043 | GSb: 0.064783 | TSUw: 0.464712 | TSUb: 0.035006\n",
      "\n",
      "Train Epoch: 2781 [4000/8000 (50%)]\tBatch Loss: 140.898734\tLearning Rate (w_theta): 0.001000\t TIME:7199.3s\n",
      "\t\t\t\tDisc: 0.797805\t\tSym: 8.520560\t\tSpars: 131.580368\n",
      "\t TVw: 0.225823 | TVb: -1.992993 | GSw: -0.235044 | GSb: 0.064782 | TSUw: 0.464712 | TSUb: 0.035006\n",
      "Validating epoch 2781...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 148.24054877212362\n",
      "Average validation loss: 27.427567724545394\n",
      "Training epoch 2782...\n",
      "\n",
      "Train Epoch: 2782 [0/8000 (0%)]\tBatch Loss: 139.469740\tLearning Rate (w_theta): 0.001000\t TIME:7201.8s\n",
      "\t\t\t\tDisc: 0.727112\t\tSym: 8.489683\t\tSpars: 130.252945\n",
      "\t TVw: 0.225118 | TVb: -1.992940 | GSw: -0.235044 | GSb: 0.064782 | TSUw: 0.464712 | TSUb: 0.035006\n",
      "\n",
      "Train Epoch: 2782 [4000/8000 (50%)]\tBatch Loss: 146.693228\tLearning Rate (w_theta): 0.001000\t TIME:7203.4s\n",
      "\t\t\t\tDisc: 0.669599\t\tSym: 8.792992\t\tSpars: 137.230637\n",
      "\t TVw: 0.224540 | TVb: -1.992852 | GSw: -0.235044 | GSb: 0.064782 | TSUw: 0.464711 | TSUb: 0.035006\n",
      "Validating epoch 2782...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 146.9402037250913\n",
      "Average validation loss: 27.187907389036397\n",
      "Training epoch 2783...\n",
      "\n",
      "Train Epoch: 2783 [0/8000 (0%)]\tBatch Loss: 149.150958\tLearning Rate (w_theta): 0.001000\t TIME:7205.9s\n",
      "\t\t\t\tDisc: 0.686992\t\tSym: 9.654944\t\tSpars: 138.809021\n",
      "\t TVw: 0.224523 | TVb: -1.992751 | GSw: -0.235044 | GSb: 0.064782 | TSUw: 0.464711 | TSUb: 0.035007\n",
      "\n",
      "Train Epoch: 2783 [4000/8000 (50%)]\tBatch Loss: 147.681393\tLearning Rate (w_theta): 0.001000\t TIME:7207.5s\n",
      "\t\t\t\tDisc: 0.766494\t\tSym: 9.018857\t\tSpars: 137.896042\n",
      "\t TVw: 0.224443 | TVb: -1.992666 | GSw: -0.235044 | GSb: 0.064781 | TSUw: 0.464711 | TSUb: 0.035007\n",
      "Validating epoch 2783...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 146.86591255801036\n",
      "Average validation loss: 27.397853811594477\n",
      "Training epoch 2784...\n",
      "\n",
      "Train Epoch: 2784 [0/8000 (0%)]\tBatch Loss: 143.991081\tLearning Rate (w_theta): 0.001000\t TIME:7209.9s\n",
      "\t\t\t\tDisc: 0.754854\t\tSym: 8.634268\t\tSpars: 134.601959\n",
      "\t TVw: 0.224320 | TVb: -1.992597 | GSw: -0.235044 | GSb: 0.064781 | TSUw: 0.464711 | TSUb: 0.035007\n",
      "\n",
      "Train Epoch: 2784 [4000/8000 (50%)]\tBatch Loss: 140.854374\tLearning Rate (w_theta): 0.001000\t TIME:7211.5s\n",
      "\t\t\t\tDisc: 0.674211\t\tSym: 8.557269\t\tSpars: 131.622894\n",
      "\t TVw: 0.224288 | TVb: -1.992499 | GSw: -0.235044 | GSb: 0.064781 | TSUw: 0.464711 | TSUb: 0.035007\n",
      "Validating epoch 2784...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 145.37290039980928\n",
      "Average validation loss: 26.810197290223478\n",
      "Training epoch 2785...\n",
      "\n",
      "Train Epoch: 2785 [0/8000 (0%)]\tBatch Loss: 145.759947\tLearning Rate (w_theta): 0.001000\t TIME:7214.0s\n",
      "\t\t\t\tDisc: 0.707724\t\tSym: 9.044562\t\tSpars: 136.007660\n",
      "\t TVw: 0.224365 | TVb: -1.992384 | GSw: -0.235044 | GSb: 0.064780 | TSUw: 0.464710 | TSUb: 0.035008\n",
      "\n",
      "Train Epoch: 2785 [4000/8000 (50%)]\tBatch Loss: 141.077564\tLearning Rate (w_theta): 0.001000\t TIME:7215.6s\n",
      "\t\t\t\tDisc: 0.697974\t\tSym: 8.934140\t\tSpars: 131.445450\n",
      "\t TVw: 0.224427 | TVb: -1.992270 | GSw: -0.235044 | GSb: 0.064780 | TSUw: 0.464710 | TSUb: 0.035008\n",
      "Validating epoch 2785...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 145.01611324275325\n",
      "Average validation loss: 27.148601568470742\n",
      "Training epoch 2786...\n",
      "\n",
      "Train Epoch: 2786 [0/8000 (0%)]\tBatch Loss: 148.973330\tLearning Rate (w_theta): 0.001000\t TIME:7218.1s\n",
      "\t\t\t\tDisc: 0.720128\t\tSym: 9.544920\t\tSpars: 138.708282\n",
      "\t TVw: 0.224238 | TVb: -1.992181 | GSw: -0.235045 | GSb: 0.064780 | TSUw: 0.464710 | TSUb: 0.035008\n",
      "\n",
      "Train Epoch: 2786 [4000/8000 (50%)]\tBatch Loss: 142.457622\tLearning Rate (w_theta): 0.001000\t TIME:7219.7s\n",
      "\t\t\t\tDisc: 0.738398\t\tSym: 9.082475\t\tSpars: 132.636749\n",
      "\t TVw: 0.224170 | TVb: -1.992086 | GSw: -0.235045 | GSb: 0.064780 | TSUw: 0.464710 | TSUb: 0.035008\n",
      "Validating epoch 2786...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 144.77524235158774\n",
      "Average validation loss: 26.815346657696836\n",
      "Training epoch 2787...\n",
      "\n",
      "Train Epoch: 2787 [0/8000 (0%)]\tBatch Loss: 148.515672\tLearning Rate (w_theta): 0.001000\t TIME:7222.1s\n",
      "\t\t\t\tDisc: 0.686869\t\tSym: 9.345374\t\tSpars: 138.483429\n",
      "\t TVw: 0.223851 | TVb: -1.991995 | GSw: -0.235045 | GSb: 0.064779 | TSUw: 0.464709 | TSUb: 0.035008\n",
      "\n",
      "Train Epoch: 2787 [4000/8000 (50%)]\tBatch Loss: 137.127576\tLearning Rate (w_theta): 0.001000\t TIME:7223.7s\n",
      "\t\t\t\tDisc: 0.691483\t\tSym: 8.271648\t\tSpars: 128.164444\n",
      "\t TVw: 0.223613 | TVb: -1.991903 | GSw: -0.235045 | GSb: 0.064779 | TSUw: 0.464709 | TSUb: 0.035009\n",
      "Validating epoch 2787...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 143.15438505774546\n",
      "Average validation loss: 27.091678994505514\n",
      "Training epoch 2788...\n",
      "\n",
      "Train Epoch: 2788 [0/8000 (0%)]\tBatch Loss: 139.364246\tLearning Rate (w_theta): 0.001000\t TIME:7226.2s\n",
      "\t\t\t\tDisc: 0.785613\t\tSym: 8.585332\t\tSpars: 129.993301\n",
      "\t TVw: 0.223516 | TVb: -1.991802 | GSw: -0.235045 | GSb: 0.064779 | TSUw: 0.464709 | TSUb: 0.035009\n",
      "\n",
      "Train Epoch: 2788 [4000/8000 (50%)]\tBatch Loss: 143.990957\tLearning Rate (w_theta): 0.001000\t TIME:7227.8s\n",
      "\t\t\t\tDisc: 0.730494\t\tSym: 9.241298\t\tSpars: 134.019165\n",
      "\t TVw: 0.223305 | TVb: -1.991719 | GSw: -0.235045 | GSb: 0.064779 | TSUw: 0.464709 | TSUb: 0.035009\n",
      "Validating epoch 2788...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 144.65914050945233\n",
      "Average validation loss: 26.42022989798737\n",
      "Training epoch 2789...\n",
      "\n",
      "Train Epoch: 2789 [0/8000 (0%)]\tBatch Loss: 152.752456\tLearning Rate (w_theta): 0.001000\t TIME:7230.3s\n",
      "\t\t\t\tDisc: 0.730658\t\tSym: 9.997827\t\tSpars: 142.023972\n",
      "\t TVw: 0.222703 | TVb: -1.991638 | GSw: -0.235045 | GSb: 0.064778 | TSUw: 0.464708 | TSUb: 0.035009\n",
      "\n",
      "Train Epoch: 2789 [4000/8000 (50%)]\tBatch Loss: 144.673304\tLearning Rate (w_theta): 0.001000\t TIME:7231.9s\n",
      "\t\t\t\tDisc: 0.649095\t\tSym: 9.139169\t\tSpars: 134.885040\n",
      "\t TVw: 0.221783 | TVb: -1.991598 | GSw: -0.235045 | GSb: 0.064778 | TSUw: 0.464708 | TSUb: 0.035010\n",
      "Validating epoch 2789...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 145.39917400979562\n",
      "Average validation loss: 26.717841982640536\n",
      "Training epoch 2790...\n",
      "\n",
      "Train Epoch: 2790 [0/8000 (0%)]\tBatch Loss: 138.381614\tLearning Rate (w_theta): 0.001000\t TIME:7234.5s\n",
      "\t\t\t\tDisc: 0.769847\t\tSym: 8.028591\t\tSpars: 129.583176\n",
      "\t TVw: 0.221176 | TVb: -1.991540 | GSw: -0.235046 | GSb: 0.064778 | TSUw: 0.464708 | TSUb: 0.035010\n",
      "\n",
      "Train Epoch: 2790 [4000/8000 (50%)]\tBatch Loss: 150.537618\tLearning Rate (w_theta): 0.001000\t TIME:7236.0s\n",
      "\t\t\t\tDisc: 0.778253\t\tSym: 9.948498\t\tSpars: 139.810867\n",
      "\t TVw: 0.220762 | TVb: -1.991494 | GSw: -0.235046 | GSb: 0.064778 | TSUw: 0.464708 | TSUb: 0.035010\n",
      "Validating epoch 2790...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 144.75216632836532\n",
      "Average validation loss: 26.27780153963541\n",
      "Training epoch 2791...\n",
      "\n",
      "Train Epoch: 2791 [0/8000 (0%)]\tBatch Loss: 137.711048\tLearning Rate (w_theta): 0.001000\t TIME:7239.3s\n",
      "\t\t\t\tDisc: 0.686860\t\tSym: 8.092806\t\tSpars: 128.931381\n",
      "\t TVw: 0.220924 | TVb: -1.991402 | GSw: -0.235046 | GSb: 0.064777 | TSUw: 0.464707 | TSUb: 0.035010\n",
      "\n",
      "Train Epoch: 2791 [4000/8000 (50%)]\tBatch Loss: 141.270252\tLearning Rate (w_theta): 0.001000\t TIME:7240.9s\n",
      "\t\t\t\tDisc: 0.688241\t\tSym: 9.263377\t\tSpars: 131.318634\n",
      "\t TVw: 0.221536 | TVb: -1.991264 | GSw: -0.235046 | GSb: 0.064777 | TSUw: 0.464707 | TSUb: 0.035011\n",
      "Validating epoch 2791...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 142.6246043274981\n",
      "Average validation loss: 26.248121625399982\n",
      "Training epoch 2792...\n",
      "\n",
      "Train Epoch: 2792 [0/8000 (0%)]\tBatch Loss: 143.500093\tLearning Rate (w_theta): 0.001000\t TIME:7243.5s\n",
      "\t\t\t\tDisc: 0.693046\t\tSym: 9.323572\t\tSpars: 133.483475\n",
      "\t TVw: 0.221971 | TVb: -1.991120 | GSw: -0.235046 | GSb: 0.064777 | TSUw: 0.464707 | TSUb: 0.035011\n",
      "\n",
      "Train Epoch: 2792 [4000/8000 (50%)]\tBatch Loss: 143.455587\tLearning Rate (w_theta): 0.001000\t TIME:7245.1s\n",
      "\t\t\t\tDisc: 0.703085\t\tSym: 9.194808\t\tSpars: 133.557693\n",
      "\t TVw: 0.222185 | TVb: -1.990995 | GSw: -0.235046 | GSb: 0.064776 | TSUw: 0.464707 | TSUb: 0.035011\n",
      "Validating epoch 2792...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 141.4190126107691\n",
      "Average validation loss: 26.309856825120548\n",
      "Training epoch 2793...\n",
      "\n",
      "Train Epoch: 2793 [0/8000 (0%)]\tBatch Loss: 137.235220\tLearning Rate (w_theta): 0.001000\t TIME:7247.5s\n",
      "\t\t\t\tDisc: 0.705828\t\tSym: 8.372868\t\tSpars: 128.156525\n",
      "\t TVw: 0.221986 | TVb: -1.990892 | GSw: -0.235046 | GSb: 0.064776 | TSUw: 0.464706 | TSUb: 0.035011\n",
      "\n",
      "Train Epoch: 2793 [4000/8000 (50%)]\tBatch Loss: 142.319303\tLearning Rate (w_theta): 0.001000\t TIME:7249.1s\n",
      "\t\t\t\tDisc: 0.766012\t\tSym: 9.201942\t\tSpars: 132.351349\n",
      "\t TVw: 0.221561 | TVb: -1.990808 | GSw: -0.235046 | GSb: 0.064776 | TSUw: 0.464706 | TSUb: 0.035011\n",
      "Validating epoch 2793...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 140.74872958129637\n",
      "Average validation loss: 26.28753615722084\n",
      "Training epoch 2794...\n",
      "\n",
      "Train Epoch: 2794 [0/8000 (0%)]\tBatch Loss: 141.394257\tLearning Rate (w_theta): 0.001000\t TIME:7251.6s\n",
      "\t\t\t\tDisc: 0.728634\t\tSym: 9.362462\t\tSpars: 131.303162\n",
      "\t TVw: 0.221141 | TVb: -1.990732 | GSw: -0.235047 | GSb: 0.064776 | TSUw: 0.464706 | TSUb: 0.035012\n",
      "\n",
      "Train Epoch: 2794 [4000/8000 (50%)]\tBatch Loss: 135.437627\tLearning Rate (w_theta): 0.001000\t TIME:7253.2s\n",
      "\t\t\t\tDisc: 0.683036\t\tSym: 8.650831\t\tSpars: 126.103760\n",
      "\t TVw: 0.220863 | TVb: -1.990645 | GSw: -0.235047 | GSb: 0.064775 | TSUw: 0.464706 | TSUb: 0.035012\n",
      "Validating epoch 2794...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 139.7856686160058\n",
      "Average validation loss: 26.14020628419943\n",
      "Training epoch 2795...\n",
      "\n",
      "Train Epoch: 2795 [0/8000 (0%)]\tBatch Loss: 137.737541\tLearning Rate (w_theta): 0.001000\t TIME:7255.7s\n",
      "\t\t\t\tDisc: 0.715409\t\tSym: 8.708045\t\tSpars: 128.314087\n",
      "\t TVw: 0.220866 | TVb: -1.990549 | GSw: -0.235047 | GSb: 0.064775 | TSUw: 0.464705 | TSUb: 0.035012\n",
      "\n",
      "Train Epoch: 2795 [4000/8000 (50%)]\tBatch Loss: 141.499702\tLearning Rate (w_theta): 0.001000\t TIME:7257.8s\n",
      "\t\t\t\tDisc: 0.717935\t\tSym: 9.890196\t\tSpars: 130.891571\n",
      "\t TVw: 0.220975 | TVb: -1.990441 | GSw: -0.235047 | GSb: 0.064775 | TSUw: 0.464705 | TSUb: 0.035012\n",
      "Validating epoch 2795...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 138.93530905885711\n",
      "Average validation loss: 26.05771468988315\n",
      "Training epoch 2796...\n",
      "\n",
      "Train Epoch: 2796 [0/8000 (0%)]\tBatch Loss: 131.973721\tLearning Rate (w_theta): 0.001000\t TIME:7260.3s\n",
      "\t\t\t\tDisc: 0.738719\t\tSym: 8.375742\t\tSpars: 122.859261\n",
      "\t TVw: 0.221051 | TVb: -1.990334 | GSw: -0.235047 | GSb: 0.064775 | TSUw: 0.464705 | TSUb: 0.035013\n",
      "\n",
      "Train Epoch: 2796 [4000/8000 (50%)]\tBatch Loss: 140.148849\tLearning Rate (w_theta): 0.001000\t TIME:7261.9s\n",
      "\t\t\t\tDisc: 0.707512\t\tSym: 8.847556\t\tSpars: 130.593781\n",
      "\t TVw: 0.220968 | TVb: -1.990230 | GSw: -0.235047 | GSb: 0.064774 | TSUw: 0.464705 | TSUb: 0.035013\n",
      "Validating epoch 2796...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 138.94277207794914\n",
      "Average validation loss: 26.050176194512154\n",
      "Training epoch 2797...\n",
      "\n",
      "Train Epoch: 2797 [0/8000 (0%)]\tBatch Loss: 135.250041\tLearning Rate (w_theta): 0.001000\t TIME:7264.4s\n",
      "\t\t\t\tDisc: 0.777864\t\tSym: 8.640534\t\tSpars: 125.831642\n",
      "\t TVw: 0.220627 | TVb: -1.990150 | GSw: -0.235047 | GSb: 0.064774 | TSUw: 0.464705 | TSUb: 0.035013\n",
      "\n",
      "Train Epoch: 2797 [4000/8000 (50%)]\tBatch Loss: 136.203149\tLearning Rate (w_theta): 0.001000\t TIME:7266.0s\n",
      "\t\t\t\tDisc: 0.740927\t\tSym: 8.869136\t\tSpars: 126.593086\n",
      "\t TVw: 0.220077 | TVb: -1.990080 | GSw: -0.235047 | GSb: 0.064774 | TSUw: 0.464704 | TSUb: 0.035013\n",
      "Validating epoch 2797...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 139.47214815074915\n",
      "Average validation loss: 25.382001140297977\n",
      "Training epoch 2798...\n",
      "\n",
      "Train Epoch: 2798 [0/8000 (0%)]\tBatch Loss: 139.646382\tLearning Rate (w_theta): 0.001000\t TIME:7268.6s\n",
      "\t\t\t\tDisc: 0.699567\t\tSym: 9.143302\t\tSpars: 129.803513\n",
      "\t TVw: 0.219411 | TVb: -1.989999 | GSw: -0.235047 | GSb: 0.064773 | TSUw: 0.464704 | TSUb: 0.035013\n",
      "\n",
      "Train Epoch: 2798 [4000/8000 (50%)]\tBatch Loss: 128.600676\tLearning Rate (w_theta): 0.001000\t TIME:7270.2s\n",
      "\t\t\t\tDisc: 0.699407\t\tSym: 7.687997\t\tSpars: 120.213272\n",
      "\t TVw: 0.219060 | TVb: -1.989925 | GSw: -0.235047 | GSb: 0.064773 | TSUw: 0.464704 | TSUb: 0.035014\n",
      "Validating epoch 2798...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 138.76369079078825\n",
      "Average validation loss: 25.42457590622792\n",
      "Training epoch 2799...\n",
      "\n",
      "Train Epoch: 2799 [0/8000 (0%)]\tBatch Loss: 134.469826\tLearning Rate (w_theta): 0.001000\t TIME:7272.8s\n",
      "\t\t\t\tDisc: 0.692381\t\tSym: 8.432146\t\tSpars: 125.345299\n",
      "\t TVw: 0.218976 | TVb: -1.989847 | GSw: -0.235047 | GSb: 0.064773 | TSUw: 0.464704 | TSUb: 0.035014\n",
      "\n",
      "Train Epoch: 2799 [4000/8000 (50%)]\tBatch Loss: 139.537446\tLearning Rate (w_theta): 0.001000\t TIME:7274.4s\n",
      "\t\t\t\tDisc: 0.695206\t\tSym: 9.476853\t\tSpars: 129.365387\n",
      "\t TVw: 0.218994 | TVb: -1.989737 | GSw: -0.235048 | GSb: 0.064773 | TSUw: 0.464703 | TSUb: 0.035014\n",
      "Validating epoch 2799...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 138.98589311692504\n",
      "Average validation loss: 25.403462306642787\n",
      "Training epoch 2800...\n",
      "\n",
      "Train Epoch: 2800 [0/8000 (0%)]\tBatch Loss: 140.964943\tLearning Rate (w_theta): 0.001000\t TIME:7277.0s\n",
      "\t\t\t\tDisc: 0.733724\t\tSym: 9.584353\t\tSpars: 130.646866\n",
      "\t TVw: 0.218714 | TVb: -1.989641 | GSw: -0.235048 | GSb: 0.064772 | TSUw: 0.464703 | TSUb: 0.035014\n",
      "\n",
      "Train Epoch: 2800 [4000/8000 (50%)]\tBatch Loss: 135.752252\tLearning Rate (w_theta): 0.001000\t TIME:7278.6s\n",
      "\t\t\t\tDisc: 0.718849\t\tSym: 9.119210\t\tSpars: 125.914192\n",
      "\t TVw: 0.218384 | TVb: -1.989555 | GSw: -0.235048 | GSb: 0.064772 | TSUw: 0.464703 | TSUb: 0.035015\n",
      "Validating epoch 2800...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 136.96632360185453\n",
      "Average validation loss: 25.062365511144574\n",
      "Training epoch 2801...\n",
      "\n",
      "Train Epoch: 2801 [0/8000 (0%)]\tBatch Loss: 135.557026\tLearning Rate (w_theta): 0.001000\t TIME:7282.0s\n",
      "\t\t\t\tDisc: 0.687965\t\tSym: 9.025677\t\tSpars: 125.843384\n",
      "\t TVw: 0.218014 | TVb: -1.989454 | GSw: -0.235048 | GSb: 0.064772 | TSUw: 0.464703 | TSUb: 0.035015\n",
      "\n",
      "Train Epoch: 2801 [4000/8000 (50%)]\tBatch Loss: 140.047335\tLearning Rate (w_theta): 0.001000\t TIME:7283.7s\n",
      "\t\t\t\tDisc: 0.676360\t\tSym: 9.426776\t\tSpars: 129.944199\n",
      "\t TVw: 0.217794 | TVb: -1.989353 | GSw: -0.235048 | GSb: 0.064772 | TSUw: 0.464702 | TSUb: 0.035015\n",
      "Validating epoch 2801...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 136.2701718514221\n",
      "Average validation loss: 25.112565280048468\n",
      "Training epoch 2802...\n",
      "\n",
      "Train Epoch: 2802 [0/8000 (0%)]\tBatch Loss: 142.734042\tLearning Rate (w_theta): 0.001000\t TIME:7286.2s\n",
      "\t\t\t\tDisc: 0.796245\t\tSym: 9.616554\t\tSpars: 132.321243\n",
      "\t TVw: 0.217608 | TVb: -1.989265 | GSw: -0.235048 | GSb: 0.064771 | TSUw: 0.464702 | TSUb: 0.035015\n",
      "\n",
      "Train Epoch: 2802 [4000/8000 (50%)]\tBatch Loss: 138.056597\tLearning Rate (w_theta): 0.001000\t TIME:7287.8s\n",
      "\t\t\t\tDisc: 0.738844\t\tSym: 8.764775\t\tSpars: 128.552979\n",
      "\t TVw: 0.217091 | TVb: -1.989200 | GSw: -0.235048 | GSb: 0.064771 | TSUw: 0.464702 | TSUb: 0.035015\n",
      "Validating epoch 2802...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 137.92402716710532\n",
      "Average validation loss: 24.487953008148285\n",
      "Training epoch 2803...\n",
      "\n",
      "Train Epoch: 2803 [0/8000 (0%)]\tBatch Loss: 138.984356\tLearning Rate (w_theta): 0.001000\t TIME:7290.4s\n",
      "\t\t\t\tDisc: 0.665574\t\tSym: 8.684016\t\tSpars: 129.634766\n",
      "\t TVw: 0.216501 | TVb: -1.989120 | GSw: -0.235048 | GSb: 0.064771 | TSUw: 0.464702 | TSUb: 0.035016\n",
      "\n",
      "Train Epoch: 2803 [4000/8000 (50%)]\tBatch Loss: 139.048851\tLearning Rate (w_theta): 0.001000\t TIME:7292.0s\n",
      "\t\t\t\tDisc: 0.654023\t\tSym: 10.031226\t\tSpars: 128.363602\n",
      "\t TVw: 0.216165 | TVb: -1.989038 | GSw: -0.235049 | GSb: 0.064771 | TSUw: 0.464701 | TSUb: 0.035016\n",
      "Validating epoch 2803...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 137.45293337979328\n",
      "Average validation loss: 24.831951678475377\n",
      "Training epoch 2804...\n",
      "\n",
      "Train Epoch: 2804 [0/8000 (0%)]\tBatch Loss: 134.883818\tLearning Rate (w_theta): 0.001000\t TIME:7294.6s\n",
      "\t\t\t\tDisc: 0.839617\t\tSym: 8.387081\t\tSpars: 125.657120\n",
      "\t TVw: 0.215769 | TVb: -1.988953 | GSw: -0.235049 | GSb: 0.064770 | TSUw: 0.464701 | TSUb: 0.035016\n",
      "\n",
      "Train Epoch: 2804 [4000/8000 (50%)]\tBatch Loss: 142.967014\tLearning Rate (w_theta): 0.001000\t TIME:7296.2s\n",
      "\t\t\t\tDisc: 0.885014\t\tSym: 8.995636\t\tSpars: 133.086365\n",
      "\t TVw: 0.214179 | TVb: -1.988957 | GSw: -0.235049 | GSb: 0.064770 | TSUw: 0.464701 | TSUb: 0.035016\n",
      "Validating epoch 2804...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 143.63595931132477\n",
      "Average validation loss: 24.103976177946883\n",
      "Training epoch 2805...\n",
      "\n",
      "Train Epoch: 2805 [0/8000 (0%)]\tBatch Loss: 156.781283\tLearning Rate (w_theta): 0.001000\t TIME:7298.8s\n",
      "\t\t\t\tDisc: 0.837188\t\tSym: 10.543887\t\tSpars: 145.400208\n",
      "\t TVw: 0.211723 | TVb: -1.989040 | GSw: -0.235049 | GSb: 0.064770 | TSUw: 0.464701 | TSUb: 0.035017\n",
      "\n",
      "Train Epoch: 2805 [4000/8000 (50%)]\tBatch Loss: 133.624134\tLearning Rate (w_theta): 0.001000\t TIME:7300.4s\n",
      "\t\t\t\tDisc: 0.589003\t\tSym: 8.755743\t\tSpars: 124.279388\n",
      "\t TVw: 0.209977 | TVb: -1.989095 | GSw: -0.235049 | GSb: 0.064769 | TSUw: 0.464700 | TSUb: 0.035017\n",
      "Validating epoch 2805...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 143.19499257330344\n",
      "Average validation loss: 23.168657748328084\n",
      "Training epoch 2806...\n",
      "\n",
      "Train Epoch: 2806 [0/8000 (0%)]\tBatch Loss: 139.507399\tLearning Rate (w_theta): 0.001000\t TIME:7303.1s\n",
      "\t\t\t\tDisc: 0.563733\t\tSym: 9.644349\t\tSpars: 129.299316\n",
      "\t TVw: 0.210739 | TVb: -1.988980 | GSw: -0.235049 | GSb: 0.064769 | TSUw: 0.464700 | TSUb: 0.035017\n",
      "\n",
      "Train Epoch: 2806 [4000/8000 (50%)]\tBatch Loss: 135.230087\tLearning Rate (w_theta): 0.001000\t TIME:7304.7s\n",
      "\t\t\t\tDisc: 0.601392\t\tSym: 9.426539\t\tSpars: 125.202156\n",
      "\t TVw: 0.213445 | TVb: -1.988729 | GSw: -0.235049 | GSb: 0.064769 | TSUw: 0.464700 | TSUb: 0.035017\n",
      "Validating epoch 2806...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 135.96144861101587\n",
      "Average validation loss: 23.94436755016078\n",
      "Training epoch 2807...\n",
      "\n",
      "Train Epoch: 2807 [0/8000 (0%)]\tBatch Loss: 137.166447\tLearning Rate (w_theta): 0.001000\t TIME:7307.3s\n",
      "\t\t\t\tDisc: 0.710371\t\tSym: 9.684278\t\tSpars: 126.771797\n",
      "\t TVw: 0.216400 | TVb: -1.988432 | GSw: -0.235049 | GSb: 0.064768 | TSUw: 0.464700 | TSUb: 0.035018\n",
      "\n",
      "Train Epoch: 2807 [4000/8000 (50%)]\tBatch Loss: 133.084932\tLearning Rate (w_theta): 0.001000\t TIME:7308.9s\n",
      "\t\t\t\tDisc: 0.742061\t\tSym: 9.207861\t\tSpars: 123.135010\n",
      "\t TVw: 0.218404 | TVb: -1.988172 | GSw: -0.235050 | GSb: 0.064768 | TSUw: 0.464700 | TSUb: 0.035018\n",
      "Validating epoch 2807...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 133.42283554704358\n",
      "Average validation loss: 24.575419788714278\n",
      "Training epoch 2808...\n",
      "\n",
      "Train Epoch: 2808 [0/8000 (0%)]\tBatch Loss: 130.409207\tLearning Rate (w_theta): 0.001000\t TIME:7311.4s\n",
      "\t\t\t\tDisc: 0.811587\t\tSym: 8.621493\t\tSpars: 120.976128\n",
      "\t TVw: 0.218842 | TVb: -1.988000 | GSw: -0.235050 | GSb: 0.064768 | TSUw: 0.464699 | TSUb: 0.035018\n",
      "\n",
      "Train Epoch: 2808 [4000/8000 (50%)]\tBatch Loss: 142.279030\tLearning Rate (w_theta): 0.001000\t TIME:7313.0s\n",
      "\t\t\t\tDisc: 0.748190\t\tSym: 9.716021\t\tSpars: 131.814819\n",
      "\t TVw: 0.217870 | TVb: -1.987913 | GSw: -0.235050 | GSb: 0.064768 | TSUw: 0.464699 | TSUb: 0.035018\n",
      "Validating epoch 2808...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 135.20353724912104\n",
      "Average validation loss: 24.229198436420624\n",
      "Training epoch 2809...\n",
      "\n",
      "Train Epoch: 2809 [0/8000 (0%)]\tBatch Loss: 136.647484\tLearning Rate (w_theta): 0.001000\t TIME:7315.6s\n",
      "\t\t\t\tDisc: 0.808431\t\tSym: 9.419559\t\tSpars: 126.419495\n",
      "\t TVw: 0.215906 | TVb: -1.987900 | GSw: -0.235050 | GSb: 0.064767 | TSUw: 0.464699 | TSUb: 0.035018\n",
      "\n",
      "Train Epoch: 2809 [4000/8000 (50%)]\tBatch Loss: 134.721346\tLearning Rate (w_theta): 0.001000\t TIME:7317.3s\n",
      "\t\t\t\tDisc: 0.774772\t\tSym: 8.525408\t\tSpars: 125.421165\n",
      "\t TVw: 0.213947 | TVb: -1.987883 | GSw: -0.235050 | GSb: 0.064767 | TSUw: 0.464699 | TSUb: 0.035019\n",
      "Validating epoch 2809...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 135.49198560536925\n",
      "Average validation loss: 23.61804790906338\n",
      "Training epoch 2810...\n",
      "\n",
      "Train Epoch: 2810 [0/8000 (0%)]\tBatch Loss: 134.074254\tLearning Rate (w_theta): 0.001000\t TIME:7319.8s\n",
      "\t\t\t\tDisc: 0.748888\t\tSym: 8.879428\t\tSpars: 124.445938\n",
      "\t TVw: 0.212233 | TVb: -1.987871 | GSw: -0.235050 | GSb: 0.064767 | TSUw: 0.464698 | TSUb: 0.035019\n",
      "\n",
      "Train Epoch: 2810 [4000/8000 (50%)]\tBatch Loss: 136.443905\tLearning Rate (w_theta): 0.001000\t TIME:7321.4s\n",
      "\t\t\t\tDisc: 0.710401\t\tSym: 8.894095\t\tSpars: 126.839409\n",
      "\t TVw: 0.211203 | TVb: -1.987822 | GSw: -0.235050 | GSb: 0.064767 | TSUw: 0.464698 | TSUb: 0.035019\n",
      "Validating epoch 2810...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 137.04514361011599\n",
      "Average validation loss: 23.472341974565435\n",
      "Training epoch 2811...\n",
      "\n",
      "Train Epoch: 2811 [0/8000 (0%)]\tBatch Loss: 141.654335\tLearning Rate (w_theta): 0.001000\t TIME:7325.2s\n",
      "\t\t\t\tDisc: 0.806305\t\tSym: 8.966301\t\tSpars: 131.881729\n",
      "\t TVw: 0.210516 | TVb: -1.987775 | GSw: -0.235050 | GSb: 0.064766 | TSUw: 0.464698 | TSUb: 0.035019\n",
      "\n",
      "Train Epoch: 2811 [4000/8000 (50%)]\tBatch Loss: 153.163972\tLearning Rate (w_theta): 0.001000\t TIME:7326.8s\n",
      "\t\t\t\tDisc: 0.839590\t\tSym: 10.861766\t\tSpars: 141.462616\n",
      "\t TVw: 0.209605 | TVb: -1.987750 | GSw: -0.235050 | GSb: 0.064766 | TSUw: 0.464698 | TSUb: 0.035020\n",
      "Validating epoch 2811...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 139.8439081795316\n",
      "Average validation loss: 22.92998105820738\n",
      "Training epoch 2812...\n",
      "\n",
      "Train Epoch: 2812 [0/8000 (0%)]\tBatch Loss: 139.976208\tLearning Rate (w_theta): 0.001000\t TIME:7329.3s\n",
      "\t\t\t\tDisc: 0.746489\t\tSym: 9.167692\t\tSpars: 130.062027\n",
      "\t TVw: 0.209606 | TVb: -1.987657 | GSw: -0.235051 | GSb: 0.064766 | TSUw: 0.464697 | TSUb: 0.035020\n",
      "\n",
      "Train Epoch: 2812 [4000/8000 (50%)]\tBatch Loss: 137.872219\tLearning Rate (w_theta): 0.001000\t TIME:7330.9s\n",
      "\t\t\t\tDisc: 0.631005\t\tSym: 9.450068\t\tSpars: 127.791145\n",
      "\t TVw: 0.210230 | TVb: -1.987554 | GSw: -0.235051 | GSb: 0.064765 | TSUw: 0.464697 | TSUb: 0.035020\n",
      "Validating epoch 2812...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 138.37029617438074\n",
      "Average validation loss: 22.681010195694856\n",
      "Training epoch 2813...\n",
      "\n",
      "Train Epoch: 2813 [0/8000 (0%)]\tBatch Loss: 132.607010\tLearning Rate (w_theta): 0.001000\t TIME:7333.4s\n",
      "\t\t\t\tDisc: 0.636498\t\tSym: 9.465408\t\tSpars: 122.505104\n",
      "\t TVw: 0.211753 | TVb: -1.987379 | GSw: -0.235051 | GSb: 0.064765 | TSUw: 0.464697 | TSUb: 0.035020\n",
      "\n",
      "Train Epoch: 2813 [4000/8000 (50%)]\tBatch Loss: 132.967883\tLearning Rate (w_theta): 0.001000\t TIME:7335.0s\n",
      "\t\t\t\tDisc: 0.721639\t\tSym: 9.271153\t\tSpars: 122.975090\n",
      "\t TVw: 0.213373 | TVb: -1.987168 | GSw: -0.235051 | GSb: 0.064765 | TSUw: 0.464697 | TSUb: 0.035021\n",
      "Validating epoch 2813...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 132.61977284797274\n",
      "Average validation loss: 23.13108545378187\n",
      "Training epoch 2814...\n",
      "\n",
      "Train Epoch: 2814 [0/8000 (0%)]\tBatch Loss: 134.819484\tLearning Rate (w_theta): 0.001000\t TIME:7337.5s\n",
      "\t\t\t\tDisc: 0.745290\t\tSym: 9.546904\t\tSpars: 124.527290\n",
      "\t TVw: 0.214433 | TVb: -1.986974 | GSw: -0.235051 | GSb: 0.064765 | TSUw: 0.464696 | TSUb: 0.035021\n",
      "\n",
      "Train Epoch: 2814 [4000/8000 (50%)]\tBatch Loss: 127.568618\tLearning Rate (w_theta): 0.001000\t TIME:7339.1s\n",
      "\t\t\t\tDisc: 0.779488\t\tSym: 8.512954\t\tSpars: 118.276176\n",
      "\t TVw: 0.214717 | TVb: -1.986810 | GSw: -0.235051 | GSb: 0.064764 | TSUw: 0.464696 | TSUb: 0.035021\n",
      "Validating epoch 2814...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 131.16101875474388\n",
      "Average validation loss: 22.934910350824634\n",
      "Training epoch 2815...\n",
      "\n",
      "Train Epoch: 2815 [0/8000 (0%)]\tBatch Loss: 128.109693\tLearning Rate (w_theta): 0.001000\t TIME:7341.6s\n",
      "\t\t\t\tDisc: 0.690183\t\tSym: 8.662705\t\tSpars: 118.756805\n",
      "\t TVw: 0.213917 | TVb: -1.986703 | GSw: -0.235051 | GSb: 0.064764 | TSUw: 0.464696 | TSUb: 0.035021\n",
      "\n",
      "Train Epoch: 2815 [4000/8000 (50%)]\tBatch Loss: 128.333939\tLearning Rate (w_theta): 0.001000\t TIME:7343.2s\n",
      "\t\t\t\tDisc: 0.679674\t\tSym: 8.599005\t\tSpars: 119.055260\n",
      "\t TVw: 0.212765 | TVb: -1.986634 | GSw: -0.235051 | GSb: 0.064764 | TSUw: 0.464696 | TSUb: 0.035021\n",
      "Validating epoch 2815...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 130.2116638472666\n",
      "Average validation loss: 22.77757552004503\n",
      "Training epoch 2816...\n",
      "\n",
      "Train Epoch: 2816 [0/8000 (0%)]\tBatch Loss: 123.665178\tLearning Rate (w_theta): 0.001000\t TIME:7345.7s\n",
      "\t\t\t\tDisc: 0.714967\t\tSym: 8.103622\t\tSpars: 114.846588\n",
      "\t TVw: 0.212040 | TVb: -1.986549 | GSw: -0.235052 | GSb: 0.064763 | TSUw: 0.464695 | TSUb: 0.035022\n",
      "\n",
      "Train Epoch: 2816 [4000/8000 (50%)]\tBatch Loss: 128.587005\tLearning Rate (w_theta): 0.001000\t TIME:7347.4s\n",
      "\t\t\t\tDisc: 0.688783\t\tSym: 8.908361\t\tSpars: 118.989861\n",
      "\t TVw: 0.211717 | TVb: -1.986452 | GSw: -0.235052 | GSb: 0.064763 | TSUw: 0.464695 | TSUb: 0.035022\n",
      "Validating epoch 2816...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 129.37922657447132\n",
      "Average validation loss: 22.41185825541896\n",
      "Training epoch 2817...\n",
      "\n",
      "Train Epoch: 2817 [0/8000 (0%)]\tBatch Loss: 136.034410\tLearning Rate (w_theta): 0.001000\t TIME:7349.8s\n",
      "\t\t\t\tDisc: 0.670802\t\tSym: 10.387488\t\tSpars: 124.976120\n",
      "\t TVw: 0.211733 | TVb: -1.986314 | GSw: -0.235052 | GSb: 0.064763 | TSUw: 0.464695 | TSUb: 0.035022\n",
      "\n",
      "Train Epoch: 2817 [4000/8000 (50%)]\tBatch Loss: 130.690873\tLearning Rate (w_theta): 0.001000\t TIME:7351.5s\n",
      "\t\t\t\tDisc: 0.770032\t\tSym: 8.897045\t\tSpars: 121.023796\n",
      "\t TVw: 0.211367 | TVb: -1.986202 | GSw: -0.235052 | GSb: 0.064763 | TSUw: 0.464695 | TSUb: 0.035022\n",
      "Validating epoch 2817...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 133.85124528083662\n",
      "Average validation loss: 22.565909351497837\n",
      "Training epoch 2818...\n",
      "\n",
      "Train Epoch: 2818 [0/8000 (0%)]\tBatch Loss: 129.221465\tLearning Rate (w_theta): 0.001000\t TIME:7354.0s\n",
      "\t\t\t\tDisc: 0.760868\t\tSym: 8.535197\t\tSpars: 119.925400\n",
      "\t TVw: 0.210254 | TVb: -1.986127 | GSw: -0.235052 | GSb: 0.064762 | TSUw: 0.464695 | TSUb: 0.035023\n",
      "\n",
      "Train Epoch: 2818 [4000/8000 (50%)]\tBatch Loss: 139.848267\tLearning Rate (w_theta): 0.001000\t TIME:7355.6s\n",
      "\t\t\t\tDisc: 0.716409\t\tSym: 10.349051\t\tSpars: 128.782806\n",
      "\t TVw: 0.208786 | TVb: -1.986086 | GSw: -0.235052 | GSb: 0.064762 | TSUw: 0.464694 | TSUb: 0.035023\n",
      "Validating epoch 2818...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 134.00533464163064\n",
      "Average validation loss: 22.380676045066913\n",
      "Training epoch 2819...\n",
      "\n",
      "Train Epoch: 2819 [0/8000 (0%)]\tBatch Loss: 140.243467\tLearning Rate (w_theta): 0.001000\t TIME:7358.0s\n",
      "\t\t\t\tDisc: 0.748275\t\tSym: 9.664442\t\tSpars: 129.830750\n",
      "\t TVw: 0.208017 | TVb: -1.985994 | GSw: -0.235052 | GSb: 0.064762 | TSUw: 0.464694 | TSUb: 0.035023\n",
      "\n",
      "Train Epoch: 2819 [4000/8000 (50%)]\tBatch Loss: 126.899776\tLearning Rate (w_theta): 0.001000\t TIME:7359.6s\n",
      "\t\t\t\tDisc: 0.617502\t\tSym: 8.708497\t\tSpars: 117.573776\n",
      "\t TVw: 0.206924 | TVb: -1.985960 | GSw: -0.235052 | GSb: 0.064761 | TSUw: 0.464694 | TSUb: 0.035023\n",
      "Validating epoch 2819...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 134.4966721292397\n",
      "Average validation loss: 21.67932174512382\n",
      "Training epoch 2820...\n",
      "\n",
      "Train Epoch: 2820 [0/8000 (0%)]\tBatch Loss: 131.227746\tLearning Rate (w_theta): 0.001000\t TIME:7362.2s\n",
      "\t\t\t\tDisc: 0.587088\t\tSym: 9.207232\t\tSpars: 121.433426\n",
      "\t TVw: 0.207313 | TVb: -1.985833 | GSw: -0.235052 | GSb: 0.064761 | TSUw: 0.464694 | TSUb: 0.035024\n",
      "\n",
      "Train Epoch: 2820 [4000/8000 (50%)]\tBatch Loss: 129.828531\tLearning Rate (w_theta): 0.001000\t TIME:7363.8s\n",
      "\t\t\t\tDisc: 0.613819\t\tSym: 9.565649\t\tSpars: 119.649063\n",
      "\t TVw: 0.208672 | TVb: -1.985640 | GSw: -0.235053 | GSb: 0.064761 | TSUw: 0.464693 | TSUb: 0.035024\n",
      "Validating epoch 2820...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 129.76857795268623\n",
      "Average validation loss: 21.97699009903175\n",
      "Training epoch 2821...\n",
      "\n",
      "Train Epoch: 2821 [0/8000 (0%)]\tBatch Loss: 131.353181\tLearning Rate (w_theta): 0.001000\t TIME:7367.0s\n",
      "\t\t\t\tDisc: 0.667257\t\tSym: 9.692394\t\tSpars: 120.993530\n",
      "\t TVw: 0.209875 | TVb: -1.985439 | GSw: -0.235053 | GSb: 0.064761 | TSUw: 0.464693 | TSUb: 0.035024\n",
      "\n",
      "Train Epoch: 2821 [4000/8000 (50%)]\tBatch Loss: 122.270663\tLearning Rate (w_theta): 0.001000\t TIME:7368.6s\n",
      "\t\t\t\tDisc: 0.682109\t\tSym: 8.363509\t\tSpars: 113.225044\n",
      "\t TVw: 0.210546 | TVb: -1.985266 | GSw: -0.235053 | GSb: 0.064760 | TSUw: 0.464693 | TSUb: 0.035024\n",
      "Validating epoch 2821...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 127.80647790696466\n",
      "Average validation loss: 22.10328040215797\n",
      "Training epoch 2822...\n",
      "\n",
      "Train Epoch: 2822 [0/8000 (0%)]\tBatch Loss: 130.317688\tLearning Rate (w_theta): 0.001000\t TIME:7371.1s\n",
      "\t\t\t\tDisc: 0.698411\t\tSym: 9.142982\t\tSpars: 120.476295\n",
      "\t TVw: 0.210399 | TVb: -1.985156 | GSw: -0.235053 | GSb: 0.064760 | TSUw: 0.464693 | TSUb: 0.035024\n",
      "\n",
      "Train Epoch: 2822 [4000/8000 (50%)]\tBatch Loss: 125.519375\tLearning Rate (w_theta): 0.001000\t TIME:7372.8s\n",
      "\t\t\t\tDisc: 0.718949\t\tSym: 8.785769\t\tSpars: 116.014656\n",
      "\t TVw: 0.210100 | TVb: -1.985074 | GSw: -0.235053 | GSb: 0.064760 | TSUw: 0.464692 | TSUb: 0.035025\n",
      "Validating epoch 2822...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 127.08784896090744\n",
      "Average validation loss: 22.00768487807221\n",
      "Training epoch 2823...\n",
      "\n",
      "Train Epoch: 2823 [0/8000 (0%)]\tBatch Loss: 123.394089\tLearning Rate (w_theta): 0.001000\t TIME:7375.2s\n",
      "\t\t\t\tDisc: 0.737208\t\tSym: 8.335233\t\tSpars: 114.321648\n",
      "\t TVw: 0.209705 | TVb: -1.984983 | GSw: -0.235053 | GSb: 0.064759 | TSUw: 0.464692 | TSUb: 0.035025\n",
      "\n",
      "Train Epoch: 2823 [4000/8000 (50%)]\tBatch Loss: 126.360065\tLearning Rate (w_theta): 0.001000\t TIME:7376.8s\n",
      "\t\t\t\tDisc: 0.725839\t\tSym: 8.915468\t\tSpars: 116.718758\n",
      "\t TVw: 0.209302 | TVb: -1.984891 | GSw: -0.235053 | GSb: 0.064759 | TSUw: 0.464692 | TSUb: 0.035025\n",
      "Validating epoch 2823...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 127.03248314053634\n",
      "Average validation loss: 21.847376019590417\n",
      "Training epoch 2824...\n",
      "\n",
      "Train Epoch: 2824 [0/8000 (0%)]\tBatch Loss: 132.824570\tLearning Rate (w_theta): 0.001000\t TIME:7379.4s\n",
      "\t\t\t\tDisc: 0.729650\t\tSym: 10.074428\t\tSpars: 122.020493\n",
      "\t TVw: 0.209178 | TVb: -1.984776 | GSw: -0.235053 | GSb: 0.064759 | TSUw: 0.464692 | TSUb: 0.035025\n",
      "\n",
      "Train Epoch: 2824 [4000/8000 (50%)]\tBatch Loss: 127.157770\tLearning Rate (w_theta): 0.001000\t TIME:7381.0s\n",
      "\t\t\t\tDisc: 0.718994\t\tSym: 9.201853\t\tSpars: 117.236923\n",
      "\t TVw: 0.209183 | TVb: -1.984652 | GSw: -0.235053 | GSb: 0.064759 | TSUw: 0.464691 | TSUb: 0.035026\n",
      "Validating epoch 2824...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 126.16242847322317\n",
      "Average validation loss: 21.78743031836519\n",
      "Training epoch 2825...\n",
      "\n",
      "Train Epoch: 2825 [0/8000 (0%)]\tBatch Loss: 120.997711\tLearning Rate (w_theta): 0.001000\t TIME:7384.0s\n",
      "\t\t\t\tDisc: 0.717485\t\tSym: 8.508619\t\tSpars: 111.771606\n",
      "\t TVw: 0.209204 | TVb: -1.984515 | GSw: -0.235053 | GSb: 0.064758 | TSUw: 0.464691 | TSUb: 0.035026\n",
      "\n",
      "Train Epoch: 2825 [4000/8000 (50%)]\tBatch Loss: 127.631961\tLearning Rate (w_theta): 0.001000\t TIME:7385.6s\n",
      "\t\t\t\tDisc: 0.724075\t\tSym: 9.007289\t\tSpars: 117.900597\n",
      "\t TVw: 0.209103 | TVb: -1.984402 | GSw: -0.235053 | GSb: 0.064758 | TSUw: 0.464691 | TSUb: 0.035026\n",
      "Validating epoch 2825...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 125.75372493465866\n",
      "Average validation loss: 21.605292321395456\n",
      "Training epoch 2826...\n",
      "\n",
      "Train Epoch: 2826 [0/8000 (0%)]\tBatch Loss: 123.306719\tLearning Rate (w_theta): 0.001000\t TIME:7388.1s\n",
      "\t\t\t\tDisc: 0.679398\t\tSym: 8.485941\t\tSpars: 114.141380\n",
      "\t TVw: 0.208791 | TVb: -1.984305 | GSw: -0.235054 | GSb: 0.064758 | TSUw: 0.464691 | TSUb: 0.035026\n",
      "\n",
      "Train Epoch: 2826 [4000/8000 (50%)]\tBatch Loss: 132.640231\tLearning Rate (w_theta): 0.001000\t TIME:7389.7s\n",
      "\t\t\t\tDisc: 0.650027\t\tSym: 9.636987\t\tSpars: 122.353218\n",
      "\t TVw: 0.208534 | TVb: -1.984202 | GSw: -0.235054 | GSb: 0.064758 | TSUw: 0.464690 | TSUb: 0.035026\n",
      "Validating epoch 2826...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 126.28606437600473\n",
      "Average validation loss: 21.576508680732537\n",
      "Training epoch 2827...\n",
      "\n",
      "Train Epoch: 2827 [0/8000 (0%)]\tBatch Loss: 126.686425\tLearning Rate (w_theta): 0.001000\t TIME:7392.2s\n",
      "\t\t\t\tDisc: 0.723944\t\tSym: 9.032244\t\tSpars: 116.930237\n",
      "\t TVw: 0.208262 | TVb: -1.984108 | GSw: -0.235054 | GSb: 0.064757 | TSUw: 0.464690 | TSUb: 0.035027\n",
      "\n",
      "Train Epoch: 2827 [4000/8000 (50%)]\tBatch Loss: 122.183077\tLearning Rate (w_theta): 0.001000\t TIME:7393.8s\n",
      "\t\t\t\tDisc: 0.692372\t\tSym: 8.261739\t\tSpars: 113.228966\n",
      "\t TVw: 0.207914 | TVb: -1.984019 | GSw: -0.235054 | GSb: 0.064757 | TSUw: 0.464690 | TSUb: 0.035027\n",
      "Validating epoch 2827...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 125.3169312650198\n",
      "Average validation loss: 21.271807913447315\n",
      "Training epoch 2828...\n",
      "\n",
      "Train Epoch: 2828 [0/8000 (0%)]\tBatch Loss: 124.849884\tLearning Rate (w_theta): 0.001000\t TIME:7396.3s\n",
      "\t\t\t\tDisc: 0.657072\t\tSym: 9.106051\t\tSpars: 115.086761\n",
      "\t TVw: 0.207835 | TVb: -1.983906 | GSw: -0.235054 | GSb: 0.064757 | TSUw: 0.464690 | TSUb: 0.035027\n",
      "\n",
      "Train Epoch: 2828 [4000/8000 (50%)]\tBatch Loss: 127.904256\tLearning Rate (w_theta): 0.001000\t TIME:7397.9s\n",
      "\t\t\t\tDisc: 0.654033\t\tSym: 9.398431\t\tSpars: 117.851791\n",
      "\t TVw: 0.207976 | TVb: -1.983766 | GSw: -0.235054 | GSb: 0.064757 | TSUw: 0.464690 | TSUb: 0.035027\n",
      "Validating epoch 2828...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 124.86172303204322\n",
      "Average validation loss: 21.245873106513113\n",
      "Training epoch 2829...\n",
      "\n",
      "Train Epoch: 2829 [0/8000 (0%)]\tBatch Loss: 120.346563\tLearning Rate (w_theta): 0.001000\t TIME:7400.4s\n",
      "\t\t\t\tDisc: 0.710545\t\tSym: 8.541200\t\tSpars: 111.094818\n",
      "\t TVw: 0.207810 | TVb: -1.983640 | GSw: -0.235054 | GSb: 0.064756 | TSUw: 0.464689 | TSUb: 0.035028\n",
      "\n",
      "Train Epoch: 2829 [4000/8000 (50%)]\tBatch Loss: 128.887637\tLearning Rate (w_theta): 0.001000\t TIME:7402.0s\n",
      "\t\t\t\tDisc: 0.754623\t\tSym: 9.752192\t\tSpars: 118.380821\n",
      "\t TVw: 0.207659 | TVb: -1.983525 | GSw: -0.235054 | GSb: 0.064756 | TSUw: 0.464689 | TSUb: 0.035028\n",
      "Validating epoch 2829...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 124.17633985208144\n",
      "Average validation loss: 21.131540830718862\n",
      "Training epoch 2830...\n",
      "\n",
      "Train Epoch: 2830 [0/8000 (0%)]\tBatch Loss: 120.747149\tLearning Rate (w_theta): 0.001000\t TIME:7404.5s\n",
      "\t\t\t\tDisc: 0.695907\t\tSym: 8.390857\t\tSpars: 111.660385\n",
      "\t TVw: 0.207456 | TVb: -1.983411 | GSw: -0.235054 | GSb: 0.064756 | TSUw: 0.464689 | TSUb: 0.035028\n",
      "\n",
      "Train Epoch: 2830 [4000/8000 (50%)]\tBatch Loss: 127.723556\tLearning Rate (w_theta): 0.001000\t TIME:7406.1s\n",
      "\t\t\t\tDisc: 0.692146\t\tSym: 9.463454\t\tSpars: 117.567955\n",
      "\t TVw: 0.207322 | TVb: -1.983284 | GSw: -0.235054 | GSb: 0.064755 | TSUw: 0.464689 | TSUb: 0.035028\n",
      "Validating epoch 2830...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 123.88343564360054\n",
      "Average validation loss: 21.056810450271648\n",
      "Training epoch 2831...\n",
      "\n",
      "Train Epoch: 2831 [0/8000 (0%)]\tBatch Loss: 124.084343\tLearning Rate (w_theta): 0.001000\t TIME:7409.3s\n",
      "\t\t\t\tDisc: 0.696643\t\tSym: 9.028844\t\tSpars: 114.358856\n",
      "\t TVw: 0.207170 | TVb: -1.983167 | GSw: -0.235054 | GSb: 0.064755 | TSUw: 0.464688 | TSUb: 0.035028\n",
      "\n",
      "Train Epoch: 2831 [4000/8000 (50%)]\tBatch Loss: 125.334797\tLearning Rate (w_theta): 0.001000\t TIME:7411.0s\n",
      "\t\t\t\tDisc: 0.697858\t\tSym: 9.083533\t\tSpars: 115.553406\n",
      "\t TVw: 0.206945 | TVb: -1.983053 | GSw: -0.235054 | GSb: 0.064755 | TSUw: 0.464688 | TSUb: 0.035029\n",
      "Validating epoch 2831...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 123.2117173442166\n",
      "Average validation loss: 21.057099747665525\n",
      "Training epoch 2832...\n",
      "\n",
      "Train Epoch: 2832 [0/8000 (0%)]\tBatch Loss: 117.643216\tLearning Rate (w_theta): 0.001000\t TIME:7413.4s\n",
      "\t\t\t\tDisc: 0.725090\t\tSym: 8.942097\t\tSpars: 107.976028\n",
      "\t TVw: 0.206810 | TVb: -1.982936 | GSw: -0.235054 | GSb: 0.064755 | TSUw: 0.464688 | TSUb: 0.035029\n",
      "\n",
      "Train Epoch: 2832 [4000/8000 (50%)]\tBatch Loss: 120.137542\tLearning Rate (w_theta): 0.001000\t TIME:7415.0s\n",
      "\t\t\t\tDisc: 0.669679\t\tSym: 8.446394\t\tSpars: 111.021469\n",
      "\t TVw: 0.206458 | TVb: -1.982819 | GSw: -0.235054 | GSb: 0.064754 | TSUw: 0.464688 | TSUb: 0.035029\n",
      "Validating epoch 2832...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 123.07648423953202\n",
      "Average validation loss: 20.819556742941497\n",
      "Training epoch 2833...\n",
      "\n",
      "Train Epoch: 2833 [0/8000 (0%)]\tBatch Loss: 125.792458\tLearning Rate (w_theta): 0.001000\t TIME:7417.5s\n",
      "\t\t\t\tDisc: 0.668725\t\tSym: 9.429642\t\tSpars: 115.694092\n",
      "\t TVw: 0.206284 | TVb: -1.982689 | GSw: -0.235054 | GSb: 0.064754 | TSUw: 0.464687 | TSUb: 0.035029\n",
      "\n",
      "Train Epoch: 2833 [4000/8000 (50%)]\tBatch Loss: 121.633472\tLearning Rate (w_theta): 0.001000\t TIME:7419.1s\n",
      "\t\t\t\tDisc: 0.754563\t\tSym: 8.358218\t\tSpars: 112.520691\n",
      "\t TVw: 0.205742 | TVb: -1.982587 | GSw: -0.235055 | GSb: 0.064754 | TSUw: 0.464687 | TSUb: 0.035029\n",
      "Validating epoch 2833...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 126.34818650017306\n",
      "Average validation loss: 20.99674997062177\n",
      "Training epoch 2834...\n",
      "\n",
      "Train Epoch: 2834 [0/8000 (0%)]\tBatch Loss: 130.582684\tLearning Rate (w_theta): 0.001000\t TIME:7421.6s\n",
      "\t\t\t\tDisc: 0.756008\t\tSym: 9.316216\t\tSpars: 120.510460\n",
      "\t TVw: 0.204310 | TVb: -1.982545 | GSw: -0.235055 | GSb: 0.064754 | TSUw: 0.464687 | TSUb: 0.035030\n",
      "\n",
      "Train Epoch: 2834 [4000/8000 (50%)]\tBatch Loss: 126.306534\tLearning Rate (w_theta): 0.001000\t TIME:7423.3s\n",
      "\t\t\t\tDisc: 0.675174\t\tSym: 8.886723\t\tSpars: 116.744637\n",
      "\t TVw: 0.202673 | TVb: -1.982510 | GSw: -0.235055 | GSb: 0.064753 | TSUw: 0.464687 | TSUb: 0.035030\n",
      "Validating epoch 2834...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 127.76247571758685\n",
      "Average validation loss: 20.585016272978542\n",
      "Training epoch 2835...\n",
      "\n",
      "Train Epoch: 2835 [0/8000 (0%)]\tBatch Loss: 131.911287\tLearning Rate (w_theta): 0.001000\t TIME:7425.8s\n",
      "\t\t\t\tDisc: 0.746045\t\tSym: 9.512815\t\tSpars: 121.652428\n",
      "\t TVw: 0.201774 | TVb: -1.982433 | GSw: -0.235055 | GSb: 0.064753 | TSUw: 0.464686 | TSUb: 0.035030\n",
      "\n",
      "Train Epoch: 2835 [4000/8000 (50%)]\tBatch Loss: 127.774073\tLearning Rate (w_theta): 0.001000\t TIME:7427.4s\n",
      "\t\t\t\tDisc: 0.690551\t\tSym: 8.995921\t\tSpars: 118.087601\n",
      "\t TVw: 0.201245 | TVb: -1.982342 | GSw: -0.235055 | GSb: 0.064753 | TSUw: 0.464686 | TSUb: 0.035030\n",
      "Validating epoch 2835...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 129.91432113598486\n",
      "Average validation loss: 20.16965073746575\n",
      "Training epoch 2836...\n",
      "\n",
      "Train Epoch: 2836 [0/8000 (0%)]\tBatch Loss: 119.218485\tLearning Rate (w_theta): 0.001000\t TIME:7429.9s\n",
      "\t\t\t\tDisc: 0.620197\t\tSym: 9.051139\t\tSpars: 109.547150\n",
      "\t TVw: 0.201373 | TVb: -1.982207 | GSw: -0.235055 | GSb: 0.064752 | TSUw: 0.464686 | TSUb: 0.035031\n",
      "\n",
      "Train Epoch: 2836 [4000/8000 (50%)]\tBatch Loss: 130.447162\tLearning Rate (w_theta): 0.001000\t TIME:7431.4s\n",
      "\t\t\t\tDisc: 0.634205\t\tSym: 10.339378\t\tSpars: 119.473579\n",
      "\t TVw: 0.202557 | TVb: -1.981998 | GSw: -0.235055 | GSb: 0.064752 | TSUw: 0.464686 | TSUb: 0.035031\n",
      "Validating epoch 2836...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 123.23186896647694\n",
      "Average validation loss: 20.54412272198655\n",
      "Training epoch 2837...\n",
      "\n",
      "Train Epoch: 2837 [0/8000 (0%)]\tBatch Loss: 124.026638\tLearning Rate (w_theta): 0.001000\t TIME:7434.0s\n",
      "\t\t\t\tDisc: 0.683648\t\tSym: 9.449588\t\tSpars: 113.893402\n",
      "\t TVw: 0.204240 | TVb: -1.981761 | GSw: -0.235055 | GSb: 0.064752 | TSUw: 0.464685 | TSUb: 0.035031\n",
      "\n",
      "Train Epoch: 2837 [4000/8000 (50%)]\tBatch Loss: 115.383806\tLearning Rate (w_theta): 0.001000\t TIME:7435.6s\n",
      "\t\t\t\tDisc: 0.700076\t\tSym: 8.404906\t\tSpars: 106.278824\n",
      "\t TVw: 0.205436 | TVb: -1.981539 | GSw: -0.235056 | GSb: 0.064751 | TSUw: 0.464685 | TSUb: 0.035031\n",
      "Validating epoch 2837...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 123.42937042683333\n",
      "Average validation loss: 20.517941835259755\n",
      "Training epoch 2838...\n",
      "\n",
      "Train Epoch: 2838 [0/8000 (0%)]\tBatch Loss: 122.962864\tLearning Rate (w_theta): 0.001000\t TIME:7438.1s\n",
      "\t\t\t\tDisc: 0.675129\t\tSym: 8.763847\t\tSpars: 113.523888\n",
      "\t TVw: 0.205009 | TVb: -1.981416 | GSw: -0.235056 | GSb: 0.064751 | TSUw: 0.464685 | TSUb: 0.035032\n",
      "\n",
      "Train Epoch: 2838 [4000/8000 (50%)]\tBatch Loss: 123.094550\tLearning Rate (w_theta): 0.001000\t TIME:7439.7s\n",
      "\t\t\t\tDisc: 0.647952\t\tSym: 9.353207\t\tSpars: 113.093391\n",
      "\t TVw: 0.203194 | TVb: -1.981371 | GSw: -0.235056 | GSb: 0.064751 | TSUw: 0.464685 | TSUb: 0.035032\n",
      "Validating epoch 2838...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 125.68721052508205\n",
      "Average validation loss: 20.09351761526302\n",
      "Training epoch 2839...\n",
      "\n",
      "Train Epoch: 2839 [0/8000 (0%)]\tBatch Loss: 121.502204\tLearning Rate (w_theta): 0.001000\t TIME:7442.4s\n",
      "\t\t\t\tDisc: 0.615857\t\tSym: 8.913454\t\tSpars: 111.972893\n",
      "\t TVw: 0.201116 | TVb: -1.981357 | GSw: -0.235056 | GSb: 0.064751 | TSUw: 0.464685 | TSUb: 0.035032\n",
      "\n",
      "Train Epoch: 2839 [4000/8000 (50%)]\tBatch Loss: 116.085198\tLearning Rate (w_theta): 0.001000\t TIME:7444.0s\n",
      "\t\t\t\tDisc: 0.582385\t\tSym: 8.637274\t\tSpars: 106.865540\n",
      "\t TVw: 0.199646 | TVb: -1.981308 | GSw: -0.235056 | GSb: 0.064750 | TSUw: 0.464684 | TSUb: 0.035032\n",
      "Validating epoch 2839...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 126.99841878038141\n",
      "Average validation loss: 20.223894280895383\n",
      "Training epoch 2840...\n",
      "\n",
      "Train Epoch: 2840 [0/8000 (0%)]\tBatch Loss: 129.101435\tLearning Rate (w_theta): 0.001000\t TIME:7446.4s\n",
      "\t\t\t\tDisc: 0.715546\t\tSym: 9.302011\t\tSpars: 119.083878\n",
      "\t TVw: 0.199229 | TVb: -1.981194 | GSw: -0.235056 | GSb: 0.064750 | TSUw: 0.464684 | TSUb: 0.035032\n",
      "\n",
      "Train Epoch: 2840 [4000/8000 (50%)]\tBatch Loss: 138.758293\tLearning Rate (w_theta): 0.001000\t TIME:7448.0s\n",
      "\t\t\t\tDisc: 0.872747\t\tSym: 10.459063\t\tSpars: 127.426483\n",
      "\t TVw: 0.199314 | TVb: -1.981069 | GSw: -0.235056 | GSb: 0.064750 | TSUw: 0.464684 | TSUb: 0.035033\n",
      "Validating epoch 2840...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 128.8521610818359\n",
      "Average validation loss: 20.53493024503278\n",
      "Training epoch 2841...\n",
      "\n",
      "Train Epoch: 2841 [0/8000 (0%)]\tBatch Loss: 138.190708\tLearning Rate (w_theta): 0.001000\t TIME:7451.7s\n",
      "\t\t\t\tDisc: 1.039853\t\tSym: 9.597297\t\tSpars: 127.553558\n",
      "\t TVw: 0.199835 | TVb: -1.980901 | GSw: -0.235056 | GSb: 0.064749 | TSUw: 0.464684 | TSUb: 0.035033\n",
      "\n",
      "Train Epoch: 2841 [4000/8000 (50%)]\tBatch Loss: 120.090313\tLearning Rate (w_theta): 0.001000\t TIME:7453.3s\n",
      "\t\t\t\tDisc: 0.516868\t\tSym: 8.836391\t\tSpars: 110.737053\n",
      "\t TVw: 0.199216 | TVb: -1.980846 | GSw: -0.235057 | GSb: 0.064749 | TSUw: 0.464683 | TSUb: 0.035033\n",
      "Validating epoch 2841...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 132.40736645688105\n",
      "Average validation loss: 19.30643475295104\n",
      "Training epoch 2842...\n",
      "\n",
      "Train Epoch: 2842 [0/8000 (0%)]\tBatch Loss: 137.722795\tLearning Rate (w_theta): 0.001000\t TIME:7455.8s\n",
      "\t\t\t\tDisc: 0.557647\t\tSym: 9.905978\t\tSpars: 127.259171\n",
      "\t TVw: 0.198939 | TVb: -1.980814 | GSw: -0.235057 | GSb: 0.064749 | TSUw: 0.464683 | TSUb: 0.035033\n",
      "\n",
      "Train Epoch: 2842 [4000/8000 (50%)]\tBatch Loss: 123.478111\tLearning Rate (w_theta): 0.001000\t TIME:7457.4s\n",
      "\t\t\t\tDisc: 0.558606\t\tSym: 9.550097\t\tSpars: 113.369408\n",
      "\t TVw: 0.198323 | TVb: -1.980815 | GSw: -0.235057 | GSb: 0.064748 | TSUw: 0.464683 | TSUb: 0.035034\n",
      "Validating epoch 2842...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 141.34887393980884\n",
      "Average validation loss: 19.959657487598577\n",
      "Training epoch 2843...\n",
      "\n",
      "Train Epoch: 2843 [0/8000 (0%)]\tBatch Loss: 143.992213\tLearning Rate (w_theta): 0.001000\t TIME:7459.9s\n",
      "\t\t\t\tDisc: 1.164192\t\tSym: 10.357593\t\tSpars: 132.470428\n",
      "\t TVw: 0.199267 | TVb: -1.980581 | GSw: -0.235057 | GSb: 0.064748 | TSUw: 0.464683 | TSUb: 0.035034\n",
      "\n",
      "Train Epoch: 2843 [4000/8000 (50%)]\tBatch Loss: 143.918734\tLearning Rate (w_theta): 0.001000\t TIME:7461.5s\n",
      "\t\t\t\tDisc: 0.561396\t\tSym: 10.841682\t\tSpars: 132.515656\n",
      "\t TVw: 0.198470 | TVb: -1.980551 | GSw: -0.235057 | GSb: 0.064747 | TSUw: 0.464682 | TSUb: 0.035034\n",
      "Validating epoch 2843...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 140.50408091007844\n",
      "Average validation loss: 19.33457602086277\n",
      "Training epoch 2844...\n",
      "\n",
      "Train Epoch: 2844 [0/8000 (0%)]\tBatch Loss: 120.530850\tLearning Rate (w_theta): 0.001000\t TIME:7464.0s\n",
      "\t\t\t\tDisc: 0.543938\t\tSym: 8.933049\t\tSpars: 111.053864\n",
      "\t TVw: 0.199467 | TVb: -1.980364 | GSw: -0.235057 | GSb: 0.064747 | TSUw: 0.464682 | TSUb: 0.035035\n",
      "\n",
      "Train Epoch: 2844 [4000/8000 (50%)]\tBatch Loss: 135.061298\tLearning Rate (w_theta): 0.001000\t TIME:7465.7s\n",
      "\t\t\t\tDisc: 0.974698\t\tSym: 9.555511\t\tSpars: 124.531090\n",
      "\t TVw: 0.201347 | TVb: -1.980033 | GSw: -0.235057 | GSb: 0.064747 | TSUw: 0.464682 | TSUb: 0.035035\n",
      "Validating epoch 2844...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 129.88720638887207\n",
      "Average validation loss: 19.733419419785704\n",
      "Training epoch 2845...\n",
      "\n",
      "Train Epoch: 2845 [0/8000 (0%)]\tBatch Loss: 118.071651\tLearning Rate (w_theta): 0.001000\t TIME:7468.2s\n",
      "\t\t\t\tDisc: 0.640369\t\tSym: 8.357750\t\tSpars: 109.073532\n",
      "\t TVw: 0.202713 | TVb: -1.979788 | GSw: -0.235057 | GSb: 0.064746 | TSUw: 0.464681 | TSUb: 0.035035\n",
      "\n",
      "Train Epoch: 2845 [4000/8000 (50%)]\tBatch Loss: 120.664054\tLearning Rate (w_theta): 0.001000\t TIME:7469.8s\n",
      "\t\t\t\tDisc: 0.668455\t\tSym: 9.450166\t\tSpars: 110.545433\n",
      "\t TVw: 0.204152 | TVb: -1.979481 | GSw: -0.235058 | GSb: 0.064746 | TSUw: 0.464681 | TSUb: 0.035035\n",
      "Validating epoch 2845...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 121.52590902284837\n",
      "Average validation loss: 20.042019544744576\n",
      "Training epoch 2846...\n",
      "\n",
      "Train Epoch: 2846 [0/8000 (0%)]\tBatch Loss: 120.360273\tLearning Rate (w_theta): 0.001000\t TIME:7472.2s\n",
      "\t\t\t\tDisc: 0.694230\t\tSym: 8.797185\t\tSpars: 110.868858\n",
      "\t TVw: 0.204890 | TVb: -1.979168 | GSw: -0.235058 | GSb: 0.064746 | TSUw: 0.464681 | TSUb: 0.035036\n",
      "\n",
      "Train Epoch: 2846 [4000/8000 (50%)]\tBatch Loss: 115.065938\tLearning Rate (w_theta): 0.001000\t TIME:7473.8s\n",
      "\t\t\t\tDisc: 0.755953\t\tSym: 8.917819\t\tSpars: 105.392166\n",
      "\t TVw: 0.204746 | TVb: -1.978895 | GSw: -0.235058 | GSb: 0.064745 | TSUw: 0.464680 | TSUb: 0.035036\n",
      "Validating epoch 2846...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 119.25928649973221\n",
      "Average validation loss: 20.405986919949356\n",
      "Training epoch 2847...\n",
      "\n",
      "Train Epoch: 2847 [0/8000 (0%)]\tBatch Loss: 118.252379\tLearning Rate (w_theta): 0.001000\t TIME:7476.4s\n",
      "\t\t\t\tDisc: 0.771616\t\tSym: 9.374592\t\tSpars: 108.106171\n",
      "\t TVw: 0.203687 | TVb: -1.978725 | GSw: -0.235058 | GSb: 0.064745 | TSUw: 0.464680 | TSUb: 0.035036\n",
      "\n",
      "Train Epoch: 2847 [4000/8000 (50%)]\tBatch Loss: 118.184277\tLearning Rate (w_theta): 0.001000\t TIME:7477.9s\n",
      "\t\t\t\tDisc: 0.738057\t\tSym: 9.156479\t\tSpars: 108.289742\n",
      "\t TVw: 0.202369 | TVb: -1.978598 | GSw: -0.235058 | GSb: 0.064745 | TSUw: 0.464680 | TSUb: 0.035036\n",
      "Validating epoch 2847...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 118.67439338364044\n",
      "Average validation loss: 20.22862797410887\n",
      "Training epoch 2848...\n",
      "\n",
      "Train Epoch: 2848 [0/8000 (0%)]\tBatch Loss: 111.714145\tLearning Rate (w_theta): 0.001000\t TIME:7480.4s\n",
      "\t\t\t\tDisc: 0.748256\t\tSym: 7.829635\t\tSpars: 103.136253\n",
      "\t TVw: 0.201502 | TVb: -1.978462 | GSw: -0.235058 | GSb: 0.064744 | TSUw: 0.464680 | TSUb: 0.035037\n",
      "\n",
      "Train Epoch: 2848 [4000/8000 (50%)]\tBatch Loss: 123.553703\tLearning Rate (w_theta): 0.001000\t TIME:7482.0s\n",
      "\t\t\t\tDisc: 0.785597\t\tSym: 9.765352\t\tSpars: 113.002754\n",
      "\t TVw: 0.201113 | TVb: -1.978323 | GSw: -0.235058 | GSb: 0.064744 | TSUw: 0.464679 | TSUb: 0.035037\n",
      "Validating epoch 2848...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 118.82338307559175\n",
      "Average validation loss: 20.200208384553882\n",
      "Training epoch 2849...\n",
      "\n",
      "Train Epoch: 2849 [0/8000 (0%)]\tBatch Loss: 115.281313\tLearning Rate (w_theta): 0.001000\t TIME:7484.5s\n",
      "\t\t\t\tDisc: 0.717241\t\tSym: 8.582306\t\tSpars: 105.981766\n",
      "\t TVw: 0.201137 | TVb: -1.978172 | GSw: -0.235058 | GSb: 0.064744 | TSUw: 0.464679 | TSUb: 0.035037\n",
      "\n",
      "Train Epoch: 2849 [4000/8000 (50%)]\tBatch Loss: 122.915235\tLearning Rate (w_theta): 0.001000\t TIME:7486.1s\n",
      "\t\t\t\tDisc: 0.713636\t\tSym: 9.453598\t\tSpars: 112.748001\n",
      "\t TVw: 0.201316 | TVb: -1.978025 | GSw: -0.235059 | GSb: 0.064744 | TSUw: 0.464679 | TSUb: 0.035037\n",
      "Validating epoch 2849...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 117.30310850919972\n",
      "Average validation loss: 20.2244174948039\n",
      "Training epoch 2850...\n",
      "\n",
      "Train Epoch: 2850 [0/8000 (0%)]\tBatch Loss: 119.240737\tLearning Rate (w_theta): 0.001000\t TIME:7488.6s\n",
      "\t\t\t\tDisc: 0.736595\t\tSym: 8.976676\t\tSpars: 109.527466\n",
      "\t TVw: 0.201558 | TVb: -1.977865 | GSw: -0.235059 | GSb: 0.064743 | TSUw: 0.464679 | TSUb: 0.035038\n",
      "\n",
      "Train Epoch: 2850 [4000/8000 (50%)]\tBatch Loss: 115.871380\tLearning Rate (w_theta): 0.001000\t TIME:7490.3s\n",
      "\t\t\t\tDisc: 0.753168\t\tSym: 9.151346\t\tSpars: 105.966866\n",
      "\t TVw: 0.201698 | TVb: -1.977712 | GSw: -0.235059 | GSb: 0.064743 | TSUw: 0.464678 | TSUb: 0.035038\n",
      "Validating epoch 2850...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 117.02685715922769\n",
      "Average validation loss: 20.19026625633625\n",
      "Training epoch 2851...\n",
      "\n",
      "Train Epoch: 2851 [0/8000 (0%)]\tBatch Loss: 121.968327\tLearning Rate (w_theta): 0.001000\t TIME:7493.5s\n",
      "\t\t\t\tDisc: 0.740419\t\tSym: 9.825610\t\tSpars: 111.402298\n",
      "\t TVw: 0.201506 | TVb: -1.977569 | GSw: -0.235059 | GSb: 0.064743 | TSUw: 0.464678 | TSUb: 0.035038\n",
      "\n",
      "Train Epoch: 2851 [4000/8000 (50%)]\tBatch Loss: 118.381688\tLearning Rate (w_theta): 0.001000\t TIME:7495.3s\n",
      "\t\t\t\tDisc: 0.756228\t\tSym: 9.212778\t\tSpars: 108.412682\n",
      "\t TVw: 0.201301 | TVb: -1.977450 | GSw: -0.235059 | GSb: 0.064742 | TSUw: 0.464678 | TSUb: 0.035038\n",
      "Validating epoch 2851...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 116.01676893778776\n",
      "Average validation loss: 19.997914416076387\n",
      "Training epoch 2852...\n",
      "\n",
      "Train Epoch: 2852 [0/8000 (0%)]\tBatch Loss: 113.481956\tLearning Rate (w_theta): 0.001000\t TIME:7497.8s\n",
      "\t\t\t\tDisc: 0.744136\t\tSym: 8.736858\t\tSpars: 104.000961\n",
      "\t TVw: 0.201013 | TVb: -1.977346 | GSw: -0.235059 | GSb: 0.064742 | TSUw: 0.464678 | TSUb: 0.035038\n",
      "\n",
      "Train Epoch: 2852 [4000/8000 (50%)]\tBatch Loss: 117.966244\tLearning Rate (w_theta): 0.001000\t TIME:7499.4s\n",
      "\t\t\t\tDisc: 0.738844\t\tSym: 9.218550\t\tSpars: 108.008850\n",
      "\t TVw: 0.200778 | TVb: -1.977221 | GSw: -0.235059 | GSb: 0.064742 | TSUw: 0.464677 | TSUb: 0.035039\n",
      "Validating epoch 2852...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 115.68566876617491\n",
      "Average validation loss: 19.781961501758293\n",
      "Training epoch 2853...\n",
      "\n",
      "Train Epoch: 2853 [0/8000 (0%)]\tBatch Loss: 119.642655\tLearning Rate (w_theta): 0.001000\t TIME:7501.9s\n",
      "\t\t\t\tDisc: 0.724272\t\tSym: 9.767840\t\tSpars: 109.150543\n",
      "\t TVw: 0.200694 | TVb: -1.977089 | GSw: -0.235059 | GSb: 0.064742 | TSUw: 0.464677 | TSUb: 0.035039\n",
      "\n",
      "Train Epoch: 2853 [4000/8000 (50%)]\tBatch Loss: 115.368463\tLearning Rate (w_theta): 0.001000\t TIME:7503.5s\n",
      "\t\t\t\tDisc: 0.684905\t\tSym: 8.863092\t\tSpars: 105.820465\n",
      "\t TVw: 0.200545 | TVb: -1.976950 | GSw: -0.235059 | GSb: 0.064741 | TSUw: 0.464677 | TSUb: 0.035039\n",
      "Validating epoch 2853...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 115.74114964434986\n",
      "Average validation loss: 19.650991710081048\n",
      "Training epoch 2854...\n",
      "\n",
      "Train Epoch: 2854 [0/8000 (0%)]\tBatch Loss: 114.851996\tLearning Rate (w_theta): 0.001000\t TIME:7506.1s\n",
      "\t\t\t\tDisc: 0.681754\t\tSym: 8.754874\t\tSpars: 105.415367\n",
      "\t TVw: 0.200293 | TVb: -1.976816 | GSw: -0.235059 | GSb: 0.064741 | TSUw: 0.464677 | TSUb: 0.035039\n",
      "\n",
      "Train Epoch: 2854 [4000/8000 (50%)]\tBatch Loss: 112.998645\tLearning Rate (w_theta): 0.001000\t TIME:7507.7s\n",
      "\t\t\t\tDisc: 0.674293\t\tSym: 8.755772\t\tSpars: 103.568581\n",
      "\t TVw: 0.199564 | TVb: -1.976699 | GSw: -0.235059 | GSb: 0.064741 | TSUw: 0.464676 | TSUb: 0.035040\n",
      "Validating epoch 2854...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 117.71235353902064\n",
      "Average validation loss: 19.363270830844474\n",
      "Training epoch 2855...\n",
      "\n",
      "Train Epoch: 2855 [0/8000 (0%)]\tBatch Loss: 113.799380\tLearning Rate (w_theta): 0.001000\t TIME:7510.2s\n",
      "\t\t\t\tDisc: 0.628154\t\tSym: 8.825759\t\tSpars: 104.345467\n",
      "\t TVw: 0.198673 | TVb: -1.976608 | GSw: -0.235060 | GSb: 0.064740 | TSUw: 0.464676 | TSUb: 0.035040\n",
      "\n",
      "Train Epoch: 2855 [4000/8000 (50%)]\tBatch Loss: 108.083513\tLearning Rate (w_theta): 0.001000\t TIME:7511.8s\n",
      "\t\t\t\tDisc: 0.645146\t\tSym: 7.808477\t\tSpars: 99.629890\n",
      "\t TVw: 0.198069 | TVb: -1.976519 | GSw: -0.235060 | GSb: 0.064740 | TSUw: 0.464676 | TSUb: 0.035040\n",
      "Validating epoch 2855...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 117.27482776564696\n",
      "Average validation loss: 19.198123661947314\n",
      "Training epoch 2856...\n",
      "\n",
      "Train Epoch: 2856 [0/8000 (0%)]\tBatch Loss: 111.329155\tLearning Rate (w_theta): 0.001000\t TIME:7514.8s\n",
      "\t\t\t\tDisc: 0.609848\t\tSym: 8.705864\t\tSpars: 102.013443\n",
      "\t TVw: 0.197843 | TVb: -1.976374 | GSw: -0.235060 | GSb: 0.064740 | TSUw: 0.464676 | TSUb: 0.035040\n",
      "\n",
      "Train Epoch: 2856 [4000/8000 (50%)]\tBatch Loss: 110.589896\tLearning Rate (w_theta): 0.001000\t TIME:7516.4s\n",
      "\t\t\t\tDisc: 0.620036\t\tSym: 8.561596\t\tSpars: 101.408264\n",
      "\t TVw: 0.198030 | TVb: -1.976217 | GSw: -0.235060 | GSb: 0.064739 | TSUw: 0.464676 | TSUb: 0.035040\n",
      "Validating epoch 2856...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 115.34749519391292\n",
      "Average validation loss: 19.20341810262236\n",
      "Training epoch 2857...\n",
      "\n",
      "Train Epoch: 2857 [0/8000 (0%)]\tBatch Loss: 119.016374\tLearning Rate (w_theta): 0.001000\t TIME:7518.8s\n",
      "\t\t\t\tDisc: 0.641813\t\tSym: 9.493899\t\tSpars: 108.880661\n",
      "\t TVw: 0.198293 | TVb: -1.976059 | GSw: -0.235060 | GSb: 0.064739 | TSUw: 0.464675 | TSUb: 0.035041\n",
      "\n",
      "Train Epoch: 2857 [4000/8000 (50%)]\tBatch Loss: 112.093720\tLearning Rate (w_theta): 0.001000\t TIME:7520.4s\n",
      "\t\t\t\tDisc: 0.666342\t\tSym: 8.440982\t\tSpars: 102.986397\n",
      "\t TVw: 0.198576 | TVb: -1.975898 | GSw: -0.235060 | GSb: 0.064739 | TSUw: 0.464675 | TSUb: 0.035041\n",
      "Validating epoch 2857...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 113.97779799447508\n",
      "Average validation loss: 19.334069048950244\n",
      "Training epoch 2858...\n",
      "\n",
      "Train Epoch: 2858 [0/8000 (0%)]\tBatch Loss: 107.560080\tLearning Rate (w_theta): 0.001000\t TIME:7523.1s\n",
      "\t\t\t\tDisc: 0.665057\t\tSym: 8.180217\t\tSpars: 98.714806\n",
      "\t TVw: 0.198763 | TVb: -1.975752 | GSw: -0.235060 | GSb: 0.064739 | TSUw: 0.464675 | TSUb: 0.035041\n",
      "\n",
      "Train Epoch: 2858 [4000/8000 (50%)]\tBatch Loss: 106.968377\tLearning Rate (w_theta): 0.001000\t TIME:7524.6s\n",
      "\t\t\t\tDisc: 0.653232\t\tSym: 7.999104\t\tSpars: 98.316040\n",
      "\t TVw: 0.198941 | TVb: -1.975583 | GSw: -0.235060 | GSb: 0.064738 | TSUw: 0.464675 | TSUb: 0.035041\n",
      "Validating epoch 2858...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 113.54755646682493\n",
      "Average validation loss: 19.53720998158152\n",
      "Training epoch 2859...\n",
      "\n",
      "Train Epoch: 2859 [0/8000 (0%)]\tBatch Loss: 115.019767\tLearning Rate (w_theta): 0.001000\t TIME:7527.1s\n",
      "\t\t\t\tDisc: 0.709841\t\tSym: 9.305654\t\tSpars: 105.004272\n",
      "\t TVw: 0.199154 | TVb: -1.975396 | GSw: -0.235060 | GSb: 0.064738 | TSUw: 0.464674 | TSUb: 0.035041\n",
      "\n",
      "Train Epoch: 2859 [4000/8000 (50%)]\tBatch Loss: 109.980376\tLearning Rate (w_theta): 0.001000\t TIME:7528.7s\n",
      "\t\t\t\tDisc: 0.707802\t\tSym: 8.311271\t\tSpars: 100.961304\n",
      "\t TVw: 0.199124 | TVb: -1.975236 | GSw: -0.235061 | GSb: 0.064738 | TSUw: 0.464674 | TSUb: 0.035042\n",
      "Validating epoch 2859...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 112.70999723886092\n",
      "Average validation loss: 19.74614022130788\n",
      "Training epoch 2860...\n",
      "\n",
      "Train Epoch: 2860 [0/8000 (0%)]\tBatch Loss: 112.037962\tLearning Rate (w_theta): 0.001000\t TIME:7531.2s\n",
      "\t\t\t\tDisc: 0.732261\t\tSym: 8.464347\t\tSpars: 102.841354\n",
      "\t TVw: 0.198955 | TVb: -1.975079 | GSw: -0.235061 | GSb: 0.064737 | TSUw: 0.464674 | TSUb: 0.035042\n",
      "\n",
      "Train Epoch: 2860 [4000/8000 (50%)]\tBatch Loss: 115.891777\tLearning Rate (w_theta): 0.001000\t TIME:7532.8s\n",
      "\t\t\t\tDisc: 0.754029\t\tSym: 9.389762\t\tSpars: 105.747986\n",
      "\t TVw: 0.198507 | TVb: -1.974976 | GSw: -0.235061 | GSb: 0.064737 | TSUw: 0.464674 | TSUb: 0.035042\n",
      "Validating epoch 2860...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 112.5786847268219\n",
      "Average validation loss: 19.547454441430506\n",
      "Training epoch 2861...\n",
      "\n",
      "Train Epoch: 2861 [0/8000 (0%)]\tBatch Loss: 119.239505\tLearning Rate (w_theta): 0.001000\t TIME:7536.0s\n",
      "\t\t\t\tDisc: 0.712923\t\tSym: 9.726182\t\tSpars: 108.800400\n",
      "\t TVw: 0.198125 | TVb: -1.974865 | GSw: -0.235061 | GSb: 0.064737 | TSUw: 0.464673 | TSUb: 0.035042\n",
      "\n",
      "Train Epoch: 2861 [4000/8000 (50%)]\tBatch Loss: 112.540257\tLearning Rate (w_theta): 0.001000\t TIME:7537.7s\n",
      "\t\t\t\tDisc: 0.710851\t\tSym: 9.000770\t\tSpars: 102.828636\n",
      "\t TVw: 0.198172 | TVb: -1.974744 | GSw: -0.235061 | GSb: 0.064737 | TSUw: 0.464673 | TSUb: 0.035043\n",
      "Validating epoch 2861...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 111.94521135998825\n",
      "Average validation loss: 19.38986402334421\n",
      "Training epoch 2862...\n",
      "\n",
      "Train Epoch: 2862 [0/8000 (0%)]\tBatch Loss: 120.044734\tLearning Rate (w_theta): 0.001000\t TIME:7540.2s\n",
      "\t\t\t\tDisc: 0.682083\t\tSym: 10.181727\t\tSpars: 109.180923\n",
      "\t TVw: 0.198603 | TVb: -1.974586 | GSw: -0.235061 | GSb: 0.064736 | TSUw: 0.464673 | TSUb: 0.035043\n",
      "\n",
      "Train Epoch: 2862 [4000/8000 (50%)]\tBatch Loss: 108.519557\tLearning Rate (w_theta): 0.001000\t TIME:7541.9s\n",
      "\t\t\t\tDisc: 0.718894\t\tSym: 8.451023\t\tSpars: 99.349640\n",
      "\t TVw: 0.199069 | TVb: -1.974421 | GSw: -0.235061 | GSb: 0.064736 | TSUw: 0.464673 | TSUb: 0.035043\n",
      "Validating epoch 2862...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 111.71075282218305\n",
      "Average validation loss: 19.599558229239182\n",
      "Training epoch 2863...\n",
      "\n",
      "Train Epoch: 2863 [0/8000 (0%)]\tBatch Loss: 110.774760\tLearning Rate (w_theta): 0.001000\t TIME:7544.3s\n",
      "\t\t\t\tDisc: 0.717424\t\tSym: 8.521226\t\tSpars: 101.536110\n",
      "\t TVw: 0.199269 | TVb: -1.974281 | GSw: -0.235061 | GSb: 0.064736 | TSUw: 0.464672 | TSUb: 0.035043\n",
      "\n",
      "Train Epoch: 2863 [4000/8000 (50%)]\tBatch Loss: 114.800810\tLearning Rate (w_theta): 0.001000\t TIME:7546.0s\n",
      "\t\t\t\tDisc: 0.715326\t\tSym: 9.102704\t\tSpars: 104.982780\n",
      "\t TVw: 0.199113 | TVb: -1.974169 | GSw: -0.235061 | GSb: 0.064735 | TSUw: 0.464672 | TSUb: 0.035043\n",
      "Validating epoch 2863...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 111.31401452284993\n",
      "Average validation loss: 19.53077149192677\n",
      "Training epoch 2864...\n",
      "\n",
      "Train Epoch: 2864 [0/8000 (0%)]\tBatch Loss: 112.522182\tLearning Rate (w_theta): 0.001000\t TIME:7548.5s\n",
      "\t\t\t\tDisc: 0.739067\t\tSym: 8.861758\t\tSpars: 102.921356\n",
      "\t TVw: 0.198858 | TVb: -1.974041 | GSw: -0.235061 | GSb: 0.064735 | TSUw: 0.464672 | TSUb: 0.035044\n",
      "\n",
      "Train Epoch: 2864 [4000/8000 (50%)]\tBatch Loss: 113.002034\tLearning Rate (w_theta): 0.001000\t TIME:7550.1s\n",
      "\t\t\t\tDisc: 0.757424\t\tSym: 9.018375\t\tSpars: 103.226234\n",
      "\t TVw: 0.198430 | TVb: -1.973920 | GSw: -0.235061 | GSb: 0.064735 | TSUw: 0.464672 | TSUb: 0.035044\n",
      "Validating epoch 2864...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 111.43529047065608\n",
      "Average validation loss: 19.221620267879395\n",
      "Training epoch 2865...\n",
      "\n",
      "Train Epoch: 2865 [0/8000 (0%)]\tBatch Loss: 115.726919\tLearning Rate (w_theta): 0.001000\t TIME:7552.6s\n",
      "\t\t\t\tDisc: 0.693542\t\tSym: 9.674810\t\tSpars: 105.358566\n",
      "\t TVw: 0.198017 | TVb: -1.973788 | GSw: -0.235061 | GSb: 0.064735 | TSUw: 0.464671 | TSUb: 0.035044\n",
      "\n",
      "Train Epoch: 2865 [4000/8000 (50%)]\tBatch Loss: 112.933898\tLearning Rate (w_theta): 0.001000\t TIME:7555.8s\n",
      "\t\t\t\tDisc: 0.697985\t\tSym: 9.282178\t\tSpars: 102.953735\n",
      "\t TVw: 0.197807 | TVb: -1.973642 | GSw: -0.235061 | GSb: 0.064734 | TSUw: 0.464671 | TSUb: 0.035044\n",
      "Validating epoch 2865...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 110.54338579313978\n",
      "Average validation loss: 19.27025122682165\n",
      "Training epoch 2866...\n",
      "\n",
      "Train Epoch: 2866 [0/8000 (0%)]\tBatch Loss: 110.437493\tLearning Rate (w_theta): 0.001000\t TIME:7558.3s\n",
      "\t\t\t\tDisc: 0.697292\t\tSym: 8.650006\t\tSpars: 101.090195\n",
      "\t TVw: 0.197862 | TVb: -1.973476 | GSw: -0.235061 | GSb: 0.064734 | TSUw: 0.464671 | TSUb: 0.035044\n",
      "\n",
      "Train Epoch: 2866 [4000/8000 (50%)]\tBatch Loss: 114.387316\tLearning Rate (w_theta): 0.001000\t TIME:7559.9s\n",
      "\t\t\t\tDisc: 0.747139\t\tSym: 9.677402\t\tSpars: 103.962776\n",
      "\t TVw: 0.197992 | TVb: -1.973316 | GSw: -0.235061 | GSb: 0.064734 | TSUw: 0.464671 | TSUb: 0.035045\n",
      "Validating epoch 2866...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 110.17905351489229\n",
      "Average validation loss: 19.347522645487857\n",
      "Training epoch 2867...\n",
      "\n",
      "Train Epoch: 2867 [0/8000 (0%)]\tBatch Loss: 105.455095\tLearning Rate (w_theta): 0.001000\t TIME:7562.4s\n",
      "\t\t\t\tDisc: 0.716875\t\tSym: 8.171333\t\tSpars: 96.566887\n",
      "\t TVw: 0.197827 | TVb: -1.973158 | GSw: -0.235061 | GSb: 0.064733 | TSUw: 0.464671 | TSUb: 0.035045\n",
      "\n",
      "Train Epoch: 2867 [4000/8000 (50%)]\tBatch Loss: 118.628497\tLearning Rate (w_theta): 0.001000\t TIME:7564.0s\n",
      "\t\t\t\tDisc: 0.736895\t\tSym: 10.258355\t\tSpars: 107.633247\n",
      "\t TVw: 0.197375 | TVb: -1.973002 | GSw: -0.235061 | GSb: 0.064733 | TSUw: 0.464670 | TSUb: 0.035045\n",
      "Validating epoch 2867...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 109.98907683458815\n",
      "Average validation loss: 19.379581631554252\n",
      "Training epoch 2868...\n",
      "\n",
      "Train Epoch: 2868 [0/8000 (0%)]\tBatch Loss: 106.095577\tLearning Rate (w_theta): 0.001000\t TIME:7566.5s\n",
      "\t\t\t\tDisc: 0.725161\t\tSym: 7.934091\t\tSpars: 97.436325\n",
      "\t TVw: 0.196861 | TVb: -1.972873 | GSw: -0.235062 | GSb: 0.064733 | TSUw: 0.464670 | TSUb: 0.035045\n",
      "\n",
      "Train Epoch: 2868 [4000/8000 (50%)]\tBatch Loss: 114.106306\tLearning Rate (w_theta): 0.001000\t TIME:7568.1s\n",
      "\t\t\t\tDisc: 0.667739\t\tSym: 9.796584\t\tSpars: 103.641983\n",
      "\t TVw: 0.196214 | TVb: -1.972733 | GSw: -0.235062 | GSb: 0.064733 | TSUw: 0.464670 | TSUb: 0.035045\n",
      "Validating epoch 2868...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 110.11821827631763\n",
      "Average validation loss: 19.13519460623634\n",
      "Training epoch 2869...\n",
      "\n",
      "Train Epoch: 2869 [0/8000 (0%)]\tBatch Loss: 106.521187\tLearning Rate (w_theta): 0.001000\t TIME:7570.6s\n",
      "\t\t\t\tDisc: 0.685968\t\tSym: 8.479079\t\tSpars: 97.356140\n",
      "\t TVw: 0.195510 | TVb: -1.972611 | GSw: -0.235062 | GSb: 0.064732 | TSUw: 0.464670 | TSUb: 0.035046\n",
      "\n",
      "Train Epoch: 2869 [4000/8000 (50%)]\tBatch Loss: 109.509308\tLearning Rate (w_theta): 0.001000\t TIME:7572.2s\n",
      "\t\t\t\tDisc: 0.712907\t\tSym: 8.882430\t\tSpars: 99.913971\n",
      "\t TVw: 0.194934 | TVb: -1.972493 | GSw: -0.235062 | GSb: 0.064732 | TSUw: 0.464669 | TSUb: 0.035046\n",
      "Validating epoch 2869...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 109.23661088462242\n",
      "Average validation loss: 18.953855463290786\n",
      "Training epoch 2870...\n",
      "\n",
      "Train Epoch: 2870 [0/8000 (0%)]\tBatch Loss: 110.110505\tLearning Rate (w_theta): 0.001000\t TIME:7574.7s\n",
      "\t\t\t\tDisc: 0.665433\t\tSym: 8.965411\t\tSpars: 100.479660\n",
      "\t TVw: 0.194836 | TVb: -1.972337 | GSw: -0.235062 | GSb: 0.064732 | TSUw: 0.464669 | TSUb: 0.035046\n",
      "\n",
      "Train Epoch: 2870 [4000/8000 (50%)]\tBatch Loss: 106.333990\tLearning Rate (w_theta): 0.001000\t TIME:7576.3s\n",
      "\t\t\t\tDisc: 0.664826\t\tSym: 8.942700\t\tSpars: 96.726463\n",
      "\t TVw: 0.194923 | TVb: -1.972170 | GSw: -0.235062 | GSb: 0.064731 | TSUw: 0.464669 | TSUb: 0.035046\n",
      "Validating epoch 2870...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 109.03027802138959\n",
      "Average validation loss: 19.215954376360713\n",
      "Training epoch 2871...\n",
      "\n",
      "Train Epoch: 2871 [0/8000 (0%)]\tBatch Loss: 112.862947\tLearning Rate (w_theta): 0.001000\t TIME:7580.0s\n",
      "\t\t\t\tDisc: 0.740221\t\tSym: 9.145209\t\tSpars: 102.977516\n",
      "\t TVw: 0.194832 | TVb: -1.972001 | GSw: -0.235062 | GSb: 0.064731 | TSUw: 0.464669 | TSUb: 0.035047\n",
      "\n",
      "Train Epoch: 2871 [4000/8000 (50%)]\tBatch Loss: 113.129188\tLearning Rate (w_theta): 0.001000\t TIME:7581.6s\n",
      "\t\t\t\tDisc: 0.755994\t\tSym: 9.384166\t\tSpars: 102.989029\n",
      "\t TVw: 0.194027 | TVb: -1.971900 | GSw: -0.235062 | GSb: 0.064731 | TSUw: 0.464668 | TSUb: 0.035047\n",
      "Validating epoch 2871...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 112.4961537283358\n",
      "Average validation loss: 18.788544781044735\n",
      "Training epoch 2872...\n",
      "\n",
      "Train Epoch: 2872 [0/8000 (0%)]\tBatch Loss: 108.581168\tLearning Rate (w_theta): 0.001000\t TIME:7584.1s\n",
      "\t\t\t\tDisc: 0.695530\t\tSym: 8.992418\t\tSpars: 98.893219\n",
      "\t TVw: 0.192464 | TVb: -1.971850 | GSw: -0.235062 | GSb: 0.064730 | TSUw: 0.464668 | TSUb: 0.035047\n",
      "\n",
      "Train Epoch: 2872 [4000/8000 (50%)]\tBatch Loss: 121.412658\tLearning Rate (w_theta): 0.001000\t TIME:7585.7s\n",
      "\t\t\t\tDisc: 0.886593\t\tSym: 9.443759\t\tSpars: 111.082306\n",
      "\t TVw: 0.190276 | TVb: -1.971860 | GSw: -0.235062 | GSb: 0.064730 | TSUw: 0.464668 | TSUb: 0.035047\n",
      "Validating epoch 2872...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 120.03990671773005\n",
      "Average validation loss: 18.491411330889846\n",
      "Training epoch 2873...\n",
      "\n",
      "Train Epoch: 2873 [0/8000 (0%)]\tBatch Loss: 129.452598\tLearning Rate (w_theta): 0.001000\t TIME:7588.2s\n",
      "\t\t\t\tDisc: 0.928913\t\tSym: 10.291302\t\tSpars: 118.232384\n",
      "\t TVw: 0.187819 | TVb: -1.971948 | GSw: -0.235062 | GSb: 0.064730 | TSUw: 0.464668 | TSUb: 0.035047\n",
      "\n",
      "Train Epoch: 2873 [4000/8000 (50%)]\tBatch Loss: 129.360049\tLearning Rate (w_theta): 0.001000\t TIME:7589.8s\n",
      "\t\t\t\tDisc: 0.764436\t\tSym: 10.497255\t\tSpars: 118.098358\n",
      "\t TVw: 0.187329 | TVb: -1.971878 | GSw: -0.235062 | GSb: 0.064729 | TSUw: 0.464667 | TSUb: 0.035048\n",
      "Validating epoch 2873...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 117.65215029032163\n",
      "Average validation loss: 18.121848467023664\n",
      "Training epoch 2874...\n",
      "\n",
      "Train Epoch: 2874 [0/8000 (0%)]\tBatch Loss: 106.741192\tLearning Rate (w_theta): 0.001000\t TIME:7592.4s\n",
      "\t\t\t\tDisc: 0.614739\t\tSym: 7.967007\t\tSpars: 98.159447\n",
      "\t TVw: 0.189308 | TVb: -1.971627 | GSw: -0.235063 | GSb: 0.064729 | TSUw: 0.464667 | TSUb: 0.035048\n",
      "\n",
      "Train Epoch: 2874 [4000/8000 (50%)]\tBatch Loss: 121.442049\tLearning Rate (w_theta): 0.001000\t TIME:7594.0s\n",
      "\t\t\t\tDisc: 0.561795\t\tSym: 10.237439\t\tSpars: 110.642815\n",
      "\t TVw: 0.191925 | TVb: -1.971325 | GSw: -0.235063 | GSb: 0.064729 | TSUw: 0.464667 | TSUb: 0.035048\n",
      "Validating epoch 2874...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 117.35736838644404\n",
      "Average validation loss: 17.97571154954302\n",
      "Training epoch 2875...\n",
      "\n",
      "Train Epoch: 2875 [0/8000 (0%)]\tBatch Loss: 120.934565\tLearning Rate (w_theta): 0.001000\t TIME:7596.4s\n",
      "\t\t\t\tDisc: 0.588464\t\tSym: 10.280680\t\tSpars: 110.065422\n",
      "\t TVw: 0.193684 | TVb: -1.971102 | GSw: -0.235063 | GSb: 0.064728 | TSUw: 0.464667 | TSUb: 0.035048\n",
      "\n",
      "Train Epoch: 2875 [4000/8000 (50%)]\tBatch Loss: 117.828620\tLearning Rate (w_theta): 0.001000\t TIME:7598.0s\n",
      "\t\t\t\tDisc: 0.644117\t\tSym: 9.953897\t\tSpars: 107.230606\n",
      "\t TVw: 0.195080 | TVb: -1.970839 | GSw: -0.235063 | GSb: 0.064728 | TSUw: 0.464666 | TSUb: 0.035049\n",
      "Validating epoch 2875...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 111.28158318727718\n",
      "Average validation loss: 18.658718755305802\n",
      "Training epoch 2876...\n",
      "\n",
      "Train Epoch: 2876 [0/8000 (0%)]\tBatch Loss: 104.250423\tLearning Rate (w_theta): 0.001000\t TIME:7600.5s\n",
      "\t\t\t\tDisc: 0.671089\t\tSym: 8.307689\t\tSpars: 95.271645\n",
      "\t TVw: 0.195583 | TVb: -1.970604 | GSw: -0.235063 | GSb: 0.064728 | TSUw: 0.464666 | TSUb: 0.035049\n",
      "\n",
      "Train Epoch: 2876 [4000/8000 (50%)]\tBatch Loss: 108.382591\tLearning Rate (w_theta): 0.001000\t TIME:7602.1s\n",
      "\t\t\t\tDisc: 0.726754\t\tSym: 8.764693\t\tSpars: 98.891144\n",
      "\t TVw: 0.195409 | TVb: -1.970349 | GSw: -0.235063 | GSb: 0.064727 | TSUw: 0.464666 | TSUb: 0.035049\n",
      "Validating epoch 2876...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 108.39586140867699\n",
      "Average validation loss: 18.735366756734212\n",
      "Training epoch 2877...\n",
      "\n",
      "Train Epoch: 2877 [0/8000 (0%)]\tBatch Loss: 113.468405\tLearning Rate (w_theta): 0.001000\t TIME:7604.7s\n",
      "\t\t\t\tDisc: 0.698327\t\tSym: 9.760489\t\tSpars: 103.009590\n",
      "\t TVw: 0.194400 | TVb: -1.970150 | GSw: -0.235063 | GSb: 0.064727 | TSUw: 0.464666 | TSUb: 0.035049\n",
      "\n",
      "Train Epoch: 2877 [4000/8000 (50%)]\tBatch Loss: 104.266589\tLearning Rate (w_theta): 0.001000\t TIME:7606.3s\n",
      "\t\t\t\tDisc: 0.741486\t\tSym: 8.270578\t\tSpars: 95.254524\n",
      "\t TVw: 0.193067 | TVb: -1.969982 | GSw: -0.235063 | GSb: 0.064727 | TSUw: 0.464666 | TSUb: 0.035050\n",
      "Validating epoch 2877...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 108.62908513330886\n",
      "Average validation loss: 18.841910350191455\n",
      "Training epoch 2878...\n",
      "\n",
      "Train Epoch: 2878 [0/8000 (0%)]\tBatch Loss: 115.828223\tLearning Rate (w_theta): 0.001000\t TIME:7608.8s\n",
      "\t\t\t\tDisc: 0.726612\t\tSym: 10.383632\t\tSpars: 104.717979\n",
      "\t TVw: 0.191918 | TVb: -1.969849 | GSw: -0.235064 | GSb: 0.064726 | TSUw: 0.464665 | TSUb: 0.035050\n",
      "\n",
      "Train Epoch: 2878 [4000/8000 (50%)]\tBatch Loss: 104.123321\tLearning Rate (w_theta): 0.001000\t TIME:7610.4s\n",
      "\t\t\t\tDisc: 0.713223\t\tSym: 8.276919\t\tSpars: 95.133179\n",
      "\t TVw: 0.191463 | TVb: -1.969678 | GSw: -0.235064 | GSb: 0.064726 | TSUw: 0.464665 | TSUb: 0.035050\n",
      "Validating epoch 2878...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 106.76889351201132\n",
      "Average validation loss: 18.485404621929607\n",
      "Training epoch 2879...\n",
      "\n",
      "Train Epoch: 2879 [0/8000 (0%)]\tBatch Loss: 106.859037\tLearning Rate (w_theta): 0.001000\t TIME:7612.9s\n",
      "\t\t\t\tDisc: 0.676631\t\tSym: 9.144732\t\tSpars: 97.037674\n",
      "\t TVw: 0.191336 | TVb: -1.969493 | GSw: -0.235064 | GSb: 0.064726 | TSUw: 0.464665 | TSUb: 0.035050\n",
      "\n",
      "Train Epoch: 2879 [4000/8000 (50%)]\tBatch Loss: 109.004816\tLearning Rate (w_theta): 0.001000\t TIME:7614.5s\n",
      "\t\t\t\tDisc: 0.647359\t\tSym: 9.148526\t\tSpars: 99.208931\n",
      "\t TVw: 0.191254 | TVb: -1.969305 | GSw: -0.235064 | GSb: 0.064726 | TSUw: 0.464665 | TSUb: 0.035051\n",
      "Validating epoch 2879...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 106.23992610857502\n",
      "Average validation loss: 18.469763364790488\n",
      "Training epoch 2880...\n",
      "\n",
      "Train Epoch: 2880 [0/8000 (0%)]\tBatch Loss: 116.841474\tLearning Rate (w_theta): 0.001000\t TIME:7617.0s\n",
      "\t\t\t\tDisc: 0.697952\t\tSym: 10.857748\t\tSpars: 105.285774\n",
      "\t TVw: 0.191129 | TVb: -1.969124 | GSw: -0.235064 | GSb: 0.064725 | TSUw: 0.464664 | TSUb: 0.035051\n",
      "\n",
      "Train Epoch: 2880 [4000/8000 (50%)]\tBatch Loss: 101.051642\tLearning Rate (w_theta): 0.001000\t TIME:7618.6s\n",
      "\t\t\t\tDisc: 0.718298\t\tSym: 7.874086\t\tSpars: 92.459259\n",
      "\t TVw: 0.191003 | TVb: -1.968949 | GSw: -0.235064 | GSb: 0.064725 | TSUw: 0.464664 | TSUb: 0.035051\n",
      "Validating epoch 2880...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 105.6581896674923\n",
      "Average validation loss: 18.49839403403038\n",
      "Training epoch 2881...\n",
      "\n",
      "Train Epoch: 2881 [0/8000 (0%)]\tBatch Loss: 108.248776\tLearning Rate (w_theta): 0.001000\t TIME:7621.8s\n",
      "\t\t\t\tDisc: 0.680650\t\tSym: 8.922245\t\tSpars: 98.645882\n",
      "\t TVw: 0.190672 | TVb: -1.968792 | GSw: -0.235064 | GSb: 0.064725 | TSUw: 0.464664 | TSUb: 0.035051\n",
      "\n",
      "Train Epoch: 2881 [4000/8000 (50%)]\tBatch Loss: 99.478616\tLearning Rate (w_theta): 0.001000\t TIME:7623.4s\n",
      "\t\t\t\tDisc: 0.676834\t\tSym: 7.990869\t\tSpars: 90.810913\n",
      "\t TVw: 0.190379 | TVb: -1.968650 | GSw: -0.235064 | GSb: 0.064724 | TSUw: 0.464664 | TSUb: 0.035051\n",
      "Validating epoch 2881...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 105.2000373821958\n",
      "Average validation loss: 18.3809531352955\n",
      "Training epoch 2882...\n",
      "\n",
      "Train Epoch: 2882 [0/8000 (0%)]\tBatch Loss: 102.793997\tLearning Rate (w_theta): 0.001000\t TIME:7625.9s\n",
      "\t\t\t\tDisc: 0.672671\t\tSym: 8.524028\t\tSpars: 93.597298\n",
      "\t TVw: 0.190107 | TVb: -1.968501 | GSw: -0.235064 | GSb: 0.064724 | TSUw: 0.464663 | TSUb: 0.035052\n",
      "\n",
      "Train Epoch: 2882 [4000/8000 (50%)]\tBatch Loss: 104.384948\tLearning Rate (w_theta): 0.001000\t TIME:7627.5s\n",
      "\t\t\t\tDisc: 0.674013\t\tSym: 8.796521\t\tSpars: 94.914413\n",
      "\t TVw: 0.189978 | TVb: -1.968357 | GSw: -0.235064 | GSb: 0.064724 | TSUw: 0.464663 | TSUb: 0.035052\n",
      "Validating epoch 2882...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 104.86940182166376\n",
      "Average validation loss: 18.13314123321293\n",
      "Training epoch 2883...\n",
      "\n",
      "Train Epoch: 2883 [0/8000 (0%)]\tBatch Loss: 100.262719\tLearning Rate (w_theta): 0.001000\t TIME:7630.0s\n",
      "\t\t\t\tDisc: 0.647843\t\tSym: 8.294846\t\tSpars: 91.320030\n",
      "\t TVw: 0.189846 | TVb: -1.968214 | GSw: -0.235064 | GSb: 0.064723 | TSUw: 0.464663 | TSUb: 0.035052\n",
      "\n",
      "Train Epoch: 2883 [4000/8000 (50%)]\tBatch Loss: 106.304609\tLearning Rate (w_theta): 0.001000\t TIME:7631.6s\n",
      "\t\t\t\tDisc: 0.660846\t\tSym: 9.296756\t\tSpars: 96.347008\n",
      "\t TVw: 0.189837 | TVb: -1.968048 | GSw: -0.235064 | GSb: 0.064723 | TSUw: 0.464663 | TSUb: 0.035052\n",
      "Validating epoch 2883...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 104.66859763597046\n",
      "Average validation loss: 18.509016915540094\n",
      "Training epoch 2884...\n",
      "\n",
      "Train Epoch: 2884 [0/8000 (0%)]\tBatch Loss: 112.281965\tLearning Rate (w_theta): 0.001000\t TIME:7634.2s\n",
      "\t\t\t\tDisc: 0.740192\t\tSym: 9.866275\t\tSpars: 101.675499\n",
      "\t TVw: 0.189873 | TVb: -1.967873 | GSw: -0.235064 | GSb: 0.064723 | TSUw: 0.464662 | TSUb: 0.035052\n",
      "\n",
      "Train Epoch: 2884 [4000/8000 (50%)]\tBatch Loss: 104.522278\tLearning Rate (w_theta): 0.001000\t TIME:7635.8s\n",
      "\t\t\t\tDisc: 0.752169\t\tSym: 8.546385\t\tSpars: 95.223724\n",
      "\t TVw: 0.189586 | TVb: -1.967719 | GSw: -0.235065 | GSb: 0.064723 | TSUw: 0.464662 | TSUb: 0.035053\n",
      "Validating epoch 2884...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 106.59400160947483\n",
      "Average validation loss: 18.11720194143254\n",
      "Training epoch 2885...\n",
      "\n",
      "Train Epoch: 2885 [0/8000 (0%)]\tBatch Loss: 105.776721\tLearning Rate (w_theta): 0.001000\t TIME:7638.3s\n",
      "\t\t\t\tDisc: 0.654041\t\tSym: 8.999030\t\tSpars: 96.123650\n",
      "\t TVw: 0.188681 | TVb: -1.967603 | GSw: -0.235065 | GSb: 0.064722 | TSUw: 0.464662 | TSUb: 0.035053\n",
      "\n",
      "Train Epoch: 2885 [4000/8000 (50%)]\tBatch Loss: 108.754048\tLearning Rate (w_theta): 0.001000\t TIME:7639.9s\n",
      "\t\t\t\tDisc: 0.591862\t\tSym: 9.679475\t\tSpars: 98.482712\n",
      "\t TVw: 0.187776 | TVb: -1.967502 | GSw: -0.235065 | GSb: 0.064722 | TSUw: 0.464662 | TSUb: 0.035053\n",
      "Validating epoch 2885...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 105.32494646923637\n",
      "Average validation loss: 17.873552682227313\n",
      "Training epoch 2886...\n",
      "\n",
      "Train Epoch: 2886 [0/8000 (0%)]\tBatch Loss: 102.027657\tLearning Rate (w_theta): 0.001000\t TIME:7642.9s\n",
      "\t\t\t\tDisc: 0.660089\t\tSym: 8.483771\t\tSpars: 92.883797\n",
      "\t TVw: 0.187435 | TVb: -1.967362 | GSw: -0.235065 | GSb: 0.064722 | TSUw: 0.464661 | TSUb: 0.035053\n",
      "\n",
      "Train Epoch: 2886 [4000/8000 (50%)]\tBatch Loss: 99.630571\tLearning Rate (w_theta): 0.001000\t TIME:7644.5s\n",
      "\t\t\t\tDisc: 0.658443\t\tSym: 7.779646\t\tSpars: 91.192482\n",
      "\t TVw: 0.187716 | TVb: -1.967181 | GSw: -0.235065 | GSb: 0.064721 | TSUw: 0.464661 | TSUb: 0.035054\n",
      "Validating epoch 2886...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 104.43373705984163\n",
      "Average validation loss: 17.806980684866062\n",
      "Training epoch 2887...\n",
      "\n",
      "Train Epoch: 2887 [0/8000 (0%)]\tBatch Loss: 102.807094\tLearning Rate (w_theta): 0.001000\t TIME:7647.0s\n",
      "\t\t\t\tDisc: 0.616054\t\tSym: 8.380974\t\tSpars: 93.810066\n",
      "\t TVw: 0.188117 | TVb: -1.966971 | GSw: -0.235065 | GSb: 0.064721 | TSUw: 0.464661 | TSUb: 0.035054\n",
      "\n",
      "Train Epoch: 2887 [4000/8000 (50%)]\tBatch Loss: 105.759249\tLearning Rate (w_theta): 0.001000\t TIME:7648.6s\n",
      "\t\t\t\tDisc: 0.643417\t\tSym: 9.209598\t\tSpars: 95.906235\n",
      "\t TVw: 0.188182 | TVb: -1.966765 | GSw: -0.235065 | GSb: 0.064721 | TSUw: 0.464661 | TSUb: 0.035054\n",
      "Validating epoch 2887...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 105.39227800247389\n",
      "Average validation loss: 18.315251582589713\n",
      "Training epoch 2888...\n",
      "\n",
      "Train Epoch: 2888 [0/8000 (0%)]\tBatch Loss: 103.616725\tLearning Rate (w_theta): 0.001000\t TIME:7651.1s\n",
      "\t\t\t\tDisc: 0.743625\t\tSym: 8.518584\t\tSpars: 94.354515\n",
      "\t TVw: 0.187320 | TVb: -1.966647 | GSw: -0.235065 | GSb: 0.064721 | TSUw: 0.464661 | TSUb: 0.035054\n",
      "\n",
      "Train Epoch: 2888 [4000/8000 (50%)]\tBatch Loss: 99.454200\tLearning Rate (w_theta): 0.001000\t TIME:7652.7s\n",
      "\t\t\t\tDisc: 0.701891\t\tSym: 8.233212\t\tSpars: 90.519096\n",
      "\t TVw: 0.186013 | TVb: -1.966586 | GSw: -0.235065 | GSb: 0.064720 | TSUw: 0.464660 | TSUb: 0.035054\n",
      "Validating epoch 2888...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 105.83387355256053\n",
      "Average validation loss: 17.845170837820007\n",
      "Training epoch 2889...\n",
      "\n",
      "Train Epoch: 2889 [0/8000 (0%)]\tBatch Loss: 115.460799\tLearning Rate (w_theta): 0.001000\t TIME:7655.2s\n",
      "\t\t\t\tDisc: 0.691338\t\tSym: 10.483718\t\tSpars: 104.285744\n",
      "\t TVw: 0.185451 | TVb: -1.966471 | GSw: -0.235066 | GSb: 0.064720 | TSUw: 0.464660 | TSUb: 0.035055\n",
      "\n",
      "Train Epoch: 2889 [4000/8000 (50%)]\tBatch Loss: 104.499493\tLearning Rate (w_theta): 0.001000\t TIME:7656.8s\n",
      "\t\t\t\tDisc: 0.657659\t\tSym: 8.854262\t\tSpars: 94.987572\n",
      "\t TVw: 0.185105 | TVb: -1.966326 | GSw: -0.235066 | GSb: 0.064720 | TSUw: 0.464660 | TSUb: 0.035055\n",
      "Validating epoch 2889...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 107.25778530304709\n",
      "Average validation loss: 17.335867681434923\n",
      "Training epoch 2890...\n",
      "\n",
      "Train Epoch: 2890 [0/8000 (0%)]\tBatch Loss: 102.052868\tLearning Rate (w_theta): 0.001000\t TIME:7659.3s\n",
      "\t\t\t\tDisc: 0.607638\t\tSym: 8.569643\t\tSpars: 92.875587\n",
      "\t TVw: 0.185070 | TVb: -1.966182 | GSw: -0.235066 | GSb: 0.064719 | TSUw: 0.464660 | TSUb: 0.035055\n",
      "\n",
      "Train Epoch: 2890 [4000/8000 (50%)]\tBatch Loss: 97.686436\tLearning Rate (w_theta): 0.001000\t TIME:7660.9s\n",
      "\t\t\t\tDisc: 0.612465\t\tSym: 8.270985\t\tSpars: 88.802986\n",
      "\t TVw: 0.185637 | TVb: -1.965974 | GSw: -0.235066 | GSb: 0.064719 | TSUw: 0.464659 | TSUb: 0.035055\n",
      "Validating epoch 2890...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 103.92227673975138\n",
      "Average validation loss: 17.236695053816405\n",
      "Training epoch 2891...\n",
      "\n",
      "Train Epoch: 2891 [0/8000 (0%)]\tBatch Loss: 109.878044\tLearning Rate (w_theta): 0.001000\t TIME:7664.0s\n",
      "\t\t\t\tDisc: 0.590708\t\tSym: 9.776556\t\tSpars: 99.510780\n",
      "\t TVw: 0.186452 | TVb: -1.965725 | GSw: -0.235066 | GSb: 0.064719 | TSUw: 0.464659 | TSUb: 0.035055\n",
      "\n",
      "Train Epoch: 2891 [4000/8000 (50%)]\tBatch Loss: 107.987912\tLearning Rate (w_theta): 0.001000\t TIME:7665.6s\n",
      "\t\t\t\tDisc: 0.736665\t\tSym: 9.292919\t\tSpars: 97.958328\n",
      "\t TVw: 0.186813 | TVb: -1.965520 | GSw: -0.235066 | GSb: 0.064718 | TSUw: 0.464659 | TSUb: 0.035056\n",
      "Validating epoch 2891...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 103.43281674100317\n",
      "Average validation loss: 18.07925430309924\n",
      "Training epoch 2892...\n",
      "\n",
      "Train Epoch: 2892 [0/8000 (0%)]\tBatch Loss: 103.323090\tLearning Rate (w_theta): 0.001000\t TIME:7668.2s\n",
      "\t\t\t\tDisc: 0.729754\t\tSym: 8.374502\t\tSpars: 94.218834\n",
      "\t TVw: 0.186701 | TVb: -1.965370 | GSw: -0.235066 | GSb: 0.064718 | TSUw: 0.464659 | TSUb: 0.035056\n",
      "\n",
      "Train Epoch: 2892 [4000/8000 (50%)]\tBatch Loss: 106.120834\tLearning Rate (w_theta): 0.001000\t TIME:7669.8s\n",
      "\t\t\t\tDisc: 0.674341\t\tSym: 9.584074\t\tSpars: 95.862419\n",
      "\t TVw: 0.186463 | TVb: -1.965220 | GSw: -0.235066 | GSb: 0.064718 | TSUw: 0.464658 | TSUb: 0.035056\n",
      "Validating epoch 2892...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 102.21146613239408\n",
      "Average validation loss: 17.718716182430107\n",
      "Training epoch 2893...\n",
      "\n",
      "Train Epoch: 2893 [0/8000 (0%)]\tBatch Loss: 102.318738\tLearning Rate (w_theta): 0.001000\t TIME:7672.3s\n",
      "\t\t\t\tDisc: 0.692834\t\tSym: 8.976185\t\tSpars: 92.649719\n",
      "\t TVw: 0.186247 | TVb: -1.965071 | GSw: -0.235067 | GSb: 0.064717 | TSUw: 0.464658 | TSUb: 0.035056\n",
      "\n",
      "Train Epoch: 2893 [4000/8000 (50%)]\tBatch Loss: 104.986550\tLearning Rate (w_theta): 0.001000\t TIME:7673.9s\n",
      "\t\t\t\tDisc: 0.652051\t\tSym: 9.656077\t\tSpars: 94.678421\n",
      "\t TVw: 0.186134 | TVb: -1.964880 | GSw: -0.235067 | GSb: 0.064717 | TSUw: 0.464658 | TSUb: 0.035057\n",
      "Validating epoch 2893...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 101.6973762138532\n",
      "Average validation loss: 17.50558245492631\n",
      "Training epoch 2894...\n",
      "\n",
      "Train Epoch: 2894 [0/8000 (0%)]\tBatch Loss: 101.135694\tLearning Rate (w_theta): 0.001000\t TIME:7676.5s\n",
      "\t\t\t\tDisc: 0.666769\t\tSym: 8.541389\t\tSpars: 91.927536\n",
      "\t TVw: 0.186005 | TVb: -1.964683 | GSw: -0.235067 | GSb: 0.064717 | TSUw: 0.464658 | TSUb: 0.035057\n",
      "\n",
      "Train Epoch: 2894 [4000/8000 (50%)]\tBatch Loss: 93.678737\tLearning Rate (w_theta): 0.001000\t TIME:7678.1s\n",
      "\t\t\t\tDisc: 0.700132\t\tSym: 7.672315\t\tSpars: 85.306290\n",
      "\t TVw: 0.185705 | TVb: -1.964507 | GSw: -0.235067 | GSb: 0.064717 | TSUw: 0.464657 | TSUb: 0.035057\n",
      "Validating epoch 2894...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 101.2604183217109\n",
      "Average validation loss: 17.487345535560053\n",
      "Training epoch 2895...\n",
      "\n",
      "Train Epoch: 2895 [0/8000 (0%)]\tBatch Loss: 96.210650\tLearning Rate (w_theta): 0.001000\t TIME:7680.6s\n",
      "\t\t\t\tDisc: 0.654234\t\tSym: 7.964794\t\tSpars: 87.591621\n",
      "\t TVw: 0.185419 | TVb: -1.964321 | GSw: -0.235067 | GSb: 0.064716 | TSUw: 0.464657 | TSUb: 0.035057\n",
      "\n",
      "Train Epoch: 2895 [4000/8000 (50%)]\tBatch Loss: 105.442439\tLearning Rate (w_theta): 0.001000\t TIME:7682.2s\n",
      "\t\t\t\tDisc: 0.705385\t\tSym: 9.423097\t\tSpars: 95.313957\n",
      "\t TVw: 0.185087 | TVb: -1.964154 | GSw: -0.235067 | GSb: 0.064716 | TSUw: 0.464657 | TSUb: 0.035057\n",
      "Validating epoch 2895...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 101.26571458824426\n",
      "Average validation loss: 17.487013926219106\n",
      "Training epoch 2896...\n",
      "\n",
      "Train Epoch: 2896 [0/8000 (0%)]\tBatch Loss: 95.635763\tLearning Rate (w_theta): 0.001000\t TIME:7684.7s\n",
      "\t\t\t\tDisc: 0.675734\t\tSym: 8.073356\t\tSpars: 86.886673\n",
      "\t TVw: 0.184635 | TVb: -1.964020 | GSw: -0.235067 | GSb: 0.064716 | TSUw: 0.464657 | TSUb: 0.035058\n",
      "\n",
      "Train Epoch: 2896 [4000/8000 (50%)]\tBatch Loss: 105.082992\tLearning Rate (w_theta): 0.001000\t TIME:7686.3s\n",
      "\t\t\t\tDisc: 0.565226\t\tSym: 8.936208\t\tSpars: 95.581558\n",
      "\t TVw: 0.184001 | TVb: -1.963871 | GSw: -0.235067 | GSb: 0.064715 | TSUw: 0.464656 | TSUb: 0.035058\n",
      "Validating epoch 2896...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 102.75358623789069\n",
      "Average validation loss: 17.15763057109769\n",
      "Training epoch 2897...\n",
      "\n",
      "Train Epoch: 2897 [0/8000 (0%)]\tBatch Loss: 97.511428\tLearning Rate (w_theta): 0.001000\t TIME:7688.8s\n",
      "\t\t\t\tDisc: 0.647453\t\tSym: 8.024428\t\tSpars: 88.839546\n",
      "\t TVw: 0.183420 | TVb: -1.963718 | GSw: -0.235067 | GSb: 0.064715 | TSUw: 0.464656 | TSUb: 0.035058\n",
      "\n",
      "Train Epoch: 2897 [4000/8000 (50%)]\tBatch Loss: 100.908912\tLearning Rate (w_theta): 0.001000\t TIME:7690.4s\n",
      "\t\t\t\tDisc: 0.679203\t\tSym: 8.606586\t\tSpars: 91.623123\n",
      "\t TVw: 0.183117 | TVb: -1.963543 | GSw: -0.235067 | GSb: 0.064715 | TSUw: 0.464656 | TSUb: 0.035058\n",
      "Validating epoch 2897...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 102.0563979578687\n",
      "Average validation loss: 17.392273783759915\n",
      "Training epoch 2898...\n",
      "\n",
      "Train Epoch: 2898 [0/8000 (0%)]\tBatch Loss: 99.744738\tLearning Rate (w_theta): 0.001000\t TIME:7692.9s\n",
      "\t\t\t\tDisc: 0.703888\t\tSym: 8.516627\t\tSpars: 90.524223\n",
      "\t TVw: 0.183042 | TVb: -1.963366 | GSw: -0.235067 | GSb: 0.064714 | TSUw: 0.464656 | TSUb: 0.035058\n",
      "\n",
      "Train Epoch: 2898 [4000/8000 (50%)]\tBatch Loss: 106.959705\tLearning Rate (w_theta): 0.001000\t TIME:7694.5s\n",
      "\t\t\t\tDisc: 0.594050\t\tSym: 10.233338\t\tSpars: 96.132317\n",
      "\t TVw: 0.182981 | TVb: -1.963173 | GSw: -0.235067 | GSb: 0.064714 | TSUw: 0.464656 | TSUb: 0.035059\n",
      "Validating epoch 2898...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 101.25548478380965\n",
      "Average validation loss: 17.263897487183904\n",
      "Training epoch 2899...\n",
      "\n",
      "Train Epoch: 2899 [0/8000 (0%)]\tBatch Loss: 98.076162\tLearning Rate (w_theta): 0.001000\t TIME:7696.9s\n",
      "\t\t\t\tDisc: 0.659060\t\tSym: 8.003016\t\tSpars: 89.414085\n",
      "\t TVw: 0.183047 | TVb: -1.962978 | GSw: -0.235068 | GSb: 0.064714 | TSUw: 0.464655 | TSUb: 0.035059\n",
      "\n",
      "Train Epoch: 2899 [4000/8000 (50%)]\tBatch Loss: 105.672224\tLearning Rate (w_theta): 0.001000\t TIME:7698.6s\n",
      "\t\t\t\tDisc: 0.666197\t\tSym: 9.773560\t\tSpars: 95.232468\n",
      "\t TVw: 0.183226 | TVb: -1.962786 | GSw: -0.235068 | GSb: 0.064714 | TSUw: 0.464655 | TSUb: 0.035059\n",
      "Validating epoch 2899...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 99.85979696121697\n",
      "Average validation loss: 17.312362513973746\n",
      "Training epoch 2900...\n",
      "\n",
      "Train Epoch: 2900 [0/8000 (0%)]\tBatch Loss: 99.312494\tLearning Rate (w_theta): 0.001000\t TIME:7701.1s\n",
      "\t\t\t\tDisc: 0.642123\t\tSym: 8.349364\t\tSpars: 90.321007\n",
      "\t TVw: 0.183470 | TVb: -1.962594 | GSw: -0.235068 | GSb: 0.064713 | TSUw: 0.464655 | TSUb: 0.035059\n",
      "\n",
      "Train Epoch: 2900 [4000/8000 (50%)]\tBatch Loss: 99.175164\tLearning Rate (w_theta): 0.001000\t TIME:7702.7s\n",
      "\t\t\t\tDisc: 0.705867\t\tSym: 8.927496\t\tSpars: 89.541801\n",
      "\t TVw: 0.183592 | TVb: -1.962418 | GSw: -0.235068 | GSb: 0.064713 | TSUw: 0.464655 | TSUb: 0.035060\n",
      "Validating epoch 2900...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 100.03730650102976\n",
      "Average validation loss: 17.31749561254131\n",
      "Training epoch 2901...\n",
      "\n",
      "Train Epoch: 2901 [0/8000 (0%)]\tBatch Loss: 97.746539\tLearning Rate (w_theta): 0.001000\t TIME:7706.4s\n",
      "\t\t\t\tDisc: 0.666621\t\tSym: 8.370598\t\tSpars: 88.709320\n",
      "\t TVw: 0.183120 | TVb: -1.962316 | GSw: -0.235068 | GSb: 0.064713 | TSUw: 0.464654 | TSUb: 0.035060\n",
      "\n",
      "Train Epoch: 2901 [4000/8000 (50%)]\tBatch Loss: 101.083865\tLearning Rate (w_theta): 0.001000\t TIME:7708.0s\n",
      "\t\t\t\tDisc: 0.630069\t\tSym: 9.298575\t\tSpars: 91.155220\n",
      "\t TVw: 0.182285 | TVb: -1.962213 | GSw: -0.235068 | GSb: 0.064712 | TSUw: 0.464654 | TSUb: 0.035060\n",
      "Validating epoch 2901...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 102.18317857097817\n",
      "Average validation loss: 16.4366544611627\n",
      "Training epoch 2902...\n",
      "\n",
      "Train Epoch: 2902 [0/8000 (0%)]\tBatch Loss: 108.056869\tLearning Rate (w_theta): 0.001000\t TIME:7710.5s\n",
      "\t\t\t\tDisc: 0.555820\t\tSym: 9.972103\t\tSpars: 97.528946\n",
      "\t TVw: 0.181478 | TVb: -1.962124 | GSw: -0.235068 | GSb: 0.064712 | TSUw: 0.464654 | TSUb: 0.035060\n",
      "\n",
      "Train Epoch: 2902 [4000/8000 (50%)]\tBatch Loss: 113.789253\tLearning Rate (w_theta): 0.001000\t TIME:7712.1s\n",
      "\t\t\t\tDisc: 0.536260\t\tSym: 10.226733\t\tSpars: 103.026260\n",
      "\t TVw: 0.181117 | TVb: -1.962013 | GSw: -0.235068 | GSb: 0.064712 | TSUw: 0.464654 | TSUb: 0.035060\n",
      "Validating epoch 2902...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 106.38887735690118\n",
      "Average validation loss: 16.257495893128677\n",
      "Training epoch 2903...\n",
      "\n",
      "Train Epoch: 2903 [0/8000 (0%)]\tBatch Loss: 110.083614\tLearning Rate (w_theta): 0.001000\t TIME:7714.7s\n",
      "\t\t\t\tDisc: 0.527238\t\tSym: 10.105624\t\tSpars: 99.450752\n",
      "\t TVw: 0.180483 | TVb: -1.961907 | GSw: -0.235068 | GSb: 0.064711 | TSUw: 0.464653 | TSUb: 0.035061\n",
      "\n",
      "Train Epoch: 2903 [4000/8000 (50%)]\tBatch Loss: 103.991774\tLearning Rate (w_theta): 0.001000\t TIME:7716.3s\n",
      "\t\t\t\tDisc: 0.526651\t\tSym: 9.393598\t\tSpars: 94.071526\n",
      "\t TVw: 0.180723 | TVb: -1.961736 | GSw: -0.235068 | GSb: 0.064711 | TSUw: 0.464653 | TSUb: 0.035061\n",
      "Validating epoch 2903...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 102.34980086602854\n",
      "Average validation loss: 16.42137785953417\n",
      "Training epoch 2904...\n",
      "\n",
      "Train Epoch: 2904 [0/8000 (0%)]\tBatch Loss: 99.784299\tLearning Rate (w_theta): 0.001000\t TIME:7718.8s\n",
      "\t\t\t\tDisc: 0.557132\t\tSym: 8.507006\t\tSpars: 90.720161\n",
      "\t TVw: 0.181931 | TVb: -1.961451 | GSw: -0.235069 | GSb: 0.064711 | TSUw: 0.464653 | TSUb: 0.035061\n",
      "\n",
      "Train Epoch: 2904 [4000/8000 (50%)]\tBatch Loss: 99.453829\tLearning Rate (w_theta): 0.001000\t TIME:7720.4s\n",
      "\t\t\t\tDisc: 0.598221\t\tSym: 9.177980\t\tSpars: 89.677628\n",
      "\t TVw: 0.183196 | TVb: -1.961120 | GSw: -0.235069 | GSb: 0.064710 | TSUw: 0.464653 | TSUb: 0.035061\n",
      "Validating epoch 2904...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 100.16716864029512\n",
      "Average validation loss: 17.04054981591341\n",
      "Training epoch 2905...\n",
      "\n",
      "Train Epoch: 2905 [0/8000 (0%)]\tBatch Loss: 102.438871\tLearning Rate (w_theta): 0.001000\t TIME:7722.9s\n",
      "\t\t\t\tDisc: 0.646936\t\tSym: 9.655651\t\tSpars: 92.136284\n",
      "\t TVw: 0.183499 | TVb: -1.960867 | GSw: -0.235069 | GSb: 0.064710 | TSUw: 0.464652 | TSUb: 0.035062\n",
      "\n",
      "Train Epoch: 2905 [4000/8000 (50%)]\tBatch Loss: 97.863048\tLearning Rate (w_theta): 0.001000\t TIME:7724.5s\n",
      "\t\t\t\tDisc: 0.713955\t\tSym: 8.774055\t\tSpars: 88.375038\n",
      "\t TVw: 0.182945 | TVb: -1.960650 | GSw: -0.235069 | GSb: 0.064710 | TSUw: 0.464652 | TSUb: 0.035062\n",
      "Validating epoch 2905...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 99.15449101357868\n",
      "Average validation loss: 17.433379347136388\n",
      "Training epoch 2906...\n",
      "\n",
      "Train Epoch: 2906 [0/8000 (0%)]\tBatch Loss: 102.988780\tLearning Rate (w_theta): 0.001000\t TIME:7727.2s\n",
      "\t\t\t\tDisc: 0.708141\t\tSym: 9.694190\t\tSpars: 92.586449\n",
      "\t TVw: 0.181991 | TVb: -1.960505 | GSw: -0.235069 | GSb: 0.064709 | TSUw: 0.464652 | TSUb: 0.035062\n",
      "\n",
      "Train Epoch: 2906 [4000/8000 (50%)]\tBatch Loss: 100.972199\tLearning Rate (w_theta): 0.001000\t TIME:7728.8s\n",
      "\t\t\t\tDisc: 0.721986\t\tSym: 8.840484\t\tSpars: 91.409729\n",
      "\t TVw: 0.181226 | TVb: -1.960360 | GSw: -0.235069 | GSb: 0.064709 | TSUw: 0.464652 | TSUb: 0.035062\n",
      "Validating epoch 2906...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 98.36642026637217\n",
      "Average validation loss: 16.847739767725756\n",
      "Training epoch 2907...\n",
      "\n",
      "Train Epoch: 2907 [0/8000 (0%)]\tBatch Loss: 94.935313\tLearning Rate (w_theta): 0.001000\t TIME:7731.4s\n",
      "\t\t\t\tDisc: 0.597770\t\tSym: 8.272235\t\tSpars: 86.065308\n",
      "\t TVw: 0.180850 | TVb: -1.960185 | GSw: -0.235069 | GSb: 0.064709 | TSUw: 0.464651 | TSUb: 0.035062\n",
      "\n",
      "Train Epoch: 2907 [4000/8000 (50%)]\tBatch Loss: 105.713943\tLearning Rate (w_theta): 0.001000\t TIME:7733.0s\n",
      "\t\t\t\tDisc: 0.633207\t\tSym: 10.473452\t\tSpars: 94.607285\n",
      "\t TVw: 0.180637 | TVb: -1.959977 | GSw: -0.235069 | GSb: 0.064709 | TSUw: 0.464651 | TSUb: 0.035063\n",
      "Validating epoch 2907...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 98.0739874064007\n",
      "Average validation loss: 17.12320133255187\n",
      "Training epoch 2908...\n",
      "\n",
      "Train Epoch: 2908 [0/8000 (0%)]\tBatch Loss: 101.752481\tLearning Rate (w_theta): 0.001000\t TIME:7735.6s\n",
      "\t\t\t\tDisc: 0.724582\t\tSym: 9.269431\t\tSpars: 91.758469\n",
      "\t TVw: 0.180224 | TVb: -1.959835 | GSw: -0.235070 | GSb: 0.064708 | TSUw: 0.464651 | TSUb: 0.035063\n",
      "\n",
      "Train Epoch: 2908 [4000/8000 (50%)]\tBatch Loss: 97.382885\tLearning Rate (w_theta): 0.001000\t TIME:7737.2s\n",
      "\t\t\t\tDisc: 0.672866\t\tSym: 8.735433\t\tSpars: 87.974586\n",
      "\t TVw: 0.179579 | TVb: -1.959715 | GSw: -0.235070 | GSb: 0.064708 | TSUw: 0.464651 | TSUb: 0.035063\n",
      "Validating epoch 2908...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 98.34595191268008\n",
      "Average validation loss: 16.55096964662721\n",
      "Training epoch 2909...\n",
      "\n",
      "Train Epoch: 2909 [0/8000 (0%)]\tBatch Loss: 105.912577\tLearning Rate (w_theta): 0.001000\t TIME:7739.7s\n",
      "\t\t\t\tDisc: 0.582163\t\tSym: 10.239395\t\tSpars: 95.091019\n",
      "\t TVw: 0.179261 | TVb: -1.959549 | GSw: -0.235070 | GSb: 0.064708 | TSUw: 0.464651 | TSUb: 0.035063\n",
      "\n",
      "Train Epoch: 2909 [4000/8000 (50%)]\tBatch Loss: 94.818905\tLearning Rate (w_theta): 0.001000\t TIME:7741.3s\n",
      "\t\t\t\tDisc: 0.652970\t\tSym: 8.448871\t\tSpars: 85.717064\n",
      "\t TVw: 0.179187 | TVb: -1.959382 | GSw: -0.235070 | GSb: 0.064707 | TSUw: 0.464650 | TSUb: 0.035064\n",
      "Validating epoch 2909...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 97.67272648009434\n",
      "Average validation loss: 16.647790918533108\n",
      "Training epoch 2910...\n",
      "\n",
      "Train Epoch: 2910 [0/8000 (0%)]\tBatch Loss: 91.874395\tLearning Rate (w_theta): 0.001000\t TIME:7743.8s\n",
      "\t\t\t\tDisc: 0.643487\t\tSym: 8.474972\t\tSpars: 82.755936\n",
      "\t TVw: 0.179273 | TVb: -1.959219 | GSw: -0.235070 | GSb: 0.064707 | TSUw: 0.464650 | TSUb: 0.035064\n",
      "\n",
      "Train Epoch: 2910 [4000/8000 (50%)]\tBatch Loss: 99.639905\tLearning Rate (w_theta): 0.001000\t TIME:7745.4s\n",
      "\t\t\t\tDisc: 0.554525\t\tSym: 8.701362\t\tSpars: 90.384018\n",
      "\t TVw: 0.179000 | TVb: -1.959075 | GSw: -0.235070 | GSb: 0.064707 | TSUw: 0.464650 | TSUb: 0.035064\n",
      "Validating epoch 2910...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 100.00769113073498\n",
      "Average validation loss: 15.994577649779606\n",
      "Training epoch 2911...\n",
      "\n",
      "Train Epoch: 2911 [0/8000 (0%)]\tBatch Loss: 107.518871\tLearning Rate (w_theta): 0.001000\t TIME:7748.6s\n",
      "\t\t\t\tDisc: 0.554695\t\tSym: 9.964718\t\tSpars: 96.999458\n",
      "\t TVw: 0.178456 | TVb: -1.958964 | GSw: -0.235070 | GSb: 0.064706 | TSUw: 0.464650 | TSUb: 0.035064\n",
      "\n",
      "Train Epoch: 2911 [4000/8000 (50%)]\tBatch Loss: 104.627174\tLearning Rate (w_theta): 0.001000\t TIME:7750.2s\n",
      "\t\t\t\tDisc: 0.518303\t\tSym: 9.286208\t\tSpars: 94.822662\n",
      "\t TVw: 0.177654 | TVb: -1.958876 | GSw: -0.235070 | GSb: 0.064706 | TSUw: 0.464649 | TSUb: 0.035064\n",
      "Validating epoch 2911...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 103.18878649923901\n",
      "Average validation loss: 15.831803563329997\n",
      "Training epoch 2912...\n",
      "\n",
      "Train Epoch: 2912 [0/8000 (0%)]\tBatch Loss: 103.264467\tLearning Rate (w_theta): 0.001000\t TIME:7752.7s\n",
      "\t\t\t\tDisc: 0.494717\t\tSym: 9.197332\t\tSpars: 93.572418\n",
      "\t TVw: 0.177277 | TVb: -1.958767 | GSw: -0.235070 | GSb: 0.064706 | TSUw: 0.464649 | TSUb: 0.035065\n",
      "\n",
      "Train Epoch: 2912 [4000/8000 (50%)]\tBatch Loss: 103.207443\tLearning Rate (w_theta): 0.001000\t TIME:7754.3s\n",
      "\t\t\t\tDisc: 0.503233\t\tSym: 9.309702\t\tSpars: 93.394508\n",
      "\t TVw: 0.177924 | TVb: -1.958574 | GSw: -0.235071 | GSb: 0.064705 | TSUw: 0.464649 | TSUb: 0.035065\n",
      "Validating epoch 2912...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 100.84153697297505\n",
      "Average validation loss: 15.972229463289324\n",
      "Training epoch 2913...\n",
      "\n",
      "Train Epoch: 2913 [0/8000 (0%)]\tBatch Loss: 102.837250\tLearning Rate (w_theta): 0.001000\t TIME:7756.8s\n",
      "\t\t\t\tDisc: 0.536727\t\tSym: 9.572954\t\tSpars: 92.727570\n",
      "\t TVw: 0.179357 | TVb: -1.958294 | GSw: -0.235071 | GSb: 0.064705 | TSUw: 0.464649 | TSUb: 0.035065\n",
      "\n",
      "Train Epoch: 2913 [4000/8000 (50%)]\tBatch Loss: 105.949806\tLearning Rate (w_theta): 0.001000\t TIME:7758.4s\n",
      "\t\t\t\tDisc: 0.564733\t\tSym: 10.262279\t\tSpars: 95.122795\n",
      "\t TVw: 0.180844 | TVb: -1.957986 | GSw: -0.235071 | GSb: 0.064705 | TSUw: 0.464648 | TSUb: 0.035065\n",
      "Validating epoch 2913...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 98.13914833961068\n",
      "Average validation loss: 16.364039446722263\n",
      "Training epoch 2914...\n",
      "\n",
      "Train Epoch: 2914 [0/8000 (0%)]\tBatch Loss: 101.020356\tLearning Rate (w_theta): 0.001000\t TIME:7760.9s\n",
      "\t\t\t\tDisc: 0.626316\t\tSym: 9.248960\t\tSpars: 91.145081\n",
      "\t TVw: 0.181488 | TVb: -1.957724 | GSw: -0.235071 | GSb: 0.064704 | TSUw: 0.464648 | TSUb: 0.035066\n",
      "\n",
      "Train Epoch: 2914 [4000/8000 (50%)]\tBatch Loss: 94.333951\tLearning Rate (w_theta): 0.001000\t TIME:7762.6s\n",
      "\t\t\t\tDisc: 0.625772\t\tSym: 8.603962\t\tSpars: 85.104218\n",
      "\t TVw: 0.180853 | TVb: -1.957556 | GSw: -0.235071 | GSb: 0.064704 | TSUw: 0.464648 | TSUb: 0.035066\n",
      "Validating epoch 2914...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 97.30454727597728\n",
      "Average validation loss: 16.690042287239578\n",
      "Training epoch 2915...\n",
      "\n",
      "Train Epoch: 2915 [0/8000 (0%)]\tBatch Loss: 91.962914\tLearning Rate (w_theta): 0.001000\t TIME:7765.1s\n",
      "\t\t\t\tDisc: 0.671671\t\tSym: 8.330618\t\tSpars: 82.960625\n",
      "\t TVw: 0.179911 | TVb: -1.957391 | GSw: -0.235071 | GSb: 0.064704 | TSUw: 0.464648 | TSUb: 0.035066\n",
      "\n",
      "Train Epoch: 2915 [4000/8000 (50%)]\tBatch Loss: 98.328786\tLearning Rate (w_theta): 0.001000\t TIME:7766.7s\n",
      "\t\t\t\tDisc: 0.735149\t\tSym: 8.922319\t\tSpars: 88.671318\n",
      "\t TVw: 0.179197 | TVb: -1.957219 | GSw: -0.235071 | GSb: 0.064703 | TSUw: 0.464647 | TSUb: 0.035066\n",
      "Validating epoch 2915...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 95.98760496845259\n",
      "Average validation loss: 16.658084201035802\n",
      "Training epoch 2916...\n",
      "\n",
      "Train Epoch: 2916 [0/8000 (0%)]\tBatch Loss: 93.852107\tLearning Rate (w_theta): 0.001000\t TIME:7769.2s\n",
      "\t\t\t\tDisc: 0.681984\t\tSym: 8.694377\t\tSpars: 84.475746\n",
      "\t TVw: 0.178728 | TVb: -1.957034 | GSw: -0.235071 | GSb: 0.064703 | TSUw: 0.464647 | TSUb: 0.035067\n",
      "\n",
      "Train Epoch: 2916 [4000/8000 (50%)]\tBatch Loss: 96.796788\tLearning Rate (w_theta): 0.001000\t TIME:7770.8s\n",
      "\t\t\t\tDisc: 0.616770\t\tSym: 9.040339\t\tSpars: 87.139679\n",
      "\t TVw: 0.178641 | TVb: -1.956808 | GSw: -0.235072 | GSb: 0.064703 | TSUw: 0.464647 | TSUb: 0.035067\n",
      "Validating epoch 2916...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 95.4514434247238\n",
      "Average validation loss: 16.416223543370037\n",
      "Training epoch 2917...\n",
      "\n",
      "Train Epoch: 2917 [0/8000 (0%)]\tBatch Loss: 100.611951\tLearning Rate (w_theta): 0.001000\t TIME:7773.8s\n",
      "\t\t\t\tDisc: 0.608254\t\tSym: 9.888683\t\tSpars: 90.115013\n",
      "\t TVw: 0.178616 | TVb: -1.956580 | GSw: -0.235072 | GSb: 0.064703 | TSUw: 0.464647 | TSUb: 0.035067\n",
      "\n",
      "Train Epoch: 2917 [4000/8000 (50%)]\tBatch Loss: 95.378412\tLearning Rate (w_theta): 0.001000\t TIME:7775.4s\n",
      "\t\t\t\tDisc: 0.755738\t\tSym: 8.689065\t\tSpars: 85.933609\n",
      "\t TVw: 0.178313 | TVb: -1.956395 | GSw: -0.235072 | GSb: 0.064702 | TSUw: 0.464646 | TSUb: 0.035067\n",
      "Validating epoch 2917...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 95.72449769588778\n",
      "Average validation loss: 16.80892680522633\n",
      "Training epoch 2918...\n",
      "\n",
      "Train Epoch: 2918 [0/8000 (0%)]\tBatch Loss: 92.493730\tLearning Rate (w_theta): 0.001000\t TIME:7778.0s\n",
      "\t\t\t\tDisc: 0.720041\t\tSym: 8.325049\t\tSpars: 83.448639\n",
      "\t TVw: 0.177809 | TVb: -1.956237 | GSw: -0.235072 | GSb: 0.064702 | TSUw: 0.464646 | TSUb: 0.035067\n",
      "\n",
      "Train Epoch: 2918 [4000/8000 (50%)]\tBatch Loss: 93.659662\tLearning Rate (w_theta): 0.001000\t TIME:7779.6s\n",
      "\t\t\t\tDisc: 0.673151\t\tSym: 8.621116\t\tSpars: 84.365395\n",
      "\t TVw: 0.177232 | TVb: -1.956083 | GSw: -0.235072 | GSb: 0.064702 | TSUw: 0.464646 | TSUb: 0.035068\n",
      "Validating epoch 2918...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 97.06668779850501\n",
      "Average validation loss: 15.986337984960343\n",
      "Training epoch 2919...\n",
      "\n",
      "Train Epoch: 2919 [0/8000 (0%)]\tBatch Loss: 100.696042\tLearning Rate (w_theta): 0.001000\t TIME:7782.1s\n",
      "\t\t\t\tDisc: 0.569264\t\tSym: 9.519974\t\tSpars: 90.606804\n",
      "\t TVw: 0.176486 | TVb: -1.955972 | GSw: -0.235072 | GSb: 0.064701 | TSUw: 0.464646 | TSUb: 0.035068\n",
      "\n",
      "Train Epoch: 2919 [4000/8000 (50%)]\tBatch Loss: 99.710026\tLearning Rate (w_theta): 0.001000\t TIME:7783.7s\n",
      "\t\t\t\tDisc: 0.537488\t\tSym: 9.772812\t\tSpars: 89.399727\n",
      "\t TVw: 0.175874 | TVb: -1.955868 | GSw: -0.235072 | GSb: 0.064701 | TSUw: 0.464646 | TSUb: 0.035068\n",
      "Validating epoch 2919...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 97.43014919600208\n",
      "Average validation loss: 15.721256839225578\n",
      "Training epoch 2920...\n",
      "\n",
      "Train Epoch: 2920 [0/8000 (0%)]\tBatch Loss: 93.667779\tLearning Rate (w_theta): 0.001000\t TIME:7786.2s\n",
      "\t\t\t\tDisc: 0.531517\t\tSym: 8.446397\t\tSpars: 84.689865\n",
      "\t TVw: 0.176081 | TVb: -1.955698 | GSw: -0.235072 | GSb: 0.064701 | TSUw: 0.464645 | TSUb: 0.035068\n",
      "\n",
      "Train Epoch: 2920 [4000/8000 (50%)]\tBatch Loss: 98.203254\tLearning Rate (w_theta): 0.001000\t TIME:7787.8s\n",
      "\t\t\t\tDisc: 0.544409\t\tSym: 9.439691\t\tSpars: 88.219154\n",
      "\t TVw: 0.177072 | TVb: -1.955427 | GSw: -0.235073 | GSb: 0.064700 | TSUw: 0.464645 | TSUb: 0.035069\n",
      "Validating epoch 2920...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 95.62773451105252\n",
      "Average validation loss: 16.388341012440062\n",
      "Training epoch 2921...\n",
      "\n",
      "Train Epoch: 2921 [0/8000 (0%)]\tBatch Loss: 93.396241\tLearning Rate (w_theta): 0.001000\t TIME:7791.1s\n",
      "\t\t\t\tDisc: 0.621259\t\tSym: 8.763034\t\tSpars: 84.011948\n",
      "\t TVw: 0.177738 | TVb: -1.955164 | GSw: -0.235073 | GSb: 0.064700 | TSUw: 0.464645 | TSUb: 0.035069\n",
      "\n",
      "Train Epoch: 2921 [4000/8000 (50%)]\tBatch Loss: 100.790706\tLearning Rate (w_theta): 0.001000\t TIME:7792.7s\n",
      "\t\t\t\tDisc: 0.724055\t\tSym: 9.984117\t\tSpars: 90.082535\n",
      "\t TVw: 0.178139 | TVb: -1.954893 | GSw: -0.235073 | GSb: 0.064700 | TSUw: 0.464645 | TSUb: 0.035069\n",
      "Validating epoch 2921...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 94.01357099310633\n",
      "Average validation loss: 16.716711256468336\n",
      "Training epoch 2922...\n",
      "\n",
      "Train Epoch: 2922 [0/8000 (0%)]\tBatch Loss: 94.281616\tLearning Rate (w_theta): 0.001000\t TIME:7795.2s\n",
      "\t\t\t\tDisc: 0.682629\t\tSym: 8.975910\t\tSpars: 84.623077\n",
      "\t TVw: 0.177919 | TVb: -1.954685 | GSw: -0.235073 | GSb: 0.064699 | TSUw: 0.464644 | TSUb: 0.035069\n",
      "\n",
      "Train Epoch: 2922 [4000/8000 (50%)]\tBatch Loss: 98.556722\tLearning Rate (w_theta): 0.001000\t TIME:7796.8s\n",
      "\t\t\t\tDisc: 0.693352\t\tSym: 9.776114\t\tSpars: 88.087257\n",
      "\t TVw: 0.177173 | TVb: -1.954516 | GSw: -0.235073 | GSb: 0.064699 | TSUw: 0.464644 | TSUb: 0.035069\n",
      "Validating epoch 2922...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 93.73330262929332\n",
      "Average validation loss: 16.38850783879838\n",
      "Training epoch 2923...\n",
      "\n",
      "Train Epoch: 2923 [0/8000 (0%)]\tBatch Loss: 87.388892\tLearning Rate (w_theta): 0.001000\t TIME:7799.3s\n",
      "\t\t\t\tDisc: 0.634091\t\tSym: 7.607028\t\tSpars: 79.147774\n",
      "\t TVw: 0.176266 | TVb: -1.954394 | GSw: -0.235073 | GSb: 0.064699 | TSUw: 0.464644 | TSUb: 0.035070\n",
      "\n",
      "Train Epoch: 2923 [4000/8000 (50%)]\tBatch Loss: 93.657589\tLearning Rate (w_theta): 0.001000\t TIME:7800.9s\n",
      "\t\t\t\tDisc: 0.636213\t\tSym: 8.948760\t\tSpars: 84.072617\n",
      "\t TVw: 0.175816 | TVb: -1.954250 | GSw: -0.235073 | GSb: 0.064698 | TSUw: 0.464644 | TSUb: 0.035070\n",
      "Validating epoch 2923...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 92.94457966335868\n",
      "Average validation loss: 15.858290436433103\n",
      "Training epoch 2924...\n",
      "\n",
      "Train Epoch: 2924 [0/8000 (0%)]\tBatch Loss: 92.793819\tLearning Rate (w_theta): 0.001000\t TIME:7803.5s\n",
      "\t\t\t\tDisc: 0.571539\t\tSym: 8.709844\t\tSpars: 83.512436\n",
      "\t TVw: 0.175697 | TVb: -1.954064 | GSw: -0.235073 | GSb: 0.064698 | TSUw: 0.464643 | TSUb: 0.035070\n",
      "\n",
      "Train Epoch: 2924 [4000/8000 (50%)]\tBatch Loss: 94.715347\tLearning Rate (w_theta): 0.001000\t TIME:7805.1s\n",
      "\t\t\t\tDisc: 0.624044\t\tSym: 9.390154\t\tSpars: 84.701149\n",
      "\t TVw: 0.175236 | TVb: -1.953913 | GSw: -0.235073 | GSb: 0.064698 | TSUw: 0.464643 | TSUb: 0.035070\n",
      "Validating epoch 2924...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 94.17928525922132\n",
      "Average validation loss: 16.35476424638264\n",
      "Training epoch 2925...\n",
      "\n",
      "Train Epoch: 2925 [0/8000 (0%)]\tBatch Loss: 98.839986\tLearning Rate (w_theta): 0.001000\t TIME:7807.6s\n",
      "\t\t\t\tDisc: 0.800974\t\tSym: 9.501468\t\tSpars: 88.537544\n",
      "\t TVw: 0.174938 | TVb: -1.953753 | GSw: -0.235074 | GSb: 0.064697 | TSUw: 0.464643 | TSUb: 0.035071\n",
      "\n",
      "Train Epoch: 2925 [4000/8000 (50%)]\tBatch Loss: 97.850878\tLearning Rate (w_theta): 0.001000\t TIME:7809.2s\n",
      "\t\t\t\tDisc: 0.732623\t\tSym: 9.082335\t\tSpars: 88.035919\n",
      "\t TVw: 0.174551 | TVb: -1.953588 | GSw: -0.235074 | GSb: 0.064697 | TSUw: 0.464643 | TSUb: 0.035071\n",
      "Validating epoch 2925...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 94.78782479147365\n",
      "Average validation loss: 16.097320867385953\n",
      "Training epoch 2926...\n",
      "\n",
      "Train Epoch: 2926 [0/8000 (0%)]\tBatch Loss: 88.628127\tLearning Rate (w_theta): 0.001000\t TIME:7811.7s\n",
      "\t\t\t\tDisc: 0.728054\t\tSym: 7.939303\t\tSpars: 79.960770\n",
      "\t TVw: 0.174259 | TVb: -1.953419 | GSw: -0.235074 | GSb: 0.064697 | TSUw: 0.464642 | TSUb: 0.035071\n",
      "\n",
      "Train Epoch: 2926 [4000/8000 (50%)]\tBatch Loss: 94.426747\tLearning Rate (w_theta): 0.001000\t TIME:7813.3s\n",
      "\t\t\t\tDisc: 0.574826\t\tSym: 9.099701\t\tSpars: 84.752220\n",
      "\t TVw: 0.174224 | TVb: -1.953235 | GSw: -0.235074 | GSb: 0.064696 | TSUw: 0.464642 | TSUb: 0.035071\n",
      "Validating epoch 2926...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 92.95044448991305\n",
      "Average validation loss: 15.939377844014926\n",
      "Training epoch 2927...\n",
      "\n",
      "Train Epoch: 2927 [0/8000 (0%)]\tBatch Loss: 95.092986\tLearning Rate (w_theta): 0.001000\t TIME:7815.9s\n",
      "\t\t\t\tDisc: 0.629067\t\tSym: 9.087996\t\tSpars: 85.375923\n",
      "\t TVw: 0.174688 | TVb: -1.953012 | GSw: -0.235074 | GSb: 0.064696 | TSUw: 0.464642 | TSUb: 0.035071\n",
      "\n",
      "Train Epoch: 2927 [4000/8000 (50%)]\tBatch Loss: 94.804475\tLearning Rate (w_theta): 0.001000\t TIME:7817.5s\n",
      "\t\t\t\tDisc: 0.666444\t\tSym: 9.248268\t\tSpars: 84.889763\n",
      "\t TVw: 0.175078 | TVb: -1.952778 | GSw: -0.235074 | GSb: 0.064696 | TSUw: 0.464642 | TSUb: 0.035072\n",
      "Validating epoch 2927...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 91.86067832104817\n",
      "Average validation loss: 16.25957758673484\n",
      "Training epoch 2928...\n",
      "\n",
      "Train Epoch: 2928 [0/8000 (0%)]\tBatch Loss: 90.958961\tLearning Rate (w_theta): 0.001000\t TIME:7820.0s\n",
      "\t\t\t\tDisc: 0.649018\t\tSym: 8.605155\t\tSpars: 81.704788\n",
      "\t TVw: 0.174995 | TVb: -1.952576 | GSw: -0.235074 | GSb: 0.064696 | TSUw: 0.464641 | TSUb: 0.035072\n",
      "\n",
      "Train Epoch: 2928 [4000/8000 (50%)]\tBatch Loss: 93.695796\tLearning Rate (w_theta): 0.001000\t TIME:7821.6s\n",
      "\t\t\t\tDisc: 0.599881\t\tSym: 8.995559\t\tSpars: 84.100357\n",
      "\t TVw: 0.174140 | TVb: -1.952440 | GSw: -0.235074 | GSb: 0.064695 | TSUw: 0.464641 | TSUb: 0.035072\n",
      "Validating epoch 2928...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 92.31701338331006\n",
      "Average validation loss: 15.798056762581073\n",
      "Training epoch 2929...\n",
      "\n",
      "Train Epoch: 2929 [0/8000 (0%)]\tBatch Loss: 91.019174\tLearning Rate (w_theta): 0.001000\t TIME:7824.1s\n",
      "\t\t\t\tDisc: 0.591734\t\tSym: 8.820332\t\tSpars: 81.607109\n",
      "\t TVw: 0.173124 | TVb: -1.952342 | GSw: -0.235075 | GSb: 0.064695 | TSUw: 0.464641 | TSUb: 0.035072\n",
      "\n",
      "Train Epoch: 2929 [4000/8000 (50%)]\tBatch Loss: 93.920046\tLearning Rate (w_theta): 0.001000\t TIME:7825.7s\n",
      "\t\t\t\tDisc: 0.728831\t\tSym: 9.020782\t\tSpars: 84.170433\n",
      "\t TVw: 0.172848 | TVb: -1.952183 | GSw: -0.235075 | GSb: 0.064695 | TSUw: 0.464641 | TSUb: 0.035073\n",
      "Validating epoch 2929...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 92.76701851063638\n",
      "Average validation loss: 16.055216362214225\n",
      "Training epoch 2930...\n",
      "\n",
      "Train Epoch: 2930 [0/8000 (0%)]\tBatch Loss: 92.948202\tLearning Rate (w_theta): 0.001000\t TIME:7828.3s\n",
      "\t\t\t\tDisc: 0.705291\t\tSym: 8.266547\t\tSpars: 83.976364\n",
      "\t TVw: 0.172975 | TVb: -1.952000 | GSw: -0.235075 | GSb: 0.064694 | TSUw: 0.464640 | TSUb: 0.035073\n",
      "\n",
      "Train Epoch: 2930 [4000/8000 (50%)]\tBatch Loss: 92.004922\tLearning Rate (w_theta): 0.001000\t TIME:7829.9s\n",
      "\t\t\t\tDisc: 0.642586\t\tSym: 9.266747\t\tSpars: 82.095589\n",
      "\t TVw: 0.172996 | TVb: -1.951826 | GSw: -0.235075 | GSb: 0.064694 | TSUw: 0.464640 | TSUb: 0.035073\n",
      "Validating epoch 2930...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 93.57694160177701\n",
      "Average validation loss: 15.456168229012308\n",
      "Training epoch 2931...\n",
      "\n",
      "Train Epoch: 2931 [0/8000 (0%)]\tBatch Loss: 101.969748\tLearning Rate (w_theta): 0.001000\t TIME:7833.1s\n",
      "\t\t\t\tDisc: 0.553751\t\tSym: 10.820263\t\tSpars: 90.595734\n",
      "\t TVw: 0.172974 | TVb: -1.951615 | GSw: -0.235075 | GSb: 0.064694 | TSUw: 0.464640 | TSUb: 0.035073\n",
      "\n",
      "Train Epoch: 2931 [4000/8000 (50%)]\tBatch Loss: 85.154564\tLearning Rate (w_theta): 0.001000\t TIME:7834.7s\n",
      "\t\t\t\tDisc: 0.592758\t\tSym: 7.919785\t\tSpars: 76.642021\n",
      "\t TVw: 0.173008 | TVb: -1.951416 | GSw: -0.235075 | GSb: 0.064693 | TSUw: 0.464640 | TSUb: 0.035073\n",
      "Validating epoch 2931...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 91.5060491030417\n",
      "Average validation loss: 15.822338509650436\n",
      "Training epoch 2932...\n",
      "\n",
      "Train Epoch: 2932 [0/8000 (0%)]\tBatch Loss: 89.388545\tLearning Rate (w_theta): 0.001000\t TIME:7837.7s\n",
      "\t\t\t\tDisc: 0.632885\t\tSym: 8.487295\t\tSpars: 80.268364\n",
      "\t TVw: 0.173332 | TVb: -1.951160 | GSw: -0.235075 | GSb: 0.064693 | TSUw: 0.464640 | TSUb: 0.035074\n",
      "\n",
      "Train Epoch: 2932 [4000/8000 (50%)]\tBatch Loss: 93.071049\tLearning Rate (w_theta): 0.001000\t TIME:7839.3s\n",
      "\t\t\t\tDisc: 0.765520\t\tSym: 9.179744\t\tSpars: 83.125786\n",
      "\t TVw: 0.173515 | TVb: -1.950922 | GSw: -0.235075 | GSb: 0.064693 | TSUw: 0.464639 | TSUb: 0.035074\n",
      "Validating epoch 2932...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 91.111363534832\n",
      "Average validation loss: 15.993897202140255\n",
      "Training epoch 2933...\n",
      "\n",
      "Train Epoch: 2933 [0/8000 (0%)]\tBatch Loss: 92.713001\tLearning Rate (w_theta): 0.001000\t TIME:7841.9s\n",
      "\t\t\t\tDisc: 0.693388\t\tSym: 9.231091\t\tSpars: 82.788521\n",
      "\t TVw: 0.172871 | TVb: -1.950782 | GSw: -0.235075 | GSb: 0.064692 | TSUw: 0.464639 | TSUb: 0.035074\n",
      "\n",
      "Train Epoch: 2933 [4000/8000 (50%)]\tBatch Loss: 94.027815\tLearning Rate (w_theta): 0.001000\t TIME:7843.5s\n",
      "\t\t\t\tDisc: 0.574852\t\tSym: 9.321295\t\tSpars: 84.131668\n",
      "\t TVw: 0.171882 | TVb: -1.950643 | GSw: -0.235076 | GSb: 0.064692 | TSUw: 0.464639 | TSUb: 0.035074\n",
      "Validating epoch 2933...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 90.92614063420245\n",
      "Average validation loss: 15.678515608099172\n",
      "Training epoch 2934...\n",
      "\n",
      "Train Epoch: 2934 [0/8000 (0%)]\tBatch Loss: 93.526014\tLearning Rate (w_theta): 0.001000\t TIME:7846.0s\n",
      "\t\t\t\tDisc: 0.664928\t\tSym: 9.140947\t\tSpars: 83.720139\n",
      "\t TVw: 0.171546 | TVb: -1.950494 | GSw: -0.235076 | GSb: 0.064692 | TSUw: 0.464639 | TSUb: 0.035075\n",
      "\n",
      "Train Epoch: 2934 [4000/8000 (50%)]\tBatch Loss: 91.580886\tLearning Rate (w_theta): 0.001000\t TIME:7847.6s\n",
      "\t\t\t\tDisc: 0.705964\t\tSym: 9.095565\t\tSpars: 81.779358\n",
      "\t TVw: 0.171736 | TVb: -1.950320 | GSw: -0.235076 | GSb: 0.064691 | TSUw: 0.464638 | TSUb: 0.035075\n",
      "Validating epoch 2934...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 91.22033879148549\n",
      "Average validation loss: 15.757692304820196\n",
      "Training epoch 2935...\n",
      "\n",
      "Train Epoch: 2935 [0/8000 (0%)]\tBatch Loss: 94.829945\tLearning Rate (w_theta): 0.001000\t TIME:7850.1s\n",
      "\t\t\t\tDisc: 0.678617\t\tSym: 9.480529\t\tSpars: 84.670799\n",
      "\t TVw: 0.171917 | TVb: -1.950138 | GSw: -0.235076 | GSb: 0.064691 | TSUw: 0.464638 | TSUb: 0.035075\n",
      "\n",
      "Train Epoch: 2935 [4000/8000 (50%)]\tBatch Loss: 84.342920\tLearning Rate (w_theta): 0.001000\t TIME:7851.8s\n",
      "\t\t\t\tDisc: 0.606973\t\tSym: 7.875908\t\tSpars: 75.860039\n",
      "\t TVw: 0.171915 | TVb: -1.949916 | GSw: -0.235076 | GSb: 0.064691 | TSUw: 0.464638 | TSUb: 0.035075\n",
      "Validating epoch 2935...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 91.56010404803973\n",
      "Average validation loss: 15.191768308082764\n",
      "Training epoch 2936...\n",
      "\n",
      "Train Epoch: 2936 [0/8000 (0%)]\tBatch Loss: 102.397778\tLearning Rate (w_theta): 0.001000\t TIME:7854.3s\n",
      "\t\t\t\tDisc: 0.561053\t\tSym: 10.653780\t\tSpars: 91.182945\n",
      "\t TVw: 0.171444 | TVb: -1.949723 | GSw: -0.235076 | GSb: 0.064690 | TSUw: 0.464638 | TSUb: 0.035075\n",
      "\n",
      "Train Epoch: 2936 [4000/8000 (50%)]\tBatch Loss: 90.641929\tLearning Rate (w_theta): 0.001000\t TIME:7855.9s\n",
      "\t\t\t\tDisc: 0.550662\t\tSym: 8.676815\t\tSpars: 81.414452\n",
      "\t TVw: 0.170483 | TVb: -1.949602 | GSw: -0.235076 | GSb: 0.064690 | TSUw: 0.464637 | TSUb: 0.035076\n",
      "Validating epoch 2936...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 93.68346242752824\n",
      "Average validation loss: 15.478314498163364\n",
      "Training epoch 2937...\n",
      "\n",
      "Train Epoch: 2937 [0/8000 (0%)]\tBatch Loss: 92.106803\tLearning Rate (w_theta): 0.001000\t TIME:7858.5s\n",
      "\t\t\t\tDisc: 0.625338\t\tSym: 9.350743\t\tSpars: 82.130722\n",
      "\t TVw: 0.169819 | TVb: -1.949474 | GSw: -0.235076 | GSb: 0.064690 | TSUw: 0.464637 | TSUb: 0.035076\n",
      "\n",
      "Train Epoch: 2937 [4000/8000 (50%)]\tBatch Loss: 92.308177\tLearning Rate (w_theta): 0.001000\t TIME:7860.1s\n",
      "\t\t\t\tDisc: 0.673672\t\tSym: 9.150001\t\tSpars: 82.484505\n",
      "\t TVw: 0.170149 | TVb: -1.949236 | GSw: -0.235077 | GSb: 0.064689 | TSUw: 0.464637 | TSUb: 0.035076\n",
      "Validating epoch 2937...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 91.19190838311074\n",
      "Average validation loss: 15.890418094159964\n",
      "Training epoch 2938...\n",
      "\n",
      "Train Epoch: 2938 [0/8000 (0%)]\tBatch Loss: 91.989501\tLearning Rate (w_theta): 0.001000\t TIME:7862.6s\n",
      "\t\t\t\tDisc: 0.698431\t\tSym: 9.419389\t\tSpars: 81.871681\n",
      "\t TVw: 0.170606 | TVb: -1.948998 | GSw: -0.235077 | GSb: 0.064689 | TSUw: 0.464637 | TSUb: 0.035076\n",
      "\n",
      "Train Epoch: 2938 [4000/8000 (50%)]\tBatch Loss: 85.291766\tLearning Rate (w_theta): 0.001000\t TIME:7864.2s\n",
      "\t\t\t\tDisc: 0.705454\t\tSym: 7.767374\t\tSpars: 76.818939\n",
      "\t TVw: 0.170837 | TVb: -1.948752 | GSw: -0.235077 | GSb: 0.064689 | TSUw: 0.464636 | TSUb: 0.035077\n",
      "Validating epoch 2938...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 89.72356247296177\n",
      "Average validation loss: 15.794757897034668\n",
      "Training epoch 2939...\n",
      "\n",
      "Train Epoch: 2939 [0/8000 (0%)]\tBatch Loss: 89.769392\tLearning Rate (w_theta): 0.001000\t TIME:7866.7s\n",
      "\t\t\t\tDisc: 0.672732\t\tSym: 9.332324\t\tSpars: 79.764336\n",
      "\t TVw: 0.170708 | TVb: -1.948527 | GSw: -0.235077 | GSb: 0.064688 | TSUw: 0.464636 | TSUb: 0.035077\n",
      "\n",
      "Train Epoch: 2939 [4000/8000 (50%)]\tBatch Loss: 83.845169\tLearning Rate (w_theta): 0.001000\t TIME:7868.3s\n",
      "\t\t\t\tDisc: 0.633711\t\tSym: 7.782954\t\tSpars: 75.428505\n",
      "\t TVw: 0.170143 | TVb: -1.948342 | GSw: -0.235077 | GSb: 0.064688 | TSUw: 0.464636 | TSUb: 0.035077\n",
      "Validating epoch 2939...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 89.4104528057634\n",
      "Average validation loss: 15.181101395915537\n",
      "Training epoch 2940...\n",
      "\n",
      "Train Epoch: 2940 [0/8000 (0%)]\tBatch Loss: 95.996127\tLearning Rate (w_theta): 0.001000\t TIME:7870.9s\n",
      "\t\t\t\tDisc: 0.552269\t\tSym: 9.653018\t\tSpars: 85.790840\n",
      "\t TVw: 0.169338 | TVb: -1.948188 | GSw: -0.235077 | GSb: 0.064688 | TSUw: 0.464636 | TSUb: 0.035077\n",
      "\n",
      "Train Epoch: 2940 [4000/8000 (50%)]\tBatch Loss: 87.598355\tLearning Rate (w_theta): 0.001000\t TIME:7872.5s\n",
      "\t\t\t\tDisc: 0.607749\t\tSym: 8.372128\t\tSpars: 78.618477\n",
      "\t TVw: 0.168867 | TVb: -1.948033 | GSw: -0.235077 | GSb: 0.064687 | TSUw: 0.464635 | TSUb: 0.035077\n",
      "Validating epoch 2940...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 89.75436067774336\n",
      "Average validation loss: 15.39285909116807\n",
      "Training epoch 2941...\n",
      "\n",
      "Train Epoch: 2941 [0/8000 (0%)]\tBatch Loss: 92.681200\tLearning Rate (w_theta): 0.001000\t TIME:7875.8s\n",
      "\t\t\t\tDisc: 0.636295\t\tSym: 9.625556\t\tSpars: 82.419350\n",
      "\t TVw: 0.168945 | TVb: -1.947832 | GSw: -0.235077 | GSb: 0.064687 | TSUw: 0.464635 | TSUb: 0.035078\n",
      "\n",
      "Train Epoch: 2941 [4000/8000 (50%)]\tBatch Loss: 93.183151\tLearning Rate (w_theta): 0.001000\t TIME:7877.4s\n",
      "\t\t\t\tDisc: 0.690831\t\tSym: 9.617335\t\tSpars: 82.874985\n",
      "\t TVw: 0.169300 | TVb: -1.947602 | GSw: -0.235078 | GSb: 0.064687 | TSUw: 0.464635 | TSUb: 0.035078\n",
      "Validating epoch 2941...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 88.4950083254479\n",
      "Average validation loss: 15.70146065822489\n",
      "Training epoch 2942...\n",
      "\n",
      "Train Epoch: 2942 [0/8000 (0%)]\tBatch Loss: 90.565470\tLearning Rate (w_theta): 0.001000\t TIME:7879.9s\n",
      "\t\t\t\tDisc: 0.706010\t\tSym: 9.004510\t\tSpars: 80.854950\n",
      "\t TVw: 0.169505 | TVb: -1.947354 | GSw: -0.235078 | GSb: 0.064686 | TSUw: 0.464635 | TSUb: 0.035078\n",
      "\n",
      "Train Epoch: 2942 [4000/8000 (50%)]\tBatch Loss: 94.822591\tLearning Rate (w_theta): 0.001000\t TIME:7881.5s\n",
      "\t\t\t\tDisc: 0.572638\t\tSym: 9.719474\t\tSpars: 84.530479\n",
      "\t TVw: 0.169122 | TVb: -1.947186 | GSw: -0.235078 | GSb: 0.064686 | TSUw: 0.464635 | TSUb: 0.035078\n",
      "Validating epoch 2942...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 88.73898389897911\n",
      "Average validation loss: 15.342615879491873\n",
      "Training epoch 2943...\n",
      "\n",
      "Train Epoch: 2943 [0/8000 (0%)]\tBatch Loss: 86.633522\tLearning Rate (w_theta): 0.001000\t TIME:7884.0s\n",
      "\t\t\t\tDisc: 0.645416\t\tSym: 8.477470\t\tSpars: 77.510635\n",
      "\t TVw: 0.168757 | TVb: -1.947035 | GSw: -0.235078 | GSb: 0.064686 | TSUw: 0.464634 | TSUb: 0.035079\n",
      "\n",
      "Train Epoch: 2943 [4000/8000 (50%)]\tBatch Loss: 88.124510\tLearning Rate (w_theta): 0.001000\t TIME:7885.6s\n",
      "\t\t\t\tDisc: 0.687228\t\tSym: 8.511012\t\tSpars: 78.926270\n",
      "\t TVw: 0.168738 | TVb: -1.946844 | GSw: -0.235078 | GSb: 0.064685 | TSUw: 0.464634 | TSUb: 0.035079\n",
      "Validating epoch 2943...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 88.3256940645251\n",
      "Average validation loss: 15.460158315241012\n",
      "Training epoch 2944...\n",
      "\n",
      "Train Epoch: 2944 [0/8000 (0%)]\tBatch Loss: 91.390287\tLearning Rate (w_theta): 0.001000\t TIME:7888.2s\n",
      "\t\t\t\tDisc: 0.721900\t\tSym: 9.488539\t\tSpars: 81.179848\n",
      "\t TVw: 0.168807 | TVb: -1.946666 | GSw: -0.235078 | GSb: 0.064685 | TSUw: 0.464634 | TSUb: 0.035079\n",
      "\n",
      "Train Epoch: 2944 [4000/8000 (50%)]\tBatch Loss: 92.237185\tLearning Rate (w_theta): 0.001000\t TIME:7889.8s\n",
      "\t\t\t\tDisc: 0.572046\t\tSym: 9.562424\t\tSpars: 82.102715\n",
      "\t TVw: 0.168767 | TVb: -1.946477 | GSw: -0.235078 | GSb: 0.064685 | TSUw: 0.464634 | TSUb: 0.035079\n",
      "Validating epoch 2944...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 87.94216850954012\n",
      "Average validation loss: 15.082889258142187\n",
      "Training epoch 2945...\n",
      "\n",
      "Train Epoch: 2945 [0/8000 (0%)]\tBatch Loss: 87.219504\tLearning Rate (w_theta): 0.001000\t TIME:7892.3s\n",
      "\t\t\t\tDisc: 0.588464\t\tSym: 8.795050\t\tSpars: 77.835991\n",
      "\t TVw: 0.168827 | TVb: -1.946285 | GSw: -0.235078 | GSb: 0.064684 | TSUw: 0.464633 | TSUb: 0.035079\n",
      "\n",
      "Train Epoch: 2945 [4000/8000 (50%)]\tBatch Loss: 87.937655\tLearning Rate (w_theta): 0.001000\t TIME:7893.9s\n",
      "\t\t\t\tDisc: 0.619879\t\tSym: 8.906247\t\tSpars: 78.411530\n",
      "\t TVw: 0.168913 | TVb: -1.946087 | GSw: -0.235078 | GSb: 0.064684 | TSUw: 0.464633 | TSUb: 0.035080\n",
      "Validating epoch 2945...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 87.06048449320306\n",
      "Average validation loss: 15.497089098512761\n",
      "Training epoch 2946...\n",
      "\n",
      "Train Epoch: 2946 [0/8000 (0%)]\tBatch Loss: 82.214742\tLearning Rate (w_theta): 0.001000\t TIME:7896.4s\n",
      "\t\t\t\tDisc: 0.711333\t\tSym: 7.801277\t\tSpars: 73.702133\n",
      "\t TVw: 0.168798 | TVb: -1.945899 | GSw: -0.235079 | GSb: 0.064684 | TSUw: 0.464633 | TSUb: 0.035080\n",
      "\n",
      "Train Epoch: 2946 [4000/8000 (50%)]\tBatch Loss: 87.367072\tLearning Rate (w_theta): 0.001000\t TIME:7898.0s\n",
      "\t\t\t\tDisc: 0.638279\t\tSym: 8.842990\t\tSpars: 77.885803\n",
      "\t TVw: 0.168023 | TVb: -1.945779 | GSw: -0.235079 | GSb: 0.064683 | TSUw: 0.464633 | TSUb: 0.035080\n",
      "Validating epoch 2946...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 88.93792263159172\n",
      "Average validation loss: 14.581425839745688\n",
      "Training epoch 2947...\n",
      "\n",
      "Train Epoch: 2947 [0/8000 (0%)]\tBatch Loss: 98.308753\tLearning Rate (w_theta): 0.001000\t TIME:7900.5s\n",
      "\t\t\t\tDisc: 0.507756\t\tSym: 10.319780\t\tSpars: 87.481216\n",
      "\t TVw: 0.167081 | TVb: -1.945679 | GSw: -0.235079 | GSb: 0.064683 | TSUw: 0.464632 | TSUb: 0.035080\n",
      "\n",
      "Train Epoch: 2947 [4000/8000 (50%)]\tBatch Loss: 94.026669\tLearning Rate (w_theta): 0.001000\t TIME:7902.1s\n",
      "\t\t\t\tDisc: 0.527459\t\tSym: 9.362438\t\tSpars: 84.136772\n",
      "\t TVw: 0.166889 | TVb: -1.945512 | GSw: -0.235079 | GSb: 0.064683 | TSUw: 0.464632 | TSUb: 0.035081\n",
      "Validating epoch 2947...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 90.15362661556813\n",
      "Average validation loss: 14.855112984989464\n",
      "Training epoch 2948...\n",
      "\n",
      "Train Epoch: 2948 [0/8000 (0%)]\tBatch Loss: 80.554784\tLearning Rate (w_theta): 0.001000\t TIME:7905.2s\n",
      "\t\t\t\tDisc: 0.572039\t\tSym: 7.812647\t\tSpars: 72.170097\n",
      "\t TVw: 0.167150 | TVb: -1.945309 | GSw: -0.235079 | GSb: 0.064682 | TSUw: 0.464632 | TSUb: 0.035081\n",
      "\n",
      "Train Epoch: 2948 [4000/8000 (50%)]\tBatch Loss: 90.418287\tLearning Rate (w_theta): 0.001000\t TIME:7906.8s\n",
      "\t\t\t\tDisc: 0.731198\t\tSym: 9.196810\t\tSpars: 80.490280\n",
      "\t TVw: 0.167642 | TVb: -1.945062 | GSw: -0.235079 | GSb: 0.064682 | TSUw: 0.464632 | TSUb: 0.035081\n",
      "Validating epoch 2948...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 88.1945831504672\n",
      "Average validation loss: 15.470125976840887\n",
      "Training epoch 2949...\n",
      "\n",
      "Train Epoch: 2949 [0/8000 (0%)]\tBatch Loss: 95.051993\tLearning Rate (w_theta): 0.001000\t TIME:7909.3s\n",
      "\t\t\t\tDisc: 0.783261\t\tSym: 9.967043\t\tSpars: 84.301689\n",
      "\t TVw: 0.167867 | TVb: -1.944839 | GSw: -0.235079 | GSb: 0.064682 | TSUw: 0.464631 | TSUb: 0.035081\n",
      "\n",
      "Train Epoch: 2949 [4000/8000 (50%)]\tBatch Loss: 84.767582\tLearning Rate (w_theta): 0.001000\t TIME:7910.9s\n",
      "\t\t\t\tDisc: 0.665809\t\tSym: 8.620603\t\tSpars: 75.481171\n",
      "\t TVw: 0.167330 | TVb: -1.944670 | GSw: -0.235079 | GSb: 0.064681 | TSUw: 0.464631 | TSUb: 0.035082\n",
      "Validating epoch 2949...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 89.27856423080438\n",
      "Average validation loss: 15.04004743235716\n",
      "Training epoch 2950...\n",
      "\n",
      "Train Epoch: 2950 [0/8000 (0%)]\tBatch Loss: 84.613541\tLearning Rate (w_theta): 0.001000\t TIME:7913.4s\n",
      "\t\t\t\tDisc: 0.606210\t\tSym: 8.214782\t\tSpars: 75.792549\n",
      "\t TVw: 0.166485 | TVb: -1.944505 | GSw: -0.235080 | GSb: 0.064681 | TSUw: 0.464631 | TSUb: 0.035082\n",
      "\n",
      "Train Epoch: 2950 [4000/8000 (50%)]\tBatch Loss: 84.783072\tLearning Rate (w_theta): 0.001000\t TIME:7915.0s\n",
      "\t\t\t\tDisc: 0.548765\t\tSym: 8.425797\t\tSpars: 75.808510\n",
      "\t TVw: 0.166035 | TVb: -1.944308 | GSw: -0.235080 | GSb: 0.064681 | TSUw: 0.464631 | TSUb: 0.035082\n",
      "Validating epoch 2950...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 86.67328875888026\n",
      "Average validation loss: 14.876687174142376\n",
      "Training epoch 2951...\n",
      "\n",
      "Train Epoch: 2951 [0/8000 (0%)]\tBatch Loss: 82.415764\tLearning Rate (w_theta): 0.001000\t TIME:7918.3s\n",
      "\t\t\t\tDisc: 0.597244\t\tSym: 7.995758\t\tSpars: 73.822762\n",
      "\t TVw: 0.166414 | TVb: -1.944046 | GSw: -0.235080 | GSb: 0.064680 | TSUw: 0.464630 | TSUb: 0.035082\n",
      "\n",
      "Train Epoch: 2951 [4000/8000 (50%)]\tBatch Loss: 85.706756\tLearning Rate (w_theta): 0.001000\t TIME:7919.9s\n",
      "\t\t\t\tDisc: 0.654866\t\tSym: 9.198283\t\tSpars: 75.853607\n",
      "\t TVw: 0.167115 | TVb: -1.943742 | GSw: -0.235080 | GSb: 0.064680 | TSUw: 0.464630 | TSUb: 0.035082\n",
      "Validating epoch 2951...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 85.41277702719812\n",
      "Average validation loss: 15.258141435157103\n",
      "Training epoch 2952...\n",
      "\n",
      "Train Epoch: 2952 [0/8000 (0%)]\tBatch Loss: 81.911208\tLearning Rate (w_theta): 0.001000\t TIME:7922.4s\n",
      "\t\t\t\tDisc: 0.743114\t\tSym: 7.800418\t\tSpars: 73.367676\n",
      "\t TVw: 0.166887 | TVb: -1.943526 | GSw: -0.235080 | GSb: 0.064680 | TSUw: 0.464630 | TSUb: 0.035083\n",
      "\n",
      "Train Epoch: 2952 [4000/8000 (50%)]\tBatch Loss: 81.515309\tLearning Rate (w_theta): 0.001000\t TIME:7924.1s\n",
      "\t\t\t\tDisc: 0.686030\t\tSym: 7.962564\t\tSpars: 72.866714\n",
      "\t TVw: 0.165747 | TVb: -1.943411 | GSw: -0.235080 | GSb: 0.064679 | TSUw: 0.464630 | TSUb: 0.035083\n",
      "Validating epoch 2952...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 86.36689346288098\n",
      "Average validation loss: 14.513933964482508\n",
      "Training epoch 2953...\n",
      "\n",
      "Train Epoch: 2953 [0/8000 (0%)]\tBatch Loss: 79.451610\tLearning Rate (w_theta): 0.001000\t TIME:7926.6s\n",
      "\t\t\t\tDisc: 0.517893\t\tSym: 7.522538\t\tSpars: 71.411179\n",
      "\t TVw: 0.164850 | TVb: -1.943282 | GSw: -0.235080 | GSb: 0.064679 | TSUw: 0.464630 | TSUb: 0.035083\n",
      "\n",
      "Train Epoch: 2953 [4000/8000 (50%)]\tBatch Loss: 82.845216\tLearning Rate (w_theta): 0.001000\t TIME:7928.2s\n",
      "\t\t\t\tDisc: 0.551649\t\tSym: 8.213550\t\tSpars: 74.080017\n",
      "\t TVw: 0.164999 | TVb: -1.943071 | GSw: -0.235080 | GSb: 0.064679 | TSUw: 0.464629 | TSUb: 0.035083\n",
      "Validating epoch 2953...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 85.13040439623538\n",
      "Average validation loss: 14.699751950620973\n",
      "Training epoch 2954...\n",
      "\n",
      "Train Epoch: 2954 [0/8000 (0%)]\tBatch Loss: 80.522239\tLearning Rate (w_theta): 0.001000\t TIME:7930.7s\n",
      "\t\t\t\tDisc: 0.549853\t\tSym: 8.114514\t\tSpars: 71.857872\n",
      "\t TVw: 0.165897 | TVb: -1.942793 | GSw: -0.235080 | GSb: 0.064678 | TSUw: 0.464629 | TSUb: 0.035084\n",
      "\n",
      "Train Epoch: 2954 [4000/8000 (50%)]\tBatch Loss: 90.192709\tLearning Rate (w_theta): 0.001000\t TIME:7932.4s\n",
      "\t\t\t\tDisc: 0.607656\t\tSym: 10.066720\t\tSpars: 79.518333\n",
      "\t TVw: 0.166608 | TVb: -1.942529 | GSw: -0.235081 | GSb: 0.064678 | TSUw: 0.464629 | TSUb: 0.035084\n",
      "Validating epoch 2954...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 84.91211232524692\n",
      "Average validation loss: 15.201561538743265\n",
      "Training epoch 2955...\n",
      "\n",
      "Train Epoch: 2955 [0/8000 (0%)]\tBatch Loss: 80.530385\tLearning Rate (w_theta): 0.001000\t TIME:7934.9s\n",
      "\t\t\t\tDisc: 0.695154\t\tSym: 8.109645\t\tSpars: 71.725586\n",
      "\t TVw: 0.166658 | TVb: -1.942317 | GSw: -0.235081 | GSb: 0.064678 | TSUw: 0.464629 | TSUb: 0.035084\n",
      "\n",
      "Train Epoch: 2955 [4000/8000 (50%)]\tBatch Loss: 92.930191\tLearning Rate (w_theta): 0.001000\t TIME:7936.5s\n",
      "\t\t\t\tDisc: 0.749644\t\tSym: 9.697278\t\tSpars: 82.483269\n",
      "\t TVw: 0.165918 | TVb: -1.942209 | GSw: -0.235081 | GSb: 0.064677 | TSUw: 0.464628 | TSUb: 0.035084\n",
      "Validating epoch 2955...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 85.55822572249778\n",
      "Average validation loss: 14.825386055551206\n",
      "Training epoch 2956...\n",
      "\n",
      "Train Epoch: 2956 [0/8000 (0%)]\tBatch Loss: 81.672432\tLearning Rate (w_theta): 0.001000\t TIME:7939.1s\n",
      "\t\t\t\tDisc: 0.649550\t\tSym: 8.045877\t\tSpars: 72.977005\n",
      "\t TVw: 0.165286 | TVb: -1.942094 | GSw: -0.235081 | GSb: 0.064677 | TSUw: 0.464628 | TSUb: 0.035084\n",
      "\n",
      "Train Epoch: 2956 [4000/8000 (50%)]\tBatch Loss: 86.677696\tLearning Rate (w_theta): 0.001000\t TIME:7940.7s\n",
      "\t\t\t\tDisc: 0.558034\t\tSym: 9.025699\t\tSpars: 77.093964\n",
      "\t TVw: 0.165193 | TVb: -1.941914 | GSw: -0.235081 | GSb: 0.064677 | TSUw: 0.464628 | TSUb: 0.035085\n",
      "Validating epoch 2956...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 85.31686172671459\n",
      "Average validation loss: 14.41518217618026\n",
      "Training epoch 2957...\n",
      "\n",
      "Train Epoch: 2957 [0/8000 (0%)]\tBatch Loss: 89.221188\tLearning Rate (w_theta): 0.001000\t TIME:7943.2s\n",
      "\t\t\t\tDisc: 0.547060\t\tSym: 9.728983\t\tSpars: 78.945145\n",
      "\t TVw: 0.165608 | TVb: -1.941709 | GSw: -0.235081 | GSb: 0.064676 | TSUw: 0.464628 | TSUb: 0.035085\n",
      "\n",
      "Train Epoch: 2957 [4000/8000 (50%)]\tBatch Loss: 83.433974\tLearning Rate (w_theta): 0.001000\t TIME:7944.8s\n",
      "\t\t\t\tDisc: 0.605382\t\tSym: 8.668245\t\tSpars: 74.160347\n",
      "\t TVw: 0.166112 | TVb: -1.941478 | GSw: -0.235081 | GSb: 0.064676 | TSUw: 0.464627 | TSUb: 0.035085\n",
      "Validating epoch 2957...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 84.14407017766803\n",
      "Average validation loss: 14.687434684096262\n",
      "Training epoch 2958...\n",
      "\n",
      "Train Epoch: 2958 [0/8000 (0%)]\tBatch Loss: 88.812497\tLearning Rate (w_theta): 0.001000\t TIME:7947.4s\n",
      "\t\t\t\tDisc: 0.574473\t\tSym: 9.247293\t\tSpars: 78.990730\n",
      "\t TVw: 0.166528 | TVb: -1.941240 | GSw: -0.235081 | GSb: 0.064676 | TSUw: 0.464627 | TSUb: 0.035085\n",
      "\n",
      "Train Epoch: 2958 [4000/8000 (50%)]\tBatch Loss: 81.695073\tLearning Rate (w_theta): 0.001000\t TIME:7949.0s\n",
      "\t\t\t\tDisc: 0.695130\t\tSym: 8.217388\t\tSpars: 72.782555\n",
      "\t TVw: 0.166202 | TVb: -1.941054 | GSw: -0.235082 | GSb: 0.064675 | TSUw: 0.464627 | TSUb: 0.035086\n",
      "Validating epoch 2958...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 84.33588186953682\n",
      "Average validation loss: 14.84392243787341\n",
      "Training epoch 2959...\n",
      "\n",
      "Train Epoch: 2959 [0/8000 (0%)]\tBatch Loss: 85.085345\tLearning Rate (w_theta): 0.001000\t TIME:7951.4s\n",
      "\t\t\t\tDisc: 0.691528\t\tSym: 9.112163\t\tSpars: 75.281654\n",
      "\t TVw: 0.165437 | TVb: -1.940892 | GSw: -0.235082 | GSb: 0.064675 | TSUw: 0.464627 | TSUb: 0.035086\n",
      "\n",
      "Train Epoch: 2959 [4000/8000 (50%)]\tBatch Loss: 81.843480\tLearning Rate (w_theta): 0.001000\t TIME:7953.0s\n",
      "\t\t\t\tDisc: 0.606730\t\tSym: 8.765665\t\tSpars: 72.471085\n",
      "\t TVw: 0.164900 | TVb: -1.940711 | GSw: -0.235082 | GSb: 0.064675 | TSUw: 0.464626 | TSUb: 0.035086\n",
      "Validating epoch 2959...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 83.531396107521\n",
      "Average validation loss: 14.40270840023129\n",
      "Training epoch 2960...\n",
      "\n",
      "Train Epoch: 2960 [0/8000 (0%)]\tBatch Loss: 83.010892\tLearning Rate (w_theta): 0.001000\t TIME:7955.6s\n",
      "\t\t\t\tDisc: 0.547369\t\tSym: 8.652511\t\tSpars: 73.811012\n",
      "\t TVw: 0.164724 | TVb: -1.940495 | GSw: -0.235082 | GSb: 0.064675 | TSUw: 0.464626 | TSUb: 0.035086\n",
      "\n",
      "Train Epoch: 2960 [4000/8000 (50%)]\tBatch Loss: 83.857031\tLearning Rate (w_theta): 0.001000\t TIME:7957.2s\n",
      "\t\t\t\tDisc: 0.614329\t\tSym: 9.138049\t\tSpars: 74.104652\n",
      "\t TVw: 0.164815 | TVb: -1.940274 | GSw: -0.235082 | GSb: 0.064674 | TSUw: 0.464626 | TSUb: 0.035086\n",
      "Validating epoch 2960...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 83.2632825091531\n",
      "Average validation loss: 14.639632603889412\n",
      "Training epoch 2961...\n",
      "\n",
      "Train Epoch: 2961 [0/8000 (0%)]\tBatch Loss: 82.726868\tLearning Rate (w_theta): 0.001000\t TIME:7960.5s\n",
      "\t\t\t\tDisc: 0.623297\t\tSym: 8.902239\t\tSpars: 73.201332\n",
      "\t TVw: 0.165008 | TVb: -1.940037 | GSw: -0.235082 | GSb: 0.064674 | TSUw: 0.464626 | TSUb: 0.035087\n",
      "\n",
      "Train Epoch: 2961 [4000/8000 (50%)]\tBatch Loss: 81.809474\tLearning Rate (w_theta): 0.001000\t TIME:7962.1s\n",
      "\t\t\t\tDisc: 0.688386\t\tSym: 8.439074\t\tSpars: 72.682014\n",
      "\t TVw: 0.164998 | TVb: -1.939824 | GSw: -0.235082 | GSb: 0.064674 | TSUw: 0.464625 | TSUb: 0.035087\n",
      "Validating epoch 2961...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 83.1041667632061\n",
      "Average validation loss: 14.691392970265206\n",
      "Training epoch 2962...\n",
      "\n",
      "Train Epoch: 2962 [0/8000 (0%)]\tBatch Loss: 82.598860\tLearning Rate (w_theta): 0.001000\t TIME:7964.6s\n",
      "\t\t\t\tDisc: 0.716328\t\tSym: 8.741480\t\tSpars: 73.141052\n",
      "\t TVw: 0.164484 | TVb: -1.939669 | GSw: -0.235082 | GSb: 0.064673 | TSUw: 0.464625 | TSUb: 0.035087\n",
      "\n",
      "Train Epoch: 2962 [4000/8000 (50%)]\tBatch Loss: 88.459884\tLearning Rate (w_theta): 0.001000\t TIME:7966.2s\n",
      "\t\t\t\tDisc: 0.538284\t\tSym: 9.752120\t\tSpars: 78.169479\n",
      "\t TVw: 0.163643 | TVb: -1.939537 | GSw: -0.235082 | GSb: 0.064673 | TSUw: 0.464625 | TSUb: 0.035087\n",
      "Validating epoch 2962...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 83.60626867117848\n",
      "Average validation loss: 14.294149163806741\n",
      "Training epoch 2963...\n",
      "\n",
      "Train Epoch: 2963 [0/8000 (0%)]\tBatch Loss: 83.657400\tLearning Rate (w_theta): 0.001000\t TIME:7969.2s\n",
      "\t\t\t\tDisc: 0.576558\t\tSym: 8.644395\t\tSpars: 74.436447\n",
      "\t TVw: 0.163405 | TVb: -1.939361 | GSw: -0.235083 | GSb: 0.064673 | TSUw: 0.464625 | TSUb: 0.035088\n",
      "\n",
      "Train Epoch: 2963 [4000/8000 (50%)]\tBatch Loss: 83.216027\tLearning Rate (w_theta): 0.001000\t TIME:7970.9s\n",
      "\t\t\t\tDisc: 0.572127\t\tSym: 8.765184\t\tSpars: 73.878716\n",
      "\t TVw: 0.163694 | TVb: -1.939130 | GSw: -0.235083 | GSb: 0.064672 | TSUw: 0.464625 | TSUb: 0.035088\n",
      "Validating epoch 2963...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 82.42912228776166\n",
      "Average validation loss: 14.555608380851748\n",
      "Training epoch 2964...\n",
      "\n",
      "Train Epoch: 2964 [0/8000 (0%)]\tBatch Loss: 88.201667\tLearning Rate (w_theta): 0.001000\t TIME:7973.4s\n",
      "\t\t\t\tDisc: 0.633094\t\tSym: 9.891441\t\tSpars: 77.677132\n",
      "\t TVw: 0.164125 | TVb: -1.938895 | GSw: -0.235083 | GSb: 0.064672 | TSUw: 0.464624 | TSUb: 0.035088\n",
      "\n",
      "Train Epoch: 2964 [4000/8000 (50%)]\tBatch Loss: 82.841200\tLearning Rate (w_theta): 0.001000\t TIME:7975.0s\n",
      "\t\t\t\tDisc: 0.615962\t\tSym: 8.994777\t\tSpars: 73.230461\n",
      "\t TVw: 0.164408 | TVb: -1.938650 | GSw: -0.235083 | GSb: 0.064672 | TSUw: 0.464624 | TSUb: 0.035088\n",
      "Validating epoch 2964...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 82.26120476439726\n",
      "Average validation loss: 14.410260297908492\n",
      "Training epoch 2965...\n",
      "\n",
      "Train Epoch: 2965 [0/8000 (0%)]\tBatch Loss: 81.511782\tLearning Rate (w_theta): 0.001000\t TIME:7977.5s\n",
      "\t\t\t\tDisc: 0.630034\t\tSym: 8.468829\t\tSpars: 72.412918\n",
      "\t TVw: 0.163770 | TVb: -1.938535 | GSw: -0.235083 | GSb: 0.064671 | TSUw: 0.464624 | TSUb: 0.035088\n",
      "\n",
      "Train Epoch: 2965 [4000/8000 (50%)]\tBatch Loss: 80.166857\tLearning Rate (w_theta): 0.001000\t TIME:7979.1s\n",
      "\t\t\t\tDisc: 0.597163\t\tSym: 8.329497\t\tSpars: 71.240196\n",
      "\t TVw: 0.163232 | TVb: -1.938402 | GSw: -0.235083 | GSb: 0.064671 | TSUw: 0.464624 | TSUb: 0.035089\n",
      "Validating epoch 2965...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 82.01060138381004\n",
      "Average validation loss: 14.034589244699877\n",
      "Training epoch 2966...\n",
      "\n",
      "Train Epoch: 2966 [0/8000 (0%)]\tBatch Loss: 85.378108\tLearning Rate (w_theta): 0.001000\t TIME:7981.6s\n",
      "\t\t\t\tDisc: 0.537113\t\tSym: 9.181174\t\tSpars: 75.659821\n",
      "\t TVw: 0.163166 | TVb: -1.938208 | GSw: -0.235083 | GSb: 0.064671 | TSUw: 0.464623 | TSUb: 0.035089\n",
      "\n",
      "Train Epoch: 2966 [4000/8000 (50%)]\tBatch Loss: 80.851468\tLearning Rate (w_theta): 0.001000\t TIME:7983.2s\n",
      "\t\t\t\tDisc: 0.677600\t\tSym: 8.515749\t\tSpars: 71.658119\n",
      "\t TVw: 0.162870 | TVb: -1.938046 | GSw: -0.235083 | GSb: 0.064670 | TSUw: 0.464623 | TSUb: 0.035089\n",
      "Validating epoch 2966...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 83.09829273893477\n",
      "Average validation loss: 14.140864995694635\n",
      "Training epoch 2967...\n",
      "\n",
      "Train Epoch: 2967 [0/8000 (0%)]\tBatch Loss: 81.697862\tLearning Rate (w_theta): 0.001000\t TIME:7985.8s\n",
      "\t\t\t\tDisc: 0.559833\t\tSym: 8.317091\t\tSpars: 72.820938\n",
      "\t TVw: 0.162774 | TVb: -1.937882 | GSw: -0.235083 | GSb: 0.064670 | TSUw: 0.464623 | TSUb: 0.035089\n",
      "\n",
      "Train Epoch: 2967 [4000/8000 (50%)]\tBatch Loss: 90.227883\tLearning Rate (w_theta): 0.001000\t TIME:7987.4s\n",
      "\t\t\t\tDisc: 0.514389\t\tSym: 9.597268\t\tSpars: 80.116226\n",
      "\t TVw: 0.162122 | TVb: -1.937733 | GSw: -0.235084 | GSb: 0.064670 | TSUw: 0.464623 | TSUb: 0.035090\n",
      "Validating epoch 2967...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 84.48400891552294\n",
      "Average validation loss: 13.844942246293378\n",
      "Training epoch 2968...\n",
      "\n",
      "Train Epoch: 2968 [0/8000 (0%)]\tBatch Loss: 82.435531\tLearning Rate (w_theta): 0.001000\t TIME:7990.0s\n",
      "\t\t\t\tDisc: 0.497798\t\tSym: 8.326496\t\tSpars: 73.611237\n",
      "\t TVw: 0.161836 | TVb: -1.937544 | GSw: -0.235084 | GSb: 0.064669 | TSUw: 0.464622 | TSUb: 0.035090\n",
      "\n",
      "Train Epoch: 2968 [4000/8000 (50%)]\tBatch Loss: 85.226581\tLearning Rate (w_theta): 0.001000\t TIME:7991.6s\n",
      "\t\t\t\tDisc: 0.531491\t\tSym: 9.476523\t\tSpars: 75.218567\n",
      "\t TVw: 0.161590 | TVb: -1.937376 | GSw: -0.235084 | GSb: 0.064669 | TSUw: 0.464622 | TSUb: 0.035090\n",
      "Validating epoch 2968...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 84.51724222488367\n",
      "Average validation loss: 14.278746818190557\n",
      "Training epoch 2969...\n",
      "\n",
      "Train Epoch: 2969 [0/8000 (0%)]\tBatch Loss: 88.739449\tLearning Rate (w_theta): 0.001000\t TIME:7994.3s\n",
      "\t\t\t\tDisc: 0.720945\t\tSym: 10.403941\t\tSpars: 77.614563\n",
      "\t TVw: 0.161904 | TVb: -1.937131 | GSw: -0.235084 | GSb: 0.064669 | TSUw: 0.464622 | TSUb: 0.035090\n",
      "\n",
      "Train Epoch: 2969 [4000/8000 (50%)]\tBatch Loss: 84.676356\tLearning Rate (w_theta): 0.001000\t TIME:7995.9s\n",
      "\t\t\t\tDisc: 0.744378\t\tSym: 8.737390\t\tSpars: 75.194588\n",
      "\t TVw: 0.161780 | TVb: -1.936931 | GSw: -0.235084 | GSb: 0.064668 | TSUw: 0.464622 | TSUb: 0.035091\n",
      "Validating epoch 2969...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 82.83617062696209\n",
      "Average validation loss: 14.223579802033612\n",
      "Training epoch 2970...\n",
      "\n",
      "Train Epoch: 2970 [0/8000 (0%)]\tBatch Loss: 84.315018\tLearning Rate (w_theta): 0.001000\t TIME:7998.5s\n",
      "\t\t\t\tDisc: 0.645227\t\tSym: 9.456107\t\tSpars: 74.213684\n",
      "\t TVw: 0.161690 | TVb: -1.936710 | GSw: -0.235084 | GSb: 0.064668 | TSUw: 0.464621 | TSUb: 0.035091\n",
      "\n",
      "Train Epoch: 2970 [4000/8000 (50%)]\tBatch Loss: 83.861129\tLearning Rate (w_theta): 0.001000\t TIME:8000.1s\n",
      "\t\t\t\tDisc: 0.653477\t\tSym: 9.105571\t\tSpars: 74.102081\n",
      "\t TVw: 0.161534 | TVb: -1.936463 | GSw: -0.235084 | GSb: 0.064667 | TSUw: 0.464621 | TSUb: 0.035091\n",
      "Validating epoch 2970...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 81.20478399154858\n",
      "Average validation loss: 14.097411054375181\n",
      "Training epoch 2971...\n",
      "\n",
      "Train Epoch: 2971 [0/8000 (0%)]\tBatch Loss: 78.501642\tLearning Rate (w_theta): 0.001000\t TIME:8003.6s\n",
      "\t\t\t\tDisc: 0.586370\t\tSym: 8.135395\t\tSpars: 69.779877\n",
      "\t TVw: 0.161320 | TVb: -1.936234 | GSw: -0.235084 | GSb: 0.064667 | TSUw: 0.464621 | TSUb: 0.035091\n",
      "\n",
      "Train Epoch: 2971 [4000/8000 (50%)]\tBatch Loss: 78.399405\tLearning Rate (w_theta): 0.001000\t TIME:8005.2s\n",
      "\t\t\t\tDisc: 0.662423\t\tSym: 8.250363\t\tSpars: 69.486618\n",
      "\t TVw: 0.160735 | TVb: -1.936054 | GSw: -0.235085 | GSb: 0.064667 | TSUw: 0.464621 | TSUb: 0.035091\n",
      "Validating epoch 2971...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 81.3587698871759\n",
      "Average validation loss: 13.867960088188553\n",
      "Training epoch 2972...\n",
      "\n",
      "Train Epoch: 2972 [0/8000 (0%)]\tBatch Loss: 81.393265\tLearning Rate (w_theta): 0.001000\t TIME:8007.7s\n",
      "\t\t\t\tDisc: 0.560597\t\tSym: 8.742214\t\tSpars: 72.090454\n",
      "\t TVw: 0.160191 | TVb: -1.935869 | GSw: -0.235085 | GSb: 0.064666 | TSUw: 0.464620 | TSUb: 0.035092\n",
      "\n",
      "Train Epoch: 2972 [4000/8000 (50%)]\tBatch Loss: 76.868869\tLearning Rate (w_theta): 0.001000\t TIME:8009.3s\n",
      "\t\t\t\tDisc: 0.568344\t\tSym: 8.065516\t\tSpars: 68.235008\n",
      "\t TVw: 0.160109 | TVb: -1.935665 | GSw: -0.235085 | GSb: 0.064666 | TSUw: 0.464620 | TSUb: 0.035092\n",
      "Validating epoch 2972...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 80.62167053117298\n",
      "Average validation loss: 13.793507973028094\n",
      "Training epoch 2973...\n",
      "\n",
      "Train Epoch: 2973 [0/8000 (0%)]\tBatch Loss: 78.297614\tLearning Rate (w_theta): 0.001000\t TIME:8011.8s\n",
      "\t\t\t\tDisc: 0.575568\t\tSym: 8.328140\t\tSpars: 69.393906\n",
      "\t TVw: 0.160300 | TVb: -1.935449 | GSw: -0.235085 | GSb: 0.064666 | TSUw: 0.464620 | TSUb: 0.035092\n",
      "\n",
      "Train Epoch: 2973 [4000/8000 (50%)]\tBatch Loss: 78.976710\tLearning Rate (w_theta): 0.001000\t TIME:8013.4s\n",
      "\t\t\t\tDisc: 0.657792\t\tSym: 8.288591\t\tSpars: 70.030327\n",
      "\t TVw: 0.160650 | TVb: -1.935220 | GSw: -0.235085 | GSb: 0.064665 | TSUw: 0.464620 | TSUb: 0.035092\n",
      "Validating epoch 2973...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 80.05964031110138\n",
      "Average validation loss: 13.992085646185382\n",
      "Training epoch 2974...\n",
      "\n",
      "Train Epoch: 2974 [0/8000 (0%)]\tBatch Loss: 79.660192\tLearning Rate (w_theta): 0.001000\t TIME:8015.9s\n",
      "\t\t\t\tDisc: 0.710375\t\tSym: 8.670260\t\tSpars: 70.279556\n",
      "\t TVw: 0.160690 | TVb: -1.935037 | GSw: -0.235085 | GSb: 0.064665 | TSUw: 0.464620 | TSUb: 0.035093\n",
      "\n",
      "Train Epoch: 2974 [4000/8000 (50%)]\tBatch Loss: 80.311787\tLearning Rate (w_theta): 0.001000\t TIME:8017.5s\n",
      "\t\t\t\tDisc: 0.539408\t\tSym: 8.672403\t\tSpars: 71.099976\n",
      "\t TVw: 0.160107 | TVb: -1.934912 | GSw: -0.235085 | GSb: 0.064665 | TSUw: 0.464619 | TSUb: 0.035093\n",
      "Validating epoch 2974...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 80.21663739233821\n",
      "Average validation loss: 13.713657504336295\n",
      "Training epoch 2975...\n",
      "\n",
      "Train Epoch: 2975 [0/8000 (0%)]\tBatch Loss: 78.441224\tLearning Rate (w_theta): 0.001000\t TIME:8020.0s\n",
      "\t\t\t\tDisc: 0.581545\t\tSym: 8.695785\t\tSpars: 69.163895\n",
      "\t TVw: 0.160157 | TVb: -1.934718 | GSw: -0.235085 | GSb: 0.064665 | TSUw: 0.464619 | TSUb: 0.035093\n",
      "\n",
      "Train Epoch: 2975 [4000/8000 (50%)]\tBatch Loss: 81.068735\tLearning Rate (w_theta): 0.001000\t TIME:8021.6s\n",
      "\t\t\t\tDisc: 0.583060\t\tSym: 9.150683\t\tSpars: 71.334991\n",
      "\t TVw: 0.160563 | TVb: -1.934470 | GSw: -0.235086 | GSb: 0.064664 | TSUw: 0.464619 | TSUb: 0.035093\n",
      "Validating epoch 2975...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 80.29248786016275\n",
      "Average validation loss: 13.921628003806939\n",
      "Training epoch 2976...\n",
      "\n",
      "Train Epoch: 2976 [0/8000 (0%)]\tBatch Loss: 82.337431\tLearning Rate (w_theta): 0.001000\t TIME:8024.1s\n",
      "\t\t\t\tDisc: 0.687961\t\tSym: 9.240802\t\tSpars: 72.408669\n",
      "\t TVw: 0.160260 | TVb: -1.934291 | GSw: -0.235086 | GSb: 0.064664 | TSUw: 0.464619 | TSUb: 0.035093\n",
      "\n",
      "Train Epoch: 2976 [4000/8000 (50%)]\tBatch Loss: 83.977881\tLearning Rate (w_theta): 0.001000\t TIME:8025.7s\n",
      "\t\t\t\tDisc: 0.695697\t\tSym: 9.223994\t\tSpars: 74.058189\n",
      "\t TVw: 0.159218 | TVb: -1.934185 | GSw: -0.235086 | GSb: 0.064664 | TSUw: 0.464618 | TSUb: 0.035094\n",
      "Validating epoch 2976...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 80.91217104623672\n",
      "Average validation loss: 13.547059088112917\n",
      "Training epoch 2977...\n",
      "\n",
      "Train Epoch: 2977 [0/8000 (0%)]\tBatch Loss: 79.407997\tLearning Rate (w_theta): 0.001000\t TIME:8028.2s\n",
      "\t\t\t\tDisc: 0.541708\t\tSym: 8.754358\t\tSpars: 70.111931\n",
      "\t TVw: 0.158728 | TVb: -1.934036 | GSw: -0.235086 | GSb: 0.064663 | TSUw: 0.464618 | TSUb: 0.035094\n",
      "\n",
      "Train Epoch: 2977 [4000/8000 (50%)]\tBatch Loss: 83.678777\tLearning Rate (w_theta): 0.001000\t TIME:8029.8s\n",
      "\t\t\t\tDisc: 0.507090\t\tSym: 9.221812\t\tSpars: 73.949875\n",
      "\t TVw: 0.158647 | TVb: -1.933813 | GSw: -0.235086 | GSb: 0.064663 | TSUw: 0.464618 | TSUb: 0.035094\n",
      "Validating epoch 2977...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 81.0162995866833\n",
      "Average validation loss: 13.41037691644456\n",
      "Training epoch 2978...\n",
      "\n",
      "Train Epoch: 2978 [0/8000 (0%)]\tBatch Loss: 85.232103\tLearning Rate (w_theta): 0.001000\t TIME:8032.3s\n",
      "\t\t\t\tDisc: 0.525310\t\tSym: 9.440893\t\tSpars: 75.265900\n",
      "\t TVw: 0.158819 | TVb: -1.933586 | GSw: -0.235086 | GSb: 0.064663 | TSUw: 0.464618 | TSUb: 0.035094\n",
      "\n",
      "Train Epoch: 2978 [4000/8000 (50%)]\tBatch Loss: 81.820890\tLearning Rate (w_theta): 0.001000\t TIME:8033.9s\n",
      "\t\t\t\tDisc: 0.605564\t\tSym: 9.059946\t\tSpars: 72.155380\n",
      "\t TVw: 0.158504 | TVb: -1.933438 | GSw: -0.235086 | GSb: 0.064662 | TSUw: 0.464617 | TSUb: 0.035095\n",
      "Validating epoch 2978...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 81.0206539929394\n",
      "Average validation loss: 13.760737610351107\n",
      "Training epoch 2979...\n",
      "\n",
      "Train Epoch: 2979 [0/8000 (0%)]\tBatch Loss: 83.452519\tLearning Rate (w_theta): 0.001000\t TIME:8036.5s\n",
      "\t\t\t\tDisc: 0.723844\t\tSym: 9.289199\t\tSpars: 73.439476\n",
      "\t TVw: 0.158521 | TVb: -1.933237 | GSw: -0.235086 | GSb: 0.064662 | TSUw: 0.464617 | TSUb: 0.035095\n",
      "\n",
      "Train Epoch: 2979 [4000/8000 (50%)]\tBatch Loss: 76.412682\tLearning Rate (w_theta): 0.001000\t TIME:8038.0s\n",
      "\t\t\t\tDisc: 0.668678\t\tSym: 7.994234\t\tSpars: 67.749771\n",
      "\t TVw: 0.158654 | TVb: -1.932995 | GSw: -0.235086 | GSb: 0.064661 | TSUw: 0.464617 | TSUb: 0.035095\n",
      "Validating epoch 2979...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 79.76024203873348\n",
      "Average validation loss: 13.610326448329277\n",
      "Training epoch 2980...\n",
      "\n",
      "Train Epoch: 2980 [0/8000 (0%)]\tBatch Loss: 78.655414\tLearning Rate (w_theta): 0.001000\t TIME:8041.1s\n",
      "\t\t\t\tDisc: 0.573006\t\tSym: 8.746837\t\tSpars: 69.335571\n",
      "\t TVw: 0.158777 | TVb: -1.932734 | GSw: -0.235087 | GSb: 0.064661 | TSUw: 0.464617 | TSUb: 0.035095\n",
      "\n",
      "Train Epoch: 2980 [4000/8000 (50%)]\tBatch Loss: 77.352433\tLearning Rate (w_theta): 0.001000\t TIME:8042.7s\n",
      "\t\t\t\tDisc: 0.589365\t\tSym: 8.408912\t\tSpars: 68.354156\n",
      "\t TVw: 0.158388 | TVb: -1.932505 | GSw: -0.235087 | GSb: 0.064661 | TSUw: 0.464616 | TSUb: 0.035096\n",
      "Validating epoch 2980...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 78.12126409185169\n",
      "Average validation loss: 13.619631991870753\n",
      "Training epoch 2981...\n",
      "\n",
      "Train Epoch: 2981 [0/8000 (0%)]\tBatch Loss: 76.135181\tLearning Rate (w_theta): 0.001000\t TIME:8046.0s\n",
      "\t\t\t\tDisc: 0.591546\t\tSym: 8.639277\t\tSpars: 66.904358\n",
      "\t TVw: 0.157721 | TVb: -1.932293 | GSw: -0.235087 | GSb: 0.064660 | TSUw: 0.464616 | TSUb: 0.035096\n",
      "\n",
      "Train Epoch: 2981 [4000/8000 (50%)]\tBatch Loss: 81.849543\tLearning Rate (w_theta): 0.001000\t TIME:8047.6s\n",
      "\t\t\t\tDisc: 0.716310\t\tSym: 8.894448\t\tSpars: 72.238785\n",
      "\t TVw: 0.156935 | TVb: -1.932107 | GSw: -0.235087 | GSb: 0.064660 | TSUw: 0.464616 | TSUb: 0.035096\n",
      "Validating epoch 2981...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 78.4759131664257\n",
      "Average validation loss: 13.321394279880826\n",
      "Training epoch 2982...\n",
      "\n",
      "Train Epoch: 2982 [0/8000 (0%)]\tBatch Loss: 78.231544\tLearning Rate (w_theta): 0.001000\t TIME:8050.2s\n",
      "\t\t\t\tDisc: 0.514710\t\tSym: 8.784667\t\tSpars: 68.932167\n",
      "\t TVw: 0.156102 | TVb: -1.931947 | GSw: -0.235087 | GSb: 0.064660 | TSUw: 0.464616 | TSUb: 0.035096\n",
      "\n",
      "Train Epoch: 2982 [4000/8000 (50%)]\tBatch Loss: 78.871166\tLearning Rate (w_theta): 0.001000\t TIME:8051.8s\n",
      "\t\t\t\tDisc: 0.558568\t\tSym: 8.913665\t\tSpars: 69.398933\n",
      "\t TVw: 0.156164 | TVb: -1.931722 | GSw: -0.235087 | GSb: 0.064659 | TSUw: 0.464615 | TSUb: 0.035096\n",
      "Validating epoch 2982...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 77.53144857117262\n",
      "Average validation loss: 13.457774790140453\n",
      "Training epoch 2983...\n",
      "\n",
      "Train Epoch: 2983 [0/8000 (0%)]\tBatch Loss: 72.493711\tLearning Rate (w_theta): 0.001000\t TIME:8054.2s\n",
      "\t\t\t\tDisc: 0.601721\t\tSym: 7.763100\t\tSpars: 64.128891\n",
      "\t TVw: 0.156678 | TVb: -1.931456 | GSw: -0.235087 | GSb: 0.064659 | TSUw: 0.464615 | TSUb: 0.035097\n",
      "\n",
      "Train Epoch: 2983 [4000/8000 (50%)]\tBatch Loss: 77.137202\tLearning Rate (w_theta): 0.001000\t TIME:8055.8s\n",
      "\t\t\t\tDisc: 0.591087\t\tSym: 8.614017\t\tSpars: 67.932098\n",
      "\t TVw: 0.156997 | TVb: -1.931229 | GSw: -0.235087 | GSb: 0.064659 | TSUw: 0.464615 | TSUb: 0.035097\n",
      "Validating epoch 2983...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 77.26757673339918\n",
      "Average validation loss: 13.379606728480816\n",
      "Training epoch 2984...\n",
      "\n",
      "Train Epoch: 2984 [0/8000 (0%)]\tBatch Loss: 74.989361\tLearning Rate (w_theta): 0.001000\t TIME:8058.4s\n",
      "\t\t\t\tDisc: 0.601896\t\tSym: 8.087881\t\tSpars: 66.299583\n",
      "\t TVw: 0.156640 | TVb: -1.931075 | GSw: -0.235087 | GSb: 0.064658 | TSUw: 0.464615 | TSUb: 0.035097\n",
      "\n",
      "Train Epoch: 2984 [4000/8000 (50%)]\tBatch Loss: 81.550789\tLearning Rate (w_theta): 0.001000\t TIME:8060.0s\n",
      "\t\t\t\tDisc: 0.668316\t\tSym: 9.289951\t\tSpars: 71.592522\n",
      "\t TVw: 0.156328 | TVb: -1.930917 | GSw: -0.235087 | GSb: 0.064658 | TSUw: 0.464615 | TSUb: 0.035097\n",
      "Validating epoch 2984...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 77.6314968045369\n",
      "Average validation loss: 13.226718283301993\n",
      "Training epoch 2985...\n",
      "\n",
      "Train Epoch: 2985 [0/8000 (0%)]\tBatch Loss: 74.798585\tLearning Rate (w_theta): 0.001000\t TIME:8062.5s\n",
      "\t\t\t\tDisc: 0.550925\t\tSym: 8.222842\t\tSpars: 66.024818\n",
      "\t TVw: 0.155986 | TVb: -1.930780 | GSw: -0.235088 | GSb: 0.064658 | TSUw: 0.464614 | TSUb: 0.035098\n",
      "\n",
      "Train Epoch: 2985 [4000/8000 (50%)]\tBatch Loss: 87.299178\tLearning Rate (w_theta): 0.001000\t TIME:8064.1s\n",
      "\t\t\t\tDisc: 0.468601\t\tSym: 9.663890\t\tSpars: 77.166687\n",
      "\t TVw: 0.155062 | TVb: -1.930686 | GSw: -0.235088 | GSb: 0.064657 | TSUw: 0.464614 | TSUb: 0.035098\n",
      "Validating epoch 2985...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 80.79226654219984\n",
      "Average validation loss: 13.061576032578\n",
      "Training epoch 2986...\n",
      "\n",
      "Train Epoch: 2986 [0/8000 (0%)]\tBatch Loss: 88.082286\tLearning Rate (w_theta): 0.001000\t TIME:8066.6s\n",
      "\t\t\t\tDisc: 0.476315\t\tSym: 10.305419\t\tSpars: 77.300552\n",
      "\t TVw: 0.154595 | TVb: -1.930541 | GSw: -0.235088 | GSb: 0.064657 | TSUw: 0.464614 | TSUb: 0.035098\n",
      "\n",
      "Train Epoch: 2986 [4000/8000 (50%)]\tBatch Loss: 77.656479\tLearning Rate (w_theta): 0.001000\t TIME:8068.2s\n",
      "\t\t\t\tDisc: 0.520990\t\tSym: 8.726385\t\tSpars: 68.409103\n",
      "\t TVw: 0.154583 | TVb: -1.930398 | GSw: -0.235088 | GSb: 0.064657 | TSUw: 0.464614 | TSUb: 0.035098\n",
      "Validating epoch 2986...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 81.45489781866434\n",
      "Average validation loss: 13.115353606762488\n",
      "Training epoch 2987...\n",
      "\n",
      "Train Epoch: 2987 [0/8000 (0%)]\tBatch Loss: 75.528009\tLearning Rate (w_theta): 0.001000\t TIME:8070.7s\n",
      "\t\t\t\tDisc: 0.571056\t\tSym: 8.531820\t\tSpars: 66.425133\n",
      "\t TVw: 0.155818 | TVb: -1.930113 | GSw: -0.235088 | GSb: 0.064656 | TSUw: 0.464613 | TSUb: 0.035099\n",
      "\n",
      "Train Epoch: 2987 [4000/8000 (50%)]\tBatch Loss: 77.172212\tLearning Rate (w_theta): 0.001000\t TIME:8072.3s\n",
      "\t\t\t\tDisc: 0.816444\t\tSym: 8.412522\t\tSpars: 67.943245\n",
      "\t TVw: 0.156696 | TVb: -1.929797 | GSw: -0.235088 | GSb: 0.064656 | TSUw: 0.464613 | TSUb: 0.035099\n",
      "Validating epoch 2987...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 79.30948838297006\n",
      "Average validation loss: 13.439668608939293\n",
      "Training epoch 2988...\n",
      "\n",
      "Train Epoch: 2988 [0/8000 (0%)]\tBatch Loss: 79.670961\tLearning Rate (w_theta): 0.001000\t TIME:8074.9s\n",
      "\t\t\t\tDisc: 0.687551\t\tSym: 9.366483\t\tSpars: 69.616928\n",
      "\t TVw: 0.156116 | TVb: -1.929592 | GSw: -0.235088 | GSb: 0.064656 | TSUw: 0.464613 | TSUb: 0.035099\n",
      "\n",
      "Train Epoch: 2988 [4000/8000 (50%)]\tBatch Loss: 81.069614\tLearning Rate (w_theta): 0.001000\t TIME:8076.5s\n",
      "\t\t\t\tDisc: 0.740389\t\tSym: 9.373345\t\tSpars: 70.955879\n",
      "\t TVw: 0.155232 | TVb: -1.929408 | GSw: -0.235088 | GSb: 0.064655 | TSUw: 0.464613 | TSUb: 0.035099\n",
      "Validating epoch 2988...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 77.27965141413125\n",
      "Average validation loss: 13.244171983911883\n",
      "Training epoch 2989...\n",
      "\n",
      "Train Epoch: 2989 [0/8000 (0%)]\tBatch Loss: 75.262774\tLearning Rate (w_theta): 0.001000\t TIME:8079.0s\n",
      "\t\t\t\tDisc: 0.654475\t\tSym: 8.389045\t\tSpars: 66.219254\n",
      "\t TVw: 0.154309 | TVb: -1.929210 | GSw: -0.235089 | GSb: 0.064655 | TSUw: 0.464612 | TSUb: 0.035100\n",
      "\n",
      "Train Epoch: 2989 [4000/8000 (50%)]\tBatch Loss: 73.833530\tLearning Rate (w_theta): 0.001000\t TIME:8080.6s\n",
      "\t\t\t\tDisc: 0.540208\t\tSym: 8.534305\t\tSpars: 64.759018\n",
      "\t TVw: 0.154029 | TVb: -1.928940 | GSw: -0.235089 | GSb: 0.064655 | TSUw: 0.464612 | TSUb: 0.035100\n",
      "Validating epoch 2989...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 76.23162089728095\n",
      "Average validation loss: 13.223084611300699\n",
      "Training epoch 2990...\n",
      "\n",
      "Train Epoch: 2990 [0/8000 (0%)]\tBatch Loss: 72.961612\tLearning Rate (w_theta): 0.001000\t TIME:8083.2s\n",
      "\t\t\t\tDisc: 0.629461\t\tSym: 7.868727\t\tSpars: 64.463425\n",
      "\t TVw: 0.154065 | TVb: -1.928685 | GSw: -0.235089 | GSb: 0.064654 | TSUw: 0.464612 | TSUb: 0.035100\n",
      "\n",
      "Train Epoch: 2990 [4000/8000 (50%)]\tBatch Loss: 74.249074\tLearning Rate (w_theta): 0.001000\t TIME:8084.8s\n",
      "\t\t\t\tDisc: 0.674861\t\tSym: 8.106035\t\tSpars: 65.468178\n",
      "\t TVw: 0.153658 | TVb: -1.928524 | GSw: -0.235089 | GSb: 0.064654 | TSUw: 0.464612 | TSUb: 0.035100\n",
      "Validating epoch 2990...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 76.79900319550669\n",
      "Average validation loss: 12.857801687749799\n",
      "Training epoch 2991...\n",
      "\n",
      "Train Epoch: 2991 [0/8000 (0%)]\tBatch Loss: 75.618222\tLearning Rate (w_theta): 0.001000\t TIME:8088.0s\n",
      "\t\t\t\tDisc: 0.503853\t\tSym: 8.347599\t\tSpars: 66.766769\n",
      "\t TVw: 0.152805 | TVb: -1.928402 | GSw: -0.235089 | GSb: 0.064654 | TSUw: 0.464611 | TSUb: 0.035100\n",
      "\n",
      "Train Epoch: 2991 [4000/8000 (50%)]\tBatch Loss: 80.290852\tLearning Rate (w_theta): 0.001000\t TIME:8089.6s\n",
      "\t\t\t\tDisc: 0.489972\t\tSym: 9.792045\t\tSpars: 70.008835\n",
      "\t TVw: 0.152753 | TVb: -1.928219 | GSw: -0.235089 | GSb: 0.064653 | TSUw: 0.464611 | TSUb: 0.035101\n",
      "Validating epoch 2991...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 76.90619417199842\n",
      "Average validation loss: 12.837191603830926\n",
      "Training epoch 2992...\n",
      "\n",
      "Train Epoch: 2992 [0/8000 (0%)]\tBatch Loss: 73.913315\tLearning Rate (w_theta): 0.001000\t TIME:8092.2s\n",
      "\t\t\t\tDisc: 0.570997\t\tSym: 8.134959\t\tSpars: 65.207359\n",
      "\t TVw: 0.153261 | TVb: -1.928007 | GSw: -0.235089 | GSb: 0.064653 | TSUw: 0.464611 | TSUb: 0.035101\n",
      "\n",
      "Train Epoch: 2992 [4000/8000 (50%)]\tBatch Loss: 75.309803\tLearning Rate (w_theta): 0.001000\t TIME:8093.7s\n",
      "\t\t\t\tDisc: 0.661724\t\tSym: 8.719414\t\tSpars: 65.928665\n",
      "\t TVw: 0.154052 | TVb: -1.927756 | GSw: -0.235089 | GSb: 0.064653 | TSUw: 0.464611 | TSUb: 0.035101\n",
      "Validating epoch 2992...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 75.6050047783187\n",
      "Average validation loss: 12.986632677966638\n",
      "Training epoch 2993...\n",
      "\n",
      "Train Epoch: 2993 [0/8000 (0%)]\tBatch Loss: 75.495795\tLearning Rate (w_theta): 0.001000\t TIME:8096.3s\n",
      "\t\t\t\tDisc: 0.671496\t\tSym: 8.514088\t\tSpars: 66.310211\n",
      "\t TVw: 0.154255 | TVb: -1.927536 | GSw: -0.235089 | GSb: 0.064652 | TSUw: 0.464610 | TSUb: 0.035101\n",
      "\n",
      "Train Epoch: 2993 [4000/8000 (50%)]\tBatch Loss: 70.970728\tLearning Rate (w_theta): 0.001000\t TIME:8097.9s\n",
      "\t\t\t\tDisc: 0.533528\t\tSym: 7.716402\t\tSpars: 62.720798\n",
      "\t TVw: 0.153499 | TVb: -1.927398 | GSw: -0.235090 | GSb: 0.064652 | TSUw: 0.464610 | TSUb: 0.035102\n",
      "Validating epoch 2993...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 75.73073104082549\n",
      "Average validation loss: 12.717462789652435\n",
      "Training epoch 2994...\n",
      "\n",
      "Train Epoch: 2994 [0/8000 (0%)]\tBatch Loss: 78.733216\tLearning Rate (w_theta): 0.001000\t TIME:8100.4s\n",
      "\t\t\t\tDisc: 0.507181\t\tSym: 9.257895\t\tSpars: 68.968140\n",
      "\t TVw: 0.152818 | TVb: -1.927229 | GSw: -0.235090 | GSb: 0.064652 | TSUw: 0.464610 | TSUb: 0.035102\n",
      "\n",
      "Train Epoch: 2994 [4000/8000 (50%)]\tBatch Loss: 75.191910\tLearning Rate (w_theta): 0.001000\t TIME:8102.0s\n",
      "\t\t\t\tDisc: 0.509076\t\tSym: 8.422916\t\tSpars: 66.259918\n",
      "\t TVw: 0.152832 | TVb: -1.926988 | GSw: -0.235090 | GSb: 0.064651 | TSUw: 0.464610 | TSUb: 0.035102\n",
      "Validating epoch 2994...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 75.02512551716339\n",
      "Average validation loss: 12.903141677411384\n",
      "Training epoch 2995...\n",
      "\n",
      "Train Epoch: 2995 [0/8000 (0%)]\tBatch Loss: 73.045700\tLearning Rate (w_theta): 0.001000\t TIME:8104.5s\n",
      "\t\t\t\tDisc: 0.582666\t\tSym: 8.365447\t\tSpars: 64.097588\n",
      "\t TVw: 0.153098 | TVb: -1.926733 | GSw: -0.235090 | GSb: 0.064651 | TSUw: 0.464610 | TSUb: 0.035102\n",
      "\n",
      "Train Epoch: 2995 [4000/8000 (50%)]\tBatch Loss: 77.344867\tLearning Rate (w_theta): 0.001000\t TIME:8106.1s\n",
      "\t\t\t\tDisc: 0.661037\t\tSym: 9.030982\t\tSpars: 67.652847\n",
      "\t TVw: 0.153022 | TVb: -1.926514 | GSw: -0.235090 | GSb: 0.064651 | TSUw: 0.464609 | TSUb: 0.035102\n",
      "Validating epoch 2995...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 74.60112971489593\n",
      "Average validation loss: 12.781051832480175\n",
      "Training epoch 2996...\n",
      "\n",
      "Train Epoch: 2996 [0/8000 (0%)]\tBatch Loss: 75.225107\tLearning Rate (w_theta): 0.001000\t TIME:8109.2s\n",
      "\t\t\t\tDisc: 0.582229\t\tSym: 8.648387\t\tSpars: 65.994492\n",
      "\t TVw: 0.152562 | TVb: -1.926345 | GSw: -0.235090 | GSb: 0.064650 | TSUw: 0.464609 | TSUb: 0.035103\n",
      "\n",
      "Train Epoch: 2996 [4000/8000 (50%)]\tBatch Loss: 72.930613\tLearning Rate (w_theta): 0.001000\t TIME:8110.8s\n",
      "\t\t\t\tDisc: 0.710948\t\tSym: 7.881820\t\tSpars: 64.337845\n",
      "\t TVw: 0.152122 | TVb: -1.926179 | GSw: -0.235090 | GSb: 0.064650 | TSUw: 0.464609 | TSUb: 0.035103\n",
      "Validating epoch 2996...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 75.227929899741\n",
      "Average validation loss: 12.719184764378312\n",
      "Training epoch 2997...\n",
      "\n",
      "Train Epoch: 2997 [0/8000 (0%)]\tBatch Loss: 73.589135\tLearning Rate (w_theta): 0.001000\t TIME:8113.3s\n",
      "\t\t\t\tDisc: 0.635725\t\tSym: 8.227420\t\tSpars: 64.725990\n",
      "\t TVw: 0.151423 | TVb: -1.926090 | GSw: -0.235090 | GSb: 0.064650 | TSUw: 0.464609 | TSUb: 0.035103\n",
      "\n",
      "Train Epoch: 2997 [4000/8000 (50%)]\tBatch Loss: 75.725316\tLearning Rate (w_theta): 0.001000\t TIME:8114.9s\n",
      "\t\t\t\tDisc: 0.533711\t\tSym: 8.837585\t\tSpars: 66.354019\n",
      "\t TVw: 0.151897 | TVb: -1.925862 | GSw: -0.235091 | GSb: 0.064649 | TSUw: 0.464608 | TSUb: 0.035103\n",
      "Validating epoch 2997...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 74.45493337042932\n",
      "Average validation loss: 12.614509304515794\n",
      "Training epoch 2998...\n",
      "\n",
      "Train Epoch: 2998 [0/8000 (0%)]\tBatch Loss: 77.521406\tLearning Rate (w_theta): 0.001000\t TIME:8117.4s\n",
      "\t\t\t\tDisc: 0.558612\t\tSym: 9.355380\t\tSpars: 67.607414\n",
      "\t TVw: 0.152766 | TVb: -1.925583 | GSw: -0.235091 | GSb: 0.064649 | TSUw: 0.464608 | TSUb: 0.035104\n",
      "\n",
      "Train Epoch: 2998 [4000/8000 (50%)]\tBatch Loss: 73.847087\tLearning Rate (w_theta): 0.001000\t TIME:8119.0s\n",
      "\t\t\t\tDisc: 0.744930\t\tSym: 8.028130\t\tSpars: 65.074028\n",
      "\t TVw: 0.152606 | TVb: -1.925425 | GSw: -0.235091 | GSb: 0.064649 | TSUw: 0.464608 | TSUb: 0.035104\n",
      "Validating epoch 2998...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 75.550285031817\n",
      "Average validation loss: 12.608226769676694\n",
      "Training epoch 2999...\n",
      "\n",
      "Train Epoch: 2999 [0/8000 (0%)]\tBatch Loss: 73.170091\tLearning Rate (w_theta): 0.001000\t TIME:8121.6s\n",
      "\t\t\t\tDisc: 0.601905\t\tSym: 8.497446\t\tSpars: 64.070740\n",
      "\t TVw: 0.151745 | TVb: -1.925309 | GSw: -0.235091 | GSb: 0.064648 | TSUw: 0.464608 | TSUb: 0.035104\n",
      "\n",
      "Train Epoch: 2999 [4000/8000 (50%)]\tBatch Loss: 72.372934\tLearning Rate (w_theta): 0.001000\t TIME:8123.2s\n",
      "\t\t\t\tDisc: 0.545244\t\tSym: 8.694557\t\tSpars: 63.133133\n",
      "\t TVw: 0.151494 | TVb: -1.925093 | GSw: -0.235091 | GSb: 0.064648 | TSUw: 0.464607 | TSUb: 0.035104\n",
      "Validating epoch 2999...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 74.29829458023393\n",
      "Average validation loss: 12.531322773427808\n",
      "Training epoch 3000...\n",
      "\n",
      "Train Epoch: 3000 [0/8000 (0%)]\tBatch Loss: 79.402326\tLearning Rate (w_theta): 0.001000\t TIME:8125.7s\n",
      "\t\t\t\tDisc: 0.507119\t\tSym: 9.112659\t\tSpars: 69.782547\n",
      "\t TVw: 0.151561 | TVb: -1.924821 | GSw: -0.235091 | GSb: 0.064648 | TSUw: 0.464607 | TSUb: 0.035105\n",
      "\n",
      "Train Epoch: 3000 [4000/8000 (50%)]\tBatch Loss: 74.774615\tLearning Rate (w_theta): 0.001000\t TIME:8127.3s\n",
      "\t\t\t\tDisc: 0.628879\t\tSym: 8.736739\t\tSpars: 65.408997\n",
      "\t TVw: 0.151095 | TVb: -1.924628 | GSw: -0.235091 | GSb: 0.064647 | TSUw: 0.464607 | TSUb: 0.035105\n",
      "Validating epoch 3000...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 74.91676692411632\n",
      "Average validation loss: 12.615594546340386\n",
      "Training epoch 3001...\n",
      "\n",
      "Train Epoch: 3001 [0/8000 (0%)]\tBatch Loss: 73.122606\tLearning Rate (w_theta): 0.001000\t TIME:8130.7s\n",
      "\t\t\t\tDisc: 0.635202\t\tSym: 8.665021\t\tSpars: 63.822384\n",
      "\t TVw: 0.150801 | TVb: -1.924430 | GSw: -0.235091 | GSb: 0.064647 | TSUw: 0.464607 | TSUb: 0.035105\n",
      "\n",
      "Train Epoch: 3001 [4000/8000 (50%)]\tBatch Loss: 75.009452\tLearning Rate (w_theta): 0.001000\t TIME:8132.3s\n",
      "\t\t\t\tDisc: 0.657471\t\tSym: 9.002715\t\tSpars: 65.349266\n",
      "\t TVw: 0.150781 | TVb: -1.924194 | GSw: -0.235091 | GSb: 0.064647 | TSUw: 0.464606 | TSUb: 0.035105\n",
      "Validating epoch 3001...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 73.54739489761583\n",
      "Average validation loss: 12.551399145178507\n",
      "Training epoch 3002...\n",
      "\n",
      "Train Epoch: 3002 [0/8000 (0%)]\tBatch Loss: 71.514236\tLearning Rate (w_theta): 0.001000\t TIME:8134.8s\n",
      "\t\t\t\tDisc: 0.601515\t\tSym: 8.171041\t\tSpars: 62.741680\n",
      "\t TVw: 0.150560 | TVb: -1.923987 | GSw: -0.235092 | GSb: 0.064646 | TSUw: 0.464606 | TSUb: 0.035105\n",
      "\n",
      "Train Epoch: 3002 [4000/8000 (50%)]\tBatch Loss: 76.677155\tLearning Rate (w_theta): 0.001000\t TIME:8136.4s\n",
      "\t\t\t\tDisc: 0.498551\t\tSym: 9.123917\t\tSpars: 67.054688\n",
      "\t TVw: 0.150163 | TVb: -1.923777 | GSw: -0.235092 | GSb: 0.064646 | TSUw: 0.464606 | TSUb: 0.035106\n",
      "Validating epoch 3002...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 73.40844187470339\n",
      "Average validation loss: 12.398028496188024\n",
      "Training epoch 3003...\n",
      "\n",
      "Train Epoch: 3003 [0/8000 (0%)]\tBatch Loss: 80.139517\tLearning Rate (w_theta): 0.001000\t TIME:8138.9s\n",
      "\t\t\t\tDisc: 0.534003\t\tSym: 10.135902\t\tSpars: 69.469612\n",
      "\t TVw: 0.150078 | TVb: -1.923561 | GSw: -0.235092 | GSb: 0.064646 | TSUw: 0.464606 | TSUb: 0.035106\n",
      "\n",
      "Train Epoch: 3003 [4000/8000 (50%)]\tBatch Loss: 77.894762\tLearning Rate (w_theta): 0.001000\t TIME:8140.5s\n",
      "\t\t\t\tDisc: 0.909558\t\tSym: 8.748586\t\tSpars: 68.236618\n",
      "\t TVw: 0.149703 | TVb: -1.923421 | GSw: -0.235092 | GSb: 0.064645 | TSUw: 0.464605 | TSUb: 0.035106\n",
      "Validating epoch 3003...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 75.02276203883366\n",
      "Average validation loss: 12.298003047621624\n",
      "Training epoch 3004...\n",
      "\n",
      "Train Epoch: 3004 [0/8000 (0%)]\tBatch Loss: 77.640815\tLearning Rate (w_theta): 0.001000\t TIME:8143.0s\n",
      "\t\t\t\tDisc: 0.759914\t\tSym: 8.728457\t\tSpars: 68.152443\n",
      "\t TVw: 0.148521 | TVb: -1.923361 | GSw: -0.235092 | GSb: 0.064645 | TSUw: 0.464605 | TSUb: 0.035106\n",
      "\n",
      "Train Epoch: 3004 [4000/8000 (50%)]\tBatch Loss: 72.512223\tLearning Rate (w_theta): 0.001000\t TIME:8144.6s\n",
      "\t\t\t\tDisc: 0.535730\t\tSym: 8.670840\t\tSpars: 63.305653\n",
      "\t TVw: 0.148005 | TVb: -1.923255 | GSw: -0.235092 | GSb: 0.064645 | TSUw: 0.464605 | TSUb: 0.035107\n",
      "Validating epoch 3004...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 76.62251693476992\n",
      "Average validation loss: 12.116372597052566\n",
      "Training epoch 3005...\n",
      "\n",
      "Train Epoch: 3005 [0/8000 (0%)]\tBatch Loss: 70.413294\tLearning Rate (w_theta): 0.001000\t TIME:8147.2s\n",
      "\t\t\t\tDisc: 0.491417\t\tSym: 7.697877\t\tSpars: 62.223999\n",
      "\t TVw: 0.148285 | TVb: -1.923020 | GSw: -0.235092 | GSb: 0.064644 | TSUw: 0.464605 | TSUb: 0.035107\n",
      "\n",
      "Train Epoch: 3005 [4000/8000 (50%)]\tBatch Loss: 86.637737\tLearning Rate (w_theta): 0.001000\t TIME:8148.8s\n",
      "\t\t\t\tDisc: 0.453480\t\tSym: 10.466728\t\tSpars: 75.717529\n",
      "\t TVw: 0.147666 | TVb: -1.922890 | GSw: -0.235092 | GSb: 0.064644 | TSUw: 0.464604 | TSUb: 0.035107\n",
      "Validating epoch 3005...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 76.88712401111754\n",
      "Average validation loss: 12.118909391199919\n",
      "Training epoch 3006...\n",
      "\n",
      "Train Epoch: 3006 [0/8000 (0%)]\tBatch Loss: 74.808190\tLearning Rate (w_theta): 0.001000\t TIME:8151.3s\n",
      "\t\t\t\tDisc: 0.505659\t\tSym: 8.515819\t\tSpars: 65.786713\n",
      "\t TVw: 0.148351 | TVb: -1.922605 | GSw: -0.235093 | GSb: 0.064643 | TSUw: 0.464604 | TSUb: 0.035107\n",
      "\n",
      "Train Epoch: 3006 [4000/8000 (50%)]\tBatch Loss: 72.204038\tLearning Rate (w_theta): 0.001000\t TIME:8152.9s\n",
      "\t\t\t\tDisc: 0.531711\t\tSym: 8.323557\t\tSpars: 63.348770\n",
      "\t TVw: 0.149349 | TVb: -1.922277 | GSw: -0.235093 | GSb: 0.064643 | TSUw: 0.464604 | TSUb: 0.035108\n",
      "Validating epoch 3006...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 73.8995031448568\n",
      "Average validation loss: 12.469507716476953\n",
      "Training epoch 3007...\n",
      "\n",
      "Train Epoch: 3007 [0/8000 (0%)]\tBatch Loss: 72.786724\tLearning Rate (w_theta): 0.001000\t TIME:8155.4s\n",
      "\t\t\t\tDisc: 0.672336\t\tSym: 8.480557\t\tSpars: 63.633831\n",
      "\t TVw: 0.149674 | TVb: -1.921974 | GSw: -0.235093 | GSb: 0.064643 | TSUw: 0.464604 | TSUb: 0.035108\n",
      "\n",
      "Train Epoch: 3007 [4000/8000 (50%)]\tBatch Loss: 73.935649\tLearning Rate (w_theta): 0.001000\t TIME:8157.0s\n",
      "\t\t\t\tDisc: 0.677154\t\tSym: 8.761112\t\tSpars: 64.497383\n",
      "\t TVw: 0.148682 | TVb: -1.921786 | GSw: -0.235093 | GSb: 0.064642 | TSUw: 0.464604 | TSUb: 0.035108\n",
      "Validating epoch 3007...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 72.62433264513717\n",
      "Average validation loss: 12.298543370976766\n",
      "Training epoch 3008...\n",
      "\n",
      "Train Epoch: 3008 [0/8000 (0%)]\tBatch Loss: 71.932562\tLearning Rate (w_theta): 0.001000\t TIME:8159.5s\n",
      "\t\t\t\tDisc: 0.619889\t\tSym: 8.534780\t\tSpars: 62.777893\n",
      "\t TVw: 0.147612 | TVb: -1.921629 | GSw: -0.235093 | GSb: 0.064642 | TSUw: 0.464603 | TSUb: 0.035108\n",
      "\n",
      "Train Epoch: 3008 [4000/8000 (50%)]\tBatch Loss: 70.214639\tLearning Rate (w_theta): 0.001000\t TIME:8161.1s\n",
      "\t\t\t\tDisc: 0.598700\t\tSym: 8.164496\t\tSpars: 61.451443\n",
      "\t TVw: 0.147233 | TVb: -1.921420 | GSw: -0.235093 | GSb: 0.064642 | TSUw: 0.464603 | TSUb: 0.035109\n",
      "Validating epoch 3008...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 72.7596129573863\n",
      "Average validation loss: 12.105837539770008\n",
      "Training epoch 3009...\n",
      "\n",
      "Train Epoch: 3009 [0/8000 (0%)]\tBatch Loss: 75.099690\tLearning Rate (w_theta): 0.001000\t TIME:8163.7s\n",
      "\t\t\t\tDisc: 0.530266\t\tSym: 9.247159\t\tSpars: 65.322266\n",
      "\t TVw: 0.147301 | TVb: -1.921188 | GSw: -0.235093 | GSb: 0.064641 | TSUw: 0.464603 | TSUb: 0.035109\n",
      "\n",
      "Train Epoch: 3009 [4000/8000 (50%)]\tBatch Loss: 66.333380\tLearning Rate (w_theta): 0.001000\t TIME:8165.3s\n",
      "\t\t\t\tDisc: 0.491664\t\tSym: 7.298615\t\tSpars: 58.543102\n",
      "\t TVw: 0.147676 | TVb: -1.920956 | GSw: -0.235093 | GSb: 0.064641 | TSUw: 0.464603 | TSUb: 0.035109\n",
      "Validating epoch 3009...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 72.04159879306646\n",
      "Average validation loss: 11.99410920196711\n",
      "Training epoch 3010...\n",
      "\n",
      "Train Epoch: 3010 [0/8000 (0%)]\tBatch Loss: 78.054385\tLearning Rate (w_theta): 0.001000\t TIME:8167.8s\n",
      "\t\t\t\tDisc: 0.528410\t\tSym: 10.302060\t\tSpars: 67.223915\n",
      "\t TVw: 0.147833 | TVb: -1.920722 | GSw: -0.235094 | GSb: 0.064641 | TSUw: 0.464602 | TSUb: 0.035109\n",
      "\n",
      "Train Epoch: 3010 [4000/8000 (50%)]\tBatch Loss: 71.057931\tLearning Rate (w_theta): 0.001000\t TIME:8169.4s\n",
      "\t\t\t\tDisc: 0.644926\t\tSym: 8.378787\t\tSpars: 62.034218\n",
      "\t TVw: 0.147282 | TVb: -1.920576 | GSw: -0.235094 | GSb: 0.064640 | TSUw: 0.464602 | TSUb: 0.035109\n",
      "Validating epoch 3010...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 73.69763958941621\n",
      "Average validation loss: 11.98703899378743\n",
      "Training epoch 3011...\n",
      "\n",
      "Train Epoch: 3011 [0/8000 (0%)]\tBatch Loss: 75.612149\tLearning Rate (w_theta): 0.001000\t TIME:8173.2s\n",
      "\t\t\t\tDisc: 0.686607\t\tSym: 9.330046\t\tSpars: 65.595497\n",
      "\t TVw: 0.146734 | TVb: -1.920451 | GSw: -0.235094 | GSb: 0.064640 | TSUw: 0.464602 | TSUb: 0.035110\n",
      "\n",
      "Train Epoch: 3011 [4000/8000 (50%)]\tBatch Loss: 75.701141\tLearning Rate (w_theta): 0.001000\t TIME:8174.8s\n",
      "\t\t\t\tDisc: 0.704421\t\tSym: 9.005295\t\tSpars: 65.991425\n",
      "\t TVw: 0.147013 | TVb: -1.920240 | GSw: -0.235094 | GSb: 0.064639 | TSUw: 0.464602 | TSUb: 0.035110\n",
      "Validating epoch 3011...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 72.90582059821034\n",
      "Average validation loss: 12.057266919586958\n",
      "Training epoch 3012...\n",
      "\n",
      "Train Epoch: 3012 [0/8000 (0%)]\tBatch Loss: 74.175365\tLearning Rate (w_theta): 0.001000\t TIME:8177.4s\n",
      "\t\t\t\tDisc: 0.637130\t\tSym: 9.079915\t\tSpars: 64.458321\n",
      "\t TVw: 0.147565 | TVb: -1.919984 | GSw: -0.235094 | GSb: 0.064639 | TSUw: 0.464601 | TSUb: 0.035110\n",
      "\n",
      "Train Epoch: 3012 [4000/8000 (50%)]\tBatch Loss: 67.831457\tLearning Rate (w_theta): 0.001000\t TIME:8179.0s\n",
      "\t\t\t\tDisc: 0.543328\t\tSym: 7.675462\t\tSpars: 59.612667\n",
      "\t TVw: 0.148073 | TVb: -1.919691 | GSw: -0.235094 | GSb: 0.064639 | TSUw: 0.464601 | TSUb: 0.035110\n",
      "Validating epoch 3012...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 71.81298326611798\n",
      "Average validation loss: 12.03417045425848\n",
      "Training epoch 3013...\n",
      "\n",
      "Train Epoch: 3013 [0/8000 (0%)]\tBatch Loss: 70.318728\tLearning Rate (w_theta): 0.001000\t TIME:8181.5s\n",
      "\t\t\t\tDisc: 0.561215\t\tSym: 8.331289\t\tSpars: 61.426224\n",
      "\t TVw: 0.147694 | TVb: -1.919476 | GSw: -0.235094 | GSb: 0.064638 | TSUw: 0.464601 | TSUb: 0.035111\n",
      "\n",
      "Train Epoch: 3013 [4000/8000 (50%)]\tBatch Loss: 72.346450\tLearning Rate (w_theta): 0.001000\t TIME:8183.1s\n",
      "\t\t\t\tDisc: 0.508244\t\tSym: 9.012771\t\tSpars: 62.825436\n",
      "\t TVw: 0.146690 | TVb: -1.919322 | GSw: -0.235094 | GSb: 0.064638 | TSUw: 0.464601 | TSUb: 0.035111\n",
      "Validating epoch 3013...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 71.3791537133601\n",
      "Average validation loss: 11.901320450152733\n",
      "Training epoch 3014...\n",
      "\n",
      "Train Epoch: 3014 [0/8000 (0%)]\tBatch Loss: 73.239743\tLearning Rate (w_theta): 0.001000\t TIME:8185.6s\n",
      "\t\t\t\tDisc: 0.510157\t\tSym: 9.298113\t\tSpars: 63.431473\n",
      "\t TVw: 0.146395 | TVb: -1.919104 | GSw: -0.235094 | GSb: 0.064638 | TSUw: 0.464600 | TSUb: 0.035111\n",
      "\n",
      "Train Epoch: 3014 [4000/8000 (50%)]\tBatch Loss: 69.921755\tLearning Rate (w_theta): 0.001000\t TIME:8187.2s\n",
      "\t\t\t\tDisc: 0.555453\t\tSym: 8.548183\t\tSpars: 60.818119\n",
      "\t TVw: 0.146655 | TVb: -1.918859 | GSw: -0.235095 | GSb: 0.064637 | TSUw: 0.464600 | TSUb: 0.035111\n",
      "Validating epoch 3014...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 71.52074185723083\n",
      "Average validation loss: 12.069128936144452\n",
      "Training epoch 3015...\n",
      "\n",
      "Train Epoch: 3015 [0/8000 (0%)]\tBatch Loss: 73.290046\tLearning Rate (w_theta): 0.001000\t TIME:8189.8s\n",
      "\t\t\t\tDisc: 0.692975\t\tSym: 8.901664\t\tSpars: 63.695408\n",
      "\t TVw: 0.146798 | TVb: -1.918622 | GSw: -0.235095 | GSb: 0.064637 | TSUw: 0.464600 | TSUb: 0.035112\n",
      "\n",
      "Train Epoch: 3015 [4000/8000 (50%)]\tBatch Loss: 66.997018\tLearning Rate (w_theta): 0.001000\t TIME:8191.4s\n",
      "\t\t\t\tDisc: 0.629795\t\tSym: 7.614027\t\tSpars: 58.753197\n",
      "\t TVw: 0.146604 | TVb: -1.918428 | GSw: -0.235095 | GSb: 0.064637 | TSUw: 0.464600 | TSUb: 0.035112\n",
      "Validating epoch 3015...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 70.86495876368869\n",
      "Average validation loss: 12.017337048196094\n",
      "Training epoch 3016...\n",
      "\n",
      "Train Epoch: 3016 [0/8000 (0%)]\tBatch Loss: 68.346080\tLearning Rate (w_theta): 0.001000\t TIME:8193.9s\n",
      "\t\t\t\tDisc: 0.651104\t\tSym: 8.168757\t\tSpars: 59.526218\n",
      "\t TVw: 0.146386 | TVb: -1.918220 | GSw: -0.235095 | GSb: 0.064636 | TSUw: 0.464599 | TSUb: 0.035112\n",
      "\n",
      "Train Epoch: 3016 [4000/8000 (50%)]\tBatch Loss: 70.045186\tLearning Rate (w_theta): 0.001000\t TIME:8195.6s\n",
      "\t\t\t\tDisc: 0.626857\t\tSym: 8.517962\t\tSpars: 60.900368\n",
      "\t TVw: 0.146196 | TVb: -1.918022 | GSw: -0.235095 | GSb: 0.064636 | TSUw: 0.464599 | TSUb: 0.035112\n",
      "Validating epoch 3016...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 70.76550136572095\n",
      "Average validation loss: 11.926700548612374\n",
      "Training epoch 3017...\n",
      "\n",
      "Train Epoch: 3017 [0/8000 (0%)]\tBatch Loss: 71.758329\tLearning Rate (w_theta): 0.001000\t TIME:8198.1s\n",
      "\t\t\t\tDisc: 0.638112\t\tSym: 8.956059\t\tSpars: 62.164158\n",
      "\t TVw: 0.146151 | TVb: -1.917828 | GSw: -0.235095 | GSb: 0.064636 | TSUw: 0.464599 | TSUb: 0.035113\n",
      "\n",
      "Train Epoch: 3017 [4000/8000 (50%)]\tBatch Loss: 71.870470\tLearning Rate (w_theta): 0.001000\t TIME:8199.7s\n",
      "\t\t\t\tDisc: 0.650645\t\tSym: 8.362941\t\tSpars: 62.856884\n",
      "\t TVw: 0.145937 | TVb: -1.917641 | GSw: -0.235095 | GSb: 0.064635 | TSUw: 0.464599 | TSUb: 0.035113\n",
      "Validating epoch 3017...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 70.63406602017625\n",
      "Average validation loss: 11.776532582939522\n",
      "Training epoch 3018...\n",
      "\n",
      "Train Epoch: 3018 [0/8000 (0%)]\tBatch Loss: 68.937143\tLearning Rate (w_theta): 0.001000\t TIME:8202.2s\n",
      "\t\t\t\tDisc: 0.607534\t\tSym: 8.152206\t\tSpars: 60.177402\n",
      "\t TVw: 0.145745 | TVb: -1.917462 | GSw: -0.235095 | GSb: 0.064635 | TSUw: 0.464599 | TSUb: 0.035113\n",
      "\n",
      "Train Epoch: 3018 [4000/8000 (50%)]\tBatch Loss: 73.314073\tLearning Rate (w_theta): 0.001000\t TIME:8203.8s\n",
      "\t\t\t\tDisc: 0.501773\t\tSym: 9.286970\t\tSpars: 63.525330\n",
      "\t TVw: 0.145539 | TVb: -1.917275 | GSw: -0.235096 | GSb: 0.064634 | TSUw: 0.464598 | TSUb: 0.035113\n",
      "Validating epoch 3018...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 71.25968746856469\n",
      "Average validation loss: 11.73512603799917\n",
      "Training epoch 3019...\n",
      "\n",
      "Train Epoch: 3019 [0/8000 (0%)]\tBatch Loss: 70.411911\tLearning Rate (w_theta): 0.001000\t TIME:8206.4s\n",
      "\t\t\t\tDisc: 0.508325\t\tSym: 8.590564\t\tSpars: 61.313023\n",
      "\t TVw: 0.145710 | TVb: -1.917041 | GSw: -0.235096 | GSb: 0.064634 | TSUw: 0.464598 | TSUb: 0.035113\n",
      "\n",
      "Train Epoch: 3019 [4000/8000 (50%)]\tBatch Loss: 72.088470\tLearning Rate (w_theta): 0.001000\t TIME:8207.9s\n",
      "\t\t\t\tDisc: 0.581967\t\tSym: 9.129653\t\tSpars: 62.376850\n",
      "\t TVw: 0.146213 | TVb: -1.916747 | GSw: -0.235096 | GSb: 0.064634 | TSUw: 0.464598 | TSUb: 0.035114\n",
      "Validating epoch 3019...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 70.42020954122667\n",
      "Average validation loss: 11.950482256106909\n",
      "Training epoch 3020...\n",
      "\n",
      "Train Epoch: 3020 [0/8000 (0%)]\tBatch Loss: 72.610061\tLearning Rate (w_theta): 0.001000\t TIME:8210.5s\n",
      "\t\t\t\tDisc: 0.754041\t\tSym: 8.813983\t\tSpars: 63.042038\n",
      "\t TVw: 0.145904 | TVb: -1.916569 | GSw: -0.235096 | GSb: 0.064633 | TSUw: 0.464598 | TSUb: 0.035114\n",
      "\n",
      "Train Epoch: 3020 [4000/8000 (50%)]\tBatch Loss: 70.426182\tLearning Rate (w_theta): 0.001000\t TIME:8212.1s\n",
      "\t\t\t\tDisc: 0.666868\t\tSym: 8.530498\t\tSpars: 61.228817\n",
      "\t TVw: 0.145275 | TVb: -1.916404 | GSw: -0.235096 | GSb: 0.064633 | TSUw: 0.464597 | TSUb: 0.035114\n",
      "Validating epoch 3020...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 70.23822939724843\n",
      "Average validation loss: 11.76672224455751\n",
      "Training epoch 3021...\n",
      "\n",
      "Train Epoch: 3021 [0/8000 (0%)]\tBatch Loss: 66.737919\tLearning Rate (w_theta): 0.001000\t TIME:8215.5s\n",
      "\t\t\t\tDisc: 0.640262\t\tSym: 7.671384\t\tSpars: 58.426273\n",
      "\t TVw: 0.144967 | TVb: -1.916198 | GSw: -0.235096 | GSb: 0.064633 | TSUw: 0.464597 | TSUb: 0.035114\n",
      "\n",
      "Train Epoch: 3021 [4000/8000 (50%)]\tBatch Loss: 70.940658\tLearning Rate (w_theta): 0.001000\t TIME:8217.0s\n",
      "\t\t\t\tDisc: 0.580388\t\tSym: 9.084140\t\tSpars: 61.276131\n",
      "\t TVw: 0.144901 | TVb: -1.915965 | GSw: -0.235096 | GSb: 0.064632 | TSUw: 0.464597 | TSUb: 0.035115\n",
      "Validating epoch 3021...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 69.81331962444719\n",
      "Average validation loss: 11.75988570688553\n",
      "Training epoch 3022...\n",
      "\n",
      "Train Epoch: 3022 [0/8000 (0%)]\tBatch Loss: 72.986337\tLearning Rate (w_theta): 0.001000\t TIME:8219.6s\n",
      "\t\t\t\tDisc: 0.541080\t\tSym: 9.215857\t\tSpars: 63.229401\n",
      "\t TVw: 0.144804 | TVb: -1.915730 | GSw: -0.235096 | GSb: 0.064632 | TSUw: 0.464597 | TSUb: 0.035115\n",
      "\n",
      "Train Epoch: 3022 [4000/8000 (50%)]\tBatch Loss: 67.116437\tLearning Rate (w_theta): 0.001000\t TIME:8221.2s\n",
      "\t\t\t\tDisc: 0.558331\t\tSym: 8.050804\t\tSpars: 58.507301\n",
      "\t TVw: 0.144520 | TVb: -1.915536 | GSw: -0.235096 | GSb: 0.064632 | TSUw: 0.464596 | TSUb: 0.035115\n",
      "Validating epoch 3022...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 68.9099410204468\n",
      "Average validation loss: 11.613618183706071\n",
      "Training epoch 3023...\n",
      "\n",
      "Train Epoch: 3023 [0/8000 (0%)]\tBatch Loss: 67.534259\tLearning Rate (w_theta): 0.001000\t TIME:8223.7s\n",
      "\t\t\t\tDisc: 0.566150\t\tSym: 8.374496\t\tSpars: 58.593613\n",
      "\t TVw: 0.144572 | TVb: -1.915309 | GSw: -0.235097 | GSb: 0.064631 | TSUw: 0.464596 | TSUb: 0.035115\n",
      "\n",
      "Train Epoch: 3023 [4000/8000 (50%)]\tBatch Loss: 67.849416\tLearning Rate (w_theta): 0.001000\t TIME:8225.3s\n",
      "\t\t\t\tDisc: 0.586625\t\tSym: 8.395040\t\tSpars: 58.867752\n",
      "\t TVw: 0.144636 | TVb: -1.915091 | GSw: -0.235097 | GSb: 0.064631 | TSUw: 0.464596 | TSUb: 0.035116\n",
      "Validating epoch 3023...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 68.59503314328927\n",
      "Average validation loss: 11.595883955566071\n",
      "Training epoch 3024...\n",
      "\n",
      "Train Epoch: 3024 [0/8000 (0%)]\tBatch Loss: 68.537485\tLearning Rate (w_theta): 0.001000\t TIME:8228.0s\n",
      "\t\t\t\tDisc: 0.577865\t\tSym: 8.618296\t\tSpars: 59.341324\n",
      "\t TVw: 0.144679 | TVb: -1.914886 | GSw: -0.235097 | GSb: 0.064631 | TSUw: 0.464596 | TSUb: 0.035116\n",
      "\n",
      "Train Epoch: 3024 [4000/8000 (50%)]\tBatch Loss: 66.615349\tLearning Rate (w_theta): 0.001000\t TIME:8229.6s\n",
      "\t\t\t\tDisc: 0.609377\t\tSym: 8.156790\t\tSpars: 57.849182\n",
      "\t TVw: 0.144669 | TVb: -1.914687 | GSw: -0.235097 | GSb: 0.064630 | TSUw: 0.464595 | TSUb: 0.035116\n",
      "Validating epoch 3024...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 68.58735665872342\n",
      "Average validation loss: 11.487648830018982\n",
      "Training epoch 3025...\n",
      "\n",
      "Train Epoch: 3025 [0/8000 (0%)]\tBatch Loss: 70.279649\tLearning Rate (w_theta): 0.001000\t TIME:8232.1s\n",
      "\t\t\t\tDisc: 0.613093\t\tSym: 9.069922\t\tSpars: 60.596634\n",
      "\t TVw: 0.144400 | TVb: -1.914551 | GSw: -0.235097 | GSb: 0.064630 | TSUw: 0.464595 | TSUb: 0.035116\n",
      "\n",
      "Train Epoch: 3025 [4000/8000 (50%)]\tBatch Loss: 69.727530\tLearning Rate (w_theta): 0.001000\t TIME:8233.7s\n",
      "\t\t\t\tDisc: 0.521995\t\tSym: 8.761893\t\tSpars: 60.443642\n",
      "\t TVw: 0.144420 | TVb: -1.914347 | GSw: -0.235097 | GSb: 0.064629 | TSUw: 0.464595 | TSUb: 0.035117\n",
      "Validating epoch 3025...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 68.89132374504734\n",
      "Average validation loss: 11.542444894146179\n",
      "Training epoch 3026...\n",
      "\n",
      "Train Epoch: 3026 [0/8000 (0%)]\tBatch Loss: 65.448161\tLearning Rate (w_theta): 0.001000\t TIME:8236.3s\n",
      "\t\t\t\tDisc: 0.568682\t\tSym: 7.644258\t\tSpars: 57.235222\n",
      "\t TVw: 0.144399 | TVb: -1.914125 | GSw: -0.235097 | GSb: 0.064629 | TSUw: 0.464595 | TSUb: 0.035117\n",
      "\n",
      "Train Epoch: 3026 [4000/8000 (50%)]\tBatch Loss: 74.200285\tLearning Rate (w_theta): 0.001000\t TIME:8237.8s\n",
      "\t\t\t\tDisc: 0.739518\t\tSym: 9.303503\t\tSpars: 64.157265\n",
      "\t TVw: 0.144209 | TVb: -1.913947 | GSw: -0.235097 | GSb: 0.064629 | TSUw: 0.464594 | TSUb: 0.035117\n",
      "Validating epoch 3026...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 69.22084304930317\n",
      "Average validation loss: 11.617004847413785\n",
      "Training epoch 3027...\n",
      "\n",
      "Train Epoch: 3027 [0/8000 (0%)]\tBatch Loss: 68.727526\tLearning Rate (w_theta): 0.001000\t TIME:8240.4s\n",
      "\t\t\t\tDisc: 0.730570\t\tSym: 8.656551\t\tSpars: 59.340405\n",
      "\t TVw: 0.143561 | TVb: -1.913827 | GSw: -0.235098 | GSb: 0.064628 | TSUw: 0.464594 | TSUb: 0.035117\n",
      "\n",
      "Train Epoch: 3027 [4000/8000 (50%)]\tBatch Loss: 67.771241\tLearning Rate (w_theta): 0.001000\t TIME:8242.0s\n",
      "\t\t\t\tDisc: 0.605655\t\tSym: 8.575120\t\tSpars: 58.590466\n",
      "\t TVw: 0.143059 | TVb: -1.913623 | GSw: -0.235098 | GSb: 0.064628 | TSUw: 0.464594 | TSUb: 0.035117\n",
      "Validating epoch 3027...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 69.20273623425274\n",
      "Average validation loss: 11.300112957645656\n",
      "Training epoch 3028...\n",
      "\n",
      "Train Epoch: 3028 [0/8000 (0%)]\tBatch Loss: 65.213027\tLearning Rate (w_theta): 0.001000\t TIME:8244.5s\n",
      "\t\t\t\tDisc: 0.540806\t\tSym: 7.706745\t\tSpars: 56.965477\n",
      "\t TVw: 0.143339 | TVb: -1.913324 | GSw: -0.235098 | GSb: 0.064628 | TSUw: 0.464594 | TSUb: 0.035118\n",
      "\n",
      "Train Epoch: 3028 [4000/8000 (50%)]\tBatch Loss: 64.120396\tLearning Rate (w_theta): 0.001000\t TIME:8246.2s\n",
      "\t\t\t\tDisc: 0.632465\t\tSym: 7.960603\t\tSpars: 55.527328\n",
      "\t TVw: 0.143093 | TVb: -1.913035 | GSw: -0.235098 | GSb: 0.064627 | TSUw: 0.464594 | TSUb: 0.035118\n",
      "Validating epoch 3028...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 68.23967792245962\n",
      "Average validation loss: 11.427935472824023\n",
      "Training epoch 3029...\n",
      "\n",
      "Train Epoch: 3029 [0/8000 (0%)]\tBatch Loss: 65.999083\tLearning Rate (w_theta): 0.001000\t TIME:8249.3s\n",
      "\t\t\t\tDisc: 0.579447\t\tSym: 8.386223\t\tSpars: 57.033413\n",
      "\t TVw: 0.142244 | TVb: -1.912851 | GSw: -0.235098 | GSb: 0.064627 | TSUw: 0.464593 | TSUb: 0.035118\n",
      "\n",
      "Train Epoch: 3029 [4000/8000 (50%)]\tBatch Loss: 65.270172\tLearning Rate (w_theta): 0.001000\t TIME:8250.9s\n",
      "\t\t\t\tDisc: 0.484929\t\tSym: 8.091243\t\tSpars: 56.694000\n",
      "\t TVw: 0.141386 | TVb: -1.912707 | GSw: -0.235098 | GSb: 0.064627 | TSUw: 0.464593 | TSUb: 0.035118\n",
      "Validating epoch 3029...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 67.7914083880893\n",
      "Average validation loss: 11.29441380906948\n",
      "Training epoch 3030...\n",
      "\n",
      "Train Epoch: 3030 [0/8000 (0%)]\tBatch Loss: 64.821348\tLearning Rate (w_theta): 0.001000\t TIME:8253.5s\n",
      "\t\t\t\tDisc: 0.510661\t\tSym: 7.867217\t\tSpars: 56.443470\n",
      "\t TVw: 0.141080 | TVb: -1.912498 | GSw: -0.235098 | GSb: 0.064626 | TSUw: 0.464593 | TSUb: 0.035119\n",
      "\n",
      "Train Epoch: 3030 [4000/8000 (50%)]\tBatch Loss: 65.143754\tLearning Rate (w_theta): 0.001000\t TIME:8255.0s\n",
      "\t\t\t\tDisc: 0.568401\t\tSym: 8.109831\t\tSpars: 56.465523\n",
      "\t TVw: 0.141537 | TVb: -1.912235 | GSw: -0.235098 | GSb: 0.064626 | TSUw: 0.464593 | TSUb: 0.035119\n",
      "Validating epoch 3030...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 67.1243907978083\n",
      "Average validation loss: 11.316299600828811\n",
      "Training epoch 3031...\n",
      "\n",
      "Train Epoch: 3031 [0/8000 (0%)]\tBatch Loss: 65.633936\tLearning Rate (w_theta): 0.001000\t TIME:8258.4s\n",
      "\t\t\t\tDisc: 0.598825\t\tSym: 8.397748\t\tSpars: 56.637363\n",
      "\t TVw: 0.141890 | TVb: -1.911991 | GSw: -0.235099 | GSb: 0.064626 | TSUw: 0.464592 | TSUb: 0.035119\n",
      "\n",
      "Train Epoch: 3031 [4000/8000 (50%)]\tBatch Loss: 69.222529\tLearning Rate (w_theta): 0.001000\t TIME:8260.0s\n",
      "\t\t\t\tDisc: 0.596340\t\tSym: 8.540819\t\tSpars: 60.085369\n",
      "\t TVw: 0.141781 | TVb: -1.911804 | GSw: -0.235099 | GSb: 0.064625 | TSUw: 0.464592 | TSUb: 0.035119\n",
      "Validating epoch 3031...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 66.85902043763393\n",
      "Average validation loss: 11.283850164569445\n",
      "Training epoch 3032...\n",
      "\n",
      "Train Epoch: 3032 [0/8000 (0%)]\tBatch Loss: 70.858442\tLearning Rate (w_theta): 0.001000\t TIME:8262.5s\n",
      "\t\t\t\tDisc: 0.608234\t\tSym: 9.682405\t\tSpars: 60.567802\n",
      "\t TVw: 0.141616 | TVb: -1.911628 | GSw: -0.235099 | GSb: 0.064625 | TSUw: 0.464592 | TSUb: 0.035120\n",
      "\n",
      "Train Epoch: 3032 [4000/8000 (50%)]\tBatch Loss: 68.027206\tLearning Rate (w_theta): 0.001000\t TIME:8264.2s\n",
      "\t\t\t\tDisc: 0.518089\t\tSym: 8.739902\t\tSpars: 58.769215\n",
      "\t TVw: 0.141160 | TVb: -1.911453 | GSw: -0.235099 | GSb: 0.064624 | TSUw: 0.464592 | TSUb: 0.035120\n",
      "Validating epoch 3032...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 68.1634550921571\n",
      "Average validation loss: 11.133543144840255\n",
      "Training epoch 3033...\n",
      "\n",
      "Train Epoch: 3033 [0/8000 (0%)]\tBatch Loss: 66.414893\tLearning Rate (w_theta): 0.001000\t TIME:8266.7s\n",
      "\t\t\t\tDisc: 0.508493\t\tSym: 8.576181\t\tSpars: 57.330219\n",
      "\t TVw: 0.140657 | TVb: -1.911328 | GSw: -0.235099 | GSb: 0.064624 | TSUw: 0.464591 | TSUb: 0.035120\n",
      "\n",
      "Train Epoch: 3033 [4000/8000 (50%)]\tBatch Loss: 64.784776\tLearning Rate (w_theta): 0.001000\t TIME:8268.3s\n",
      "\t\t\t\tDisc: 0.608967\t\tSym: 7.741148\t\tSpars: 56.434662\n",
      "\t TVw: 0.140977 | TVb: -1.911103 | GSw: -0.235099 | GSb: 0.064624 | TSUw: 0.464591 | TSUb: 0.035120\n",
      "Validating epoch 3033...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 67.43647788592286\n",
      "Average validation loss: 11.35427616724847\n",
      "Training epoch 3034...\n",
      "\n",
      "Train Epoch: 3034 [0/8000 (0%)]\tBatch Loss: 68.047637\tLearning Rate (w_theta): 0.001000\t TIME:8270.8s\n",
      "\t\t\t\tDisc: 0.688870\t\tSym: 8.645160\t\tSpars: 58.713608\n",
      "\t TVw: 0.141672 | TVb: -1.910789 | GSw: -0.235099 | GSb: 0.064623 | TSUw: 0.464591 | TSUb: 0.035120\n",
      "\n",
      "Train Epoch: 3034 [4000/8000 (50%)]\tBatch Loss: 65.966100\tLearning Rate (w_theta): 0.001000\t TIME:8272.4s\n",
      "\t\t\t\tDisc: 0.611449\t\tSym: 8.442209\t\tSpars: 56.912441\n",
      "\t TVw: 0.141391 | TVb: -1.910586 | GSw: -0.235099 | GSb: 0.064623 | TSUw: 0.464591 | TSUb: 0.035121\n",
      "Validating epoch 3034...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 66.68451040028447\n",
      "Average validation loss: 11.1711556803552\n",
      "Training epoch 3035...\n",
      "\n",
      "Train Epoch: 3035 [0/8000 (0%)]\tBatch Loss: 71.365831\tLearning Rate (w_theta): 0.001000\t TIME:8275.1s\n",
      "\t\t\t\tDisc: 0.564526\t\tSym: 9.697096\t\tSpars: 61.104210\n",
      "\t TVw: 0.140786 | TVb: -1.910364 | GSw: -0.235099 | GSb: 0.064623 | TSUw: 0.464590 | TSUb: 0.035121\n",
      "\n",
      "Train Epoch: 3035 [4000/8000 (50%)]\tBatch Loss: 68.700671\tLearning Rate (w_theta): 0.001000\t TIME:8276.7s\n",
      "\t\t\t\tDisc: 0.623445\t\tSym: 8.952111\t\tSpars: 59.125114\n",
      "\t TVw: 0.140052 | TVb: -1.910175 | GSw: -0.235100 | GSb: 0.064622 | TSUw: 0.464590 | TSUb: 0.035121\n",
      "Validating epoch 3035...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 66.54367832196172\n",
      "Average validation loss: 11.242280534436249\n",
      "Training epoch 3036...\n",
      "\n",
      "Train Epoch: 3036 [0/8000 (0%)]\tBatch Loss: 64.021394\tLearning Rate (w_theta): 0.001000\t TIME:8279.3s\n",
      "\t\t\t\tDisc: 0.554049\t\tSym: 7.802645\t\tSpars: 55.664700\n",
      "\t TVw: 0.139407 | TVb: -1.910010 | GSw: -0.235100 | GSb: 0.064622 | TSUw: 0.464590 | TSUb: 0.035121\n",
      "\n",
      "Train Epoch: 3036 [4000/8000 (50%)]\tBatch Loss: 64.943488\tLearning Rate (w_theta): 0.001000\t TIME:8280.9s\n",
      "\t\t\t\tDisc: 0.488921\t\tSym: 7.836864\t\tSpars: 56.617702\n",
      "\t TVw: 0.139184 | TVb: -1.909805 | GSw: -0.235100 | GSb: 0.064622 | TSUw: 0.464590 | TSUb: 0.035122\n",
      "Validating epoch 3036...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 66.63246908559442\n",
      "Average validation loss: 11.148474807348244\n",
      "Training epoch 3037...\n",
      "\n",
      "Train Epoch: 3037 [0/8000 (0%)]\tBatch Loss: 65.951774\tLearning Rate (w_theta): 0.001000\t TIME:8283.4s\n",
      "\t\t\t\tDisc: 0.529652\t\tSym: 8.443740\t\tSpars: 56.978382\n",
      "\t TVw: 0.139345 | TVb: -1.909570 | GSw: -0.235100 | GSb: 0.064621 | TSUw: 0.464589 | TSUb: 0.035122\n",
      "\n",
      "Train Epoch: 3037 [4000/8000 (50%)]\tBatch Loss: 63.367665\tLearning Rate (w_theta): 0.001000\t TIME:8285.0s\n",
      "\t\t\t\tDisc: 0.583102\t\tSym: 8.170610\t\tSpars: 54.613953\n",
      "\t TVw: 0.139572 | TVb: -1.909329 | GSw: -0.235100 | GSb: 0.064621 | TSUw: 0.464589 | TSUb: 0.035122\n",
      "Validating epoch 3037...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 65.80454884326896\n",
      "Average validation loss: 11.07189597441134\n",
      "Training epoch 3038...\n",
      "\n",
      "Train Epoch: 3038 [0/8000 (0%)]\tBatch Loss: 64.148916\tLearning Rate (w_theta): 0.001000\t TIME:8287.5s\n",
      "\t\t\t\tDisc: 0.595179\t\tSym: 7.929180\t\tSpars: 55.624557\n",
      "\t TVw: 0.139513 | TVb: -1.909148 | GSw: -0.235100 | GSb: 0.064621 | TSUw: 0.464589 | TSUb: 0.035122\n",
      "\n",
      "Train Epoch: 3038 [4000/8000 (50%)]\tBatch Loss: 64.360125\tLearning Rate (w_theta): 0.001000\t TIME:8289.2s\n",
      "\t\t\t\tDisc: 0.542891\t\tSym: 8.326263\t\tSpars: 55.490971\n",
      "\t TVw: 0.139337 | TVb: -1.908952 | GSw: -0.235100 | GSb: 0.064620 | TSUw: 0.464589 | TSUb: 0.035123\n",
      "Validating epoch 3038...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 65.61984394019296\n",
      "Average validation loss: 11.053738401959382\n",
      "Training epoch 3039...\n",
      "\n",
      "Train Epoch: 3039 [0/8000 (0%)]\tBatch Loss: 65.863188\tLearning Rate (w_theta): 0.001000\t TIME:8291.8s\n",
      "\t\t\t\tDisc: 0.557254\t\tSym: 8.669959\t\tSpars: 56.635975\n",
      "\t TVw: 0.139232 | TVb: -1.908772 | GSw: -0.235100 | GSb: 0.064620 | TSUw: 0.464589 | TSUb: 0.035123\n",
      "\n",
      "Train Epoch: 3039 [4000/8000 (50%)]\tBatch Loss: 70.832753\tLearning Rate (w_theta): 0.001000\t TIME:8293.4s\n",
      "\t\t\t\tDisc: 0.492151\t\tSym: 9.556052\t\tSpars: 60.784550\n",
      "\t TVw: 0.139182 | TVb: -1.908544 | GSw: -0.235101 | GSb: 0.064619 | TSUw: 0.464588 | TSUb: 0.035123\n",
      "Validating epoch 3039...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 66.69356200273492\n",
      "Average validation loss: 11.010754358214845\n",
      "Training epoch 3040...\n",
      "\n",
      "Train Epoch: 3040 [0/8000 (0%)]\tBatch Loss: 64.141081\tLearning Rate (w_theta): 0.001000\t TIME:8295.9s\n",
      "\t\t\t\tDisc: 0.623561\t\tSym: 7.970169\t\tSpars: 55.547352\n",
      "\t TVw: 0.138727 | TVb: -1.908405 | GSw: -0.235101 | GSb: 0.064619 | TSUw: 0.464588 | TSUb: 0.035123\n",
      "\n",
      "Train Epoch: 3040 [4000/8000 (50%)]\tBatch Loss: 72.810518\tLearning Rate (w_theta): 0.001000\t TIME:8297.5s\n",
      "\t\t\t\tDisc: 0.656290\t\tSym: 10.100993\t\tSpars: 62.053234\n",
      "\t TVw: 0.138547 | TVb: -1.908253 | GSw: -0.235101 | GSb: 0.064619 | TSUw: 0.464588 | TSUb: 0.035123\n",
      "Validating epoch 3040...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 66.55152363169245\n",
      "Average validation loss: 10.783737063339556\n",
      "Training epoch 3041...\n",
      "\n",
      "Train Epoch: 3041 [0/8000 (0%)]\tBatch Loss: 66.912433\tLearning Rate (w_theta): 0.001000\t TIME:8300.7s\n",
      "\t\t\t\tDisc: 0.528317\t\tSym: 8.733920\t\tSpars: 57.650196\n",
      "\t TVw: 0.138864 | TVb: -1.907976 | GSw: -0.235101 | GSb: 0.064618 | TSUw: 0.464588 | TSUb: 0.035124\n",
      "\n",
      "Train Epoch: 3041 [4000/8000 (50%)]\tBatch Loss: 69.238214\tLearning Rate (w_theta): 0.001000\t TIME:8302.3s\n",
      "\t\t\t\tDisc: 0.515925\t\tSym: 9.275554\t\tSpars: 59.446735\n",
      "\t TVw: 0.138820 | TVb: -1.907729 | GSw: -0.235101 | GSb: 0.064618 | TSUw: 0.464587 | TSUb: 0.035124\n",
      "Validating epoch 3041...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 65.39770055947699\n",
      "Average validation loss: 10.812655324057761\n",
      "Training epoch 3042...\n",
      "\n",
      "Train Epoch: 3042 [0/8000 (0%)]\tBatch Loss: 67.184348\tLearning Rate (w_theta): 0.001000\t TIME:8304.8s\n",
      "\t\t\t\tDisc: 0.532153\t\tSym: 8.914177\t\tSpars: 57.738018\n",
      "\t TVw: 0.138581 | TVb: -1.907462 | GSw: -0.235101 | GSb: 0.064618 | TSUw: 0.464587 | TSUb: 0.035124\n",
      "\n",
      "Train Epoch: 3042 [4000/8000 (50%)]\tBatch Loss: 63.094784\tLearning Rate (w_theta): 0.001000\t TIME:8306.5s\n",
      "\t\t\t\tDisc: 0.537642\t\tSym: 8.185488\t\tSpars: 54.371655\n",
      "\t TVw: 0.138104 | TVb: -1.907247 | GSw: -0.235101 | GSb: 0.064617 | TSUw: 0.464587 | TSUb: 0.035124\n",
      "Validating epoch 3042...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 66.19409131718317\n",
      "Average validation loss: 11.468928795420618\n",
      "Training epoch 3043...\n",
      "\n",
      "Train Epoch: 3043 [0/8000 (0%)]\tBatch Loss: 80.366874\tLearning Rate (w_theta): 0.001000\t TIME:8309.0s\n",
      "\t\t\t\tDisc: 1.156547\t\tSym: 10.372764\t\tSpars: 68.837563\n",
      "\t TVw: 0.136775 | TVb: -1.907161 | GSw: -0.235101 | GSb: 0.064617 | TSUw: 0.464587 | TSUb: 0.035125\n",
      "\n",
      "Train Epoch: 3043 [4000/8000 (50%)]\tBatch Loss: 66.147097\tLearning Rate (w_theta): 0.001000\t TIME:8310.6s\n",
      "\t\t\t\tDisc: 0.622167\t\tSym: 8.440011\t\tSpars: 57.084919\n",
      "\t TVw: 0.135237 | TVb: -1.907085 | GSw: -0.235101 | GSb: 0.064617 | TSUw: 0.464586 | TSUb: 0.035125\n",
      "Validating epoch 3043...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 69.91115995563875\n",
      "Average validation loss: 10.6560914903116\n",
      "Training epoch 3044...\n",
      "\n",
      "Train Epoch: 3044 [0/8000 (0%)]\tBatch Loss: 63.392245\tLearning Rate (w_theta): 0.001000\t TIME:8313.7s\n",
      "\t\t\t\tDisc: 0.520658\t\tSym: 8.170419\t\tSpars: 54.701168\n",
      "\t TVw: 0.135611 | TVb: -1.906843 | GSw: -0.235102 | GSb: 0.064616 | TSUw: 0.464586 | TSUb: 0.035125\n",
      "\n",
      "Train Epoch: 3044 [4000/8000 (50%)]\tBatch Loss: 68.327198\tLearning Rate (w_theta): 0.001000\t TIME:8315.3s\n",
      "\t\t\t\tDisc: 0.676891\t\tSym: 9.041954\t\tSpars: 58.608353\n",
      "\t TVw: 0.136774 | TVb: -1.906471 | GSw: -0.235102 | GSb: 0.064616 | TSUw: 0.464586 | TSUb: 0.035125\n",
      "Validating epoch 3044...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 66.12347982650172\n",
      "Average validation loss: 10.938990897571056\n",
      "Training epoch 3045...\n",
      "\n",
      "Train Epoch: 3045 [0/8000 (0%)]\tBatch Loss: 65.797397\tLearning Rate (w_theta): 0.001000\t TIME:8317.8s\n",
      "\t\t\t\tDisc: 0.609952\t\tSym: 8.606352\t\tSpars: 56.581093\n",
      "\t TVw: 0.137051 | TVb: -1.906166 | GSw: -0.235102 | GSb: 0.064615 | TSUw: 0.464586 | TSUb: 0.035126\n",
      "\n",
      "Train Epoch: 3045 [4000/8000 (50%)]\tBatch Loss: 69.423326\tLearning Rate (w_theta): 0.001000\t TIME:8319.4s\n",
      "\t\t\t\tDisc: 0.465691\t\tSym: 9.369298\t\tSpars: 59.588337\n",
      "\t TVw: 0.135837 | TVb: -1.905983 | GSw: -0.235102 | GSb: 0.064615 | TSUw: 0.464585 | TSUb: 0.035126\n",
      "Validating epoch 3045...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 67.14918944105452\n",
      "Average validation loss: 10.760451661966806\n",
      "Training epoch 3046...\n",
      "\n",
      "Train Epoch: 3046 [0/8000 (0%)]\tBatch Loss: 68.912474\tLearning Rate (w_theta): 0.001000\t TIME:8322.0s\n",
      "\t\t\t\tDisc: 0.488866\t\tSym: 8.780962\t\tSpars: 59.642647\n",
      "\t TVw: 0.133589 | TVb: -1.905885 | GSw: -0.235102 | GSb: 0.064615 | TSUw: 0.464585 | TSUb: 0.035126\n",
      "\n",
      "Train Epoch: 3046 [4000/8000 (50%)]\tBatch Loss: 67.411297\tLearning Rate (w_theta): 0.001000\t TIME:8323.6s\n",
      "\t\t\t\tDisc: 0.555485\t\tSym: 8.421158\t\tSpars: 58.434654\n",
      "\t TVw: 0.131877 | TVb: -1.905743 | GSw: -0.235102 | GSb: 0.064614 | TSUw: 0.464585 | TSUb: 0.035126\n",
      "Validating epoch 3046...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 70.38152354818865\n",
      "Average validation loss: 10.590106587933601\n",
      "Training epoch 3047...\n",
      "\n",
      "Train Epoch: 3047 [0/8000 (0%)]\tBatch Loss: 65.086015\tLearning Rate (w_theta): 0.001000\t TIME:8326.1s\n",
      "\t\t\t\tDisc: 0.535178\t\tSym: 8.323713\t\tSpars: 56.227123\n",
      "\t TVw: 0.131578 | TVb: -1.905472 | GSw: -0.235102 | GSb: 0.064614 | TSUw: 0.464585 | TSUb: 0.035127\n",
      "\n",
      "Train Epoch: 3047 [4000/8000 (50%)]\tBatch Loss: 69.322286\tLearning Rate (w_theta): 0.001000\t TIME:8327.8s\n",
      "\t\t\t\tDisc: 0.573068\t\tSym: 9.077138\t\tSpars: 59.672081\n",
      "\t TVw: 0.131397 | TVb: -1.905231 | GSw: -0.235102 | GSb: 0.064613 | TSUw: 0.464584 | TSUb: 0.035127\n",
      "Validating epoch 3047...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 68.09949423954303\n",
      "Average validation loss: 11.095024056744553\n",
      "Training epoch 3048...\n",
      "\n",
      "Train Epoch: 3048 [0/8000 (0%)]\tBatch Loss: 71.136677\tLearning Rate (w_theta): 0.001000\t TIME:8330.3s\n",
      "\t\t\t\tDisc: 0.833527\t\tSym: 9.455276\t\tSpars: 60.847874\n",
      "\t TVw: 0.131578 | TVb: -1.904982 | GSw: -0.235103 | GSb: 0.064613 | TSUw: 0.464584 | TSUb: 0.035127\n",
      "\n",
      "Train Epoch: 3048 [4000/8000 (50%)]\tBatch Loss: 64.524953\tLearning Rate (w_theta): 0.001000\t TIME:8332.0s\n",
      "\t\t\t\tDisc: 0.538510\t\tSym: 8.239304\t\tSpars: 55.747139\n",
      "\t TVw: 0.131636 | TVb: -1.904719 | GSw: -0.235103 | GSb: 0.064613 | TSUw: 0.464584 | TSUb: 0.035128\n",
      "Validating epoch 3048...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 66.70797104762673\n",
      "Average validation loss: 11.535463056126394\n",
      "Training epoch 3049...\n",
      "\n",
      "Train Epoch: 3049 [0/8000 (0%)]\tBatch Loss: 73.052540\tLearning Rate (w_theta): 0.001000\t TIME:8334.5s\n",
      "\t\t\t\tDisc: 1.128555\t\tSym: 9.218216\t\tSpars: 62.705769\n",
      "\t TVw: 0.131308 | TVb: -1.904498 | GSw: -0.235103 | GSb: 0.064612 | TSUw: 0.464584 | TSUb: 0.035128\n",
      "\n",
      "Train Epoch: 3049 [4000/8000 (50%)]\tBatch Loss: 84.433473\tLearning Rate (w_theta): 0.001000\t TIME:8336.1s\n",
      "\t\t\t\tDisc: 1.258314\t\tSym: 11.744403\t\tSpars: 71.430756\n",
      "\t TVw: 0.129732 | TVb: -1.904332 | GSw: -0.235103 | GSb: 0.064612 | TSUw: 0.464583 | TSUb: 0.035128\n",
      "Validating epoch 3049...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 74.36339154930533\n",
      "Average validation loss: 10.553126801203396\n",
      "Training epoch 3050...\n",
      "\n",
      "Train Epoch: 3050 [0/8000 (0%)]\tBatch Loss: 68.131781\tLearning Rate (w_theta): 0.001000\t TIME:8338.8s\n",
      "\t\t\t\tDisc: 0.686935\t\tSym: 8.683608\t\tSpars: 58.761238\n",
      "\t TVw: 0.128725 | TVb: -1.904117 | GSw: -0.235103 | GSb: 0.064611 | TSUw: 0.464583 | TSUb: 0.035128\n",
      "\n",
      "Train Epoch: 3050 [4000/8000 (50%)]\tBatch Loss: 70.598981\tLearning Rate (w_theta): 0.001000\t TIME:8340.4s\n",
      "\t\t\t\tDisc: 0.594353\t\tSym: 9.533875\t\tSpars: 60.470753\n",
      "\t TVw: 0.128402 | TVb: -1.903916 | GSw: -0.235103 | GSb: 0.064611 | TSUw: 0.464583 | TSUb: 0.035129\n",
      "Validating epoch 3050...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 69.80632094148253\n",
      "Average validation loss: 10.251391840381885\n",
      "Training epoch 3051...\n",
      "\n",
      "Train Epoch: 3051 [0/8000 (0%)]\tBatch Loss: 67.431677\tLearning Rate (w_theta): 0.001000\t TIME:8343.5s\n",
      "\t\t\t\tDisc: 0.522414\t\tSym: 9.009585\t\tSpars: 57.899677\n",
      "\t TVw: 0.129678 | TVb: -1.903523 | GSw: -0.235103 | GSb: 0.064610 | TSUw: 0.464582 | TSUb: 0.035129\n",
      "\n",
      "Train Epoch: 3051 [4000/8000 (50%)]\tBatch Loss: 64.566025\tLearning Rate (w_theta): 0.001000\t TIME:8345.1s\n",
      "\t\t\t\tDisc: 0.454313\t\tSym: 8.512236\t\tSpars: 55.599476\n",
      "\t TVw: 0.130432 | TVb: -1.903235 | GSw: -0.235104 | GSb: 0.064610 | TSUw: 0.464582 | TSUb: 0.035129\n",
      "Validating epoch 3051...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 68.06540819143935\n",
      "Average validation loss: 9.980388658604028\n",
      "Training epoch 3052...\n",
      "\n",
      "Train Epoch: 3052 [0/8000 (0%)]\tBatch Loss: 64.606214\tLearning Rate (w_theta): 0.001000\t TIME:8347.7s\n",
      "\t\t\t\tDisc: 0.480659\t\tSym: 8.600339\t\tSpars: 55.525215\n",
      "\t TVw: 0.130330 | TVb: -1.903049 | GSw: -0.235104 | GSb: 0.064609 | TSUw: 0.464581 | TSUb: 0.035130\n",
      "\n",
      "Train Epoch: 3052 [4000/8000 (50%)]\tBatch Loss: 62.823758\tLearning Rate (w_theta): 0.001000\t TIME:8349.3s\n",
      "\t\t\t\tDisc: 0.427576\t\tSym: 8.345389\t\tSpars: 54.050793\n",
      "\t TVw: 0.130528 | TVb: -1.902785 | GSw: -0.235104 | GSb: 0.064609 | TSUw: 0.464581 | TSUb: 0.035130\n",
      "Validating epoch 3052...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 64.82921352081\n",
      "Average validation loss: 9.891395900662882\n",
      "Training epoch 3053...\n",
      "\n",
      "Train Epoch: 3053 [0/8000 (0%)]\tBatch Loss: 64.290600\tLearning Rate (w_theta): 0.001000\t TIME:8351.8s\n",
      "\t\t\t\tDisc: 0.466824\t\tSym: 8.548134\t\tSpars: 55.275642\n",
      "\t TVw: 0.130917 | TVb: -1.902469 | GSw: -0.235104 | GSb: 0.064609 | TSUw: 0.464581 | TSUb: 0.035130\n",
      "\n",
      "Train Epoch: 3053 [4000/8000 (50%)]\tBatch Loss: 69.741619\tLearning Rate (w_theta): 0.001000\t TIME:8353.3s\n",
      "\t\t\t\tDisc: 0.486134\t\tSym: 9.841236\t\tSpars: 59.414249\n",
      "\t TVw: 0.131115 | TVb: -1.902190 | GSw: -0.235104 | GSb: 0.064608 | TSUw: 0.464581 | TSUb: 0.035131\n",
      "Validating epoch 3053...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 65.76579095057645\n",
      "Average validation loss: 9.943470983556267\n",
      "Training epoch 3054...\n",
      "\n",
      "Train Epoch: 3054 [0/8000 (0%)]\tBatch Loss: 59.947371\tLearning Rate (w_theta): 0.001000\t TIME:8355.9s\n",
      "\t\t\t\tDisc: 0.442905\t\tSym: 8.008258\t\tSpars: 51.496208\n",
      "\t TVw: 0.130835 | TVb: -1.902050 | GSw: -0.235104 | GSb: 0.064608 | TSUw: 0.464580 | TSUb: 0.035131\n",
      "\n",
      "Train Epoch: 3054 [4000/8000 (50%)]\tBatch Loss: 66.889186\tLearning Rate (w_theta): 0.001000\t TIME:8357.5s\n",
      "\t\t\t\tDisc: 0.453541\t\tSym: 8.986579\t\tSpars: 57.449066\n",
      "\t TVw: 0.131582 | TVb: -1.901763 | GSw: -0.235104 | GSb: 0.064608 | TSUw: 0.464580 | TSUb: 0.035131\n",
      "Validating epoch 3054...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 64.47336525546177\n",
      "Average validation loss: 10.17175335006542\n",
      "Training epoch 3055...\n",
      "\n",
      "Train Epoch: 3055 [0/8000 (0%)]\tBatch Loss: 72.017027\tLearning Rate (w_theta): 0.001000\t TIME:8360.0s\n",
      "\t\t\t\tDisc: 0.495754\t\tSym: 9.864599\t\tSpars: 61.656673\n",
      "\t TVw: 0.132151 | TVb: -1.901523 | GSw: -0.235104 | GSb: 0.064607 | TSUw: 0.464580 | TSUb: 0.035131\n",
      "\n",
      "Train Epoch: 3055 [4000/8000 (50%)]\tBatch Loss: 61.583901\tLearning Rate (w_theta): 0.001000\t TIME:8361.6s\n",
      "\t\t\t\tDisc: 0.498439\t\tSym: 8.281194\t\tSpars: 52.804268\n",
      "\t TVw: 0.132485 | TVb: -1.901246 | GSw: -0.235105 | GSb: 0.064607 | TSUw: 0.464580 | TSUb: 0.035132\n",
      "Validating epoch 3055...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 64.6695036026732\n",
      "Average validation loss: 10.129074300629803\n",
      "Training epoch 3056...\n",
      "\n",
      "Train Epoch: 3056 [0/8000 (0%)]\tBatch Loss: 62.962545\tLearning Rate (w_theta): 0.001000\t TIME:8364.2s\n",
      "\t\t\t\tDisc: 0.570141\t\tSym: 8.309621\t\tSpars: 54.082783\n",
      "\t TVw: 0.132748 | TVb: -1.900950 | GSw: -0.235105 | GSb: 0.064606 | TSUw: 0.464579 | TSUb: 0.035132\n",
      "\n",
      "Train Epoch: 3056 [4000/8000 (50%)]\tBatch Loss: 63.751352\tLearning Rate (w_theta): 0.001000\t TIME:8365.8s\n",
      "\t\t\t\tDisc: 0.644637\t\tSym: 8.925159\t\tSpars: 54.181557\n",
      "\t TVw: 0.132531 | TVb: -1.900702 | GSw: -0.235105 | GSb: 0.064606 | TSUw: 0.464579 | TSUb: 0.035132\n",
      "Validating epoch 3056...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 63.04907558225064\n",
      "Average validation loss: 10.468980871216397\n",
      "Training epoch 3057...\n",
      "\n",
      "Train Epoch: 3057 [0/8000 (0%)]\tBatch Loss: 61.723022\tLearning Rate (w_theta): 0.001000\t TIME:8368.3s\n",
      "\t\t\t\tDisc: 0.642954\t\tSym: 7.828641\t\tSpars: 53.251427\n",
      "\t TVw: 0.131978 | TVb: -1.900485 | GSw: -0.235105 | GSb: 0.064606 | TSUw: 0.464579 | TSUb: 0.035132\n",
      "\n",
      "Train Epoch: 3057 [4000/8000 (50%)]\tBatch Loss: 62.821742\tLearning Rate (w_theta): 0.001000\t TIME:8369.9s\n",
      "\t\t\t\tDisc: 0.604288\t\tSym: 8.578816\t\tSpars: 53.638638\n",
      "\t TVw: 0.131769 | TVb: -1.900278 | GSw: -0.235105 | GSb: 0.064605 | TSUw: 0.464579 | TSUb: 0.035133\n",
      "Validating epoch 3057...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 63.125532062244346\n",
      "Average validation loss: 10.437073648347996\n",
      "Training epoch 3058...\n",
      "\n",
      "Train Epoch: 3058 [0/8000 (0%)]\tBatch Loss: 66.456754\tLearning Rate (w_theta): 0.001000\t TIME:8372.5s\n",
      "\t\t\t\tDisc: 0.610120\t\tSym: 9.044968\t\tSpars: 56.801666\n",
      "\t TVw: 0.131927 | TVb: -1.900061 | GSw: -0.235105 | GSb: 0.064605 | TSUw: 0.464578 | TSUb: 0.035133\n",
      "\n",
      "Train Epoch: 3058 [4000/8000 (50%)]\tBatch Loss: 58.644831\tLearning Rate (w_theta): 0.001000\t TIME:8374.1s\n",
      "\t\t\t\tDisc: 0.564895\t\tSym: 7.496222\t\tSpars: 50.583714\n",
      "\t TVw: 0.132142 | TVb: -1.899820 | GSw: -0.235105 | GSb: 0.064604 | TSUw: 0.464578 | TSUb: 0.035133\n",
      "Validating epoch 3058...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 62.73456511898393\n",
      "Average validation loss: 10.449724436506537\n",
      "Training epoch 3059...\n",
      "\n",
      "Train Epoch: 3059 [0/8000 (0%)]\tBatch Loss: 61.886074\tLearning Rate (w_theta): 0.001000\t TIME:8376.6s\n",
      "\t\t\t\tDisc: 0.640307\t\tSym: 8.110978\t\tSpars: 53.134789\n",
      "\t TVw: 0.132263 | TVb: -1.899573 | GSw: -0.235105 | GSb: 0.064604 | TSUw: 0.464578 | TSUb: 0.035133\n",
      "\n",
      "Train Epoch: 3059 [4000/8000 (50%)]\tBatch Loss: 65.177278\tLearning Rate (w_theta): 0.001000\t TIME:8378.3s\n",
      "\t\t\t\tDisc: 0.609304\t\tSym: 8.830722\t\tSpars: 55.737251\n",
      "\t TVw: 0.132029 | TVb: -1.899377 | GSw: -0.235105 | GSb: 0.064604 | TSUw: 0.464578 | TSUb: 0.035134\n",
      "Validating epoch 3059...\n",
      "-------------------------------------------\n",
      "Epoch statistics:\n",
      "Average training loss: 63.33039204974597\n",
      "Average validation loss: 9.903085805752811\n",
      "Training epoch 3060...\n",
      "\n",
      "Train Epoch: 3060 [0/8000 (0%)]\tBatch Loss: 62.357218\tLearning Rate (w_theta): 0.001000\t TIME:8380.8s\n",
      "\t\t\t\tDisc: 0.479255\t\tSym: 8.375003\t\tSpars: 53.502960\n",
      "\t TVw: 0.131588 | TVb: -1.899219 | GSw: -0.235106 | GSb: 0.064603 | TSUw: 0.464577 | TSUb: 0.035134\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 20000000 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4084\\3719546261.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\ecg-denoising\\workspace\\src\\fistanet\\solver.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_target\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m                 \u001b[1;31m# measured vector (104*1); add channels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    626\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Handle `CustomType` automatically\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \"\"\"\n\u001b[1;32m--> 265\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mcollate_numpy_array_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 20000000 bytes."
     ]
    }
   ],
   "source": [
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504e485-5480-4fae-a0e1-4382092f3fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a993b5-8bff-4192-8e0a-389d302c2c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2186b40-3acc-4d32-9620-ae8dac4a8731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ecgenv)",
   "language": "python",
   "name": "ecgenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
