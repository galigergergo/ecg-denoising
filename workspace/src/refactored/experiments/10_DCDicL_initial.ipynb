{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed402e43-c224-4c07-8b59-07eff24cf8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from os.path import join as pjoin\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "PROJECT_PATH = 'C:\\\\Users\\\\galiger.gergo\\\\Desktop\\\\ecg-denoising\\\\workspace'\n",
    "PROJECT_SRC_PATH = os.path.join(PROJECT_PATH, 'src\\\\refactored')\n",
    "PROJECT_DCDL_PATH = os.path.join(PROJECT_PATH, 'src\\\\refactored\\\\src\\\\models\\\\DCDicL')\n",
    "\n",
    "sys.path.append(PROJECT_SRC_PATH)\n",
    "sys.path.append(PROJECT_DCDL_PATH)\n",
    "\n",
    "from src.trainers.DCDicLTrainer import DCDicLTrainer\n",
    "from src.utils.loader import DataSplit\n",
    "from src.models.DCDicL.models.model import Model as DCDicL\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "mlflow.set_tracking_uri('http://localhost:8080')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "593e2376",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(PROJECT_PATH, 'data')\n",
    "DATA_FILE_GEN = 'generated/BW_master_10000_2024-04-07-12-43-32.pkl'\n",
    "DATA_FILE_SIGS = 'steinbrinker/testing_data_mvg_avg.npy'\n",
    "DATA_FILE_BW = 'mit-bih/bw'\n",
    "DATA_FILE_GAUSS = 'generated/gaussian_noise.npy'\n",
    "DATA_FILE_BPDN_MAX = 'generated/BW_alphas-BPDN_10000_2024-04-07-12-43-32.npy'\n",
    "DATA_FILE_BPDN = 'generated/BW_alphas-BPDN-1iters_10000_2024-04-07-12-43-32.npy'\n",
    "# DATA_FILE_BPDN = 'generated/BW_alphas-BPDN-3iters_10000_2024-04-07-12-43-32.npy'\n",
    "# DATA_FILE_BPDN = 'generated/BW_alphas-BPDN-5iters_10000_2024-04-07-12-43-32.npy'\n",
    "DATA_FILE_BPDN_FINAL = 'generated/BW_alphas-BPDN_10000_2024-04-07-12-43-32.npy'\n",
    "DICT_FILE_BW = 'steinbrinker/dictionary_BW_real_data.npy'\n",
    "NOISE_TYPE = 'bw'\n",
    "if NOISE_TYPE == 'bw':\n",
    "    DATA_FILE_NOISE = DATA_FILE_BW\n",
    "elif NOISE_TYPE == 'gauss':\n",
    "    DATA_FILE_NOISE = DATA_FILE_GAUSS\n",
    "DATA_SIZE = 10000\n",
    "BATCH_SIZE = 10\n",
    "TVT_SPLIT = {\n",
    "    'train': 80,\n",
    "    'valid': 10,\n",
    "    'test': 10\n",
    "}\n",
    "\n",
    "\n",
    "LOAD_MODEL_RUN = 'bdb03e3d83e94eccbebcaee555cb0da1'\n",
    "LOAD_MODEL_EPOCH = None\n",
    "\n",
    "LR_DEC_AFTER = 15000\n",
    "LR_DEC_EVERY = 10\n",
    "LEARNING_RATE = 1e-1\n",
    "\n",
    "opt = {\n",
    "  \"task\": \"train\"           # taskname\n",
    "  ,\n",
    "  \"is_train\": True,\n",
    "  \"gpu_ids\": [              # gpu id\n",
    "    0\n",
    "  ],\n",
    "  \"path\": {\n",
    "    \"root\": \"debug/denoising\",\n",
    "    \"pretrained_netG\": None       # pretrained path\n",
    "  },\n",
    "  \"data\": {\n",
    "    \"type\": \"denoising\",\n",
    "    \"n_channels\": 1,              # image channels\n",
    "    \"train\": {\n",
    "      \"sigma\": [\n",
    "        0,\n",
    "        50\n",
    "      ],\n",
    "      \"dataroot_H\": \"~/data/denoising/train/\",\n",
    "      \"H_size\": 128,             # patch size\n",
    "      \"num_workers\": 8,\n",
    "      \"batch_size\": 32           # batch size\n",
    "    },\n",
    "    \"test\": {\n",
    "      \"sigma\": [\n",
    "        15,\n",
    "        25,\n",
    "        50\n",
    "      ],\n",
    "      \"dataroot_H\": \"~/data/denoising/test\"      # test path\n",
    "    }\n",
    "  },\n",
    "  \"netG\": {\n",
    "    \"type\": \"denoising\",\n",
    "    \"d_size\": 3,      # dictionary size\n",
    "    \"n_iter\": 2,      # stages\n",
    "    \"in_nc\": 1,       # image channel\n",
    "    \"out_nc\": 1,\n",
    "    \"nc_x\": [\n",
    "      64,\n",
    "      128,\n",
    "      256,\n",
    "      512\n",
    "    ],\n",
    "    \"nb\": 2           # number of blocks\n",
    "  },\n",
    "  \"train\": {\n",
    "    \"manual_seed\": RANDOM_SEED,\n",
    "    \"reload_broadcast\": False,\n",
    "    \"G_optimizer_lr\": 1e-4,           # lr\n",
    "    \"G_scheduler_milestones\": [       # milestones\n",
    "      200000,\n",
    "      400000,\n",
    "      600000,\n",
    "      800000\n",
    "    ],\n",
    "    \"G_scheduler_gamma\": 0.5,\n",
    "    \"checkpoint_test\": 10,\n",
    "    \"checkpoint_savemodel\": 5000,\n",
    "    \"checkpoint_log\": 100,\n",
    "    \"checkpoint_saveimage\": 5000,\n",
    "    \"checkpoint_visual\": 5000\n",
    "  },\n",
    "  \"test\": {\n",
    "    \"visualize\": True\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7197ff3a-a079-4ada-a5db-8fed82ba5067",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = mlflow.set_experiment('dcdicl-initial-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2583a42-d126-4d9c-9bfa-33814d84dca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/29 14:04:15 WARNING mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics because creating `GPUMonitor` failed with error: GPU is lost.\n",
      "2024/11/29 14:04:15 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "C:\\Users\\galiger.gergo\\.conda\\envs\\ECGEnvNew\\Lib\\site-packages\\torch\\cuda\\__init__.py:128: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 1: invalid argument (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\c10\\cuda\\CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization method [orthogonal + uniform], gain is [0.20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/29 14:04:16 INFO mlflow.tracking._tracking_service.client: 🏃 View run rare-snail-464 at: http://localhost:8080/#/experiments/123604823160901751/runs/05302b2c093444aea9b4d666bca42de4.\n",
      "2024/11/29 14:04:16 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:8080/#/experiments/123604823160901751.\n",
      "2024/11/29 14:04:16 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/11/29 14:04:16 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 1: invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m dictionary \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_DIR, DICT_FILE_BW))\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m model \u001b[38;5;241m=\u001b[39m DCDicL(opt)\n\u001b[0;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39minit()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Specify and log training parameters\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\ecg-denoising\\workspace\\src\\refactored\\src\\models\\DCDicL\\models\\model.py:30\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, opt)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m opt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu_ids\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# self.is_train = opt['is_train']\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# self.type = opt['netG']['type']\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet \u001b[38;5;241m=\u001b[39m select_network(opt)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet \u001b[38;5;241m=\u001b[39m DataParallel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschedulers \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\.conda\\envs\\ECGEnvNew\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(convert)\n",
      "File \u001b[1;32m~\\.conda\\envs\\ECGEnvNew\\Lib\\site-packages\\torch\\nn\\modules\\module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 780\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\ECGEnvNew\\Lib\\site-packages\\torch\\nn\\modules\\module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 780\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\ECGEnvNew\\Lib\\site-packages\\torch\\nn\\modules\\module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 780\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\ECGEnvNew\\Lib\\site-packages\\torch\\nn\\modules\\module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[0;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\ECGEnvNew\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1155\u001b[0m             device,\n\u001b[0;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m             non_blocking,\n\u001b[0;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1159\u001b[0m         )\n\u001b[1;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1161\u001b[0m         device,\n\u001b[0;32m   1162\u001b[0m         dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1163\u001b[0m         non_blocking,\n\u001b[0;32m   1164\u001b[0m     )\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\ECGEnvNew\\Lib\\site-packages\\torch\\cuda\\__init__.py:314\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[0;32m    313\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 314\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_init()\n\u001b[0;32m    315\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[0;32m    318\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 1: invalid argument"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(log_system_metrics=True) as run:\n",
    "    # Seed random generators to ensure deterministic experiments\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    torch.cuda.manual_seed(RANDOM_SEED)\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    generator = torch.Generator()\n",
    "    generator.manual_seed(RANDOM_SEED) \n",
    "    \n",
    "    # Define PyTorch device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Read and log train, validation and test datasets\n",
    "    trn_ldr, val_ldr, tst_ldr = DataSplit(DATA_DIR, NOISE_TYPE, DATA_FILE_GEN, DATA_FILE_SIGS, DATA_FILE_NOISE,\n",
    "                                          DATA_FILE_BPDN, DATA_FILE_BPDN_FINAL, TVT_SPLIT, BATCH_SIZE, generator=generator)\n",
    "    Psi = torch.from_numpy(np.load(pjoin(DATA_DIR, DICT_FILE_BW)))\n",
    "    Psi = Psi.clone().detach().to(device=device)\n",
    "    bpdn_est = np.load(os.path.join(DATA_DIR, DATA_FILE_BPDN_MAX))\n",
    "    dictionary = np.load(os.path.join(DATA_DIR, DICT_FILE_BW))\n",
    "\n",
    "    # Load model\n",
    "    model = DCDicL(opt)\n",
    "    model.init()\n",
    "    \n",
    "    # Specify and log training parameters\n",
    "    dt = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "    params = {\n",
    "        'device': device,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'lr': LEARNING_RATE,\n",
    "        'lr_dec_after': LR_DEC_AFTER,\n",
    "        'lr_dec_every': LR_DEC_EVERY,\n",
    "        'opt': opt,\n",
    "        'load_model_run': LOAD_MODEL_RUN,\n",
    "        'load_model_epoch': LOAD_MODEL_EPOCH\n",
    "    }   \n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Define, train and evaluate model\n",
    "    trainer = DCDicLTrainer(model, Psi, bpdn_est, dictionary, params)\n",
    "    trainer.train(trn_ldr, val_ldr, 15000, start_epoch=0, log_model_every=100, log_comp_fig_every=10)\n",
    "    trainer.evaluate(tst_ldr)\n",
    "    trainer.evaluate(tst_ldr, criterion=torch.nn.HuberLoss(), crit_text='huber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7d8cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18445b6d-8981-4691-bf76-9dd2b281ab11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ECGEnvNew)",
   "language": "python",
   "name": "ecgenvnew"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
